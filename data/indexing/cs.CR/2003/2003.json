[{"id": "2003.00001", "submitter": "Ricardo P\\'erez-Marco", "authors": "Cyril Grunspan, Ricardo P\\'erez-Marco", "title": "The mathematics of Bitcoin", "comments": "7 pages, 4 figures", "journal-ref": "EMS Newsletter [115 (2020)], [31-37]. \\c{opyright} European\n  Mathematical Society", "doi": null, "report-no": null, "categories": "math.HO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey recent results on the mathematical stability of Bitcoin protocol.\nProfitability and probability of a double spend are estimated in closed form\nwith classical special functions. The stability of Bitcoin mining rules is\nanalyzed and several theorems are proved using martingale and combinatorics\ntechniques. In particular, the empirical observation of the stability of the\nBitcoin protocol is proved.\n  This survey article on the mathematics of Bitcoin is published by the\nNewsletter of the European Mathematical Society, vol.115, 2020, p.31-37.\nContinuation of arXiv:1601.05254 (EMS Newsletter, 100, 2016 p.32).\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 07:57:44 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Grunspan", "Cyril", ""], ["P\u00e9rez-Marco", "Ricardo", ""]]}, {"id": "2003.00003", "submitter": "Klaus-Tycho Foerster", "authors": "Utz Nisslmueller, Klaus-Tycho Foerster, Stefan Schmid, Christian\n  Decker", "title": "Toward Active and Passive Confidentiality Attacks On Cryptocurrency\n  Off-Chain Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptocurrency off-chain networks such as Lightning (e.g., Bitcoin) or Raiden\n(e.g., Ethereum) aim to increase the scalability of traditional on-chain\ntransactions. To support nodes in learning about possible paths to route their\ntransactions, these networks need to provide gossip and probing mechanisms.\nThis paper explores whether these mechanisms may be exploited to infer\nsensitive information about the flow of transactions, and eventually harm\nprivacy. In particular, we identify two threats, related to an active and a\npassive adversary. The first is a probing attack: here the adversary aims to\ndetect the maximum amount which is transferable in a given direction over a\ntarget channel by actively probing it and differentiating the response messages\nit receives. The second is a timing attack: the adversary discovers how close\nthe destination of a routed payment actually is, by acting as a passive\nman-in-the middle and analyzing the time deltas between sent messages and their\ncorresponding responses. We then analyze the limitations of these attacks and\npropose remediations for scenarios in which they are able to produce accurate\nresults.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 08:56:08 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Nisslmueller", "Utz", ""], ["Foerster", "Klaus-Tycho", ""], ["Schmid", "Stefan", ""], ["Decker", "Christian", ""]]}, {"id": "2003.00010", "submitter": "S\\'ebastien Rouault", "authors": "El-Mahdi El-Mhamdi, Rachid Guerraoui, S\\'ebastien Rouault", "title": "Distributed Momentum for Byzantine-resilient Learning", "comments": "Source code (for academic use only):\n  https://github.com/LPD-EPFL/ByzantineMomentum", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Momentum is a variant of gradient descent that has been proposed for its\nbenefits on convergence. In a distributed setting, momentum can be implemented\neither at the server or the worker side. When the aggregation rule used by the\nserver is linear, commutativity with addition makes both deployments\nequivalent. Robustness and privacy are however among motivations to abandon\nlinear aggregation rules. In this work, we demonstrate the benefits on\nrobustness of using momentum at the worker side. We first prove that computing\nmomentum at the workers reduces the variance-norm ratio of the gradient\nestimation at the server, strengthening Byzantine resilient aggregation rules.\nWe then provide an extensive experimental demonstration of the robustness\neffect of worker-side momentum on distributed SGD.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 16:57:27 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 09:24:24 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["El-Mhamdi", "El-Mahdi", ""], ["Guerraoui", "Rachid", ""], ["Rouault", "S\u00e9bastien", ""]]}, {"id": "2003.00040", "submitter": "Javier Carnerero-Cano", "authors": "Javier Carnerero-Cano, Luis Mu\\~noz-Gonz\\'alez, Phillippa Spencer and\n  Emil C. Lupu", "title": "Regularisation Can Mitigate Poisoning Attacks: A Novel Analysis Based on\n  Multiobjective Bilevel Optimisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) algorithms are vulnerable to poisoning attacks, where a\nfraction of the training data is manipulated to deliberately degrade the\nalgorithms' performance. Optimal poisoning attacks, which can be formulated as\nbilevel optimisation problems, help to assess the robustness of learning\nalgorithms in worst-case scenarios. However, current attacks against algorithms\nwith hyperparameters typically assume that these hyperparameters remain\nconstant ignoring the effect the attack has on them. We show that this approach\nleads to an overly pessimistic view of the robustness of the algorithms. We\npropose a novel optimal attack formulation that considers the effect of the\nattack on the hyperparameters by modelling the attack as a multiobjective\nbilevel optimisation problem. We apply this novel attack formulation to ML\nclassifiers using $L_2$ regularisation and show that, in contrast to results\npreviously reported, $L_2$ regularisation enhances the stability of the\nlearning algorithms and helps to mitigate the attacks. Our empirical evaluation\non different datasets confirms the limitations of previous strategies,\nevidences the benefits of using $L_2$ regularisation to dampen the effect of\npoisoning attacks and shows how the regularisation hyperparameter increases\nwith the fraction of poisoning points.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 19:46:10 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 13:44:48 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Carnerero-Cano", "Javier", ""], ["Mu\u00f1oz-Gonz\u00e1lez", "Luis", ""], ["Spencer", "Phillippa", ""], ["Lupu", "Emil C.", ""]]}, {"id": "2003.00118", "submitter": "Suat Mercan", "authors": "Dominik Danko, Suat Mercan, Mumin Cebe Kemal Akkaya", "title": "Assuring the Integrity of Videos from Wireless-based IoT Devices using\n  Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain technology has drawn attention fromvarious communities. The\nunderlying consensus mechanism inBlockchain enables a myriad of applications\nfor the integrityassurance of stored data. In this paper, we utilize\nBlockchaintechnology to verify the authenticity of a video captured by\nastreaming IoT device for forensic investigation purposes. Theproposed approach\ncomputes the hash of video frames beforethey leave the IoT device and are\ntransferred to a remote basestation. To guarantee the transmission, we ensure\nthat this hashis sent through a TCP-based connection. The hash is then storedon\nmultiple nodes on a permissioned blockchain platform. Incase the video is\nmodified, the discrepancy will be detected byinvestigating the previously\nstored hash on the blockchain andcomparing it with the hash of the existing\nframe in question.In this work, we present the prototype as proof-of-concept\nwithexperiment results. The system has been tested on a RaspberryPi with\ndifferent quality of videos to evaluate performance. Theresults show that the\nconcept can be implemented with moderatevideo resolutions.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 23:36:13 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Danko", "Dominik", ""], ["Mercan", "Suat", ""], ["Akkaya", "Mumin Cebe Kemal", ""]]}, {"id": "2003.00120", "submitter": "Zhikuan Zhao", "authors": "Zhuolin Yang, Zhikuan Zhao, Hengzhi Pei, Boxin Wang, Bojan Karlas, Ji\n  Liu, Heng Guo, Bo Li and Ce Zhang", "title": "End-to-end Robustness for Sensing-Reasoning Machine Learning Pipelines", "comments": "43 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning (ML) being applied to many mission-critical scenarios,\ncertifying ML model robustness becomes increasingly important. Many previous\nworks focuses on the robustness of independent ML and ensemble models, and can\nonly certify a very small magnitude of the adversarial perturbation. In this\npaper, we take a different viewpoint and improve learning robustness by going\nbeyond independent ML and ensemble models. We aim at promoting the generic\nSensing-Reasoning machine learning pipeline which contains both the sensing\n(e.g. deep neural networks) and reasoning (e.g. Markov logic networks (MLN))\ncomponents enriched with domain knowledge. Can domain knowledge help improve\nlearning robustness? Can we formally certify the end-to-end robustness of such\nan ML pipeline?\n  We first theoretically analyze the computational complexity of checking the\nprovable robustness in the reasoning component. We then derive the provable\nrobustness bound for several concrete reasoning components. We show that for\nreasoning components such as MLN and a specific family of Bayesian networks it\nis possible to certify the robustness of the whole pipeline even with a large\nmagnitude of perturbation which cannot be certified by existing work. Finally,\nwe conduct extensive real-world experiments on large scale datasets to evaluate\nthe certified robustness for Sensing-Reasoning ML pipelines.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 23:41:58 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 23:30:03 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Yang", "Zhuolin", ""], ["Zhao", "Zhikuan", ""], ["Pei", "Hengzhi", ""], ["Wang", "Boxin", ""], ["Karlas", "Bojan", ""], ["Liu", "Ji", ""], ["Guo", "Heng", ""], ["Li", "Bo", ""], ["Zhang", "Ce", ""]]}, {"id": "2003.00175", "submitter": "Daliang Xu", "authors": "Daliang Xu and Dongwei Chen and Chun Yang and KangSun and Xu Cheng and\n  Dong Tong", "title": "DangKiller: Eliminating Dangling Pointers Efficiently via Implicit\n  Identifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Use-After-Free vulnerabilities, allowing the attacker to access unintended\nmemory via dangling pointers, are more threatening. However, most detection\nschemes can only detect dangling pointers and invalid them, but not provide a\ntolerance mechanism to repair the errors at runtime. Also, these techniques\nobtain and manage the metadata inefficiently with complex structures and too\nmuch scan (sweep). The goal of this paper is to use compiler instrumentation to\neliminate dangling pointers automatically and efficiently. In this paper, we\nobserve that most techniques lack accurate efficient pointer graph metadata\nmaintaining methods, so they need to scan the log to reduce the redundancy and\nsweep the whole address space to find dangling pointers. Also, they lack a\ndirect, efficiently obtaining metadata approach. The key insight of this paper\nis that a unique identifier can be used as a key to a hash or direct-map\nalgorithm. Thus, this paper maintains the same implicit identifier with each\nmemory object and its corresponding referent. Associating the unique ID with\nmetadata for memory objects, obtaining and managing the pointer graph metadata\ncan be efficiently. Therefore, with the delayed free technique adopted into\nC/C++, we present the DangKiller as a novel and lightweight dangling pointer\nelimination solution. We first demonstrate the MinFat Pointer, which can\ncalculate unique implicit ID for each object and pointer quickly, and use hash\nalgorithm to obtain metadata. Secondly, we propose the Log Cache and Log\nCompression mechanism based on the ID to decrease the redundancy of dangling\npointer candidates. Coupled with the Address Tagging architecture on an ARM64\nsystem, our experiments show that the DangKiller can eliminate use-after-free\nvulnerabilities at only 11% and 3% runtime overheads for the SPEC CPU2006 and\n2017 benchmarks respectively, except for unique cases.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 04:11:27 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Xu", "Daliang", ""], ["Chen", "Dongwei", ""], ["Yang", "Chun", ""], ["KangSun", "", ""], ["Cheng", "Xu", ""], ["Tong", "Dong", ""]]}, {"id": "2003.00177", "submitter": "Fuwei Li", "authors": "Fuwei Li, Lifeng Lai, and Shuguang Cui", "title": "Optimal Feature Manipulation Attacks Against Linear Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate how to manipulate the coefficients obtained via\nlinear regression by adding carefully designed poisoning data points to the\ndataset or modify the original data points. Given the energy budget, we first\nprovide the closed-form solution of the optimal poisoning data point when our\ntarget is modifying one designated regression coefficient. We then extend the\nanalysis to the more challenging scenario where the attacker aims to change one\nparticular regression coefficient while making others to be changed as small as\npossible. For this scenario, we introduce a semidefinite relaxation method to\ndesign the best attack scheme. Finally, we study a more powerful adversary who\ncan perform a rank-one modification on the feature matrix. We propose an\nalternating optimization method to find the optimal rank-one modification\nmatrix. Numerical examples are provided to illustrate the analytical results\nobtained in this paper.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 04:26:59 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Li", "Fuwei", ""], ["Lai", "Lifeng", ""], ["Cui", "Shuguang", ""]]}, {"id": "2003.00229", "submitter": "Kang Wei", "authors": "Kang Wei, Jun Li, Ming Ding, Chuan Ma, Hang Su, Bo Zhang and H.\n  Vincent Poor", "title": "User-Level Privacy-Preserving Federated Learning: Analysis and\n  Performance Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL), as a type of collaborative machine learning\nframework, is capable of preserving private data from mobile terminals (MTs)\nwhile training the data into useful models. Nevertheless, from a viewpoint of\ninformation theory, it is still possible for a curious server to infer private\ninformation from the shared models uploaded by MTs. To address this problem, we\nfirst make use of the concept of local differential privacy (LDP), and propose\na user-level differential privacy (UDP) algorithm by adding artificial noise to\nthe shared models before uploading them to servers. According to our analysis,\nthe UDP framework can realize $(\\epsilon_{i}, \\delta_{i})$-LDP for the $i$-th\nMT with adjustable privacy protection levels by varying the variances of the\nartificial noise processes. We then derive a theoretical convergence\nupper-bound for the UDP algorithm. It reveals that there exists an optimal\nnumber of communication rounds to achieve the best learning performance. More\nimportantly, we propose a communication rounds discounting (CRD) method.\nCompared with the heuristic search method, the proposed CRD method can achieve\na much better trade-off between the computational complexity of searching and\nthe convergence performance. Extensive experiments indicate that our UDP\nalgorithm using the proposed CRD method can effectively improve both the\ntraining efficiency and model quality for the given privacy protection levels.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 10:13:39 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 01:39:03 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Wei", "Kang", ""], ["Li", "Jun", ""], ["Ding", "Ming", ""], ["Ma", "Chuan", ""], ["Su", "Hang", ""], ["Zhang", "Bo", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2003.00294", "submitter": "Suat Mercan", "authors": "Suat Mercan, Enes Erdin, and Kemal Akkaya", "title": "Improving Sustainability of Cryptocurrency Payment Networks for IoT\n  Applications", "comments": null, "journal-ref": null, "doi": "10.1109/ICCWorkshops49005.2020.9145389", "report-no": null, "categories": "cs.CR cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain-based cryptocurrencies received a lot of attention recently for\ntheir applications in many domains. IoT domain is one of such applications,\nwhich can utilize cryptocur-rencies for micro payments without compromising\ntheir payment privacy. However, long confirmation times of transactions and\nrelatively high fees hinder the adoption of cryptoccurency based\nmicro-payments. The payment channel networks is one of the proposed solutions\nto address these issue where nodes establish payment channels among themselves\nwithout writing on blockchain. IoT devices can benefit from such payment\nnetworks as long as they are capable of sustaining their overhead. Payment\nchannel networks pose unique characteristics as far as the routing problem is\nconcerned. Specifically, they should stay balanced to have a sustainable\nnetwork for maintaining payments for longer times, which is crucial for IoT\ndevices once they are deployed.In this paper, we present a payment channel\nnetwork design that aims to keep the channels balanced by using a common weight\npolicy across the network. We additionally propose using multi-point\nconnections to nodes for each IoT device for unbalanced payment scenarios. The\nexperiment results show that we can keep the channels in the network more\nequally balanced compared to the minimal fee approach. In addition, multiple\nconnections from IoT devices to nodes increase the success ratio significantly.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 16:33:25 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Mercan", "Suat", ""], ["Erdin", "Enes", ""], ["Akkaya", "Kemal", ""]]}, {"id": "2003.00296", "submitter": "Massimo Bartoletti", "authors": "Massimo Bartoletti, Maurizio Murgia, and Roberto Zunino", "title": "Renegotiation and recursion in Bitcoin contracts", "comments": "Full version of the paper presented at COORDINATION 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BitML is a process calculus to express smart contracts that can be run on\nBitcoin. One of its current limitations is that, once a contract has been\nstipulated, the participants cannot renegotiate its terms: this prevents\nexpressing common financial contracts, where funds have to be added by\nparticipants at run-time. In this paper, we extend BitML with a new primitive\nfor contract renegotiation. At the same time, the new primitive can be used to\nwrite recursive contracts, which was not possible in the original BitML. We\nshow that, despite the increased expressiveness, it is still possible to\nexecute BitML on standard Bitcoin, preserving the security guarantees of BitML.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 16:42:13 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 21:01:46 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Bartoletti", "Massimo", ""], ["Murgia", "Maurizio", ""], ["Zunino", "Roberto", ""]]}, {"id": "2003.00378", "submitter": "Xiao Zhang", "authors": "Xiao Zhang, Jinghui Chen, Quanquan Gu, David Evans", "title": "Understanding the Intrinsic Robustness of Image Distributions using\n  Conditional Generative Models", "comments": "14 pages, 2 figures, 5 tables, AISTATS final paper reformatted for\n  readability", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Starting with Gilmer et al. (2018), several works have demonstrated the\ninevitability of adversarial examples based on different assumptions about the\nunderlying input probability space. It remains unclear, however, whether these\nresults apply to natural image distributions. In this work, we assume the\nunderlying data distribution is captured by some conditional generative model,\nand prove intrinsic robustness bounds for a general class of classifiers, which\nsolves an open problem in Fawzi et al. (2018). Building upon the\nstate-of-the-art conditional generative models, we study the intrinsic\nrobustness of two common image benchmarks under $\\ell_2$ perturbations, and\nshow the existence of a large gap between the robustness limits implied by our\ntheory and the adversarial robustness achieved by current state-of-the-art\nrobust models. Code for all our experiments is available at\nhttps://github.com/xiaozhanguva/Intrinsic-Rob.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 01:45:04 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Zhang", "Xiao", ""], ["Chen", "Jinghui", ""], ["Gu", "Quanquan", ""], ["Evans", "David", ""]]}, {"id": "2003.00395", "submitter": "Ranesh Kumar Naha", "authors": "Abdullah Al-Noman Patwary, Anmin Fu, Ranesh Kumar Naha, Sudheer Kumar\n  Battula, Saurabh Garg, Md Anwarul Kaium Patwary, and Erfan Aghasian", "title": "Authentication, Access Control, Privacy, Threats and Trust Management\n  Towards Securing Fog Computing Environments: A Review", "comments": "34 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fog computing is an emerging computing paradigm that has come into\nconsideration for the deployment of IoT applications amongst researchers and\ntechnology industries over the last few years. Fog is highly distributed and\nconsists of a wide number of autonomous end devices, which contribute to the\nprocessing. However, the variety of devices offered across different users are\nnot audited. Hence, the security of Fog devices is a major concern in the Fog\ncomputing environment. Furthermore, mitigating and preventing those security\nmeasures is a research issue. Therefore, to provide the necessary security for\nFog devices, we need to understand what the security concerns are with regards\nto Fog. All aspects of Fog security, which have not been covered by other\nliterature works needs to be identified and need to be aggregate all issues in\nFog security. It needs to be noted that computation devices consist of many\nordinary users, and are not managed by any central entity or managing body.\nTherefore, trust and privacy is also a key challenge to gain market adoption\nfor Fog. To provide the required trust and privacy, we need to also focus on\nauthentication, threats and access control mechanisms as well as techniques in\nFog computing. In this paper, we perform a survey and propose a taxonomy, which\npresents an overview of existing security concerns in the context of the Fog\ncomputing paradigm. We discuss the Blockchain-based solutions towards a secure\nFog computing environment and presented various research challenges and\ndirections for future research.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 04:08:18 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Patwary", "Abdullah Al-Noman", ""], ["Fu", "Anmin", ""], ["Naha", "Ranesh Kumar", ""], ["Battula", "Sudheer Kumar", ""], ["Garg", "Saurabh", ""], ["Patwary", "Md Anwarul Kaium", ""], ["Aghasian", "Erfan", ""]]}, {"id": "2003.00405", "submitter": "Monther Aldwairi", "authors": "Monther Aldwairi, Yahya Flaifel, Khaldoon Mhaidat", "title": "Efficient Wu-Manber Pattern Matching Hardware for Intrusion and Malware\n  Detection", "comments": "6 pages", "journal-ref": "International Conference on Electrical, Electronics, Computers,\n  Communication, Mechanical and Computing (EECCMC), 28-29th January 2018, Tamil\n  Nadu, India", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network intrusion detection systems and antivirus software are essential in\ndetecting malicious network traffic and attacks such as denial-of-service and\nmalwares. Each attack, worm or virus has its own distinctive signature.\nSignature-based intrusion detection and antivirus systems depend on pattern\nmatching to look for possible attack signatures. Pattern matching is a very\ncomplex task, which requires a lot of time, memory and computing resources.\nSoftware-based intrusion detection is not fast enough to match high network\nspeeds and the increasing number of attacks. In this paper, we propose special\npurpose hardware for Wu-Manber pattern matching algorithm. FPGAs form an\nexcellent choice because of their massively parallel structure, reprogrammable\nlogic and memory resources. The hardware is designed in Verilog and implemented\nusing Xilinx ISE. For evaluation, we dope network traffic traces collected\nusing Wireshark with 2500 signatures from the ClamAV virus definitions\ndatabase. Experimental results show high speed that reaches up to 216 Mbps. In\naddition, we evaluate time, device usage, and power consumption.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 05:13:03 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Aldwairi", "Monther", ""], ["Flaifel", "Yahya", ""], ["Mhaidat", "Khaldoon", ""]]}, {"id": "2003.00476", "submitter": "Jumabek Alikhanov", "authors": "Azizjon Meliboev, Jumabek Alikhanov, Wooseong Kim", "title": "1D CNN Based Network Intrusion Detection with Normalization on\n  Imbalanced Data", "comments": "Need more polishing", "journal-ref": "IEEE ICAIIC 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrusion detection system (IDS) plays an essential role in computer networks\nprotecting computing resources and data from outside attacks. Recent IDS faces\nchallenges improving flexibility and efficiency of the IDS for unexpected and\nunpredictable attacks. Deep neural network (DNN) is considered popularly for\ncomplex systems to abstract features and learn as a machine learning technique.\nIn this paper, we propose a deep learning approach for developing the efficient\nand flexible IDS using one-dimensional Convolutional Neural Network (1D-CNN).\nTwo-dimensional CNN methods have shown remarkable performance in detecting\nobjects of images in computer vision area. Meanwhile, the 1D-CNN can be used\nfor supervised learning on time-series data. We establish a machine learning\nmodel based on the 1D-CNN by serializing Transmission Control Protocol/Internet\nProtocol (TCP/IP) packets in a predetermined time range as an invasion Internet\ntraffic model for the IDS, where normal and abnormal network traffics are\ncategorized and labeled for supervised learning in the 1D-CNN. We evaluated our\nmodel on UNSW\\_NB15 IDS dataset to show the effectiveness of our method. For\ncomparison study in performance, machine learning-based Random Forest (RF) and\nSupport Vector Machine (SVM) models in addition to the 1D-CNN with various\nnetwork parameters and architecture are exploited. In each experiment, the\nmodels are run up to 200 epochs with a learning rate in 0.0001 on imbalanced\nand balanced data. 1D-CNN and its variant architectures have outperformed\ncompared to the classical machine learning classifiers. This is mainly due to\nthe reason that CNN has the capability to extract high-level feature\nrepresentations that represent the abstract form of low-level feature sets of\nnetwork traffic connections.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 12:23:46 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 09:44:56 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Meliboev", "Azizjon", ""], ["Alikhanov", "Jumabek", ""], ["Kim", "Wooseong", ""]]}, {"id": "2003.00505", "submitter": "Lichao Sun", "authors": "Lichao Sun, Yingbo Zhou, Philip S. Yu, Caiming Xiong", "title": "Differentially Private Deep Learning with Smooth Sensitivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensuring the privacy of sensitive data used to train modern machine learning\nmodels is of paramount importance in many areas of practice. One approach to\nstudy these concerns is through the lens of differential privacy. In this\nframework, privacy guarantees are generally obtained by perturbing models in\nsuch a way that specifics of data used to train the model are made ambiguous. A\nparticular instance of this approach is through a \"teacher-student\" framework,\nwherein the teacher, who owns the sensitive data, provides the student with\nuseful, but noisy, information, hopefully allowing the student model to perform\nwell on a given task without access to particular features of the sensitive\ndata. Because stronger privacy guarantees generally involve more significant\nperturbation on the part of the teacher, deploying existing frameworks\nfundamentally involves a trade-off between student's performance and privacy\nguarantee. One of the most important techniques used in previous works involves\nan ensemble of teacher models, which return information to a student based on a\nnoisy voting procedure. In this work, we propose a novel voting mechanism with\nsmooth sensitivity, which we call Immutable Noisy ArgMax, that, under certain\nconditions, can bear very large random noising from the teacher without\naffecting the useful information transferred to the student.\n  Compared with previous work, our approach improves over the state-of-the-art\nmethods on all measures, and scale to larger tasks with both better performance\nand stronger privacy ($\\epsilon \\approx 0$). This new proposed framework can be\napplied with any machine learning models, and provides an appealing solution\nfor tasks that requires training on a large amount of data.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 15:38:00 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Sun", "Lichao", ""], ["Zhou", "Yingbo", ""], ["Yu", "Philip S.", ""], ["Xiong", "Caiming", ""]]}, {"id": "2003.00542", "submitter": "Ashutosh Bhatia Dr.", "authors": "Ayush Bahuguna, Ashutosh Bhatia, Kamlesh Tiwari, and Deepak\n  Vishwakarma", "title": "User profiling using smartphone network traffic analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent decade has witnessed phenomenal growth in communication\ntechnology. Development of user-friendly software platforms, such as Facebook,\nWhatsApp etc. have facilitated ease of communication and thereby people have\nstarted freely sharing messages and multimedia over the Internet. Further,\nthere is a shift in trends with services being accessed from smartphones over\npersonal computers. To protect the security and privacy of the smartphone\nusers, most of the applications use encryption that encapsulates communications\nover the Internet. However, research has shown that the statistical information\npresent in a traffic can be used to identify the application, and further, the\nactivity performed by the user inside that application. In this paper, we\nextend the scope of analysis by proposing a learning framework to leverage\napplication and activity data to profile smartphone users in terms of their\ngender, profession age group etc. This will greatly help the authoritative\nagencies to conduct their investigations related to national security and other\npurposes.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 18:17:24 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Bahuguna", "Ayush", ""], ["Bhatia", "Ashutosh", ""], ["Tiwari", "Kamlesh", ""], ["Vishwakarma", "Deepak", ""]]}, {"id": "2003.00563", "submitter": "Roi Livni", "authors": "Mark Bun and Roi Livni and Shay Moran", "title": "An Equivalence Between Private Classification and Online Prediction", "comments": "An earlier version of this manuscript claimed an upper bound over the\n  sample complexity that is exponential in the Littlestone dimension. The\n  argument was erranous, and the current version contains a correction, which\n  leads to double-exponential dependence in the Littlestone-dimension", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that every concept class with finite Littlestone dimension can be\nlearned by an (approximate) differentially-private algorithm. This answers an\nopen question of Alon et al. (STOC 2019) who proved the converse statement\n(this question was also asked by Neel et al.~(FOCS 2019)). Together these two\nresults yield an equivalence between online learnability and private PAC\nlearnability.\n  We introduce a new notion of algorithmic stability called \"global stability\"\nwhich is essential to our proof and may be of independent interest. We also\ndiscuss an application of our results to boosting the privacy and accuracy\nparameters of differentially-private learners.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 19:20:37 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 03:50:38 GMT"}, {"version": "v3", "created": "Tue, 22 Jun 2021 08:52:13 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Bun", "Mark", ""], ["Livni", "Roi", ""], ["Moran", "Shay", ""]]}, {"id": "2003.00572", "submitter": "Shravan Ravi Narayan", "authors": "Shravan Narayan, Craig Disselkoen, Tal Garfinkel, Nathan Froyd, Eric\n  Rahm, Sorin Lerner, Hovav Shacham, Deian Stefan", "title": "Retrofitting Fine Grain Isolation in the Firefox Renderer (Extended\n  Version)", "comments": "Accepted at Usenix Security 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Firefox and other major browsers rely on dozens of third-party libraries to\nrender audio, video, images, and other content. These libraries are a frequent\nsource of vulnerabilities. To mitigate this threat, we are migrating Firefox to\nan architecture that isolates these libraries in lightweight sandboxes,\ndramatically reducing the impact of a compromise.\n  Retrofitting isolation can be labor-intensive, very prone to security bugs,\nand requires critical attention to performance. To help, we developed RLBox, a\nframework that minimizes the burden of converting Firefox to securely and\nefficiently use untrusted code. To enable this, RLBox employs static\ninformation flow enforcement, and lightweight dynamic checks, expressed\ndirectly in the C++ type system.\n  RLBox supports efficient sandboxing through either software-based-fault\nisolation or multi-core process isolation. Performance overheads are modest and\ntransient, and have only minor impact on page latency. We demonstrate this by\nsandboxing performance-sensitive image decoding libraries ( libjpeg and libpng\n), video decoding libraries ( libtheora and libvpx ), the libvorbis audio\ndecoding library, and the zlib decompression library.\n  RLBox, using a WebAssembly sandbox, has been integrated into production\nFirefox to sandbox the libGraphite font shaping library.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 20:05:25 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 00:01:34 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Narayan", "Shravan", ""], ["Disselkoen", "Craig", ""], ["Garfinkel", "Tal", ""], ["Froyd", "Nathan", ""], ["Rahm", "Eric", ""], ["Lerner", "Sorin", ""], ["Shacham", "Hovav", ""], ["Stefan", "Deian", ""]]}, {"id": "2003.00578", "submitter": "Patrick Struck", "authors": "Tommaso Gagliardoni, Juliane Kr\\\"amer, and Patrick Struck", "title": "Quantum Indistinguishability for Public Key Encryption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study the quantum security of public key encryption schemes\n(PKE). Boneh and Zhandry (CRYPTO'13) initiated this research area for PKE and\nsymmetric key encryption (SKE), albeit restricted to a classical\nindistinguishability phase. Gagliardoni et al. (CRYPTO'16) advanced the study\nof quantum security by giving, for SKE, the first definition with a quantum\nindistinguishability phase. For PKE, on the other hand, no notion of quantum\nsecurity with a quantum indistinguishability phase exists. Our main result is a\nnovel quantum security notion (qIND-qCPA) for PKE with a quantum\nindistinguishability phase, which closes the aforementioned gap. We show a\ndistinguishing attack against code-based schemes and against LWE-based schemes\nwith certain parameters. We also show that the canonical hybrid PKE-SKE\nencryption construction is qIND-qCPA-secure, even if the underlying PKE scheme\nby itself is not. Finally, we classify quantum-resistant PKE schemes based on\nthe applicability of our security notion. Our core idea follows the approach of\nGagliardoni et al. by using so-called type-2 operators for encrypting the\nchallenge message. At first glance, type-2 operators appear unnatural for PKE,\nas the canonical way of building them requires both the secret and the public\nkey. However, we identify a class of PKE schemes - which we call recoverable -\nand show that for this class type-2 operators require merely the public key.\nMoreover, recoverable schemes allow to realise type-2 operators even if they\nsuffer from decryption failures, which in general thwarts the reversibility\nmandated by type-2 operators. Our work reveals that many real-world\nquantum-resistant PKE schemes, including most NIST PQC candidates and the\ncanonical hybrid construction, are indeed recoverable.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 20:42:32 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 08:45:10 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 09:02:16 GMT"}, {"version": "v4", "created": "Tue, 2 Mar 2021 14:52:15 GMT"}, {"version": "v5", "created": "Sun, 13 Jun 2021 07:11:16 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Gagliardoni", "Tommaso", ""], ["Kr\u00e4mer", "Juliane", ""], ["Struck", "Patrick", ""]]}, {"id": "2003.00602", "submitter": "Monica Ribero", "authors": "M\\'onica Ribero, Jette Henderson, Sinead Williamson, Haris Vikalo", "title": "Federating Recommendations Using Differentially Private Prototypes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning methods allow us to make recommendations to users in\napplications across fields including entertainment, dating, and commerce, by\nexploiting similarities in users' interaction patterns. However, in domains\nthat demand protection of personally sensitive data, such as medicine or\nbanking, how can we learn such a model without accessing the sensitive data,\nand without inadvertently leaking private information? We propose a new\nfederated approach to learning global and local private models for\nrecommendation without collecting raw data, user statistics, or information\nabout personal preferences. Our method produces a set of prototypes that allows\nus to infer global behavioral patterns, while providing differential privacy\nguarantees for users in any database of the system. By requiring only two\nrounds of communication, we both reduce the communication costs and avoid the\nexcessive privacy loss associated with iterative procedures. We test our\nframework on synthetic data as well as real federated medical data and\nMovielens ratings data. We show local adaptation of the global model allows our\nmethod to outperform centralized matrix-factorization-based recommender system\nmodels, both in terms of accuracy of matrix reconstruction and in terms of\nrelevance of the recommendations, while maintaining provable privacy\nguarantees. We also show that our method is more robust and is characterized by\nsmaller variance than individual models learned by independent entities.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 22:21:31 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Ribero", "M\u00f3nica", ""], ["Henderson", "Jette", ""], ["Williamson", "Sinead", ""], ["Vikalo", "Haris", ""]]}, {"id": "2003.00610", "submitter": "Laia Amor\\'os", "authors": "Laia Amor\\'os, Syed Mahbub Hafiz, Keewoo Lee, and M. Caner Tol", "title": "Gimme That Model!: A Trusted ML Model Trading Protocol", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a HE-based protocol for trading ML models and describe possible\nimprovements to the protocol to make the overall transaction more efficient and\nsecure.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 23:24:10 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 09:36:05 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Amor\u00f3s", "Laia", ""], ["Hafiz", "Syed Mahbub", ""], ["Lee", "Keewoo", ""], ["Tol", "M. Caner", ""]]}, {"id": "2003.00633", "submitter": "Toshiyuki Katsura", "authors": "Toshiyuki Katsura and Katsuyuki Takashima", "title": "Counting Richelot isogenies between superspecial abelian surfaces", "comments": "16 pages, the replacement of the paper \"Counting superspecial\n  Richelot isogenies and its cryptographic application.\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Castryck, Decru, and Smith used superspecial genus-2 curves and their\nRichelot isogeny graph for basing genus-2 isogeny cryptography, and recently,\nCostello and Smith devised an improved isogeny path-finding algorithm in the\ngenus-2 setting. In order to establish a firm ground for the cryptographic\nconstruction and analysis, we give a new characterization of {\\em decomposed\nRichelot isogenies} in terms of {\\em involutive reduced automorphisms} of\ngenus-2 curves over a finite field, and explicitly count such decomposed (and\nnon-decomposed) Richelot isogenies between {\\em superspecial} principally\npolarized abelian surfaces. As a corollary, we give another algebraic geometric\nproof of Theorem 2 in the paper of Castryck et al.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 02:37:14 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 15:40:55 GMT"}, {"version": "v3", "created": "Sat, 27 Jun 2020 13:29:47 GMT"}, {"version": "v4", "created": "Tue, 28 Jul 2020 00:15:42 GMT"}, {"version": "v5", "created": "Sat, 19 Sep 2020 02:22:10 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Katsura", "Toshiyuki", ""], ["Takashima", "Katsuyuki", ""]]}, {"id": "2003.00653", "submitter": "Wei Jin", "authors": "Wei Jin, Yaxin Li, Han Xu, Yiqi Wang, Shuiwang Ji, Charu Aggarwal and\n  Jiliang Tang", "title": "Adversarial Attacks and Defenses on Graphs: A Review, A Tool and\n  Empirical Studies", "comments": "Accepted by SIGKDD Explorations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks (DNNs) have achieved significant performance in various\ntasks. However, recent studies have shown that DNNs can be easily fooled by\nsmall perturbation on the input, called adversarial attacks. As the extensions\nof DNNs to graphs, Graph Neural Networks (GNNs) have been demonstrated to\ninherit this vulnerability. Adversary can mislead GNNs to give wrong\npredictions by modifying the graph structure such as manipulating a few edges.\nThis vulnerability has arisen tremendous concerns for adapting GNNs in\nsafety-critical applications and has attracted increasing research attention in\nrecent years. Thus, it is necessary and timely to provide a comprehensive\noverview of existing graph adversarial attacks and the countermeasures. In this\nsurvey, we categorize existing attacks and defenses, and review the\ncorresponding state-of-the-art methods. Furthermore, we have developed a\nrepository with representative algorithms\n(https://github.com/DSE-MSU/DeepRobust/tree/master/deeprobust/graph). The\nrepository enables us to conduct empirical studies to deepen our understandings\non attacks and defenses on graphs.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 04:32:38 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 18:31:56 GMT"}, {"version": "v3", "created": "Sat, 12 Dec 2020 17:21:00 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Jin", "Wei", ""], ["Li", "Yaxin", ""], ["Xu", "Han", ""], ["Wang", "Yiqi", ""], ["Ji", "Shuiwang", ""], ["Aggarwal", "Charu", ""], ["Tang", "Jiliang", ""]]}, {"id": "2003.00801", "submitter": "Shoeb Siddiqui", "authors": "Shoeb Siddiqui, Ganesh Vanahalli, Sujit Gujar", "title": "BitcoinF: Achieving Fairness for Bitcoin in Transaction-Fee-Only Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A blockchain, such as Bitcoin, is an append-only, secure, transparent,\ndistributed ledger. A fair blockchain is expected to have healthy metrics; high\nhonest mining power, low processing latency, i.e., low wait times for\ntransactions and stable price of consumption, i.e., the minimum transaction fee\nrequired to have a transaction processed. As Bitcoin matures, the influx of\ntransactions increases and the block rewards become insignificant. We show that\nunder these conditions, it becomes hard to maintain the health of the\nblockchain. In Bitcoin, under these mature operating conditions (MOC), the\nminers would find it challenging to cover their mining costs as there would be\nno more revenue from merely mining a block. It may cause miners not to continue\nmining, threatening the blockchain's security. Further, as we show in this\npaper using simulations, the cost of acting in favor of the health of the\nblockchain, under MOC, is very high in Bitcoin, causing all miners to process\ntransactions greedily. It leads to stranded transactions, i.e., transactions\noffering low transaction fees, experiencing unreasonably high processing\nlatency. To make matters worse, a compounding effect of these stranded\ntransactions is the rising price of consumption. Such phenomena not only induce\nunfairness as experienced by the miners and the users but also deteriorate the\nhealth of the blockchain.\n  We propose BitcoinF transaction processing protocol, a simple, yet highly\neffective modification to the existing Bitcoin protocol to fix these issues of\nunfairness. BitcoinF resolves these issues of unfairness while preserving the\nability of the users to express urgency and have their transactions\nprioritized.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 12:37:08 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Siddiqui", "Shoeb", ""], ["Vanahalli", "Ganesh", ""], ["Gujar", "Sujit", ""]]}, {"id": "2003.00862", "submitter": "Bing Li", "authors": "Grace Li Zhang, Bing Li, Meng Li, Bei Yu, David Z. Pan, Michaela\n  Brunner, Georg Sigl and Ulf Schlichtmann", "title": "TimingCamouflage+: Netlist Security Enhancement with Unconventional\n  Timing (with Appendix)", "comments": null, "journal-ref": null, "doi": "10.1109/TCAD.2020.2974338", "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With recent advances in reverse engineering, attackers can reconstruct a\nnetlist to counterfeit chips by opening the die and scanning all layers of\nauthentic chips. This relatively easy counterfeiting is made possible by the\nuse of the standard simple clocking scheme, where all combinational blocks\nfunction within one clock period, so that a netlist of combinational logic\ngates and flip-flops is sufficient to duplicate a design. In this paper, we\npropose to invalidate the assumption that a netlist completely represents the\nfunction of a circuit with unconventional timing. With the introduced\nwave-pipelining paths, attackers have to capture gate and interconnect delays\nduring reverse engineering, or to test a huge number of combinational paths to\nidentify the wave-pipelining paths. To hinder the test-based attack, we\nconstruct false paths with wave-pipelining to increase the counterfeiting\nchallenge. Experimental results confirm that wave-pipelining true paths and\nfalse paths can be constructed in benchmark circuits successfully with only a\nnegligible cost, thus thwarting the potential attack techniques.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 13:10:03 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Zhang", "Grace Li", ""], ["Li", "Bing", ""], ["Li", "Meng", ""], ["Yu", "Bei", ""], ["Pan", "David Z.", ""], ["Brunner", "Michaela", ""], ["Sigl", "Georg", ""], ["Schlichtmann", "Ulf", ""]]}, {"id": "2003.00870", "submitter": "Shahram Behzad", "authors": "Shahram Behzad, Reza Fotohi, Jaber Hosseini Balov, Mohammad Javad\n  Rabipour", "title": "An Artificial Immune Based Approach for Detection and Isolation\n  Misbehavior Attacks in Wireless Networks", "comments": "19 pages, 12 figures, Journal", "journal-ref": "JCP, 13(6), 705-720 (2018)", "doi": "10.17706/jcp.13.6.705-720", "report-no": null, "categories": "cs.NI cs.CR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MANETs (Mobile Ad-hoc Networks) is a temporal network, which is managed by\nautonomous nodes, which have the ability to communicate with each other without\nhaving fixed network infrastructure or any central base station. Due to some\nreasons such as dynamic changes of the network topology, trusting the nodes to\neach other, lack of fixed substructure for the analysis of nodes behaviors and\nloss of specific offensive lines, this type of networks is not supportive\nagainst malicious nodes attacks. One of these attacks is black hole attack. In\nthis attack, the malicious nodes absorb data packets and destroy them. Thus, it\nis essential to present an algorithm against the black hole attacks. This paper\nproposed a new approach, which improvement the security of DSR routing protocol\nto encounter the black hole attacks. This schema tries to identify malicious\nnodes according to nodes behaviors in a MANETs and isolate them from routing.\nThe proposed protocol, called AIS-DSR (Artificial Immune System DSR) employ AIS\n(Artificial Immune System) to defend against black hole attacks. AIS-DSR is\nevaluated through extensive simulations in the ns-2 environment. The results\nshow that AIS-DSR outperforms other existing solutions in terms of throughput,\nend-to-end delay, packets loss ratio and packets drop ratio.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 16:27:19 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Behzad", "Shahram", ""], ["Fotohi", "Reza", ""], ["Balov", "Jaber Hosseini", ""], ["Rabipour", "Mohammad Javad", ""]]}, {"id": "2003.00903", "submitter": "Peter Robinson", "authors": "Peter Robinson, Raghavendra Ramesh, John Brainard, and Sandra Johnson", "title": "Atomic Crosschain Transactions White Paper", "comments": "8 pages, 8 figures, 3 code listings. arXiv admin note: substantial\n  text overlap with arXiv:1911.08083", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Atomic Crosschain Transaction technology allows composable programming across\nprivate Ethereum blockchains. It allows for inter-contract and inter-blockchain\nfunction calls that are both synchronous and atomic: if one part fails, the\nwhole call graph of function calls is rolled back. It is not based on existing\ntechniques such as Hash Time Locked Contracts, relay chains, block header\ntransfer, or trusted intermediaries. BLS Threshold Signatures are used to prove\nto validators on one blockchain that information came from another blockchain\nand that a majority of the validators of that blockchain agree on the\ninformation. Coordination Contracts are used to manage the state of a\nCrosschain Transaction and as a repository of Blockchain Public Keys. Dynamic\ncode analysis and signed nested transactions are used together with live\nargument checking to ensure execution only occurs if the execution results in\nvalid state changes. Contract Locking and Lockability enable atomic updates.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 06:35:20 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 05:12:46 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Robinson", "Peter", ""], ["Ramesh", "Raghavendra", ""], ["Brainard", "John", ""], ["Johnson", "Sandra", ""]]}, {"id": "2003.00916", "submitter": "Bert Abrath", "authors": "Bert Abrath, Bart Coppens, Jens Van den Broeck, Brecht Wyseur,\n  Alessandro Cabutto, Paolo Falcarin, Bjorn De Sutter", "title": "Code Renewability for Native Software Protection", "comments": "30 pages", "journal-ref": null, "doi": "10.1145/3404891", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software protection aims at safeguarding assets embedded in software by\npreventing and delaying reverse engineering and tampering attacks. This paper\npresents an architecture and supporting tool flow to renew parts of native\napplications dynamically. Renewed and diversified code and data belonging to\neither the original application or to linked-in protections are delivered from\na secure server to a client on demand. This results in frequent changes to the\nsoftware components when they are under attack, thus making attacks harder. By\nsupporting various forms of diversification and renewability, novel protection\ncombinations become available, and existing combinations become stronger. The\nprototype implementation is evaluated on a number of industrial use cases.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 13:45:04 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Abrath", "Bert", ""], ["Coppens", "Bart", ""], ["Broeck", "Jens Van den", ""], ["Wyseur", "Brecht", ""], ["Cabutto", "Alessandro", ""], ["Falcarin", "Paolo", ""], ["De Sutter", "Bjorn", ""]]}, {"id": "2003.00971", "submitter": "Philip Kulp", "authors": "Philip H. Kulp and Nikki E. Robinson", "title": "Graphing Website Relationships for Risk Prediction: Identifying Derived\n  Threats to Users Based on Known Indicators", "comments": "10 pages, 3 figures, 3 tables", "journal-ref": null, "doi": "10.1007/978-3-030-63089-8", "report-no": null, "categories": "cs.CR cs.DB cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hypothesis for the study was that the relationship based on referrer\nlinks and the number of hops to a malicious site could indicate the risk to\nanother website. We chose Receiver Operating Characteristics (ROC) analysis as\nthe method of comparing true positive and false positive rates for captured web\ntraffic to test the predictive capabilities of our model. Known threat\nindicators were used as designators, and the Neo4j graph database was leveraged\nto map the relationships between other websites based on referring links. Using\nthe referring traffic, we mapped user visits across websites with a known\nrelationship to track the rate at which users progressed from a non-malicious\nwebsite to a known threat. The results were grouped by the hop distance from\nthe known threat to calculate the predictive rate. The results of the model\nproduced true positive rates between 58.59% and 63.45% and false positive rates\nbetween 7.42% to 37.50%, respectively. The true and false positive rates\nsuggest an improved performance based on the closer proximity from the known\nthreat, while an increased referring distance from the threat resulted in\nhigher rates of false positives.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 15:41:48 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Kulp", "Philip H.", ""], ["Robinson", "Nikki E.", ""]]}, {"id": "2003.00973", "submitter": "Debabrota Basu", "authors": "Ashish Dandekar, Debabrota Basu, Stephane Bressan", "title": "Differential Privacy at Risk: Bridging Randomness and Privacy Budget", "comments": "Presented in Workshop on Privacy Preserving AI (PPAI) at AAAI, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The calibration of noise for a privacy-preserving mechanism depends on the\nsensitivity of the query and the prescribed privacy level. A data steward must\nmake the non-trivial choice of a privacy level that balances the requirements\nof users and the monetary constraints of the business entity. We analyse roles\nof the sources of randomness, namely the explicit randomness induced by the\nnoise distribution and the implicit randomness induced by the data-generation\ndistribution, that are involved in the design of a privacy-preserving\nmechanism. The finer analysis enables us to provide stronger privacy guarantees\nwith quantifiable risks. Thus, we propose privacy at risk that is a\nprobabilistic calibration of privacy-preserving mechanisms. We provide a\ncomposition theorem that leverages privacy at risk. We instantiate the\nprobabilistic calibration for the Laplace mechanism by providing analytical\nresults. We also propose a cost model that bridges the gap between the privacy\nlevel and the compensation budget estimated by a GDPR compliant business\nentity. The convexity of the proposed cost model leads to a unique fine-tuning\nof privacy level that minimises the compensation budget. We show its\neffectiveness by illustrating a realistic scenario that avoids overestimation\nof the compensation budget by using privacy at risk for the Laplace mechanism.\nWe quantitatively show that composition using the cost optimal privacy at risk\nprovides stronger privacy guarantee than the classical advanced composition.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 15:44:14 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 23:14:27 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Dandekar", "Ashish", ""], ["Basu", "Debabrota", ""], ["Bressan", "Stephane", ""]]}, {"id": "2003.00997", "submitter": "Aleksei Triastcyn", "authors": "Aleksei Triastcyn, Boi Faltings", "title": "Generating Higher-Fidelity Synthetic Datasets with Privacy Guarantees", "comments": "7 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of enhancing user privacy in common machine\nlearning development tasks, such as data annotation and inspection, by\nsubstituting the real data with samples form a generative adversarial network.\nWe propose employing Bayesian differential privacy as the means to achieve a\nrigorous theoretical guarantee while providing a better privacy-utility\ntrade-off. We demonstrate experimentally that our approach produces\nhigher-fidelity samples, compared to prior work, allowing to (1) detect more\nsubtle data errors and biases, and (2) reduce the need for real data labelling\nby achieving high accuracy when training directly on artificial samples.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 16:23:41 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Triastcyn", "Aleksei", ""], ["Faltings", "Boi", ""]]}, {"id": "2003.01031", "submitter": "Giorgio Severi", "authors": "Giorgio Severi, Jim Meyer, Scott Coull, Alina Oprea", "title": "Explanation-Guided Backdoor Poisoning Attacks Against Malware\n  Classifiers", "comments": "18 pages, 5 figures. To appear in USENIX Security 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training pipelines for machine learning (ML) based malware classification\noften rely on crowdsourced threat feeds, exposing a natural attack injection\npoint. In this paper, we study the susceptibility of feature-based ML malware\nclassifiers to backdoor poisoning attacks, specifically focusing on challenging\n\"clean label\" attacks where attackers do not control the sample labeling\nprocess. We propose the use of techniques from explainable machine learning to\nguide the selection of relevant features and values to create effective\nbackdoor triggers in a model-agnostic fashion. Using multiple reference\ndatasets for malware classification, including Windows PE files, PDFs, and\nAndroid applications, we demonstrate effective attacks against a diverse set of\nmachine learning models and evaluate the effect of various constraints imposed\non the attacker. To demonstrate the feasibility of our backdoor attacks in\npractice, we create a watermarking utility for Windows PE files that preserves\nthe binary's functionality, and we leverage similar behavior-preserving\nalteration methodologies for Android and PDF files. Finally, we experiment with\npotential defensive strategies and show the difficulties of completely\ndefending against these attacks, especially when the attacks blend in with the\nlegitimate sample distribution.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 17:04:38 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2020 02:12:35 GMT"}, {"version": "v3", "created": "Mon, 11 Jan 2021 00:14:51 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Severi", "Giorgio", ""], ["Meyer", "Jim", ""], ["Coull", "Scott", ""], ["Oprea", "Alina", ""]]}, {"id": "2003.01090", "submitter": "Ahmadreza Jeddi", "authors": "Ahmadreza Jeddi, Mohammad Javad Shafiee, Michelle Karg, Christian\n  Scharfenberger and Alexander Wong", "title": "Learn2Perturb: an End-to-end Feature Perturbation Learning to Improve\n  Adversarial Robustness", "comments": "13 pages, 6 figures To be published in proceedings of IEEE conference\n  on Computer Vision and Pattern Recognition (CVPR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep neural networks have been achieving state-of-the-art performance\nacross a wide variety of applications, their vulnerability to adversarial\nattacks limits their widespread deployment for safety-critical applications.\nAlongside other adversarial defense approaches being investigated, there has\nbeen a very recent interest in improving adversarial robustness in deep neural\nnetworks through the introduction of perturbations during the training process.\nHowever, such methods leverage fixed, pre-defined perturbations and require\nsignificant hyper-parameter tuning that makes them very difficult to leverage\nin a general fashion. In this study, we introduce Learn2Perturb, an end-to-end\nfeature perturbation learning approach for improving the adversarial robustness\nof deep neural networks. More specifically, we introduce novel\nperturbation-injection modules that are incorporated at each layer to perturb\nthe feature space and increase uncertainty in the network. This feature\nperturbation is performed at both the training and the inference stages.\nFurthermore, inspired by the Expectation-Maximization, an alternating\nback-propagation training algorithm is introduced to train the network and\nnoise parameters consecutively. Experimental results on CIFAR-10 and CIFAR-100\ndatasets show that the proposed Learn2Perturb method can result in deep neural\nnetworks which are $4-7\\%$ more robust on $l_{\\infty}$ FGSM and PDG adversarial\nattacks and significantly outperforms the state-of-the-art against $l_2$ $C\\&W$\nattack and a wide range of well-known black-box attacks.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 18:27:35 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 16:51:46 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Jeddi", "Ahmadreza", ""], ["Shafiee", "Mohammad Javad", ""], ["Karg", "Michelle", ""], ["Scharfenberger", "Christian", ""], ["Wong", "Alexander", ""]]}, {"id": "2003.01171", "submitter": "Xxx Lin Lin", "authors": "Daixin Wang and Jianbin Lin and Peng Cui and Quanhui Jia and Zhen Wang\n  and Yanming Fang and Quan Yu and Jun Zhou and Shuang Yang and Yuan Qi", "title": "A Semi-supervised Graph Attentive Network for Financial Fraud Detection", "comments": "icdm", "journal-ref": null, "doi": "10.1109/ICDM.2019.00070", "report-no": null, "categories": "cs.SI cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of financial services, fraud detection has been a very\nimportant problem to guarantee a healthy environment for both users and\nproviders. Conventional solutions for fraud detection mainly use some\nrule-based methods or distract some features manually to perform prediction.\nHowever, in financial services, users have rich interactions and they\nthemselves always show multifaceted information. These data form a large\nmultiview network, which is not fully exploited by conventional methods.\nAdditionally, among the network, only very few of the users are labelled, which\nalso poses a great challenge for only utilizing labeled data to achieve a\nsatisfied performance on fraud detection.\n  To address the problem, we expand the labeled data through their social\nrelations to get the unlabeled data and propose a semi-supervised attentive\ngraph neural network, namedSemiGNN to utilize the multi-view labeled and\nunlabeled data for fraud detection. Moreover, we propose a hierarchical\nattention mechanism to better correlate different neighbors and different\nviews. Simultaneously, the attention mechanism can make the model interpretable\nand tell what are the important factors for the fraud and why the users are\npredicted as fraud. Experimentally, we conduct the prediction task on the users\nof Alipay, one of the largest third-party online and offline cashless payment\nplatform serving more than 4 hundreds of million users in China. By utilizing\nthe social relations and the user attributes, our method can achieve a better\naccuracy compared with the state-of-the-art methods on two tasks. Moreover, the\ninterpretable results also give interesting intuitions regarding the tasks.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 10:35:25 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Wang", "Daixin", ""], ["Lin", "Jianbin", ""], ["Cui", "Peng", ""], ["Jia", "Quanhui", ""], ["Wang", "Zhen", ""], ["Fang", "Yanming", ""], ["Yu", "Quan", ""], ["Zhou", "Jun", ""], ["Yang", "Shuang", ""], ["Qi", "Yuan", ""]]}, {"id": "2003.01218", "submitter": "Armin Ziaie Tabari", "authors": "Armin Ziaie Tabari and Xinming Ou", "title": "A First Step Towards Understanding Real-world Attacks on IoT Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of Internet of Things (IoT) devices, it is imperative\nto proactively understand the real-world cybersecurity threats posed to them.\nThis paper describes our initial efforts towards building a honeypot ecosystem\nas a means to gathering and analyzing real attack data against IoT devices. A\nprimary condition for a honeypot to yield useful insights is to let attackers\nbelieve they are real systems used by humans and organizations. IoT devices\npose unique challenges in this respect, due to the large variety of device\ntypes and the physical-connectedness nature. We thus create a multiphased\napproach in building a honeypot ecosystem, where researchers can gradually\nincrease a low-interaction honeypot's sophistication in emulating an IoT device\nby observing real-world attackers' behaviors. We deployed honeypots both\non-premise and in the cloud, with associated analysis and vetting\ninfrastructures to ensure these honeypots cannot be easily identified as such\nand appear to be real systems. In doing so we were able to attract increasingly\nsophisticated attack data. We present the design of this honeypot ecosystem and\nour observation on the attack data so far. Our data shows that real-world\nattackers are explicitly going after IoT devices, and some captured activities\nseem to involve direct human interaction (as opposed to scripted automatic\nactivities). We also build a low interaction honeypot for IoT cameras, called\nHoneycamera, that present to attackers seemingly real videos. This is our first\nstep towards building a more comprehensive honeypot ecosystem that will allow\nresearchers to gain concrete understanding of what attackers are going after on\nIoT devices, so as to more proactively protect them.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 22:12:42 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Tabari", "Armin Ziaie", ""], ["Ou", "Xinming", ""]]}, {"id": "2003.01261", "submitter": "AmirMahdi Sadeghzadeh", "authors": "Amir Mahdi Sadeghzadeh, Saeed Shiravi, and Rasool Jalili", "title": "Adversarial Network Traffic: Towards Evaluating the Robustness of Deep\n  Learning-Based Network Traffic Classification", "comments": "14 pages, 3 figures, and 7 tables. Accepted in IEEE Transactions on\n  Network and Service Management (TNSM). Supplementary Material:\n  https://github.com/amsadeghzadeh/AdversarialNetworkTraffic", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network traffic classification is used in various applications such as\nnetwork traffic management, policy enforcement, and intrusion detection\nsystems. Although most applications encrypt their network traffic and some of\nthem dynamically change their port numbers, Machine Learning (ML) and\nespecially Deep Learning (DL)-based classifiers have shown impressive\nperformance in network traffic classification. In this paper, we evaluate the\nrobustness of DL-based network traffic classifiers against Adversarial Network\nTraffic (ANT). ANT causes DL-based network traffic classifiers to predict\nincorrectly using Universal Adversarial Perturbation (UAP) generating methods.\nSince there is no need to buffer network traffic before sending ANT, it is\ngenerated live. We partition the input space of the DL-based network traffic\nclassification into three categories: packet classification, flow content\nclassification, and flow time series classification. To generate ANT, we\npropose three new attacks injecting UAP into network traffic. AdvPad attack\ninjects a UAP into the content of packets to evaluate the robustness of packet\nclassifiers. AdvPay attack injects a UAP into the payload of a dummy packet to\nevaluate the robustness of flow content classifiers. AdvBurst attack injects a\nspecific number of dummy packets with crafted statistical features based on a\nUAP into a selected burst of a flow to evaluate the robustness of flow time\nseries classifiers. The results indicate injecting a little UAP into network\ntraffic, highly decreases the performance of DL-based network traffic\nclassifiers in all categories.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 00:19:35 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 17:27:15 GMT"}, {"version": "v3", "created": "Sun, 14 Jun 2020 11:17:28 GMT"}, {"version": "v4", "created": "Wed, 20 Jan 2021 23:52:11 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Sadeghzadeh", "Amir Mahdi", ""], ["Shiravi", "Saeed", ""], ["Jalili", "Rasool", ""]]}, {"id": "2003.01279", "submitter": "Nataniel Ruiz", "authors": "Nataniel Ruiz, Sarah Adel Bargal, Stan Sclaroff", "title": "Disrupting Deepfakes: Adversarial Attacks Against Conditional Image\n  Translation Networks and Facial Manipulation Systems", "comments": "Accepted at CVPR 2020 Workshop on Adversarial Machine Learning in\n  Computer Vision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face modification systems using deep learning have become increasingly\npowerful and accessible. Given images of a person's face, such systems can\ngenerate new images of that same person under different expressions and poses.\nSome systems can also modify targeted attributes such as hair color or age.\nThis type of manipulated images and video have been coined Deepfakes. In order\nto prevent a malicious user from generating modified images of a person without\ntheir consent we tackle the new problem of generating adversarial attacks\nagainst such image translation systems, which disrupt the resulting output\nimage. We call this problem disrupting deepfakes. Most image translation\narchitectures are generative models conditioned on an attribute (e.g. put a\nsmile on this person's face). We are first to propose and successfully apply\n(1) class transferable adversarial attacks that generalize to different\nclasses, which means that the attacker does not need to have knowledge about\nthe conditioning class, and (2) adversarial training for generative adversarial\nnetworks (GANs) as a first step towards robust image translation networks.\nFinally, in gray-box scenarios, blurring can mount a successful defense against\ndisruption. We present a spread-spectrum adversarial attack, which evades blur\ndefenses. Our open-source code can be found at\nhttps://github.com/natanielruiz/disrupting-deepfakes.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 01:18:16 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 18:18:14 GMT"}, {"version": "v3", "created": "Mon, 27 Apr 2020 19:58:25 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Ruiz", "Nataniel", ""], ["Bargal", "Sarah Adel", ""], ["Sclaroff", "Stan", ""]]}, {"id": "2003.01518", "submitter": "Polina Zilberman", "authors": "Polina Zilberman and Rami Puzis and Sunders Bruskin and Shai Shwarz\n  and Yuval Elovici", "title": "SoK: A Survey of Open-Source Threat Emulators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Threat emulators are tools or sets of scripts that emulate cyber attacks or\nmalicious behavior. They can be used to create and launch single procedure\nattacks and multi-step attacks; the resulting attacks may be known or unknown\ncyber attacks. The motivation for using threat emulators varies and includes\nthe need to perform automated security audits in organizations or reduce the\nsize of red teams in order to lower pen testing costs; or the desire to create\nbaseline tests for security tools under development or supply pen testers with\nanother tool in their arsenal. In this paper, we review and compare various\nopen-source threat emulators. We focus on tactics and techniques from the MITRE\nATT&CK Enterprise matrix and determine whether they can be performed and tested\nwith the emulators. We develop a comprehensive methodology for our qualitative\nand quantitative comparison of threat emulators with respect to general\nfeatures, such as prerequisites, attack definition, cleanup, and more. Finally,\nwe discuss the circumstances in which one threat emulator is preferred over\nanother. This survey can help security teams, security developers, and product\ndeployment teams examine their network environment or products with the most\nsuitable threat emulator. Using the guidelines provided, a team can select the\nthreat emulator that best meets their needs without evaluating all of them.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 14:18:47 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 13:39:23 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Zilberman", "Polina", ""], ["Puzis", "Rami", ""], ["Bruskin", "Sunders", ""], ["Shwarz", "Shai", ""], ["Elovici", "Yuval", ""]]}, {"id": "2003.01718", "submitter": "Marialena Akriotou", "authors": "Charis Mesaritakis (1), Marialena Akriotou (2), Dimitris Syvridis (2)\n  ((1) Dept. Information & Communication Systems Engineering University of the\n  Aegean Karlovassi-Samos, Greece, (2) Dept. Informatics & Telecommunications\n  National & Kapodistrian University of Athens, Athens, Greece)", "title": "Laser Induced Speckle as a Foundation for Physical Security and Optical\n  Computing", "comments": null, "journal-ref": "In 2018 Photonics in Switching and Computing (PSC) (pp. 1-3). IEEE\n  (Sep 2018)", "doi": "10.1109/PS.2018.8751356", "report-no": null, "categories": "cs.ET cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a photonic system that exploits the speckle generated by the\ninteraction of a laser source and a semitransparent scattering medium, in our\ncase a large-core optical fiber, as a physical root of trust for cryptographic\napplications, while the same configuration can act as a high-rate machine\nlearning paradigm.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 11:32:33 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Mesaritakis", "Charis", ""], ["Akriotou", "Marialena", ""], ["Syvridis", "Dimitris", ""]]}, {"id": "2003.01782", "submitter": "Takami Sato", "authors": "Takami Sato, Junjie Shen, Ningfei Wang, Yunhan Jack Jia, Xue Lin and\n  Qi Alfred Chen", "title": "Security of Deep Learning based Lane Keeping System under Physical-World\n  Adversarial Attack", "comments": "Project page: https://sites.google.com/view/lane-keeping-adv-attack/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lane-Keeping Assistance System (LKAS) is convenient and widely available\ntoday, but also extremely security and safety critical. In this work, we design\nand implement the first systematic approach to attack real-world DNN-based\nLKASes. We identify dirty road patches as a novel and domain-specific threat\nmodel for practicality and stealthiness. We formulate the attack as an\noptimization problem, and address the challenge from the inter-dependencies\namong attacks on consecutive camera frames. We evaluate our approach on a\nstate-of-the-art LKAS and our preliminary results show that our attack can\nsuccessfully cause it to drive off lane boundaries within as short as 1.3\nseconds.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 20:35:25 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Sato", "Takami", ""], ["Shen", "Junjie", ""], ["Wang", "Ningfei", ""], ["Jia", "Yunhan Jack", ""], ["Lin", "Xue", ""], ["Chen", "Qi Alfred", ""]]}, {"id": "2003.01801", "submitter": "Philip Sperl", "authors": "Philip Sperl, Jan-Philipp Schulze, Konstantin B\\\"ottinger", "title": "$\\text{A}^3$: Activation Anomaly Analysis", "comments": "The first two authors contributed equally to this work", "journal-ref": null, "doi": "10.1007/978-3-030-67661-2_5", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by recent advances in coverage-guided analysis of neural networks,\nwe propose a novel anomaly detection method. We show that the hidden activation\nvalues contain information useful to distinguish between normal and anomalous\nsamples. Our approach combines three neural networks in a purely data-driven\nend-to-end model. Based on the activation values in the target network, the\nalarm network decides if the given sample is normal. Thanks to the anomaly\nnetwork, our method even works in strict semi-supervised settings. Strong\nanomaly detection results are achieved on common data sets surpassing current\nbaseline methods. Our semi-supervised anomaly detection method allows to\ninspect large amounts of data for anomalies across various applications.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 21:23:56 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 15:08:00 GMT"}, {"version": "v3", "created": "Tue, 7 Apr 2020 11:45:14 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Sperl", "Philip", ""], ["Schulze", "Jan-Philipp", ""], ["B\u00f6ttinger", "Konstantin", ""]]}, {"id": "2003.01876", "submitter": "Yangsibo Huang", "authors": "Yangsibo Huang, Yushan Su, Sachin Ravi, Zhao Song, Sanjeev Arora, Kai\n  Li", "title": "Privacy-preserving Learning via Deep Net Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper attempts to answer the question whether neural network pruning can\nbe used as a tool to achieve differential privacy without losing much data\nutility. As a first step towards understanding the relationship between neural\nnetwork pruning and differential privacy, this paper proves that pruning a\ngiven layer of the neural network is equivalent to adding a certain amount of\ndifferentially private noise to its hidden-layer activations. The paper also\npresents experimental results to show the practical implications of the\ntheoretical finding and the key parameter values in a simple practical setting.\nThese results show that neural network pruning can be a more effective\nalternative to adding differentially private noise for neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 03:42:54 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Huang", "Yangsibo", ""], ["Su", "Yushan", ""], ["Ravi", "Sachin", ""], ["Song", "Zhao", ""], ["Arora", "Sanjeev", ""], ["Li", "Kai", ""]]}, {"id": "2003.01908", "submitter": "Hadi Salman", "authors": "Hadi Salman, Mingjie Sun, Greg Yang, Ashish Kapoor and J. Zico Kolter", "title": "Denoised Smoothing: A Provable Defense for Pretrained Classifiers", "comments": "10 pages main text; 29 pages total", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for provably defending any pretrained image classifier\nagainst $\\ell_p$ adversarial attacks. This method, for instance, allows public\nvision API providers and users to seamlessly convert pretrained non-robust\nclassification services into provably robust ones. By prepending a\ncustom-trained denoiser to any off-the-shelf image classifier and using\nrandomized smoothing, we effectively create a new classifier that is guaranteed\nto be $\\ell_p$-robust to adversarial examples, without modifying the pretrained\nclassifier. Our approach applies to both the white-box and the black-box\nsettings of the pretrained classifier. We refer to this defense as denoised\nsmoothing, and we demonstrate its effectiveness through extensive\nexperimentation on ImageNet and CIFAR-10. Finally, we use our approach to\nprovably defend the Azure, Google, AWS, and ClarifAI image classification APIs.\nOur code replicating all the experiments in the paper can be found at:\nhttps://github.com/microsoft/denoised-smoothing.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 06:15:55 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 02:20:16 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Salman", "Hadi", ""], ["Sun", "Mingjie", ""], ["Yang", "Greg", ""], ["Kapoor", "Ashish", ""], ["Kolter", "J. Zico", ""]]}, {"id": "2003.01985", "submitter": "Siamak F. Shahandashti", "authors": "Michael Carr and Siamak F. Shahandashti", "title": "Revisiting Security Vulnerabilities in Commercial Password Managers", "comments": "This is an accepted manuscript to appear in the proceedings of the\n  35th Int'l Conf. on ICT Systems Security & Privacy Protection (IFIP SEC\n  2020), Maribor, Slovenia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this work we analyse five popular commercial password managers for\nsecurity vulnerabilities. Our analysis is twofold. First, we compile a list of\npreviously disclosed vulnerabilities through a comprehensive review of the\nacademic and non-academic sources and test each password manager against all\nthe previously disclosed vulnerabilities. We find a mixed picture of fixed and\npersisting vulnerabilities. Then we carry out systematic functionality tests on\nthe considered password managers and find four new vulnerabilities. Notably,\none of the new vulnerabilities we identified allows a malicious app to\nimpersonate a legitimate app to two out of five widely-used password managers\nwe tested and as a result steal the user's password for the targeted service.\nWe implement a proof-of-concept attack to show the feasibility of this\nvulnerability in a real-life scenario. Finally, we report and reflect on our\nexperience of responsible disclosure of the newly discovered vulnerabilities to\nthe corresponding password manager vendors.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 10:37:35 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 16:55:58 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Carr", "Michael", ""], ["Shahandashti", "Siamak F.", ""]]}, {"id": "2003.01991", "submitter": "Maurantonio Caprolu", "authors": "Maurantonio Caprolu, Roberto Di Pietro, Simone Raponi, Savio\n  Sciancalepore, Pietro Tedeschi", "title": "Vessels Cybersecurity: Issues, Challenges, and the Road Ahead", "comments": null, "journal-ref": "IEEE Communications Magazine ( Volume: 58 , Issue: 6 , June 2020 )", "doi": "10.1109/MCOM.001.1900632", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vessels cybersecurity is recently gaining momentum, as a result of a few\nrecent attacks to vessels at sea. These recent attacks have shacked the\nmaritime domain, which was thought to be relatively immune to cyber threats.\nThe cited belief is now over, as proved by recent mandates issued by the\nInternational Maritime Organization (IMO). According to these regulations, all\nvessels should be the subject of a cybersecurity risk analysis, and technical\ncontrols should be adopted to mitigate the resulting risks. This initiative is\nlaudable since, despite the recent incidents, the vulnerabilities and threats\naffecting modern vessels are still unclear to operating entities, leaving the\npotential for dreadful consequences of further attacks just a matter of \"when\",\nnot \"if\". In this contribution, we investigate and systematize the major\nsecurity weaknesses affecting systems and communication technologies adopted in\nmodern vessels. Specifically, we describe the architecture and main features of\nthe different systems, pointing out their main security issues, and specifying\nhow they were exploited by attackers to cause service disruption and relevant\nfinancial losses. We also identify a few countermeasures to the introduced\nattacks. Finally, we highlight a few research challenges to be addressed by\nindustry and academia to strengthen vessels security.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 10:51:22 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Caprolu", "Maurantonio", ""], ["Di Pietro", "Roberto", ""], ["Raponi", "Simone", ""], ["Sciancalepore", "Savio", ""], ["Tedeschi", "Pietro", ""]]}, {"id": "2003.02133", "submitter": "Lingjuan Lyu", "authors": "Lingjuan Lyu, Han Yu, Qiang Yang", "title": "Threats to Federated Learning: A Survey", "comments": "7 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the emergence of data silos and popular privacy awareness, the\ntraditional centralized approach of training artificial intelligence (AI)\nmodels is facing strong challenges. Federated learning (FL) has recently\nemerged as a promising solution under this new reality. Existing FL protocol\ndesign has been shown to exhibit vulnerabilities which can be exploited by\nadversaries both within and without the system to compromise data privacy. It\nis thus of paramount importance to make FL system designers to be aware of the\nimplications of future FL algorithm design on privacy-preservation. Currently,\nthere is no survey on this topic. In this paper, we bridge this important gap\nin FL literature. By providing a concise introduction to the concept of FL, and\na unique taxonomy covering threat models and two major attacks on FL: 1)\npoisoning attacks and 2) inference attacks, this paper provides an accessible\nreview of this important topic. We highlight the intuitions, key techniques as\nwell as fundamental assumptions adopted by various attacks, and discuss\npromising future research directions towards more robust privacy preservation\nin FL.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 15:30:10 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Lyu", "Lingjuan", ""], ["Yu", "Han", ""], ["Yang", "Qiang", ""]]}, {"id": "2003.02164", "submitter": "Tidiane Sylla", "authors": "Tidiane Sylla (USTTB, LaBRI), Mohamed Aymen Chalouf (OCIF), Francine\n  Krief (LaBRI), Karim Samak\\'e (USTTB)", "title": "Towards a Context-Aware Security and Privacy as a Service in the\n  Internet of Things", "comments": null, "journal-ref": "13th IFIP WG 11.2 International Conference, WISTP 2019, Paris,\n  France, December 11--12, 2019, Proceedings, pp.240-252, 2020", "doi": "10.1007/978-3-030-41702-4_15", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart city is one of the most known Internet of Things (IoT) applications.\nThe smart city services improve user's daily lives. However, security and\nprivacy issues are slowing down their adoption. In addition, the\ncharacteristics of IoT devices, applications and users make security\nimplementation of the considered applications a challenging task. To address\nthese issues, we present, in this paper, a new context-aware security and\nprivacy architecture for the IoT. Thanks to the \"as a service\" approach, this\nnew architecture will be user-centric. It will also support known context-aware\nsecurity issues: dynamicity, flexibility. In addition, it will address\nmobility, customization of security and privacy services, and support for\ngeneric IoT applications, particularly for smart city. To do so, a knowledge\nplane allowing effective management of context-awareness is proposed. A\nsecurity and privacy plane allowing better implementation of context-aware\nsecurity and privacy mechanisms is also proposed. This will be done through\ndynamic composition of context-based micro services. The role of the different\ncomponents of these two planes are also described.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 16:17:31 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Sylla", "Tidiane", "", "USTTB, LaBRI"], ["Chalouf", "Mohamed Aymen", "", "OCIF"], ["Krief", "Francine", "", "LaBRI"], ["Samak\u00e9", "Karim", "", "USTTB"]]}, {"id": "2003.02229", "submitter": "Chenguang Wang", "authors": "Chenguang Wang, Simon Tindemans, Kaikai Pan, Peter Palensky", "title": "Detection of False Data Injection Attacks Using the Autoencoder Approach", "comments": "6 pages, 5 figures, 1 table, conference", "journal-ref": "2020 International Conference on Probabilistic Methods Applied to\n  Power Systems (PMAPS), Liege, Belgium, 2020", "doi": "10.1109/PMAPS47429.2020.9183526", "report-no": null, "categories": "eess.SY cs.CR cs.SY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State estimation is of considerable significance for the power system\noperation and control. However, well-designed false data injection attacks can\nutilize blind spots in conventional residual-based bad data detection methods\nto manipulate measurements in a coordinated manner and thus affect the secure\noperation and economic dispatch of grids. In this paper, we propose a detection\napproach based on an autoencoder neural network. By training the network on the\ndependencies intrinsic in 'normal' operation data, it effectively overcomes the\nchallenge of unbalanced training data that is inherent in power system attack\ndetection. To evaluate the detection performance of the proposed mechanism, we\nconduct a series of experiments on the IEEE 118-bus power system. The\nexperiments demonstrate that the proposed autoencoder detector displays robust\ndetection performance under a variety of attack scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 18:15:45 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 09:00:16 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Wang", "Chenguang", ""], ["Tindemans", "Simon", ""], ["Pan", "Kaikai", ""], ["Palensky", "Peter", ""]]}, {"id": "2003.02388", "submitter": "Claude Gravel", "authors": "Claude Gravel, Daniel Panario and Bastien Rigault", "title": "Finding linearly generated subsequences", "comments": "19 pages International Workshop on the Arithmetic of Finite Fields,\n  WAIFI 2020 https://link.springer.com/conference/waifi", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new algorithm to compute determinants of all possible Hankel\nmatrices made up from a given finite length sequence over a finite field. Our\nalgorithm fits within the dynamic programming paradigm by exploiting new\nrecursive relations on the determinants of Hankel matrices together with new\nobservations concerning the distribution of zero determinants among the\npossible matrix sizes allowed by the length of the original sequence. The\nalgorithm can be used to isolate \\emph{very} efficiently linear shift feedback\nregisters hidden in strings with random prefix and random postfix for instance\nand, therefore, recovering the shortest generating vector. Our new mathematical\nidentities can be used also in any other situations involving determinants of\nHankel matrices. We also implement a parallel version of our algorithm. We\ncompare our results empirically with the trivial algorithm which consists of\ncomputing determinants for each possible Hankel matrices made up from a given\nfinite length sequence. Our new accelerated approach on a single processor is\nfaster than the trivial algorithm on 160 processors for input sequences of\nlength 16384 for instance.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 00:51:00 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 04:07:35 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Gravel", "Claude", ""], ["Panario", "Daniel", ""], ["Rigault", "Bastien", ""]]}, {"id": "2003.02460", "submitter": "Yao-Yuan Yang", "authors": "Yao-Yuan Yang, Cyrus Rashtchian, Hongyang Zhang, Ruslan Salakhutdinov,\n  Kamalika Chaudhuri", "title": "A Closer Look at Accuracy vs. Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current methods for training robust networks lead to a drop in test accuracy,\nwhich has led prior works to posit that a robustness-accuracy tradeoff may be\ninevitable in deep learning. We take a closer look at this phenomenon and first\nshow that real image datasets are actually separated. With this property in\nmind, we then prove that robustness and accuracy should both be achievable for\nbenchmark datasets through locally Lipschitz functions, and hence, there should\nbe no inherent tradeoff between robustness and accuracy. Through extensive\nexperiments with robustness methods, we argue that the gap between theory and\npractice arises from two limitations of current methods: either they fail to\nimpose local Lipschitzness or they are insufficiently generalized. We explore\ncombining dropout with robust training methods and obtain better\ngeneralization. We conclude that achieving robustness and accuracy in practice\nmay require using methods that impose local Lipschitzness and augmenting them\nwith deep learning generalization techniques. Code available at\nhttps://github.com/yangarbiter/robust-local-lipschitz\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 07:09:32 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 04:15:33 GMT"}, {"version": "v3", "created": "Sun, 12 Jul 2020 19:59:39 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Yang", "Yao-Yuan", ""], ["Rashtchian", "Cyrus", ""], ["Zhang", "Hongyang", ""], ["Salakhutdinov", "Ruslan", ""], ["Chaudhuri", "Kamalika", ""]]}, {"id": "2003.02488", "submitter": "Pawel Drozdowski", "authors": "P. Drozdowski, C. Rathgeb, A. Dantcheva, N. Damer, C. Busch", "title": "Demographic Bias in Biometrics: A Survey on an Emerging Challenge", "comments": "15 pages, 3 figures, 3 tables. Submitted to IEEE Transactions on\n  Technology and Society. Update after first round of peer review", "journal-ref": "IEEE Transactions on Technology and Society 1, no. 2 (2020):\n  89-103", "doi": "10.1109/TTS.2020.2992344", "report-no": null, "categories": "cs.CY cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems incorporating biometric technologies have become ubiquitous in\npersonal, commercial, and governmental identity management applications. Both\ncooperative (e.g. access control) and non-cooperative (e.g. surveillance and\nforensics) systems have benefited from biometrics. Such systems rely on the\nuniqueness of certain biological or behavioural characteristics of human\nbeings, which enable for individuals to be reliably recognised using automated\nalgorithms.\n  Recently, however, there has been a wave of public and academic concerns\nregarding the existence of systemic bias in automated decision systems\n(including biometrics). Most prominently, face recognition algorithms have\noften been labelled as \"racist\" or \"biased\" by the media, non-governmental\norganisations, and researchers alike.\n  The main contributions of this article are: (1) an overview of the topic of\nalgorithmic bias in the context of biometrics, (2) a comprehensive survey of\nthe existing literature on biometric bias estimation and mitigation, (3) a\ndiscussion of the pertinent technical and social matters, and (4) an outline of\nthe remaining challenges and future work items, both from technological and\nsocial points of view.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 09:07:59 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 08:18:24 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Drozdowski", "P.", ""], ["Rathgeb", "C.", ""], ["Dantcheva", "A.", ""], ["Damer", "N.", ""], ["Busch", "C.", ""]]}, {"id": "2003.02575", "submitter": "Dvir Cohen", "authors": "Dvir Cohen, Yisroel Mirsky, Yuval Elovici, Rami Puzis, Manuel Kamp,\n  Tobias Martin, Asaf Shabtai", "title": "DANTE: A framework for mining and monitoring darknet traffic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trillions of network packets are sent over the Internet to destinations which\ndo not exist. This 'darknet' traffic captures the activity of botnets and other\nmalicious campaigns aiming to discover and compromise devices around the world.\nIn order to mine threat intelligence from this data, one must be able to handle\nlarge streams of logs and represent the traffic patterns in a meaningful way.\nHowever, by observing how network ports (services) are used, it is possible to\ncapture the intent of each transmission. In this paper, we present DANTE: a\nframework and algorithm for mining darknet traffic. DANTE learns the meaning of\ntargeted network ports by applying Word2Vec to observed port sequences. Then,\nwhen a host sends a new sequence, DANTE represents the transmission as the\naverage embedding of the ports found that sequence. Finally, DANTE uses a novel\nand incremental time-series cluster tracking algorithm on observed sequences to\ndetect recurring behaviors and new emerging threats. To evaluate the system, we\nran DANTE on a full year of darknet traffic (over three Tera-Bytes) collected\nby the largest telecommunications provider in Europe, Deutsche Telekom and\nanalyzed the results. DANTE discovered 1,177 new emerging threats and was able\nto track malicious campaigns over time. We also compared DANTE to the current\nbest approach and found DANTE to be more practical and effective at detecting\ndarknet traffic patterns.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 12:47:29 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Cohen", "Dvir", ""], ["Mirsky", "Yisroel", ""], ["Elovici", "Yuval", ""], ["Puzis", "Rami", ""], ["Kamp", "Manuel", ""], ["Martin", "Tobias", ""], ["Shabtai", "Asaf", ""]]}, {"id": "2003.02685", "submitter": "Ecenaz Erdemir", "authors": "Ecenaz Erdemir, Pier Luigi Dragotti and Deniz Gunduz", "title": "Privacy-Aware Time-Series Data Sharing with Deep Reinforcement Learning", "comments": "13 pages, 10 figures. arXiv admin note: text overlap with\n  arXiv:1907.07606", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of things (IoT) devices are becoming increasingly popular thanks to\nmany new services and applications they offer. However, in addition to their\nmany benefits, they raise privacy concerns since they share fine-grained\ntime-series user data with untrusted third parties. In this work, we study the\nprivacy-utility trade-off (PUT) in time-series data sharing. Existing\napproaches to PUT mainly focus on a single data point; however, temporal\ncorrelations in time-series data introduce new challenges. Methods that\npreserve the privacy for the current time may leak significant amount of\ninformation at the trace level as the adversary can exploit temporal\ncorrelations in a trace. We consider sharing the distorted version of a user's\ntrue data sequence with an untrusted third party. We measure the privacy\nleakage by the mutual information between the user's true data sequence and\nshared version. We consider both the instantaneous and average distortion\nbetween the two sequences, under a given distortion measure, as the utility\nloss metric. To tackle the history-dependent mutual information minimization,\nwe reformulate the problem as a Markov decision process (MDP), and solve it\nusing asynchronous actor-critic deep reinforcement learning (RL). We evaluate\nthe performance of the proposed solution in location trace privacy on both\nsynthetic and GeoLife GPS trajectory datasets. For the latter, we show the\nvalidity of our solution by testing the privacy of the released location\ntrajectory against an adversary network.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 18:47:25 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 11:52:41 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Erdemir", "Ecenaz", ""], ["Dragotti", "Pier Luigi", ""], ["Gunduz", "Deniz", ""]]}, {"id": "2003.02693", "submitter": "Jiahua Xu", "authors": "Daniel Perez and Jiahua Xu and Benjamin Livshits", "title": "Revisiting Transactional Statistics of High-scalability Blockchains", "comments": null, "journal-ref": "Proceedings of the ACM Internet Measurement Conference (2020)", "doi": "10.1145/3419394.3423628", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Scalability has been a bottleneck for major blockchains such as Bitcoin and\nEthereum. Despite the significantly improved scalability claimed by several\nhigh--profile blockchain projects, there has been little effort to understand\nhow their transactional throughput is being used. In this paper, we examine\nrecent network traffic of three major high-scalability blockchains--EOSIO,\nTezos and XRP Ledger (XRPL)--over a period of seven months. Our analysis\nreveals that only a small fraction of the transactions are used for value\ntransfer purposes. In particular, 96% of the transactions on EOSIO were\ntriggered by the airdrop of a currently valueless token; on Tezos, 76% of\nthroughput was used for maintaining consensus; and over 94% of transactions on\nXRPL carried no economic value. We also identify a persisting airdrop on EOSIO\nas a DoS attack and detect a two-month-long spam attack on XRPL. The paper\nexplores the different designs of the three blockchains and sheds light on how\nthey could shape user behavior.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 15:01:58 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 22:22:19 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 13:59:03 GMT"}, {"version": "v4", "created": "Sat, 15 Aug 2020 17:18:21 GMT"}, {"version": "v5", "created": "Sat, 3 Oct 2020 14:13:18 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Perez", "Daniel", ""], ["Xu", "Jiahua", ""], ["Livshits", "Benjamin", ""]]}, {"id": "2003.02732", "submitter": "Jiyi Zhang", "authors": "Jiyi Zhang, Ee-Chien Chang, Hwee Kuan Lee", "title": "Confusing and Detecting ML Adversarial Attacks with Injected Attractors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning adversarial attacks find adversarial samples of a\nvictim model ${\\mathcal M}$ by following the gradient of some attack objective\nfunctions, either explicitly or implicitly. To confuse and detect such attacks,\nwe take the proactive approach that modifies those functions with the goal of\nmisleading the attacks to some local minimals, or to some designated regions\nthat can be easily picked up by an analyzer. To achieve this goal, we propose\nadding a large number of artifacts, which we called $attractors$, onto the\notherwise smooth function. An attractor is a point in the input space, where\nsamples in its neighborhood have gradient pointing toward it. We observe that\ndecoders of watermarking schemes exhibit properties of attractors and give a\ngeneric method that injects attractors from a watermark decoder into the victim\nmodel ${\\mathcal M}$. This principled approach allows us to leverage on known\nwatermarking schemes for scalability and robustness and provides explainability\nof the outcomes. Experimental studies show that our method has competitive\nperformance. For instance, for un-targeted attacks on CIFAR-10 dataset, we can\nreduce the overall attack success rate of DeepFool to 1.9%, whereas known\ndefense LID, FS and MagNet can reduce the rate to 90.8%, 98.5% and 78.5%\nrespectively.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 16:02:11 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 07:30:32 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 13:56:22 GMT"}, {"version": "v4", "created": "Mon, 8 Mar 2021 07:56:30 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Zhang", "Jiyi", ""], ["Chang", "Ee-Chien", ""], ["Lee", "Hwee Kuan", ""]]}, {"id": "2003.02833", "submitter": "Cen Chen", "authors": "Cen Chen, Chen Liang, Jianbin Lin, Li Wang, Ziqi Liu, Xinxing Yang,\n  Xiukun Wang, Jun Zhou, Yang Shuang, Yuan Qi", "title": "InfDetect: a Large Scale Graph-based Fraud Detection System for\n  E-Commerce Insurance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The insurance industry has been creating innovative products around the\nemerging online shopping activities. Such e-commerce insurance is designed to\nprotect buyers from potential risks such as impulse purchases and counterfeits.\nFraudulent claims towards online insurance typically involve multiple parties\nsuch as buyers, sellers, and express companies, and they could lead to heavy\nfinancial losses. In order to uncover the relations behind organized fraudsters\nand detect fraudulent claims, we developed a large-scale insurance fraud\ndetection system, i.e., InfDetect, which provides interfaces for commonly used\ngraphs, standard data processing procedures, and a uniform graph learning\nplatform. InfDetect is able to process big graphs containing up to 100 millions\nof nodes and billions of edges. In this paper, we investigate different graphs\nto facilitate fraudster mining, such as a device-sharing graph, a transaction\ngraph, a friendship graph, and a buyer-seller graph. These graphs are fed to a\nuniform graph learning platform containing supervised and unsupervised graph\nlearning algorithms. Cases on widely applied e-commerce insurance are described\nto demonstrate the usage and capability of our system. InfDetect has\nsuccessfully detected thousands of fraudulent claims and saved over tens of\nthousands of dollars daily.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 05:43:49 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 03:51:14 GMT"}, {"version": "v3", "created": "Thu, 12 Mar 2020 09:24:50 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Chen", "Cen", ""], ["Liang", "Chen", ""], ["Lin", "Jianbin", ""], ["Wang", "Li", ""], ["Liu", "Ziqi", ""], ["Yang", "Xinxing", ""], ["Wang", "Xiukun", ""], ["Zhou", "Jun", ""], ["Shuang", "Yang", ""], ["Qi", "Yuan", ""]]}, {"id": "2003.02834", "submitter": "Chaochao Chen", "authors": "Chaochao Chen, Jun Zhou, Bingzhe Wu, Wenjin Fang, Li Wang, Yuan Qi,\n  Xiaolin Zheng", "title": "Practical Privacy Preserving POI Recommendation", "comments": "Accepted by ACM TIST", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Point-of-Interest (POI) recommendation has been extensively studied and\nsuccessfully applied in industry recently. However, most existing approaches\nbuild centralized models on the basis of collecting users' data. Both private\ndata and models are held by the recommender, which causes serious privacy\nconcerns. In this paper, we propose a novel Privacy preserving POI\nRecommendation (PriRec) framework. First, to protect data privacy, users'\nprivate data (features and actions) are kept on their own side, e.g., Cellphone\nor Pad. Meanwhile, the public data need to be accessed by all the users are\nkept by the recommender to reduce the storage costs of users' devices. Those\npublic data include: (1) static data only related to the status of POI, such as\nPOI categories, and (2) dynamic data depend on user-POI actions such as visited\ncounts. The dynamic data could be sensitive, and we develop local differential\nprivacy techniques to release such data to public with privacy guarantees.\nSecond, PriRec follows the representations of Factorization Machine (FM) that\nconsists of linear model and the feature interaction model. To protect the\nmodel privacy, the linear models are saved on users' side, and we propose a\nsecure decentralized gradient descent protocol for users to learn it\ncollaboratively. The feature interaction model is kept by the recommender since\nthere is no privacy risk, and we adopt secure aggregation strategy in federated\nlearning paradigm to learn it. To this end, PriRec keeps users' private raw\ndata and models in users' own hands, and protects user privacy to a large\nextent. We apply PriRec in real-world datasets, and comprehensive experiments\ndemonstrate that, compared with FM, PriRec achieves comparable or even better\nrecommendation accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 06:06:40 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 06:11:26 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Chen", "Chaochao", ""], ["Zhou", "Jun", ""], ["Wu", "Bingzhe", ""], ["Fang", "Wenjin", ""], ["Wang", "Li", ""], ["Qi", "Yuan", ""], ["Zheng", "Xiaolin", ""]]}, {"id": "2003.02892", "submitter": "Corentin Thomasset", "authors": "Corentin Thomasset and David Barrera", "title": "SERENIoT: Collaborative Network Security Policy Management and\n  Enforcement for Smart Homes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Network traffic whitelisting has emerged as a dominant approach for securing\nconsumer IoT devices. However, determining what the whitelisted behavior of an\nIoT device should be remains an open challenge. Proposals to date have relied\non manufacturers and trusted parties to provide whitelists, but these proposals\nrequire manufacturer involvement or placing trust in an additional stakeholder.\nAlternatively, locally monitoring devices can allow building whitelists of\nobserved behavior, but devices may not exhaust their functionality set during\nthe observation period, or the behavior may change following a software update\nwhich requires re-training. This paper proposes a blockchain-based system for\ndetermining whether an IoT device is behaving like other devices of the same\ntype. Our system (SERENIoT, pronounced Serenity) overcomes the challenge of\ninitially determining the correct behavior for a device. Nodes in the SERENIoT\npublic blockchain submit summaries of the network behavior observed for\nconnected IoT devices and build whitelists of behavior observed by the majority\nof nodes. Changes in behavior through software updates are automatically\nwhitelisted once the update is broadly deployed. Through a proof-of-concept\nimplementation of SERENIoT on a small Raspberry Pi IoT network and a\nlarge-scale Amazon EC2 simulation, we evaluate the security, scalability, and\nperformance of our system.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 19:55:07 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Thomasset", "Corentin", ""], ["Barrera", "David", ""]]}, {"id": "2003.03021", "submitter": "Kai Jia", "authors": "Kai Jia, Martin Rinard", "title": "Exploiting Verified Neural Networks via Floating Point Numerical Error", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the need to reliably characterize the robustness of deep neural\nnetworks, researchers have developed verification algorithms for deep neural\nnetworks. Given a neural network, the verifiers aim to answer whether certain\nproperties are guaranteed with respect to all inputs in a space. However,\nlittle attention has been paid to floating point numerical error in neural\nnetwork verification.\n  We show that the negligence of floating point error is easily exploitable in\npractice. For a pretrained neural network, we present a method that efficiently\nsearches inputs regarding which a complete verifier incorrectly claims the\nnetwork is robust. We also present a method to construct neural network\narchitectures and weights that induce wrong results of an incomplete verifier.\nOur results highlight that, to achieve practically reliable verification of\nneural networks, any verification system must accurately (or conservatively)\nmodel the effects of any floating point computations in the network inference\nor verification system.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 03:58:26 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 08:24:48 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Jia", "Kai", ""], ["Rinard", "Martin", ""]]}, {"id": "2003.03052", "submitter": "Yan Zhang", "authors": "Vitalik Buterin, Diego Hernandez, Thor Kamphefner, Khiem Pham, Zhi\n  Qiao, Danny Ryan, Juhyeok Sin, Ying Wang, Yan X Zhang", "title": "Combining GHOST and Casper", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present \"Gasper,\" a proof-of-stake-based consensus protocol, which is an\nidealized version of the proposed Ethereum 2.0 beacon chain. The protocol\ncombines Casper FFG, a finality tool, with LMD GHOST, a fork-choice rule. We\nprove safety, plausible liveness, and probabilistic liveness under different\nsets of assumptions.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 06:39:10 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 01:32:01 GMT"}, {"version": "v3", "created": "Mon, 11 May 2020 18:27:40 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Buterin", "Vitalik", ""], ["Hernandez", "Diego", ""], ["Kamphefner", "Thor", ""], ["Pham", "Khiem", ""], ["Qiao", "Zhi", ""], ["Ryan", "Danny", ""], ["Sin", "Juhyeok", ""], ["Wang", "Ying", ""], ["Zhang", "Yan X", ""]]}, {"id": "2003.03100", "submitter": "Wei Song", "authors": "Wei Song, Xuezixiang Li, Sadia Afroz, Deepali Garg, Dmitry Kuznetsov,\n  Heng Yin", "title": "MAB-Malware: A Reinforcement Learning Framework for Attacking Static\n  Malware Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern commercial antivirus systems increasingly rely on machine learning to\nkeep up with the rampant inflation of new malware. However, it is well-known\nthat machine learning models are vulnerable to adversarial examples (AEs).\nPrevious works have shown that ML malware classifiers are fragile to the\nwhite-box adversarial attacks. However, ML models used in commercial antivirus\nproducts are usually not available to attackers and only return hard\nclassification labels. Therefore, it is more practical to evaluate the\nrobustness of ML models and real-world AVs in a pure black-box manner. We\npropose a black-box Reinforcement Learning (RL) based framework to generate AEs\nfor PE malware classifiers and AV engines. It regards the adversarial attack\nproblem as a multi-armed bandit problem, which finds an optimal balance between\nexploiting the successful patterns and exploring more varieties. Compared to\nother frameworks, our improvements lie in three points. 1) Limiting the\nexploration space by modeling the generation process as a stateless process to\navoid combination explosions. 2) Due to the critical role of payload in AE\ngeneration, we design to reuse the successful payload in modeling. 3)\nMinimizing the changes on AE samples to correctly assign the rewards in RL\nlearning. It also helps identify the root cause of evasions. As a result, our\nframework has much higher black-box evasion rates than other off-the-shelf\nframeworks. Results show it has over 74\\%--97\\% evasion rate for two\nstate-of-the-art ML detectors and over 32\\%--48\\% evasion rate for commercial\nAVs in a pure black-box setting. We also demonstrate that the transferability\nof adversarial attacks among ML-based classifiers is higher than the attack\ntransferability between purely ML-based and commercial AVs.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 09:33:39 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 15:45:59 GMT"}, {"version": "v3", "created": "Thu, 29 Apr 2021 21:01:53 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Song", "Wei", ""], ["Li", "Xuezixiang", ""], ["Afroz", "Sadia", ""], ["Garg", "Deepali", ""], ["Kuznetsov", "Dmitry", ""], ["Yin", "Heng", ""]]}, {"id": "2003.03172", "submitter": "Tapajit Dey", "authors": "Tapajit Dey, Sara Mousavi, Eduardo Ponce, Tanner Fry, Bogdan\n  Vasilescu, Anna Filippova, Audris Mockus", "title": "Detecting and Characterizing Bots that Commit Code", "comments": "Preprint of the paper accepted in MSR, 2020 conference", "journal-ref": null, "doi": "10.1145/3379597.3387478", "report-no": null, "categories": "cs.SE cs.CR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Some developer activity traditionally performed manually, such as\nmaking code commits, opening, managing, or closing issues is increasingly\nsubject to automation in many OSS projects. Specifically, such activity is\noften performed by tools that react to events or run at specific times. We\nrefer to such automation tools as bots and, in many software mining scenarios\nrelated to developer productivity or code quality it is desirable to identify\nbots in order to separate their actions from actions of individuals. Aim: Find\nan automated way of identifying bots and code committed by these bots, and to\ncharacterize the types of bots based on their activity patterns. Method and\nResult: We propose BIMAN, a systematic approach to detect bots using author\nnames, commit messages, files modified by the commit, and projects associated\nwith the ommits. For our test data, the value for AUC-ROC was 0.9. We also\ncharacterized these bots based on the time patterns of their code commits and\nthe types of files modified, and found that they primarily work with\ndocumentation files and web pages, and these files are most prevalent in HTML\nand JavaScript ecosystems. We have compiled a shareable dataset containing\ndetailed information about 461 bots we found (all of whom have more than 1000\ncommits) and 13,762,430 commits they created.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 21:54:07 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 01:28:42 GMT"}, {"version": "v3", "created": "Fri, 27 Mar 2020 20:47:56 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Dey", "Tapajit", ""], ["Mousavi", "Sara", ""], ["Ponce", "Eduardo", ""], ["Fry", "Tanner", ""], ["Vasilescu", "Bogdan", ""], ["Filippova", "Anna", ""], ["Mockus", "Audris", ""]]}, {"id": "2003.03221", "submitter": "Dominik Scholz", "authors": "Dominik Scholz, Sebastian Gallenm\\\"uller, Henning Stubbe, Bassam\n  Jaber, Minoo Rouhi, Georg Carle", "title": "Me Love (SYN-)Cookies: SYN Flood Mitigation in Programmable Data Planes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The SYN flood attack is a common attack strategy on the Internet, which tries\nto overload services with requests leading to a Denial-of-Service (DoS). Highly\nasymmetric costs for connection setup - putting the main burden on the attackee\n- make SYN flooding an efficient and popular DoS attack strategy. Abusing the\nwidely used TCP as an attack vector complicates the detection of malicious\ntraffic and its prevention utilizing naive connection blocking strategies.\nModern programmable data plane devices are capable of handling traffic in the\n10 Gbit/s range without overloading. We discuss how we can harness their\nperformance to defend entire networks against SYN flood attacks. Therefore, we\nanalyze different defense strategies, SYN authentication and SYN cookie, and\ndiscuss implementation difficulties when ported to different target data\nplanes: software, network processors, and FPGAs. We provide prototype\nimplementations and performance figures for all three platforms. Further, we\nfully disclose the artifacts leading to the experiments described in this work.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 14:02:34 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Scholz", "Dominik", ""], ["Gallenm\u00fcller", "Sebastian", ""], ["Stubbe", "Henning", ""], ["Jaber", "Bassam", ""], ["Rouhi", "Minoo", ""], ["Carle", "Georg", ""]]}, {"id": "2003.03296", "submitter": "Hui Xu", "authors": "Hui Xu, Zhuangbin Chen, Mingshen Sun, Yangfan Zhou, Michael Lyu", "title": "Memory-Safety Challenge Considered Solved? An In-Depth Study with All\n  Rust CVEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rust is an emerging programing language that aims at preventing memory-safety\nbugs without sacrificing much efficiency. The claimed property is very\nattractive to developers, and many projects start using the language. However,\ncan Rust achieve the memory-safety promise? This paper studies the question by\nsurveying 186 real-world bug reports collected from several origins which\ncontain all existing Rust CVEs (common vulnerability and exposures) of\nmemory-safety issues by 2020-12-31. We manually analyze each bug and extract\ntheir culprit patterns. Our analysis result shows that Rust can keep its\npromise that all memory-safety bugs require unsafe code, and many memory-safety\nbugs in our dataset are mild soundness issues that only leave a possibility to\nwrite memory-safety bugs without unsafe code. Furthermore, we summarize three\ntypical categories of memory-safety bugs, including automatic memory reclaim,\nunsound function, and unsound generic or trait. While automatic memory claim\nbugs are related to the side effect of Rust newly-adopted ownership-based\nresource management scheme, unsound function reveals the essential challenge of\nRust development for avoiding unsound code, and unsound generic or trait\nintensifies the risk of introducing unsoundness. Based on these findings, we\npropose two promising directions towards improving the security of Rust\ndevelopment, including several best practices of using specific APIs and\nmethods to detect particular bugs involving unsafe code. Our work intends to\nraise more discussions regarding the memory-safety issues of Rust and\nfacilitate the maturity of the language.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 16:16:45 GMT"}, {"version": "v2", "created": "Sun, 12 Apr 2020 14:44:13 GMT"}, {"version": "v3", "created": "Sat, 9 May 2020 11:05:15 GMT"}, {"version": "v4", "created": "Wed, 30 Sep 2020 06:57:44 GMT"}, {"version": "v5", "created": "Sat, 3 Oct 2020 06:00:27 GMT"}, {"version": "v6", "created": "Thu, 25 Feb 2021 01:45:19 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Xu", "Hui", ""], ["Chen", "Zhuangbin", ""], ["Sun", "Mingshen", ""], ["Zhou", "Yangfan", ""], ["Lyu", "Michael", ""]]}, {"id": "2003.03394", "submitter": "Miguel D. Bustamante", "authors": "Ikram Ullah, Umar Hayat and Miguel D. Bustamante", "title": "Image Encryption Using Elliptic Curves and Rossby/Drift Wave Triads", "comments": "Accepted and published version (Entropy 2020, 22, 454)", "journal-ref": "Entropy 2020, 22, 454", "doi": "10.3390/e22040454", "report-no": null, "categories": "cs.CR math.AG physics.ao-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose an image encryption scheme based on quasi-resonant Rossby/drift\nwave triads (related to elliptic surfaces) and Mordell elliptic curves (MECs).\nBy defining a total order on quasi-resonant triads, at a first stage we\nconstruct quasi-resonant triads using auxiliary parameters of elliptic surfaces\nin order to generate pseudo-random numbers. At a second stage, we employ an MEC\nto construct a dynamic substitution box (S-box) for the plain image. The\ngenerated pseudo-random numbers and S-box are used to provide diffusion and\nconfusion, respectively, in the tested image. We test the proposed scheme\nagainst well-known attacks by encrypting all gray images taken from the\nUSC-SIPI image database. Our experimental results indicate the high security of\nthe newly developed scheme. Finally, via extensive comparisons we show that the\nnew scheme outperforms other popular schemes.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 19:02:55 GMT"}, {"version": "v2", "created": "Sun, 10 May 2020 12:45:38 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Ullah", "Ikram", ""], ["Hayat", "Umar", ""], ["Bustamante", "Miguel D.", ""]]}, {"id": "2003.03409", "submitter": "Kartick Kolachala", "authors": "Lalitha Muthu Subramanian, Roopa Vishwanathan, Kartick Kolachala", "title": "Balance Transfers and Bailouts in Credit Networks using Blockchains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a technique for rebalancing link weights in\ndecentralized credit networks. Credit networks are peer-to-peer trust-based\nnetworks that enable fast and inexpensive cross-currency transactions compared\nto traditional bank wire transfers, which has led to their increasing\npopularity and use. Although researchers have studied security of transactions\nand privacy of users of such networks, and have invested significant efforts\ninto designing efficient routing algorithms for credit networks, comparatively\nlittle work has been done in the area of {replenishing} credit links of users\nin the network. Replenishing links at regular intervals in a credit network is\nimportant to keep users solvent, the network viable with enough liquidity, and\nto prevent transaction failures. This is achieved by a process called\n{rebalancing} that enables a poorly funded user to create incoming as well as\noutgoing credit links. We propose a system where a user with zero or no link\nweights can create incoming links with existing, trusted users in the network,\nin a procedure we call {balance transfer}, followed by creating outgoing links\nto existing or new users that would like to join the network, a process we call\n{bailout}. Both these processes together constitute our proposed rebalancing\nmechanism. Our techniques would also serve to make the network more competitive\nby offering users lower rates of interest, and enable users to earn routing\nfees-based revenue by participating in high throughput transaction paths.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 19:48:31 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Subramanian", "Lalitha Muthu", ""], ["Vishwanathan", "Roopa", ""], ["Kolachala", "Kartick", ""]]}, {"id": "2003.03471", "submitter": "Matthew Taylor", "authors": "Matthew Taylor, Ruturaj K. Vaidya, Drew Davidson, Lorenzo De Carli,\n  Vaibhav Rastogi", "title": "SpellBound: Defending Against Package Typosquatting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Package managers for software repositories based on a single programming\nlanguage are very common. Examples include npm (JavaScript), and PyPI (Python).\nThese tools encourage code reuse, making it trivial for developers to import\nexternal packages. Unfortunately, repositories' size and the ease with which\npackages can be published facilitates the practice of typosquatting: the\nuploading of a package with name similar to that of a highly popular package,\ntypically with the aim of capturing some of the popular package's installs.\nTyposquatting has serious negative implications, resulting in developers\nimporting malicious packages, or -- as we show -- code clones which do not\nincorporate recent security updates. In order to tackle this problem, we\npresent SpellBound, a tool for identifying and reporting potentially erroneous\nimports to developers. SpellBound implements a novel typosquatting detection\ntechnique, based on an in-depth analysis of npm and PyPI. Our technique\nleverages a model of lexical similarity between names, and further incorporates\nthe notion of package popularity. This approach flags cases where\nunknown/scarcely used packages would be installed in place of popular ones with\nsimilar names, before installation occurs. We evaluated SpellBound on both npm\nand PyPI, with encouraging results: SpellBound flags typosquatting cases while\ngenerating limited warnings (0.5% of total package installs), and low overhead\n(only 2.5% of package install time). Furthermore, SpellBound allowed us to\nconfirm known cases of typosquatting and discover one high-profile, unknown\ncase of typosquatting that resulted in a package takedown by the npm security\nteam.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 23:59:48 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Taylor", "Matthew", ""], ["Vaidya", "Ruturaj K.", ""], ["Davidson", "Drew", ""], ["De Carli", "Lorenzo", ""], ["Rastogi", "Vaibhav", ""]]}, {"id": "2003.03474", "submitter": "Jordan Lam", "authors": "Jordan Lam, Robert Abbas", "title": "Machine Learning based Anomaly Detection for 5G Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protecting the networks of tomorrow is set to be a challenging domain due to\nincreasing cyber security threats and widening attack surfaces created by the\nInternet of Things (IoT), increased network heterogeneity, increased use of\nvirtualisation technologies and distributed architectures. This paper proposes\nSDS (Software Defined Security) as a means to provide an automated, flexible\nand scalable network defence system. SDS will harness current advances in\nmachine learning to design a CNN (Convolutional Neural Network) using NAS\n(Neural Architecture Search) to detect anomalous network traffic. SDS can be\napplied to an intrusion detection system to create a more proactive and\nend-to-end defence for a 5G network. To test this assumption, normal and\nanomalous network flows from a simulated environment have been collected and\nanalyzed with a CNN. The results from this method are promising as the model\nhas identified benign traffic with a 100% accuracy rate and anomalous traffic\nwith a 96.4% detection rate. This demonstrates the effectiveness of network\nflow analysis for a variety of common malicious attacks and also provides a\nviable option for detection of encrypted malicious network traffic.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 00:17:08 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Lam", "Jordan", ""], ["Abbas", "Robert", ""]]}, {"id": "2003.03540", "submitter": "Swaprava Nath", "authors": "Jay Gupta and Swaprava Nath", "title": "SkillCheck: An Incentive-based Certification System using Blockchains", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Skill verification is a central problem in workforce hiring. Companies and\nacademia often face the difficulty of ascertaining the skills of an applicant\nsince the certifications of the skills claimed by a candidate are generally not\nimmediately verifiable and costly to test. Blockchains have been proposed in\nthe literature for skill verification and tamper-proof information storage in a\ndecentralized manner. However, most of these approaches deal with storing the\ncertificates issued by traditional universities on the blockchain. Among the\nfew techniques that consider the certification procedure itself, questions like\n(a) scalability with limited staff, (b) uniformity of grades over multiple\nevaluators, or (c) honest effort extraction from the evaluators are usually not\naddressed. We propose a blockchain-based platform named SkillCheck, which\nconsiders the questions above, and ensure several desirable properties. The\nplatform incentivizes effort in grading via payments with tokens which it\ngenerates from the payments of the users of the platform, e.g., the recruiters\nand test-takers. We provide a detailed description of the design of the\nplatform along with the provable properties of the algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 09:12:46 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 06:51:14 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Gupta", "Jay", ""], ["Nath", "Swaprava", ""]]}, {"id": "2003.03658", "submitter": "Brian Powell", "authors": "Brian A. Powell", "title": "Securing LSB embedding against structural steganalysis", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work explores the extent to which LSB embedding can be made secure\nagainst structural steganalysis through a modification of cover image\nstatistics prior to message embedding. Natural images possess symmetries that\nare expressed through approximately equal cardinalities of certain sets of\n$k$-tuples of consecutive pixels. LSB embedding disturbs this balance and a\n$k^{\\rm th}$-order structural attack infers the presence of a hidden message\nwith a length in proportion to the size of the imbalance amongst sets of\n$k$-tuples. To protect against $k^{\\rm th}$-order structural attacks, cover\nmodifications involve the redistribution of $k$-tuples among the different sets\nso that symmetries of the cover image are broken, then repaired through the act\nof LSB embedding so that the stego image bears the statistics of the original\ncover. To protect against all orders up to some order $k$, the statistics of\n$n$-tuples must be preserved where $n$ is the least common multiple of all\norders $\\leq k$. We find that this is only feasible for securing against up to\n$3^{\\rm rd}$-order attacks (Sample Pairs and Triples analyses) since\nhigher-order protections result in virtually zero embedding capacities.\nSecuring up to $3^{\\rm rd}$-order requires redistribution of sextuplets: rather\nthan perform these $6^{\\rm th}$-order cover modifications, which result in tiny\nembedding capacities, we reduce the problem to the redistribution of triplets\nin a manner that also preserves the statistics of pairs. This is done by\nembedding into only certain pixels of each sextuplet, constraining the maximum\nembedding rate to be $\\leq 2/3$ bits per channel. Testing on a variety of image\nformats, we report best performance for JPEG-compressed images with a mean\nmaximum embedding rate undetectable by $2^{\\rm nd}$- and $3^{\\rm rd}$-order\nattacks of 0.21 bits per channel.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 20:41:18 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Powell", "Brian A.", ""]]}, {"id": "2003.03663", "submitter": "Polina Zilberman", "authors": "Rami Puzis and Polina Zilberman and Yuval Elovici", "title": "ATHAFI: Agile Threat Hunting And Forensic Investigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attackers rapidly change their attacks to evade detection. Even the most\nsophisticated Intrusion Detection Systems that are based on artificial\nintelligence and advanced data analytic cannot keep pace with the rapid\ndevelopment of new attacks. When standard detection mechanisms fail or do not\nprovide sufficient forensic information to investigate and mitigate attacks,\ntargeted threat hunting performed by competent personnel is used.\nUnfortunately, many organization do not have enough security analysts to\nperform threat hunting tasks and today the level of automation of threat\nhunting is low.\n  In this paper we describe a framework for agile threat hunting and forensic\ninvestigation (ATHAFI), which automates the threat hunting process at multiple\nlevels. Adaptive targeted data collection, attack hypotheses generation,\nhypotheses testing, and continuous threat intelligence feeds allow to perform\nsimple investigations in a fully automated manner. The increased level of\nautomation will significantly boost the analyst's productivity during\ninvestigation of the harshest cases.\n  Special Workflow Generation module adapts the threat hunting procedures\neither to the latest Threat Intelligence obtained from external sources (e.g.\nNational CERT) or to the likeliest attack hypotheses generated by the Attack\nHypotheses Generation module. The combination of Attack Hypotheses Generation\nand Workflows Generation enables intelligent adjustment of workflows, which\nreact to emerging threats effectively.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 20:55:57 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Puzis", "Rami", ""], ["Zilberman", "Polina", ""], ["Elovici", "Yuval", ""]]}, {"id": "2003.03675", "submitter": "Yang Zhang", "authors": "Ahmed Salem and Rui Wen and Michael Backes and Shiqing Ma and Yang\n  Zhang", "title": "Dynamic Backdoor Attacks Against Machine Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) has made tremendous progress during the past decade and\nis being adopted in various critical real-world applications. However, recent\nresearch has shown that ML models are vulnerable to multiple security and\nprivacy attacks. In particular, backdoor attacks against ML models that have\nrecently raised a lot of awareness. A successful backdoor attack can cause\nsevere consequences, such as allowing an adversary to bypass critical\nauthentication systems.\n  Current backdooring techniques rely on adding static triggers (with fixed\npatterns and locations) on ML model inputs. In this paper, we propose the first\nclass of dynamic backdooring techniques: Random Backdoor, Backdoor Generating\nNetwork (BaN), and conditional Backdoor Generating Network (c-BaN). Triggers\ngenerated by our techniques can have random patterns and locations, which\nreduce the efficacy of the current backdoor detection mechanisms. In\nparticular, BaN and c-BaN are the first two schemes that algorithmically\ngenerate triggers, which rely on a novel generative network. Moreover, c-BaN is\nthe first conditional backdooring technique, that given a target label, it can\ngenerate a target-specific trigger. Both BaN and c-BaN are essentially a\ngeneral framework which renders the adversary the flexibility for further\ncustomizing backdoor attacks.\n  We extensively evaluate our techniques on three benchmark datasets: MNIST,\nCelebA, and CIFAR-10. Our techniques achieve almost perfect attack performance\non backdoored data with a negligible utility loss. We further show that our\ntechniques can bypass current state-of-the-art defense mechanisms against\nbackdoor attacks, including Neural Cleanse, ABS, and STRIP.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 22:46:51 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Salem", "Ahmed", ""], ["Wen", "Rui", ""], ["Backes", "Michael", ""], ["Ma", "Shiqing", ""], ["Zhang", "Yang", ""]]}, {"id": "2003.03699", "submitter": "Depeng Xu", "authors": "Depeng Xu, Wei Du and Xintao Wu", "title": "Removing Disparate Impact of Differentially Private Stochastic Gradient\n  Descent on Model Accuracy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When we enforce differential privacy in machine learning, the utility-privacy\ntrade-off is different w.r.t. each group. Gradient clipping and random noise\naddition disproportionately affect underrepresented and complex classes and\nsubgroups, which results in inequality in utility loss. In this work, we\nanalyze the inequality in utility loss by differential privacy and propose a\nmodified differentially private stochastic gradient descent (DPSGD), called\nDPSGD-F, to remove the potential disparate impact of differential privacy on\nthe protected group. DPSGD-F adjusts the contribution of samples in a group\ndepending on the group clipping bias such that differential privacy has no\ndisparate impact on group utility. Our experimental evaluation shows how group\nsample size and group clipping bias affect the impact of differential privacy\nin DPSGD, and how adaptive clipping for each group helps to mitigate the\ndisparate impact caused by differential privacy in DPSGD-F.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 02:06:15 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 21:04:37 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Xu", "Depeng", ""], ["Du", "Wei", ""], ["Wu", "Xintao", ""]]}, {"id": "2003.03713", "submitter": "Bo Liu", "authors": "Bang-Ying Tang and Bo Liu and Wan-Rong Yu and Chun-Qing Wu", "title": "Shannon-Limit Approached Information Reconciliation for Quantum Key\n  Distribution", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information reconciliation (IR) corrects the errors in sifted keys and\nensures the correctness of quantum key distribution (QKD) systems. Polar\ncodes-based IR schemes can achieve high reconciliation efficiency, however, the\nincidental high frame error rate decreases the secure key rate of QKD systems.\nIn this article, we propose a Shannon-limit approached (SLA) IR scheme, which\nmainly contains two phases: the forward reconciliation phase and the\nacknowledgment reconciliation phase. In the forward reconciliation phase, the\nsifted key is divided into sub-blocks and performed with the improved block\nchecked successive cancellation list (BC-SCL) decoder of polar codes.\nAfterwards, only the failure corrected sub-blocks perform the additional\nacknowledgment reconciliation phase, which decreases the frame error rate of\nthe SLA IR scheme. The experimental results show that the overall failure\nprobability of SLA IR scheme is decreased to $10^{-8}$ and the efficiency is\nimproved to 1.091 with the IR block length of 128Mb. Furthermore, the\nefficiency of the proposed SLA IR scheme is 1.055, approached to Shannon-limit,\nwhen quantum bit error rate is 0.02 and the input scale of 1Gb, which is\nhundred times larger than the state-of-art implemented polar codes-based IR\nschemes.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 03:59:56 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 01:59:58 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Tang", "Bang-Ying", ""], ["Liu", "Bo", ""], ["Yu", "Wan-Rong", ""], ["Wu", "Chun-Qing", ""]]}, {"id": "2003.03722", "submitter": "Jieyu Lin", "authors": "Jieyu Lin, Kristina Dzeparoska, Sai Qian Zhang, Alberto Leon-Garcia,\n  Nicolas Papernot", "title": "On the Robustness of Cooperative Multi-Agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cooperative multi-agent reinforcement learning (c-MARL), agents learn to\ncooperatively take actions as a team to maximize a total team reward. We\nanalyze the robustness of c-MARL to adversaries capable of attacking one of the\nagents on a team. Through the ability to manipulate this agent's observations,\nthe adversary seeks to decrease the total team reward.\n  Attacking c-MARL is challenging for three reasons: first, it is difficult to\nestimate team rewards or how they are impacted by an agent mispredicting;\nsecond, models are non-differentiable; and third, the feature space is\nlow-dimensional. Thus, we introduce a novel attack. The attacker first trains a\npolicy network with reinforcement learning to find a wrong action it should\nencourage the victim agent to take. Then, the adversary uses targeted\nadversarial examples to force the victim to take this action.\n  Our results on the StartCraft II multi-agent benchmark demonstrate that\nc-MARL teams are highly vulnerable to perturbations applied to one of their\nagent's observations. By attacking a single agent, our attack method has highly\nnegative impact on the overall team reward, reducing it from 20 to 9.4. This\nresults in the team's winning rate to go down from 98.9% to 0%.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 05:12:13 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Lin", "Jieyu", ""], ["Dzeparoska", "Kristina", ""], ["Zhang", "Sai Qian", ""], ["Leon-Garcia", "Alberto", ""], ["Papernot", "Nicolas", ""]]}, {"id": "2003.03810", "submitter": "Kaihua Qin", "authors": "Kaihua Qin, Liyi Zhou, Benjamin Livshits and Arthur Gervais", "title": "Attacking the DeFi Ecosystem with Flash Loans for Fun and Profit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Credit allows a lender to loan out surplus capital to a borrower. In the\ntraditional economy, credit bears the risk that the borrower may default on its\ndebt, the lender hence requires upfront collateral from the borrower, plus\ninterest fee payments. Due to the atomicity of blockchain transactions, lenders\ncan offer flash loans, i.e., loans that are only valid within one transaction\nand must be repaid by the end of that transaction. This concept has lead to a\nnumber of interesting attack possibilities, some of which were exploited in\nFebruary 2020.\n  This paper is the first to explore the implication of transaction atomicity\nand flash loans for the nascent decentralized finance (DeFi) ecosystem. We show\nquantitatively how transaction atomicity increases the arbitrage revenue. We\nmoreover analyze two existing attacks with ROIs beyond 500k%. We formulate\nfinding the attack parameters as an optimization problem over the state of the\nunderlying Ethereum blockchain and the state of the DeFi ecosystem. We show how\nmalicious adversaries can efficiently maximize an attack profit and hence\ndamage the DeFi ecosystem further. Specifically, we present how two previously\nexecuted attacks can be \"boosted\" to result in a profit of 829.5k USD and 1.1M\nUSD, respectively, which is a boost of 2.37x and 1.73x, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 16:52:34 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 20:28:58 GMT"}, {"version": "v3", "created": "Sat, 23 Jan 2021 17:13:59 GMT"}, {"version": "v4", "created": "Sat, 20 Mar 2021 10:42:45 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Qin", "Kaihua", ""], ["Zhou", "Liyi", ""], ["Livshits", "Benjamin", ""], ["Gervais", "Arthur", ""]]}, {"id": "2003.03850", "submitter": "Sharjeel Khan", "authors": "Sharjeel Khan, Girish Mururu and Santosh Pande", "title": "A Compiler Assisted Scheduler for Detecting and Mitigating Cache-Based\n  Side Channel Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Side channel attacks steal secret keys by cleverly leveraging information\nleakages and can, therefore, break encryption. Thus, detection and mitigation\nof side channel attacks is a very important problem, but the solutions proposed\nin the literature have limitations in that they do not work in a real-world\nmulti-tenancy setting on servers, have high false positives, or have high\noverheads. In this work, we demonstrate a compiler guided scheduler, Biscuit,\nthat detects cache-based side channel attacks for processes scheduled on\nmulti-tenancy server farms. A key element of this solution involves the use of\na cache-miss model which is inserted by the compiler at the entrances of loop\nnests to predict the cache misses of the corresponding loop. Such inserted\nlibrary calls, or beacons, convey the cache miss information to the scheduler\nat run time, which uses it to co-schedule processes such that their combined\ncache footprint does not exceed the maximum capacity of the last level cache.\nThe scheduled processes are then monitored for actual vs predicted cache\nmisses, and when an anomaly is detected, the scheduler performs a search to\nisolate the attacker. We show that Biscuit is able to detect and mitigate\nPrime+Probe, Flush+Reload, and Flush+Flush attacks on OpenSSL cryptography\nalgorithms with an F-score of 1, and also to detect and mitigate degradation of\nservice on a vision application suite with an F-score of 0.9375. Under a\nno-attack scenario, the scheme poses low overheads (up to a maximum of 6\npercent). In the case of an attack, the scheme ends up with less than 11\npercent overhead and is able to reduce the degradation of service in some cases\nby 40 percent. With these many desirable features such as an ability to deal\nwith multi-tenancy, its ability to detect attacks early, its ability to\nmitigate those attacks, and low runtime overheads, Biscuit is a practical\nsolution.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 21:22:12 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 00:40:33 GMT"}, {"version": "v3", "created": "Tue, 27 Oct 2020 14:07:49 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Khan", "Sharjeel", ""], ["Mururu", "Girish", ""], ["Pande", "Santosh", ""]]}, {"id": "2003.04024", "submitter": "Zhihui Li", "authors": "Dan-Li Zhi, Zhi-Hui Li, Zhao-Wei Han, Li-Juan Liu", "title": "A Verifiable Quantum Secret Sharing Scheme Based on a Single Qubit", "comments": null, "journal-ref": null, "doi": "10.1007/s10773-020-04599-7", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To detect frauds from some internal participants or external attackers, some\nverifiable threshold quantum secret sharing schemes have been proposed. In this\npaper, we present a new verifiable threshold structure based on a single qubit\nusing bivariate polynomial. First, Alice chooses an asymmetric bivariate\npolynomial and sends a pair of values from this polynomial to each participant.\nThen Alice and participants implement in sequence unitary transformation on the\n$d$-dimensional quantum state based on unbiased bases, where those unitary\ntransformations are contacted by this polynomial. Finally, security analysis\nshows that the proposed scheme can detect the fraud from external and internal\nattacks compared with the exiting schemes and is comparable to the recent\nschemes.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 10:24:55 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Zhi", "Dan-Li", ""], ["Li", "Zhi-Hui", ""], ["Han", "Zhao-Wei", ""], ["Liu", "Li-Juan", ""]]}, {"id": "2003.04038", "submitter": "Peng Wang", "authors": "Xiang Li and Peng Wang", "title": "TEDL: A Text Encryption Method Based on Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen an increasing emphasis on information security, and\nvarious encryption methods have been proposed. However, for symmetric\nencryption methods, the well-known encryption techniques still rely on the key\nspace to guarantee security and suffer from frequent key updating. Aiming to\nsolve those problems, this paper proposes a novel text encryption method based\non deep learning called TEDL, where the secret key includes hyperparameters in\ndeep learning model and the core step of encryption is transforming input data\ninto weights trained under hyperparameters. Firstly, both communication parties\nestablish a word vector table by training a deep learning model according to\nspecified hyperparameters. Then, a self-update codebook is constructed on the\nword vector table with the SHA-256 function and other tricks. When\ncommunication starts, encryption and decryption are equivalent to indexing and\ninverted indexing on the codebook, respectively, thus achieving the\ntransformation between plaintext and ciphertext. Results of experiments and\nrelevant analyses show that TEDL performs well for security, efficiency,\ngenerality, and has a lower demand for the frequency of key redistribution.\nEspecially, as a supplement to current encryption methods, the time-consuming\nprocess of constructing a codebook increases the difficulty of brute-force\nattacks while not degrade the communication efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 11:04:36 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 03:47:14 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Li", "Xiang", ""], ["Wang", "Peng", ""]]}, {"id": "2003.04079", "submitter": "Pedro Casas Dr.", "authors": "Gonzalo Mar\\'in, Pedro Casas, Germ\\'an Capdehourat", "title": "DeepMAL -- Deep Learning Models for Malware Traffic Detection and\n  Classification", "comments": "3rd International Data Science Conference (IDSC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust network security systems are essential to prevent and mitigate the\nharming effects of the ever-growing occurrence of network attacks. In recent\nyears, machine learning-based systems have gain popularity for network security\napplications, usually considering the application of shallow models, which rely\non the careful engineering of expert, handcrafted input features. The main\nlimitation of this approach is that handcrafted features can fail to perform\nwell under different scenarios and types of attacks. Deep Learning (DL) models\ncan solve this limitation using their ability to learn feature representations\nfrom raw, non-processed data. In this paper we explore the power of DL models\non the specific problem of detection and classification of malware network\ntraffic. As a major advantage with respect to the state of the art, we consider\nraw measurements coming directly from the stream of monitored bytes as input to\nthe proposed models, and evaluate different raw-traffic feature\nrepresentations, including packet and flow-level ones. We introduce DeepMAL, a\nDL model which is able to capture the underlying statistics of malicious\ntraffic, without any sort of expert handcrafted features. Using publicly\navailable traffic traces containing different families of malware traffic, we\nshow that DeepMAL can detect and classify malware flows with high accuracy,\noutperforming traditional, shallow-like models.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 16:54:26 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 16:56:46 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Mar\u00edn", "Gonzalo", ""], ["Casas", "Pedro", ""], ["Capdehourat", "Germ\u00e1n", ""]]}, {"id": "2003.04163", "submitter": "Newton Carlos Will", "authors": "Marciano da Rocha and Dalton C\\'ezane Gomes Valadares and Angelo\n  Perkusich and Kyller Costa Gorgonio and Rodrigo Tomaz Pagno and Newton Carlos\n  Will", "title": "Secure Cloud Storage with Client-Side Encryption Using a Trusted\n  Execution Environment", "comments": null, "journal-ref": null, "doi": "10.5220/0009130600310043", "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the evolution of computer systems, the amount of sensitive data to be\nstored as well as the number of threats on these data grow up, making the data\nconfidentiality increasingly important to computer users. Currently, with\ndevices always connected to the Internet, the use of cloud data storage\nservices has become practical and common, allowing quick access to such data\nwherever the user is. Such practicality brings with it a concern, precisely the\nconfidentiality of the data which is delivered to third parties for storage. In\nthe home environment, disk encryption tools have gained special attention from\nusers, being used on personal computers and also having native options in some\nsmartphone operating systems. The present work uses the data sealing, feature\nprovided by the Intel Software Guard Extensions (Intel SGX) technology, for\nfile encryption. A virtual file system is created in which applications can\nstore their data, keeping the security guarantees provided by the Intel SGX\ntechnology, before send the data to a storage provider. This way, even if the\nstorage provider is compromised, the data are safe. To validate the proposal,\nthe Cryptomator software, which is a free client-side encryption tool for cloud\nfiles, was integrated with an Intel SGX application (enclave) for data sealing.\nThe results demonstrate that the solution is feasible, in terms of performance\nand security, and can be expanded and refined for practical use and integration\nwith cloud synchronization services.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 14:18:57 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["da Rocha", "Marciano", ""], ["Valadares", "Dalton C\u00e9zane Gomes", ""], ["Perkusich", "Angelo", ""], ["Gorgonio", "Kyller Costa", ""], ["Pagno", "Rodrigo Tomaz", ""], ["Will", "Newton Carlos", ""]]}, {"id": "2003.04185", "submitter": "Gurcan Comert", "authors": "Gurcan Comert, Mizanur Rahman, Mhafuzul Islam, and Mashrur Chowdhury", "title": "Change Point Models for Real-time Cyber Attack Detection in Connected\n  Vehicle Environment", "comments": "11 pages, 4 figures, submitted to IEEE Transactions on Intelligent\n  Transportation Systems. arXiv admin note: substantial text overlap with\n  arXiv:1811.12620", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG eess.SP stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connected vehicle (CV) systems are cognizant of potential cyber attacks\nbecause of increasing connectivity between its different components such as\nvehicles, roadside infrastructure, and traffic management centers. However, it\nis a challenge to detect security threats in real-time and develop appropriate\nor effective countermeasures for a CV system because of the dynamic behavior of\nsuch attacks, high computational power requirement, and a historical data\nrequirement for training detection models. To address these challenges,\nstatistical models, especially change point models, have potentials for\nreal-time anomaly detections. Thus, the objective of this study is to\ninvestigate the efficacy of two change point models, Expectation Maximization\n(EM) and two forms of Cumulative Summation (CUSUM) algorithms (i.e., typical\nand adaptive), for real-time V2I cyber attack detection in a CV Environment. To\nprove the efficacy of these models, we evaluated these two models for three\ndifferent type of cyber attack, denial of service (DOS), impersonation, and\nfalse information, using basic safety messages (BSMs) generated from CVs\nthrough simulation. Results from numerical analysis revealed that EM, CUSUM,\nand adaptive CUSUM could detect these cyber attacks, DOS, impersonation, and\nfalse information, with an accuracy of (99%, 100%, 100%), (98%, 10%, 100%), and\n(100%, 98%, 100%) respectively.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 21:19:42 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Comert", "Gurcan", ""], ["Rahman", "Mizanur", ""], ["Islam", "Mhafuzul", ""], ["Chowdhury", "Mashrur", ""]]}, {"id": "2003.04244", "submitter": "Pratham Oza", "authors": "Pratham Oza, Mahsa Foruhandeh, Ryan Gerdes and Thidapat Chantem", "title": "Secure Traffic Lights: Replay Attack Detection for Model-based Smart\n  Traffic Controllers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid urbanization calls for smart traffic management solutions that\nincorporate sensors, distributed traffic controllers and V2X communication\ntechnologies to provide fine-grained traffic control to mitigate congestion. As\nin many other cyber-physical systems, smart traffic management systems\ntypically lack security measures. This allows numerous opportunities for\nadversarial entities to craft attacks on the sensor networks, wireless data\nsharing and/or the distributed traffic controllers. We show that such\nvulnerabilities can be exploited to disrupt mobility in a large urban area and\ncause unsafe conditions for drivers and the pedestrians on the roads.\nSpecifically, in this paper, we look into vulnerabilities in model-based\ntraffic controllers and show that, even with state-of-the-art attack detectors\nin place, false-data injection can be used to hamper mobility. We demonstrate a\nreplay attack by modeling an isolated intersection in VISSIM, a popular traffic\nsimulator and also discuss countermeasures to thwart such attacks.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 16:32:27 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Oza", "Pratham", ""], ["Foruhandeh", "Mahsa", ""], ["Gerdes", "Ryan", ""], ["Chantem", "Thidapat", ""]]}, {"id": "2003.04247", "submitter": "David Sommer", "authors": "David Marco Sommer, Liwei Song, Sameer Wagh, Prateek Mittal", "title": "Towards Probabilistic Verification of Machine Unlearning", "comments": "code is available at\n  https://github.com/inspire-group/unlearning-verification", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The right to be forgotten, also known as the right to erasure, is the right\nof individuals to have their data erased from an entity storing it. The status\nof this long held notion was legally solidified recently by the General Data\nProtection Regulation (GDPR) in the European Union. Consequently, there is a\nneed for mechanisms whereby users can verify if service providers comply with\ntheir deletion requests. In this work, we take the first step in proposing a\nformal framework to study the design of such verification mechanisms for data\ndeletion requests -- also known as machine unlearning -- in the context of\nsystems that provide machine learning as a service (MLaaS). Our framework\nallows the rigorous quantification of any verification mechanism based on\nstandard hypothesis testing. Furthermore, we propose a novel backdoor-based\nverification mechanism and demonstrate its effectiveness in certifying data\ndeletion with high confidence, thus providing a basis for quantitatively\ninferring machine unlearning.\n  We evaluate our approach over a range of network architectures such as\nmulti-layer perceptrons (MLP), convolutional neural networks (CNN), residual\nnetworks (ResNet), and long short-term memory (LSTM), as well as over 5\ndifferent datasets. We demonstrate that our approach has minimal effect on the\nML service's accuracy but provides high confidence verification of unlearning.\nOur proposed mechanism works even if only a handful of users employ our system\nto ascertain compliance with data deletion requests. In particular, with just\n5% of users participating, modifying half their data with a backdoor, and with\nmerely 30 test queries, our verification mechanism has both false positive and\nfalse negative ratios below $10^{-3}$. We also show the effectiveness of our\napproach by testing it against an adaptive adversary that uses a\nstate-of-the-art backdoor defense method.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 16:39:46 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 16:01:10 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Sommer", "David Marco", ""], ["Song", "Liwei", ""], ["Wagh", "Sameer", ""], ["Mittal", "Prateek", ""]]}, {"id": "2003.04309", "submitter": "Zhihui Li", "authors": "Li-Juan Liu, Zhi-Hui Li, Zhao-Wei Han, Dan-Li Zhi", "title": "A quantum secret sharing scheme with verifiable function", "comments": null, "journal-ref": null, "doi": "10.1140/epjd/e2020-10010-3", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the $\\left( {t,n} \\right)$ threshold quantum secret sharing scheme, it is\ndifficult to ensure that internal participants are honest. In this paper, a\nverifiable $\\left( {t,n} \\right)$ threshold quantum secret sharing scheme is\ndesigned combined with classical secret sharing scheme. First of all, the\ndistributor uses the asymmetric binary polynomials to generate the shares and\nsends them to each participant. Secondly, the distributor sends the initial\nquantum state with the secret to the first participant, and each participant\nperforms unitary operation that using the mutually unbiased bases on the\nobtained $d$ dimension single bit quantum state ($d$ is a large odd prime\nnumber). In this process, distributor can randomly check the participants, and\nfind out the internal fraudsters by unitary inverse operation gradually upward.\nThen the secret is reconstructed after all other participants simultaneously\npublic transmission. Security analysis show that this scheme can resist both\nexternal and internal attacks.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 10:39:52 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Liu", "Li-Juan", ""], ["Li", "Zhi-Hui", ""], ["Han", "Zhao-Wei", ""], ["Zhi", "Dan-Li", ""]]}, {"id": "2003.04367", "submitter": "Bin Kong", "authors": "Quanyu Liao, Xin Wang, Bin Kong, Siwei Lyu, Youbing Yin, Qi Song, Xi\n  Wu", "title": "Category-wise Attack: Transferable Adversarial Examples for Anchor Free\n  Object Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been demonstrated to be vulnerable to adversarial\nattacks: subtle perturbations can completely change the classification results.\nTheir vulnerability has led to a surge of research in this direction. However,\nmost works dedicated to attacking anchor-based object detection models. In this\nwork, we aim to present an effective and efficient algorithm to generate\nadversarial examples to attack anchor-free object models based on two\napproaches. First, we conduct category-wise instead of instance-wise attacks on\nthe object detectors. Second, we leverage the high-level semantic information\nto generate the adversarial examples. Surprisingly, the generated adversarial\nexamples it not only able to effectively attack the targeted anchor-free object\ndetector but also to be transferred to attack other object detectors, even\nanchor-based detectors such as Faster R-CNN.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 04:49:03 GMT"}, {"version": "v2", "created": "Sat, 4 Apr 2020 16:07:53 GMT"}, {"version": "v3", "created": "Sat, 11 Apr 2020 21:30:41 GMT"}, {"version": "v4", "created": "Tue, 23 Jun 2020 00:14:15 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Liao", "Quanyu", ""], ["Wang", "Xin", ""], ["Kong", "Bin", ""], ["Lyu", "Siwei", ""], ["Yin", "Youbing", ""], ["Song", "Qi", ""], ["Wu", "Xi", ""]]}, {"id": "2003.04426", "submitter": "Christos Karapapas", "authors": "Christos Karapapas, Iakovos Pittaras, Nikos Fotiou, George C. Polyzos", "title": "Ransomware as a Service using Smart Contracts and IPFS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized systems, such as distributed ledgers and the InterPlanetary\nFile System (IPFS), are designed to offer more open and robust services.\nHowever, they also create opportunities for illegal activities. We demonstrate\nhow these technologies can be used to launch a ransomware as a service\ncampaign. We show that criminals can transact with affiliates and victims\nwithout having to reveal their identity. Furthermore, by exploiting the\nrobustness and resilience to churn of IPFS, as well as the decentralized\ncomputing capabilities of Ethereum, criminals can remain offline during most\nprocedures, with many privacy guarantees.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 21:49:31 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Karapapas", "Christos", ""], ["Pittaras", "Iakovos", ""], ["Fotiou", "Nikos", ""], ["Polyzos", "George C.", ""]]}, {"id": "2003.04463", "submitter": "Sarah Bird", "authors": "Sarah Bird, Vikas Mishra, Steven Englehardt, Rob Willoughby, David\n  Zeber, Walter Rudametkin, Martin Lopatka", "title": "Actions speak louder than words: Semi-supervised learning for browser\n  fingerprinting detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As online tracking continues to grow, existing anti-tracking and\nfingerprinting detection techniques that require significant manual input must\nbe augmented. Heuristic approaches to fingerprinting detection are precise but\nmust be carefully curated. Supervised machine learning techniques proposed for\ndetecting tracking require manually generated label-sets. Seeking to overcome\nthese challenges, we present a semi-supervised machine learning approach for\ndetecting fingerprinting scripts. Our approach is based on the core insight\nthat fingerprinting scripts have similar patterns of API access when generating\ntheir fingerprints, even though their access patterns may not match exactly.\nUsing this insight, we group scripts by their JavaScript (JS) execution traces\nand apply a semi-supervised approach to detect new fingerprinting scripts. We\ndetail our methodology and demonstrate its ability to identify the majority of\nscripts ($\\geqslant$94.9%) identified by existing heuristic techniques. We also\nshow that the approach expands beyond detecting known scripts by surfacing\ncandidate scripts that are likely to include fingerprinting. Through an\nanalysis of these candidate scripts we discovered fingerprinting scripts that\nwere missed by heuristics and for which there are no heuristics. In particular,\nwe identified over one hundred device-class fingerprinting scripts present on\nhundreds of domains. To the best of our knowledge, this is the first time\ndevice-class fingerprinting has been measured in the wild. These successes\nillustrate the power of a sparse vector representation and semi-supervised\nlearning to complement and extend existing tracking detection techniques.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 23:58:56 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Bird", "Sarah", ""], ["Mishra", "Vikas", ""], ["Englehardt", "Steven", ""], ["Willoughby", "Rob", ""], ["Zeber", "David", ""], ["Rudametkin", "Walter", ""], ["Lopatka", "Martin", ""]]}, {"id": "2003.04493", "submitter": "Qinqing Zheng", "authors": "Qinqing Zheng, Jinshuo Dong, Qi Long, Weijie J. Su", "title": "Sharp Composition Bounds for Gaussian Differential Privacy via Edgeworth\n  Expansion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CR cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Datasets containing sensitive information are often sequentially analyzed by\nmany algorithms. This raises a fundamental question in differential privacy\nregarding how the overall privacy bound degrades under composition. To address\nthis question, we introduce a family of analytical and sharp privacy bounds\nunder composition using the Edgeworth expansion in the framework of the\nrecently proposed f-differential privacy. In contrast to the existing\ncomposition theorems using the central limit theorem, our new privacy bounds\nunder composition gain improved tightness by leveraging the refined\napproximation accuracy of the Edgeworth expansion. Our approach is easy to\nimplement and computationally efficient for any number of compositions. The\nsuperiority of these new bounds is confirmed by an asymptotic error analysis\nand an application to quantifying the overall privacy guarantees of noisy\nstochastic gradient descent used in training private deep neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 01:54:15 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 15:18:11 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Zheng", "Qinqing", ""], ["Dong", "Jinshuo", ""], ["Long", "Qi", ""], ["Su", "Weijie J.", ""]]}, {"id": "2003.04498", "submitter": "Stefan Saroiu", "authors": "Lucian Cojocar, Jeremie Kim, Minesh Patel, Lillian Tsai, Stefan\n  Saroiu, Alec Wolman, Onur Mutlu", "title": "Are We Susceptible to Rowhammer? An End-to-End Methodology for Cloud\n  Providers", "comments": "A version of this paper will appear in the IEEE S&P 2020 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud providers are concerned that Rowhammer poses a potentially critical\nthreat to their servers, yet today they lack a systematic way to test whether\nthe DRAM used in their servers is vulnerable to Rowhammer attacks. This paper\npresents an end-to-end methodology to determine if cloud servers are\nsusceptible to these attacks. With our methodology, a cloud provider can\nconstruct worst-case testing conditions for DRAM.\n  We apply our methodology to three classes of servers from a major cloud\nprovider. Our findings show that none of the CPU instruction sequences used in\nprior work to mount Rowhammer attacks create worst-case DRAM testing\nconditions. To address this limitation, we develop an instruction sequence that\nleverages microarchitectural side-effects to ``hammer'' DRAM at a near-optimal\nrate on modern Intel Skylake and Cascade Lake platforms. We also design a DDR4\nfault injector that can reverse engineer row adjacency for any DDR4 DIMM. When\napplied to our cloud provider's DIMMs, we find that DRAM rows do not always\nfollow a linear map.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 02:05:13 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Cojocar", "Lucian", ""], ["Kim", "Jeremie", ""], ["Patel", "Minesh", ""], ["Tsai", "Lillian", ""], ["Saroiu", "Stefan", ""], ["Wolman", "Alec", ""], ["Mutlu", "Onur", ""]]}, {"id": "2003.04693", "submitter": "Alexander Freij", "authors": "Alexander Freij, Shougang Yuan, Huiyang Zhou, Yan Solihin", "title": "Streamlining Integrity Tree Updates for Secure Persistent Non-Volatile\n  Memory", "comments": "13 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging non-volatile main memory (NVMM) is rapidly being integrated into\ncomputer systems. However, NVMM is vulnerable to potential data remanence and\nreplay attacks.\n  Established security models including split counter mode encryption and\nBonsai Merkle tree (BMT) authentication have been introduced against such data\nintegrity attacks. However, these security methods are not readily compatible\nwith NVMM. Recent works on secure NVMM pointed out the need for data and its\nmetadata, including the counter, the message authentication code (MAC), and the\nBMT to be persisted atomically. However, memory persistency models have been\noverlooked for secure NVMM, which is essential for crash recoverability.\n  In this work, we analyze the invariants that need to be ensured in order to\nsupport crash recovery for secure NVMM. We highlight that prior research has\nsubstantially under-estimated the cost of BMT persistence and propose several\noptimization techniques to reduce the overhead of atomically persisting updates\nto BMTs. The optimizations proposed explore the use of pipelining, out-of-order\nwrites, and update coalescing while conforming to strict or epoch persistency\nmodels respectively. We evaluate our work and show that our proposed\noptimizations significantly reduce the performance overhead of secure NVMM with\ncrash recoverability.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 13:29:34 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Freij", "Alexander", ""], ["Yuan", "Shougang", ""], ["Zhou", "Huiyang", ""], ["Solihin", "Yan", ""]]}, {"id": "2003.04735", "submitter": "Rui Zhang", "authors": "Rui Zhang, Quanyan Zhu", "title": "Security of Distributed Machine Learning: A Game-Theoretic Approach to\n  Design Secure DSVM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed machine learning algorithms play a significant role in processing\nmassive data sets over large networks. However, the increasing reliance on\nmachine learning on information and communication technologies (ICTs) makes it\ninherently vulnerable to cyber threats. This work aims to develop secure\ndistributed algorithms to protect the learning from data poisoning and network\nattacks. We establish a game-theoretic framework to capture the conflicting\ngoals of a learner who uses distributed support vector machines (SVMs) and an\nattacker who is capable of modifying training data and labels. We develop a\nfully distributed and iterative algorithm to capture real-time reactions of the\nlearner at each node to adversarial behaviors. The numerical results show that\ndistributed SVM is prone to fail in different types of attacks, and their\nimpact has a strong dependence on the network structure and attack\ncapabilities.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 18:54:17 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 21:50:35 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Zhang", "Rui", ""], ["Zhu", "Quanyan", ""]]}, {"id": "2003.04868", "submitter": "Philipp Markert", "authors": "Philipp Markert, Daniel V. Bailey, Maximilian Golla, Markus D\\\"urmuth,\n  Adam J. Aviv", "title": "This PIN Can Be Easily Guessed: Analyzing the Security of Smartphone\n  Unlock PINs", "comments": "15+3 pages, 9 figures, 8+5 tables", "journal-ref": "IEEE Symposium on Security and Privacy (SP), 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide the first comprehensive study of user-chosen 4- and\n6-digit PINs (n=1220) collected on smartphones with participants being\nexplicitly primed for device unlocking. We find that against a throttled\nattacker (with 10, 30, or 100 guesses, matching the smartphone unlock setting),\nusing 6-digit PINs instead of 4-digit PINs provides little to no increase in\nsecurity, and surprisingly may even decrease security. We also study the\neffects of blocklists, where a set of \"easy to guess\" PINs is disallowed during\nselection. Two such blocklists are in use today by iOS, for 4-digits (274 PINs)\nas well as 6-digits (2910 PINs). We extracted both blocklists compared them\nwith four other blocklists, including a small 4-digit (27 PINs), a large\n4-digit (2740 PINs), and two placebo blocklists for 4- and 6-digit PINs that\nalways excluded the first-choice PIN. We find that relatively small blocklists\nin use today by iOS offer little or no benefit against a throttled guessing\nattack. Security gains are only observed when the blocklists are much larger,\nwhich in turn comes at the cost of increased user frustration. Our analysis\nsuggests that a blocklist at about 10% of the PIN space may provide the best\nbalance between usability and security.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 17:30:16 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 11:01:41 GMT"}, {"version": "v3", "created": "Wed, 16 Jun 2021 12:02:18 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Markert", "Philipp", ""], ["Bailey", "Daniel V.", ""], ["Golla", "Maximilian", ""], ["D\u00fcrmuth", "Markus", ""], ["Aviv", "Adam J.", ""]]}, {"id": "2003.04884", "submitter": "Nicholas Carlini", "authors": "Nicholas Carlini, Matthew Jagielski, Ilya Mironov", "title": "Cryptanalytic Extraction of Neural Network Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We argue that the machine learning problem of model extraction is actually a\ncryptanalytic problem in disguise, and should be studied as such. Given oracle\naccess to a neural network, we introduce a differential attack that can\nefficiently steal the parameters of the remote model up to floating point\nprecision. Our attack relies on the fact that ReLU neural networks are\npiecewise linear functions, and thus queries at the critical points reveal\ninformation about the model parameters.\n  We evaluate our attack on multiple neural network models and extract models\nthat are 2^20 times more precise and require 100x fewer queries than prior\nwork. For example, we extract a 100,000 parameter neural network trained on the\nMNIST digit recognition task with 2^21.5 queries in under an hour, such that\nthe extracted model agrees with the oracle on all inputs up to a worst-case\nerror of 2^-25, or a model with 4,000 parameters in 2^18.5 queries with\nworst-case error of 2^-40.4. Code is available at\nhttps://github.com/google-research/cryptanalytic-model-extraction.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 17:57:14 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 16:58:14 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Carlini", "Nicholas", ""], ["Jagielski", "Matthew", ""], ["Mironov", "Ilya", ""]]}, {"id": "2003.04969", "submitter": "Shantanu Sharma", "authors": "Nisha Panwar, Shantanu Sharma, Peeyush Gupta, Dhrubajyoti Ghosh,\n  Sharad Mehrotra, Nalini Venkatasubramanian", "title": "IoT Expunge: Implementing Verifiable Retention of IoT Data", "comments": "This paper has been accepted in 10th ACM Conference on Data and\n  Application Security and Privacy (CODASPY), 2020", "journal-ref": null, "doi": "10.1145/3374664.3375737", "report-no": null, "categories": "cs.CR cs.DB cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing deployment of Internet of Things (IoT) systems aims to ease the\ndaily life of end-users by providing several value-added services. However, IoT\nsystems may capture and store sensitive, personal data about individuals in the\ncloud, thereby jeopardizing user-privacy. Emerging legislation, such as\nCalifornia's CalOPPA and GDPR in Europe, support strong privacy laws to protect\nan individual's data in the cloud. One such law relates to strict enforcement\nof data retention policies. This paper proposes a framework, entitled IoT\nExpunge that allows sensor data providers to store the data in cloud platforms\nthat will ensure enforcement of retention policies. Additionally, the cloud\nprovider produces verifiable proofs of its adherence to the retention policies.\nExperimental results on a real-world smart building testbed show that IoT\nExpunge imposes minimal overheads to the user to verify the data against data\nretention policies.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 20:55:01 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Panwar", "Nisha", ""], ["Sharma", "Shantanu", ""], ["Gupta", "Peeyush", ""], ["Ghosh", "Dhrubajyoti", ""], ["Mehrotra", "Sharad", ""], ["Venkatasubramanian", "Nalini", ""]]}, {"id": "2003.04984", "submitter": "Reza Fotohi", "authors": "Reza Fotohi", "title": "Securing of Unmanned Aerial Systems (UAS) against security threats using\n  human immune system", "comments": "29 pages, 12 figures, 10 tables, 8 equations, Journal", "journal-ref": "Reliability Engineering & System Safety, 193, 106675 (2020)", "doi": "10.1016/j.ress.2019.106675", "report-no": null, "categories": "cs.CR cs.AI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  UASs form a large part of the fighting ability of the advanced military\nforces. In particular, these systems that carry confidential information are\nsubject to security attacks. Accordingly, an Intrusion Detection System (IDS)\nhas been proposed in the proposed design to protect against the security\nproblems using the human immune system (HIS). The IDSs are used to detect and\nrespond to attempts to compromise the target system. Since the UASs operate in\nthe real world, the testing and validation of these systems with a variety of\nsensors is confronted with problems. This design is inspired by HIS. In the\nmapping, insecure signals are equivalent to an antigen that are detected by\nantibody-based training patterns and removed from the operation cycle. Among\nthe main uses of the proposed design are the quick detection of intrusive\nsignals and quarantining their activity. Moreover, SUAS-HIS method is evaluated\nhere via extensive simulations carried out in NS-3 environment. The simulation\nresults indicate that the UAS network performance metrics are improved in terms\nof false positive rate, false negative rate, detection rate, and packet\ndelivery rate.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 19:05:16 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Fotohi", "Reza", ""]]}, {"id": "2003.04997", "submitter": "Michael Byrne", "authors": "Philip Kortum, Michael D. Byrne, and Julie Whitmore", "title": "Voter Verification of BMD Ballots Is a Two-Part Question: Can They?\n  Mostly, They Can. Do They? Mostly, They Don't", "comments": "21 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The question of whether or not voters actually verify ballots produced by\nballot marking devices (BMDs) is presently the subject of some controversy.\nRecent studies (e.g., Bernhard, et al. 2020) suggest the verification rate is\nlow. What is not clear from previous research is whether this is more a result\nof voters being unable to do so accurately or whether this is because voters\nsimply choose not to attempt verification in the first place. In order to\nunderstand this problem, we conducted an experiment in which 108 participants\nparticipated in a mock election where the BMD displayed the voters' true\nchoices, but then changed a subset of those choices on the printed ballot. The\ndesign of the printed ballot, the length of the ballot, the number of changes\nthat were made to the ballot, the location of those changes, and the\ninstructions provided to the voters were manipulated as part of the experiment.\nResults indicated that of those voters who chose to examine the printed ballot,\n76% detected anomalies, indicating that voters can reliably detect errors on\ntheir ballot if they will simply review it. This suggests that administrative\nremedies, rather than attempts to alter fundamental human perceptual\ncapabilities, could be employed to encourage voters to check their ballots,\nwhich could prove as an effective countermeasure.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 21:06:42 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Kortum", "Philip", ""], ["Byrne", "Michael D.", ""], ["Whitmore", "Julie", ""]]}, {"id": "2003.05005", "submitter": "Shreyank N Gowda", "authors": "Shreyank N Gowda, Chun Yuan", "title": "Using an ensemble color space model to tackle adversarial examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minute pixel changes in an image drastically change the prediction that the\ndeep learning model makes. One of the most significant problems that could\narise due to this, for instance, is autonomous driving. Many methods have been\nproposed to combat this with varying amounts of success. We propose a 3 step\nmethod for defending such attacks. First, we denoise the image using\nstatistical methods. Second, we show that adopting multiple color spaces in the\nsame model can help us to fight these adversarial attacks further as each color\nspace detects certain features explicit to itself. Finally, the feature maps\ngenerated are enlarged and sent back as an input to obtain even smaller\nfeatures. We show that the proposed model does not need to be trained to defend\nan particular type of attack and is inherently more robust to black-box,\nwhite-box, and grey-box adversarial attack techniques. In particular, the model\nis 56.12 percent more robust than compared models in case of white box attacks\nwhen the models are not subject to adversarial example training.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 21:20:53 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Gowda", "Shreyank N", ""], ["Yuan", "Chun", ""]]}, {"id": "2003.05039", "submitter": "Rukayat Erinfolami Miss", "authors": "Rukayat Ayomide Erinfolami and Aravind Prakash", "title": "Devil is Virtual: Reversing Virtual Inheritance in C++ Binaries", "comments": "Accepted at CCS20. This is a technical report version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Complexities that arise from implementation of object-oriented concepts in\nC++ such as virtual dispatch and dynamic type casting have attracted the\nattention of attackers and defenders alike.\n  Binary-level defenses are dependent on full and precise recovery of class\ninheritance tree of a given program.\n  While current solutions focus on recovering single and multiple inheritances\nfrom the binary, they are oblivious to virtual inheritance. Conventional wisdom\namong binary-level defenses is that virtual inheritance is uncommon and/or\nsupport for single and multiple inheritances provides implicit support for\nvirtual inheritance. In this paper, we show neither to be true.\n  Specifically, (1) we present an efficient technique to detect virtual\ninheritance in C++ binaries and show through a study that virtual inheritance\ncan be found in non-negligible number (more than 10\\% on Linux and 12.5\\% on\nWindows) of real-world C++ programs including Mysql and libstdc++. (2) we show\nthat failure to handle virtual inheritance introduces both false positives and\nfalse negatives in the hierarchy tree. These false positves and negatives\neither introduce attack surface when the hierarchy recovered is used to enforce\nCFI policies, or make the hierarchy difficult to understand when it is needed\nfor program understanding (e.g., during decompilation). (3) We present a\nsolution to recover virtual inheritance from COTS binaries. We recover a\nmaximum of 95\\% and 95.5\\% (GCC -O0) and a minimum of 77.5\\% and 73.8\\% (Clang\n-O2) of virtual and intermediate bases respectively in the virtual inheritance\ntree.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 23:51:39 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 18:11:28 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Erinfolami", "Rukayat Ayomide", ""], ["Prakash", "Aravind", ""]]}, {"id": "2003.05067", "submitter": "arXiv Admin", "authors": "George Yuan", "title": "The Framework of Consensus Equilibria for Mining-Pool Games in\n  Blockchain Ecosystems", "comments": "arXiv admin note: submission has been withdrawn by arXiv\n  administrators due to inappropriate overlap with external sources", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to establish the general framework of consensus\nequilibria for Mining-Pool Games in Blockchain Ecosystems, and with the\nexplanation for the stability of in terms of the existence of consensus\nequilibria related to mining gap game's behaviors by using one new concept\ncalled consensus games in Blockchain Ecosystems, here, the Blockchain ecosystem\nmainly means the economic activities by taking into the account of three types\nof different factors which are expenses, reward mechanism and mining power for\nthe work on blockschain by applying the key consensus called Proof of Work due\nto Nakamoto in 2008.\n  In order to do so, we first give an outline how the general existence of\nconsensus equilibria for Mining Pool Games is formulated, and then used to\nexplain the stable for Gap Games for Bitcoin in the sense by the existence of\nconsensus equilibria under the framework of Blockchain consensus, we then\nestablish a general existence result for consensus equilibria of general mining\ngap games by using the profit functions for miners as the payoffs in game\ntheory. As applications, the general existence results for consensus equilibria\nof Gap games are established, which not only help us to claim the existence for\nthe general stability for Gap games under the general framework of Blockchain\necosystems, but also allow us to illustrate a number of different phenomenon on\nthe study of mining-pool games with possible impacts due to miners's gap\nbehaviors with scenarios embedded n Bitcoin economics. Our study on the\nexplanation for the stability of mining gap game for Blockchain ecosystems\nshows that the concept of consensus equilibria may play a important role for\nthe development of fundamental theory for consensus economics.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 13:31:37 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 20:28:37 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Yuan", "George", ""]]}, {"id": "2003.05071", "submitter": "Nam Tran", "authors": "Nam N. Tran, Hemanshu R. Pota, Quang N. Tran, Xuefei Yin, Jiankun Hu", "title": "Designing False Data Injection attacks penetrating AC-based Bad Data\n  Detection System and FDI Dataset generation", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evolution of the traditional power system towards the modern smart grid\nhas posed many new cybersecurity challenges to this critical infrastructure.\nOne of the most dangerous cybersecurity threats is the False Data Injection\n(FDI) attack, especially when it is capable of completely bypassing the widely\ndeployed Bad Data Detector of State Estimation and interrupting the normal\noperation of the power system. Most of the simulated FDI attacks are designed\nusing simplified linearized DC model while most industry standard State\nEstimation systems are based on the nonlinear AC model. In this paper, a\ncomprehensive FDI attack scheme is presented based on the nonlinear AC model. A\ncase study of the nine-bus Western System Coordinated Council (WSCC)'s power\nsystem is provided, using an industry standard package to assess the outcomes\nof the proposed design scheme. A public FDI dataset is generated as a test set\nfor the community to develop and evaluate new detection algorithms, which are\nlacking in the field. The FDI's stealthy quality of the dataset is assessed and\nproven through a preliminary analysis based on both physical power law and\nstatistical analysis.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 01:36:42 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Tran", "Nam N.", ""], ["Pota", "Hemanshu R.", ""], ["Tran", "Quang N.", ""], ["Yin", "Xuefei", ""], ["Hu", "Jiankun", ""]]}, {"id": "2003.05088", "submitter": "Nam Tran", "authors": "Nam N. Tran, Hemanshu R. Pota, Quang N. Tran, Jiankun Hu", "title": "Designing constraint-based false data injection attacks against the\n  unbalanced distribution smart grids", "comments": "14 pages, 10 figures. This paper was accepted accepted for\n  publication in the IEEE Internet of Things Journal on January, 31st 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of smart power grid which plays a vital role in the upcoming smart\ncity era is accompanied with the implementation of a monitoring tool, called\nstate estimation. For the case of the unbalanced residential distribution grid,\nthe state estimating operation which is conducted at a regional scale is\nconsidered as an application of the edge computing-based Internet of Things\n(IoT). While the outcome of the state estimation is important to the subsequent\ncontrol activities, its accuracy heavily depends on the data integrity of the\ninformation collected from the scattered measurement devices. This fact exposes\nthe vulnerability of the state estimation module under the effect of\ndata-driven attacks. Among these, false data injection attack (FDI) is\nattracting much attention due to its capability to interfere with the normal\noperation of the network without being detected. This paper presents an attack\ndesign scheme based on a nonlinear physical-constraint model that is able to\nproduce an FDI attack with theoretically stealthy characteristic. To\ndemonstrate the effectiveness of the proposed design scheme, simulations with\nthe IEEE 13-node test feeder and the WSCC 9-bus system are conducted. The\nexperimental results indicate that not only the false positive rate of the bad\ndata detection mechanism is 100 per cent but the physical consequence of the\nattack is severe. These results pose a serious challenge for operators in\nmaintaining the integrity of measurement data.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 02:55:16 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 11:42:30 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Tran", "Nam N.", ""], ["Pota", "Hemanshu R.", ""], ["Tran", "Quang N.", ""], ["Hu", "Jiankun", ""]]}, {"id": "2003.05106", "submitter": "Geovane Fedrecheski", "authors": "Geovane Fedrecheski, Jan M. Rabaey, Laisa C. P. Costa, Pablo C.\n  Calcina Ccori, William T. Pereira, Marcelo K. Zuffo", "title": "Self-Sovereign Identity for IoT environments: A Perspective", "comments": null, "journal-ref": null, "doi": "10.1109/GIOTS49054.2020.9119664", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper analyses the concept of Self-Sovereign Identity (SSI), an emerging\napproach for establishing digital identity, in the context of the Internet of\nThings (IoT). We contrast existing approaches for identity on the Internet,\nsuch as cloud-based accounts and digital certificates, with SSI standards such\nas Decentralized Identifiers (DIDs) and Verifiable Credentials (VCs). To the\nbest of our knowledge, this is the first thorough comparison of these\napproaches. The benefits and challenges of using DIDs and VCs to identify and\nauthenticate IoT devices and their respective users are discussed. In the end,\nwe establish that SSI, with its owner-centric, privacy-aware and decentrailized\napproach, provides a viable and attractive option for secure identification of\nIoT devices and users.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 04:29:14 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Fedrecheski", "Geovane", ""], ["Rabaey", "Jan M.", ""], ["Costa", "Laisa C. P.", ""], ["Ccori", "Pablo C. Calcina", ""], ["Pereira", "William T.", ""], ["Zuffo", "Marcelo K.", ""]]}, {"id": "2003.05188", "submitter": "Steffen Haas", "authors": "Steffen Haas, Florian Wilkens, Mathias Fischer", "title": "Scan Correlation -- Revealing distributed scan campaigns", "comments": "Accepted for publication at DISSECT '20", "journal-ref": "NOMS 2020 - 2020 IEEE/IFIP Network Operations and Management\n  Symposium, Budapest, Hungary, 2020, pp. 1-6", "doi": "10.1109/NOMS47738.2020.9110470", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public networks are exposed to port scans from the Internet. Attackers search\nfor vulnerable services they can exploit. In large scan campaigns, attackers\noften utilize different machines to perform distributed scans, which impedes\ntheir detection and might also camouflage the actual goal of the scanning\ncampaign. In this paper, we present a correlation algorithm to detect scans,\nidentify potential relations among them, and reassemble them to larger\ncampaigns. We evaluate our approach on real-world Internet traffic and our\nresults indicate that it can summarize and characterize standalone and\ndistributed scan campaigns based on their tools and intention.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 09:42:39 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Haas", "Steffen", ""], ["Wilkens", "Florian", ""], ["Fischer", "Mathias", ""]]}, {"id": "2003.05198", "submitter": "Chaochao Chen", "authors": "Longfei Zheng, Chaochao Chen, Yingting Liu, Bingzhe Wu, Xibin Wu, Li\n  Wang, Lei Wang, Jun Zhou, Shuang Yang", "title": "Industrial Scale Privacy Preserving Deep Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Network (DNN) has been showing great potential in kinds of\nreal-world applications such as fraud detection and distress prediction.\nMeanwhile, data isolation has become a serious problem currently, i.e.,\ndifferent parties cannot share data with each other. To solve this issue, most\nresearch leverages cryptographic techniques to train secure DNN models for\nmulti-parties without compromising their private data. Although such methods\nhave strong security guarantee, they are difficult to scale to deep networks\nand large datasets due to its high communication and computation complexities.\nTo solve the scalability of the existing secure Deep Neural Network (DNN) in\ndata isolation scenarios, in this paper, we propose an industrial scale privacy\npreserving neural network learning paradigm, which is secure against\nsemi-honest adversaries. Our main idea is to split the computation graph of DNN\ninto two parts, i.e., the computations related to private data are performed by\neach party using cryptographic techniques, and the rest computations are done\nby a neutral server with high computation ability. We also present a defender\nmechanism for further privacy protection. We conduct experiments on real-world\nfraud detection dataset and financial distress prediction dataset, the\nencouraging results demonstrate the practicalness of our proposal.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 10:15:37 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 05:42:35 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Zheng", "Longfei", ""], ["Chen", "Chaochao", ""], ["Liu", "Yingting", ""], ["Wu", "Bingzhe", ""], ["Wu", "Xibin", ""], ["Wang", "Li", ""], ["Wang", "Lei", ""], ["Zhou", "Jun", ""], ["Yang", "Shuang", ""]]}, {"id": "2003.05207", "submitter": "Jelle Don", "authors": "Jelle Don, Serge Fehr and Christian Majenz", "title": "The Measure-and-Reprogram Technique 2.0: Multi-Round Fiat-Shamir and\n  More", "comments": "22 pages", "journal-ref": "In: Micciancio D., Ristenpart T. (eds) Advances in Cryptology --\n  CRYPTO 2020. CRYPTO 2020. Lecture Notes in Computer Science, vol 12172.\n  Springer, Cham", "doi": "10.1007/978-3-030-56877-1_21", "report-no": null, "categories": "cs.CR quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit recent works by Don, Fehr, Majenz and Schaffner and by Liu and\nZhandry on the security of the Fiat-Shamir transformation of $\\Sigma$-protocols\nin the quantum random oracle model (QROM). Two natural questions that arise in\nthis context are: (1) whether the results extend to the Fiat-Shamir\ntransformation of multi-round interactive proofs, and (2) whether Don et al.'s\n$O(q^2)$ loss in security is optimal.\n  Firstly, we answer question (1) in the affirmative. As a byproduct of solving\na technical difficulty in proving this result, we slightly improve the result\nof Don et al., equipping it with a cleaner bound and an even simpler proof. We\napply our result to digital signature schemes showing that it can be used to\nprove strong security for schemes like MQDSS in the QROM. As another\napplication we prove QROM-security of a non-interactive OR proof by Liu, Wei\nand Wong.\n  As for question (2), we show via a Grover-search based attack that Don et\nal.'s quadratic security loss for the Fiat-Shamir transformation of\n$\\Sigma$-protocols is optimal up to a small constant factor. This extends to\nour new multi-round result, proving it tight up to a factor that depends on the\nnumber of rounds only, i.e. is constant for any constant-round interactive\nproof.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 10:33:57 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 09:49:27 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Don", "Jelle", ""], ["Fehr", "Serge", ""], ["Majenz", "Christian", ""]]}, {"id": "2003.05273", "submitter": "Marios Fanourakis", "authors": "Marios Fanourakis", "title": "Opportunistic multi-party shuffling for data reporting privacy", "comments": "14 pages, 18 figures, parts of this paper were used in the PhD thesis\n  of the same author available at https://archive-ouverte.unige.ch/unige:112869", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important feature of data collection frameworks, in which voluntary\nparticipants are involved, is that of privacy. Besides data encryption, which\nprotects the data from third parties in case the communication channel is\ncompromised, there are schemes to obfuscate the data and thus provide some\nanonymity in the data itself, as well as schemes that 'mix' the data to prevent\ntracing the data back to the source by using network identifiers. This mixing\nis usually implemented by utilizing special mix networks in the data collection\nframework. In this paper we focus on schemes for mixing the data where the\nparticipants do not need to trust the mix network or the data collector with\nhiding the source of the data so that we can evaluate the efficacy of peer to\npeer mixing strategies in the real world. To achieve this, we present a simple\nopportunistic multi-party shuffling scheme to mix the data and effectively\nobfuscate the source of the data. We successfully simulate 3 cases with\nartificial parameters and then use the real-world Mobile Data Challenge (MDC)\ndata to simulate an additional 2 scenarios with realistic parameters. Our\nresults show that such approaches can be effective depending on the time\nconstraints of the data collection and we conclude with design implications for\nthe implementation of the proposed data collection scheme in real life\ndeployments.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 13:20:16 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Fanourakis", "Marios", ""]]}, {"id": "2003.05328", "submitter": "Song Bian", "authors": "Song Bian, Tianchen Wang, Masayuki Hiromoto, Yiyu Shi, Takashi Sato", "title": "ENSEI: Efficient Secure Inference via Frequency-Domain Homomorphic\n  Convolution for Privacy-Preserving Visual Recognition", "comments": "10 pages, 3 figures, in Proceedings of Conference on Computer Vision\n  and Pattern Recognition (CVPR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose ENSEI, a secure inference (SI) framework based on\nthe frequency-domain secure convolution (FDSC) protocol for the efficient\nexecution of privacy-preserving visual recognition. Our observation is that,\nunder the combination of homomorphic encryption and secret sharing, homomorphic\nconvolution can be obliviously carried out in the frequency domain,\nsignificantly simplifying the related computations. We provide protocol designs\nand parameter derivations for number-theoretic transform (NTT) based FDSC. In\nthe experiment, we thoroughly study the accuracy-efficiency trade-offs between\ntime- and frequency-domain homomorphic convolution. With ENSEI, compared to the\nbest known works, we achieve 5--11x online time reduction, up to 33x setup time\nreduction, and up to 10x reduction in the overall inference time. A further 33%\nof bandwidth reductions can be obtained on binary neural networks with only 1%\nof accuracy degradation on the CIFAR-10 dataset.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 14:35:48 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Bian", "Song", ""], ["Wang", "Tianchen", ""], ["Hiromoto", "Masayuki", ""], ["Shi", "Yiyu", ""], ["Sato", "Takashi", ""]]}, {"id": "2003.05503", "submitter": "Anil Kurmus", "authors": "Andrea Mambretti, Alexandra Sandulescu, Alessandro Sorniotti, William\n  Robertson, Engin Kirda, Anil Kurmus", "title": "Bypassing memory safety mechanisms through speculative control flow\n  hijacks", "comments": "To appear at IEEE EuroS&P 2021\n  (https://www.ieee-security.org/TC/EuroSP2021/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prevalence of memory corruption bugs in the past decades resulted in\nnumerous defenses, such as stack canaries, control flow integrity (CFI), and\nmemory safe languages. These defenses can prevent entire classes of\nvulnerabilities, and help increase the security posture of a program. In this\npaper, we show that memory corruption defenses can be bypassed using\nspeculative execution attacks. We study the cases of stack protectors, CFI, and\nbounds checks in Go, demonstrating under which conditions they can be bypassed\nby a form of speculative control flow hijack, relying on speculative or\narchitectural overwrites of control flow data. Information is leaked by\nredirecting the speculative control flow of the victim to a gadget accessing\nsecret data and acting as a side channel send. We also demonstrate, for the\nfirst time, that this can be achieved by stitching together multiple gadgets,\nin a speculative return-oriented programming attack. We discuss and implement\nsoftware mitigations, showing moderate performance impact.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 19:53:45 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 16:55:57 GMT"}, {"version": "v3", "created": "Mon, 19 Apr 2021 12:39:21 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Mambretti", "Andrea", ""], ["Sandulescu", "Alexandra", ""], ["Sorniotti", "Alessandro", ""], ["Robertson", "William", ""], ["Kirda", "Engin", ""], ["Kurmus", "Anil", ""]]}, {"id": "2003.05564", "submitter": "Chundong Wang", "authors": "Chundong Wang, Yee Ching Tok, Rohini Poolat, Sudipta Chattopadhyay,\n  Mohan Rajesh Elara", "title": "Securing Autonomous Service Robots through Fuzzing, Detection, and\n  Mitigation", "comments": "14 pages", "journal-ref": "Journal of Systems Architecture, 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous service robots share social spaces with humans, usually working\ntogether for domestic or professional tasks. Cyber security breaches in such\nrobots undermine the trust between humans and robots. In this paper, we\ninvestigate how to apprehend and inflict security threats at the design and\nimplementation stage of a movable autonomous service robot. To this end, we\nleverage the idea of directed fuzzing and design RoboFuzz that systematically\ntests an autonomous service robot in line with the robot's states and the\nsurrounding environment. The methodology of RoboFuzz is to study critical\nenvironmental parameters affecting the robot's state transitions and subject\nthe robot control program with rational but harmful sensor values so as to\ncompromise the robot. Furthermore, we develop detection and mitigation\nalgorithms to counteract the impact of RoboFuzz. The difficulties mainly lie in\nthe trade-off among limited computation resources, timely detection and the\nretention of work efficiency in mitigation. In particular, we propose detection\nand mitigation methods that take advantage of historical records of obstacles\nto detect inconsistent obstacle appearances regarding untrustworthy sensor\nvalues and navigate the movable robot to continue moving so as to carry on a\nplanned task. By doing so, we manage to maintain a low cost for detection and\nmitigation but also retain the robot's work efficacy. We have prototyped the\nbundle of RoboFuzz, detection and mitigation algorithms in a real-world movable\nrobot. Experimental results confirm that RoboFuzz makes a success rate of up to\n93.3% in imposing concrete threats to the robot while the overall loss of work\nefficacy is merely 4.1% at the mitigation mode.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 01:30:19 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Wang", "Chundong", ""], ["Tok", "Yee Ching", ""], ["Poolat", "Rohini", ""], ["Chattopadhyay", "Sudipta", ""], ["Elara", "Mohan Rajesh", ""]]}, {"id": "2003.05631", "submitter": "Jiangnan Li", "authors": "Jiangnan Li, Yingyuan Yang, Jinyuan Stella Sun, Kevin Tomsovic,\n  Hairong Qi", "title": "ConAML: Constrained Adversarial Machine Learning for Cyber-Physical\n  Systems", "comments": "This paper has been accepted by the 16th ACM ASIA Conference on\n  Computer and Communications Security (ACM ASIACCS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research demonstrated that the superficially well-trained machine\nlearning (ML) models are highly vulnerable to adversarial examples. As ML\ntechniques are becoming a popular solution for cyber-physical systems (CPSs)\napplications in research literatures, the security of these applications is of\nconcern. However, current studies on adversarial machine learning (AML) mainly\nfocus on pure cyberspace domains. The risks the adversarial examples can bring\nto the CPS applications have not been well investigated. In particular, due to\nthe distributed property of data sources and the inherent physical constraints\nimposed by CPSs, the widely-used threat models and the state-of-the-art AML\nalgorithms in previous cyberspace research become infeasible.\n  We study the potential vulnerabilities of ML applied in CPSs by proposing\nConstrained Adversarial Machine Learning (ConAML), which generates adversarial\nexamples that satisfy the intrinsic constraints of the physical systems. We\nfirst summarize the difference between AML in CPSs and AML in existing\ncyberspace systems and propose a general threat model for ConAML. We then\ndesign a best-effort search algorithm to iteratively generate adversarial\nexamples with linear physical constraints. We evaluate our algorithms with\nsimulations of two typical CPSs, the power grids and the water treatment\nsystem. The results show that our ConAML algorithms can effectively generate\nadversarial examples which significantly decrease the performance of the ML\nmodels even under practical constraints.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 05:59:56 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 21:13:22 GMT"}, {"version": "v3", "created": "Tue, 24 Nov 2020 21:23:09 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Li", "Jiangnan", ""], ["Yang", "Yingyuan", ""], ["Sun", "Jinyuan Stella", ""], ["Tomsovic", "Kevin", ""], ["Qi", "Hairong", ""]]}, {"id": "2003.05687", "submitter": "Mayank Raikwar", "authors": "Mayank Raikwar, Danilo Gligoroski, Goran Velinov", "title": "Trends in Development of Databases and Blockchain", "comments": "Accepted in The Second International Workshop on Blockchain\n  Applications and Theory (BAT 2020)", "journal-ref": "2020 Seventh International Conference on Software Defined Systems\n  (SDS)", "doi": "10.1109/SDS49854.2020.9143893", "report-no": null, "categories": "cs.DC cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is about the mutual influence between two technologies: Databases\nand Blockchain. It addresses two questions: 1. How the database technology has\ninfluenced the development of blockchain technology?, and 2. How blockchain\ntechnology has influenced the introduction of new functionalities in some\nmodern databases? For the first question, we explain how database technology\ncontributes to blockchain technology by unlocking different features such as\nACID (Atomicity, Consistency, Isolation, and Durability) transactional\nconsistency, rich queries, real-time analytics, and low latency. We explain how\nthe CAP (Consistency, Availability, Partition tolerance) theorem known for\ndatabases influenced the DCS (Decentralization, Consistency, Scalability)\ntheorem for the blockchain systems. By using an analogous relaxation approach\nas it was used for the proof of the CAP theorem, we postulate a\n\"DCS-satisfiability conjecture.\" For the second question, we review different\ndatabases that are designed specifically for blockchain and provide most of the\nblockchain functionality like immutability, privacy, censorship resistance,\nalong with database features.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 10:04:41 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Raikwar", "Mayank", ""], ["Gligoroski", "Danilo", ""], ["Velinov", "Goran", ""]]}, {"id": "2003.05703", "submitter": "Jonathan Peck", "authors": "Raaghavi Sivaguru, Jonathan Peck, Femi Olumofin, Anderson Nascimento\n  and Martine De Cock", "title": "Inline Detection of DGA Domains Using Side Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware applications typically use a command and control (C&C) server to\nmanage bots to perform malicious activities. Domain Generation Algorithms\n(DGAs) are popular methods for generating pseudo-random domain names that can\nbe used to establish a communication between an infected bot and the C&C\nserver. In recent years, machine learning based systems have been widely used\nto detect DGAs. There are several well known state-of-the-art classifiers in\nthe literature that can detect DGA domain names in real-time applications with\nhigh predictive performance. However, these DGA classifiers are highly\nvulnerable to adversarial attacks in which adversaries purposely craft domain\nnames to evade DGA detection classifiers. In our work, we focus on hardening\nDGA classifiers against adversarial attacks. To this end, we train and evaluate\nstate-of-the-art deep learning and random forest (RF) classifiers for DGA\ndetection using side information that is harder for adversaries to manipulate\nthan the domain name itself. Additionally, the side information features are\nselected such that they are easily obtainable in practice to perform inline DGA\ndetection. The performance and robustness of these models is assessed by\nexposing them to one day of real-traffic data as well as domains generated by\nadversarial attack algorithms. We found that the DGA classifiers that rely on\nboth the domain name and side information have high performance and are more\nrobust against adversaries.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 11:00:30 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Sivaguru", "Raaghavi", ""], ["Peck", "Jonathan", ""], ["Olumofin", "Femi", ""], ["Nascimento", "Anderson", ""], ["De Cock", "Martine", ""]]}, {"id": "2003.05748", "submitter": "Sean Saito", "authors": "Sean Saito, Jin Wang", "title": "Explaining Away Attacks Against Neural Networks", "comments": "2 pages, 2 figures; Accepted at MLSys 2020 First Workshop on Secure\n  and Resilient Autonomy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of identifying adversarial attacks on image-based\nneural networks. We present intriguing experimental results showing significant\ndiscrepancies between the explanations generated for the predictions of a model\non clean and adversarial data. Utilizing this intuition, we propose a framework\nwhich can identify whether a given input is adversarial based on the\nexplanations given by the model. Code for our experiments can be found here:\nhttps://github.com/seansaito/Explaining-Away-Attacks-Against-Neural-Networks.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 15:32:30 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Saito", "Sean", ""], ["Wang", "Jin", ""]]}, {"id": "2003.05813", "submitter": "Tianxiang Dai", "authors": "Tianxiang Dai and Haya Shulman", "title": "SMap: Internet-wide Scanning for Ingress Filtering", "comments": "This project needs lots of re-work and is requested to be withdrawn\n  by author's organisation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To protect from attacks, networks need to enforce ingress filtering. Despite\nthe importance, the existing studies do not allow to infer the extent of\ningress filtering at Internet-scale, providing results with only a limited\ncoverage: they can either measure networks that operate servers with faulty\nnetwork-stack implementations, or require installation of the measurement\nsoftware by volunteers, or assume specific properties, like traceroute loops,\nwhich are challenging to reproduce in practice. Improving coverage of the\nspoofing measurements is critical.\n  In this work we present the Spoofing Mapper (SMap): the first scanner for\nperforming Internet-wide studies of enforcement of ingress filtering. The SMap\nmeasurement methodology utilises standard protocols' behaviour that are present\nin almost any network. SMap not only provides better coverage of\ningress-filtering measurements, but it is also more effective than the previous\napproaches. We applied SMap for Internet-wide measurements: we found that 21%\nof all the Autonomous Systems (ASes) in the Internet do not filter spoofed\npackets, in contrast to 2.5% ASes identified by the most recent study with\nvolunteers (of the Spoofer Project), as well as 13173 new spoofable ASes, which\nwere not detected by the other tools. Our study with SMap provides the most\ncomprehensive view of ingress filtering deployment in the Internet and\nremediation in filtering spoofed packets over a period of six months until\nFebruary 2020. SMap is simple to use and does not require installation on the\ntested network nor coordination with the tested networks.\n  We set up a web service at http://to_be_revealed/ which reports statistics\nfrom SMap evaluations and enables continual Internet-wide data collection and\nanalysis. We also make our datasets as well as the SMap tool publicly available\nto enable researchers to reproduce and validate the results.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 14:16:22 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 08:12:41 GMT"}, {"version": "v3", "created": "Tue, 26 May 2020 12:34:35 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Dai", "Tianxiang", ""], ["Shulman", "Haya", ""]]}, {"id": "2003.05836", "submitter": "Letterio Galletta", "authors": "Matteo Busi and Pierpaolo Degano and Letterio Galletta", "title": "Control-flow Flattening Preserves the Constant-Time Policy (Extended\n  Version)", "comments": "Extended version of ITASEC20 camera ready paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obfuscating compilers protect a software by obscuring its meaning and\nimpeding the reconstruction of its original source code. The typical concern\nwhen defining such compilers is their robustness against reverse engineering\nand the performance of the produced code. Little work has been done in studying\nwhether the security properties of a program are preserved under obfuscation.\nIn this paper we start addressing this problem: we consider control-flow\nflattening, a popular obfuscation technique used in industrial compilers, and a\nspecific security policy, namely constant-time. We prove that this obfuscation\npreserves the policy, i.e., that every program satisfying the policy still does\nafter the transformation.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 15:08:31 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Busi", "Matteo", ""], ["Degano", "Pierpaolo", ""], ["Galletta", "Letterio", ""]]}, {"id": "2003.05846", "submitter": "Saul Johnson", "authors": "Saul Johnson, Jo\\~ao Ferreira, Alexandra Mendes, Julien Cordry", "title": "Lost in Disclosure: On The Inference of Password Composition Policies", "comments": "6 pages, 8 figures, 7 tables", "journal-ref": "2019 IEEE International Symposium on Software Reliability\n  Engineering Workshops (ISSREW), 2019, pp. 264-269", "doi": "10.1109/ISSREW.2019.00082", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale password data breaches are becoming increasingly commonplace,\nwhich has enabled researchers to produce a substantial body of password\nsecurity research utilising real-world password datasets, which often contain\nnumbers of records in the tens or even hundreds of millions. While much study\nhas been conducted on how password composition policies (sets of rules that a\nuser must abide by when creating a password) influence the distribution of\nuser-chosen passwords on a system, much less research has been done on\ninferring the password composition policy that a given set of user-chosen\npasswords was created under. In this paper, we state the problem with the naive\napproach to this challenge, and suggest a simple approach that produces more\nreliable results. We also present pol-infer, a tool that implements this\napproach, and demonstrates its use in inferring password composition policies.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 15:27:00 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Johnson", "Saul", ""], ["Ferreira", "Jo\u00e3o", ""], ["Mendes", "Alexandra", ""], ["Cordry", "Julien", ""]]}, {"id": "2003.05915", "submitter": "Guy Dodin", "authors": "Guy Dodin", "title": "Protection of genomic information: a classical and a quantum approach", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Splitting a literal genomic sequence into 4 binary files is enough to ensure\nconfidentiality and integrity during storage and transfer of information. The\nbinary files are resources for RSA or one-time-pad (OTP) cryptography\nprotocols. It is speculated that representing nucleic bases as Bell states in a\nquantum view of a sequence would provide tools for genomic data protection when\nimplemented in an authentic quantum computer, soon to come as a practical and\nreadily available device.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 17:28:02 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Dodin", "Guy", ""]]}, {"id": "2003.05987", "submitter": "Christof Ferreira Torres", "authors": "Christof Ferreira Torres, Mathis Baden, Robert Norvill, Beltran Borja\n  Fiz Pontiveros, Hugo Jonker, Sjouke Mauw", "title": "{\\AE}GIS: Shielding Vulnerable Smart Contracts Against Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, smart contracts have suffered major exploits, costing\nmillions of dollars. Unlike traditional programs, smart contracts are deployed\non a blockchain. As such, they cannot be modified once deployed. Though various\ntools have been proposed to detect vulnerable smart contracts, the majority\nfails to protect vulnerable contracts that have already been deployed on the\nblockchain. Only very few solutions have been proposed so far to tackle the\nissue of post-deployment. However, these solutions suffer from low precision\nand are not generic enough to prevent any type of attack.\n  In this work, we introduce {\\AE}GIS, a dynamic analysis tool that protects\nsmart contracts from being exploited during runtime. Its capability of\ndetecting new vulnerabilities can easily be extended through so-called attack\npatterns. These patterns are written in a domain-specific language that is\ntailored to the execution model of Ethereum smart contracts. The language\nenables the description of malicious control and data flows. In addition, we\npropose a novel mechanism to streamline and speed up the process of managing\nattack patterns. Patterns are voted upon and stored via a smart contract, thus\nleveraging the benefits of tamper-resistance and transparency provided by the\nblockchain. We compare {\\AE}GIS to current state-of-the-art tools and\ndemonstrate that our solution achieves higher precision in detecting attacks.\nFinally, we perform a large-scale analysis on the first 4.5 million blocks of\nthe Ethereum blockchain, thereby confirming the occurrences of well reported\nand yet unreported attacks in the wild.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 19:27:26 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Torres", "Christof Ferreira", ""], ["Baden", "Mathis", ""], ["Norvill", "Robert", ""], ["Pontiveros", "Beltran Borja Fiz", ""], ["Jonker", "Hugo", ""], ["Mauw", "Sjouke", ""]]}, {"id": "2003.06068", "submitter": "Lambert Leong", "authors": "Lambert T. Leong", "title": "Snapshot Samplings of the Bitcoin Transaction Network and Analysis of\n  Cryptocurrency Growth", "comments": "8 pages, 8 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this work was to perform a network analysis on the rapidly\ngrowing bitcoin transaction network. Using a web-socket API, we collected data\non all transactions occurring during a six hour window. Sender and receiver\naddresses as well as the amount of bitcoin exchanged were record. Graphs were\ngenerated, using R and Gephi, in which nodes represent addresses and edges\nrepresent the exchange of bitcoin. The six hour data set was subsetted into a\none and two hour sampling snapshot of the network. We performed comparisons and\nanalysis on all subsets of the data in an effort to determine the minimum\nsampling length that represented the network as a whole. Our results suggest\nthat the six hour sampling was the minimum limit with respect to sampling time\nneeded to accurately characterize the bitcoin transaction network.Anonymity is\na desired feature of the blockchain and bitcoin network however, it limited us\nin our analysis and conclusions we drew from our results were mostly inferred.\nFuture work is needed and being done to gather more comprehensive data so that\nthe bitcoin transaction network can be better analyzed.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 00:19:42 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Leong", "Lambert T.", ""]]}, {"id": "2003.06103", "submitter": "Viet Vo", "authors": "Viet Vo, Xingliang Yuan, Shi-Feng Sun, Joseph K. Liu, Surya Nepal and\n  Cong Wang", "title": "ShieldDB: An Encrypted Document Database with Padding Countermeasures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The security of our data stores is underestimated in current practice, which\nresulted in many large-scale data breaches. To change the status quo, this\npaper presents the design of ShieldDB, an encrypted document database. ShieldDB\nadapts the searchable encryption technique to preserve the search functionality\nover encrypted documents without having much impact on its scalability.\nHowever, merely realising such a theoretical primitive suffers from real-world\nthreats, where a knowledgeable adversary can exploit the leakage (aka access\npattern to the database) to break the claimed protection on data\nconfidentiality. To address this challenge in practical deployment, ShieldDB is\ndesigned with tailored padding countermeasures. Unlike prior works, we target a\nmore realistic adversarial model, where the database gets updated continuously,\nand the adversary can monitor it at an (or multiple) arbitrary time\ninterval(s). ShieldDB's padding strategies ensure that the access pattern to\nthe database is obfuscated all the time. Additionally, ShieldDB provides other\nadvanced features, including forward privacy, re-encryption, and flushing, to\nfurther improve its security and efficiency. We present a full-fledged\nimplementation of ShieldDB and conduct intensive evaluations on Azure Cloud.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 04:21:54 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Vo", "Viet", ""], ["Yuan", "Xingliang", ""], ["Sun", "Shi-Feng", ""], ["Liu", "Joseph K.", ""], ["Nepal", "Surya", ""], ["Wang", "Cong", ""]]}, {"id": "2003.06127", "submitter": "Bowen Liu", "authors": "Bowen Liu (1), Pawel Szalachowski (1), Siwei Sun (2 and 3) ((1)\n  Singapore University of Technology and Design, Singapore, (2) State Key\n  Laboratory of Information Security, Institute of Information Engineering,\n  Chinese Academy of Sciences, Beijing China, (3) School of Cyber Security,\n  University of Chinese Academy of Sciences, Beijing, China)", "title": "Fail-safe Watchtowers and Short-lived Assertions for Payment Channels", "comments": "ACM AsiaCCS'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent development of payment channels and their extensions (e.g., state\nchannels) provides a promising scalability solution for blockchains which\nallows untrusting parties to transact off-chain and resolve potential disputes\nvia on-chain smart contracts. To protect participants who have no constant\naccess to the blockchain, a watching service named as watchtower is proposed --\na third-party entity obligated to monitor channel states (on behalf of the\nparticipants) and correct them on-chain if necessary. Unfortunately, currently\nproposed watchtower schemes suffer from multiple security and efficiency\ndrawbacks. In this paper, we explore the design space behind watchtowers. We\npropose a novel watching service named as fail-safe watchtowers. In contrast to\nprior proposed watching services, our fail-safe watchtower does not watch\non-chain smart contracts constantly. Instead, it only sends a single on-chain\nmessage periodically confirming or denying the final states of channels being\nclosed. Our watchtowers can easily handle a large number of channels, are\nprivacy-preserving, and fail-safe tolerating multiple attack vectors.\nFurthermore, we show that watchtowers (in general) may be an option\neconomically unjustified for multiple payment scenarios and we introduce a\nsimple, yet powerful concept of short-lived assertions which can mitigate\nmisbehaving parties in these scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 06:15:59 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Liu", "Bowen", "", "2 and 3"], ["Szalachowski", "Pawel", "", "2 and 3"], ["Sun", "Siwei", "", "2 and 3"]]}, {"id": "2003.06159", "submitter": "Marios Fanourakis", "authors": "Marios Fanourakis", "title": "A report on personally identifiable sensor data from smartphone devices", "comments": "17 pages, 5 tables, parts of this paper were used in the PhD thesis\n  by the same author available at https://archive-ouverte.unige.ch/unige:112869", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An average smartphone is equipped with an abundance of sensors to provide a\nvariety of vital functionalities and conveniences. The data from these sensors\ncan be collected in order to find trends or discover interesting correlations\nin the data but can also be used by nefarious entities for the purpose of\nrevealing the identity of the persons who generated this data.In this paper, we\nseek to identify what types of sensor data can be collected on a smartphone and\nwhich of those types can pose a threat to user privacy by looking into the\nhardware capabilities of modern smartphone devices and how smartphone data is\nused in the literature. We then summarize some implications that this\ninformation could have on the GDPR.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 09:20:22 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Fanourakis", "Marios", ""]]}, {"id": "2003.06185", "submitter": "Martin Henze", "authors": "Dennis van der Velde, Martin Henze, Philipp Kathmann, Erik Wassermann,\n  Michael Andres, Detert Bracht, Raphael Ernst, George Hallak, Benedikt Klaer,\n  Philipp Linnartz, Benjamin Meyer, Simon Ofner, Tobias Pletzer, Richard\n  Sethmann", "title": "Methods for Actors in the Electric Power System to Prevent, Detect and\n  React to ICT Attacks and Failures", "comments": "6 pages, 4 figures, to be published in Proceedings of the 2020 6th\n  IEEE International Energy Conference (ENERGYCon)", "journal-ref": null, "doi": "10.1109/ENERGYCon48941.2020.9236523", "report-no": null, "categories": "cs.CR cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fundamental changes in power supply and increasing decentralization\nrequire more active grid operation and an increased integration of ICT at all\npower system actors. This trend raises complexity and increasingly leads to\ninteractions between primary grid operation and ICT as well as different power\nsystem actors. For example, virtual power plants control various assets in the\ndistribution grid via ICT to jointly market existing flexibilities. Failures of\nICT or targeted attacks can thus have serious effects on security of supply and\nsystem stability. This paper presents a holistic approach to providing methods\nspecifically for actors in the power system for prevention, detection, and\nreaction to ICT attacks and failures. The focus of our measures are solutions\nfor ICT monitoring, systems for the detection of ICT attacks and intrusions in\nthe process network, and the provision of actionable guidelines as well as a\npractice environment for the response to potential ICT security incidents.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 10:16:11 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["van der Velde", "Dennis", ""], ["Henze", "Martin", ""], ["Kathmann", "Philipp", ""], ["Wassermann", "Erik", ""], ["Andres", "Michael", ""], ["Bracht", "Detert", ""], ["Ernst", "Raphael", ""], ["Hallak", "George", ""], ["Klaer", "Benedikt", ""], ["Linnartz", "Philipp", ""], ["Meyer", "Benjamin", ""], ["Ofner", "Simon", ""], ["Pletzer", "Tobias", ""], ["Sethmann", "Richard", ""]]}, {"id": "2003.06197", "submitter": "Madhumitha Harishankar", "authors": "Madhumitha Harishankar, Dimitrios-Georgios Akestoridis, Sriram V.\n  Iyer, Aron Laszka, Carlee Joe-Wong, Patrick Tague", "title": "PayPlace: Secure and Flexible Operator-Mediated Payments in Blockchain\n  Marketplaces at Scale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized marketplace applications demand fast, cheap and easy-to-use\ncryptocurrency payment mechanisms to facilitate high transaction volumes. The\nstandard solution for off-chain payments, state channels, are optimized for\nfrequent transactions between two entities and impose prohibitive liquidity and\ncapital requirements on payment senders for marketplace transactions. We\npropose PayPlace, a scalable off-chain protocol for payments between consumers\nand sellers. Using PayPlace, consumers establish a virtual unidirectional\npayment channel with an intermediary operator to pay for their transactions.\nUnlike state channels, however, the PayPlace operator can reference the\ncustodial funds accrued off-chain in these channels to in-turn make\ntamper-proof off-chain payments to merchants, without locking up corresponding\ncapital in channels with merchants. Our design ensures that new payments made\nto merchants are guaranteed to be safe once notarized and provably mitigates\nwell-known drawbacks in previous constructions like the data availability\nattack and ensures that neither consumers nor merchants need to be online to\nensure continued safety of their notarized funds. We show that the on-chain\nmonetary and computational costs for PayPlace is O(1) in the number of payment\ntransactions processed, and is near-constant in other parameters in most\nscenarios. PayPlace can hence scale the payment throughput for large-scale\nmarketplaces at no marginal cost and is orders of magnitude cheaper than the\nstate-of-art solution for non-pairwise off-chain payments, Zero Knowledge\nRollups.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 10:53:57 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 18:34:16 GMT"}, {"version": "v3", "created": "Tue, 4 Aug 2020 12:11:38 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Harishankar", "Madhumitha", ""], ["Akestoridis", "Dimitrios-Georgios", ""], ["Iyer", "Sriram V.", ""], ["Laszka", "Aron", ""], ["Joe-Wong", "Carlee", ""], ["Tague", "Patrick", ""]]}, {"id": "2003.06344", "submitter": "Jiawei Zhou", "authors": "Jiawei Zhou, Zhiying Xu, Alexander M. Rush, Minlan Yu", "title": "Automating Botnet Detection with Graph Neural Networks", "comments": "Data and code available\n  https://github.com/harvardnlp/botnet-detection . Accepted as a workshop paper\n  in MLSys 2020 Conference", "journal-ref": "AutoML for Networking and Systems Workshop of MLSys 2020\n  Conference", "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Botnets are now a major source for many network attacks, such as DDoS attacks\nand spam. However, most traditional detection methods heavily rely on\nheuristically designed multi-stage detection criteria. In this paper, we\nconsider the neural network design challenges of using modern deep learning\ntechniques to learn policies for botnet detection automatically. To generate\ntraining data, we synthesize botnet connections with different underlying\ncommunication patterns overlaid on large-scale real networks as datasets. To\ncapture the important hierarchical structure of centralized botnets and the\nfast-mixing structure for decentralized botnets, we tailor graph neural\nnetworks (GNN) to detect the properties of these structures. Experimental\nresults show that GNNs are better able to capture botnet structure than\nprevious non-learning methods when trained with appropriate data, and that\ndeeper GNNs are crucial for learning difficult botnet topologies. We believe\nour data and studies can be useful for both the network security and graph\nlearning communities.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 15:34:33 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Zhou", "Jiawei", ""], ["Xu", "Zhiying", ""], ["Rush", "Alexander M.", ""], ["Yu", "Minlan", ""]]}, {"id": "2003.06428", "submitter": "Chih-Yuan Yang", "authors": "Chih-Yuan Yang and Ravi Sahita", "title": "Towards a Resilient Machine Learning Classifier -- a Case Study of\n  Ransomware Detection", "comments": "Conference on Applied Machine Learning for Information Security 2019,\n  Washington DC (CAMLIS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The damage caused by crypto-ransomware, due to encryption, is difficult to\nrevert and cause data losses. In this paper, a machine learning (ML) classifier\nwas built to early detect ransomware (called crypto-ransomware) that uses\ncryptography by program behavior. If a signature-based detection was missed, a\nbehavior-based detector can be the last line of defense to detect and contain\nthe damages. We find that input/output activities of ransomware and the\nfile-content entropy are unique traits to detect crypto-ransomware. A\ndeep-learning (DL) classifier can detect ransomware with a high accuracy and a\nlow false positive rate. We conduct an adversarial research against the models\ngenerated. We use simulated ransomware programs to launch a gray-box analysis\nto probe the weakness of ML classifiers and to improve model robustness. In\naddition to accuracy and resiliency, trustworthiness is the other key criteria\nfor a quality detector. Making sure that the correct information was used for\ninference is important for a security application. The Integrated Gradient\nmethod was used to explain the deep learning model and also to reveal why false\nnegatives evade the detection. The approaches to build and to evaluate a\nreal-world detector were demonstrated and discussed.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 18:02:19 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Yang", "Chih-Yuan", ""], ["Sahita", "Ravi", ""]]}, {"id": "2003.06468", "submitter": "Ali Rahmati", "authors": "Ali Rahmati, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard, and\n  Huaiyu Dai", "title": "GeoDA: a geometric framework for black-box adversarial attacks", "comments": "In Proceedings of IEEE Conference on Computer Vision and Pattern\n  Recognition (CVPR), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are known as carefully perturbed images fooling image\nclassifiers. We propose a geometric framework to generate adversarial examples\nin one of the most challenging black-box settings where the adversary can only\ngenerate a small number of queries, each of them returning the top-$1$ label of\nthe classifier. Our framework is based on the observation that the decision\nboundary of deep networks usually has a small mean curvature in the vicinity of\ndata samples. We propose an effective iterative algorithm to generate\nquery-efficient black-box perturbations with small $\\ell_p$ norms for $p \\ge\n1$, which is confirmed via experimental evaluations on state-of-the-art natural\nimage classifiers. Moreover, for $p=2$, we theoretically show that our\nalgorithm actually converges to the minimal $\\ell_2$-perturbation when the\ncurvature of the decision boundary is bounded. We also obtain the optimal\ndistribution of the queries over the iterations of the algorithm. Finally,\nexperimental results confirm that our principled black-box attack algorithm\nperforms better than state-of-the-art algorithms as it generates smaller\nperturbations with a reduced number of queries.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 20:03:01 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Rahmati", "Ali", ""], ["Moosavi-Dezfooli", "Seyed-Mohsen", ""], ["Frossard", "Pascal", ""], ["Dai", "Huaiyu", ""]]}, {"id": "2003.06552", "submitter": "Yuan Lu", "authors": "Yuan Lu, Qiang Tang, Guiling Wang", "title": "Generic Superlight Client for Permissionless Blockchains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conduct a systematic study on the light client of permissionless\nblockchains, in the setting where the full nodes and the light clients are\nrational. Under such a game-theoretic model, we design a superlight-client\nprotocol to enable a client to employ some relaying full nodes (e.g. two or\none) to read the blockchain. The protocol is \"generic\", i.e., it can be\ndeployed disregarding the underlying consensuses, and also \"superlight\", i.e.,\nthe computational cost of the light client to predicate the (non)existence of a\ntransaction in the blockchain becomes a small constant. Since our protocol\nresolves a fundamental challenge of broadening the usage of blockchain\ntechnology, it captures a wide variety of important use-cases such as\nmulti-chain wallets, DApp browsers and more.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 04:45:20 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 13:41:55 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Lu", "Yuan", ""], ["Tang", "Qiang", ""], ["Wang", "Guiling", ""]]}, {"id": "2003.06559", "submitter": "Chawin Sitawarin", "authors": "Chawin Sitawarin, David Wagner", "title": "Minimum-Norm Adversarial Examples on KNN and KNN-Based Models", "comments": "3rd Deep Learning and Security Workshop (co-located with the 41st\n  IEEE Symposium on Security and Privacy)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the robustness against adversarial examples of kNN classifiers and\nclassifiers that combine kNN with neural networks. The main difficulty lies in\nthe fact that finding an optimal attack on kNN is intractable for typical\ndatasets. In this work, we propose a gradient-based attack on kNN and kNN-based\ndefenses, inspired by the previous work by Sitawarin & Wagner [1]. We\ndemonstrate that our attack outperforms their method on all of the models we\ntested with only a minimal increase in the computation time. The attack also\nbeats the state-of-the-art attack [2] on kNN when k > 1 using less than 1% of\nits running time. We hope that this attack can be used as a new baseline for\nevaluating the robustness of kNN and its variants.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 05:36:33 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Sitawarin", "Chawin", ""], ["Wagner", "David", ""]]}, {"id": "2003.06568", "submitter": "Ningyu He", "authors": "Ningyu He, Ruiyi Zhang, Lei Wu, Haoyu Wang, Xiapu Luo, Yao Guo, Ting\n  Yu, Xuxian Jiang", "title": "Security Analysis of EOSIO Smart Contracts", "comments": "17 pages, 4 figures; typos corrected, section II and III revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The EOSIO blockchain, one of the representative Delegated Proof-of-Stake\n(DPoS) blockchain platforms, has grown rapidly recently. Meanwhile, a number of\nvulnerabilities and high-profile attacks against top EOSIO DApps and their\nsmart contracts have also been discovered and observed in the wild, resulting\nin serious financial damages. Most of EOSIO's smart contracts are not\nopen-sourced and they are typically compiled to WebAssembly (Wasm) bytecode,\nthus making it challenging to analyze and detect the presence of possible\nvulnerabilities. In this paper, we propose EOSAFE, the first static analysis\nframework that can be used to automatically detect vulnerabilities in EOSIO\nsmart contracts at the bytecode level. Our framework includes a practical\nsymbolic execution engine for Wasm, a customized library emulator for EOSIO\nsmart contracts, and four heuristics-driven detectors to identify the presence\nof four most popular vulnerabilities in EOSIO smart contracts. Experiment\nresults suggest that EOSAFE achieves promising results in detecting\nvulnerabilities, with an F1-measure of 98%. We have applied EOSAFE to all\nactive 53,666 smart contracts in the ecosystem (as of November 15, 2019). Our\nresults show that over 25% of the smart contracts are vulnerable. We further\nanalyze possible exploitation attempts against these vulnerable smart contracts\nand identify 48 in-the-wild attacks (25 of them have been confirmed by DApp\ndevelopers), resulting in financial loss of at least 1.7 million USD.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 06:57:01 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 09:08:54 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["He", "Ningyu", ""], ["Zhang", "Ruiyi", ""], ["Wu", "Lei", ""], ["Wang", "Haoyu", ""], ["Luo", "Xiapu", ""], ["Guo", "Yao", ""], ["Yu", "Ting", ""], ["Jiang", "Xuxian", ""]]}, {"id": "2003.06612", "submitter": "Eugene Bagdasaryan", "authors": "Kleomenis Katevas, Eugene Bagdasaryan, Jason Waterman, Mohamad Mounir\n  Safadieh, Eleanor Birrell, Hamed Haddadi, Deborah Estrin", "title": "Policy-Based Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present PoliFL, a decentralized, edge-based framework that\nsupports heterogeneous privacy policies for federated learning. We evaluate our\nsystem on three use cases that train models with sensitive user data collected\nby mobile phones - predictive text, image classification, and notification\nengagement prediction - on a Raspberry Pi edge device. We find that PoliFL is\nable to perform accurate model training and inference within reasonable\nresource and time budgets while also enforcing heterogeneous privacy policies.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 12:04:36 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 23:01:17 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 02:31:06 GMT"}, {"version": "v4", "created": "Wed, 17 Feb 2021 14:36:48 GMT"}, {"version": "v5", "created": "Fri, 19 Feb 2021 02:09:31 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Katevas", "Kleomenis", ""], ["Bagdasaryan", "Eugene", ""], ["Waterman", "Jason", ""], ["Safadieh", "Mohamad Mounir", ""], ["Birrell", "Eleanor", ""], ["Haddadi", "Hamed", ""], ["Estrin", "Deborah", ""]]}, {"id": "2003.06616", "submitter": "Sakshi Patel", "authors": "Sakshi Patel, Bharath K P and Rajesh Kumar Muthu", "title": "Image Encryption Decryption Using Chaotic Logistic Mapping and DNA\n  Encoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper we have proposed a method that uses chaotic logistic mapping\nand DNA encoding to encrypt the image. A 32 bit ASCII private key is used to\ndiffuse the image. The results demonstrated clearly show that encryption\nalgorithm based on chaotic logistic mapping and DNA encoding gives better\nresult than encrypting only with chaotic logistic mapping. The proposed method\nalso takes into account the possible parametric like Peak Signal to Noise Ratio\nand Structure Similarity.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 12:16:55 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Patel", "Sakshi", ""], ["P", "Bharath K", ""], ["Muthu", "Rajesh Kumar", ""]]}, {"id": "2003.06646", "submitter": "Subhajit Chaudhury", "authors": "Subhajit Chaudhury, Toshihiko Yamasaki", "title": "Investigating Generalization in Neural Networks under Optimally Evolved\n  Training Perturbations", "comments": "Accepted at IEEE ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the generalization properties of neural networks\nunder input perturbations and show that minimal training data corruption by a\nfew pixel modifications can cause drastic overfitting. We propose an\nevolutionary algorithm to search for optimal pixel perturbations using novel\ncost function inspired from literature in domain adaptation that explicitly\nmaximizes the generalization gap and domain divergence between clean and\ncorrupted images. Our method outperforms previous pixel-based data distribution\nshift methods on state-of-the-art Convolutional Neural Networks (CNNs)\narchitectures. Interestingly, we find that the choice of optimization plays an\nimportant role in generalization robustness due to the empirical observation\nthat SGD is resilient to such training data corruption unlike adaptive\noptimization techniques (ADAM). Our source code is available at\nhttps://github.com/subhajitchaudhury/evo-shift.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 14:38:07 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Chaudhury", "Subhajit", ""], ["Yamasaki", "Toshihiko", ""]]}, {"id": "2003.06693", "submitter": "Ping-Yeh Chiang", "authors": "Ping-Yeh Chiang, Renkun Ni, Ahmed Abdelkader, Chen Zhu, Christoph\n  Studer, Tom Goldstein", "title": "Certified Defenses for Adversarial Patches", "comments": "International Conference on Learning Representations, ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial patch attacks are among one of the most practical threat models\nagainst real-world computer vision systems. This paper studies certified and\nempirical defenses against patch attacks. We begin with a set of experiments\nshowing that most existing defenses, which work by pre-processing input images\nto mitigate adversarial patches, are easily broken by simple white-box\nadversaries. Motivated by this finding, we propose the first certified defense\nagainst patch attacks, and propose faster methods for its training.\nFurthermore, we experiment with different patch shapes for testing, obtaining\nsurprisingly good robustness transfer across shapes, and present preliminary\nresults on certified defense against sparse attacks. Our complete\nimplementation can be found on:\nhttps://github.com/Ping-C/certifiedpatchdefense.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 19:57:31 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 15:51:40 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Chiang", "Ping-Yeh", ""], ["Ni", "Renkun", ""], ["Abdelkader", "Ahmed", ""], ["Zhu", "Chen", ""], ["Studer", "Christoph", ""], ["Goldstein", "Tom", ""]]}, {"id": "2003.06814", "submitter": "ShawnXY Yang", "authors": "Xiao Yang, Yinpeng Dong, Tianyu Pang, Jun Zhu, Hang Su", "title": "Towards Privacy Protection by Generating Adversarial Identity Masks", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As billions of personal data such as photos are shared through social media\nand network, the privacy and security of data have drawn an increasing\nattention. Several attempts have been made to alleviate the leakage of identity\ninformation with the aid of image obfuscation techniques. However, most of the\npresent results are either perceptually unsatisfactory or ineffective against\nreal-world recognition systems. In this paper, we argue that an algorithm for\nprivacy protection must block the ability of automatic inference of the\nidentity and at the same time, make the resultant image natural from the users'\npoint of view. To achieve this, we propose a targeted identity-protection\niterative method (TIP-IM), which can generate natural face images by adding\nadversarial identity masks to conceal ones' identity against a recognition\nsystem. Extensive experiments on various state-of-the-art face recognition\nmodels demonstrate the effectiveness of our proposed method on alleviating the\nidentity leakage of face images, without sacrificing? the visual quality of the\nprotected images.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 12:45:10 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Yang", "Xiao", ""], ["Dong", "Yinpeng", ""], ["Pang", "Tianyu", ""], ["Zhu", "Jun", ""], ["Su", "Hang", ""]]}, {"id": "2003.06826", "submitter": "Peng Cheng", "authors": "Wangze Ni, Han Wu, Peng Cheng, Lei Chen, Xuemin Lin, Lei Chen, Xin\n  Lai, Xiao Zhang", "title": "CoinMagic: A Differential Privacy Framework for Ring Signature Schemes", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By allowing users to obscure their transactions via including \"mixins\" (chaff\ncoins), ring signature schemes have been widely used to protect a sender's\nidentity of a transaction in privacy-preserving blockchain systems, like Monero\nand Bytecoin. However, recent works point out that the existing ring signature\nscheme is vulnerable to the \"chain-reaction\" analysis (i.e., the spent coin in\na given ring signature can be deduced through elimination). Especially, when\nthe diversity of mixins is low, the spent coin will have a high risk to be\ndetected. To overcome the weakness, the ring signature should be consisted of a\nset of mixins with high diversity and produce observations having \"similar\"\ndistributions for any two coins. In this paper, we propose a notion, namely\n$\\epsilon$-coin-indistinguishability ($\\epsilon$-CI), to formally define the\n\"similar\" distribution guaranteed through a differential privacy scheme. Then,\nwe formally define the CI-aware mixins selection problem with disjoint-superset\nconstraint (CIA-MS-DS), which aims to find a mixin set that has maximal\ndiversity and satisfies the constraints of $\\epsilon$-CI and the budget. In\nCIA-MS-DS, each ring signature is either disjoint with or the superset of its\npreceding ring signatures. We prove that CIA-MS-DS is NP-hard and thus\nintractable. To solve the CIA-MS-DS problem, we propose two approximation\nalgorithms, namely the Progressive Algorithm and the Game Theoretic Algorithm,\nwith theoretic guarantees. Through extensive experiments on both real data sets\nand synthetic data sets, we demonstrate the efficiency and the effectiveness of\nour approaches.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 13:23:57 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Ni", "Wangze", ""], ["Wu", "Han", ""], ["Cheng", "Peng", ""], ["Chen", "Lei", ""], ["Lin", "Xuemin", ""], ["Chen", "Lei", ""], ["Lai", "Xin", ""], ["Zhang", "Xiao", ""]]}, {"id": "2003.06974", "submitter": "Yiming Li", "authors": "Yiming Li, Baoyuan Wu, Yan Feng, Yanbo Fan, Yong Jiang, Zhifeng Li,\n  Shutao Xia", "title": "Toward Adversarial Robustness via Semi-supervised Robust Training", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples have been shown to be the severe threat to deep neural\nnetworks (DNNs). One of the most effective adversarial defense methods is\nadversarial training (AT) through minimizing the adversarial risk $R_{adv}$,\nwhich encourages both the benign example $x$ and its adversarially perturbed\nneighborhoods within the $\\ell_{p}$-ball to be predicted as the ground-truth\nlabel. In this work, we propose a novel defense method, the robust training\n(RT), by jointly minimizing two separated risks ($R_{stand}$ and $R_{rob}$),\nwhich is with respect to the benign example and its neighborhoods respectively.\nThe motivation is to explicitly and jointly enhance the accuracy and the\nadversarial robustness. We prove that $R_{adv}$ is upper-bounded by $R_{stand}\n+ R_{rob}$, which implies that RT has similar effect as AT. Intuitively,\nminimizing the standard risk enforces the benign example to be correctly\npredicted, and the robust risk minimization encourages the predictions of the\nneighbor examples to be consistent with the prediction of the benign example.\nBesides, since $R_{rob}$ is independent of the ground-truth label, RT is\nnaturally extended to the semi-supervised mode ($i.e.$, SRT), to further\nenhance the adversarial robustness. Moreover, we extend the $\\ell_{p}$-bounded\nneighborhood to a general case, which covers different types of perturbations,\nsuch as the pixel-wise ($i.e.$, $x + \\delta$) or the spatial perturbation\n($i.e.$, $ AX + b$). Extensive experiments on benchmark datasets not only\nverify the superiority of the proposed SRT method to state-of-the-art methods\nfor defensing pixel-wise or spatial perturbations separately, but also\ndemonstrate its robustness to both perturbations simultaneously. The code for\nreproducing main results is available at\n\\url{https://github.com/THUYimingLi/Semi-supervised_Robust_Training}.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 02:14:08 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 10:14:20 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 01:12:53 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Li", "Yiming", ""], ["Wu", "Baoyuan", ""], ["Feng", "Yan", ""], ["Fan", "Yanbo", ""], ["Jiang", "Yong", ""], ["Li", "Zhifeng", ""], ["Xia", "Shutao", ""]]}, {"id": "2003.06979", "submitter": "Bhavya Kailkhura", "authors": "Saikiran Bulusu, Bhavya Kailkhura, Bo Li, Pramod K. Varshney, Dawn\n  Song", "title": "Anomalous Example Detection in Deep Learning: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning (DL) is vulnerable to out-of-distribution and adversarial\nexamples resulting in incorrect outputs. To make DL more robust, several\nposthoc (or runtime) anomaly detection techniques to detect (and discard) these\nanomalous samples have been proposed in the recent past. This survey tries to\nprovide a structured and comprehensive overview of the research on anomaly\ndetection for DL based applications. We provide a taxonomy for existing\ntechniques based on their underlying assumptions and adopted approaches. We\ndiscuss various techniques in each of the categories and provide the relative\nstrengths and weaknesses of the approaches. Our goal in this survey is to\nprovide an easier yet better understanding of the techniques belonging to\ndifferent categories in which research has been done on this topic. Finally, we\nhighlight the unsolved research challenges while applying anomaly detection\ntechniques in DL systems and present some high-impact future research\ndirections.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 02:47:23 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 21:59:16 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Bulusu", "Saikiran", ""], ["Kailkhura", "Bhavya", ""], ["Li", "Bo", ""], ["Varshney", "Pramod K.", ""], ["Song", "Dawn", ""]]}, {"id": "2003.06990", "submitter": "Yibin Xu", "authors": "Yibin Xu, Yangyu Huang, Jianhua Shao, George Theodorakopoulos", "title": "A Flexible n/2 Adversary Node Resistant and Halting Recoverable\n  Blockchain Sharding Protocol", "comments": "Accepted by Concurrency and Computation Practice and Experience", "journal-ref": null, "doi": "10.1002/CPE.5773", "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain sharding is a promising approach to solving the dilemma between\ndecentralisation and high performance (transaction throughput) for blockchain.\nThe main challenge of Blockchain sharding systems is how to reach a decision on\na statement among a sub-group (shard) of people while ensuring the whole\npopulation recognises this statement. Namely, the challenge is to prevent an\nadversary who does not have the majority of nodes globally but have the\nmajority of nodes inside a shard. Most Blockchain sharding approaches can only\nreach a correct consensus inside a shard with at most $n/3$ evil nodes in a $n$\nnode system. There is a blockchain sharding approach which can prevent an\nincorrect decision to be reached when the adversary does not have $n/2$ nodes\nglobally. However, the system can be stopped from reaching consensus (become\ndeadlocked) if the adversary controls a smaller number of nodes.\n  In this paper, we present an improved Blockchain sharding approach that can\nwithstand $n/2$ adversarial nodes and recover from deadlocks. The recovery is\nmade by dynamically adjusting the number of shards and the shard size. A\nperformance analysis suggests our approach has a high performance (transaction\nthroughput) while requiring little bandwidth for synchronisation.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 03:21:01 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 08:16:05 GMT"}, {"version": "v3", "created": "Thu, 19 Mar 2020 11:05:19 GMT"}, {"version": "v4", "created": "Mon, 23 Mar 2020 13:16:28 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Xu", "Yibin", ""], ["Huang", "Yangyu", ""], ["Shao", "Jianhua", ""], ["Theodorakopoulos", "George", ""]]}, {"id": "2003.07133", "submitter": "Anna Maria Mandalari", "authors": "Anna Maria Mandalari (1), Roman Kolcun (1), Hamed Haddadi (1), Daniel\n  J. Dubois (2) and David Choffnes (2) ((1) Imperial College London, (2)\n  Northeastern University)", "title": "Towards Automatic Identification and Blocking of Non-Critical IoT\n  Traffic Destinations", "comments": "5 pages, 1 figure, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The consumer Internet of Things (IoT) space has experienced a significant\nrise in popularity in the recent years. From smart speakers, to baby monitors,\nand smart kettles and TVs, these devices are increasingly found in households\naround the world while users may be unaware of the risks associated with owning\nthese devices. Previous work showed that these devices can threaten\nindividuals' privacy and security by exposing information online to a large\nnumber of service providers and third party analytics services. Our analysis\nshows that many of these Internet connections (and the information they expose)\nare neither critical, nor even essential to the operation of these devices.\nHowever, automatically separating out critical from non-critical network\ntraffic for an IoT device is nontrivial, and requires expert analysis based on\nmanual experimentation in a controlled setting. In this paper, we investigate\nwhether it is possible to automatically classify network traffic destinations\nas either critical (essential for devices to function properly) or not, hence\nallowing the home gateway to act as a selective firewall to block undesired,\nnon-critical destinations. Our initial results demonstrate that some IoT\ndevices contact destinations that are not critical to their operation, and\nthere is no impact on device functionality if these destinations are blocked.\nWe take the first steps towards designing and evaluating IoTrimmer, a framework\nfor automated testing and analysis of various destinations contacted by\ndevices, and selectively blocking the ones that do not impact device\nfunctionality.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 11:53:52 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Mandalari", "Anna Maria", ""], ["Kolcun", "Roman", ""], ["Haddadi", "Hamed", ""], ["Dubois", "Daniel J.", ""], ["Choffnes", "David", ""]]}, {"id": "2003.07191", "submitter": "Monowar Hasan", "authors": "Monowar Hasan, Sibin Mohan, Takayuki Shimizu, and Hongsheng Lu", "title": "Securing Vehicle-to-Everything (V2X) Communication Platforms", "comments": "Accepted for publication, IEEE Transactions on Intelligent Vehicles,\n  March 2020. arXiv admin note: text overlap with arXiv:1610.06810 by other\n  authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern vehicular wireless technology enables vehicles to exchange information\nat any time, from any place, to any network -- forms the vehicle-to-everything\n(V2X) communication platforms. Despite benefits, V2X applications also face\ngreat challenges to security and privacy -- a very valid concern since breaches\nare not uncommon in automotive communication networks and applications. In this\nsurvey, we provide an extensive overview of V2X ecosystem. We also review main\nsecurity/privacy issues, current standardization activities and existing\ndefense mechanisms proposed within the V2X domain. We then identified semantic\ngaps of existing security solutions and outline possible open issues.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 18:52:43 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Hasan", "Monowar", ""], ["Mohan", "Sibin", ""], ["Shimizu", "Takayuki", ""], ["Lu", "Hongsheng", ""]]}, {"id": "2003.07208", "submitter": "Saul Johnson", "authors": "Saul Johnson", "title": "Passlab: A Password Security Tool for the Blue Team", "comments": "4 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If we wish to compromise some password-protected system as an attacker (i.e.\na member of the red team), we have a large number of popular and\nactively-maintained tools to choose from in helping us to realise our goal.\nPassword hash cracking hardware and software, online guessing tools, exploit\nframeworks, and a wealth of tools for helping us to perform reconnaissance on\nthe target system are widely available. By comparison, if we wish to defend a\npassword-protected system against such an attack (i.e. as a member of the blue\nteam), we have comparatively few tools to choose from. In this research\nabstract, we present our work to date on Passlab, a password security tool\ndesigned to help system administrators take advantage of formal methods in\norder to make sensible and evidence-based security decisions using a clean and\nintuitive user interface.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 18:12:00 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Johnson", "Saul", ""]]}, {"id": "2003.07233", "submitter": "Kiran Karra", "authors": "Kiran Karra, Chace Ashcraft, Neil Fendley", "title": "The TrojAI Software Framework: An OpenSource tool for Embedding Trojans\n  into Deep Learning Models", "comments": "8 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the TrojAI software framework, an open source set\nof Python tools capable of generating triggered (poisoned) datasets and\nassociated deep learning (DL) models with trojans at scale. We utilize the\ndeveloped framework to generate a large set of trojaned MNIST classifiers, as\nwell as demonstrate the capability to produce a trojaned reinforcement-learning\nmodel using vector observations. Results on MNIST show that the nature of the\ntrigger, training batch size, and dataset poisoning percentage all affect\nsuccessful embedding of trojans. We test Neural Cleanse against the trojaned\nMNIST models and successfully detect anomalies in the trained models\napproximately $18\\%$ of the time. Our experiments and workflow indicate that\nthe TrojAI software framework will enable researchers to easily understand the\neffects of various configurations of the dataset and training hyperparameters\non the generated trojaned deep learning model, and can be used to rapidly and\ncomprehensively test new trojan detection methods.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 01:45:32 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Karra", "Kiran", ""], ["Ashcraft", "Chace", ""], ["Fendley", "Neil", ""]]}, {"id": "2003.07242", "submitter": "Yee Ching Tok", "authors": "Yee Ching Tok, Chundong Wang, Sudipta Chattopadhyay", "title": "STITCHER: Correlating Digital Forensic Evidence on Internet-of-Things\n  Devices", "comments": "15 pages", "journal-ref": "Forensic Science International: Digital Investigation, 2020", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing adoption of Internet-of-Things (IoT) devices present new\nchallenges to digital forensic investigators and law enforcement agencies when\ninvestigation into cybercrime on these new platforms are required. However,\nthere has been no formal study to document actual challenges faced by\ninvestigators and whether existing tools help them in their work. Prior issues\nsuch as the correlation and consistency problem in digital forensic evidence\nhave also become a pressing concern in light of numerous evidence sources from\nIoT devices. Motivated by these observations, we conduct a user study with 39\ndigital forensic investigators from both public and private sectors to document\nthe challenges they faced in traditional and IoT digital forensics. We also\ncreated a tool, STITCHER, that addresses the technical challenges faced by\ninvestigators when handling IoT digital forensics investigation. We simulated\nan IoT crime that mimics sophisticated cybercriminals and invited our user\nstudy participants to utilize STITCHER to investigate the crime. The efficacy\nof STITCHER is confirmed by our study results where 96.2% of users indicated\nthat STITCHER assisted them in handling the crime, and 61.5% of users who used\nSTITCHER with its full features solved the crime completely.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 14:10:38 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 12:23:21 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Tok", "Yee Ching", ""], ["Wang", "Chundong", ""], ["Chattopadhyay", "Sudipta", ""]]}, {"id": "2003.07262", "submitter": "Abdelhakim Hannousse", "authors": "Abdelhakim Hannousse, Salima Yahiouche", "title": "Securing Microservices and Microservice Architectures: A Systematic\n  Mapping Study", "comments": null, "journal-ref": "Computer Science Review 41C (2021) 100415", "doi": "10.1016/j.cosrev.2021.100415", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Microservice architectures (MSA) are becoming trending alternatives to\nexisting software development paradigms notably for developing complex and\ndistributed applications. Microservices emerged as an architectural design\npattern aiming to address the scalability and ease the maintenance of online\nservices. However, security breaches have increased threatening availability,\nintegrity and confidentiality of microservice-based systems. A growing body of\nliterature is found addressing security threats and security mechanisms to\nindividual microservices and microservice architectures. The aim of this study\nis to provide a helpful guide to developers about already recognized threats on\nmicroservices and how they can be detected, mitigated or prevented; we also aim\nto identify potential research gaps on securing MSA. In this paper, we conduct\na systematic mapping in order to categorize threats on MSA with their security\nproposals. Therefore, we extracted threats and details of proposed solutions\nreported in selected studies. Obtained results are used to design a lightweight\nontology for security patterns of MSA. The ontology can be queried to identify\nsource of threats, security mechanisms used to prevent each threat,\napplicability layer and validation techniques used for each mechanism. The\nsystematic search yielded 1067 studies of which 46 are selected as primary\nstudies. The results of the mapping revealed an unbalanced research focus in\nfavor of external attacks; auditing and enforcing access control are the most\ninvestigated techniques compared with prevention and mitigation. Additionally,\nwe found that most proposed solutions are soft-infrastructure applicable layer\ncompared with other layers such as communication and deployment. We also found\nthat performance analysis and case studies are the most used validation\ntechniques of security proposals.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 14:53:56 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 23:23:17 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Hannousse", "Abdelhakim", ""], ["Yahiouche", "Salima", ""]]}, {"id": "2003.07270", "submitter": "Leila Karimi", "authors": "Leila Karimi, Maryam Aldairi, James Joshi, Mai Abdelhakim", "title": "An Automatic Attribute Based Access Control Policy Extraction from\n  Access Logs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid advances in computing and information technologies,\ntraditional access control models have become inadequate in terms of capturing\nfine-grained, and expressive security requirements of newly emerging\napplications. An attribute-based access control (ABAC) model provides a more\nflexible approach for addressing the authorization needs of complex and dynamic\nsystems. While organizations are interested in employing newer authorization\nmodels, migrating to such models pose as a significant challenge. Many\nlarge-scale businesses need to grant authorization to their user populations\nthat are potentially distributed across disparate and heterogeneous computing\nenvironments. Each of these computing environments may have its own access\ncontrol model. The manual development of a single policy framework for an\nentire organization is tedious, costly, and error-prone.\n  In this paper, we present a methodology for automatically learning ABAC\npolicy rules from access logs of a system to simplify the policy development\nprocess. The proposed approach employs an unsupervised learning-based algorithm\nfor detecting patterns in access logs and extracting ABAC authorization rules\nfrom these patterns. In addition, we present two policy improvement algorithms,\nincluding rule pruning and policy refinement algorithms to generate a higher\nquality mined policy. Finally, we implement a prototype of the proposed\napproach to demonstrate its feasibility.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 15:08:54 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 15:52:13 GMT"}, {"version": "v3", "created": "Mon, 4 Jan 2021 02:39:33 GMT"}, {"version": "v4", "created": "Sat, 30 Jan 2021 17:43:34 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Karimi", "Leila", ""], ["Aldairi", "Maryam", ""], ["Joshi", "James", ""], ["Abdelhakim", "Mai", ""]]}, {"id": "2003.07314", "submitter": "Pengcheng Xia", "authors": "Pengcheng Xia, Bowen Zhang, Ru Ji, Bingyu Gao, Lei Wu, Xiapu Luo,\n  Haoyu Wang, Guoai Xu", "title": "Characterizing Cryptocurrency Exchange Scams", "comments": "15 pages,18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the indispensable trading platforms of the ecosystem, hundreds of\ncryptocurrency exchanges are emerging to facilitate the trading of digital\nassets. While, it also attracts the attentions of attackers. A number of scam\nattacks were reported targeting cryptocurrency exchanges, leading to a huge\nmount of financial loss. However, no previous work in our research community\nhas systematically studied this problem. In this paper, we make the first\neffort to identify and characterize the cryptocurrency exchange scams. We first\nidentify over 1,500 scam domains and over 300 fake apps, by collecting existing\nreports and using typosquatting generation techniques. Then we investigate the\nrelationship between them, and identify 94 scam domain families and 30 fake app\nfamilies. We further characterize the impacts of such scams, and reveal that\nthese scams have incurred financial loss of 520k US dollars at least. We\nfurther observe that the fake apps have been sneaked to major app markets\n(including Google Play) to infect unsuspicious users. Our findings demonstrate\nthe urgency to identify and prevent cryptocurrency exchange scams. To\nfacilitate future research, we have publicly released all the identified scam\ndomains and fake apps to the community.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 16:34:47 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Xia", "Pengcheng", ""], ["Zhang", "Bowen", ""], ["Ji", "Ru", ""], ["Gao", "Bingyu", ""], ["Wu", "Lei", ""], ["Luo", "Xiapu", ""], ["Wang", "Haoyu", ""], ["Xu", "Guoai", ""]]}, {"id": "2003.07421", "submitter": "Erin Lanus", "authors": "Alan T. Sherman, Erin Lanus, Moses Liskov, Edward Zieglar, Richard\n  Chang, Enis Golaszewski, Ryan Wnuk-Fink, Cyrus J. Bonyadi, Mario Yaksetig,\n  and Ian Blumenfeld", "title": "Formal Methods Analysis of the Secure Remote Password Protocol", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the Secure Remote Password (SRP) protocol for structural\nweaknesses using the Cryptographic Protocol Shapes Analyzer (CPSA) in the first\nformal analysis of SRP (specifically, Version 3).\n  SRP is a widely deployed Password Authenticated Key Exchange (PAKE) protocol\nused in 1Password, iCloud Keychain, and other products. As with many PAKE\nprotocols, two participants use knowledge of a pre-shared password to\nauthenticate each other and establish a session key. SRP aims to resist\ndictionary attacks, not store plaintext-equivalent passwords on the server,\navoid patent infringement, and avoid export controls by not using encryption.\nFormal analysis of SRP is challenging in part because existing tools provide no\nsimple way to reason about its use of the mathematical expression $v + g^b \\mod\nq$.\n  Modeling $v + g^b$ as encryption, we complete an exhaustive study of all\npossible execution sequences of SRP. Ignoring possible algebraic attacks, this\nanalysis detects no major structural weakness, and in particular no leakage of\nany secrets. We do uncover one notable weakness of SRP, which follows from its\ndesign constraints. It is possible for a malicious server to fake an\nauthentication session with a client, without the client's participation. This\naction might facilitate an escalation of privilege attack, if the client has\nhigher privileges than does the server. We conceived of this attack before we\nused CPSA and confirmed it by generating corresponding execution shapes using\nCPSA.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 19:31:03 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Sherman", "Alan T.", ""], ["Lanus", "Erin", ""], ["Liskov", "Moses", ""], ["Zieglar", "Edward", ""], ["Chang", "Richard", ""], ["Golaszewski", "Enis", ""], ["Wnuk-Fink", "Ryan", ""], ["Bonyadi", "Cyrus J.", ""], ["Yaksetig", "Mario", ""], ["Blumenfeld", "Ian", ""]]}, {"id": "2003.07435", "submitter": "Aron Laszka", "authors": "Mudabbir Kaleem and Anastasia Mavridou and Aron Laszka", "title": "Vyper: A Security Comparison with Solidity Based on Common\n  Vulnerabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vyper has been proposed as a new high-level language for Ethereum smart\ncontract development due to numerous security vulnerabilities and attacks\nwitnessed on contracts written in Solidity since the system's inception. Vyper\naims to address these vulnerabilities by providing a language that focuses on\nsimplicity, auditability and security. We present a survey where we study how\nwell-known and commonly-encountered vulnerabilities in Solidity feature in\nVyper's development environment. We analyze all such vulnerabilities\nindividually and classify them into five groups based on their status in Vyper.\nTo the best of our knowledge, our survey is the first attempt to study security\nvulnerabilities in Vyper.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 20:39:22 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 18:49:47 GMT"}, {"version": "v3", "created": "Sun, 24 May 2020 15:04:24 GMT"}, {"version": "v4", "created": "Sun, 14 Jun 2020 21:12:00 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Kaleem", "Mudabbir", ""], ["Mavridou", "Anastasia", ""], ["Laszka", "Aron", ""]]}, {"id": "2003.07440", "submitter": "Archisman Ghosh", "authors": "Archisman Ghosh, Debayan Das and Shreyas Sen", "title": "Physical Time-Varying Transfer Functions as Generic Low-Overhead\n  Power-SCA Countermeasure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mathematically-secure cryptographic algorithms leak significant side channel\ninformation through their power supplies when implemented on a physical\nplatform. These side channel leakages can be exploited by an attacker to\nextract the secret key of an embedded device. The existing state-of-the-art\ncountermeasures mainly focus on the power balancing, gate-level masking, or\nsignal-to-noise (SNR) reduction using noise injection and signature\nattenuation, all of which suffer either from the limitations of high power/area\noverheads, performance degradation or are not synthesizable. In this article,\nwe propose a generic low-overhead digital-friendly power SCA countermeasure\nutilizing physical Time-Varying Transfer Functions (TVTF) by randomly shuffling\ndistributed switched capacitors to significantly obfuscate the traces in the\ntime domain. System-level simulation results of the TVTF-AES implemented in\nTSMC 65nm CMOS technology show > 4000x MTD improvement over the unprotected\nimplementation with nearly 1.25x power and 1.2x area overheads, and without any\nperformance degradation.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 21:06:04 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Ghosh", "Archisman", ""], ["Das", "Debayan", ""], ["Sen", "Shreyas", ""]]}, {"id": "2003.07495", "submitter": "Bowen Liu", "authors": "Bowen Liu, Siwei Sun, Pawel Szalachowski", "title": "SMACS: Smart Contract Access Control Service", "comments": "IEEE/IFIP DSN'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although blockchain-based smart contracts promise a ``trustless'' way of\nenforcing agreements even with monetary consequences, they suffer from multiple\nsecurity issues. Many of these issues could be mitigated via an effective\naccess control system, however, its realization is challenging due to the\nproperties of current blockchain platforms (like lack of privacy, costly\non-chain resources, or latency). To address this problem, we propose the SMACS\nframework, where updatable and sophisticated Access Control Rules (ACRs)} for\nsmart contracts can be realized with low cost. SMACS shifts the burden of\nexpensive ACRs validation and management operations to an off-chain\ninfrastructure, while implementing on-chain only lightweight token-based access\ncontrol. SMACS is flexible and in addition to simple access control lists can\neasily implement rules enhancing the runtime security of smart contracts. With\ndedicated ACRs backed by vulnerability-detection tools, SMACS can protect\nvulnerable contracts after deployment. We fully implement SMACS and evaluate\nit.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 02:07:09 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Liu", "Bowen", ""], ["Sun", "Siwei", ""], ["Szalachowski", "Pawel", ""]]}, {"id": "2003.07505", "submitter": "Md Amiruzzaman", "authors": "Md Amiruzzaman and Rizal Mohd Nor", "title": "Hide Secret Information in Blocks: Minimum Distortion Embedding", "comments": "This paper is accepted for publication in IEEE SPIN 2020 conference", "journal-ref": "2020 7th International Conference on Signal Processing and\n  Integrated Networks (SPIN)", "doi": "10.1109/SPIN48934.2020.9071138", "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a new steganographic method is presented that provides minimum\ndistortion in the stego image. The proposed encoding algorithm focuses on DCT\nrounding error and optimizes that in a way to reduce distortion in the stego\nimage, and the proposed algorithm produces less distortion than existing\nmethods (e.g., F5 algorithm). The proposed method is based on DCT rounding\nerror which helps to lower distortion and higher embedding capacity.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 02:49:35 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Amiruzzaman", "Md", ""], ["Nor", "Rizal Mohd", ""]]}, {"id": "2003.07610", "submitter": "Ritajit Majumdar", "authors": "Nayana Das and Ritajit Majumdar", "title": "Comment on \"Quantum key agreement protocol\"", "comments": "5 pages, single column (Publication detail updated; updated the text)", "journal-ref": "International Journal of Quantum Information (2020)", "doi": "10.1142/S0219749920500392", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The first two party Quantum Key Agreement (QKA) protocol, based on quantum\nteleportation, was proposed by Zhou et al. (Electronics Letters 40.18 (2004):\n1149-1150). In this protocol, to obtain the key bit string, one of the parties\nuse a device to obtain inner product of two quantum states, one being unknown,\nand the other one performs Bell measurement. However, in this article, we show\nthat it is not possible to obtain a device that would output the inner product\nof two qubits even when only one of the qubit is unknown. This is so because\nexistence of such device would imply perfectly distinguishing among four\ndifferent states in a two-dimensional vector space. This is not permissible in\nquantum mechanics. Furthermore, we argue that existence of such a device would\nalso imply violation of the \"No Signalling Theorem\" as well. Finally, we also\ncomment that this protocol is not a valid key agreement protocol at all.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 10:11:06 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 08:26:04 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Das", "Nayana", ""], ["Majumdar", "Ritajit", ""]]}, {"id": "2003.07622", "submitter": "Stephan Wiefling", "authors": "Stephan Wiefling, Luigi Lo Iacono and Markus D\\\"urmuth", "title": "Is This Really You? An Empirical Study on Risk-Based Authentication\n  Applied in the Wild", "comments": "14 pages, 7 tables", "journal-ref": "34th IFIP TC-11 International Conference on Information Security\n  and Privacy Protection (IFIP SEC 2019). IFIP Advances in Information and\n  Communication Technology, vol. 562, pp. 134-148. Springer, Cham", "doi": "10.1007/978-3-030-22312-0_10", "report-no": null, "categories": "cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Risk-based authentication (RBA) is an adaptive security measure to strengthen\npassword-based authentication. RBA monitors additional implicit features during\npassword entry such as device or geolocation information, and requests\nadditional authentication factors if a certain risk level is detected. RBA is\nrecommended by the NIST digital identity guidelines, is used by several large\nonline services, and offers protection against security risks such as password\ndatabase leaks, credential stuffing, insecure passwords and large-scale\nguessing attacks. Despite its relevance, the procedures used by\nRBA-instrumented online services are currently not disclosed. Consequently,\nthere is little scientific research about RBA, slowing down progress and deeper\nunderstanding, making it harder for end users to understand the security\nprovided by the services they use and trust, and hindering the widespread\nadoption of RBA.\n  In this paper, with a series of studies on eight popular online services, we\n(i) analyze which features and combinations/classifiers are used and are useful\nin practical instances, (ii) develop a framework and a methodology to measure\nRBA in the wild, and (iii) survey and discuss the differences in the user\ninterface for RBA. Following this, our work provides a first deeper\nunderstanding of practical RBA deployments and helps fostering further research\nin this direction.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 10:32:08 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Wiefling", "Stephan", ""], ["Iacono", "Luigi Lo", ""], ["D\u00fcrmuth", "Markus", ""]]}, {"id": "2003.07630", "submitter": "Huafei Zhu", "authors": "Huafei Zhu, Zengxiang Li, Mervyn Cheah, Rick Siow Mong Goh", "title": "Privacy-preserving Weighted Federated Learning within Oracle-Aided MPC\n  Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies privacy-preserving weighted federated learning within the\noracle-aided multi-party computation (MPC) framework. The contribution of this\npaper mainly comprises the following three-fold:\n  In the first fold, a new notion which we call weighted federated learning\n(wFL) is introduced and formalized inspired by McMahan et al.'s seminal paper.\nThe weighted federated learning concept formalized in this paper differs from\nthat presented in McMahan et al.'s paper since both addition and multiplication\noperations are executed over ciphers in our model while these operations are\nexecuted over plaintexts in McMahan et al.'s model.\n  In the second fold, an oracle-aided MPC solution for computing weighted\nfederated learning is formalized by decoupling the security of federated\nlearning systems from that of underlying multi-party computations. Our\ndecoupling formulation may benefit machine learning developers to select their\nbest security practices from the state-of-the-art security tool sets;\n  In the third fold, a concrete solution to the weighted federated learning\nproblem is presented and analysed. The security of our implementation is\nguaranteed by the security composition theorem assuming that the underlying\nmultiplication algorithm is secure against honest-but-curious adversaries.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 10:39:51 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 03:04:39 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Zhu", "Huafei", ""], ["Li", "Zengxiang", ""], ["Cheah", "Mervyn", ""], ["Goh", "Rick Siow Mong", ""]]}, {"id": "2003.07775", "submitter": "Stefan Lenz", "authors": "Stefan Lenz, Harald Binder", "title": "Deep generative models in DataSHIELD", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The best way to calculate statistics from medical data is to use the data of\nindividual patients. In some settings, this data is difficult to obtain due to\nprivacy restrictions. In Germany, for example, it is not possible to pool\nroutine data from different hospitals for research purposes without the consent\nof the patients. The DataSHIELD software provides an infrastructure and a set\nof statistical methods for joint analyses of distributed data. The contained\nalgorithms are reformulated to work with aggregated data from the participating\nsites instead of the individual data. If a desired algorithm is not implemented\nin DataSHIELD or cannot be reformulated in such a way, using artificial data is\nan alternative. We present a methodology together with a software\nimplementation that builds on DataSHIELD to create artificial data that\npreserve complex patterns from distributed individual patient data. Such data\nsets of artificial patients, which are not linked to real patients, can then be\nused for joint analyses. We use deep Boltzmann machines (DBMs) as generative\nmodels for capturing the distribution of data. For the implementation, we\nemploy the package \"BoltzmannMachines\" from the Julia programming language and\nwrap it for use with DataSHIELD, which is based on R. As an exemplary\napplication, we conduct a distributed analysis with DBMs on a synthetic data\nset, which simulates genetic variant data. Patterns from the original data can\nbe recovered in the artificial data using hierarchical clustering of the\nvirtual patients, demonstrating the feasibility of the approach. Our\nimplementation adds to DataSHIELD the ability to generate artificial data that\ncan be used for various analyses, e. g. for pattern recognition with deep\nlearning. This also demonstrates more generally how DataSHIELD can be flexibly\nextended with advanced algorithms from languages other than R.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 10:15:06 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Lenz", "Stefan", ""], ["Binder", "Harald", ""]]}, {"id": "2003.07859", "submitter": "Saif Jabari", "authors": "Yue Wang, Esha Sarkar, Wenqing Li, Michail Maniatakos, Saif Eddin\n  Jabari", "title": "Stop-and-Go: Exploring Backdoor Attacks on Deep Reinforcement\n  Learning-based Traffic Congestion Control Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SY eess.SY physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that the introduction of autonomous vehicles (AVs) in\ntraffic could help reduce traffic jams. Deep reinforcement learning methods\ndemonstrate good performance in complex control problems, including autonomous\nvehicle control, and have been used in state-of-the-art AV controllers.\nHowever, the use of deep neural networks (DNNs) renders automated driving\nvulnerable to machine learning-based attacks. In this work, we explore\nbackdooring/trojanning of DRL-based AV controllers. We develop a trigger design\nmethodology that is based on well-established principles of traffic physics.\nThe malicious actions include vehicle deceleration and acceleration to cause\nstop-and-go traffic waves to emerge (congestion attacks), or AV acceleration\nresulting in the AV crashing into the vehicle in front (insurance attack). In\nthe pre-injection stage, we consider the stealth of this backdoor attack by\nselecting triggers that are closest to the genuine data. We demonstrate our\nattack in simulated traffic on a circular track. Experimental results show that\nthe backdoored model does not compromise the performance of normal operation\nwith the maximum decrease in cumulative rewards being 1%, but it can be\nmaliciously activated to cause a crash or congestion when the corresponding\ntriggers appear. We also discuss the effectiveness of state-of-the-art defenses\ntowards the presented attacks.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 08:20:43 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 10:47:54 GMT"}, {"version": "v3", "created": "Sun, 7 Mar 2021 09:19:00 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Wang", "Yue", ""], ["Sarkar", "Esha", ""], ["Li", "Wenqing", ""], ["Maniatakos", "Michail", ""], ["Jabari", "Saif Eddin", ""]]}, {"id": "2003.07907", "submitter": "Ozan Tonguz K.", "authors": "Keith Shannon, Elias Towe, and Ozan K. Tonguz", "title": "On the Use of Quantum Entanglement in Secure Communications: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computing and quantum communications are exciting new frontiers in\ncomputing and communications. Indeed, the massive investments made by the\ngovernments of the US, China, and EU in these new technologies are not a secret\nand are based on the expected potential of these technologies to revolutionize\ncommunications, computing, and security. In addition to several field trials\nand hero experiments, a number of companies such as Google and IBM are actively\nworking in these areas and some have already reported impressive demonstrations\nin the past few years. While there is some skepticism about whether quantum\ncryptography will eventually replace classical cryptography, the advent of\nquantum computing could necessitate the use of quantum cryptography as the\nultimate frontier of secure communications. This is because, with the amazing\nspeeds demonstrated with quantum computers, breaking cryptographic keys might\nno longer be a daunting task in the next decade or so. Hence, quantum\ncryptography as the ultimate frontier in secure communications might not be\nsuch a far-fetched idea. It is well known that Heisenberg's Uncertainty\nPrinciple is essentially a \"negative result\" in Physics and Quantum Mechanics.\nIt turns out that Heisenberg's Uncertainty Principle, one of the most\ninteresting results in Quantum Mechanics, could be the theoretical basis and\nthe main scientific principle behind the ultimate frontier in quantum\ncryptography or secure communications in conjunction with Quantum Entanglement.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 19:32:40 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Shannon", "Keith", ""], ["Towe", "Elias", ""], ["Tonguz", "Ozan K.", ""]]}, {"id": "2003.07949", "submitter": "Vishaal Krishnan", "authors": "Vishaal Krishnan and Fabio Pasqualetti", "title": "Data-Driven Attack Detection for Linear Systems", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CR cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the attack detection problem in a data-driven and\nmodel-free setting, for deterministic systems with linear and time-invariant\ndynamics. Differently from existing studies that leverage knowledge of the\nsystem dynamics to derive security bounds and monitoring schemes, we focus on\nthe case where the system dynamics, as well as the attack strategy and attack\nlocation, are unknown. We derive fundamental security limitations as a function\nof only the observed data and without estimating the system dynamics (in fact,\nno assumption is made on the identifiability of the system). In particular, (i)\nwe derive detection limitations as a function of the informativity and length\nof the observed data, (ii) provide a data-driven characterization of\nundetectable attacks, and (iii) construct a data-driven detection monitor.\nSurprisingly, and in accordance with recent studies on data-driven control, our\nresults show that model-based and data-driven security techniques share the\nsame fundamental limitations, provided that the collected data remains\nsufficiently informative.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 21:30:25 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Krishnan", "Vishaal", ""], ["Pasqualetti", "Fabio", ""]]}, {"id": "2003.07982", "submitter": "Ramesh Sah", "authors": "Ramesh Kumar Sah and Hassan Ghasemzadeh", "title": "Adversarial Transferability in Wearable Sensor Systems", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning is used for inference and decision making in wearable sensor\nsystems. However, recent studies have found that machine learning algorithms\nare easily fooled by the addition of adversarial perturbations to their inputs.\nWhat is more interesting is that adversarial examples generated for one machine\nlearning system is also effective against other systems. This property of\nadversarial examples is called transferability. In this work, we take the first\nstride in studying adversarial transferability in wearable sensor systems from\nthe following perspectives: 1) transferability between machine learning\nsystems, 2) transferability across subjects, 3) transferability across sensor\nbody locations, and 4) transferability across datasets. We found strong\nuntargeted transferability in most cases. Targeted attacks were less successful\nwith success scores from $0\\%$ to $80\\%$. The transferability of adversarial\nexamples depends on many factors such as the inclusion of data from all\nsubjects, sensor body position, number of samples in the dataset, type of\nlearning algorithm, and the distribution of source and target system dataset.\nThe transferability of adversarial examples decreases sharply when the data\ndistribution of the source and target system becomes more distinct. We also\nprovide guidelines for the community for designing robust sensor systems.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 23:19:52 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 16:10:42 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Sah", "Ramesh Kumar", ""], ["Ghasemzadeh", "Hassan", ""]]}, {"id": "2003.08054", "submitter": "Mohamed Yaseen Jabarulla", "authors": "Mohamed Yaseen Jabarulla and Heung-No Lee", "title": "Blockchain-Based Distributed Patient-Centric Image Management System", "comments": "18 Pages, 12 Figures, 2 Tables. Included detailed analysis of the\n  proposed framework. Submitted to MDPI-Applied Science", "journal-ref": "https://www.mdpi.com/2076-3417/11/1/196", "doi": "10.3390/app11010196", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, many researchers have focused on developing a feasible\nsolution for storing and exchanging medical images in the field of health care.\nCurrent practices are deployed on cloud-based centralized data centers, which\nincrease maintenance costs, require massive storage space, and raise privacy\nconcerns about sharing information over a network. Therefore, it is important\nto design a framework to enable sharing and storing of big medical data\nefficiently within a trustless environment. In the present paper, we propose a\nnovel proof-of-concept design for a distributed patient-centric image\nmanagement (PCIM) system that is aimed to ensure safety and control of patient\nprivate data without using a centralized infrastructure. In this system, we\nemployed an emerging Ethereum blockchain and a distributed file system\ntechnology called InterPlanetary File System (IPFS). Then, we implemented an\nEthereum smart contract called the patientcentric access control protocol to\nenable a distributed and trustworthy access control policy. IPFS provides the\nmeans for decentralized storage of medical images with global accessibility. We\ndescribe how the PCIM system architecture facilitates the distributed and\nsecured patient-centric data access across multiple entities such as hospitals,\npatients, and image requestors. Finally, we deployed a smart contract prototype\non an Ethereum testnet blockchain and evaluated the proposed framework within\nthe Windows environment. The evaluation results demonstrated that the proposed\nscheme is efficient and feasible.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 05:45:06 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 11:50:40 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 07:41:34 GMT"}, {"version": "v4", "created": "Tue, 24 Nov 2020 08:27:10 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Jabarulla", "Mohamed Yaseen", ""], ["Lee", "Heung-No", ""]]}, {"id": "2003.08225", "submitter": "Yuan Gong", "authors": "Yuan Gong, Jian Yang, Christian Poellabauer", "title": "Detecting Replay Attacks Using Multi-Channel Audio: A Neural\n  Network-Based Method", "comments": "Code of this work is available here:\n  https://github.com/YuanGongND/multichannel-antispoof", "journal-ref": "in IEEE Signal Processing Letters, vol. 27, pp. 920-924, 2020", "doi": "10.1109/LSP.2020.2996908", "report-no": null, "categories": "cs.SD cs.CR cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapidly growing number of security-sensitive systems that use voice\nas the primary input, it becomes increasingly important to address these\nsystems' potential vulnerability to replay attacks. Previous efforts to address\nthis concern have focused primarily on single-channel audio. In this paper, we\nintroduce a novel neural network-based replay attack detection model that\nfurther leverages spatial information of multi-channel audio and is able to\nsignificantly improve the replay attack detection performance.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 13:56:54 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 15:33:52 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 19:37:34 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Gong", "Yuan", ""], ["Yang", "Jian", ""], ["Poellabauer", "Christian", ""]]}, {"id": "2003.08343", "submitter": "Islam Elnabarawy", "authors": "Islam Elnabarawy, Wei Jiang, Donald C. Wunsch II", "title": "Survey of Privacy-Preserving Collaborative Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering recommendation systems provide recommendations to\nusers based on their own past preferences, as well as those of other users who\nshare similar interests. The use of recommendation systems has grown widely in\nrecent years, helping people choose which movies to watch, books to read, and\nitems to buy. However, users are often concerned about their privacy when using\nsuch systems, and many users are reluctant to provide accurate information to\nmost online services. Privacy-preserving collaborative filtering recommendation\nsystems aim to provide users with accurate recommendations while maintaining\ncertain guarantees about the privacy of their data. This survey examines the\nrecent literature in privacy-preserving collaborative filtering, providing a\nbroad perspective of the field and classifying the key contributions in the\nliterature using two different criteria: the type of vulnerability they address\nand the type of approach they use to solve it.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 17:14:50 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Elnabarawy", "Islam", ""], ["Jiang", "Wei", ""], ["Wunsch", "Donald C.", "II"]]}, {"id": "2003.08365", "submitter": "Quanshi Zhang", "authors": "Hao Zhang, Yiting Chen, Liyao Xiang, Haotian Ma, Jie Shi, Quanshi\n  Zhang", "title": "Deep Quaternion Features for Privacy Protection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to revise the neural network to construct the\nquaternion-valued neural network (QNN), in order to prevent intermediate-layer\nfeatures from leaking input information. The QNN uses quaternion-valued\nfeatures, where each element is a quaternion. The QNN hides input information\ninto a random phase of quaternion-valued features. Even if attackers have\nobtained network parameters and intermediate-layer features, they cannot\nextract input information without knowing the target phase. In this way, the\nQNN can effectively protect the input privacy. Besides, the output accuracy of\nQNNs only degrades mildly compared to traditional neural networks, and the\ncomputational cost is much less than other privacy-preserving methods.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 17:38:24 GMT"}, {"version": "v2", "created": "Sun, 21 Jun 2020 09:37:52 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Zhang", "Hao", ""], ["Chen", "Yiting", ""], ["Xiang", "Liyao", ""], ["Ma", "Haotian", ""], ["Shi", "Jie", ""], ["Zhang", "Quanshi", ""]]}, {"id": "2003.08433", "submitter": "George Amariucai", "authors": "Abhishek Jana, Md Kamruzzaman Sarker, Monireh Ebrahimi, Pascal\n  Hitzler, George T Amariucai", "title": "Neural Fuzzy Extractors: A Secure Way to Use Artificial Neural Networks\n  for Biometric User Authentication", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Powered by new advances in sensor development and artificial intelligence,\nthe decreasing cost of computation, and the pervasiveness of handheld\ncomputation devices, biometric user authentication (and identification) is\nrapidly becoming ubiquitous. Modern approaches to biometric authentication,\nbased on sophisticated machine learning techniques, cannot avoid storing either\ntrained-classifier details or explicit user biometric data, thus exposing\nusers' credentials to falsification. In this paper, we introduce a secure way\nto handle user-specific information involved with the use of vector-space\nclassifiers or artificial neural networks for biometric authentication. Our\nproposed architecture, called a Neural Fuzzy Extractor (NFE), allows the\ncoupling of pre-existing classifiers with fuzzy extractors, through a\nartificial-neural-network-based buffer called an expander, with minimal or no\nperformance degradation. The NFE thus offers all the performance advantages of\nmodern deep-learning-based classifiers, and all the security of standard fuzzy\nextractors. We demonstrate the NFE retrofit to a classic artificial neural\nnetwork for a simple scenario of fingerprint-based user authentication.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 18:48:25 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Jana", "Abhishek", ""], ["Sarker", "Md Kamruzzaman", ""], ["Ebrahimi", "Monireh", ""], ["Hitzler", "Pascal", ""], ["Amariucai", "George T", ""]]}, {"id": "2003.08500", "submitter": "Farhad Farokhi", "authors": "Farhad Farokhi, Nan Wu, David Smith, Mohamed Ali Kaafar", "title": "The Cost of Privacy in Asynchronous Differentially-Private Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR eess.SP math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider training machine learning models using Training data located on\nmultiple private and geographically-scattered servers with different privacy\nsettings. Due to the distributed nature of the data, communicating with all\ncollaborating private data owners simultaneously may prove challenging or\naltogether impossible. In this paper, we develop differentially-private\nasynchronous algorithms for collaboratively training machine-learning models on\nmultiple private datasets. The asynchronous nature of the algorithms implies\nthat a central learner interacts with the private data owners one-on-one\nwhenever they are available for communication without needing to aggregate\nquery responses to construct gradients of the entire fitness function.\nTherefore, the algorithm efficiently scales to many data owners. We define the\ncost of privacy as the difference between the fitness of a privacy-preserving\nmachine-learning model and the fitness of trained machine-learning model in the\nabsence of privacy concerns. We prove that we can forecast the performance of\nthe proposed privacy-preserving asynchronous algorithms. We demonstrate that\nthe cost of privacy has an upper bound that is inversely proportional to the\ncombined size of the training datasets squared and the sum of the privacy\nbudgets squared. We validate the theoretical results with experiments on\nfinancial and medical datasets. The experiments illustrate that collaboration\namong more than 10 data owners with at least 10,000 records with privacy\nbudgets greater than or equal to 1 results in a superior machine-learning model\nin comparison to a model trained in isolation on only one of the datasets,\nillustrating the value of collaboration and the cost of the privacy. The number\nof the collaborating datasets can be lowered if the privacy budget is higher.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 23:06:28 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 04:53:58 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Farokhi", "Farhad", ""], ["Wu", "Nan", ""], ["Smith", "David", ""], ["Kaafar", "Mohamed Ali", ""]]}, {"id": "2003.08567", "submitter": "Praneeth Vepakomma", "authors": "Ramesh Raskar, Isabel Schunemann, Rachel Barbar, Kristen Vilcans, Jim\n  Gray, Praneeth Vepakomma, Suraj Kapa, Andrea Nuzzo, Rajiv Gupta, Alex Berke,\n  Dazza Greenwood, Christian Keegan, Shriank Kanaparti, Robson Beaudry, David\n  Stansbury, Beatriz Botero Arcila, Rishank Kanaparti, Vitor Pamplona,\n  Francesco M Benedetti, Alina Clough, Riddhiman Das, Kaushal Jain, Khahlil\n  Louisy, Greg Nadeau, Vitor Pamplona, Steve Penrod, Yasaman Rajaee, Abhishek\n  Singh, Greg Storm, John Werner", "title": "Apps Gone Rogue: Maintaining Personal Privacy in an Epidemic", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Containment, the key strategy in quickly halting an epidemic, requires rapid\nidentification and quarantine of the infected individuals, determination of\nwhom they have had close contact with in the previous days and weeks, and\ndecontamination of locations the infected individual has visited. Achieving\ncontainment demands accurate and timely collection of the infected individual's\nlocation and contact history. Traditionally, this process is labor intensive,\nsusceptible to memory errors, and fraught with privacy concerns. With the\nrecent almost ubiquitous availability of smart phones, many people carry a tool\nwhich can be utilized to quickly identify an infected individual's contacts\nduring an epidemic, such as the current 2019 novel Coronavirus crisis.\nUnfortunately, the very same first-generation contact tracing tools have been\nused to expand mass surveillance, limit individual freedoms and expose the most\nprivate details about individuals. We seek to outline the different\ntechnological approaches to mobile-phone based contact-tracing to date and\nelaborate on the opportunities and the risks that these technologies pose to\nindividuals and societies. We describe advanced security enhancing approaches\nthat can mitigate these risks and describe trade-offs one must make when\ndeveloping and deploying any mass contact-tracing technology. With this paper,\nour aim is to continue to grow the conversation regarding contact-tracing for\nepidemic and pandemic containment and discuss opportunities to advance this\nspace. We invite feedback and discussion.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 04:22:24 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Raskar", "Ramesh", ""], ["Schunemann", "Isabel", ""], ["Barbar", "Rachel", ""], ["Vilcans", "Kristen", ""], ["Gray", "Jim", ""], ["Vepakomma", "Praneeth", ""], ["Kapa", "Suraj", ""], ["Nuzzo", "Andrea", ""], ["Gupta", "Rajiv", ""], ["Berke", "Alex", ""], ["Greenwood", "Dazza", ""], ["Keegan", "Christian", ""], ["Kanaparti", "Shriank", ""], ["Beaudry", "Robson", ""], ["Stansbury", "David", ""], ["Arcila", "Beatriz Botero", ""], ["Kanaparti", "Rishank", ""], ["Pamplona", "Vitor", ""], ["Benedetti", "Francesco M", ""], ["Clough", "Alina", ""], ["Das", "Riddhiman", ""], ["Jain", "Kaushal", ""], ["Louisy", "Khahlil", ""], ["Nadeau", "Greg", ""], ["Pamplona", "Vitor", ""], ["Penrod", "Steve", ""], ["Rajaee", "Yasaman", ""], ["Singh", "Abhishek", ""], ["Storm", "Greg", ""], ["Werner", "John", ""]]}, {"id": "2003.08580", "submitter": "Nikita Samarin", "authors": "Nikita Samarin, Alisa Frik, Sean Brooks, Coye Cheshire, Serge Egelman", "title": "Surveying Vulnerable Populations: A Case Study of Civil Society\n  Organizations", "comments": "[v2] Appears in the Workshop on Inclusive Privacy and Security (WIPS)\n  co-located with Symposium on Usable Privacy and Security (SOUPS) 2020; [v1]\n  Appears in the Networked Privacy Workshop co-located with ACM Conference on\n  Human Factors in Computing Systems (CHI) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared to organizations in other sectors, civil society organizations\n(CSOs) are particularly vulnerable to security and privacy threats, as they\nlack adequate resources and expertise to defend themselves. At the same time,\ntheir security needs and practices have not gained much attention among\nresearchers, and existing solutions designed for the average users do not\nconsider the contexts in which CSO employees operate. As part of our\npreliminary work, we conducted an anonymous online survey with 102 CSO\nemployees to collect information about their perceived risks of different\nsecurity and privacy threats, and their self-reported mitigation strategies.\nThe design of our preliminary survey accounted for the unique requirements of\nour target population by establishing trust with respondents, using\nanonymity-preserving incentive strategies, and distributing the survey with the\nhelp of a trusted intermediary. However, by carefully examining our methods and\nthe feedback received from respondents, we uncovered several issues with our\nmethodology, including the length of the survey, the framing of the questions,\nand the design of the recruitment email. We hope that the discussion presented\nin this paper will inform and assist researchers and practitioners working on\nunderstanding and improving the security and privacy of CSOs.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 05:30:21 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 21:01:40 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Samarin", "Nikita", ""], ["Frik", "Alisa", ""], ["Brooks", "Sean", ""], ["Cheshire", "Coye", ""], ["Egelman", "Serge", ""]]}, {"id": "2003.08585", "submitter": "Baha Rababah", "authors": "Baha Rababah, Srija Srivastava", "title": "Hybrid Model For Intrusion Detection Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing number of new attacks on ever growing network traffic, it\nis becoming challenging to alert immediately any malicious activities to avoid\nloss of sensitive data and money. This is making intrusion detection as one of\nthe major areas of concern in network security. Anomaly based network intrusion\ndetection technique is one of the most commonly used technique. Depending upon\nthe dataset used to test those techniques, the accuracy varies. Most of the\ntimes this dataset does not represent the real network traffic. Considering\nthis, this project involves analysis of different machine learning algorithms\nused in intrusion detection systems, when tested upon two datasets which are\nsimilar to current real world network traffic(CICIDS2017) and an improvement of\nKDD 99 (NSL-KDD). After the analysis of different intrusion detection systems\non both the datasets, this project aimed to develop a new hybrid model for\nintrusion detection systems. This new hybrid approach combines decision tree\nand random forest algorithms using stacking scheme to achieve an accuracy of\n85.2% and precision of 86.2% for NSL-KDD dataset, and achieve an accuracy of\n98% and precision of 98% for CICIDS2017 dataset.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 05:52:29 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Rababah", "Baha", ""], ["Srivastava", "Srija", ""]]}, {"id": "2003.08633", "submitter": "Erwin Quiring", "authors": "Erwin Quiring and Konrad Rieck", "title": "Backdooring and Poisoning Neural Networks with Image-Scaling Attacks", "comments": "IEEE Deep Learning and Security Workshop (DLS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backdoors and poisoning attacks are a major threat to the security of\nmachine-learning and vision systems. Often, however, these attacks leave\nvisible artifacts in the images that can be visually detected and weaken the\nefficacy of the attacks. In this paper, we propose a novel strategy for hiding\nbackdoor and poisoning attacks. Our approach builds on a recent class of\nattacks against image scaling. These attacks enable manipulating images such\nthat they change their content when scaled to a specific resolution. By\ncombining poisoning and image-scaling attacks, we can conceal the trigger of\nbackdoors as well as hide the overlays of clean-label poisoning. Furthermore,\nwe consider the detection of image-scaling attacks and derive an adaptive\nattack. In an empirical evaluation, we demonstrate the effectiveness of our\nstrategy. First, we show that backdoors and poisoning work equally well when\ncombined with image-scaling attacks. Second, we demonstrate that current\ndetection defenses against image-scaling attacks are insufficient to uncover\nour manipulations. Overall, our work provides a novel means for hiding traces\nof manipulations, being applicable to different poisoning approaches.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 08:59:50 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Quiring", "Erwin", ""], ["Rieck", "Konrad", ""]]}, {"id": "2003.08634", "submitter": "Jagmohan Tanti Dr", "authors": "Munesh Kumari and Jagmohan Tanti", "title": "A model of public key cryptography using multinacci matrices", "comments": "In this paper, we have proposed a Public Key Cryptography (P KC)\n  using block matrices with generalized Fibonacci sequence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we have proposed a Public Key Cryptography (P KC) using block\nmatrices with generalized Fibonacci sequence. First, we have shown the\nmultiplicative commutativity of generalized matrices which are constructed\nusing generalized Fibonacci sequences and then we develop a cryptographical\nscheme. We also discuss the efficiency and strength of proposed scheme in\ncontext of block matrices.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 09:05:44 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Kumari", "Munesh", ""], ["Tanti", "Jagmohan", ""]]}, {"id": "2003.08725", "submitter": "Yi Liu", "authors": "Yi Liu, James J.Q. Yu, Jiawen Kang, Dusit Niyato, Shuyu Zhang", "title": "Privacy-preserving Traffic Flow Prediction: A Federated Learning\n  Approach", "comments": "This paper is in the second round of under review of the IEEE\n  Internet of Things Journal", "journal-ref": null, "doi": "10.1109/JIOT.2020.2991401", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing traffic flow forecasting approaches by deep learning models achieve\nexcellent success based on a large volume of datasets gathered by governments\nand organizations. However, these datasets may contain lots of user's private\ndata, which is challenging the current prediction approaches as user privacy is\ncalling for the public concern in recent years. Therefore, how to develop\naccurate traffic prediction while preserving privacy is a significant problem\nto be solved, and there is a trade-off between these two objectives. To address\nthis challenge, we introduce a privacy-preserving machine learning technique\nnamed federated learning and propose a Federated Learning-based Gated Recurrent\nUnit neural network algorithm (FedGRU) for traffic flow prediction. FedGRU\ndiffers from current centralized learning methods and updates universal\nlearning models through a secure parameter aggregation mechanism rather than\ndirectly sharing raw data among organizations. In the secure parameter\naggregation mechanism, we adopt a Federated Averaging algorithm to reduce the\ncommunication overhead during the model parameter transmission process.\nFurthermore, we design a Joint Announcement Protocol to improve the scalability\nof FedGRU. We also propose an ensemble clustering-based scheme for traffic flow\nprediction by grouping the organizations into clusters before applying FedGRU\nalgorithm. Through extensive case studies on a real-world dataset, it is shown\nthat FedGRU's prediction accuracy is 90.96% higher than the advanced deep\nlearning models, which confirm that FedGRU can achieve accurate and timely\ntraffic prediction without compromising the privacy and security of raw data.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 13:07:49 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Liu", "Yi", ""], ["Yu", "James J. Q.", ""], ["Kang", "Jiawen", ""], ["Niyato", "Dusit", ""], ["Zhang", "Shuyu", ""]]}, {"id": "2003.08837", "submitter": "Christian Berghoff", "authors": "Christian Berghoff and Matthias Neu and Arndt von Twickel", "title": "Vulnerabilities of Connectionist AI Applications: Evaluation and Defence", "comments": "20 pages, 8 figures, 1 table", "journal-ref": null, "doi": "10.3389/fdata.2020.00023", "report-no": null, "categories": "cs.CR cs.AI cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article deals with the IT security of connectionist artificial\nintelligence (AI) applications, focusing on threats to integrity, one of the\nthree IT security goals. Such threats are for instance most relevant in\nprominent AI computer vision applications. In order to present a holistic view\non the IT security goal integrity, many additional aspects such as\ninterpretability, robustness and documentation are taken into account. A\ncomprehensive list of threats and possible mitigations is presented by\nreviewing the state-of-the-art literature. AI-specific vulnerabilities such as\nadversarial attacks and poisoning attacks as well as their AI-specific root\ncauses are discussed in detail. Additionally and in contrast to former reviews,\nthe whole AI supply chain is analysed with respect to vulnerabilities,\nincluding the planning, data acquisition, training, evaluation and operation\nphases. The discussion of mitigations is likewise not restricted to the level\nof the AI system itself but rather advocates viewing AI systems in the context\nof their supply chains and their embeddings in larger IT infrastructures and\nhardware devices. Based on this and the observation that adaptive attackers may\ncircumvent any single published AI-specific defence to date, the article\nconcludes that single protective measures are not sufficient but rather\nmultiple measures on different levels have to be combined to achieve a minimum\nlevel of IT security for AI applications.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 12:33:59 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Berghoff", "Christian", ""], ["Neu", "Matthias", ""], ["von Twickel", "Arndt", ""]]}, {"id": "2003.08861", "submitter": "Varun Chandrasekaran", "authors": "Varun Chandrasekaran, Chuhan Gao, Brian Tang, Kassem Fawaz, Somesh\n  Jha, Suman Banerjee", "title": "Face-Off: Adversarial Face Obfuscation", "comments": "Published in PoPETs 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in deep learning have made face recognition technologies pervasive.\nWhile useful to social media platforms and users, this technology carries\nsignificant privacy threats. Coupled with the abundant information they have\nabout users, service providers can associate users with social interactions,\nvisited places, activities, and preferences--some of which the user may not\nwant to share. Additionally, facial recognition models used by various agencies\nare trained by data scraped from social media platforms. Existing approaches to\nmitigate these privacy risks from unwanted face recognition result in an\nimbalanced privacy-utility trade-off to users. In this paper, we address this\ntrade-off by proposing Face-Off, a privacy-preserving framework that introduces\nstrategic perturbations to the user's face to prevent it from being correctly\nrecognized. To realize Face-Off, we overcome a set of challenges related to the\nblack-box nature of commercial face recognition services, and the scarcity of\nliterature for adversarial attacks on metric networks. We implement and\nevaluate Face-Off to find that it deceives three commercial face recognition\nservices from Microsoft, Amazon, and Face++. Our user study with 423\nparticipants further shows that the perturbations come at an acceptable cost\nfor the users.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 15:23:07 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 05:42:18 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Chandrasekaran", "Varun", ""], ["Gao", "Chuhan", ""], ["Tang", "Brian", ""], ["Fawaz", "Kassem", ""], ["Jha", "Somesh", ""], ["Banerjee", "Suman", ""]]}, {"id": "2003.08915", "submitter": "Olivier Nicole", "authors": "Olivier Nicole, Matthieu Lemerre, S\\'ebastien Bardin, Xavier Rival", "title": "Automatically Proving Microkernels Free from Privilege Escalation from\n  their Executable", "comments": "19 pages, 11 figures, submitted to IEEE Symposium on Security and\n  Privacy 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Operating system kernels are the security keystone of most computer systems,\nas they provide the core protection mechanisms. Kernels are in particular\nresponsible for their own security, i.e. they must prevent untrusted user tasks\nfrom reaching their level of privilege. We demonstrate that proving such\nabsence of privilege escalation is a pre-requisite for any definitive security\nproof of the kernel. While prior OS kernel formal verifications were performed\neither on source code or crafted kernels, with manual or semi-automated methods\nrequiring significant human efforts in annotations or proofs, we show that it\nis possible to compute such kernel security proofs using fully-automated\nmethods and starting from the executable code of an existing microkernel with\nno modification, thus formally verifying absence of privilege escalation with\nhigh confidence for a low cost. We applied our method on two embedded\nmicrokernels, including the industrial kernel AnonymOS: with only 58 lines of\nannotation and less than 10 minutes of computation, our method finds a\nvulnerability in a first (buggy) version of AnonymOS and verifies absence of\nprivilege escalation in a second (secure) version.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 17:28:36 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Nicole", "Olivier", ""], ["Lemerre", "Matthieu", ""], ["Bardin", "S\u00e9bastien", ""], ["Rival", "Xavier", ""]]}, {"id": "2003.09019", "submitter": "Quan Thoi Minh Nguyen", "authors": "Quan Thoi Minh Nguyen", "title": "Intuitive Understanding of Quantum Computation and Post-Quantum\n  Cryptography", "comments": "Add hash-based signature's detail", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Post-quantum cryptography is inevitable. National Institute of Standards and\nTechnology (NIST) starts standardizing quantum-resistant public-key\ncryptography (aka post-quantum cryptography). The reason is that investment in\nquantum computing is blooming which poses significant threats to our currently\ndeployed cryptographic algorithms. As a security engineer, to prepare for the\napocalypse in advance, I've been watching the development of quantum computers\nand post-quantum cryptography closely. Never mind, I simply made up an excuse\nto study these fascinating scientific fields. However, they are extremely hard\nto understand, at least to an amateur like me. This article shares with you my\nnotes with the hope that you will have an intuitive understanding of the\nbeautiful and mind-blowing quantum algorithms and post-quantum cryptography.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 03:29:37 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 07:50:50 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Nguyen", "Quan Thoi Minh", ""]]}, {"id": "2003.09120", "submitter": "Piotr Kulicki", "authors": "Xin Sun, Piotr Kulicki, Mirek Sopek", "title": "Multi-party Quantum Byzantine Agreement Without Entanglement", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": "10.3390/e22101152", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a protocol of quantum communication to achieve\nByzantine agreement among multiple parties. The striking feature of our\nproposal in comparison to the existing protocols is that we do not use\nentanglement to achieve the agreement. There are two stages in our protocol. In\nthe first stage, a list of numbers that satisfies some special properties is\ndistributed to every participant by a group of semi-honest list distributors\nvia quantum secure communication. Then, in the second stage those participants\nexchange some information to reach agreement.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 06:26:44 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Sun", "Xin", ""], ["Kulicki", "Piotr", ""], ["Sopek", "Mirek", ""]]}, {"id": "2003.09262", "submitter": "Ruben Tolosana", "authors": "Oscar Delgado-Mohatar, Julian Fierrez, Ruben Tolosana and Ruben\n  Vera-Rodriguez", "title": "Blockchain meets Biometrics: Concepts, Application to Template\n  Protection, and Trends", "comments": "arXiv admin note: text overlap with arXiv:1904.13128", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain technologies provide excellent architectures and practical tools\nfor securing and managing the sensitive and private data stored in biometric\ntemplates, but at a cost. We discuss opportunities and challenges in the\nintegration of blockchain and biometrics, with emphasis in biometric template\nstorage and protection, a key problem in biometrics still largely unsolved. Key\ntradeoffs involved in that integration, namely, latency, processing time,\neconomic cost, and biometric performance are experimentally studied through the\nimplementation of a smart contract on the Ethereum blockchain platform, which\nis publicly available in github for research purposes.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 08:11:13 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Delgado-Mohatar", "Oscar", ""], ["Fierrez", "Julian", ""], ["Tolosana", "Ruben", ""], ["Vera-Rodriguez", "Ruben", ""]]}, {"id": "2003.09316", "submitter": "Ning Xie", "authors": "Ning Xie, Ji Hu, Junjie Chen, Qiqi Zhang, and Changsheng Chen", "title": "Detection of Information Hiding at Anti-Copying 2D Barcodes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns the problem of detecting the use of information hiding at\nanti-copying 2D barcodes. Prior hidden information detection schemes are either\nheuristicbased or Machine Learning (ML) based. The key limitation of prior\nheuristics-based schemes is that they do not answer the fundamental question of\nwhy the information hidden at a 2D barcode can be detected. The key limitation\nof prior MLbased information schemes is that they lack robustness because a\nprinted 2D barcode is very much environmentally dependent, and thus an\ninformation hiding detection scheme trained in one environment often does not\nwork well in another environment. In this paper, we propose two hidden\ninformation detection schemes at the existing anti-copying 2D barcodes. The\nfirst scheme is to directly use the pixel distance to detect the use of an\ninformation hiding scheme in a 2D barcode, referred as to the Pixel Distance\nBased Detection (PDBD) scheme. The second scheme is first to calculate the\nvariance of the raw signal and the covariance between the recovered signal and\nthe raw signal, and then based on the variance results, detects the use of\ninformation hiding scheme in a 2D barcode, referred as to the Pixel Variance\nBased Detection (PVBD) scheme. Moreover, we design advanced IC attacks to\nevaluate the security of two existing anti-copying 2D barcodes. We implemented\nour schemes and conducted extensive performance comparison between our schemes\nand prior schemes under different capturing devices, such as a scanner and a\ncamera phone. Our experimental results show that the PVBD scheme can correctly\ndetect the existence of the hidden information at both the 2LQR code and the\nLCAC 2D barcode. Moreover, the probability of successfully attacking of our IC\nattacks achieves 0.6538 for the 2LQR code and 1 for the LCAC 2D barcode.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 15:06:50 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Xie", "Ning", ""], ["Hu", "Ji", ""], ["Chen", "Junjie", ""], ["Zhang", "Qiqi", ""], ["Chen", "Changsheng", ""]]}, {"id": "2003.09347", "submitter": "Chawin Sitawarin", "authors": "Chawin Sitawarin, Supriyo Chakraborty, David Wagner", "title": "Improving Adversarial Robustness Through Progressive Hardening", "comments": "Preprint. Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adversarial training (AT) has become a popular choice for training robust\nnetworks. However, it tends to sacrifice clean accuracy heavily in favor of\nrobustness, and with a large perturbation, it can cause models to learn a\ntrivial solution, always predicting the same class. To address the above\nconcerns, we propose Adversarial Training with Early Stopping (ATES), guided by\nprinciples from curriculum learning that emphasizes on starting \"easy\" and\ngradually ramping up on the \"difficulty\" of training. ATES is derived from our\nformulation for curriculum learning in the adversarial setting which introduces\nan additional curriculum constraint to the normal adversarial loss. To satisfy\nthis constraint, we apply early stopping on the adversarial example generation\nstep when a specified level of difficulty is reached. ATES stabilizes network\ntraining even for a large perturbation norm and allows the network to operate\nat a better clean accuracy versus robustness trade-off curve compared to AT.\nThis leads to a significant improvement in both clean accuracy and robustness\ncompared to AT, TRADES, and the other baselines.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 20:59:45 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 17:24:26 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Sitawarin", "Chawin", ""], ["Chakraborty", "Supriyo", ""], ["Wagner", "David", ""]]}, {"id": "2003.09381", "submitter": "Subrata Nandi M. Tech.", "authors": "Subrata Nandi, Srinivasan Krishnaswamy, Behrouz Zolfaghari and Pinaki\n  Mitra", "title": "The application of $\\sigma$-LFSR in Key-Dependent Feedback Configuration\n  for Word-Oriented Stream Ciphers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose and evaluate a method for generating key-dependent\nfeedback configurations (KDFC) for $\\sigma$-LFSRs. $\\sigma$-LFSRs with such\nconfigurations can be applied to any stream cipher that uses a word-based LFSR.\nHere, a configuration generation algorithm uses the secret key(K) and the\ninitialization vector (IV) to generate a feedback configuration. We have\nmathematically analysed the feedback configurations generated by this method.\nAs a test case, we have applied this method on SNOW 2.0 and have studied its\nimpact on resistance to various attacks. Further, we have also tested the\ngenerated keystream for randomness and have briefly described its\nimplementation and the challenges involved in the same.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 16:53:55 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 09:12:08 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Nandi", "Subrata", ""], ["Krishnaswamy", "Srinivasan", ""], ["Zolfaghari", "Behrouz", ""], ["Mitra", "Pinaki", ""]]}, {"id": "2003.09481", "submitter": "Simeon Krastnikov", "authors": "Simeon Krastnikov, Florian Kerschbaum, Douglas Stebila", "title": "Efficient Oblivious Database Joins", "comments": null, "journal-ref": "Proceedings of the VLDB Endowment (PVLDB), 13(11): 2132-2145, 2020", "doi": "10.14778/3407790.3407814", "report-no": null, "categories": "cs.DB cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major algorithmic challenge in designing applications intended for secure\nremote execution is ensuring that they are oblivious to their inputs, in the\nsense that their memory access patterns do not leak sensitive information to\nthe server. This problem is particularly relevant to cloud databases that wish\nto allow queries over the client's encrypted data. One of the major obstacles\nto such a goal is the join operator, which is non-trivial to implement\nobliviously without resorting to generic but inefficient solutions like\nOblivious RAM (ORAM).\n  We present an oblivious algorithm for equi-joins which (up to a logarithmic\nfactor) matches the optimal $O(n\\log n)$ complexity of the standard non-secure\nsort-merge join (on inputs producing $O(n)$ outputs). We do not use use\nexpensive primitives like ORAM or rely on unrealistic hardware or security\nassumptions. Our approach, which is based on sorting networks and novel\nprovably-oblivious constructions, is conceptually simple, easily verifiable,\nand very efficient in practice. Its data-independent algorithmic structure\nmakes it secure in various different settings for remote computation, even in\nthose that are known to be vulnerable to certain side-channel attacks (such as\nIntel SGX) or with strict requirements for low circuit complexity (like secure\nmultiparty computation). We confirm that our approach is easily realizable\nthrough a compact implementation which matches our expectations for performance\nand is shown, both formally and empirically, to possess the desired security\ncharacteristics.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 19:49:21 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 14:52:56 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2020 17:05:25 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Krastnikov", "Simeon", ""], ["Kerschbaum", "Florian", ""], ["Stebila", "Douglas", ""]]}, {"id": "2003.09561", "submitter": "Sijia Geng", "authors": "Sijia Geng, Yuekang Li, Yunlan Du, Jun Xu, Yang Liu, Bing Mao", "title": "An Empirical Study on Benchmarks of Artificial Software Vulnerabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, various techniques (e.g., fuzzing) have been developed for\nvulnerability detection. To evaluate those techniques, the community has been\ndeveloping benchmarks of artificial vulnerabilities because of a shortage of\nground-truth. However, people have concerns that such vulnerabilities cannot\nrepresent reality and may lead to unreliable and misleading results.\nUnfortunately, there lacks research on handling such concerns.\n  In this work, to understand how close these benchmarks mirror reality, we\nperform an empirical study on three artificial vulnerability benchmarks -\nLAVA-M, Rode0day and CGC (2669 bugs) and various real-world memory-corruption\nvulnerabilities (80 CVEs). Furthermore, we propose a model to depict the\nproperties of memory-corruption vulnerabilities. Following this model, we\nconduct intensive experiments and data analyses. Our analytic results reveal\nthat while artificial benchmarks attempt to approach the real world, they still\nsignificantly differ from reality. Based on the findings, we propose a set of\nstrategies to improve the quality of artificial benchmarks.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 02:40:44 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Geng", "Sijia", ""], ["Li", "Yuekang", ""], ["Du", "Yunlan", ""], ["Xu", "Jun", ""], ["Liu", "Yang", ""], ["Mao", "Bing", ""]]}, {"id": "2003.09744", "submitter": "Philipp Brune", "authors": "Philipp Brune (Neu-Ulm University of Applied Sciences, Neu-Ulm,\n  Germany)", "title": "Towards an Enterprise-Ready Implementation of Artificial\n  Intelligence-Enabled, Blockchain-Based Smart Contracts", "comments": "4 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain technology and artificial intelligence (AI) are current hot topics\nin research and practice. However, the potentials of their combination have\nbeen studied just recently to a larger extend. While different use cases for\ncombining AI and blockchain have been discussed, the idea of enabling\nblockchain-based smart contracts to perform \"smarter\" decisions by using AI or\nmachine learning (ML) models has only been considered on the conceptual level\nso far. It remained open, how such AI-enabled smart contracts could be\nimplemented in a robust way for real-world applications. Therefore, in this\npaper a new, enterprise-class implementation of AI-enabled smart contracts is\npresented and first insights regarding its feasibility are discussed.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 20:21:01 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Brune", "Philipp", "", "Neu-Ulm University of Applied Sciences, Neu-Ulm,\n  Germany"]]}, {"id": "2003.10074", "submitter": "Yuan Lu", "authors": "Yuan Lu, Qiang Tang, Guiling Wang", "title": "Dragoon: Private Decentralized HITs Made Practical", "comments": "small differences from a version accepted to appear in ICDCS 2020 (to\n  fix a minor bug)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid popularity of blockchain, decentralized human intelligence\ntasks (HITs) are proposed to crowdsource human knowledge without relying on\nvulnerable third-party platforms. However, the inherent limits of blockchain\ncause decentralized HITs to face a few \"new\" challenges. For example, the\nconfidentiality of solicited data turns out to be the sine qua non, though it\nwas an arguably dispensable property in the centralized setting. To ensure the\n\"new\" requirement of data privacy, existing decentralized HITs use generic\nzero-knowledge proof frameworks (e.g. SNARK), but scarcely perform well in\npractice, due to the inherently expensive cost of generality.\n  We present a practical decentralized protocol for HITs, which also achieves\nthe fairness between requesters and workers. At the core of our contributions,\nwe avoid the powerful yet highly-costly generic zk-proof tools and propose a\nspecial-purpose scheme to prove the quality of encrypted data. By various\nnon-trivial statement reformations, proving the quality of encrypted data is\nreduced to efficient verifiable decryption, thus making decentralized HITs\npractical. Along the way, we rigorously define the ideal functionality of\ndecentralized HITs and then prove the security due to the ideal-real paradigm.\n  We further instantiate our protocol to implement a system called Dragoon, an\ninstance of which is deployed atop Ethereum to facilitate an image annotation\ntask used by ImageNet. Our evaluations demonstrate its practicality: the\non-chain handling cost of Dragoon is even less than the handling fee of\nAmazon's Mechanical Turk for the same ImageNet HIT.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 04:20:26 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 17:15:06 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 18:41:37 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Lu", "Yuan", ""], ["Tang", "Qiang", ""], ["Wang", "Guiling", ""]]}, {"id": "2003.10082", "submitter": "Th\\'eo Taburet", "authors": "Th\\'eo Taburet, Patrick Bas, Wadih Sawaya, Remi Cogranne", "title": "JPEG Steganography and Synchronization of DCT Coefficients for a Given\n  Development Pipeline", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short paper proposes to use the statistical analysis of the correlation\nbetween DCT coefficients to design a new synchronization strategy that can be\nused for cost-based steganographic schemes in the JPEG domain. First, an\nanalysis is performed on the covariance matrix of DCT coefficients of\nneighboring blocks after a development similar to the one used to generate\nBossBase. This analysis exhibits groups of uncorrelated coefficients: 4 groups\nper block and 2 groups of uncorrelated diagonal neighbors together with groups\nof mutually correlated coefficients groups of 6 coefficients per blocs and 8\ncoefficients between 2 adjacent blocks. Using the uncorrelated groups, an\nembedding scheme can be designed using only 8 disjoint lattices. The cost map\nfor each lattice is updated firstly by using an implicit underlying Gaussian\ndistribution with a variance directly computed from the embedding costs, and\nsecondly by deriving conditional distributions from multivariate distributions.\nThe covariance matrix of these distributions takes into account both the\ncorrelations exhibited by the analysis of the covariance matrix and the\nvariance derived from the cost. This synchronization scheme enables to obtain a\ngain of PE of 5% at QF 95 for an embedding rate close to 0.3 bnzac coefficient\nusing DCTR feature sets.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 04:52:21 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 00:45:37 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Taburet", "Th\u00e9o", ""], ["Bas", "Patrick", ""], ["Sawaya", "Wadih", ""], ["Cogranne", "Remi", ""]]}, {"id": "2003.10118", "submitter": "Benjamin Smith", "authors": "Daniel Bernstein (UIC CS), Luca de Feo, Antonin Leroux (DGA, GRACE),\n  Benjamin Smith (GRACE, X-DEP-INFO)", "title": "Faster computation of isogenies of large prime degree", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $\\mathcal{E}/\\mathbb{F}_q$ be an elliptic curve, and $P$ a point in\n$\\mathcal{E}(\\mathbb{F}_q)$ of prime order $\\ell$. V\\'elu's formulae let us\ncompute a quotient curve $\\mathcal{E}' = \\mathcal{E}/\\langle{P}\\rangle$ and\nrational maps defining a quotient isogeny $\\phi: \\mathcal{E} \\to \\mathcal{E}'$\nin $\\tilde{O}(\\ell)$ $\\mathbb{F}_q$-operations, where the $\\tilde{O}$ is\nuniform in $q$.This article shows how to compute $\\mathcal{E}'$, and $\\phi(Q)$\nfor $Q$ in $\\mathcal{E}(\\mathbb{F}_q)$, using only $\\tilde{O}(\\sqrt{\\ell})$\n$\\mathbb{F}_q$-operations, where the $\\tilde{O}$ is again uniform in $q$.As an\napplication, this article speeds up some computations used in the isogeny-based\ncryptosystems CSIDH and CSURF.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 08:01:11 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Bernstein", "Daniel", "", "UIC CS"], ["de Feo", "Luca", "", "DGA, GRACE"], ["Leroux", "Antonin", "", "DGA, GRACE"], ["Smith", "Benjamin", "", "GRACE, X-DEP-INFO"]]}, {"id": "2003.10128", "submitter": "Yi-Shan Lin", "authors": "Wei-Kang Fu, Yi-Shan Lin, Giovanni Campagna, De-Yi Tsai, Chun-Ting\n  Liu, Chung-Huan Mei, Edward Y. Chang, Monica S. Lam, Shih-Wei Liao", "title": "Soteria: A Provably Compliant User Right Manager Using a Novel Two-Layer\n  Blockchain Technology", "comments": "12 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Soteria is a user right management system designed to safeguard user-data\nprivacy in a transparent and provable manner in compliance to regulations such\nas GDPR and CCPA. Soteria represents user data rights as formal executable\nsharing agreements, which can automatically be translated into a human readable\nform and enforced as data are queried. To support revocation and to prove\ncompliance, an indelible, audited trail of the hash of data access and sharing\nagreements are stored on a two-layer distributed ledger. The main chain ensures\npartition tolerance and availability (PA) properties while side chains ensure\nconsistency and availability (CA), thus providing the three properties of the\nCAP (consistency, availability, and partition tolerance) theorem. Besides\ndepicting the two-layer architecture of Soteria, this paper evaluates\nrepresentative consensus protocols and reports performance statistics.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 08:26:54 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 04:31:54 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Fu", "Wei-Kang", ""], ["Lin", "Yi-Shan", ""], ["Campagna", "Giovanni", ""], ["Tsai", "De-Yi", ""], ["Liu", "Chun-Ting", ""], ["Mei", "Chung-Huan", ""], ["Chang", "Edward Y.", ""], ["Lam", "Monica S.", ""], ["Liao", "Shih-Wei", ""]]}, {"id": "2003.10325", "submitter": "Antoine Boutet", "authors": "Claude Rosin Ngueveu (UQAM), Antoine Boutet (PRIVATICS), Carole\n  Frindel (CREATIS), S\\'ebastien Gambs (UQAM), Th\\'eo Jourdan (CREATIS,\n  PRIVATICS), Claude Rosin", "title": "DYSAN: Dynamically sanitizing motion sensor data against sensitive\n  inferences through adversarial networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the widespread adoption of the quantified self movement, an increasing\nnumber of users rely on mobile applications to monitor their physical activity\nthrough their smartphones. Granting to applications a direct access to sensor\ndata expose users to privacy risks. Indeed, usually these motion sensor data\nare transmitted to analytics applications hosted on the cloud leveraging\nmachine learning models to provide feedback on their health to users. However,\nnothing prevents the service provider to infer private and sensitive\ninformation about a user such as health or demographic attributes.In this\npaper, we present DySan, a privacy-preserving framework to sanitize motion\nsensor data against unwanted sensitive inferences (i.e., improving privacy)\nwhile limiting the loss of accuracy on the physical activity monitoring (i.e.,\nmaintaining data utility). To ensure a good trade-off between utility and\nprivacy, DySan leverages on the framework of Generative Adversarial Network\n(GAN) to sanitize the sensor data. More precisely, by learning in a competitive\nmanner several networks, DySan is able to build models that sanitize motion\ndata against inferences on a specified sensitive attribute (e.g., gender) while\nmaintaining a high accuracy on activity recognition. In addition, DySan\ndynamically selects the sanitizing model which maximize the privacy according\nto the incoming data. Experiments conducted on real datasets demonstrate that\nDySan can drasticallylimit the gender inference to 47% while only reducing the\naccuracy of activity recognition by 3%.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 15:16:43 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 13:57:46 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Ngueveu", "Claude Rosin", "", "UQAM"], ["Boutet", "Antoine", "", "PRIVATICS"], ["Frindel", "Carole", "", "CREATIS"], ["Gambs", "S\u00e9bastien", "", "UQAM"], ["Jourdan", "Th\u00e9o", "", "CREATIS,\n  PRIVATICS"], ["Rosin", "Claude", ""]]}, {"id": "2003.10360", "submitter": "Jos\\'e Antonio Perusqu\\'ia Cort\\'es", "authors": "Jos\\'e A. Perusqu\\'ia, Jim E. Griffin and Cristiano Villa", "title": "Bayesian Models Applied to Cyber Security Anomaly Detection Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber security is an important concern for all individuals, organisations and\ngovernments globally. Cyber attacks have become more sophisticated, frequent\nand dangerous than ever, and traditional anomaly detection methods have been\nproved to be less effective when dealing with these new classes of cyber\nthreats. In order to address this, both classical and Bayesian models offer a\nvalid and innovative alternative to the traditional signature-based methods,\nmotivating the increasing interest in statistical research that it has been\nobserved in recent years. In this review we provide a description of some\ntypical cyber security challenges, typical types of data and statistical\nmethods, paying special attention to Bayesian approaches for these problems.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 16:26:13 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 14:59:47 GMT"}, {"version": "v3", "created": "Wed, 3 Mar 2021 12:09:31 GMT"}, {"version": "v4", "created": "Thu, 3 Jun 2021 23:04:16 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Perusqu\u00eda", "Jos\u00e9 A.", ""], ["Griffin", "Jim E.", ""], ["Villa", "Cristiano", ""]]}, {"id": "2003.10402", "submitter": "V\\'ictor Mayoral Vilches", "authors": "V\\'ictor Mayoral-Vilches, Nuria Garc\\'ia-Maestro, McKenna Towers and\n  Endika Gil-Uriarte", "title": "DevSecOps in Robotics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quality in software is often understood as \"execution according to design\npurpose\" whereas security means that \"software will not put data or computing\nsystems at risk of unauthorized access.\" There seems to be a connection between\nthese two aspects but, how do we integrate both of them in the robotics\ndevelopment cycle? In this article we introduce DevSecOps in Robotics, a set of\nbest practices designed to help roboticists implant security deep in the heart\nof their development and operations processes. First, we briefly describe\nDevOps, introduce the value added with DevSecOps and describe and illustrate\nhow these practices may be implemented in the robotics field. We finalize with\na discussion on the relationship between security, quality and safety, open\nproblems and future research questions.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 17:25:13 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 14:38:08 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Mayoral-Vilches", "V\u00edctor", ""], ["Garc\u00eda-Maestro", "Nuria", ""], ["Towers", "McKenna", ""], ["Gil-Uriarte", "Endika", ""]]}, {"id": "2003.10440", "submitter": "Yang Li", "authors": "Lei Wang, Zhaoyang Qu, Yang Li, Kewei Hu, Jian Sun, Kai Xue and\n  Mingshi Cui", "title": "Method for Extracting Patterns of Coordinated Network Attacks on\n  Electric Power CPS based on Temporal-Topological Correlation", "comments": "Accepted by IEEE Access", "journal-ref": "IEEE Access 8 (2020) 57260-57272", "doi": "10.1109/ACCESS.2020.2982057", "report-no": null, "categories": "cs.CR cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the analysis of coordinated network attacks on electric power\ncyber-physical system (CPS), it is difficult to restore the complete attack\npath, and the intent of the attack cannot be identified automatically. A method\nis therefore proposed for the extracting patterns of coordinated network\nattacks on electric power CPS based on temporal-topological correlation. First,\nthe attack events are aggregated according to the alarm log of the cyber space,\nand a temporal-causal Bayesian network-based cyber attack recognition algorithm\nis proposed to parse out the cyber attack sequences of the same attacker. Then,\naccording to the characteristic curves of different attack measurement data in\nphysical space, a combination of physical attack event criteria algorithm is\ndesigned to distinguish the types of physical attack events. Finally, physical\nattack events and cyber attack sequences are matched via temporal-topological\ncorrelation, frequent patterns of attack sequences are extracted, and hidden\nmulti-step attack patterns are found from scattered grid measurement data and\ninformation from alarm logs. The effectiveness and efficiency of the proposed\nmethod are verified by the testbed at Mississippi State University.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 15:00:35 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Wang", "Lei", ""], ["Qu", "Zhaoyang", ""], ["Li", "Yang", ""], ["Hu", "Kewei", ""], ["Sun", "Jian", ""], ["Xue", "Kai", ""], ["Cui", "Mingshi", ""]]}, {"id": "2003.10478", "submitter": "Abderrahmen Trichili", "authors": "Ivan Vybornyi, Abderrahmen Trichili, Mohamed-Slim Alouini", "title": "Backflash Light as a Security Vulnerability in Quantum Key Distribution\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Based on the fundamental rules of quantum mechanics, two communicating\nparties can generate and share a secret random key that can be used to encrypt\nand decrypt messages sent over an insecure channel. This process is known as\nquantum key distribution (QKD). Contrary to classical encryption schemes, the\nsecurity of a QKD system does not depend on the computational complexity of\nspecific mathematical problems. However, QKD systems can be subject to\ndifferent kinds of attacks, exploiting engineering and technical imperfections\nof the components forming the systems. Here, we review the security\nvulnerabilities of QKD. We mainly focus on a particular effect known as\nbackflash light, which can be a source of eavesdropping attacks. We equally\nhighlight the methods for quantifying backflash emission and the different ways\nto mitigate this effect.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 18:23:12 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Vybornyi", "Ivan", ""], ["Trichili", "Abderrahmen", ""], ["Alouini", "Mohamed-Slim", ""]]}, {"id": "2003.10486", "submitter": "Jovonni Pharr", "authors": "Jovonni L. Pharr", "title": "AfricaOS: Using a distributed, proposal-based, replicated state machine\n  towards liberation from the Berlin Conference of 1885", "comments": "v0.0.1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Berlin Conference of 1885 has influenced the way native Africans, and the\nAfrican Diaspora live their daily lives. France contractually controls several\nresources generated by the continent of Africa. Herein lies a technical\nproposal to free Africa from the financial and economic agreements coerced upon\nthe continent over a century ago by utilizing decentralized collaboration\nthrough advanced technology. AfricaOS (AOS) aims to provide a philosophical,\nand fundamental framework for implementing a simple, distributed, collaborative\ncomputer for agreement amongst peers. The work also demonstrates an algebra\nover transactions, use of the protocol for privatization, a method for\ntokenizing barter economies, and methods to design mechanisms for use in\nimplementing protocol behavior.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 18:34:52 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Pharr", "Jovonni L.", ""]]}, {"id": "2003.10513", "submitter": "Patrick Schaumont", "authors": "Bilgiday Yuce, Patrick Schaumont, Marc Witteman", "title": "Fault Attacks on Secure Embedded Software: Threats, Design and\n  Evaluation", "comments": "17 pages, 6 figures, 4 tables, preprint", "journal-ref": "J Hardw Syst Secur 2, 111-130 (2018)", "doi": "10.1007/s41635-018-0038-1", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedded software is developed under the assumption that hardware execution\nis always correct. Fault attacks break and exploit that assumption. Through the\ncareful introduction of targeted faults, an adversary modifies the control-flow\nor data-flow integrity of software. The modified program execution is then\nanalyzed and used as a source of information leakage, or as a mechanism for\nprivilege escalation. Due to the increasing complexity of modern embedded\nsystems, and due to the difficulty of guaranteeing correct hardware execution\neven under a weak adversary, fault attacks are a growing threat. For example,\nthe assumption that an adversary has to be close to the physical execution of\nsoftware, in order to inject an exploitable fault into hardware, has repeatedly\nbeen shown to be incorrect. This article is a review on hardware-based fault\nattacks on software, with emphasis on the context of embedded systems. We\npresent a detailed discussion of the anatomy of a fault attack, and we make a\nreview of fault attack evaluation techniques. The paper emphasizes the\nperspective from the attacker, rather than the perspective of countermeasure\ndevelopment. However, we emphasize that improvements to countermeasures often\nbuild on insight into the attacks.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 19:51:55 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Yuce", "Bilgiday", ""], ["Schaumont", "Patrick", ""], ["Witteman", "Marc", ""]]}, {"id": "2003.10546", "submitter": "Hyunji Chung", "authors": "Hyunji Chung, Jungheum Park, Sangjin Lee", "title": "Forensic Analysis of Residual Information in Adobe PDF Files", "comments": "11 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, as electronic files include personal records and business\nactivities, these files can be used as important evidences in a digital\nforensic investigation process. In general, the data that can be verified using\nits own application programs is largely used in the investigation of document\nfiles. However, in the case of the PDF file that has been largely used at the\npresent time, certain data, which include the data before some modifications,\nexist in electronic document files unintentionally. Because such residual\ninformation may present the writing process of a file, it can be usefully used\nin a forensic viewpoint. This paper introduces why the residual information is\nstored inside the PDF file and explains a way to extract the information. In\naddition, we demonstrate the attributes of PDF files can be used to hide data.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 05:47:05 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Chung", "Hyunji", ""], ["Park", "Jungheum", ""], ["Lee", "Sangjin", ""]]}, {"id": "2003.10560", "submitter": "Xingjian Ding", "authors": "Xingjian Ding, Jianxiong Guo, Deying Li, Weili Wu", "title": "Attract More Miners to Join in Blochchain Construction for Internet of\n  Things", "comments": null, "journal-ref": "IEEE Transactions on Network Science and Engineering 2020", "doi": "10.1109/TNSE.2020.3040446", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The world-changing blockchain technique provides a novel method to establish\na secure, trusted and decentralized system for solving the security and\npersonal privacy problems in Industrial Internet of Things (IIoT) applications.\nThe mining process in blockchain requires miners to solve a proof-of-work\npuzzle, which requires high computational power. However, the lightweight IIoT\ndevices cannot directly participate in the mining process due to the limitation\nof power and computational resources. The edge computing service makes it\npossible for IIoT applications to build a blockchain network, in which IIoT\ndevices purchase computational resources from edge servers and thus can offload\ntheir computational tasks. The amount of computational resource purchased by\nIIoT devices depends on how many profits they can get in the mining process,\nand will directly affect the security of the blockchain network. In this paper,\nwe investigate the incentive mechanism for the blockchain platform to attract\nIIoT devices to purchase more computational power from edge servers to\nparticipate in the mining process, thereby building a more secure blockchain\nnetwork. We model the interaction between the blockchain platform and IIoT\ndevices as a two-stage Stackelberg game, where the blockchain platform act as\nthe leader, and IIoT devices act as followers. We analyze the existence and\nuniqueness of the Stackelberg equilibrium, and propose an efficient algorithm\nto compute the Stackelberg equilibrium point. Furthermore, we evaluate the\nperformance of our algorithm through extensive simulations, and analyze the\nstrategies of blockchain platform and IIoT devices under different situations.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 21:57:22 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 20:33:25 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Ding", "Xingjian", ""], ["Guo", "Jianxiong", ""], ["Li", "Deying", ""], ["Wu", "Weili", ""]]}, {"id": "2003.10577", "submitter": "Alireza Nooraiepour", "authors": "Alireza Nooraiepour and Sina Rezaei Aghdam", "title": "Learning End-to-End Codes for the BPSK-constrained Gaussian Wiretap\n  Channel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Finite-length codes are learned for the Gaussian wiretap channel in an\nend-to-end manner assuming that the communication parties are equipped with\ndeep neural networks (DNNs), and communicate through binary phase-shift keying\n(BPSK) modulation scheme. The goal is to find codes via DNNs which allow a pair\nof transmitter and receiver to communicate reliably and securely in the\npresence of an adversary aiming at decoding the secret messages. Following the\ninformation-theoretic secrecy principles, the security is evaluated in terms of\nmutual information utilizing a deep learning tool called MINE (mutual\ninformation neural estimation). System performance is evaluated for different\nDNN architectures, designed based on the existing secure coding schemes, at the\ntransmitter. Numerical results demonstrate that the legitimate parties can\nindeed establish a secure transmission in this setting as the learned codes\nachieve points on almost the boundary of the equivocation region.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 23:26:36 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Nooraiepour", "Alireza", ""], ["Aghdam", "Sina Rezaei", ""]]}, {"id": "2003.10595", "submitter": "Liwei Song", "authors": "Liwei Song, Prateek Mittal", "title": "Systematic Evaluation of Privacy Risks of Machine Learning Models", "comments": "Accepted by USENIX Security 2021, code is available at\n  https://github.com/inspire-group/membership-inference-evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are prone to memorizing sensitive data, making them\nvulnerable to membership inference attacks in which an adversary aims to guess\nif an input sample was used to train the model. In this paper, we show that\nprior work on membership inference attacks may severely underestimate the\nprivacy risks by relying solely on training custom neural network classifiers\nto perform attacks and focusing only on the aggregate results over data\nsamples, such as the attack accuracy. To overcome these limitations, we first\npropose to benchmark membership inference privacy risks by improving existing\nnon-neural network based inference attacks and proposing a new inference attack\nmethod based on a modification of prediction entropy. We also propose\nbenchmarks for defense mechanisms by accounting for adaptive adversaries with\nknowledge of the defense and also accounting for the trade-off between model\naccuracy and privacy risks. Using our benchmark attacks, we demonstrate that\nexisting defense approaches are not as effective as previously reported.\n  Next, we introduce a new approach for fine-grained privacy analysis by\nformulating and deriving a new metric called the privacy risk score. Our\nprivacy risk score metric measures an individual sample's likelihood of being a\ntraining member, which allows an adversary to identify samples with high\nprivacy risks and perform attacks with high confidence. We experimentally\nvalidate the effectiveness of the privacy risk score and demonstrate that the\ndistribution of privacy risk score across individual samples is heterogeneous.\nFinally, we perform an in-depth investigation for understanding why certain\nsamples have high privacy risks, including correlations with model sensitivity,\ngeneralization error, and feature embeddings. Our work emphasizes the\nimportance of a systematic and rigorous evaluation of privacy risks of machine\nlearning models.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 00:53:53 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 18:56:31 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Song", "Liwei", ""], ["Mittal", "Prateek", ""]]}, {"id": "2003.10637", "submitter": "Ruixuan Liu", "authors": "Ruixuan Liu, Yang Cao, Masatoshi Yoshikawa, Hong Chen", "title": "FedSel: Federated SGD under Local Differential Privacy with Top-k\n  Dimension Selection", "comments": "18 pages, to be published in DASFAA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As massive data are produced from small gadgets, federated learning on mobile\ndevices has become an emerging trend. In the federated setting, Stochastic\nGradient Descent (SGD) has been widely used in federated learning for various\nmachine learning models. To prevent privacy leakages from gradients that are\ncalculated on users' sensitive data, local differential privacy (LDP) has been\nconsidered as a privacy guarantee in federated SGD recently. However, the\nexisting solutions have a dimension dependency problem: the injected noise is\nsubstantially proportional to the dimension $d$. In this work, we propose a\ntwo-stage framework FedSel for federated SGD under LDP to relieve this problem.\nOur key idea is that not all dimensions are equally important so that we\nprivately select Top-k dimensions according to their contributions in each\niteration of federated SGD. Specifically, we propose three private dimension\nselection mechanisms and adapt the gradient accumulation technique to stabilize\nthe learning process with noisy updates. We also theoretically analyze privacy,\naccuracy and time complexity of FedSel, which outperforms the state-of-the-art\nsolutions. Experiments on real-world and synthetic datasets verify the\neffectiveness and efficiency of our framework.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 03:31:21 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Liu", "Ruixuan", ""], ["Cao", "Yang", ""], ["Yoshikawa", "Masatoshi", ""], ["Chen", "Hong", ""]]}, {"id": "2003.10639", "submitter": "I-Ta Lee", "authors": "I-Ta Lee, Manish Marwah, and Martin Arlitt", "title": "Attention-Based Self-Supervised Feature Learning for Security Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While applications of machine learning in cyber-security have grown rapidly,\nmost models use manually constructed features. This manual approach is\nerror-prone and requires domain expertise. In this paper, we design a\nself-supervised sequence-to-sequence model with attention to learn an embedding\nfor data routinely used in cyber-security applications. The method is validated\non two real world public data sets. The learned features are used in an anomaly\ndetection model and perform better than learned features from baseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 03:37:02 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Lee", "I-Ta", ""], ["Marwah", "Manish", ""], ["Arlitt", "Martin", ""]]}, {"id": "2003.10712", "submitter": "Tomoyuki Morimae", "authors": "Tomoyuki Morimae", "title": "Information-theoretically-sound non-interactive classical verification\n  of quantum computing with trusted center", "comments": "14 pages, no figure", "journal-ref": null, "doi": null, "report-no": "YITP-20-29", "categories": "quant-ph cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The posthoc verification protocol [J. F. Fitzsimons, M. Hajdu{\\v s}ek, and T.\nMorimae, Physical Review Letters {\\bf120}, 040501 (2018)] enables an\ninformation-theoretically-sound non-interactive verification of quantum\ncomputing, but the message from the prover to the verifier is quantum and the\nverifier has to do single-qubit measurements. The Mahadev protocol removes\nthese quantum parts, but the soundness becomes the computational one. In this\npaper, we construct an information-theoretically-sound non-interactive\nclassical verification protocol for quantum computing with a trusted center.\nThe trusted center sends random BB84 states to the prover, and the classical\ndescriptions of these BB84 states to the verifier. The messages from the center\nto the prover and the verifier are independent of the instance. By slightly\nmodifying our protocol, we also construct a non-interactive statistical\nzero-knowledge proof system for QMA with the trusted center.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 08:18:16 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Morimae", "Tomoyuki", ""]]}, {"id": "2003.10745", "submitter": "Kashyap Thimmaraju", "authors": "Kashyap Thimmaraju and Stefan Schmid", "title": "Towards Fine-Grained Billing For Cloud Networking", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit multi-tenant network virtualization in data centers, and make the\ncase for tenant-specific virtual switches. In particular, tenant-specific\nvirtual switches allow cloud providers to extend fine-grained billing (known,\ne.g., from serverless architectures) to the network, accounting not only for\nIO, but also CPU or energy. We sketch an architecture and present economical\nmotivation and recent technological enablers. We also find that virtual\nswitches today do not offer sufficient multi-tenancy and can introduce\nartificial performance bottlenecks, e.g., in load balancers. We conclude by\ndiscussing additional use cases for tentant-specific switches.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 10:06:06 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Thimmaraju", "Kashyap", ""], ["Schmid", "Stefan", ""]]}, {"id": "2003.10830", "submitter": "Johann Knechtel", "authors": "Satwik Patnaik, Mohammed Ashraf, Ozgur Sinanoglu, Johann Knechtel", "title": "Obfuscating the Interconnects: Low-Cost and Resilient Full-Chip Layout\n  Camouflaging", "comments": "arXiv admin note: text overlap with arXiv:1711.05284", "journal-ref": null, "doi": "10.1109/TCAD.2020.2981034", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Layout camouflaging can protect the intellectual property of modern circuits.\nMost prior art, however, incurs excessive layout overheads and necessitates\ncustomization of active-device manufacturing processes, i.e., the\nfront-end-of-line (FEOL). As a result, camouflaging has typically been applied\nselectively, which can ultimately undermine its resilience. Here, we propose a\nlow-cost and generic scheme---full-chip camouflaging can be finally realized\nwithout reservations. Our scheme is based on obfuscating the interconnects,\ni.e., the back-end-of-line (BEOL), through design-time handling for real and\ndummy wires and vias. To that end, we implement custom, BEOL-centric\nobfuscation cells, and develop a CAD flow using industrial tools. Our scheme\ncan be applied to any design and technology node without FEOL-level\nmodifications. Considering its BEOL-centric nature, we advocate applying our\nscheme in conjunction with split manufacturing, to furthermore protect against\nuntrusted fabs. We evaluate our scheme for various designs at the physical,\nDRC-clean layout level. Our scheme incurs a significantly lower cost than most\nof the prior art. Notably, for fully camouflaged layouts, we observe average\npower, performance, and area overheads of 24.96%, 19.06%, and 32.55%,\nrespectively. We conduct a thorough security study addressing the threats\n(attacks) related to untrustworthy FEOL fabs (proximity attacks) and malicious\nend-users (SAT-based attacks). An empirical key finding is that only\nlarge-scale camouflaging schemes like ours are practically secure against\npowerful SAT-based attacks. Another key finding is that our scheme hinders both\nplacement- and routing-centric proximity attacks; correct connections are\nreduced by 7.47X, and complexity is increased by 24.15X, respectively, for such\nattacks.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 10:40:47 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Patnaik", "Satwik", ""], ["Ashraf", "Mohammed", ""], ["Sinanoglu", "Ozgur", ""], ["Knechtel", "Johann", ""]]}, {"id": "2003.10877", "submitter": "Suat Mercan", "authors": "Suat Mercan, Enes Erdin, Kemal Akkaya", "title": "Improving Transaction Success Rate via Smart Gateway Selection in\n  Cryptocurrency Payment Channel Networks", "comments": "arXiv admin note: text overlap with arXiv:2003.00294", "journal-ref": null, "doi": "10.1109/ICBC48266.2020.9169458", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last decade has experienced a vast interest in Blockchain-based\ncryptocurrencies with a specific focus on the applications of this technology.\nHowever, slow confirmation times of transactions and unforeseeable high fees\nhamper their wide adoption for micro-payments. The idea of establishing payment\nchannel networks is one of the many proposed solutions to address this\nscalability issue where nodes, by utilizing smart contracting, establish\npayment channels between each other and perform off-chain transactions.\nHowever, due to the way these channels are created, both sides have a certain\none-way capacity for making transactions. Consequently, if one sides exceeds\nthis one-way capacity, the channel becomes useless in that particular\ndirection, which causes failures of payments and eventually creates an\nimbalance in the overall network. To keep the payment channel network\nsustainable, in this paper, we aim to increase the overall success rate of\npayments by effectively exploiting the fact that end-users are usually\nconnected to the network at multiple points (i.e., gateways) any of which can\nbe used to initiate the payment. We propose an efficient method for selection\nof the gateway for a user by considering the gateway's inbound and outbound\npayment traffic ratio. We then augment this proposed method with split payment\ncapability to further increase success rate especially for large transactions.\nThe evaluation of the proposed method shows that compared to greedy and\nmaxflow-based approaches, we can achieve much higher success rates, which are\nfurther improved with split payments.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 18:17:07 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Mercan", "Suat", ""], ["Erdin", "Enes", ""], ["Akkaya", "Kemal", ""]]}, {"id": "2003.10933", "submitter": "Zhuo Ma", "authors": "Yang Liu, Zhuo Ma, Ximeng Liu, Jian Liu, Zhongyuan Jiang, Jianfeng Ma,\n  Philip Yu, Kui Ren", "title": "Learn to Forget: Memorization Elimination for Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, with the rapidly exploding amount of user data, more companies\nchoose to train various business-specified machine learning models, especially\nneural networks, to improve service quality. Nevertheless, the current machine\nlearning application is still a one-way trip for the user data. As long as\nusers contribute their data, there is no way to retreat the contribution. Such\nan irreversible setting has two potential risks: 1) from a legislative point of\nview, many national regulations emphasize that users should have the right to\nremove their personal data; 2) from a security point of view, the unintended\nmemorization of a neural network increases the possibility of an adversary to\nextract user's sensitive information. To this end, memorization elimination for\nmachine learning models becomes a popular research topic.\n  Considering that there is no uniform indicator to evaluate a memorization\nelimination method, we explore the concept of membership inference and define a\nnovel indicator, called forgetting rate. It well describes the transformation\nrate of the eliminated data from \"memorized\" to \"unknown\" after conducting\nmemorization elimination. Furthermore, we propose Forsaken, a method that\nallows users to eliminate the unintended memorization of their private data\nfrom a trained neural network. The unintended memorization here is formed by\nthe out-of-distribution but sensitive data inadvertently uploaded by users.\nCompared to prior work, our method avoids retraining, achieves higher\nforgetting rate, and causes less accuracy loss through a trainable dummy\ngradient generator.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 15:46:38 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2021 12:29:00 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Liu", "Yang", ""], ["Ma", "Zhuo", ""], ["Liu", "Ximeng", ""], ["Liu", "Jian", ""], ["Jiang", "Zhongyuan", ""], ["Ma", "Jianfeng", ""], ["Yu", "Philip", ""], ["Ren", "Kui", ""]]}, {"id": "2003.11061", "submitter": "Ahmad Shabani Baghani", "authors": "Ahmad Shabani Baghani, Sonbol Rahimpour, and Majid Khabbazian", "title": "The DAO Induction Attack Against the RPL-based Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RPL is the emerging routing standard for low power and lossy networks (LLNs).\nLLN is a key component of the Internet of Things (IoT), hence its security is\nimperative for the age of IoT. In this work, we present the DAO induction\nattack, a novel attack against RPL. In this attack, a malicious insider or a\ncompromised node periodically increments its DTSN number. Each such increment\ncan trigger/induce a large number of control message transmissions in the\nnetwork. We show that this degrades the network performance in terms of\nend-to-end latency, packet loss ratio, and power consumption. To mitigate, we\npropose a lightweight solution to detect the DAO induction attack. Our solution\nimposes nearly no overhead on IoT devices, which is important as these devices\nare typically constrained in terms of power, memory and processing.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 18:31:42 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Baghani", "Ahmad Shabani", ""], ["Rahimpour", "Sonbol", ""], ["Khabbazian", "Majid", ""]]}, {"id": "2003.11110", "submitter": "Junfeng Guo", "authors": "Junfeng Guo, Ting Wang, Cong Liu", "title": "PoisHygiene: Detecting and Mitigating Poisoning Attacks in Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The black-box nature of deep neural networks (DNNs) facilitates attackers to\nmanipulate the behavior of DNN through data poisoning. Being able to detect and\nmitigate poisoning attacks, typically categorized into backdoor and adversarial\npoisoning (AP), is critical in enabling safe adoption of DNNs in many\napplication domains. Although recent works demonstrate encouraging results on\ndetection of certain backdoor attacks, they exhibit inherent limitations which\nmay significantly constrain the applicability. Indeed, no technique exists for\ndetecting AP attacks, which represents a harder challenge given that such\nattacks exhibit no common and explicit rules while backdoor attacks do (i.e.,\nembedding backdoor triggers into poisoned data). We believe the key to detect\nand mitigate AP attacks is the capability of observing and leveraging essential\npoisoning-induced properties within an infected DNN model. In this paper, we\npresent PoisHygiene, the first effective and robust detection and mitigation\nframework against AP attacks. PoisHygiene is fundamentally motivated by Dr.\nErnest Rutherford's story (i.e., the 1908 Nobel Prize winner), on observing the\nstructure of atom through random electron sampling.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 20:55:08 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 20:03:54 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Guo", "Junfeng", ""], ["Wang", "Ting", ""], ["Liu", "Cong", ""]]}, {"id": "2003.11170", "submitter": "Nirav Ajmeri", "authors": "Nirav Ajmeri (1), Shubham Goyal (2), Munindar P. Singh (1) ((1) North\n  Carolina State University, (2) Amazon)", "title": "Norms and Sanctions as a Basis for Promoting Cybersecurity Practices", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many cybersecurity breaches occur due to users not following good\ncybersecurity practices, chief among them being regulations for applying\nsoftware patches to operating systems, updating applications, and maintaining\nstrong passwords.\n  We capture cybersecurity expectations on users as norms. We empirically\ninvestigate sanctioning mechanisms in promoting compliance with those norms as\nwell as the detrimental effect of sanctions on the ability of users to complete\ntheir work. We realize these ideas in a game that emulates the decision making\nof workers in a research lab.\n  Through a human-subject study, we find that whereas individual sanctions are\nmore effective than group sanctions in achieving compliance and less\ndetrimental on the ability of users to complete their work, individual\nsanctions offer significantly lower resilience especially for organizations\ncomprising risk seekers. Our findings have implications for workforce training\nin cybersecurity.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 01:07:06 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Ajmeri", "Nirav", ""], ["Goyal", "Shubham", ""], ["Singh", "Munindar P.", ""]]}, {"id": "2003.11231", "submitter": "Mahmood Yousefi-Azar", "authors": "Mahmood Yousefi-Azar, Mohamed-Ali Kaafar, Andy Walker", "title": "Unsupervised Learning for security of Enterprise networks by\n  micro-segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Micro-segmentation is a network security technique that requires delivering\nservices for each unique segment. To do so, the first stage is defining these\nunique segments (a.k.a security groups) and then initializing policy-driven\nsecurity controls. In this paper, we propose an unsupervised learning technique\nthat covers both the security grouping and policy creation. For the network\nasset grouping, we develop a distance-based machine learning algorithm using\nthe dynamic behavior of the assets. That is, after observing the entire network\nlogs, our unsupervised learning algorithm suggests partitioning network assets\ninto the groups. A key point of this un-supervised technique is that the\ngrouping is only generated during the training phase and remains valid during\nthe testing phase. The outcome of the grouping stage is then fed into the rules\n(security policies) creation stage enabling to establish the security groups as\nthe lowest granularity of firewall rules. We conducted both quantitative and\nqualitative experiments and demonstrate the good performance of our network\nmicro-segmentation approach. We further developed a prototype to validate the\nrun-time performance of our approach at scale in a real-world environment. The\nhyper-parameters of our approach provides users with a flexible model to be\nfine-tuned to adapt very easily with the enterprise's security governance.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 06:16:11 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Yousefi-Azar", "Mahmood", ""], ["Kaafar", "Mohamed-Ali", ""], ["Walker", "Andy", ""]]}, {"id": "2003.11286", "submitter": "Emmanuel Fouotsa Fouemma", "authors": "Narcisse Bang Mbang and Emmanuel Fouotsa and Celestin Lele", "title": "Parallel Computation of Optimal Ate Cryptographic Pairings at the $128$,\n  $192$ and $256$-bit security levels using elliptic net algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CR math.NT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Efficient computations of pairings with Miller Algorithm have recently\nreceived a great attention due to the many applications in cryptography. In\nthis work, we give formulae for the optimal Ate pairing in terms of elliptic\nnets associated to twisted Barreto-Naehrig (BN) curve, Barreto-Lynn-Scott(BLS)\ncurves and Kachisa-Schaefer-Scott(KSS) curves considered at the $128$, $192$\nand $256$-bit security levels, and Scott-Guillevic curve with embedding degree\n$54$. We show how to parallelize the computation of these pairings when the\nelliptic net algorithm instead is used and we obtain except in the case of\nKachisa-Schaefer-Scott(KSS) curves considered at the $256$-bit security level,\nmore efficient theoretical results with $8$ processors compared to the case\nwhere the Miller algorithm is used. This work still confirms that $BLS48$\ncurves are the best for pairing-based cryptography at $256$-bit security level\n\\cite{NARDIEFO19}.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 09:19:26 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 21:55:51 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Mbang", "Narcisse Bang", ""], ["Fouotsa", "Emmanuel", ""], ["Lele", "Celestin", ""]]}, {"id": "2003.11323", "submitter": "Javier Del Ser Dr.", "authors": "Alejandro Barredo-Arrieta and Javier Del Ser", "title": "Plausible Counterfactuals: Auditing Deep Learning Classifiers with\n  Realistic Adversarial Examples", "comments": "7 pages, 5 figures. Accepted for its presentation at WCCI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last decade has witnessed the proliferation of Deep Learning models in\nmany applications, achieving unrivaled levels of predictive performance.\nUnfortunately, the black-box nature of Deep Learning models has posed\nunanswered questions about what they learn from data. Certain application\nscenarios have highlighted the importance of assessing the bounds under which\nDeep Learning models operate, a problem addressed by using assorted approaches\naimed at audiences from different domains. However, as the focus of the\napplication is placed more on non-expert users, it results mandatory to provide\nthe means for him/her to trust the model, just like a human gets familiar with\na system or process: by understanding the hypothetical circumstances under\nwhich it fails. This is indeed the angular stone for this research work: to\nundertake an adversarial analysis of a Deep Learning model. The proposed\nframework constructs counterfactual examples by ensuring their plausibility,\ne.g. there is a reasonable probability that a human could generate them without\nresorting to a computer program. Therefore, this work must be regarded as\nvaluable auditing exercise of the usable bounds a certain model is constrained\nwithin, thereby allowing for a much greater understanding of the capabilities\nand pitfalls of a model used in a real application. To this end, a Generative\nAdversarial Network (GAN) and multi-objective heuristics are used to furnish a\nplausible attack to the audited model, efficiently trading between the\nconfusion of this model, the intensity and plausibility of the generated\ncounterfactual. Its utility is showcased within a human face classification\ntask, unveiling the enormous potential of the proposed framework.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 11:08:56 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Barredo-Arrieta", "Alejandro", ""], ["Del Ser", "Javier", ""]]}, {"id": "2003.11340", "submitter": "Kashyap Thimmaraju", "authors": "Kashyap Thimmaraju, Julian Fietkau and Fatemeh Ganji", "title": "Towards an Insightful Computer Security Seminar", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe our experience in designing and evaluating our\ngraduate level computer security seminar course. In particular, our seminar is\ndesigned with two goals in mind. First, to instil critical thinking by teaching\ngraduate students how to read, review and present scientific literature.\nSecond, to learn about the state-of-the-art in computer security and privacy\nresearch by reviewing proceedings from one of the top four security and privacy\nconferences including IEEE Symposium on Security and Privacy (Oakland SP),\nUSENIX Security, Network and Distributed System Security Symposium (NDSS) and\nACM Conference on Computer and Communications Security (CCS). The course\nentails each student to i) choose a specific technical session from the most\nrecent conference, ii) review and present three papers from the chosen session\nand iii) analyze the relationship between the chosen papers from the session.\nTo evaluate the course, we designed a set of questions to understand the\nmotivation and decisions behind the students' choices as well as to evaluate\nand improve the quality of the course. Our key insights from the evaluation are\nthe following: The three most popular topics of interest were Privacy, Web\nSecurity and Authentication, ii) 33% of the students chose the sessions based\non the title of papers and iii) when providing an encouraging environment,\nstudents enjoy and engage in discussions.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 11:40:58 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Thimmaraju", "Kashyap", ""], ["Fietkau", "Julian", ""], ["Ganji", "Fatemeh", ""]]}, {"id": "2003.11424", "submitter": "Hamidreza Ehteram", "authors": "Hamidreza Ehteram, Mohammad Taha Toghani, Mohammad Ali Maddah-Ali", "title": "BlockMarkchain: A Secure Decentralized Data Market with a Constant Load\n  on the Blockchain", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop BlockMarkchain, as a secure data market place,\nwhere individual data sellers can exchange certified data with buyers, in a\nsecure environment, without any mutual trust among the parties, and without\ntrusting on a third party, as a mediator. To develop this platform, we rely on\na smart contract, deployed on a secure public blockchain. The main challenges\nhere are to verify the validity of data and to prevent malicious behavior of\nthe parties, while preserving the privacy of the data and taking into account\nthe limited computing and storage resources available on the blockchain. In\nBlockMarkchain, the buyer has the option to dispute the honesty of the seller\nand prove the invalidity of the data to the smart contract. The smart contract\nevaluates the buyer's claim and punishes the dishonest party by forfeiting\nhis/her deposit in favor of the honest party. BlockMarkchain enjoys several\nsalient features including (i) the certified data has never been revealed on\nthe public blockchain, (ii) the size of data posted on the blockchain, the load\nof computation on the blockchain, and the cost of communication with the\nblockchain is constant and negligible, and (iii) the computation cost of\nverifications on the parties is not expensive.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 14:32:11 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Ehteram", "Hamidreza", ""], ["Toghani", "Mohammad Taha", ""], ["Maddah-Ali", "Mohammad Ali", ""]]}, {"id": "2003.11446", "submitter": "Krzysztof Grining", "authors": "Dominik Bojko, Krzysztof Grining, Marek Klonowski", "title": "Probabilistic Counters for Privacy Preserving Data Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic counters are well known tools often used for space-efficient\nset cardinality estimation. In this paper we investigate probabilistic counters\nfrom the perspective of preserving privacy. We use standard, rigid differential\nprivacy notion. The intuition is that the probabilistic counters do not reveal\ntoo much information about individuals, but provide only general information\nabout the population. Thus they can be used safely without violating privacy of\nindividuals. It turned out however that providing a precise, formal analysis of\nprivacy parameters of probabilistic counters is surprisingly difficult and\nneeds advanced techniques and a very careful approach.\n  We demonstrate also that probabilistic counters can be used as a privacy\nprotecion mechanism without any extra randomization. That is, the inherit\nrandomization from the protocol is sufficient for protecting privacy, even if\nthe probabilistic counter is used many times. In particular we present a\nspecific privacy-preserving data aggregation protocol based on a probabilistic\ncounter. Our results can be used for example in performing distributed surveys.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 15:29:27 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Bojko", "Dominik", ""], ["Grining", "Krzysztof", ""], ["Klonowski", "Marek", ""]]}, {"id": "2003.11506", "submitter": "Alberto Sonnino", "authors": "Mathieu Baudet, George Danezis, Alberto Sonnino", "title": "FastPay: High-Performance Byzantine Fault Tolerant Settlement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  FastPay allows a set of distributed authorities, some of which are Byzantine,\nto maintain a high-integrity and availability settlement system for pre-funded\npayments. It can be used to settle payments in a native unit of value\n(crypto-currency), or as a financial side-infrastructure to support retail\npayments in fiat currencies. FastPay is based on Byzantine Consistent Broadcast\nas its core primitive, foregoing the expenses of full atomic commit channels\n(consensus). The resulting system has low-latency for both confirmation and\npayment finality. Remarkably, each authority can be sharded across many\nmachines to allow unbounded horizontal scalability. Our experiments demonstrate\nintra-continental confirmation latency of less than 100ms, making FastPay\napplicable to point of sale payments. In laboratory environments, we achieve\nover 80,000 transactions per second with 20 authorities---surpassing the\nrequirements of current retail card payment networks, while significantly\nincreasing their robustness.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 17:23:29 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 19:50:20 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 11:43:49 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Baudet", "Mathieu", ""], ["Danezis", "George", ""], ["Sonnino", "Alberto", ""]]}, {"id": "2003.11511", "submitter": "Yun William Yu", "authors": "Hyunghoon Cho, Daphne Ippolito, Yun William Yu", "title": "Contact Tracing Mobile Apps for COVID-19: Privacy Considerations and\n  Related Trade-offs", "comments": "12 pages, 1 table, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contact tracing is an essential tool for public health officials and local\ncommunities to fight the spread of novel diseases, such as for the COVID-19\npandemic. The Singaporean government just released a mobile phone app,\nTraceTogether, that is designed to assist health officials in tracking down\nexposures after an infected individual is identified. However, there are\nimportant privacy implications of the existence of such tracking apps. Here, we\nanalyze some of those implications and discuss ways of ameliorating the privacy\nconcerns without decreasing usefulness to public health. We hope in writing\nthis document to ensure that privacy is a central feature of conversations\nsurrounding mobile contact tracing apps and to encourage community efforts to\ndevelop alternative effective solutions with stronger privacy protection for\nthe users. Importantly, though we discuss potential modifications, this\ndocument is not meant as a formal research paper, but instead is a response to\nsome of the privacy characteristics of direct contact tracing apps like\nTraceTogether and an early-stage Request for Comments to the community.\n  Date written: 2020-03-24\n  Minor correction: 2020-03-30\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 17:31:37 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 14:57:49 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Cho", "Hyunghoon", ""], ["Ippolito", "Daphne", ""], ["Yu", "Yun William", ""]]}, {"id": "2003.11663", "submitter": "Arash Atashpendar", "authors": "Arash Atashpendar", "title": "From Information Theory Puzzles in Deletion Channels to Deniability in\n  Quantum Cryptography", "comments": "PhD thesis, 152 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DM cs.IT math.IT quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From the output produced by a memoryless deletion channel with a uniformly\nrandom input of known length $n$, one obtains a posterior distribution on the\nchannel input. The difference between the Shannon entropy of this distribution\nand that of the uniform prior measures the amount of information about the\nchannel input which is conveyed by the output of length $m$. We first\nconjecture on the basis of experimental data that the entropy of the posterior\nis minimized by the constant strings $\\texttt{000}\\ldots$, $\\texttt{111}\\ldots$\nand maximized by the alternating strings $\\texttt{0101}\\ldots$,\n$\\texttt{1010}\\ldots$. We present related combinatorial theorems involving\nbinary (sub/super)-sequences and prove the minimal entropy conjecture for\nsingle and double deletions using clustering techniques. We then prove the\nminimization conjecture in the asymptotic limit using results from hidden word\nstatistics by showing how the analytic-combinatorial methods of Flajolet,\nSzpankowski and Vall\\'ee, relying on generating functions, can be applied to\nresolve the case of fixed output length and $n\\rightarrow\\infty$.\n  Next, we revisit the notion of deniability in quantum key exchange (QKE). We\nintroduce and formalize the notion of coercer-deniable QKE. We then establish a\nconnection between covert communication and deniability to propose DC-QKE, a\nsimple and provably secure construction for coercer-deniable QKE. We relate\ndeniability to fundamental concepts in quantum information theory and suggest a\ngeneric approach based on entanglement distillation for achieving\ninformation-theoretic deniability, followed by an analysis of other closely\nrelated results such as the relation between the impossibility of\nunconditionally secure quantum bit commitment and deniability. Finally, we\npresent an efficient coercion-resistant and quantum-secure voting scheme, based\non fully homomorphic encryption.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 22:20:47 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Atashpendar", "Arash", ""]]}, {"id": "2003.11855", "submitter": "Bowen Zhang", "authors": "Bowen Zhang, Benedetta Tondi, Xixiang Lv and Mauro Barni", "title": "Challenging the adversarial robustness of DNNs based on error-correcting\n  output codes", "comments": "This paper is accepted by Security and Communication Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existence of adversarial examples and the easiness with which they can be\ngenerated raise several security concerns with regard to deep learning systems,\npushing researchers to develop suitable defense mechanisms. The use of networks\nadopting error-correcting output codes (ECOC) has recently been proposed to\ncounter the creation of adversarial examples in a white-box setting. In this\npaper, we carry out an in-depth investigation of the adversarial robustness\nachieved by the ECOC approach. We do so by proposing a new adversarial attack\nspecifically designed for multi-label classification architectures, like the\nECOC-based one, and by applying two existing attacks. In contrast to previous\nfindings, our analysis reveals that ECOC-based networks can be attacked quite\neasily by introducing a small adversarial perturbation. Moreover, the\nadversarial examples can be generated in such a way to achieve high\nprobabilities for the predicted target class, hence making it difficult to use\nthe prediction confidence to detect them. Our findings are proven by means of\nexperimental results obtained on MNIST, CIFAR-10 and GTSRB classification\ntasks.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 12:14:56 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 02:45:39 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Zhang", "Bowen", ""], ["Tondi", "Benedetta", ""], ["Lv", "Xixiang", ""], ["Barni", "Mauro", ""]]}, {"id": "2003.11915", "submitter": "Sebastiaan H\\\"oppner", "authors": "Bart Baesens, Sebastiaan H\\\"oppner, Irene Ortner, and Tim Verdonck", "title": "robROSE: A robust approach for dealing with imbalanced data in fraud\n  detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge when trying to detect fraud is that the fraudulent\nactivities form a minority class which make up a very small proportion of the\ndata set. In most data sets, fraud occurs in typically less than 0.5% of the\ncases. Detecting fraud in such a highly imbalanced data set typically leads to\npredictions that favor the majority group, causing fraud to remain undetected.\nWe discuss some popular oversampling techniques that solve the problem of\nimbalanced data by creating synthetic samples that mimic the minority class. A\nfrequent problem when analyzing real data is the presence of anomalies or\noutliers. When such atypical observations are present in the data, most\noversampling techniques are prone to create synthetic samples that distort the\ndetection algorithm and spoil the resulting analysis. A useful tool for anomaly\ndetection is robust statistics, which aims to find the outliers by first\nfitting the majority of the data and then flagging data observations that\ndeviate from it. In this paper, we present a robust version of ROSE, called\nrobROSE, which combines several promising approaches to cope simultaneously\nwith the problem of imbalanced data and the presence of outliers. The proposed\nmethod achieves to enhance the presence of the fraud cases while ignoring\nanomalies. The good performance of our new sampling technique is illustrated on\nsimulated and real data sets and it is shown that robROSE can provide better\ninsight in the structure of the data. The source code of the robROSE algorithm\nis made freely available.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 16:11:07 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Baesens", "Bart", ""], ["H\u00f6ppner", "Sebastiaan", ""], ["Ortner", "Irene", ""], ["Verdonck", "Tim", ""]]}, {"id": "2003.11936", "submitter": "Kalika Prasad", "authors": "Kalika Prasad and Hrishikesh Mahato", "title": "Cryptography using generalized Fibonacci matrices with Affine-Hill\n  cipher", "comments": "Construction, development and efficiency", "journal-ref": null, "doi": "10.1080/09720529.2020.1838744", "report-no": null, "categories": "cs.CR math.CO math.NT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this article, we have proposed a public key cryptography using Affine-Hill\ncipher with a generalized Fibonacci matrix(called multinacci matrix). Also\nproposed a key establishment(exchange of key matrix $K=Q_{\\lambda}^{k}$ of\norder $\\lambda\\times\\lambda$ for encryption-decryption) scheme with the help of\nmultinacci sequences under prime modulo. In this scheme, instead of exchanging\nkey matrix, we need to exchange the only pair of numbers $(\\lambda, k)$, which\nreduces the time complexity as well as space complexity and comes with a large\nkey-space.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 17:56:16 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Prasad", "Kalika", ""], ["Mahato", "Hrishikesh", ""]]}, {"id": "2003.11967", "submitter": "Weilin Zheng", "authors": "Weilin Zheng, Zibin Zheng, Hong-Ning Dai, Xu Chen, and Peilin Zheng", "title": "XBlock-EOS: Extracting and Exploring Blockchain Data From EOSIO", "comments": "15 pages, 12 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain-based cryptocurrencies and applications have flourished in\nblockchain research community. Massive data generated from diverse blockchain\nsystems bring not only huge business values but also technological challenges\nin data analytics of heterogeneous blockchain data. Different from Bitcoin and\nEthereum, EOSIO has richer diversity and a higher volume of blockchain data due\nto its unique architectural design in resource management, consensus scheme and\nhigh throughput. Despite its popularity (e.g., 89,800,000 blocks generated till\nNovember 14, 2019 since its launch on June 8, 2018), few studies have been made\non data analysis of EOSIO. To fill this gap, we collect and process the\nup-to-date on-chain data from EOSIO. We name these well-processed EOSIO\ndatasets as XBlock-EOS, which consists of 7 well-processed datasets: 1) Block,\nTransaction and Action, 2) Internal and External EOS Transfer Action, 3)\nContract Information, 4) Contract Invocation, 5) Token Action, 6) Account\nCreation, 7) Resource Management. It is challenging to process and analyze a\nhigh volume of raw EOSIO data and establish the mapping from original raw data\nto the well-grained datasets since it requires substantial efforts in\nextracting various types of data as well as sophisticated knowledge on software\nengineering and data analytics. Meanwhile, we present statistics and\nexploration on these datasets. Moreover, we also outline the possible research\nopportunities based on XBlock-EOS.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 15:03:11 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 11:20:16 GMT"}, {"version": "v3", "created": "Thu, 17 Dec 2020 02:40:28 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Zheng", "Weilin", ""], ["Zheng", "Zibin", ""], ["Dai", "Hong-Ning", ""], ["Chen", "Xu", ""], ["Zheng", "Peilin", ""]]}, {"id": "2003.11995", "submitter": "Hua Sun", "authors": "Hua Sun", "title": "Secure Groupcast with Shared Keys", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a transmitter and $K$ receivers, each of which shares a key\nvariable with the transmitter. Through a noiseless broadcast channel, the\ntransmitter wishes to send a common message $W$ securely to $N$ out of the $K$\nreceivers while the remaining $K-N$ receivers learn no information about $W$.\nWe are interested in the maximum message rate, i.e., the maximum number of bits\nof $W$ that can be securely groupcast to the legitimate receivers per key block\nand the minimum broadcast bandwidth, i.e., the minimum number of bits of the\nbroadcast information required to securely groupcast the message bits.\n  We focus on the setting of combinatorial keys, where every subset of the $K$\nreceivers share an independent key of arbitrary size. Under this combinatorial\nkey setting, the maximum message rate is characterized for the following\nscenarios - 1) $N=1$ or $N=K-1$, i.e., secure unicast to 1 receiver with $K-1$\neavesdroppers or secure groupcast to $K-1$ receivers with $1$ eavesdropper, 2)\n$N=2, K=4$, i.e., secure groupcast to $2$ out of 4 receivers, and 3) the\nsymmetric setting where the key size for any subset of the same cardinality is\nequal for any $N,K$. Further, for the latter two cases, the minimum broadcast\nbandwidth for the maximum message rate is characterized.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 15:58:10 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Sun", "Hua", ""]]}, {"id": "2003.12020", "submitter": "Saeed Mahloujifar", "authors": "Sanjam Garg, Somesh Jha, Saeed Mahloujifar, Mohammad Mahmoody,\n  Abhradeep Thakurta", "title": "Obliviousness Makes Poisoning Adversaries Weaker", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poisoning attacks have emerged as a significant security threat to machine\nlearning (ML) algorithms. It has been demonstrated that adversaries who make\nsmall changes to the training set, such as adding specially crafted data\npoints, can hurt the performance of the output model. Most of these attacks\nrequire the full knowledge of training data or the underlying data\ndistribution. In this paper we study the power of oblivious adversaries who do\nnot have any information about the training set. We show a separation between\noblivious and full-information poisoning adversaries. Specifically, we\nconstruct a sparse linear regression problem for which LASSO estimator is\nrobust against oblivious adversaries whose goal is to add a non-relevant\nfeatures to the model with certain poisoning budget. On the other hand,\nnon-oblivious adversaries, with the same budget, can craft poisoning examples\nbased on the rest of the training data and successfully add non-relevant\nfeatures to the model.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 16:40:35 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Garg", "Sanjam", ""], ["Jha", "Somesh", ""], ["Mahloujifar", "Saeed", ""], ["Mahmoody", "Mohammad", ""], ["Thakurta", "Abhradeep", ""]]}, {"id": "2003.12027", "submitter": "Arsenia (Ersi) Chorti", "authors": "Gustavo A. Nunez Segura, Sotiris Skaperas, Arsenia Chorti, Lefteris\n  Mamatas and Cintia Borges Margi", "title": "Denial of Service Attacks Detection in Software-Defined Wireless Sensor\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Software-defined networking (SDN) is a promising technology to overcome many\nchallenges in wireless sensor networks (WSN), particularly with respect to\nflexibility and reuse. Conversely, the centralization and the planes'\nseparation turn SDNs vulnerable to new security threats in the general context\nof distributed denial of service (DDoS) attacks. State-of-the-art approaches to\nidentify DDoS do not always take into consideration restrictions in typical\nWSNs e.g., computational complexity and power constraints, while further\nperformance improvement is always a target. The objective of this work is to\npropose a lightweight but very efficient DDoS attack detection approach using\nchange point analysis. Our approach has a high detection rate and linear\ncomplexity, so that it is suitable for WSNs. We demonstrate the performance of\nour detector in software-defined WSNs of 36 and 100 nodes with varying attack\nintensity (the number of attackers ranges from 5% to 20% of nodes). We use\nchange point detectors to monitor anomalies in two metrics: the data packets\ndelivery rate and the control packets overhead. Our results show that with\nincreasing intensity of attack, our approach can achieve a detection rate close\nto100% and that the type of attack can also be inferred.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 16:49:28 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Segura", "Gustavo A. Nunez", ""], ["Skaperas", "Sotiris", ""], ["Chorti", "Arsenia", ""], ["Mamatas", "Lefteris", ""], ["Margi", "Cintia Borges", ""]]}, {"id": "2003.12034", "submitter": "Arsenia (Ersi) Chorti", "authors": "Miroslav Mitev, Arsenia Chorti, E. Veronica Belmega, Martin Reed", "title": "Man-in-the-Middle and Denial of Service Attacks in Wireless Secret Key\n  Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Wireless secret key generation (W-SKG) from shared randomness (e.g., from the\nwireless channel fading realizations), is a well established scheme that can be\nused for session key agreement. W-SKG approaches can be of particular interest\nin delay constrained wireless networks and notably in the context of ultra\nreliable low latency communications (URLLC) in beyond fifth generation (B5G)\nsystems. However, W-SKG schemes are known to be malleable over the so called\n\"advantage distillation\" phase, during which observations of the shared\nrandomness are obtained at the legitimate parties. As an example, an active\nattacker can act as a man-in-the-middle (MiM) by injecting pilot signals and/or\ncan mount denial of service attacks (DoS) in the form of jamming. This paper\ninvestigates the impact of injection and reactive jamming attacks in W-SKG.\nFirst, it is demonstrated that injection attacks can be reduced to -\npotentially less harmful - jamming attacks by pilot randomization; a novel\nsystem design with randomized QPSK pilots is presented. Subsequently, the\noptimal jamming strategy is identified in a block fading additive white\nGaussian noise (BF-AWGN) channel in the presence of a reactive jammer, using a\ngame theoretic formulation. It is shown that the impact of a reactive jammer is\nfar more severe than that of a simple proactive jammer\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 17:04:05 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Mitev", "Miroslav", ""], ["Chorti", "Arsenia", ""], ["Belmega", "E. Veronica", ""], ["Reed", "Martin", ""]]}, {"id": "2003.12052", "submitter": "Hamidreza Ehteram", "authors": "Hamidreza Ehteram, Mohammad Ali Maddah-Ali, Mahtab Mirmohseni", "title": "Corella: A Private Multi Server Learning Approach based on Correlated\n  Queries", "comments": "13 pages, 9 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emerging applications of machine learning algorithms on mobile devices\nmotivate us to offload the computation tasks of training a model or deploying a\ntrained one to the cloud or at the edge of the network. One of the major\nchallenges in this setup is to guarantee the privacy of the client data.\nVarious methods have been proposed to protect privacy in the literature. Those\ninclude (i) adding noise to the client data, which reduces the accuracy of the\nresult, (ii) using secure multiparty computation (MPC), which requires\nsignificant communication among the computing nodes or with the client, (iii)\nrelying on homomorphic encryption (HE) methods, which significantly increases\ncomputation load at the servers. In this paper, we propose $\\textit{Corella}$\nas an alternative approach to protect the privacy of data. The proposed scheme\nrelies on a cluster of servers, where at most $T \\in \\mathbb{N}$ of them may\ncollude, each running a learning model (e.g., a deep neural network). Each\nserver is fed with the client data, added with $\\textit{strong}$ noise,\nindependent from user data. The variance of the noise is set to be large enough\nto make the information leakage to any subset of up to $T$ servers\ninformation-theoretically negligible. On the other hand, the added noises for\ndifferent servers are $\\textit{correlated}$. This correlation among the queries\nallows the parameters of the models running on different servers to be\n$\\textit{trained}$ such that the client can mitigate the contribution of the\nnoises by combining the outputs of the servers, and recover the final result\nwith high accuracy and with a minor computational effort. Simulation results\nfor various datasets demonstrate the accuracy of the proposed approach for the\nclassification, using deep neural networks, and the autoencoder, as supervised\nand unsupervised learning tasks, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 17:44:00 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 09:39:00 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Ehteram", "Hamidreza", ""], ["Maddah-Ali", "Mohammad Ali", ""], ["Mirmohseni", "Mahtab", ""]]}, {"id": "2003.12093", "submitter": "Filipo Sharevski", "authors": "Filipo Sharevski, Peter Jachim, Kevin Florek", "title": "To Tweet or Not to Tweet: Covertly Manipulating a Twitter Debate on\n  Vaccines Using Malware-Induced Misperceptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trolling and social bots have been proven as powerful tactics for\nmanipulating the public opinion and sowing discord among Twitter users. This\neffort requires substantial content fabrication and account coordination to\nevade Twitter's detection of nefarious platform use. In this paper we explore\nan alternative tactic for covert social media interference by inducing\nmisperceptions about genuine, non-trolling content from verified users. This\ntactic uses a malware that covertly manipulates targeted words, hashtags, and\nTwitter metrics before the genuine content is presented to a targeted user in a\ncovert man-in-the-middle fashion. Early tests of the malware found that it is\ncapable of achieving a similar goal as trolls and social bots, that is,\nsilencing or provoking social media users to express their opinion in polarized\ndebates on social media. Following this, we conducted experimental tests in\ncontrolled settings (N=315) where the malware covertly manipulated the\nperception in a Twitter debate on the risk of vaccines causing autism. The\nempirical results demonstrate that inducing misperception is an effective\ntactic to silence users on Twitter when debating polarizing issues like\nvaccines. We used the findings to propose a solution for countering the effect\nof the malware-induced misperception that could also be used against trolls and\nsocial bots on Twitter.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 18:23:52 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Sharevski", "Filipo", ""], ["Jachim", "Peter", ""], ["Florek", "Kevin", ""]]}, {"id": "2003.12095", "submitter": "Floyd Johnson", "authors": "Carlos E. Gonz\\'alez-Guill\\'en, Mar\\'ia Isabel Gonz\\'alez Vasco, Floyd\n  Johnson, \\'Angel L. P\\'erez del Pozo", "title": "Concerning Quantum Identification Without Entanglement", "comments": "8 pages, 0 figures, 1 protocol review", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identification schemes are interactive protocols typically involving two\nparties, a prover, who wants to provide evidence of his or her identity and a\nverifier, who checks the provided evidence and decide whether it comes or not\nfrom the intended prover. In this paper, we comment on a recent proposal for\nquantum identity authentication from Zawadzki, and give a concrete attack\nupholding theoretical impossibility results from Lo and Buhrman et al. More\nprecisely, we show that using a simple strategyan adversary may indeed obtain\nnon-negligible information on the shared identification secret. While the\nsecurity of a quantum identity authentication scheme is not formally defined in\n[1], it is clear that such a definition should somehow imply that an external\nentity may gain no information on the shared identification scheme (even if he\nactively participates injecting messages in a protocol execution, which is not\nassumed in our attack strategy).\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 18:26:48 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 14:29:45 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Gonz\u00e1lez-Guill\u00e9n", "Carlos E.", ""], ["Vasco", "Mar\u00eda Isabel Gonz\u00e1lez", ""], ["Johnson", "Floyd", ""], ["del Pozo", "\u00c1ngel L. P\u00e9rez", ""]]}, {"id": "2003.12154", "submitter": "Fatemehsadat Mireshghallah", "authors": "Fatemehsadat Mireshghallah, Mohammadkazem Taram, Ali Jalali, Ahmed\n  Taha Elthakeb, Dean Tullsen, Hadi Esmaeilzadeh", "title": "Not All Features Are Equal: Discovering Essential Features for\n  Preserving Prediction Privacy", "comments": "This paper is presented at the 2021 Web conference (WWW 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When receiving machine learning services from the cloud, the provider does\nnot need to receive all features; in fact, only a subset of the features are\nnecessary for the target prediction task. Discerning this subset is the key\nproblem of this work. We formulate this problem as a gradient-based\nperturbation maximization method that discovers this subset in the input\nfeature space with respect to the functionality of the prediction model used by\nthe provider. After identifying the subset, our framework, Cloak, suppresses\nthe rest of the features using utility-preserving constant values that are\ndiscovered through a separate gradient-based optimization process. We show that\nCloak does not necessarily require collaboration from the service provider\nbeyond its normal service, and can be applied in scenarios where we only have\nblack-box access to the service provider's model. We theoretically guarantee\nthat Cloak's optimizations reduce the upper bound of the Mutual Information\n(MI) between the data and the sifted representations that are sent out.\nExperimental results show that Cloak reduces the mutual information between the\ninput and the sifted representations by 85.01% with only a negligible reduction\nin utility (1.42%). In addition, we show that Cloak greatly diminishes\nadversaries' ability to learn and infer non-conducive features.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 20:45:09 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 05:02:25 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Mireshghallah", "Fatemehsadat", ""], ["Taram", "Mohammadkazem", ""], ["Jalali", "Ali", ""], ["Elthakeb", "Ahmed Taha", ""], ["Tullsen", "Dean", ""], ["Esmaeilzadeh", "Hadi", ""]]}, {"id": "2003.12197", "submitter": "Vishnu Naresh Boddeti", "authors": "Joshua J. Engelsma and Anil K. Jain and Vishnu Naresh Boddeti", "title": "HERS: Homomorphically Encrypted Representation Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method to search for a probe (or query) image representation\nagainst a large gallery in the encrypted domain. We require that the probe and\ngallery images be represented in terms of a fixed-length representation, which\nis typical for representations obtained from learned networks. Our encryption\nscheme is agnostic to how the fixed-length representation is obtained and can\ntherefore be applied to any fixed-length representation in any application\ndomain. Our method, dubbed HERS (Homomorphically Encrypted Representation\nSearch), operates by (i) compressing the representation towards its estimated\nintrinsic dimensionality with minimal loss of accuracy (ii) encrypting the\ncompressed representation using the proposed fully homomorphic encryption\nscheme, and (iii) efficiently searching against a gallery of encrypted\nrepresentations directly in the encrypted domain, without decrypting them.\nNumerical results on large galleries of face, fingerprint, and object datasets\nsuch as ImageNet show that, for the first time, accurate and fast image search\nwithin the encrypted domain is feasible at scale (500 seconds; $275\\times$\nspeed up over state-of-the-art for encrypted search against a gallery of 100\nmillion).\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 01:10:54 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 03:22:54 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Engelsma", "Joshua J.", ""], ["Jain", "Anil K.", ""], ["Boddeti", "Vishnu Naresh", ""]]}, {"id": "2003.12208", "submitter": "Jacob Fustos", "authors": "Jacob Fustos, Michael Bechtel, Heechul Yun", "title": "SpectreRewind: Leaking Secrets to Past Instructions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transient execution attacks utilize micro-architectural covert channels to\nleak secrets that should not have been accessible during logical program\nexecution. Commonly used micro-architectural covert channels are those that\nleave lasting footprints in the microarchitectural state, for example, a cache\nstate change, from which the secret is recovered after the transient execution\nis completed.\n  In this paper, we present SpectreRewind, a new approach to create contention\nbased covert channels for transient execution attacks. In our approach, a\ncovert channel is established by issuing the necessary instructions logically\nbefore the transiently executed victim code. Unlike prior contention based\ncovert channels, which require simultaneous multi-threading (SMT),\nSpectreRewind supports single hardware thread based covert channels, making it\nviable on systems where attacker cannot utilize SMT. We show that contention on\nthe floating point division unit on commodity processors can be used to create\na high-performance (~100 KB/s), low-noise covert channel for transient\nexecution attacks instead of commonly used flush+reload based cache covert\nchannels.\n  We implement a Meltdown attack utilizing the proposed covert channel showing\ncompetitive performance compared to the stateof-the-art cache based covert\nchannel implementation. We also show that the covert channel works in the\nJavaScript engine of a Chrome browser.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 02:35:38 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 05:06:33 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Fustos", "Jacob", ""], ["Bechtel", "Michael", ""], ["Yun", "Heechul", ""]]}, {"id": "2003.12341", "submitter": "Martin Henze", "authors": "Linus Roepert, Markus Dahlmanns, Ina Berenice Fink, Jan Pennekamp,\n  Martin Henze", "title": "Assessing the Security of OPC UA Deployments", "comments": "2 pages, 1 figure, to be published in Proceedings of the 1st ITG\n  Workshop on IT Security (ITSec)", "journal-ref": null, "doi": "10.15496/publikation-41813", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To address the increasing security demands of industrial deployments, OPC UA\nis one of the first industrial protocols explicitly designed with security in\nmind. However, deploying it securely requires a thorough configuration of a\nwide range of options. Thus, assessing the security of OPC UA deployments and\ntheir configuration is necessary to ensure secure operation, most importantly\nconfidentiality and integrity of industrial processes. In this work, we present\nextensions to the popular Metasploit Framework to ease network-based security\nassessments of OPC UA deployments. To this end, we discuss methods to discover\nOPC UA servers, test their authentication, obtain their configuration, and\ncheck for vulnerabilities. Ultimately, our work enables operators to verify the\n(security) configuration of their systems and identify potential attack\nvectors.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 11:39:43 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Roepert", "Linus", ""], ["Dahlmanns", "Markus", ""], ["Fink", "Ina Berenice", ""], ["Pennekamp", "Jan", ""], ["Henze", "Martin", ""]]}, {"id": "2003.12359", "submitter": "Yuan Zhou", "authors": "Kun Cheng, Yuan Zhou, Bihuan Chen, Rui Wang, Yuebin Bai and Yang Liu", "title": "Guardauto: A Decentralized Runtime Protection System for Autonomous\n  Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the broad attack surface and the lack of runtime protection, potential\nsafety and security threats hinder the real-life adoption of autonomous\nvehicles. Although efforts have been made to mitigate some specific attacks,\nthere are few works on the protection of the self-driving system. This paper\npresents a decentralized self-protection framework called Guardauto to protect\nthe self-driving system against runtime threats. First, Guardauto proposes an\nisolation model to decouple the self-driving system and isolate its components\nwith a set of partitions. Second, Guardauto provides self-protection mechanisms\nfor each target component, which combines different methods to monitor the\ntarget execution and plan adaption actions accordingly. Third, Guardauto\nprovides cooperation among local self-protection mechanisms to identify the\nroot-cause component in the case of cascading failures affecting multiple\ncomponents. A prototype has been implemented and evaluated on the open-source\nautonomous driving system Autoware. Results show that Guardauto could\neffectively mitigate runtime failures and attacks, and protect the control\nsystem with acceptable performance overhead.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 09:28:23 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Cheng", "Kun", ""], ["Zhou", "Yuan", ""], ["Chen", "Bihuan", ""], ["Wang", "Rui", ""], ["Bai", "Yuebin", ""], ["Liu", "Yang", ""]]}, {"id": "2003.12363", "submitter": "Muhammad Junaid Farooq", "authors": "Timothy Kieras and Muhammad Junaid Farooq and Quanyan Zhu", "title": "Modeling and Assessment of IoT Supply Chain Security Risks: The Role of\n  Structural and Parametric Uncertainties", "comments": null, "journal-ref": "IEEE Symposium on Security and Privacy 2020, Workshop on Cyber\n  Resilient Supply Chain Technologies", "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supply chain security threats pose new challenges to security risk modeling\ntechniques for complex ICT systems such as the IoT. With established techniques\ndrawn from attack trees and reliability analysis providing needed points of\nreference, graph-based analysis can provide a framework for considering the\nrole of suppliers in such systems. We present such a framework here while\nhighlighting the need for a component-centered model. Given resource\nlimitations when applying this model to existing systems, we study various\nclasses of uncertainties in model development, including structural\nuncertainties and uncertainties in the magnitude of estimated event\nprobabilities. Using case studies, we find that structural uncertainties\nconstitute a greater challenge to model utility and as such should receive\nparticular attention. Best practices in the face of these uncertainties are\nproposed.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 22:08:00 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Kieras", "Timothy", ""], ["Farooq", "Muhammad Junaid", ""], ["Zhu", "Quanyan", ""]]}, {"id": "2003.12365", "submitter": "Sharif Abuadbba Dr", "authors": "Sharif Abuadbba, Kyuyeon Kim, Minki Kim, Chandra Thapa, Seyit A.\n  Camtepe, Yansong Gao, Hyoungshick Kim, Surya Nepal", "title": "Can We Use Split Learning on 1D CNN Models for Privacy Preserving\n  Training?", "comments": "13 pages, Accepted at ACM ASIACCS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new collaborative learning, called split learning, was recently introduced,\naiming to protect user data privacy without revealing raw input data to a\nserver. It collaboratively runs a deep neural network model where the model is\nsplit into two parts, one for the client and the other for the server.\nTherefore, the server has no direct access to raw data processed at the client.\nUntil now, the split learning is believed to be a promising approach to protect\nthe client's raw data; for example, the client's data was protected in\nhealthcare image applications using 2D convolutional neural network (CNN)\nmodels. However, it is still unclear whether the split learning can be applied\nto other deep learning models, in particular, 1D CNN.\n  In this paper, we examine whether split learning can be used to perform\nprivacy-preserving training for 1D CNN models. To answer this, we first design\nand implement an 1D CNN model under split learning and validate its efficacy in\ndetecting heart abnormalities using medical ECG data. We observed that the 1D\nCNN model under split learning can achieve the same accuracy of 98.9\\% like the\noriginal (non-split) model. However, our evaluation demonstrates that split\nlearning may fail to protect the raw data privacy on 1D CNN models. To address\nthe observed privacy leakage in split learning, we adopt two privacy leakage\nmitigation techniques: 1) adding more hidden layers to the client side and 2)\napplying differential privacy. Although those mitigation techniques are helpful\nin reducing privacy leakage, they have a significant impact on model accuracy.\nHence, based on those results, we conclude that split learning alone would not\nbe sufficient to maintain the confidentiality of raw sequential data in 1D CNN\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 06:06:14 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Abuadbba", "Sharif", ""], ["Kim", "Kyuyeon", ""], ["Kim", "Minki", ""], ["Thapa", "Chandra", ""], ["Camtepe", "Seyit A.", ""], ["Gao", "Yansong", ""], ["Kim", "Hyoungshick", ""], ["Nepal", "Surya", ""]]}, {"id": "2003.12375", "submitter": "Bryan Ford", "authors": "Bryan Ford", "title": "Democratic Value and Money for Decentralized Digital Society", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical monetary systems regularly subject the most vulnerable majority of\nthe world's population to debilitating financial shocks, and have manifestly\nallowed uncontrolled global inequality over the long term. Given these basic\nfailures, how can we avoid asking whether mainstream macroeconomic principles\nare actually compatible with democratic principles such as equality or the\nprotection of human rights and dignity? This idea paper takes a constructive\nlook at this question, by exploring how alternate monetary principles might\nresult in a form of money more compatible with democratic principles -- dare we\ncall it \"democratic money\"? In this alternative macroeconomic philosophy, both\nthe supply of and the demand for money must be rooted in people, so as to give\nall people both equal opportunities for economic participation. Money must be\ndesigned around equality, not only across all people alive at a given moment,\nbut also across past and future generations of people, guaranteeing that our\ndescendants cannot be enslaved by their ancestors' economic luck or misfortune.\nDemocratic money must reliably give all people a means to enable everyday\ncommerce, investment, and value creation in good times and bad, and must impose\nhard limits on financial inequality. Democratic money must itself be governed\ndemocratically, and must economically facilitate the needs of citizens in a\ndemocracy for trustworthy and unbiased information with which to make wise\ncollective decisions. An intriguing approach to implementing and deploying\ndemocratic money is via a cryptocurrency built on a proof-of-personhood\nfoundation, giving each opt-in human participant one equal unit of stake. Such\na cryptocurrency would have both interesting similarities to, and important\ndifferences from, a Universal Basic Income (UBI) denominated in an existing\ncurrency.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 09:30:47 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Ford", "Bryan", ""]]}, {"id": "2003.12401", "submitter": "Jose Moura", "authors": "Jose Moura, David Hutchison", "title": "Resilient Cyber-Physical Systems: Using NFV Orchestration", "comments": "13 pages, 6 figures, 2 tables, 49 references; this article supersedes\n  arXiv:1908.05077(v1), e.g. sections 3 and 4 of the current article supersede\n  section 5 of arXiv:1908.05077(v1)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-Physical Systems (CPSs) are increasingly important in critical areas of\nour society such as intelligent power grids, next generation mobile devices,\nand smart buildings. CPS operation has characteristics including considerable\nheterogeneity, variable dynamics, and high complexity. These systems have also\nscarce resources in order to satisfy their entire load demand, which can be\ndivided into data processing and service execution. These new characteristics\nof CPSs need to be managed with novel strategies to ensure their resilient\noperation. Towards this goal, we propose an SDN-based solution enhanced by\ndistributed Network Function Virtualization (NFV) modules located at the\ntop-most level of our solution architecture. These NFV agents will take\norchestrated management decisions among themselves to ensure a resilient CPS\nconfiguration against threats, and an optimum operation of the CPS. For this,\nwe study and compare two distinct incentive mechanisms to enforce cooperation\namong NFVs. Thus, we aim to offer novel perspectives into the management of\nresilient CPSs, embedding IoT devices, modeled by Game Theory (GT), using the\nlatest software and virtualization platforms.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 15:30:25 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 20:44:17 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Moura", "Jose", ""], ["Hutchison", "David", ""]]}, {"id": "2003.12456", "submitter": "Avishai Wool", "authors": "Nimrod Gilboa Markevich and Avishai Wool", "title": "Hardware Fingerprinting for the ARINC 429 Avionic Bus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ARINC 429 is the most common data bus in use today in civil avionics.\nHowever, the protocol lacks any form of source authentication. A technician\nwith physical access to the bus is able to replace a transmitter by a rogue\ndevice, and the receivers will accept its malicious data as they have no method\nof verifying the authenticity of messages. Updating the protocol would close\noff security loopholes in new aircraft but would require thousands of airplanes\nto be modified. For the interim, until the protocol is replaced, we propose the\nfirst intrusion detection system that utilizes a hardware fingerprinting\napproach for sender identification for the ARINC 429 data bus. Our approach\nrelies on the observation that changes in hardware, such as replacing a\ntransmitter or a receiver with a rogue one, modify the electric signal of the\ntransmission. Because we rely on the analog properties, and not on the digital\ncontent of the transmissions, we are able to detect a hardware switch as soon\nas it occurs, even if the data that is being transmitted is completely normal.\nThus, we are able to preempt the attack before any damage is caused. In this\npaper we describe the design of our intrusion detection system and evaluate its\nperformance against different adversary models. Our analysis includes both a\ntheoretical Markov-chain model and an extensive empirical evaluation. For this\npurpose, we collected a data corpus of ARINC 429 data traces, which may be of\nindependent interest since, to the best of our knowledge, no public corpus is\navailable. We find that our intrusion detection system is quite realistic:\ne.g., it achieves near-zero false alarms per second, while detecting a rogue\ntransmitter in under 50ms, and detecting a rogue receiver in under 3 seconds.\nIn other words, technician attacks can be reliably detected during the\npre-flight checks, well before the aircraft takes off.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 15:02:37 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Markevich", "Nimrod Gilboa", ""], ["Wool", "Avishai", ""]]}, {"id": "2003.12470", "submitter": "Haaroon Yousaf", "authors": "George Kappos, Haaroon Yousaf, Ania Piotrowska, Sanket Kanjalkar,\n  Sergi Delgado-Segura, Andrew Miller, Sarah Meiklejohn", "title": "An Empirical Analysis of Privacy in the Lightning Network", "comments": "26 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Payment channel networks, and the Lightning Network in particular, seem to\noffer a solution to the lack of scalability and privacy offered by Bitcoin and\nother blockchain-based cryptocurrencies. Previous research has focused on the\nscalability, availability, and crypto-economics of the Lightning Network, but\nrelatively little attention has been paid to exploring the level of privacy it\nachieves in practice. This paper presents a thorough analysis of the privacy\noffered by the Lightning Network, by presenting several attacks that exploit\npublicly available information about the network in order to learn information\nthat is designed to be kept secret, such as how many coins a node has available\nor who the sender and recipient are in a payment routed through the network.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 15:30:47 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 12:37:13 GMT"}, {"version": "v3", "created": "Thu, 21 Jan 2021 12:08:05 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Kappos", "George", ""], ["Yousaf", "Haaroon", ""], ["Piotrowska", "Ania", ""], ["Kanjalkar", "Sanket", ""], ["Delgado-Segura", "Sergi", ""], ["Miller", "Andrew", ""], ["Meiklejohn", "Sarah", ""]]}, {"id": "2003.12598", "submitter": "Muhamad Felemban", "authors": "Muhamad Felemban, Anas Daghistani, Yahya Javeed, Jason Kobes, Arif\n  Ghafoor", "title": "A Security and Performance Driven Architecture for Cloud Data Centers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing cyber-security threats, ensuring the security of data in\nCloud data centers is a challenging task. A prominent type of attack on Cloud\ndata centers is data tampering attack that can jeopardize the confidentiality\nand the integrity of data. In this article, we present a security and\nperformance driven architecture for these centers that incorporates an\nintrusion management system for multi-tenant distributed transactional\ndatabases. The proposed architecture uses a novel data partitioning and\nplacement scheme based on damage containment and communication cost of\ndistributed transactions. In addition, we present a benchmarking framework for\nevaluating the performance of the proposed architecture. The results illustrate\na trade-off between security and performance goals for Cloud data centers.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 18:54:24 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Felemban", "Muhamad", ""], ["Daghistani", "Anas", ""], ["Javeed", "Yahya", ""], ["Kobes", "Jason", ""], ["Ghafoor", "Arif", ""]]}, {"id": "2003.12613", "submitter": "Xuezhou Zhang", "authors": "Xuezhou Zhang, Yuzhe Ma, Adish Singla, Xiaojin Zhu", "title": "Adaptive Reward-Poisoning Attacks against Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reward-poisoning attacks against reinforcement learning (RL), an attacker\ncan perturb the environment reward $r_t$ into $r_t+\\delta_t$ at each step, with\nthe goal of forcing the RL agent to learn a nefarious policy. We categorize\nsuch attacks by the infinity-norm constraint on $\\delta_t$: We provide a lower\nthreshold below which reward-poisoning attack is infeasible and RL is certified\nto be safe; we provide a corresponding upper threshold above which the attack\nis feasible. Feasible attacks can be further categorized as non-adaptive where\n$\\delta_t$ depends only on $(s_t,a_t, s_{t+1})$, or adaptive where $\\delta_t$\ndepends further on the RL agent's learning process at time $t$. Non-adaptive\nattacks have been the focus of prior works. However, we show that under mild\nconditions, adaptive attacks can achieve the nefarious policy in steps\npolynomial in state-space size $|S|$, whereas non-adaptive attacks require\nexponential steps. We provide a constructive proof that a Fast Adaptive Attack\nstrategy achieves the polynomial rate. Finally, we show that empirically an\nattacker can find effective reward-poisoning attacks using state-of-the-art\ndeep RL techniques.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 19:46:23 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 21:02:31 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Zhang", "Xuezhou", ""], ["Ma", "Yuzhe", ""], ["Singla", "Adish", ""], ["Zhu", "Xiaojin", ""]]}, {"id": "2003.12632", "submitter": "Tamzidul Hoque", "authors": "Tamzidul Hoque, Shuo Yang, Aritra Bhattacharyay, Jonathan Cruz, and\n  Swarup Bhunia", "title": "An Automated Framework for Board-level Trojan Benchmarking", "comments": "7 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Economic and operational advantages have led the supply chain of printed\ncircuit boards (PCBs) to incorporate various untrusted entities. Any of the\nuntrusted entities are capable of introducing malicious alterations to\nfacilitate a functional failure or leakage of secret information during field\noperation. While researchers have been investigating the threat of malicious\nmodification within the scale of individual microelectronic components, the\npossibility of a board-level malicious manipulation has essentially been\nunexplored. In the absence of standard benchmarking solutions, prospective\ncountermeasures for PCB trust assurance are likely to utilize homegrown\nrepresentation of the attacks that undermines their evaluation and does not\nprovide scope for comparison with other techniques. In this paper, we have\ndeveloped the first-ever benchmarking solution to facilitate an unbiased and\ncomparable evaluation of countermeasures applicable to PCB trust assurance.\nBased on a taxonomy tailored for PCB-level alterations, we have developed\nhigh-level Trojan models. From these models, we have generated a custom pool of\nboard-level Trojan designs of varied complexity and functionality. We have also\ndeveloped a tool-flow for automatically inserting these Trojans into various\nPCB designs and generate the Trojan benchmarks (i.e., PCB designs with Trojan).\nThe tool-based Trojan insertion facilitate a comprehensive evaluation against\nlarge number of diverse Trojan implementations and application of data mining\nfor trust verification. Finally, with experimental measurements from a\nfabricated PCB, we analyze the stealthiness of the Trojan designs.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 20:44:50 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Hoque", "Tamzidul", ""], ["Yang", "Shuo", ""], ["Bhattacharyay", "Aritra", ""], ["Cruz", "Jonathan", ""], ["Bhunia", "Swarup", ""]]}, {"id": "2003.12703", "submitter": "Mingyi Zhou", "authors": "Mingyi Zhou, Jing Wu, Yipeng Liu, Shuaicheng Liu, Ce Zhu", "title": "DaST: Data-free Substitute Training for Adversarial Attacks", "comments": "Accepted by CVPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are vulnerable to adversarial examples. For the\nblack-box setting, current substitute attacks need pre-trained models to\ngenerate adversarial examples. However, pre-trained models are hard to obtain\nin real-world tasks. In this paper, we propose a data-free substitute training\nmethod (DaST) to obtain substitute models for adversarial black-box attacks\nwithout the requirement of any real data. To achieve this, DaST utilizes\nspecially designed generative adversarial networks (GANs) to train the\nsubstitute models. In particular, we design a multi-branch architecture and\nlabel-control loss for the generative model to deal with the uneven\ndistribution of synthetic samples. The substitute model is then trained by the\nsynthetic samples generated by the generative model, which are labeled by the\nattacked model subsequently. The experiments demonstrate the substitute models\nproduced by DaST can achieve competitive performance compared with the baseline\nmodels which are trained by the same train set with attacked models.\nAdditionally, to evaluate the practicability of the proposed method on the\nreal-world task, we attack an online machine learning model on the Microsoft\nAzure platform. The remote model misclassifies 98.35% of the adversarial\nexamples crafted by our method. To the best of our knowledge, we are the first\nto train a substitute model for adversarial attacks without any real data.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 04:28:13 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 15:25:06 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Zhou", "Mingyi", ""], ["Wu", "Jing", ""], ["Liu", "Yipeng", ""], ["Liu", "Shuaicheng", ""], ["Zhu", "Ce", ""]]}, {"id": "2003.12705", "submitter": "Yanmin Gong", "authors": "Rui Hu, Yuanxiong Guo, E. Paul. Ratazzi and Yanmin Gong", "title": "Differentially Private Federated Learning for Resource-Constrained\n  Internet of Things", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the proliferation of smart devices having built-in sensors, Internet\nconnectivity, and programmable computation capability in the era of Internet of\nthings (IoT), tremendous data is being generated at the network edge. Federated\nlearning is capable of analyzing the large amount of data from a distributed\nset of smart devices without requiring them to upload their data to a central\nplace. However, the commonly-used federated learning algorithm is based on\nstochastic gradient descent (SGD) and not suitable for resource-constrained IoT\nenvironments due to its high communication resource requirement. Moreover, the\nprivacy of sensitive data on smart devices has become a key concern and needs\nto be protected rigorously. This paper proposes a novel federated learning\nframework called DP-PASGD for training a machine learning model efficiently\nfrom the data stored across resource-constrained smart devices in IoT while\nguaranteeing differential privacy. The optimal schematic design of DP-PASGD\nthat maximizes the learning performance while satisfying the limits on resource\ncost and privacy loss is formulated as an optimization problem, and an\napproximate solution method based on the convergence analysis of DP-PASGD is\ndeveloped to solve the optimization problem efficiently. Numerical results\nbased on real-world datasets verify the effectiveness of the proposed DP-PASGD\nscheme.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 04:32:54 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Hu", "Rui", ""], ["Guo", "Yuanxiong", ""], ["Ratazzi", "E. Paul.", ""], ["Gong", "Yanmin", ""]]}, {"id": "2003.12760", "submitter": "Mingyi Zhou", "authors": "Mingyi Zhou, Jing Wu, Yipeng Liu, Xiaolin Huang, Shuaicheng Liu, Xiang\n  Zhang, Ce Zhu", "title": "Adversarial Imitation Attack", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models are known to be vulnerable to adversarial examples. A\npractical adversarial attack should require as little as possible knowledge of\nattacked models. Current substitute attacks need pre-trained models to generate\nadversarial examples and their attack success rates heavily rely on the\ntransferability of adversarial examples. Current score-based and decision-based\nattacks require lots of queries for the attacked models. In this study, we\npropose a novel adversarial imitation attack. First, it produces a replica of\nthe attacked model by a two-player game like the generative adversarial\nnetworks (GANs). The objective of the generative model is to generate examples\nthat lead the imitation model returning different outputs with the attacked\nmodel. The objective of the imitation model is to output the same labels with\nthe attacked model under the same inputs. Then, the adversarial examples\ngenerated by the imitation model are utilized to fool the attacked model.\nCompared with the current substitute attacks, imitation attacks can use less\ntraining data to produce a replica of the attacked model and improve the\ntransferability of adversarial examples. Experiments demonstrate that our\nimitation attack requires less training data than the black-box substitute\nattacks, but achieves an attack success rate close to the white-box attack on\nunseen data with no query.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 10:02:49 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 05:10:40 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Zhou", "Mingyi", ""], ["Wu", "Jing", ""], ["Liu", "Yipeng", ""], ["Huang", "Xiaolin", ""], ["Liu", "Shuaicheng", ""], ["Zhang", "Xiang", ""], ["Zhu", "Ce", ""]]}, {"id": "2003.12776", "submitter": "Paolo Modesti", "authors": "Abdulaziz Almehrej, Leo Freitas and Paolo Modesti", "title": "Security Analysis of the Open Banking Account and Transaction API\n  Protocol", "comments": "18 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To counteract the lack of competition and innovation in the financial\nservices industry, the EU has issued the Second Payment Services Directive\n(PSD2) encouraging account servicing payment service providers to share data.\nThe UK, similarly to other European countries, has promoted a standard API for\ndata sharing:~the Open Banking Standard. We present a formal security analysis\nof its APIs, focusing on the correctness of the Account and Transaction API\nprotocol. The work relies on a previously proposed methodology, which provided\na practical approach to protocol modelling and verification.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 12:09:13 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Almehrej", "Abdulaziz", ""], ["Freitas", "Leo", ""], ["Modesti", "Paolo", ""]]}, {"id": "2003.12805", "submitter": "Kate Highnam", "authors": "Kate Highnam, Domenic Puzio, Song Luo, and Nicholas R. Jennings", "title": "Real-Time Detection of Dictionary DGA Network Traffic using Deep\n  Learning", "comments": "12 pages, 6 figures, PrePrint, code on Github\n  (https://github.com/jinxmirror13/bilbo-bagging-hybrid)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Botnets and malware continue to avoid detection by static rules engines when\nusing domain generation algorithms (DGAs) for callouts to unique, dynamically\ngenerated web addresses. Common DGA detection techniques fail to reliably\ndetect DGA variants that combine random dictionary words to create domain names\nthat closely mirror legitimate domains. To combat this, we created a novel\nhybrid neural network, Bilbo the `bagging` model, that analyses domains and\nscores the likelihood they are generated by such algorithms and therefore are\npotentially malicious. Bilbo is the first parallel usage of a convolutional\nneural network (CNN) and a long short-term memory (LSTM) network for DGA\ndetection. Our unique architecture is found to be the most consistent in\nperformance in terms of AUC, F1 score, and accuracy when generalising across\ndifferent dictionary DGA classification tasks compared to current\nstate-of-the-art deep learning architectures. We validate using\nreverse-engineered dictionary DGA domains and detail our real-time\nimplementation strategy for scoring real-world network logs within a large\nfinancial enterprise. In four hours of actual network traffic, the model\ndiscovered at least five potential command-and-control networks that commercial\nvendor tools did not flag.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 14:57:22 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Highnam", "Kate", ""], ["Puzio", "Domenic", ""], ["Luo", "Song", ""], ["Jennings", "Nicholas R.", ""]]}, {"id": "2003.12901", "submitter": "Julian Sch\\\"utte", "authors": "Julian Sch\\\"utte and Dennis Titze", "title": "liOS: Lifting iOS apps for fun and profit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although iOS is the second most popular mobile operating system and is often\nconsidered the more secure one, approaches to automatically analyze iOS\napplications are scarce and generic app analysis frameworks do not exist. This\nis on the one hand due to the closed ecosystem putting obstacles in the way of\nreverse engineers and on the other hand due to the complexity of reverse\nengineering and analyzing app binaries. Reliably lifting accurate call graphs,\ncontrol flows, and data dependence graphs from binary code, as well as\nreconstructing object-oriented high-level concepts is a non-trivial task and\nthe choice of the lifted target representation determines the analysis\ncapabilities. None of the various existing intermediate representations is a\nperfect fit for all types of analysis, while the detection of vulnerabilities\nrequires techniques ranging from simple pattern matching to complex\ninter-procedural data flow analyses. We address this gap by introducing liOS, a\nbinary lifting and analysis framework for iOS applications that extracts lifted\ninformation from several frontends and unifies them in a \"supergraph\"\nrepresentation that tolerates missing parts and is further extended and\ninterlinked by liOS \"passes\". A static analysis of the binary is then realized\nin the form of graph traversal queries, which can be considered as an\nadvancement of classic program query languages. We illustrate this approach by\nmeans of a typical JavaScript/Objective-C bridge, which can lead to remote code\nexecution in iOS applications.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 22:30:12 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Sch\u00fctte", "Julian", ""], ["Titze", "Dennis", ""]]}, {"id": "2003.12905", "submitter": "Michael Soltys", "authors": "Michael Soltys", "title": "Cybersecurity in the AWS Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper re-examines the content of a standard advanced course in\nCybersecurity from the perspective of Cloud Computing. More precisely, we\nreview the core concepts of Cybersecurity, as presented in a senior\nundergraduate or graduate class, in light of the Amazon Web Services (AWS)\ncloud.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 22:45:28 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Soltys", "Michael", ""]]}, {"id": "2003.12909", "submitter": "Adish Singla", "authors": "Amin Rakhsha, Goran Radanovic, Rati Devidze, Xiaojin Zhu, Adish Singla", "title": "Policy Teaching via Environment Poisoning: Training-time Adversarial\n  Attacks against Reinforcement Learning", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a security threat to reinforcement learning where an attacker\npoisons the learning environment to force the agent into executing a target\npolicy chosen by the attacker. As a victim, we consider RL agents whose\nobjective is to find a policy that maximizes average reward in undiscounted\ninfinite-horizon problem settings. The attacker can manipulate the rewards or\nthe transition dynamics in the learning environment at training-time and is\ninterested in doing so in a stealthy manner. We propose an optimization\nframework for finding an \\emph{optimal stealthy attack} for different measures\nof attack cost. We provide sufficient technical conditions under which the\nattack is feasible and provide lower/upper bounds on the attack cost. We\ninstantiate our attacks in two settings: (i) an \\emph{offline} setting where\nthe agent is doing planning in the poisoned environment, and (ii) an\n\\emph{online} setting where the agent is learning a policy using a\nregret-minimization framework with poisoned feedback. Our results show that the\nattacker can easily succeed in teaching any target policy to the victim under\nmild conditions and highlight a significant security threat to reinforcement\nlearning agents in practice.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 23:22:28 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 00:07:20 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Rakhsha", "Amin", ""], ["Radanovic", "Goran", ""], ["Devidze", "Rati", ""], ["Zhu", "Xiaojin", ""], ["Singla", "Adish", ""]]}, {"id": "2003.12920", "submitter": "Shajulin Benedict", "authors": "Shajulin Benedict, Rumaize P., Jaspreet Kaur", "title": "IoT Blockchain Solution for Air Quality Monitoring in SmartCities", "comments": "IEEE ANTS2019 Accepted Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IoT cloud enabled societal applications have dramatically increased in the\nrecent past due to the thrust for innovations, notably through startup\ninitiatives, in various sectors such as agriculture, healthcare, industry, and\nso forth. The existing IoT cloud solutions have led practitioners or\nresearchers to a haphazard clutter of serious security hazards and performance\ninefficiencies. This paper proposes a blockchain enabled IoT cloud\nimplementation to tackle the existing issues in smart cities. It particularly\nhighlights the implementation of chaincodes for air quality monitoring systems\nin SmartCities; the proposed architecture named as IoT enabled Blockchain for\nAir Quality Monitoring System (IB-AQMS) is illustrated using experiments.\nExperimental results were carried out and the findings were disclosed in the\npaper.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 01:44:22 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Benedict", "Shajulin", ""], ["P.", "Rumaize", ""], ["Kaur", "Jaspreet", ""]]}, {"id": "2003.13073", "submitter": "Didem Demirag", "authors": "Didem Demirag and Erman Ayday", "title": "Tracking the Invisible: Privacy-Preserving Contact Tracing to Control\n  the Spread of a Virus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, tracking and controlling the spread of a virus is a crucial need for\nalmost all countries. Doing this early would save millions of lives and help\ncountries keep a stable economy. The easiest way to control the spread of a\nvirus is to immediately inform the individuals who recently had close contact\nwith the diagnosed patients. However, to achieve this, a centralized authority\n(e.g., a health authority) needs detailed location information from both\nhealthy individuals and diagnosed patients. Thus, such an approach, although\nbeneficial to control the spread of a virus, results in serious privacy\nconcerns, and hence privacy-preserving solutions are required to solve this\nproblem. Previous works on this topic either (i) compromise privacy (especially\nprivacy of diagnosed patients) to have better efficiency or (ii) provide\nunscalable solutions. In this work, we propose a technique based on private set\nintersection between physical contact histories of individuals (that are\nrecorded using smart phones) and a centralized database (run by a health\nauthority) that keeps the identities of the positive diagnosed patients for the\ndisease. Proposed solution protects the location privacy of both healthy\nindividuals and diagnosed patients and it guarantees that the identities of the\ndiagnosed patients remain hidden from other individuals. Notably, proposed\nscheme allows individuals to receive warning messages indicating their previous\ncontacts with a positive diagnosed patient. Such warning messages will help\nthem realize the risk and isolate themselves from other people. We make sure\nthat the warning messages are only observed by the corresponding individuals\nand not by the health authority. We also implement the proposed scheme and show\nits efficiency and scalability via simulations.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 16:54:47 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 15:29:12 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Demirag", "Didem", ""], ["Ayday", "Erman", ""]]}, {"id": "2003.13155", "submitter": "Zhuolun Xiang", "authors": "Ittai Abraham, Kartik Nayak, Ling Ren, Zhuolun Xiang", "title": "Byzantine Agreement, Broadcast and State Machine Replication with\n  Near-optimal Good-case Latency", "comments": "A brief announcement appeared in DISC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the problem \\textit{good-case latency} of Byzantine\nagreement, broadcast and state machine replication in the synchronous\nauthenticated setting. The good-case latency measure captures the time it takes\nto reach agreement when all non-faulty parties have the same input (or in\nBB/SMR when the sender/leader is non-faulty). Previous result implies a lower\nbound showing that any Byzantine agreement or broadcast protocol tolerating\nmore than $n/3$ faults must have a good-case latency of at least $\\Delta$,\nwhere $\\Delta$ is the assumed maximum message delay bound. Our first result is\na family of protocols we call $1\\Delta$ that have near-optimal good-case\nlatency. We propose a protocol $1\\Delta$-BA that solves Byzantine agreement in\nthe synchronous and authenticated setting with near-optimal good-case latency\nof $\\Delta+2\\delta$ and optimal resilience $f<n/2$, where $\\delta$ is the\nactual (unknown) delay bound. We then extend our protocol and present\n$1\\Delta$-BB and $1\\Delta$-SMR for Byzantine fault tolerant broadcast and state\nmachine replication, respectively, in the same setting and with the same\ngood-case latency of $\\Delta+2\\delta$ and $f<n/2$ fault tolerance. Our\n$1\\Delta$-SMR upper bound improves the gap between the best current solution,\nSync HotStuff, which obtains a good-case latency of $2\\Delta$ per command and\nthe lower bound of $\\Delta$ on good-case latency. Finally, we investigate\nweaker notions of the synchronous setting and show how to adopt the $1\\Delta$\napproach to these models.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 22:53:34 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 15:57:07 GMT"}, {"version": "v3", "created": "Thu, 17 Dec 2020 07:19:15 GMT"}, {"version": "v4", "created": "Sat, 19 Dec 2020 21:13:55 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Abraham", "Ittai", ""], ["Nayak", "Kartik", ""], ["Ren", "Ling", ""], ["Xiang", "Zhuolun", ""]]}, {"id": "2003.13164", "submitter": "Sheikh Ariful Islam", "authors": "Sheikh Ariful Islam, Love Kumar Sah, and Srinivas Katkoori", "title": "Analytical Estimation and Localization of Hardware Trojan Vulnerability\n  in RTL Designs", "comments": "Accepted to be Published in: Proceedings of the 21st International\n  Symposium on Quality Electronic Design (ISQED 2020), Mar. 25-26, 2020, Santa\n  Clara, CA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offshoring the proprietary Intellectual property (IP) has recently increased\nthe threat of malicious logic insertion in the form of Hardware Trojan (HT). A\npotential and stealthy HT is triggered with nets that switch rarely during\nregular circuit operation. Detection of HT in the host design requires\nexhaustive simulation to activate the HT during pre- and postsilicon. Although\nthe nets with variable switching probability less than a threshold are\nprimarily chosen as a good candidate for Trojan triggering, there is no\nsystematic fine-grained approach for earlier detection of rare nets from\nword-level measures of input signals. In this paper, we propose a high-level\ntechnique to estimate the nets with the rare activity of arithmetic modules\nfrom word-level information. Specifically, for a given module, we use the\nknowledge of internal construction of the architecture to detect \"low activity\"\nand \"local regions\" without resorting to expensive RTL and other low-level\nsimulations. The presented heuristic method abstracts away from the low-level\ndetails of design and describes the rare activity of bits (modules) in a word\n(architecture) as a function of signal statistics. The resulting quick\nestimates of nets in rare regions allows a designer to develop a compact test\ngeneration algorithm without the knowledge of the bit-level activity. We\ndetermine the effect of different positions of the breakpoint in the input\nsignal to calculate the accuracy of the approach. We conduct a set of\nexperiments on six adder architectures and four multiplier architectures. The\naverage error to calculate the rare nets between RTL simulation and estimated\nvalues are below 2% in all architectures.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 23:58:33 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Islam", "Sheikh Ariful", ""], ["Sah", "Love Kumar", ""], ["Katkoori", "Srinivas", ""]]}, {"id": "2003.13192", "submitter": "Uri Stemmer", "authors": "Haim Kaplan, Micha Sharir, Uri Stemmer", "title": "How to Find a Point in the Convex Hull Privately", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the question of how to compute a point in the convex hull of an\ninput set $S$ of $n$ points in ${\\mathbb R}^d$ in a differentially private\nmanner. This question, which is trivial non-privately, turns out to be quite\ndeep when imposing differential privacy. In particular, it is known that the\ninput points must reside on a fixed finite subset $G\\subseteq{\\mathbb R}^d$,\nand furthermore, the size of $S$ must grow with the size of $G$. Previous works\nfocused on understanding how $n$ needs to grow with $|G|$, and showed that\n$n=O\\left(d^{2.5}\\cdot8^{\\log^*|G|}\\right)$ suffices (so $n$ does not have to\ngrow significantly with $|G|$). However, the available constructions exhibit\nrunning time at least $|G|^{d^2}$, where typically $|G|=X^d$ for some (large)\ndiscretization parameter $X$, so the running time is in fact $\\Omega(X^{d^3})$.\n  In this paper we give a differentially private algorithm that runs in\n$O(n^d)$ time, assuming that $n=\\Omega(d^4\\log X)$. To get this result we study\nand exploit some structural properties of the Tukey levels (the regions $D_{\\ge\nk}$ consisting of points whose Tukey depth is at least $k$, for $k=0,1,...$).\nIn particular, we derive lower bounds on their volumes for point sets $S$ in\ngeneral position, and develop a rather subtle mechanism for handling point sets\n$S$ in degenerate position (where the deep Tukey regions have zero volume). A\nnaive approach to the construction of the Tukey regions requires $n^{O(d^2)}$\ntime. To reduce the cost to $O(n^d)$, we use an approximation scheme for\nestimating the volumes of the Tukey regions (within their affine spans in case\nof degeneracy), and for sampling a point from such a region, a scheme that is\nbased on the volume estimation framework of Lov\\'asz and Vempala (FOCS 2003)\nand of Cousins and Vempala (STOC 2015). Making this framework differentially\nprivate raises a set of technical challenges that we address.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 02:42:48 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Kaplan", "Haim", ""], ["Sharir", "Micha", ""], ["Stemmer", "Uri", ""]]}, {"id": "2003.13213", "submitter": "Yuan Luo", "authors": "Yuan Luo, Ya Xiao, Long Cheng, Guojun Peng, Danfeng Daphne Yao", "title": "Deep Learning-Based Anomaly Detection in Cyber-Physical Systems:\n  Progress and Opportunities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is crucial to ensure the security of cyber-physical systems\n(CPS). However, due to the increasing complexity of CPSs and more sophisticated\nattacks, conventional anomaly detection methods, which face the growing volume\nof data and need domain-specific knowledge, cannot be directly applied to\naddress these challenges. To this end, deep learning-based anomaly detection\n(DLAD) methods have been proposed. In this paper, we review state-of-the-art\nDLAD methods in CPSs. We propose a taxonomy in terms of the type of anomalies,\nstrategies, implementation, and evaluation metrics to understand the essential\nproperties of current methods. Further, we utilize this taxonomy to identify\nand highlight new characteristics and designs in each CPS domain. Also, we\ndiscuss the limitations and open problems of these methods. Moreover, to give\nusers insights into choosing proper DLAD methods in practice, we experimentally\nexplore the characteristics of typical neural models, the workflow of DLAD\nmethods, and the running performance of DL models. Finally, we discuss the\ndeficiencies of DL approaches, our findings, and possible directions to improve\nDLAD methods and motivate future research.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 04:25:16 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 08:56:04 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Luo", "Yuan", ""], ["Xiao", "Ya", ""], ["Cheng", "Long", ""], ["Peng", "Guojun", ""], ["Yao", "Danfeng Daphne", ""]]}, {"id": "2003.13251", "submitter": "Kyungho Joo", "authors": "Kyungho Joo, Wonsuk Choi, Dong Hoon Lee", "title": "Hold the Door! Fingerprinting Your Car Key to Prevent Keyless Entry Car\n  Theft", "comments": "Published in NDSS 2020 proceeding", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the traditional way to unlock car doors has been replaced with a\nkeyless entry system which proves more convenient for automobile owners. When a\ndriver with a key fob is in the vicinity of the vehicle, doors automatically\nunlock on user command. However, unfortunately, it has been shown that these\nkeyless entry systems are vulnerable to signal relaying attacks. While it is\nevident that automobile manufacturers incorporate preventative methods to\nsecure these keyless entry systems, they continue to be vulnerable to a range\nof attacks. Relayed signals result in valid packets that are verified as\nlegitimate, and this makes it is difficult to distinguish a legitimate door\nunlock request from a malicious signal. In response to this vulnerability, this\npaper presents an RF fingerprinting method (coined HOld the DOoR, HODOR) to\ndetect attacks on keyless entry systems the first attempt to exploit the RF\nfingerprint technique in the automotive domain. HODOR is designed as a sub\nauthentication method that supports existing authentication systems for keyless\nentry systems and does not require any modification of the main system to\nperform. Through a series of experiments, the results demonstrate that HODOR\ncompetently and reliably detects attacks on keyless entry systems. HODOR\nachieves both an average false positive rate (FPR) of 0.27 percent with a false\nnegative rate (FNR) of 0 percent for the detection of simulated attacks,\ncorresponding to current research on keyless entry car theft.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 07:50:13 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Joo", "Kyungho", ""], ["Choi", "Wonsuk", ""], ["Lee", "Dong Hoon", ""]]}, {"id": "2003.13259", "submitter": "Pawel Szalachowski", "authors": "Pawel Szalachowski", "title": "SmartCert: Redesigning Digital Certificates with Smart Contracts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Transport Layer Security (TLS) protocol and its public-key infrastructure\n(PKI) are widely used in the Internet to achieve secure communication.\nValidating domain ownership by trusted certification authorities (CAs) is a\ncritical step in issuing digital certificates, but unfortunately, this process\nprovides a poor security level. In this work, we present SmartCert, a novel\napproach based on smart contracts to improve digital certificates. A\ncertificate in SmartCert conveys detailed information about its validation\nstate which is constantly changing but only with respect to the specified smart\ncontract code and individual domain policies. CAs issuing and updating\ncertificates are kept accountable and their actions are transparent and\nmonitored by the code. We present the implementation and evaluation of\nSmartCert, and discuss its deployability.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 08:08:33 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Szalachowski", "Pawel", ""]]}, {"id": "2003.13296", "submitter": "Matthias De Lange", "authors": "Matthias De Lange, Xu Jia, Sarah Parisot, Ales Leonardis, Gregory\n  Slabaugh, Tinne Tuytelaars", "title": "Unsupervised Model Personalization while Preserving Privacy and\n  Scalability: An Open Problem", "comments": "CVPR 2020", "journal-ref": "Proceedings of the IEEE/CVF Conference on Computer Vision and\n  Pattern Recognition (CVPR), June 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates the task of unsupervised model personalization,\nadapted to continually evolving, unlabeled local user images. We consider the\npractical scenario where a high capacity server interacts with a myriad of\nresource-limited edge devices, imposing strong requirements on scalability and\nlocal data privacy. We aim to address this challenge within the continual\nlearning paradigm and provide a novel Dual User-Adaptation framework (DUA) to\nexplore the problem. This framework flexibly disentangles user-adaptation into\nmodel personalization on the server and local data regularization on the user\ndevice, with desirable properties regarding scalability and privacy\nconstraints. First, on the server, we introduce incremental learning of\ntask-specific expert models, subsequently aggregated using a concealed\nunsupervised user prior. Aggregation avoids retraining, whereas the user prior\nconceals sensitive raw user data, and grants unsupervised adaptation. Second,\nlocal user-adaptation incorporates a domain adaptation point of view, adapting\nregularizing batch normalization parameters to the user data. We explore\nvarious empirical user configurations with different priors in categories and a\ntenfold of transforms for MIT Indoor Scene recognition, and classify numbers in\na combined MNIST and SVHN setup. Extensive experiments yield promising results\nfor data-driven local adaptation and elicit user priors for server adaptation\nto depend on the model rather than user data. Hence, although user-adaptation\nremains a challenging open problem, the DUA framework formalizes a principled\nfoundation for personalizing both on server and user device, while maintaining\nprivacy and scalability.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 09:35:12 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["De Lange", "Matthias", ""], ["Jia", "Xu", ""], ["Parisot", "Sarah", ""], ["Leonardis", "Ales", ""], ["Slabaugh", "Gregory", ""], ["Tuytelaars", "Tinne", ""]]}, {"id": "2003.13376", "submitter": "Yansong Gao Dr", "authors": "Yansong Gao, Minki Kim, Sharif Abuadbba, Yeonjae Kim, Chandra Thapa,\n  Kyuyeon Kim, Seyit A. Camtepe, Hyoungshick Kim, Surya Nepal", "title": "End-to-End Evaluation of Federated Learning and Split Learning for\n  Internet of Things", "comments": "10 pages, 12 figures", "journal-ref": "The 39th International Symposium on Reliable Distributed Systems\n  (SRDS) 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is the first attempt to evaluate and compare felderated learning\n(FL) and split neural networks (SplitNN) in real-world IoT settings in terms of\nlearning performance and device implementation overhead. We consider a variety\nof datasets, different model architectures, multiple clients, and various\nperformance metrics. For learning performance, which is specified by the model\naccuracy and convergence speed metrics, we empirically evaluate both FL and\nSplitNN under different types of data distributions such as imbalanced and\nnon-independent and identically distributed (non-IID) data. We show that the\nlearning performance of SplitNN is better than FL under an imbalanced data\ndistribution, but worse than FL under an extreme non-IID data distribution. For\nimplementation overhead, we end-to-end mount both FL and SplitNN on Raspberry\nPis, and comprehensively evaluate overheads including training time,\ncommunication overhead under the real LAN setting, power consumption and memory\nusage. Our key observations are that under IoT scenario where the communication\ntraffic is the main concern, the FL appears to perform better over SplitNN\nbecause FL has the significantly lower communication overhead compared with\nSplitNN, which empirically corroborate previous statistical analysis. In\naddition, we reveal several unrecognized limitations about SplitNN, forming the\nbasis for future research.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 12:12:51 GMT"}, {"version": "v2", "created": "Sun, 2 Aug 2020 08:51:07 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Gao", "Yansong", ""], ["Kim", "Minki", ""], ["Abuadbba", "Sharif", ""], ["Kim", "Yeonjae", ""], ["Thapa", "Chandra", ""], ["Kim", "Kyuyeon", ""], ["Camtepe", "Seyit A.", ""], ["Kim", "Hyoungshick", ""], ["Nepal", "Surya", ""]]}, {"id": "2003.13399", "submitter": "Mengjiao Wang", "authors": "Mengjiao Wang, Hikaru Ichijo and Bob Xiao", "title": "Cryptocurrency Address Clustering and Labeling", "comments": "7 pages, 5 figures, technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anonymity is one of the most important qualities of blockchain technology.\nFor example, one can simply create a bitcoin address to send and receive funds\nwithout providing KYC to any authority. In general, the real identity behind\ncryptocurrency addresses is not known, however, some addresses can be clustered\naccording to their ownership by analyzing behavioral patterns, allowing those\nwith known attribution to be assigned labels. These labels may be further used\nfor legal and compliance purposes to assist in law enforcement investigations.\nIn this document, we discuss our methodology behind assigning attribution\nlabels to cryptocurrency addresses.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 12:34:11 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Wang", "Mengjiao", ""], ["Ichijo", "Hikaru", ""], ["Xiao", "Bob", ""]]}, {"id": "2003.13526", "submitter": "Luca Demetrio", "authors": "Luca Demetrio, Battista Biggio, Giovanni Lagorio, Fabio Roli,\n  Alessandro Armando", "title": "Functionality-preserving Black-box Optimization of Adversarial Windows\n  Malware", "comments": null, "journal-ref": null, "doi": "10.1109/TIFS.2021.3082330", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Windows malware detectors based on machine learning are vulnerable to\nadversarial examples, even if the attacker is only given black-box query access\nto the model. The main drawback of these attacks is that: (i) they are\nquery-inefficient, as they rely on iteratively applying random transformations\nto the input malware; and (ii) they may also require executing the adversarial\nmalware in a sandbox at each iteration of the optimization process, to ensure\nthat its intrusive functionality is preserved. In this paper, we overcome these\nissues by presenting a novel family of black-box attacks that are both\nquery-efficient and functionality-preserving, as they rely on the injection of\nbenign content - which will never be executed - either at the end of the\nmalicious file, or within some newly-created sections. Our attacks are\nformalized as a constrained minimization problem which also enables optimizing\nthe trade-off between the probability of evading detection and the size of the\ninjected payload. We empirically investigate this trade-off on two popular\nstatic Windows malware detectors, and show that our black-box attacks can\nbypass them with only few queries and small payloads, even when they only\nreturn the predicted labels. We also evaluate whether our attacks transfer to\nother commercial antivirus solutions, and surprisingly find that they can\nevade, on average, more than 12 commercial antivirus engines. We conclude by\ndiscussing the limitations of our approach, and its possible future extensions\nto target malware classifiers based on dynamic analysis.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 14:56:01 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 07:46:51 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2020 15:16:04 GMT"}, {"version": "v4", "created": "Thu, 18 Feb 2021 15:43:31 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Demetrio", "Luca", ""], ["Biggio", "Battista", ""], ["Lagorio", "Giovanni", ""], ["Roli", "Fabio", ""], ["Armando", "Alessandro", ""]]}, {"id": "2003.13604", "submitter": "Elisa Bertino", "authors": "Elisa Bertino, Syed Rafiul Hussain, and Omar Chowdhury", "title": "5G Security and Privacy: A Research Roadmap", "comments": "A Computing Community Consortium (CCC) white paper, 8 pages", "journal-ref": null, "doi": null, "report-no": "ccc2020whitepaper_1", "categories": "cs.CY cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cellular networks represent a critical infrastructure and their security is\nthus crucial. 5G - the latest generation of cellular networks - combines\ndifferent technologies to increase capacity, reduce latency, and save energy.\nDue to its complexity and scale, however, ensuring its security is extremely\nchallenging. In this white paper, we outline recent approaches supporting\nsystematic analyses of 4G LTE and 5G protocols and their related defenses and\nintroduce an initial security and privacy roadmap, covering different research\nchallenges, including formal and comprehensive analyses of cellular protocols\nas defined by the standardization groups, verification of the software\nimplementing the protocols, the design of robust defenses, and application and\ndevice security.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 16:36:43 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Bertino", "Elisa", ""], ["Hussain", "Syed Rafiul", ""], ["Chowdhury", "Omar", ""]]}, {"id": "2003.13617", "submitter": "Javad Ghofrani", "authors": "Kirill Loisha, Javad Ghofrani, Dirk Reichelt", "title": "A Systematic Mapping Study on Blockchain Technology for Digital\n  Protection of Communication with Industrial Control", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the next few years, Blockchain will play a central role in IoT as a\ntechnology. It enables the traceability of processes between multiple parties\nindependent of a central instance. Blockchain allows to make the processes more\ntransparent, cheaper, and safer. This research paper was conducted as\nsystematic literature search. Our aim is to understand current state of\nimplementation in context of Blockchain Technology for digital protection of\ncommunication in industrial cyber-physical systems. We have extracted 28\nprimary papers from scientific databases and classified into different\ncategories using visualizations. The results show that the focus in around 14\\%\npapers is on solution proposal and implementation of use cases \"Secure transfer\nof order data\" using Ethereum Blockchain, 7\\% papers applying Hyperledger\nFabric and Multichain. The majority of research (around 43\\%) is focusing on\nsolution development for supply chain and process traceability.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 16:49:11 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Loisha", "Kirill", ""], ["Ghofrani", "Javad", ""], ["Reichelt", "Dirk", ""]]}, {"id": "2003.13667", "submitter": "Karim Banawan", "authors": "Sajani Vithana and Karim Banawan and Sennur Ulukus", "title": "Semantic Private Information Retrieval", "comments": "submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of semantic private information retrieval\n(semantic PIR). In semantic PIR, a user retrieves a message out of $K$\nindependent messages stored in $N$ replicated and non-colluding databases\nwithout revealing the identity of the desired message to any individual\ndatabase. The messages come with \\emph{different semantics}, i.e., the messages\nare allowed to have \\emph{non-uniform a priori probabilities} denoted by\n$(p_i>0,\\: i \\in [K])$, which are a proxy for their respective popularity of\nretrieval, and \\emph{arbitrary message sizes} $(L_i,\\: i \\in [K])$. This is a\ngeneralization of the classical private information retrieval (PIR) problem,\nwhere messages are assumed to have equal a priori probabilities and equal\nmessage sizes. We derive the semantic PIR capacity for general $K$, $N$. The\nresults show that the semantic PIR capacity depends on the number of databases\n$N$, the number of messages $K$, the a priori probability distribution of\nmessages $p_i$, and the message sizes $L_i$. We present two achievable semantic\nPIR schemes: The first one is a deterministic scheme which is based on message\nasymmetry. This scheme employs non-uniform subpacketization. The second scheme\nis probabilistic and is based on choosing one query set out of multiple options\nat random to retrieve the required message without the need for exponential\nsubpacketization. We derive necessary and sufficient conditions for the\nsemantic PIR capacity to exceed the classical PIR capacity with equal priors\nand sizes. Our results show that the semantic PIR capacity can be larger than\nthe classical PIR capacity when longer messages have higher popularities.\nHowever, when messages are equal-length, the non-uniform priors cannot be\nexploited to improve the retrieval rate over the classical PIR capacity.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 17:51:57 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Vithana", "Sajani", ""], ["Banawan", "Karim", ""], ["Ulukus", "Sennur", ""]]}, {"id": "2003.13670", "submitter": "Mayank Varia", "authors": "Ran Canetti, Ari Trachtenberg, and Mayank Varia", "title": "Anonymous Collocation Discovery: Harnessing Privacy to Tame the\n  Coronavirus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Successful containment of the Coronavirus pandemic rests on the ability to\nquickly and reliably identify those who have been in close proximity to a\ncontagious individual. Existing tools for doing so rely on the collection of\nexact location information of individuals over lengthy time periods, and\ncombining this information with other personal information. This unprecedented\nencroachment on individual privacy at national scales has created an outcry and\nrisks rejection of these tools.\n  We propose an alternative: an extremely simple scheme for providing\nfine-grained and timely alerts to users who have been in the close vicinity of\nan infected individual. Crucially, this is done while preserving the anonymity\nof all individuals, and without collecting or storing any personal information\nor location history. Our approach is based on using short-range communication\nmechanisms, like Bluetooth, that are available in all modern cell phones. It\ncan be deployed with very little infrastructure, and incurs a relatively low\nfalse-positive rate compared to other collocation methods. We also describe a\nnumber of extensions and tradeoffs.\n  We believe that the privacy guarantees provided by the scheme will encourage\nquick and broad voluntary adoption. When combined with sufficient testing\ncapacity and existing best practices from healthcare professionals, we hope\nthat this may significantly reduce the infection rate.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 17:54:26 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 11:51:40 GMT"}, {"version": "v3", "created": "Wed, 1 Apr 2020 17:52:47 GMT"}, {"version": "v4", "created": "Fri, 3 Apr 2020 22:13:00 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Canetti", "Ran", ""], ["Trachtenberg", "Ari", ""], ["Varia", "Mayank", ""]]}, {"id": "2003.13746", "submitter": "Fan Yao", "authors": "Fan Yao, Adnan Siraj Rakin, Deliang Fan", "title": "DeepHammer: Depleting the Intelligence of Deep Neural Networks through\n  Targeted Chain of Bit Flips", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security of machine learning is increasingly becoming a major concern due to\nthe ubiquitous deployment of deep learning in many security-sensitive domains.\nMany prior studies have shown external attacks such as adversarial examples\nthat tamper with the integrity of DNNs using maliciously crafted inputs.\nHowever, the security implication of internal threats (i.e., hardware\nvulnerability) to DNN models has not yet been well understood. In this paper,\nwe demonstrate the first hardware-based attack on quantized deep neural\nnetworks-DeepHammer-that deterministically induces bit flips in model weights\nto compromise DNN inference by exploiting the rowhammer vulnerability.\nDeepHammer performs aggressive bit search in the DNN model to identify the most\nvulnerable weight bits that are flippable under system constraints. To trigger\ndeterministic bit flips across multiple pages within reasonable amount of time,\nwe develop novel system-level techniques that enable fast deployment of victim\npages, memory-efficient rowhammering and precise flipping of targeted bits.\nDeepHammer can deliberately degrade the inference accuracy of the victim DNN\nsystem to a level that is only as good as random guess, thus completely\ndepleting the intelligence of targeted DNN systems. We systematically\ndemonstrate our attacks on real systems against 12 DNN architectures with 4\ndifferent datasets and different application domains. Our evaluation shows that\nDeepHammer is able to successfully tamper DNN inference behavior at run-time\nwithin a few minutes. We further discuss several mitigation techniques from\nboth algorithm and system levels to protect DNNs against such attacks. Our work\nhighlights the need to incorporate security mechanisms in future deep learning\nsystem to enhance the robustness of DNN against hardware-based deterministic\nfault injections.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 18:51:59 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Yao", "Fan", ""], ["Rakin", "Adnan Siraj", ""], ["Fan", "Deliang", ""]]}, {"id": "2003.13761", "submitter": "Yanmin Gong", "authors": "Rui Hu, Yuanxiong Guo, and Yanmin Gong", "title": "Concentrated Differentially Private and Utility Preserving Federated\n  Learning", "comments": "Under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a machine learning setting where a set of edge devices\ncollaboratively train a model under the orchestration of a central server\nwithout sharing their local data. At each communication round of federated\nlearning, edge devices perform multiple steps of stochastic gradient descent\nwith their local data and then upload the computation results to the server for\nmodel update. During this process, the challenge of privacy leakage arises due\nto the information exchange between edge devices and the server when the server\nis not fully trusted. While some previous privacy-preserving mechanisms could\nreadily be used for federated learning, they usually come at a high cost on\nconvergence of the algorithm and utility of the learned model. In this paper,\nwe develop a federated learning approach that addresses the privacy challenge\nwithout much degradation on model utility through a combination of local\ngradient perturbation, secure aggregation, and zero-concentrated differential\nprivacy (zCDP). We provide a tight end-to-end privacy guarantee of our approach\nand analyze its theoretical convergence rates. Through extensive numerical\nexperiments on real-world datasets, we demonstrate the effectiveness of our\nproposed method and show its superior trade-off between privacy and model\nutility.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 19:20:42 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 19:31:59 GMT"}, {"version": "v3", "created": "Sun, 20 Sep 2020 22:12:30 GMT"}, {"version": "v4", "created": "Tue, 22 Sep 2020 15:12:02 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Hu", "Rui", ""], ["Guo", "Yuanxiong", ""], ["Gong", "Yanmin", ""]]}, {"id": "2003.13904", "submitter": "Fatemeh Ganji", "authors": "Rabin Yu Acharya, Sreeja Chowdhury, Fatemeh Ganji, and Domenic Forte", "title": "Attack of the Genes: Finding Keys and Parameters of Locked Analog ICs\n  Using Genetic Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware intellectual property (IP) theft is a major issue in today's\nglobalized supply chain. To address it, numerous logic locking and obfuscation\ntechniques have been proposed. While locking initially focused on digital\nintegrated circuits (ICs), there have been recent attempts to extend it to\nanalog ICs, which are easier to reverse engineer and to copy than digital ICs.\nIn this paper, we use algorithms based on evolutionary strategies to\ninvestigate the security of analog obfuscation/locking techniques. We present a\ngenetic algorithm (GA) approach which is capable of completely breaking a\nlocked analog circuit by finding either its obfuscation key or its obfuscated\nparameters. We implement both the GA attack as well as a more naive\nsatisfiability modulo theory (SMT)-based attack on common analog benchmark\ncircuits obfuscated by combinational locking and parameter biasing. We find\nthat GA attack can unlock all the circuits using only the locked netlist and an\nunlocked chip in minutes. On the other hand, while the SMT attack converges\nfaster, it requires circuit specification to execute and it also returns\nmultiple keys that need to be brute-forced by a post-processing step. We also\ndiscuss how the GA attack can generalize to other recent analog locking\ntechniques not tested in the paper\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 01:38:00 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Acharya", "Rabin Yu", ""], ["Chowdhury", "Sreeja", ""], ["Ganji", "Fatemeh", ""], ["Forte", "Domenic", ""]]}, {"id": "2003.13917", "submitter": "C.-H. Huck Yang", "authors": "Chao-Han Huck Yang, Jun Qi, Pin-Yu Chen, Xiaoli Ma, Chin-Hui Lee", "title": "Characterizing Speech Adversarial Examples Using Self-Attention U-Net\n  Enhancement", "comments": "The first draft was finished in August 2019. Accepted to IEEE ICASSP\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.CR cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent studies have highlighted adversarial examples as ubiquitous threats to\nthe deep neural network (DNN) based speech recognition systems. In this work,\nwe present a U-Net based attention model, U-Net$_{At}$, to enhance adversarial\nspeech signals. Specifically, we evaluate the model performance by\ninterpretable speech recognition metrics and discuss the model performance by\nthe augmented adversarial training. Our experiments show that our proposed\nU-Net$_{At}$ improves the perceptual evaluation of speech quality (PESQ) from\n1.13 to 2.78, speech transmission index (STI) from 0.65 to 0.75, short-term\nobjective intelligibility (STOI) from 0.83 to 0.96 on the task of speech\nenhancement with adversarial speech examples. We conduct experiments on the\nautomatic speech recognition (ASR) task with adversarial audio attacks. We find\nthat (i) temporal features learned by the attention network are capable of\nenhancing the robustness of DNN based ASR models; (ii) the generalization power\nof DNN based ASR model could be enhanced by applying adversarial training with\nan additive adversarial data augmentation. The ASR metric on word-error-rates\n(WERs) shows that there is an absolute 2.22 $\\%$ decrease under gradient-based\nperturbation, and an absolute 2.03 $\\%$ decrease, under evolutionary-optimized\nperturbation, which suggests that our enhancement models with adversarial\ntraining can further secure a resilient ASR system.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 02:16:34 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Yang", "Chao-Han Huck", ""], ["Qi", "Jun", ""], ["Chen", "Pin-Yu", ""], ["Ma", "Xiaoli", ""], ["Lee", "Chin-Hui", ""]]}, {"id": "2003.13922", "submitter": "Tianhao Wang", "authors": "Aiping Xiong, Tianhao Wang, Ninghui Li, Somesh Jha", "title": "Towards Effective Differential Privacy Communication for Users' Data\n  Sharing Decision and Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy protects an individual's privacy by perturbing data on\nan aggregated level (DP) or individual level (LDP). We report four online\nhuman-subject experiments investigating the effects of using different\napproaches to communicate differential privacy techniques to laypersons in a\nhealth app data collection setting. Experiments 1 and 2 investigated\nparticipants' data disclosure decisions for low-sensitive and high-sensitive\npersonal information when given different DP or LDP descriptions. Experiments 3\nand 4 uncovered reasons behind participants' data sharing decisions, and\nexamined participants' subjective and objective comprehensions of these DP or\nLDP descriptions. When shown descriptions that explain the implications instead\nof the definition/processes of DP or LDP technique, participants demonstrated\nbetter comprehension and showed more willingness to share information with LDP\nthan with DP, indicating their understanding of LDP's stronger privacy\nguarantee compared with DP.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 02:36:39 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Xiong", "Aiping", ""], ["Wang", "Tianhao", ""], ["Li", "Ninghui", ""], ["Jha", "Somesh", ""]]}, {"id": "2003.13955", "submitter": "Farzad Zafarani", "authors": "Farzad Zafarani and Chris Clifton", "title": "Differentially Private Naive Bayes Classifier using Smooth Sensitivity", "comments": "14 Pages, PETS'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing collection of users' data, protecting individual privacy\nhas gained more interest. Differential Privacy is a strong concept of\nprotecting individuals. Naive Bayes is one of the popular machine learning\nalgorithm, used as a baseline for many tasks. In this work, we have provided a\ndifferentially private Naive Bayes classifier that adds noise proportional to\nthe Smooth Sensitivity of its parameters. We have compared our result to\nVaidya, Shafiq, Basu, and Hong in which they have scaled the noise to the\nglobal sensitivity of the parameters. Our experiment results on the real-world\ndatasets show that the accuracy of our method has improved significantly while\nstill preserving $\\varepsilon$-differential privacy.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 05:03:04 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 17:31:22 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Zafarani", "Farzad", ""], ["Clifton", "Chris", ""]]}, {"id": "2003.13999", "submitter": "Weilin Zheng", "authors": "Weilin Zheng, Xu Chen, Zibin Zheng, Xiapu Luo, Jiahui Cui", "title": "AxeChain: A Secure and Decentralized blockchain for solving\n  Easily-Verifiable problems", "comments": "14 pages, 14 figures, 3 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Proof-of-Work (PoW) is the most widely used consensus mechanism for\nblockchain, it received harsh criticism due to its massive waste of energy for\nmeaningless hash calculation. Some studies have introduced Proof-of-Stake to\naddress this issue. However, such protocols widen the gap between rich and poor\nand in the worst case lead to an oligopoly, where the rich control the entire\nnetwork. Other studies have attempted to translate the energy consumption of\nPoW into useful work, but they have many limitations, such as narrow\napplication scope, serious security issues and impractical incentive model. In\nthis paper, we introduce AxeChain, which can use the computing power of\nblockchain to solve practical problems raised by users without greatly\ncompromising decentralization or security. AxeChain achieves this by coupling\nhard problem solving with PoW mining. We model the security of AxeChain and\nderive a balance curve between power utilization and system security. That is,\nunder the reasonable assumption that the attack power does not exceed 1/3 of\nthe total power, 1/2 of total power can be safely used to solve practical\nproblems. We also design a novel incentive model based on the amount of work\ninvolved in problem solving, balancing the interests of both the users and\nminers. Moreover, our experimental results show that AxeChain provides strong\nsecurity guarantees, no matter what kind of problem is submitted.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 07:40:16 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Zheng", "Weilin", ""], ["Chen", "Xu", ""], ["Zheng", "Zibin", ""], ["Luo", "Xiapu", ""], ["Cui", "Jiahui", ""]]}, {"id": "2003.14053", "submitter": "Jonas Geiping", "authors": "Jonas Geiping, Hartmut Bauermeister, Hannah Dr\\\"oge, Michael Moeller", "title": "Inverting Gradients -- How easy is it to break privacy in federated\n  learning?", "comments": "23 pages, 20 figures. The first three authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea of federated learning is to collaboratively train a neural network\non a server. Each user receives the current weights of the network and in turns\nsends parameter updates (gradients) based on local data. This protocol has been\ndesigned not only to train neural networks data-efficiently, but also to\nprovide privacy benefits for users, as their input data remains on device and\nonly parameter gradients are shared. But how secure is sharing parameter\ngradients? Previous attacks have provided a false sense of security, by\nsucceeding only in contrived settings - even for a single image. However, by\nexploiting a magnitude-invariant loss along with optimization strategies based\non adversarial attacks, we show that is is actually possible to faithfully\nreconstruct images at high resolution from the knowledge of their parameter\ngradients, and demonstrate that such a break of privacy is possible even for\ntrained deep networks. We analyze the effects of architecture as well as\nparameters on the difficulty of reconstructing an input image and prove that\nany input to a fully connected layer can be reconstructed analytically\nindependent of the remaining architecture. Finally we discuss settings\nencountered in practice and show that even averaging gradients over several\niterations or several images does not protect the user's privacy in federated\nlearning applications in computer vision.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 09:35:02 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 11:41:10 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Geiping", "Jonas", ""], ["Bauermeister", "Hartmut", ""], ["Dr\u00f6ge", "Hannah", ""], ["Moeller", "Michael", ""]]}, {"id": "2003.14094", "submitter": "Mahboubeh Nazari", "authors": "Mahboubeh Nazari, Sousan Tarahomi, Sobhan Aliabady", "title": "A Lightweight Adaptable DNS Channel for Covert Data Transmission", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the vital role of security in online communications and this fact that\nattackers are developing their tools, modernizing the security tools is an\nessential. The efficiency of crypto systems has been proven after years,\nhowever one may need to communicate stealthy without drawing attention\nespecially in transferring secret data such as keys. Covert channels are\nsuitable tools that used to conceal the existence of data besides end\ncommunication parties by employing principles of steganography. They can make\nsecure communications with obscurity. Working stealthy and providing an\nacceptable throughput are issues in designing covert channels. The DNS protocol\nproperties like its necessity for running applications and the availability can\nprovide aforementioned issues decently. In this paper, we proposed a storage\ncovert channel which uses DNS protocol as a media for transferring data. The\nkey features include connection establishment, adaptability with network\nenvironment, implying a lightweight obfuscation method and HMAC to meet\nconfidentiality and integrity. Experimental results show the proposed channel\nstatistics are well adapted with normal traffics. The channel has an average\ncapacity of 2.65 bytes of data per packet.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 11:05:53 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Nazari", "Mahboubeh", ""], ["Tarahomi", "Sousan", ""], ["Aliabady", "Sobhan", ""]]}, {"id": "2003.14099", "submitter": "Do Le Quoc", "authors": "Franz Gregor and Wojciech Ozga and S\\'ebastien Vaucher and Rafael\n  Pires and Do Le Quoc and Sergei Arnautov and Andr\\'e Martin and Valerio\n  Schiavoni and Pascal Felber and Christof Fetzer", "title": "Trust Management as a Service: Enabling Trusted Execution in the Face of\n  Byzantine Stakeholders", "comments": "European Commission Project: LEGaTO - Low Energy Toolset for\n  Heterogeneous Computing (EC-H2020-780681)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Trust is arguably the most important challenge for critical services both\ndeployed as well as accessed remotely over the network. These systems are\nexposed to a wide diversity of threats, ranging from bugs to exploits, active\nattacks, rogue operators, or simply careless administrators. To protect such\napplications, one needs to guarantee that they are properly configured and\nsecurely provisioned with the \"secrets\" (e.g., encryption keys) necessary to\npreserve not only the confidentiality, integrity and freshness of their data\nbut also their code. Furthermore, these secrets should not be kept under the\ncontrol of a single stakeholder - which might be compromised and would\nrepresent a single point of failure - and they must be protected across\nsoftware versions in the sense that attackers cannot get access to them via\nmalicious updates. Traditional approaches for solving these challenges often\nuse ad hoc techniques and ultimately rely on a hardware security module (HSM)\nas root of trust. We propose a more powerful and generic approach to trust\nmanagement that instead relies on trusted execution environments (TEEs) and a\nset of stakeholders as root of trust. Our system, PALAEMON, can operate as a\nmanaged service deployed in an untrusted environment, i.e., one can delegate\nits operations to an untrusted cloud provider with the guarantee that data will\nremain confidential despite not trusting any individual human (even with root\naccess) nor system software. PALAEMON addresses in a secure, efficient and\ncost-effective way five main challenges faced when developing trusted networked\napplications and services. Our evaluation on a range of benchmarks and real\napplications shows that PALAEMON performs efficiently and can protect secrets\nof services without any change to their source code.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 11:13:05 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Gregor", "Franz", ""], ["Ozga", "Wojciech", ""], ["Vaucher", "S\u00e9bastien", ""], ["Pires", "Rafael", ""], ["Quoc", "Do Le", ""], ["Arnautov", "Sergei", ""], ["Martin", "Andr\u00e9", ""], ["Schiavoni", "Valerio", ""], ["Felber", "Pascal", ""], ["Fetzer", "Christof", ""]]}, {"id": "2003.14123", "submitter": "Harel Berger", "authors": "Harel Berger and Chen Hajaj and Amit Dvir", "title": "When the Guard failed the Droid: A case study of Android malware", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Android malware is a persistent threat to billions of users around the world.\nAs a countermeasure, Android malware detection systems are occasionally\nimplemented. However, these systems are often vulnerable to \\emph{evasion\nattacks}, in which an adversary manipulates malicious instances so that they\nare misidentified as benign. In this paper, we launch various innovative\nevasion attacks against several Android malware detection systems. The\nvulnerability inherent to all of these systems is that they are part of\nAndroguard~\\cite{desnos2011androguard}, a popular open source library used in\nAndroid malware detection systems. Some of the detection systems decrease to a\n0\\% detection rate after the attack. Therefore, the use of open source\nlibraries in malware detection systems calls for caution.\n  In addition, we present a novel evaluation scheme for evasion attack\ngeneration that exploits the weak spots of known Android malware detection\nsystems. In so doing, we evaluate the functionality and maliciousness of the\nmanipulated instances created by our evasion attacks. We found variations in\nboth the maliciousness and functionality tests of our manipulated apps. We show\nthat non-functional apps, while considered malicious, do not threaten users and\nare thus useless from an attacker's point of view. We conclude that evasion\nattacks must be assessed for both functionality and maliciousness to evaluate\ntheir impact, a step which is far from commonplace today.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 11:55:18 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Berger", "Harel", ""], ["Hajaj", "Chen", ""], ["Dvir", "Amit", ""]]}, {"id": "2003.14215", "submitter": "Roberto La Scala", "authors": "Roberto La Scala, Sharwan K. Tiwari", "title": "Stream/block ciphers, difference equations and algebraic attacks", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a general class of stream and block ciphers that\nare defined by means of systems of (ordinary) explicit difference equations\nover a finite field. We call this class \"difference ciphers\". Many important\nciphers such as systems of LFSRs, Trivium/Bivium and Keeloq are difference\nciphers. To the purpose of studying their underlying explicit difference\nsystems, we introduce key notions as state transition endomorphisms and show\nconditions for their invertibility. Reducible and periodic systems are also\nconsidered. We then propose general algebraic attacks to difference ciphers\nwhich are experimented by means of Bivium and Keeloq.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 18:40:13 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["La Scala", "Roberto", ""], ["Tiwari", "Sharwan K.", ""]]}, {"id": "2003.14243", "submitter": "Adam Wolisz", "authors": "Adam Wolisz", "title": "A Fully Distributed, Privacy Respecting Approach for Back-tracking of\n  Potentially Infectious Contacts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In limiting the rapid spread of highly infectious diseases like Covid-19\nmeans to immediately identify individuals who had been in contact with a newly\ndiagnosed infected person have proven to be important. Such potential victims\ncan go into quarantine until tested thus constraining further spread. This note\ndescribes a concept of mobile device (e.g. Smart phones) based approach for\ntracking interpersonal contacts which might have led to infection and alerting\nthe potential victims. The approach assures means for defense against malicious\nusage while assuring a high level of privacy for all people involved.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 14:23:19 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Wolisz", "Adam", ""]]}, {"id": "2003.14265", "submitter": "Rajesh Jayaram", "authors": "Omri Ben-Eliezer and Rajesh Jayaram and David P. Woodruff and Eylon\n  Yogev", "title": "A Framework for Adversarially Robust Streaming Algorithms", "comments": "To appear in PODS 2020. Version 2: acknowledged all funding support", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the adversarial robustness of streaming algorithms. In this\ncontext, an algorithm is considered robust if its performance guarantees hold\neven if the stream is chosen adaptively by an adversary that observes the\noutputs of the algorithm along the stream and can react in an online manner.\nWhile deterministic streaming algorithms are inherently robust, many central\nproblems in the streaming literature do not admit sublinear-space deterministic\nalgorithms; on the other hand, classical space-efficient randomized algorithms\nfor these problems are generally not adversarially robust. This raises the\nnatural question of whether there exist efficient adversarially robust\n(randomized) streaming algorithms for these problems.\n  In this work, we show that the answer is positive for various important\nstreaming problems in the insertion-only model, including distinct elements and\nmore generally $F_p$-estimation, $F_p$-heavy hitters, entropy estimation, and\nothers. For all of these problems, we develop adversarially robust\n$(1+\\varepsilon)$-approximation algorithms whose required space matches that of\nthe best known non-robust algorithms up to a $\\text{poly}(\\log n,\n1/\\varepsilon)$ multiplicative factor (and in some cases even up to a constant\nfactor). Towards this end, we develop several generic tools allowing one to\nefficiently transform a non-robust streaming algorithm into a robust one in\nvarious scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 14:50:27 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 14:23:12 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Ben-Eliezer", "Omri", ""], ["Jayaram", "Rajesh", ""], ["Woodruff", "David P.", ""], ["Yogev", "Eylon", ""]]}, {"id": "2003.14271", "submitter": "Murdoch Gabbay", "authors": "Lars Brunjes and Murdoch J. Gabbay", "title": "UTxO- vs account-based smart contract blockchain programming paradigms", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-61467-6_6", "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We implement two versions of a simple but illustrative smart contract: one in\nSolidity on the Ethereum blockchain platform, and one in Plutus on the Cardano\nplatform, with annotated code excerpts and with source code attached. We get a\nclearer view of the Cardano programming model in particular by introducing a\nnovel mathematical abstraction which we call Idealised EUTxO. For each version\nof the contract, we trace how the architectures of the underlying platforms and\ntheir mathematics affects the natural programming styles and natural classes of\nerrors. We prove some simple but novel results about alpha-conversion and\nobservational equivalence for Cardano, and explain why Ethereum does not have\nthem. We conclude with a wide-ranging and detailed discussion in the light of\nthe examples, mathematical model, and mathematical results so far.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 14:53:56 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 06:40:15 GMT"}, {"version": "v3", "created": "Mon, 6 Apr 2020 10:38:49 GMT"}, {"version": "v4", "created": "Mon, 20 Jul 2020 08:29:50 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Brunjes", "Lars", ""], ["Gabbay", "Murdoch J.", ""]]}, {"id": "2003.14356", "submitter": "Chris Mitchell", "authors": "Chris J Mitchell", "title": "Yet another insecure group key distribution scheme using secret sharing", "comments": "Minor modifications to provide extra background", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recently proposed group key distribution scheme known as UMKESS, based on\nsecret sharing, is shown to be insecure. Not only is it insecure, but it does\nnot always work, and the rationale for its design is unsound. UMKESS is the\nlatest in a long line of flawed group key distribution schemes based on secret\nsharing techniques.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 16:38:50 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 11:44:38 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Mitchell", "Chris J", ""]]}, {"id": "2003.14412", "submitter": "Michiel Bakker", "authors": "Alex Berke, Michiel Bakker, Praneeth Vepakomma, Kent Larson, Alex\n  'Sandy' Pentland", "title": "Assessing Disease Exposure Risk with Location Data: A Proposal for\n  Cryptographic Preservation of Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Governments and researchers around the world are implementing digital contact\ntracing solutions to stem the spread of infectious disease, namely COVID-19.\nMany of these solutions threaten individual rights and privacy. Our goal is to\nbreak past the false dichotomy of effective versus privacy-preserving contact\ntracing. We offer an alternative approach to assess and communicate users' risk\nof exposure to an infectious disease while preserving individual privacy. Our\nproposal uses recent GPS location histories, which are transformed and\nencrypted, and a private set intersection protocol to interface with a\nsemi-trusted authority.\n  There have been other recent proposals for privacy-preserving contact\ntracing, based on Bluetooth and decentralization, that could further eliminate\nthe need for trust in authority. However, solutions with Bluetooth are\ncurrently limited to certain devices and contexts while decentralization adds\ncomplexity. The goal of this work is two-fold: we aim to propose a\nlocation-based system that is more privacy-preserving than what is currently\nbeing adopted by governments around the world, and that is also practical to\nimplement with the immediacy needed to stem a viral outbreak.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 17:56:30 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 17:38:06 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Berke", "Alex", ""], ["Bakker", "Michiel", ""], ["Vepakomma", "Praneeth", ""], ["Larson", "Kent", ""], ["Pentland", "Alex 'Sandy'", ""]]}]