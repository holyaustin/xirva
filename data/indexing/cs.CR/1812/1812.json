[{"id": "1812.00117", "submitter": "Masahito Hayashi", "authors": "Masahito Hayashi", "title": "Secure physical layer network coding versus secure network coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secure network coding realizes the secrecy of the message when the message is\ntransmitted via noiseless network and a part of edges or a part of intermediate\nnodes are eavesdropped. In this framework, if the channels of the network has\nnoise, we apply the error correction to noisy channel before applying the\nsecure network coding. In contrast, secure physical layer network coding is a\nmethod to securely transmit a message by a combination of coding operation on\nnodes when the network is given as a set of noisy channels. In this paper, we\ngive several examples of network, in which, secure physical layer network\ncoding has advantage over secure network coding.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 01:16:27 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Hayashi", "Masahito", ""]]}, {"id": "1812.00125", "submitter": "Fabrice Benhamouda", "authors": "Fabrice Benhamouda and Marc Joye", "title": "How to Profile Privacy-Conscious Users in Recommender Systems", "comments": "6 pages, accepted at the Privacy Preserving Machine Learning NeurIPS\n  2018 Workshop (PPML), https://ppml-workshop.github.io/ppml", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix factorization is a popular method to build a recommender system. In\nsuch a system, existing users and items are associated to a low-dimension\nvector called a profile. The profiles of a user and of an item can be combined\n(via inner product) to predict the rating that the user would get on the item.\nOne important issue of such a system is the so-called cold-start problem: how\nto allow a user to learn her profile, so that she can then get accurate\nrecommendations?\n  While a profile can be computed if the user is willing to rate well-chosen\nitems and/or provide supplemental attributes or demographics (such as gender),\nrevealing this additional information is known to allow the analyst of the\nrecommender system to infer many more personal sensitive information. We design\na protocol to allow privacy-conscious users to benefit from\nmatrix-factorization-based recommender systems while preserving their privacy.\nMore precisely, our protocol enables a user to learn her profile, and from that\nto predict ratings without the user revealing any personal information. The\nprotocol is secure in the standard model against semi-honest adversaries.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 02:16:49 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Benhamouda", "Fabrice", ""], ["Joye", "Marc", ""]]}, {"id": "1812.00140", "submitter": "Valentin Manes Jean Marie", "authors": "Valentin J.M. Manes, HyungSeok Han, Choongwoo Han, Sang Kil Cha,\n  Manuel Egele, Edward J. Schwartz, Maverick Woo", "title": "The Art, Science, and Engineering of Fuzzing: A Survey", "comments": "29 pages, under submission to ACM Computing Surveys (July 2018) -\n  2018.12.10 update: correct minor mistakes in overview table - 2019.02.16\n  update: source clean - 2019.04.08: submission to TSE, 21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among the many software vulnerability discovery techniques available today,\nfuzzing has remained highly popular due to its conceptual simplicity, its low\nbarrier to deployment, and its vast amount of empirical evidence in discovering\nreal-world software vulnerabilities. At a high level, fuzzing refers to a\nprocess of repeatedly running a program with generated inputs that may be\nsyntactically or semantically malformed. While researchers and practitioners\nalike have invested a large and diverse effort towards improving fuzzing in\nrecent years, this surge of work has also made it difficult to gain a\ncomprehensive and coherent view of fuzzing. To help preserve and bring\ncoherence to the vast literature of fuzzing, this paper presents a unified,\ngeneral-purpose model of fuzzing together with a taxonomy of the current\nfuzzing literature. We methodically explore the design decisions at every stage\nof our model fuzzer by surveying the related literature and innovations in the\nart, science, and engineering that make modern-day fuzzers effective.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 04:16:27 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 06:07:17 GMT"}, {"version": "v3", "created": "Sat, 16 Feb 2019 01:11:18 GMT"}, {"version": "v4", "created": "Mon, 8 Apr 2019 01:13:43 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Manes", "Valentin J. M.", ""], ["Han", "HyungSeok", ""], ["Han", "Choongwoo", ""], ["Cha", "Sang Kil", ""], ["Egele", "Manuel", ""], ["Schwartz", "Edward J.", ""], ["Woo", "Maverick", ""]]}, {"id": "1812.00151", "submitter": "Qi Lei", "authors": "Qi Lei, Lingfei Wu, Pin-Yu Chen, Alexandros G. Dimakis, Inderjit S.\n  Dhillon, Michael Witbrock", "title": "Discrete Adversarial Attacks and Submodular Optimization with\n  Applications to Text Classification", "comments": "In SysML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are carefully constructed modifications to an input that\ncompletely change the output of a classifier but are imperceptible to humans.\nDespite these successful attacks for continuous data (such as image and audio\nsamples), generating adversarial examples for discrete structures such as text\nhas proven significantly more challenging. In this paper we formulate the\nattacks with discrete input on a set function as an optimization task. We prove\nthat this set function is submodular for some popular neural network text\nclassifiers under simplifying assumption. This finding guarantees a $1-1/e$\napproximation factor for attacks that use the greedy algorithm. Meanwhile, we\nshow how to use the gradient of the attacked classifier to guide the greedy\nsearch. Empirical studies with our proposed optimization scheme show\nsignificantly improved attack ability and efficiency, on three different text\nclassification tasks over various baselines. We also use a joint sentence and\nword paraphrasing technique to maintain the original semantics and syntax of\nthe text. This is validated by a human subject evaluation in subjective metrics\non the quality and semantic coherence of our generated adversarial text.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 05:48:16 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 19:56:23 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Lei", "Qi", ""], ["Wu", "Lingfei", ""], ["Chen", "Pin-Yu", ""], ["Dimakis", "Alexandros G.", ""], ["Dhillon", "Inderjit S.", ""], ["Witbrock", "Michael", ""]]}, {"id": "1812.00190", "submitter": "Raja Naeem Akram", "authors": "Julia A. Meister, Raja Naeem Akram, Konstantinos Markantonakis", "title": "Deep Learning Application in Security and Privacy -- Theory and\n  Practice: A Position Paper", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technology is shaping our lives in a multitude of ways. This is fuelled by a\ntechnology infrastructure, both legacy and state of the art, composed of a\nheterogeneous group of hardware, software, services and organisations. Such\ninfrastructure faces a diverse range of challenges to its operations that\ninclude security, privacy, resilience, and quality of services. Among these,\ncybersecurity and privacy are taking the centre-stage, especially since the\nGeneral Data Protection Regulation (GDPR) came into effect. Traditional\nsecurity and privacy techniques are overstretched and adversarial actors have\nevolved to design exploitation techniques that circumvent protection. With the\never-increasing complexity of technology infrastructure, security and\nprivacy-preservation specialists have started to look for adaptable and\nflexible protection methods that can evolve (potentially autonomously) as the\nadversarial actor changes its techniques. For this, Artificial Intelligence\n(AI), Machine Learning (ML) and Deep Learning (DL) were put forward as\nsaviours. In this paper, we look at the promises of AI, ML, and DL stated in\nacademic and industrial literature and evaluate how realistic they are. We also\nput forward potential challenges a DL based security and privacy protection\ntechnique has to overcome. Finally, we conclude the paper with a discussion on\nwhat steps the DL and the security and privacy-preservation community have to\ntake to ensure that DL is not just going to be hype, but an opportunity to\nbuild a secure, reliable, and trusted technology infrastructure on which we can\nrely on for so much in our lives.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 11:30:23 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Meister", "Julia A.", ""], ["Akram", "Raja Naeem", ""], ["Markantonakis", "Konstantinos", ""]]}, {"id": "1812.00197", "submitter": "David Gens", "authors": "Ghada Dessouky, David Gens, Patrick Haney, Garrett Persyn, Arun\n  Kanuparthi, Hareesh Khattri, Jason M. Fung, Ahmad-Reza Sadeghi, Jeyavijayan\n  Rajendran", "title": "When a Patch is Not Enough - HardFails: Software-Exploitable Hardware\n  Bugs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we take a deep dive into microarchitectural security from a\nhardware designer's perspective by reviewing the existing approaches to detect\nhardware vulnerabilities during the design phase. We show that a protection gap\ncurrently exists in practice that leaves chip designs vulnerable to\nsoftware-based attacks. In particular, existing verification approaches fail to\ndetect specific classes of vulnerabilities, which we call HardFails: these bugs\nevade detection by current verification techniques while being exploitable from\nsoftware. We demonstrate such vulnerabilities in real-world SoCs using RISC-V\nto showcase and analyze concrete instantiations of HardFails. Patching these\nhardware bugs may not always be possible and can potentially result in a\nproduct recall. We base our findings on two extensive case studies: the recent\nHack@DAC 2018 hardware security competition, where 54 independent teams of\nresearchers competed world-wide over a period of 12 weeks to catch inserted\nsecurity bugs in SoC RTL designs, and an in-depth systematic evaluation of\nstate-of-the-art verification approaches. Our findings indicate that even\ncombinations of techniques will miss high-impact bugs due to the large number\nof modules with complex interdependencies and fundamental limitations of\ncurrent detection approaches. We also craft a real-world software attack that\nexploits one of the RTL bugs from Hack@DAC that evaded detection and discuss\nnovel approaches to mitigate the growing problem of cross-layer bugs at design\ntime.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 12:19:48 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Dessouky", "Ghada", ""], ["Gens", "David", ""], ["Haney", "Patrick", ""], ["Persyn", "Garrett", ""], ["Kanuparthi", "Arun", ""], ["Khattri", "Hareesh", ""], ["Fung", "Jason M.", ""], ["Sadeghi", "Ahmad-Reza", ""], ["Rajendran", "Jeyavijayan", ""]]}, {"id": "1812.00257", "submitter": "Mohamed Medhat Gaber", "authors": "Diana Haidar, Mohamed Medhat Gaber, Yevgeniya Kovalchuk", "title": "AnyThreat: An Opportunistic Knowledge Discovery Approach to Insider\n  Threat Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Insider threat detection is getting an increased concern from academia,\nindustry, and governments due to the growing number of malicious insider\nincidents. The existing approaches proposed for detecting insider threats still\nhave a common shortcoming, which is the high number of false alarms (false\npositives). The challenge in these approaches is that it is essential to detect\nall anomalous behaviours which belong to a particular threat. To address this\nshortcoming, we propose an opportunistic knowledge discovery system, namely\nAnyThreat, with the aim to detect any anomalous behaviour in all malicious\ninsider threats. We design the AnyThreat system with four components. (1) A\nfeature engineering component, which constructs community data sets from the\nactivity logs of a group of users having the same role. (2) An oversampling\ncomponent, where we propose a novel oversampling technique named Artificial\nMinority Oversampling and Trapper REmoval (AMOTRE). AMOTRE first removes the\nminority (anomalous) instances that have a high resemblance with normal\n(majority) instances to reduce the number of false alarms, then it\nsynthetically oversamples the minority class by shielding the border of the\nmajority class. (3) A class decomposition component, which is introduced to\ncluster the instances of the majority class into subclasses to weaken the\neffect of the majority class without information loss. (4) A classification\ncomponent, which applies a classification method on the subclasses to achieve a\nbetter separation between the majority class(es) and the minority class(es).\nAnyThreat is evaluated on synthetic data sets generated by Carnegie Mellon\nUniversity. It detects approximately 87.5% of malicious insider threats, and\nachieves the minimum of false positives=3.36%.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 20:20:49 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Haidar", "Diana", ""], ["Gaber", "Mohamed Medhat", ""], ["Kovalchuk", "Yevgeniya", ""]]}, {"id": "1812.00263", "submitter": "Varun Chandrasekaran", "authors": "Varun Chandrasekaran, Suman Banerjee, Bilge Mutlu, Kassem Fawaz", "title": "PowerCut and Obfuscator: An Exploration of the Design Space for\n  Privacy-Preserving Interventions for Voice Assistants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pervasive use of smart speakers has raised numerous privacy concerns.\nWhile work to date provides an understanding of user perceptions of these\nthreats, limited research focuses on how we can mitigate these concerns, either\nthrough redesigning the smart speaker or through dedicated privacy-preserving\ninterventions. In this paper, we present the design and prototyping of two\nprivacy-preserving interventions: `Obfuscator' targeted at disabling recording\nat the microphones, and `PowerCut' targeted at disabling power to the smart\nspeaker. We present our findings from a technology probe study involving 24\nhouseholds that interacted with our prototypes; the primary objective was to\ngain a better understanding of the design space for technological interventions\nthat might address these concerns. Our data and findings reveal complex\ntrade-offs among utility, privacy, and usability and stresses the importance of\nmulti-functionality, aesthetics, ease-of-use, and form factor. We discuss the\nimplications of our findings for the development of subsequent interventions\nand the future design of smart speakers.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 21:04:04 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 12:02:43 GMT"}, {"version": "v3", "created": "Mon, 31 May 2021 18:58:02 GMT"}, {"version": "v4", "created": "Wed, 9 Jun 2021 18:24:53 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Chandrasekaran", "Varun", ""], ["Banerjee", "Suman", ""], ["Mutlu", "Bilge", ""], ["Fawaz", "Kassem", ""]]}, {"id": "1812.00292", "submitter": "Edward Chou Mr.", "authors": "Edward Chou, Florian Tram\\`er, Giancarlo Pellegrino", "title": "SentiNet: Detecting Localized Universal Attacks Against Deep Learning\n  Systems", "comments": "Deep Learning and Security Workshop (DLS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SentiNet is a novel detection framework for localized universal attacks on\nneural networks. These attacks restrict adversarial noise to contiguous\nportions of an image and are reusable with different images -- constraints that\nprove useful for generating physically-realizable attacks. Unlike most other\nworks on adversarial detection, SentiNet does not require training a model or\npreknowledge of an attack prior to detection. Our approach is appealing due to\nthe large number of possible mechanisms and attack-vectors that an\nattack-specific defense would have to consider. By leveraging the neural\nnetwork's susceptibility to attacks and by using techniques from model\ninterpretability and object detection as detection mechanisms, SentiNet turns a\nweakness of a model into a strength. We demonstrate the effectiveness of\nSentiNet on three different attacks -- i.e., data poisoning attacks, trojaned\nnetworks, and adversarial patches (including physically realizable attacks) --\nand show that our defense is able to achieve very competitive performance\nmetrics for all three threats. Finally, we show that SentiNet is robust against\nstrong adaptive adversaries, who build adversarial patches that specifically\ntarget the components of SentiNet's architecture.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 00:03:07 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 03:35:18 GMT"}, {"version": "v3", "created": "Fri, 13 Mar 2020 00:13:15 GMT"}, {"version": "v4", "created": "Sat, 9 May 2020 08:34:57 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Chou", "Edward", ""], ["Tram\u00e8r", "Florian", ""], ["Pellegrino", "Giancarlo", ""]]}, {"id": "1812.00381", "submitter": "Ilia Shumailov", "authors": "Rasika Bhalerao, Maxwell Aliapoulios, Ilia Shumailov, Sadia Afroz,\n  Damon McCoy", "title": "Towards Automatic Discovery of Cybercrime Supply Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cybercrime forums enable modern criminal entrepreneurs to collaborate with\nother criminals into increasingly efficient and sophisticated criminal\nendeavors. Understanding the connections between different products and\nservices can often illuminate effective interventions. However, generating this\nunderstanding of supply chains currently requires time-consuming manual effort.\n  In this paper, we propose a language-agnostic method to automatically extract\nsupply chains from cybercrime forum posts and replies. Our supply chain\ndetection algorithm can identify 36% and 58% relevant chains within major\nEnglish and Russian forums, respectively, showing improvements over the\nbaselines of 13% and 36%, respectively. Our analysis of the automatically\ngenerated supply chains demonstrates underlying connections between products\nand services within these forums. For example, the extracted supply chain\nilluminated the connection between hack-for-hire services and the selling of\nrare and valuable `OG' accounts, which has only recently been reported. The\nunderstanding of connections between products and services exposes potentially\neffective intervention points.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 12:38:58 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 23:48:55 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Bhalerao", "Rasika", ""], ["Aliapoulios", "Maxwell", ""], ["Shumailov", "Ilia", ""], ["Afroz", "Sadia", ""], ["McCoy", "Damon", ""]]}, {"id": "1812.00483", "submitter": "Ting Wang", "authors": "Yujie Ji, Xinyang Zhang, Shouling Ji, Xiapu Luo, Ting Wang", "title": "Model-Reuse Attacks on Deep Learning Systems", "comments": "In Proceedings of the 2018 ACM Conference on Computer and\n  Communications Security (CCS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many of today's machine learning (ML) systems are built by reusing an array\nof, often pre-trained, primitive models, each fulfilling distinct functionality\n(e.g., feature extraction). The increasing use of primitive models\nsignificantly simplifies and expedites the development cycles of ML systems.\nYet, because most of such models are contributed and maintained by untrusted\nsources, their lack of standardization or regulation entails profound security\nimplications, about which little is known thus far.\n  In this paper, we demonstrate that malicious primitive models pose immense\nthreats to the security of ML systems. We present a broad class of {\\em\nmodel-reuse} attacks wherein maliciously crafted models trigger host ML systems\nto misbehave on targeted inputs in a highly predictable manner. By empirically\nstudying four deep learning systems (including both individual and ensemble\nsystems) used in skin cancer screening, speech recognition, face verification,\nand autonomous steering, we show that such attacks are (i) effective - the host\nsystems misbehave on the targeted inputs as desired by the adversary with high\nprobability, (ii) evasive - the malicious models function indistinguishably\nfrom their benign counterparts on non-targeted inputs, (iii) elastic - the\nmalicious models remain effective regardless of various system design choices\nand tuning strategies, and (iv) easy - the adversary needs little prior\nknowledge about the data used for system tuning or inference. We provide\nanalytical justification for the effectiveness of model-reuse attacks, which\npoints to the unprecedented complexity of today's primitive models. This issue\nthus seems fundamental to many ML systems. We further discuss potential\ncountermeasures and their challenges, which lead to several promising research\ndirections.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2018 22:48:55 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Ji", "Yujie", ""], ["Zhang", "Xinyang", ""], ["Ji", "Shouling", ""], ["Luo", "Xiapu", ""], ["Wang", "Ting", ""]]}, {"id": "1812.00535", "submitter": "Mengkai Song", "authors": "Zhibo Wang, Mengkai Song, Zhifei Zhang, Yang Song, Qian Wang, Hairong\n  Qi", "title": "Beyond Inferring Class Representatives: User-Level Privacy Leakage From\n  Federated Learning", "comments": "The 38th Annual IEEE International Conference on Computer\n  Communications (INFOCOM 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning, i.e., a mobile edge computing framework for deep\nlearning, is a recent advance in privacy-preserving machine learning, where the\nmodel is trained in a decentralized manner by the clients, i.e., data curators,\npreventing the server from directly accessing those private data from the\nclients. This learning mechanism significantly challenges the attack from the\nserver side. Although the state-of-the-art attacking techniques that\nincorporated the advance of Generative adversarial networks (GANs) could\nconstruct class representatives of the global data distribution among all\nclients, it is still challenging to distinguishably attack a specific client\n(i.e., user-level privacy leakage), which is a stronger privacy threat to\nprecisely recover the private data from a specific client. This paper gives the\nfirst attempt to explore user-level privacy leakage against the federated\nlearning by the attack from a malicious server. We propose a framework\nincorporating GAN with a multi-task discriminator, which simultaneously\ndiscriminates category, reality, and client identity of input samples. The\nnovel discrimination on client identity enables the generator to recover user\nspecified private data. Unlike existing works that tend to interfere the\ntraining process of the federated learning, the proposed method works\n\"invisibly\" on the server side. The experimental results demonstrate the\neffectiveness of the proposed attacking approach and the superior to the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 03:12:39 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 02:14:01 GMT"}, {"version": "v3", "created": "Wed, 5 Dec 2018 01:17:05 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Wang", "Zhibo", ""], ["Song", "Mengkai", ""], ["Zhang", "Zhifei", ""], ["Song", "Yang", ""], ["Wang", "Qian", ""], ["Qi", "Hairong", ""]]}, {"id": "1812.00552", "submitter": "Jie Li", "authors": "Jie Li, Rongrong Ji, Hong Liu, Xiaopeng Hong, Yue Gao and Qi Tian", "title": "Universal Perturbation Attack Against Image Retrieval", "comments": "ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Universal adversarial perturbations (UAPs), a.k.a. input-agnostic\nperturbations, has been proved to exist and be able to fool cutting-edge deep\nlearning models on most of the data samples. Existing UAP methods mainly focus\non attacking image classification models. Nevertheless, little attention has\nbeen paid to attacking image retrieval systems. In this paper, we make the\nfirst attempt in attacking image retrieval systems. Concretely, image retrieval\nattack is to make the retrieval system return irrelevant images to the query at\nthe top ranking list. It plays an important role to corrupt the neighbourhood\nrelationships among features in image retrieval attack. To this end, we propose\na novel method to generate retrieval-against UAP to break the neighbourhood\nrelationships of image features via degrading the corresponding ranking metric.\nTo expand the attack method to scenarios with varying input sizes or\nuntouchable network parameters, a multi-scale random resizing scheme and a\nranking distillation strategy are proposed. We evaluate the proposed method on\nfour widely-used image retrieval datasets, and report a significant performance\ndrop in terms of different metrics, such as mAP and mP@10. Finally, we test our\nattack methods on the real-world visual search engine, i.e., Google Images,\nwhich demonstrates the practical potentials of our methods.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 04:52:06 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 02:27:12 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Li", "Jie", ""], ["Ji", "Rongrong", ""], ["Liu", "Hong", ""], ["Hong", "Xiaopeng", ""], ["Gao", "Yue", ""], ["Tian", "Qi", ""]]}, {"id": "1812.00599", "submitter": "Qi Wang", "authors": "Qi Wang, Dehua Zhou and Yanling Li", "title": "Secure outsourced calculations with homomorphic encryption", "comments": null, "journal-ref": "Advanced Computing: An International Journal (ACIJ), Vol.9, No.6,\n  November 2018", "doi": "10.5121/acij.2018.9601", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of cloud computing, the privacy security incidents\noccur frequently, especially data security issues. Cloud users would like to\nupload their sensitive information to cloud service providers in encrypted form\nrather than the raw data, and to prevent the misuse of data. The main challenge\nis to securely process or analyze these encrypted data without disclosing any\nuseful information, and to achieve the rights management efficiently. In this\npaper, we propose the encrypted data processing protocols for cloud computing\nby utilizing additively homomorphic encryption and proxy cryptography. For the\ntraditional homomorphic encryption schemes with many limitations, which are not\nsuitable for cloud computing applications. We simulate a cloud computing\nscenario with flexible access control and extend the original homomorphic\ncryptosystem to suit our scenario by supporting various arithmetical\ncalculations. We also prove the correctness and security of our protocols, and\nanalyze the advantages and performance by comparing with some latest works.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 08:27:14 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Wang", "Qi", ""], ["Zhou", "Dehua", ""], ["Li", "Yanling", ""]]}, {"id": "1812.00619", "submitter": "Evgeniy Shishkin", "authors": "Evgeniy Shishkin", "title": "Debugging Smart Contract's Business Logic Using Symbolic Model-Checking", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart contracts are a special type of programs running inside a blockchain.\nImmutable and transparent, they provide means to implement fault-tolerant and\ncensorship-resistant services. Unfortunately, its immutability causes a serious\nchallenge of ensuring that a business logic and implementation is correct\nupfront, before publishing in a blockchain. Several big accidents have indeed\nshown that users of this technology need special tools to verify smart contract\ncorrectness. Existing automated checkers are able to detect only well known\nimplementation bugs, leaving the question of business logic correctness far\naside. In this work, we present a symbolic model-checking technique along with\na formal specification method for a subset of Solidity programming language\nthat is able to express both state properties and trace properties; the latter\nconstitutes a weak analogy of temporal properties. We evaluate the proposed\ntechnique on the MiniDAO smart contract, a young brother of notorious TheDAO.\nOur Proof-of-Concept was able to detect a non-trivial error in the business\nlogic of this smart contract in a few seconds.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 09:25:22 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Shishkin", "Evgeniy", ""]]}, {"id": "1812.00622", "submitter": "Jean-Philippe Fauvelle", "authors": "Jean-Philippe Fauvelle, Alexandre Dey, Sylvain Navers", "title": "Protection of an information system by artificial intelligence: a\n  three-phase approach based on behaviour analysis to detect a hostile scenario", "comments": "in French. European Cyber Week - C\\&ESAR Conference - Artificial\n  Intelligence and Cybersecurity, Nov 2018, Rennes, France. 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of the behaviour of individuals and entities (UEBA) is an area\nof artificial intelligence that detects hostile actions (e.g. attacks, fraud,\ninfluence, poisoning) due to the unusual nature of observed events, by affixing\nto a signature-based operation. A UEBA process usually involves two phases,\nlearning and inference. Intrusion detection systems (IDS) available still\nsuffer from bias, including over-simplification of problems, underexploitation\nof the AI potential, insufficient consideration of the temporality of events,\nand perfectible management of the memory cycle of behaviours. In addition,\nwhile an alert generated by a signature-based IDS can refer to the signature on\nwhich the detection is based, the IDS in the UEBA domain produce results, often\nassociated with a score, whose explainable character is less obvious. Our\nunsupervised approach is to enrich this process by adding a third phase to\ncorrelate events (incongruities, weak signals) that are presumed to be linked\ntogether, with the benefit of a reduction of false positives and negatives. We\nalso seek to avoid a so-called \"boiled frog\" bias inherent in continuous\nlearning. Our first results are interesting and have an explainable character,\nboth on synthetic and real data.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 09:29:03 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Fauvelle", "Jean-Philippe", ""], ["Dey", "Alexandre", ""], ["Navers", "Sylvain", ""]]}, {"id": "1812.00740", "submitter": "David Stutz", "authors": "David Stutz, Matthias Hein, Bernt Schiele", "title": "Disentangling Adversarial Robustness and Generalization", "comments": "Conference on Computer Vision and Pattern Recognition 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining deep networks that are robust against adversarial examples and\ngeneralize well is an open problem. A recent hypothesis even states that both\nrobust and accurate models are impossible, i.e., adversarial robustness and\ngeneralization are conflicting goals. In an effort to clarify the relationship\nbetween robustness and generalization, we assume an underlying, low-dimensional\ndata manifold and show that: 1. regular adversarial examples leave the\nmanifold; 2. adversarial examples constrained to the manifold, i.e.,\non-manifold adversarial examples, exist; 3. on-manifold adversarial examples\nare generalization errors, and on-manifold adversarial training boosts\ngeneralization; 4. regular robustness and generalization are not necessarily\ncontradicting goals. These assumptions imply that both robust and accurate\nmodels are possible. However, different models (architectures, training\nstrategies etc.) can exhibit different robustness and generalization\ncharacteristics. To confirm our claims, we present extensive experiments on\nsynthetic data (with known manifold) as well as on EMNIST, Fashion-MNIST and\nCelebA.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 14:04:35 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 10:25:38 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Stutz", "David", ""], ["Hein", "Matthias", ""], ["Schiele", "Bernt", ""]]}, {"id": "1812.00784", "submitter": "Mounir Baammi", "authors": "Mounir Baammi", "title": "Malware static analysis and DDoS capabilities detection", "comments": "60 Pages, 10 Figures, 12 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The present thesis addresses the topic of denial of service capabilities\ndetection at malware binary level, with the aim of designing a framework that\nintegrate results from different binary analysis methods and decide on the DDoS\ncapabilities of the analysed malware. We have implemented a process to extract\nmeaningful data from malware samples, the extracted data was used to find\ncharacteristics and features that can lead to the detection of DDoS\ncapabilities in binaries. Based on the discoveries, a set of rules was\nelaborated to detect those features in binaries. The method is tested on a\ndataset of 815 samples. Another dataset of 525 benign binaries is also used to\ntest false positives rate of the implemented method. The results of our method\nare compared with Virus Total analysis results to assess our detection\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 14:44:53 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Baammi", "Mounir", ""]]}, {"id": "1812.00891", "submitter": "Ting Wang", "authors": "Xinyang Zhang and Ningfei Wang and Hua Shen and Shouling Ji and Xiapu\n  Luo and Ting Wang", "title": "Interpretable Deep Learning under Fire", "comments": "USENIX Security Symposium '20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing explanations for deep neural network (DNN) models is crucial for\ntheir use in security-sensitive domains. A plethora of interpretation models\nhave been proposed to help users understand the inner workings of DNNs: how\ndoes a DNN arrive at a specific decision for a given input? The improved\ninterpretability is believed to offer a sense of security by involving human in\nthe decision-making process. Yet, due to its data-driven nature, the\ninterpretability itself is potentially susceptible to malicious manipulations,\nabout which little is known thus far.\n  Here we bridge this gap by conducting the first systematic study on the\nsecurity of interpretable deep learning systems (IDLSes). We show that existing\n\\imlses are highly vulnerable to adversarial manipulations. Specifically, we\npresent ADV^2, a new class of attacks that generate adversarial inputs not only\nmisleading target DNNs but also deceiving their coupled interpretation models.\nThrough empirical evaluation against four major types of IDLSes on benchmark\ndatasets and in security-critical applications (e.g., skin cancer diagnosis),\nwe demonstrate that with ADV^2 the adversary is able to arbitrarily designate\nan input's prediction and interpretation. Further, with both analytical and\nempirical evidence, we identify the prediction-interpretation gap as one root\ncause of this vulnerability -- a DNN and its interpretation model are often\nmisaligned, resulting in the possibility of exploiting both models\nsimultaneously. Finally, we explore potential countermeasures against ADV^2,\nincluding leveraging its low transferability and incorporating it in an\nadversarial training framework. Our findings shed light on designing and\noperating IDLSes in a more secure and informative fashion, leading to several\npromising research directions.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 16:45:28 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 16:51:16 GMT"}, {"version": "v3", "created": "Wed, 18 Sep 2019 01:54:10 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Zhang", "Xinyang", ""], ["Wang", "Ningfei", ""], ["Shen", "Hua", ""], ["Ji", "Shouling", ""], ["Luo", "Xiapu", ""], ["Wang", "Ting", ""]]}, {"id": "1812.00910", "submitter": "Reza Shokri", "authors": "Milad Nasr, Reza Shokri, Amir Houmansadr", "title": "Comprehensive Privacy Analysis of Deep Learning: Passive and Active\n  White-box Inference Attacks against Centralized and Federated Learning", "comments": "2019 IEEE Symposium on Security and Privacy (SP)", "journal-ref": null, "doi": "10.1109/SP.2019.00065", "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are susceptible to various inference attacks as they\nremember information about their training data. We design white-box inference\nattacks to perform a comprehensive privacy analysis of deep learning models. We\nmeasure the privacy leakage through parameters of fully trained models as well\nas the parameter updates of models during training. We design inference\nalgorithms for both centralized and federated learning, with respect to passive\nand active inference attackers, and assuming different adversary prior\nknowledge.\n  We evaluate our novel white-box membership inference attacks against deep\nlearning algorithms to trace their training data records. We show that a\nstraightforward extension of the known black-box attacks to the white-box\nsetting (through analyzing the outputs of activation functions) is ineffective.\nWe therefore design new algorithms tailored to the white-box setting by\nexploiting the privacy vulnerabilities of the stochastic gradient descent\nalgorithm, which is the algorithm used to train deep neural networks. We\ninvestigate the reasons why deep learning models may leak information about\ntheir training data. We then show that even well-generalized models are\nsignificantly susceptible to white-box membership inference attacks, by\nanalyzing state-of-the-art pre-trained and publicly available models for the\nCIFAR dataset. We also show how adversarial participants, in the federated\nlearning setting, can successfully run active membership inference attacks\nagainst other participants, even when the global model achieves high prediction\naccuracies.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 17:11:21 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 18:22:55 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Nasr", "Milad", ""], ["Shokri", "Reza", ""], ["Houmansadr", "Amir", ""]]}, {"id": "1812.00920", "submitter": "Bumjin Im", "authors": "Bumjin Im, Ang Chen and Dan Wallach", "title": "An Historical Analysis of the SEAndroid Policy Evolution", "comments": "16 pages, 11 figures, published in ACSAC '18", "journal-ref": null, "doi": "10.1145/3274694.3274709", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Android adopted SELinux's mandatory access control (MAC) mechanisms in 2013.\nSince then, billions of Android devices have benefited from mandatory access\ncontrol security policies. These policies are expressed in a variety of rules,\nmaintained by Google and extended by Android OEMs. Over the years, the rules\nhave grown to be quite complex, making it challenging to properly understand or\nconfigure these policies.\n  In this paper, we perform a measurement study on the SEAndroid repository to\nunderstand the evolution of these policies. We propose a new metric to measure\nthe complexity of the policy by expanding policy rules, with their abstraction\nfeatures such as macros and groups, into primitive \"boxes\", which we then use\nto show that the complexity of the SEAndroid policies has been growing\nexponentially over time. By analyzing the Git commits, snapshot by snapshot, we\nare also able to analyze the \"age\" of policy rules, the trend of changes, and\nthe contributor composition. We also look at hallmark events in Android's\nhistory, such as the \"Stagefright\" vulnerability in Android's media facilities,\npointing out how these events led to changes in the MAC policies. The growing\ncomplexity of Android's mandatory policies suggests that we will eventually hit\nthe limits of our ability to understand these policies, requiring new tools and\ntechniques.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 17:23:49 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Im", "Bumjin", ""], ["Chen", "Ang", ""], ["Wallach", "Dan", ""]]}, {"id": "1812.00939", "submitter": "Yusuke Kawamoto", "authors": "Yusuke Kawamoto and Takao Murakami", "title": "Local Obfuscation Mechanisms for Hiding Probability Distributions", "comments": "Full version of Proc. ESORICS 2019 (with a longer appendix)", "journal-ref": null, "doi": "10.1007/978-3-030-29959-0_7", "report-no": null, "categories": "cs.CR cs.DB cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a formal model for the information leakage of probability\ndistributions and define a notion called distribution privacy as the local\ndifferential privacy for probability distributions. Roughly, the distribution\nprivacy of a local obfuscation mechanism means that the attacker cannot\nsignificantly gain any information on the distribution of the mechanism's input\nby observing its output. Then we show that existing local mechanisms can hide\ninput distributions in terms of distribution privacy, while deteriorating the\nutility by adding too much noise. For example, we prove that the Laplace\nmechanism needs to add a large amount of noise proportionally to the infinite\nWasserstein distance between the two distributions we want to make\nindistinguishable. To improve the tradeoff between distribution privacy and\nutility, we introduce a local obfuscation mechanism, called a tupling\nmechanism, that adds random dummy data to the output. Then we apply this\nmechanism to the protection of user attributes in location based services. By\nexperiments, we demonstrate that the tupling mechanism outperforms popular\nlocal mechanisms in terms of attribute obfuscation and service quality.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 18:06:20 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 08:37:22 GMT"}, {"version": "v3", "created": "Tue, 30 Apr 2019 14:12:13 GMT"}, {"version": "v4", "created": "Mon, 8 Jul 2019 11:16:03 GMT"}, {"version": "v5", "created": "Tue, 6 Aug 2019 17:06:09 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Kawamoto", "Yusuke", ""], ["Murakami", "Takao", ""]]}, {"id": "1812.00942", "submitter": "Sergi Delgado Segura", "authors": "Sergi Delgado-Segura, Surya Bakshi, Cristina P\\'erez-Sol\\`a, James\n  Litton, Andrew Pachulski, Andrew Miller, and Bobby Bhattacharjee", "title": "TxProbe: Discovering Bitcoin's Network Topology Using Orphan\n  Transactions", "comments": "to appear, FC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin relies on a peer-to-peer overlay network to broadcast transactions\nand blocks. From the viewpoint of network measurement, we would like to observe\nthis topology so we can characterize its performance, fairness and robustness.\nHowever, this is difficult because Bitcoin is deliberately designed to hide its\ntopology from onlookers. Knowledge of the topology is not in itself a\nvulnerability, although it could conceivably help an attacker performing\ntargeted eclipse attacks or to deanonymize transaction senders.\n  In this paper we present TxProbe, a novel technique for reconstructing the\nBitcoin network topology. TxProbe makes use of peculiarities in how Bitcoin\nprocesses out of order, or \"orphaned\" transactions. We conducted experiments on\nBitcoin testnet that suggest our technique reconstructs topology with precision\nand recall surpassing 90%. We also used TxProbe to take a snapshot of the\nBitcoin testnet in just a few hours. TxProbe may be useful for future\nmeasurement campaigns of Bitcoin or other cryptocurrency networks.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 18:08:47 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 10:57:00 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Delgado-Segura", "Sergi", ""], ["Bakshi", "Surya", ""], ["P\u00e9rez-Sol\u00e0", "Cristina", ""], ["Litton", "James", ""], ["Pachulski", "Andrew", ""], ["Miller", "Andrew", ""], ["Bhattacharjee", "Bobby", ""]]}, {"id": "1812.00955", "submitter": "Noah Apthorpe", "authors": "Noah Apthorpe, Danny Yuxing Huang, Dillon Reisman, Arvind Narayanan,\n  Nick Feamster", "title": "Keeping the Smart Home Private with Smart(er) IoT Traffic Shaping", "comments": "21 pages, 9 figures, 4 tables. This article draws heavily from\n  arXiv:1705.06805, arXiv:1705.06809, and arXiv:1708.05044. Camera-ready\n  version", "journal-ref": "Proceedings on Privacy Enhancing Technologies 2019.3 (2019)\n  128-148", "doi": "10.2478/popets-2019-0040", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of smart home Internet of Things (IoT) devices presents\nunprecedented challenges for preserving privacy within the home. In this paper,\nwe demonstrate that a passive network observer (e.g., an Internet service\nprovider) can infer private in-home activities by analyzing Internet traffic\nfrom commercially available smart home devices even when the devices use\nend-to-end transport-layer encryption. We evaluate common approaches for\ndefending against these types of traffic analysis attacks, including firewalls,\nvirtual private networks, and independent link padding, and find that none\nsufficiently conceal user activities with reasonable data overhead. We develop\na new defense, \"stochastic traffic padding\" (STP), that makes it difficult for\na passive network adversary to reliably distinguish genuine user activities\nfrom generated traffic patterns designed to look like user interactions. Our\nanalysis provides a theoretical bound on an adversary's ability to accurately\ndetect genuine user activities as a function of the amount of additional cover\ntraffic generated by the defense technique.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 18:26:24 GMT"}, {"version": "v2", "created": "Sat, 16 Mar 2019 05:27:47 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Apthorpe", "Noah", ""], ["Huang", "Danny Yuxing", ""], ["Reisman", "Dillon", ""], ["Narayanan", "Arvind", ""], ["Feamster", "Nick", ""]]}, {"id": "1812.01197", "submitter": "Bihuan Chen", "authors": "Junjie Wang, Bihuan Chen, Lei Wei, Yang Liu", "title": "Superion: Grammar-Aware Greybox Fuzzing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, coverage-based greybox fuzzing has proven itself to be one\nof the most effective techniques for finding security bugs in practice.\nParticularly, American Fuzzy Lop (AFL for short) is deemed to be a great\nsuccess in fuzzing relatively simple test inputs. Unfortunately, when it meets\nstructured test inputs such as XML and JavaScript, those grammar-blind trimming\nand mutation strategies in AFL hinder the effectiveness and efficiency.\n  To this end, we propose a grammar-aware coverage-based greybox fuzzing\napproach to fuzz programs that process structured inputs. Given the grammar\n(which is often publicly available) of test inputs, we introduce a\ngrammar-aware trimming strategy to trim test inputs at the tree level using the\nabstract syntax trees (ASTs) of parsed test inputs. Further, we introduce two\ngrammar-aware mutation strategies (i.e., enhanced dictionary-based mutation and\ntree-based mutation). Specifically, tree-based mutation works via replacing\nsubtrees using the ASTs of parsed test inputs. Equipped with grammar-awareness,\nour approach can carry the fuzzing exploration into width and depth.\n  We implemented our approach as an extension to AFL, named Superion; and\nevaluated the effectiveness of Superion on real-life large-scale programs (a\nXML engine libplist and three JavaScript engines WebKit, Jerryscript and\nChakraCore). Our results have demonstrated that Superion can improve the code\ncoverage (i.e., 16.7% and 8.8% in line and function coverage) and bug-finding\ncapability (i.e., 31 new bugs, among which we discovered 21 new vulnerabilities\nwith 16 CVEs assigned and 3.2K USD bug bounty rewards received) over AFL and\njsfunfuzz. We also demonstrated the effectiveness of our grammar-aware trimming\nand mutation.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 03:22:54 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2018 11:59:28 GMT"}, {"version": "v3", "created": "Wed, 23 Jan 2019 12:21:47 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Wang", "Junjie", ""], ["Chen", "Bihuan", ""], ["Wei", "Lei", ""], ["Liu", "Yang", ""]]}, {"id": "1812.01372", "submitter": "Muthuramakrishnan Venkitasubramaniam", "authors": "Siddharth Garg, Zahra Ghodsi, Carmit Hazay, Yuval Ishai, Antonio\n  Marcedone, Muthuramakrishnan Venkitasubramaniam", "title": "Outsourcing Private Machine Learning via Lightweight Secure Arithmetic\n  Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In several settings of practical interest, two parties seek to\ncollaboratively perform inference on their private data using a public machine\nlearning model. For instance, several hospitals might wish to share patient\nmedical records for enhanced diagnostics and disease prediction, but may not be\nable to share data in the clear because of privacy concerns. In this work, we\npropose an actively secure protocol for outsourcing secure and private machine\nlearning computations. Recent works on the problem have mainly focused on\npassively secure protocols, whose security holds against passive\n(`semi-honest') parties but may completely break down in the presence of active\n(`malicious') parties who can deviate from the protocol. Secure neural networks\nbased classification algorithms can be seen as an instantiation of an\narithmetic computation over integers.\n  We showcase the efficiency of our protocol by applying it to real-world\ninstances of arithmetized neural network computations, including a network\ntrained to perform collaborative disease prediction.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 12:31:50 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Garg", "Siddharth", ""], ["Ghodsi", "Zahra", ""], ["Hazay", "Carmit", ""], ["Ishai", "Yuval", ""], ["Marcedone", "Antonio", ""], ["Venkitasubramaniam", "Muthuramakrishnan", ""]]}, {"id": "1812.01503", "submitter": "Fei Wang", "authors": "Fei Wang, Zhenjiang Li, Jinsong Han", "title": "Continuous User Authentication by Contactless Wireless Sensing", "comments": "10 pages, 11 figures", "journal-ref": null, "doi": "10.1109/JIOT.2019.2916777", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents BodyPIN, which is a continuous user authentication system\nby contactless wireless sensing using commodity Wi-Fi. BodyPIN can track the\ncurrent user's legal identity throughout a computer system's execution. In case\nthe authentication fails, the consequent accesses will be denied to protect the\nsystem. The recent rich wireless-based user identification designs cannot be\napplied to BodyPIN directly, because they identify a user's various activities,\nrather than the user herself. The enforced to be performed activities can thus\ninterrupt the user's operations on the system, highly inconvenient and not\nuser-friendly. In this paper, we leverage the bio-electromagnetics domain human\nmodel for quantifying the impact of human body on the bypassing Wi-Fi signals\nand deriving the component that indicates a user's identity. Then we extract\nsuitable Wi-Fi signal features to fully represent such an identity component,\nbased on which we fulfill the continuous user authentication design. We\nimplement a BodyPIN prototype by commodity Wi-Fi NICs without any extra or\ndedicated wireless hardware. We show that BodyPIN achieves promising\nauthentication performances, which is also lightweight and robust under various\npractical settings.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 16:12:40 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Wang", "Fei", ""], ["Li", "Zhenjiang", ""], ["Han", "Jinsong", ""]]}, {"id": "1812.01514", "submitter": "Imane Fouad", "authors": "Imane Fouad, Nataliia Bielova, Arnaud Legout, Natasa\n  Sarafijanovic-Djukic", "title": "Missed by Filter Lists: Detecting Unknown Third-Party Trackers with\n  Invisible Pixels", "comments": "This paper has been accepted to PETs 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Web tracking has been extensively studied over the last decade. To detect\ntracking, previous studies and user tools rely on filter lists. However, it has\nbeen shown that filter lists miss trackers. In this paper, we propose an\nalternative method to detect trackers inspired by analyzing behavior of\ninvisible pixels. By crawling 84,658 webpages from 8,744 domains, we detect\nthat third-party invisible pixels are widely deployed: they are present on more\nthan 94.51% of domains and constitute 35.66% of all third-party images. We\npropose a fine-grained behavioral classification of tracking based on the\nanalysis of invisible pixels. We use this classification to detect new\ncategories of tracking and uncover new collaborations between domains on the\nfull dataset of 4,216,454 third-party requests. We demonstrate that two popular\nmethods to detect tracking, based on EasyList&EasyPrivacy and on Disconnect\nlists respectively miss 25.22% and 30.34% of the trackers that we detect.\nMoreover, we find that if we combine all three lists 379,245 requests\noriginated from 8,744 domains still track users on 68.70% of websites.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 16:33:45 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 08:54:55 GMT"}, {"version": "v3", "created": "Fri, 27 Sep 2019 08:19:22 GMT"}, {"version": "v4", "created": "Fri, 28 Feb 2020 09:32:18 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Fouad", "Imane", ""], ["Bielova", "Nataliia", ""], ["Legout", "Arnaud", ""], ["Sarafijanovic-Djukic", "Natasa", ""]]}, {"id": "1812.01533", "submitter": "Behrooz Khadem", "authors": "Behrooz Khadem, Siavosh Abedi, Isa Sa-adatyar", "title": "An Idea to Increase the Security of EAP-MD5 Protocol Against Dictionary\n  Attack", "comments": "6 pages, 4 figures, 1 table, presented in 3rd International\n  Conference on Combinatorics, Cryptography and Computation, December 15, 2018\n  in IUST, Iran", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IEEE 802.1X is an international standard for Port-based Network Access\nControl which provides authentication for devices applicant of either local\nnetwork or wireless local network. This standard defines the packing of EAP\nprotocol on IEEE 802. In this standard, authentication protocols become a\ncomplementary part of network security. There is a variety in EAP family\nprotocols, regarding their speed and security. One of the fastest of these\nprotocols is EAP-MD5 which is the main subject of this paper. Moreover, in\norder to improve EAP-MD5 security, a series of attacks against it have been\ninvestigated. In this paper at first EAP-MD5 protocol is introduced briefly and\na series of the dictionary attacks against it are described. Then, based on\nobserved weaknesses, by proposing an appropriate idea while maintaining the\nspeed of execution, its security against dictionary attack is improved.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 17:07:27 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Khadem", "Behrooz", ""], ["Abedi", "Siavosh", ""], ["Sa-adatyar", "Isa", ""]]}, {"id": "1812.01541", "submitter": "Pascal Cotret", "authors": "Muhammad Abdul Wahab, Pascal Cotret, Mounir Nasr Allah, Guillaume\n  Hiet, Arnab Kumar Biswas, Vianney Lap\\^otre, Guy Gogniat", "title": "A small and adaptive coprocessor for information flow tracking in ARM\n  SoCs", "comments": null, "journal-ref": "2018 International Conference on Reconfigurable Computing and\n  FPGAs (Reconfig'18)", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DIFT (Dynamic Information Flow Tracking) has been a hot topic for more than a\ndecade. Unfortunately, existing hardware DIFT approaches have not been widely\nused neither by research community nor by hardware vendors. It is due to two\nmajor reasons: current hardware DIFT solutions lack support for multi-threaded\napplications and implementations for hardcore processors. This work addresses\nboth issues by introducing an approach with some unique features: DIFT for\nmulti-threaded software, virtual memory protection (rather than physical memory\nas in related works) and Linux kernel support using an information flow monitor\ncalled RFBlare. These goals are accomplished by taking advantage of a notable\nfeature of ARM CoreSight components (context ID) combined with a custom DIFT\ncoprocessor and RFBlare. The communication time overhead, major source of\nslowdown in total DIFT time overhead, is divided by a factor 3.8 compared to\nexisting solutions with similar software constraints as in this work. The area\noverhead of this work is lower than 1% and power overhead is 16.2% on a\nmiddle-class Xilinx Zynq SoC.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 17:19:49 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Wahab", "Muhammad Abdul", ""], ["Cotret", "Pascal", ""], ["Allah", "Mounir Nasr", ""], ["Hiet", "Guillaume", ""], ["Biswas", "Arnab Kumar", ""], ["Lap\u00f4tre", "Vianney", ""], ["Gogniat", "Guy", ""]]}, {"id": "1812.01566", "submitter": "Netanel Raviv", "authors": "Netanel Raviv, Itzhak Tamo, Eitan Yaakobi", "title": "Private Information Retrieval in Graph Based Replication Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a Private Information Retrieval (PIR) protocol, a user can download a file\nfrom a database without revealing the identity of the file to each individual\nserver. A PIR protocol is called $t$-private if the identity of the file\nremains concealed even if $t$ of the servers collude. Graph based replication\nis a simple technique, which is prevalent in both theory and practice, for\nachieving erasure robustness in storage systems. In this technique each file is\nreplicated on two or more storage servers, giving rise to a (hyper-)graph\nstructure. In this paper we study private information retrieval protocols in\ngraph based replication systems. The main interest of this work is maximizing\nthe parameter $t$, and in particular, understanding the structure of the\ncolluding sets which emerge in a given graph. Our main contribution is a\n$2$-replication scheme which guarantees perfect privacy from acyclic sets in\nthe graph, and guarantees partial-privacy in the presence of cycles.\nFurthermore, by providing an upper bound, it is shown that the PIR rate of this\nscheme is at most a factor of two from its optimal value for an important\nfamily of graphs. Lastly, we extend our results to larger replication factors\nand to graph-based coding, which is a similar technique with smaller storage\noverhead and larger PIR rate.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 18:13:26 GMT"}, {"version": "v2", "created": "Mon, 4 Mar 2019 22:05:07 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Raviv", "Netanel", ""], ["Tamo", "Itzhak", ""], ["Yaakobi", "Eitan", ""]]}, {"id": "1812.01597", "submitter": "Kevin Moran P", "authors": "Kaushal Kafle, Kevin Moran, Sunil Manandhar, Adwait Nadkarni, Denys\n  Poshyvanyk", "title": "A Study of Data Store-based Home Automation", "comments": "Accepted to the The 9th ACM Conference on Data and Application\n  Security and Privacy (CODASPY'19), 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Home automation platforms provide a new level of convenience by enabling\nconsumers to automate various aspects of physical objects in their homes. While\nthe convenience is beneficial, security flaws in the platforms or integrated\nthird-party products can have serious consequences for the integrity of a\nuser's physical environment. In this paper we perform a systematic security\nevaluation of two popular smart home platforms, Google's Nest platform and\nPhilips Hue, that implement home automation \"routines\" (i.e., trigger-action\nprograms involving apps and devices) via manipulation of state variables in a\ncentralized data store. Our semi-automated analysis examines, among other\nthings, platform access control enforcement, the rigor of non-system\nenforcement procedures, and the potential for misuse of routines. This analysis\nresults in ten key findings with serious security implications. For instance,\nwe demonstrate the potential for the misuse of smart home routines in the Nest\nplatform to perform a lateral privilege escalation, illustrate how Nest's\nproduct review system is ineffective at preventing multiple stages of this\nattack that it examines, and demonstrate how emerging platforms may fail to\nprovide even bare-minimum security by allowing apps to arbitrarily add/remove\nother apps from the user's smart home. Our findings draw attention to the\nunique security challenges of platforms that execute routines via centralized\ndata stores and highlight the importance of enforcing security by design in\nemerging home automation platforms.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 18:54:04 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Kafle", "Kaushal", ""], ["Moran", "Kevin", ""], ["Manandhar", "Sunil", ""], ["Nadkarni", "Adwait", ""], ["Poshyvanyk", "Denys", ""]]}, {"id": "1812.01647", "submitter": "Jonathan Uesato", "authors": "Jonathan Uesato, Ananya Kumar, Csaba Szepesvari, Tom Erez, Avraham\n  Ruderman, Keith Anderson, Krishmamurthy (Dj) Dvijotham, Nicolas Heess,\n  Pushmeet Kohli", "title": "Rigorous Agent Evaluation: An Adversarial Approach to Uncover\n  Catastrophic Failures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of evaluating learning systems in safety\ncritical domains such as autonomous driving, where failures can have\ncatastrophic consequences. We focus on two problems: searching for scenarios\nwhen learned agents fail and assessing their probability of failure. The\nstandard method for agent evaluation in reinforcement learning, Vanilla Monte\nCarlo, can miss failures entirely, leading to the deployment of unsafe agents.\nWe demonstrate this is an issue for current agents, where even matching the\ncompute used for training is sometimes insufficient for evaluation. To address\nthis shortcoming, we draw upon the rare event probability estimation literature\nand propose an adversarial evaluation approach. Our approach focuses evaluation\non adversarially chosen situations, while still providing unbiased estimates of\nfailure probabilities. The key difficulty is in identifying these adversarial\nsituations -- since failures are rare there is little signal to drive\noptimization. To solve this we propose a continuation approach that learns\nfailure modes in related but less robust agents. Our approach also allows reuse\nof data already collected for training the agent. We demonstrate the efficacy\nof adversarial evaluation on two standard domains: humanoid control and\nsimulated driving. Experimental results show that our methods can find\ncatastrophic failures and estimate failures rates of agents multiple orders of\nmagnitude faster than standard evaluation schemes, in minutes to hours rather\nthan days.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 19:39:53 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Uesato", "Jonathan", "", "Dj"], ["Kumar", "Ananya", "", "Dj"], ["Szepesvari", "Csaba", "", "Dj"], ["Erez", "Tom", "", "Dj"], ["Ruderman", "Avraham", "", "Dj"], ["Anderson", "Keith", "", "Dj"], ["Krishmamurthy", "", "", "Dj"], ["Dvijotham", "", ""], ["Heess", "Nicolas", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1812.01661", "submitter": "Binghui Wang", "authors": "Binghui Wang, Jinyuan Jia, Neil Zhenqiang Gong", "title": "Graph-based Security and Privacy Analytics via Collective Classification\n  with Joint Weight Learning and Propagation", "comments": "Network and Distributed System Security Symposium (NDSS), 2019.\n  Dataset link: http://gonglab.pratt.duke.edu/code-data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many security and privacy problems can be modeled as a graph classification\nproblem, where nodes in the graph are classified by collective classification\nsimultaneously. State-of-the-art collective classification methods for such\ngraph-based security and privacy analytics follow the following paradigm:\nassign weights to edges of the graph, iteratively propagate reputation scores\nof nodes among the weighted graph, and use the final reputation scores to\nclassify nodes in the graph. The key challenge is to assign edge weights such\nthat an edge has a large weight if the two corresponding nodes have the same\nlabel, and a small weight otherwise. Although collective classification has\nbeen studied and applied for security and privacy problems for more than a\ndecade, how to address this challenge is still an open question. In this work,\nwe propose a novel collective classification framework to address this\nlong-standing challenge. We first formulate learning edge weights as an\noptimization problem, which quantifies the goals about the final reputation\nscores that we aim to achieve. However, it is computationally hard to solve the\noptimization problem because the final reputation scores depend on the edge\nweights in a very complex way. To address the computational challenge, we\npropose to jointly learn the edge weights and propagate the reputation scores,\nwhich is essentially an approximate solution to the optimization problem. We\ncompare our framework with state-of-the-art methods for graph-based security\nand privacy analytics using four large-scale real-world datasets from various\napplication scenarios such as Sybil detection in social networks, fake review\ndetection in Yelp, and attribute inference attacks. Our results demonstrate\nthat our framework achieves higher accuracies than state-of-the-art methods\nwith an acceptable computational overhead.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 20:02:08 GMT"}, {"version": "v2", "created": "Thu, 6 Dec 2018 02:33:54 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 00:54:54 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Wang", "Binghui", ""], ["Jia", "Jinyuan", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "1812.01667", "submitter": "Pascal Cotret", "authors": "Muhammad Abdul Wahab, Pascal Cotret, Mounir Nasr Allah, Guillaume\n  Hiet, Arnab Kumar Biswas, Vianney Lap\\^otre, Guy Gogniat", "title": "A novel lightweight hardware-assisted static instrumentation approach\n  for ARM SoC using debug components", "comments": null, "journal-ref": "Asian Hardware Oriented Security and Trust Symposium 2018\n  (AsianHOST'18)", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of hardware-assisted solutions for software security, program\nmonitoring, and event-checking approaches require instrumentation of the target\nsoftware, an operation which can be performed using an SBI (Static Binary\nInstrumentation) or a DBI (Dynamic Binary Instrumentation) framework.\nHardware-assisted instrumentation can use one of these two solutions to\ninstrument data to a memory-mapped register. Both these approaches require an\nin-depth knowledge of frameworks and an important amount of software\nmodifications in order to instrument a whole application. This work proposes a\nnovel way to instrument an application with minor modifications, at the source\ncode level, taking advantage of underlying hardware debug components such as CS\n(CoreSight) components available on Xilinx Zynq SoCs. As an example, the\ninstrumentation approach proposed in this work is used to detect a double free\nsecurity attack. Furthermore, it is evaluated in terms of runtime and area\noverhead. Results show that the proposed solution takes 30 $\\mu$s on average to\ninstrument an instruction while the optimized version only takes 0.014 us which\nis ten times better than usual memory-mapped register solutions used in\nexisting works.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 20:21:50 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Wahab", "Muhammad Abdul", ""], ["Cotret", "Pascal", ""], ["Allah", "Mounir Nasr", ""], ["Hiet", "Guillaume", ""], ["Biswas", "Arnab Kumar", ""], ["Lap\u00f4tre", "Vianney", ""], ["Gogniat", "Guy", ""]]}, {"id": "1812.01741", "submitter": "Shantanu Sharma", "authors": "Sharad Mehrotra, Kerim Yasin Oktay, Shantanu Sharma", "title": "Exploiting Data Sensitivity on Partitioned Data", "comments": "This chapter will appear in the book titled: From Database to Cyber\n  Security: Essays Dedicated to Sushil Jajodia on the Occasion of His 70th\n  Birthday", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several researchers have proposed solutions for secure data outsourcing on\nthe public clouds based on encryption, secret-sharing, and trusted hardware.\nExisting approaches, however, exhibit many limitations including high\ncomputational complexity, imperfect security, and information leakage. This\nchapter describes an emerging trend in secure data processing that recognizes\nthat an entire dataset may not be sensitive, and hence, non-sensitivity of data\ncan be exploited to overcome some of the limitations of existing\nencryption-based approaches. In particular, data and computation can be\npartitioned into sensitive or non-sensitive datasets - sensitive data can\neither be encrypted prior to outsourcing or stored/processed locally on trusted\nservers. The non-sensitive dataset, on the other hand, can be outsourced and\nprocessed in the cleartext. While partitioned computing can bring new\nefficiencies since it does not incur (expensive) encrypted data processing\ncosts on non-sensitive data, it can lead to information leakage. We study\npartitioned computing in two contexts - first, in the context of the hybrid\ncloud where local resources are integrated with public cloud resources to form\nan effective and secure storage and computational platform for enterprise data.\nIn the hybrid cloud, sensitive data is stored on the private cloud to prevent\nleakage and a computation is partitioned between private and public clouds.\nCare must be taken that the public cloud cannot infer any information about\nsensitive data from inter-cloud data access during query processing. We then\nconsider partitioned computing in a public cloud only setting, where sensitive\ndata is encrypted before outsourcing. We formally define a partitioned security\ncriterion that any approach to partitioned computing on public clouds must\nensure in order to not introduce any new vulnerabilities to the existing secure\nsolution.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 23:00:04 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Mehrotra", "Sharad", ""], ["Oktay", "Kerim Yasin", ""], ["Sharma", "Shantanu", ""]]}, {"id": "1812.01782", "submitter": "Zhili Chen Prof.", "authors": "Zhili Chen, Yu Wang, Shun Zhang, Hong Zhong, Lin Chen", "title": "Differentially Private User-based Collaborative Filtering Recommendation\n  Based on K-means Clustering", "comments": "23 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering (CF) recommendation algorithms are well-known for\ntheir outstanding recommendation performances, but previous researches showed\nthat they could cause privacy leakage for users due to k-nearest neighboring\n(KNN) attacks. Recently, the notion of differential privacy (DP) has been\napplied to privacy preservation for collaborative filtering recommendation\nalgorithms. However, as far as we know, existing differentially private CF\nrecommendation schemes degraded the recommendation performance (such as recall\nand precision) to an unacceptable level. In this paper, in order to address the\nperformance degradation problem, we propose a differentially private user-based\ncollaborative filtering recommendation scheme based on k-means clustering\n(KDPCF). Specifically, to improve the recommendation performance, we first\ncluster the dataset into categories by k-means clustering and appropriately\nadjust the size of the target category to which the target user belongs, so\nthat only users in the well-sized target category can be used for\nrecommendations. Then we efficiently select a set of neighbors from the target\ncategory at one time by employing only one exponential mechanism instead of the\ncomposition of multiple ones, and base on the neighbor set to recommend. We\ntheoretically prove that our scheme achieves differential privacy. Empirically,\nwe use the MovieLens dataset to evaluate our recommendation system. The\nexperimental results demonstrate a significant performance gain compared to\nexisting schemes.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 02:17:23 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Chen", "Zhili", ""], ["Wang", "Yu", ""], ["Zhang", "Shun", ""], ["Zhong", "Hong", ""], ["Chen", "Lin", ""]]}, {"id": "1812.01790", "submitter": "Charith Perera", "authors": "Balkis Abidi, Sadok Ben Yahia, Charith Perera", "title": "Hybrid Microaggregation for Privacy-Preserving Data Mining", "comments": "16", "journal-ref": "Journal of Ambient Intelligence and Humanized Computing, 2018", "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  k-Anonymity by microaggregation is one of the most commonly used\nanonymization techniques. This success is owe to the achievement of a worth of\ninterest tradeoff between information loss and identity disclosure risk.\nHowever, this method may have some drawbacks. On the disclosure limitation\nside, there is a lack of protection against attribute disclosure. On the data\nutility side, dealing with a real datasets is a challenging task to achieve.\nIndeed, the latter are characterized by their large number of attributes and\nthe presence of noisy data, such that outliers or, even, data with missing\nvalues. Generating an anonymous individual data useful for data mining tasks,\nwhile decreasing the influence of noisy data is a compelling task to achieve.\nIn this paper, we introduce a new microaggregation method, called HM-PFSOM,\nbased on fuzzy possibilistic clustering. Our proposed method operates through\nan hybrid manner. This means that the anonymization process is applied per\nblock of similar data. Thus, we can help to decrease the information loss\nduring the anonymization process. The HMPFSOM approach proposes to study the\ndistribution of confidential attributes within each sub-dataset. Then,\naccording to the latter distribution, the privacy parameter k is determined, in\nsuch a way to preserve the diversity of confidential attributes within the\nanonymized microdata. This allows to decrease the disclosure risk of\nconfidential information.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 07:42:33 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Abidi", "Balkis", ""], ["Yahia", "Sadok Ben", ""], ["Perera", "Charith", ""]]}, {"id": "1812.01804", "submitter": "Huangyi Ge", "authors": "Huangyi Ge, Sze Yiu Chau, Bruno Ribeiro, Ninghui Li", "title": "Random Spiking and Systematic Evaluation of Defenses Against Adversarial\n  Examples", "comments": "To be appear in ACM CODESPY 2020", "journal-ref": null, "doi": "10.1145/3374664.3375736", "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image classifiers often suffer from adversarial examples, which are generated\nby strategically adding a small amount of noise to input images to trick\nclassifiers into misclassification. Over the years, many defense mechanisms\nhave been proposed, and different researchers have made seemingly contradictory\nclaims on their effectiveness. We present an analysis of possible adversarial\nmodels, and propose an evaluation framework for comparing different defense\nmechanisms. As part of the framework, we introduce a more powerful and\nrealistic adversary strategy. Furthermore, we propose a new defense mechanism\ncalled Random Spiking (RS), which generalizes dropout and introduces random\nnoises in the training process in a controlled manner. Evaluations under our\nproposed framework suggest RS delivers better protection against adversarial\nexamples than many existing schemes.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 03:31:07 GMT"}, {"version": "v2", "created": "Mon, 4 Mar 2019 17:08:21 GMT"}, {"version": "v3", "created": "Sat, 12 Oct 2019 20:55:52 GMT"}, {"version": "v4", "created": "Mon, 20 Jan 2020 22:09:40 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Ge", "Huangyi", ""], ["Chau", "Sze Yiu", ""], ["Ribeiro", "Bruno", ""], ["Li", "Ninghui", ""]]}, {"id": "1812.02009", "submitter": "Meng Shen", "authors": "Liehuang Zhu, Baokun Zheng, Meng Shen, Shui Yu, Feng Gao, Hongyu Li,\n  Kexin Shi, Keke Gai", "title": "Research on the Security of Blockchain Data: A Survey", "comments": null, "journal-ref": "Journal of Computer Science and Technology, 2020, 35(4): 843-862", "doi": "10.1007/s11390-020-9638-7", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the more and more extensive application of blockchain, blockchain\nsecurity has been widely concerned by the society and deeply studied by\nscholars. Moreover, the security of blockchain data directly affects the\nsecurity of various applications of blockchain. In this survey, we perform a\ncomprehensive classification and summary of the security of blockchain data.\nFirst, we present classification of blockchain data attacks. Subsequently, we\npresent the attacks and defenses of blockchain data in terms of privacy,\navailability, integrity and controllability. Data privacy attacks present data\nleakage or data obtained by attackers through analysis. Data availability\nattacks present abnormal or incorrect access to blockchain data. Data integrity\nattacks present blockchain data being tampered. Data controllability attacks\npresent blockchain data accidentally manipulated by smart contract\nvulnerability. Finally, we present several important open research directions\nto identify follow-up studies in this area.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 14:09:25 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2018 09:23:08 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Zhu", "Liehuang", ""], ["Zheng", "Baokun", ""], ["Shen", "Meng", ""], ["Yu", "Shui", ""], ["Gao", "Feng", ""], ["Li", "Hongyu", ""], ["Shi", "Kexin", ""], ["Gai", "Keke", ""]]}, {"id": "1812.02055", "submitter": "Jinyuan Jia", "authors": "Jinyuan Jia and Neil Zhenqiang Gong", "title": "Calibrate: Frequency Estimation and Heavy Hitter Identification with\n  Local Differential Privacy via Incorporating Prior Knowledge", "comments": "Accepted by INFOCOM'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating frequencies of certain items among a population is a basic step in\ndata analytics, which enables more advanced data analytics (e.g., heavy hitter\nidentification, frequent pattern mining), client software optimization, and\ndetecting unwanted or malicious hijacking of user settings in browsers.\nFrequency estimation and heavy hitter identification with local differential\nprivacy (LDP) protect user privacy as well as the data collector. Existing LDP\nalgorithms cannot leverage 1) prior knowledge about the noise in the estimated\nitem frequencies and 2) prior knowledge about the true item frequencies. As a\nresult, they achieve suboptimal performance in practice.\n  In this work, we aim to design LDP algorithms that can leverage such prior\nknowledge. Specifically, we design ${Calibrate}$ to incorporate the prior\nknowledge via statistical inference. ${Calibrate}$ can be appended to an\nexisting LDP algorithm to reduce its estimation errors. We model the prior\nknowledge about the noise and the true item frequencies as two probability\ndistributions, respectively. Given the two probability distributions and an\nestimated frequency of an item produced by an existing LDP algorithm, our\n${Calibrate}$ computes the conditional probability distribution of the item's\nfrequency and uses the mean of the conditional probability distribution as the\ncalibrated frequency for the item. It is challenging to estimate the two\nprobability distributions due to data sparsity. We address the challenge via\nintegrating techniques from statistics and machine learning. Our empirical\nresults on two real-world datasets show that ${Calibrate}$ significantly\noutperforms state-of-the-art LDP algorithms for frequency estimation and heavy\nhitter identification.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 15:45:50 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 16:25:09 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Jia", "Jinyuan", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "1812.02132", "submitter": "Matthias M\\\"uller", "authors": "Abdullah Hamdi, Matthias M\\\"uller, Bernard Ghanem", "title": "SADA: Semantic Adversarial Diagnostic Attacks for Autonomous\n  Applications", "comments": "Accepted at AAAI'20", "journal-ref": "AAAI 2020", "doi": "10.1609/aaai.v34i07.6722", "report-no": null, "categories": "cs.CV cs.CR cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One major factor impeding more widespread adoption of deep neural networks\n(DNNs) is their lack of robustness, which is essential for safety-critical\napplications such as autonomous driving. This has motivated much recent work on\nadversarial attacks for DNNs, which mostly focus on pixel-level perturbations\nvoid of semantic meaning. In contrast, we present a general framework for\nadversarial attacks on trained agents, which covers semantic perturbations to\nthe environment of the agent performing the task as well as pixel-level\nattacks. To do this, we re-frame the adversarial attack problem as learning a\ndistribution of parameters that always fools the agent. In the semantic case,\nour proposed adversary (denoted as BBGAN) is trained to sample parameters that\ndescribe the environment with which the black-box agent interacts, such that\nthe agent performs its dedicated task poorly in this environment. We apply\nBBGAN on three different tasks, primarily targeting aspects of autonomous\nnavigation: object detection, self-driving, and autonomous UAV racing. On these\ntasks, BBGAN can generate failure cases that consistently fool a trained agent.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 17:42:36 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 21:28:55 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 16:20:42 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Hamdi", "Abdullah", ""], ["M\u00fcller", "Matthias", ""], ["Ghanem", "Bernard", ""]]}, {"id": "1812.02220", "submitter": "Praneet Singh", "authors": "Praneet Singh, Kedar Deshpande", "title": "Performance Evaluation of Cryptographic Ciphers on IoT Devices", "comments": "6 pages, 7 figures, International Conference on Recent Trends in\n  Computational Engineering and Technologies (ICTRCET'18), May 17-18, 2018,\n  Bangalore, India", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of Internet of Things (IoT) and the increasing use of\napplication-based processors, security infrastructure needs to be examined on\nsome widely-used IoT hardware architectures. Applications in today's world are\nmoving towards IoT concepts as this makes them fast, efficient, modular and\nfuture-proof. However, this leads to a greater security risk as IoT devices\nthrive in an ecosystem of co-existence and interconnection. As a result of\nthese security risks, it is of utmost importance to test the existing\ncryptographic ciphers on such devices and determine if they are viable in terms\nof swiftness of execution time and memory consumption efficiency. It is also\nimportant to determine if there is a requirement to develop new lightweight\ncryptographic ciphers for these devices. This paper hopes to accomplish the\nabove-mentioned objective by testing various encryption-decryption techniques\non different IoT based devices and creating a comparison of execution speeds\nbetween these devices for a variety of different data sizes. Keywords-Internet\nof things(IoT), application-based processors, security, encryption-decryption,\nspeed, efficiency\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 20:51:57 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Singh", "Praneet", ""], ["Deshpande", "Kedar", ""]]}, {"id": "1812.02232", "submitter": "Michael Stay", "authors": "Kyle Butt, Derek Sorensen, Michael Stay", "title": "Casanova", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Casanova, a leaderless optimistic consensus protocol designed\nfor a permissioned blockchain. Casanova produces blocks in a DAG rather than a\nchain, and combines voting rounds with block production by singling out\nindividual conflicting transactions.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 21:25:38 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 21:27:30 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Butt", "Kyle", ""], ["Sorensen", "Derek", ""], ["Stay", "Michael", ""]]}, {"id": "1812.02245", "submitter": "Arash Atashpendar", "authors": "Arash Atashpendar, G. Vamsi Policharla, Peter B. R{\\o}nne, Peter Y. A.\n  Ryan", "title": "Revisiting Deniability in Quantum Key Exchange via Covert Communication\n  and Entanglement Distillation", "comments": "16 pages, published in the proceedings of NordSec 2018", "journal-ref": "NordSec 2018. Lecture Notes in Computer Science, vol. 11252, pp\n  104-120, Springer, Cham (2018)", "doi": "10.1007/978-3-030-03638-6_7", "report-no": null, "categories": "quant-ph cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the notion of deniability in quantum key exchange (QKE), a topic\nthat remains largely unexplored. In the only work on this subject by Donald\nBeaver, it is argued that QKE is not necessarily deniable due to an\neavesdropping attack that limits key equivocation. We provide more insight into\nthe nature of this attack and how it extends to other constructions such as QKE\nobtained from uncloneable encryption. We then adopt the framework for quantum\nauthenticated key exchange, developed by Mosca et al., and extend it to\nintroduce the notion of coercer-deniable QKE, formalized in terms of the\nindistinguishability of real and fake coercer views. Next, we apply results\nfrom a recent work by Arrazola and Scarani on covert quantum communication to\nestablish a connection between covert QKE and deniability. We propose DC-QKE, a\nsimple deniable covert QKE protocol, and prove its deniability via a reduction\nto the security of covert QKE. Finally, we consider how entanglement\ndistillation can be used to enable information-theoretically deniable protocols\nfor QKE and tasks beyond key exchange.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 22:02:47 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Atashpendar", "Arash", ""], ["Policharla", "G. Vamsi", ""], ["R\u00f8nne", "Peter B.", ""], ["Ryan", "Peter Y. A.", ""]]}, {"id": "1812.02274", "submitter": "Chong Xiang", "authors": "Qingrong Chen, Chong Xiang, Minhui Xue, Bo Li, Nikita Borisov, Dali\n  Kaarfar, Haojin Zhu", "title": "Differentially Private Data Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have recently been widely adopted in various\napplications, and such success is largely due to a combination of algorithmic\nbreakthroughs, computation resource improvements, and access to a large amount\nof data. However, the large-scale data collections required for deep learning\noften contain sensitive information, therefore raising many privacy concerns.\nPrior research has shown several successful attacks in inferring sensitive\ntraining data information, such as model inversion, membership inference, and\ngenerative adversarial networks (GAN) based leakage attacks against\ncollaborative deep learning. In this paper, to enable learning efficiency as\nwell as to generate data with privacy guarantees and high utility, we propose a\ndifferentially private autoencoder-based generative model (DP-AuGM) and a\ndifferentially private variational autoencoder-based generative model\n(DP-VaeGM). We evaluate the robustness of two proposed models. We show that\nDP-AuGM can effectively defend against the model inversion, membership\ninference, and GAN-based attacks. We also show that DP-VaeGM is robust against\nthe membership inference attack. We conjecture that the key to defend against\nthe model inversion and GAN-based attacks is not due to differential privacy\nbut the perturbation of training data. Finally, we demonstrate that both\nDP-AuGM and DP-VaeGM can be easily integrated with real-world machine learning\napplications, such as machine learning as a service and federated learning,\nwhich are otherwise threatened by the membership inference attack and the\nGAN-based attack, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 00:10:40 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Chen", "Qingrong", ""], ["Xiang", "Chong", ""], ["Xue", "Minhui", ""], ["Li", "Bo", ""], ["Borisov", "Nikita", ""], ["Kaarfar", "Dali", ""], ["Zhu", "Haojin", ""]]}, {"id": "1812.02282", "submitter": "Mubashir Husain Rehmani", "authors": "Muneeb Ul Hassan, Mubashir Husain Rehmani, Jinjun Chen", "title": "Differential Privacy Techniques for Cyber Physical Systems: A Survey", "comments": "46 pages, 12 figures", "journal-ref": "IEEE Communications Surveys and Tutorials, Sep 2019", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern cyber physical systems (CPSs) has widely being used in our daily lives\nbecause of development of information and communication technologies (ICT).With\nthe provision of CPSs, the security and privacy threats associated to these\nsystems are also increasing. Passive attacks are being used by intruders to get\naccess to private information of CPSs. In order to make CPSs data more secure,\ncertain privacy preservation strategies such as encryption, and k-anonymity\nhave been presented in the past. However, with the advances in CPSs\narchitecture, these techniques also needs certain modifications. Meanwhile,\ndifferential privacy emerged as an efficient technique to protect CPSs data\nprivacy. In this paper, we present a comprehensive survey of differential\nprivacy techniques for CPSs. In particular, we survey the application and\nimplementation of differential privacy in four major applications of CPSs named\nas energy systems, transportation systems, healthcare and medical systems, and\nindustrial Internet of things (IIoT). Furthermore, we present open issues,\nchallenges, and future research direction for differential privacy techniques\nfor CPSs. This survey can serve as basis for the development of modern\ndifferential privacy techniques to address various problems and data privacy\nscenarios of CPSs.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 00:55:29 GMT"}, {"version": "v2", "created": "Wed, 1 May 2019 11:31:41 GMT"}, {"version": "v3", "created": "Fri, 27 Sep 2019 14:35:21 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Hassan", "Muneeb Ul", ""], ["Rehmani", "Mubashir Husain", ""], ["Chen", "Jinjun", ""]]}, {"id": "1812.02292", "submitter": "Xiangyun Tang", "authors": "Xiangyun Tang, Liehuang Zhu, Meng Shen and Xiaojiang Du", "title": "When Homomorphic Cryptosystem Meets Differential Privacy: Training\n  Machine Learning Classifier with Privacy Protection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) classifiers are invaluable building blocks that have\nbeen used in many fields. High quality training dataset collected from multiple\ndata providers is essential to train accurate classifiers. However, it raises\nconcern about data privacy due to potential leakage of sensitive information in\ntraining dataset. Existing studies have proposed many solutions to\nprivacy-preserving training of ML classifiers, but it remains a challenging\ntask to strike a balance among accuracy, computational efficiency, and\nsecurity. In this paper, we propose Heda, an efficient privacypreserving scheme\nfor training ML classifiers. By combining homomorphic cryptosystem (HC) with\ndifferential privacy (DP), Heda obtains the tradeoffs between efficiency and\naccuracy, and enables flexible switch among different tradeoffs by parameter\ntuning. In order to make such combination efficient and feasible, we present\nnovel designs based on both HC and DP: A library of building blocks based on\npartially HC are proposed to construct complex training algorithms without\nintroducing a trusted thirdparty or computational relaxation; A set of\ntheoretical methods are proposed to determine appropriate privacy budget and to\nreduce sensitivity. Security analysis demonstrates that our solution can\nconstruct complex ML training algorithm securely. Extensive experimental\nresults show the effectiveness and efficiency of the proposed scheme.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 02:07:53 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Tang", "Xiangyun", ""], ["Zhu", "Liehuang", ""], ["Shen", "Meng", ""], ["Du", "Xiaojiang", ""]]}, {"id": "1812.02357", "submitter": "Zeyad Al-Odat", "authors": "Zeyad A. Al-Odat, Sudarshan K. Srinivasan, Eman Al-qtiemat, Mohana\n  Asha Latha Dubasi, Sana Shuja", "title": "IoT-Based Secure Embedded Scheme for Insulin Pump Data Acquisition and\n  Monitoring", "comments": "4 pages, 4 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces an Internet of Things (IoT)-based data acquisition and\nmonitoring scheme for insulin pumps. The proposed work employs embedded system\nhardware (Keil LPC1768-board) for data acquisition and monitoring. The hardware\nis used as an abstract layer between the insulin pump and the cloud. Diabetes\ndata are secured before they are sent to the cloud for storage. Each patient's\nrecord is digitally signed using a secure hash algorithm mechanism. The\nproposed work will protect the patient's records from being breached from\nunauthorized entities, and authenticates them from improper modifications. The\ndesign is tested and verified using $\\mu$Vision studio, the Keil board\nmentioned above, and an ALARIS 8100 infusion pump. Moreover, a test case for a\nreal cloud example is presented with the help of the Center of Computationally\nAssisted System and Technology. This center provided the infrastructure service\nto test our work.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 05:32:35 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Al-Odat", "Zeyad A.", ""], ["Srinivasan", "Sudarshan K.", ""], ["Al-qtiemat", "Eman", ""], ["Dubasi", "Mohana Asha Latha", ""], ["Shuja", "Sana", ""]]}, {"id": "1812.02361", "submitter": "Suin Kang", "authors": "Suin Kang, Hye Min Kim and Huy Kang Kim", "title": "Trustworthy Smart Band: Security Requirement Analysis with Threat\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As smart bands make life more convenient and provide a positive lifestyle,\nmany people are now using them. Since smart bands deal with private\ninformation, security design and implementation for smart band system become\nnecessary. To make a trustworthy smart band, we must derive the security\nrequirements of the system first, and then design the system satisfying the\nsecurity requirements. In this paper, we apply threat modeling techniques such\nas Data Flow Diagram, STRIDE, and Attack Tree to the smart band system to\nidentify threats and derive security requirements accordingly. Through threat\nmodeling, we found the vulnerabilities of the smart band system and\nsuccessfully exploited smart bands with them. To defend against these threats,\nwe propose security measures and verify that they are secure by using Scyther\nwhich is a tool for automatic verification of security protocol.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 06:00:48 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Kang", "Suin", ""], ["Kim", "Hye Min", ""], ["Kim", "Huy Kang", ""]]}, {"id": "1812.02386", "submitter": "Cheng Xu", "authors": "Cheng Xu and Ce Zhang and Jianliang Xu", "title": "vChain: Enabling Verifiable Boolean Range Queries over Blockchain\n  Databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchains have recently been under the spotlight due to the boom of\ncryptocurrencies and decentralized applications. There is an increasing demand\nfor querying the data stored in a blockchain database. To ensure query\nintegrity, the user can maintain the entire blockchain database and query the\ndata locally. However, this approach is not economic, if not infeasible,\nbecause of the blockchain's huge data size and considerable maintenance costs.\nIn this paper, we take the first step toward investigating the problem of\nverifiable query processing over blockchain databases. We propose a novel\nframework, called vChain, that alleviates the storage and computing costs of\nthe user and employs verifiable queries to guarantee the results' integrity. To\nsupport verifiable Boolean range queries, we propose an accumulator-based\nauthenticated data structure that enables dynamic aggregation over arbitrary\nquery attributes. Two new indexes are further developed to aggregate\nintra-block and inter-block data records for efficient query verification. We\nalso propose an inverted prefix tree structure to accelerate the processing of\na large number of subscription queries simultaneously. Security analysis and\nempirical study validate the robustness and practicality of the proposed\ntechniques.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 07:33:37 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Xu", "Cheng", ""], ["Zhang", "Ce", ""], ["Xu", "Jianliang", ""]]}, {"id": "1812.02428", "submitter": "Sai Sri Sathya", "authors": "Sai Sri Sathya, Praneeth Vepakomma, Ramesh Raskar, Ranjan Ramachandra\n  and Santanu Bhattacharya", "title": "A Review of Homomorphic Encryption Libraries for Secure Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we provide a survey of various libraries for homomorphic\nencryption. We describe key features and trade-offs that should be considered\nwhile choosing the right approach for secure computation. We then present a\ncomparison of six commonly available Homomorphic Encryption libraries - SEAL,\nHElib, TFHE, Paillier, ELGamal and RSA across these identified features.\nSupport for different languages and real-life applications are also elucidated.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 09:55:24 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2018 06:06:35 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Sathya", "Sai Sri", ""], ["Vepakomma", "Praneeth", ""], ["Raskar", "Ramesh", ""], ["Ramachandra", "Ranjan", ""], ["Bhattacharya", "Santanu", ""]]}, {"id": "1812.02575", "submitter": "Andrey Malinin", "authors": "Andrey Malinin and Mark Gales", "title": "Prior Networks for Detection of Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are considered a serious issue for safety critical\napplications of AI, such as finance, autonomous vehicle control and medicinal\napplications. Though significant work has resulted in increased robustness of\nsystems to these attacks, systems are still vulnerable to well-crafted attacks.\nTo address this problem, several adversarial attack detection methods have been\nproposed. However, a system can still be vulnerable to adversarial samples that\nare designed to specifically evade these detection methods. One recent\ndetection scheme that has shown good performance is based on uncertainty\nestimates derived from Monte-Carlo dropout ensembles. Prior Networks, a new\nmethod of estimating predictive uncertainty, has been shown to outperform\nMonte-Carlo dropout on a range of tasks. One of the advantages of this approach\nis that the behaviour of a Prior Network can be explicitly tuned to, for\nexample, predict high uncertainty in regions where there are no training data\nsamples. In this work, Prior Networks are applied to adversarial attack\ndetection using measures of uncertainty in a similar fashion to Monte-Carlo\nDropout. Detection based on measures of uncertainty derived from DNNs and\nMonte-Carlo dropout ensembles are used as a baseline. Prior Networks are shown\nto significantly out-perform these baseline approaches over a range of\nadversarial attacks in both detection of whitebox and blackbox configurations.\nEven when the adversarial attacks are constructed with full knowledge of the\ndetection mechanism, it is shown to be highly challenging to successfully\ngenerate an adversarial sample.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 14:59:29 GMT"}], "update_date": "2018-12-08", "authors_parsed": [["Malinin", "Andrey", ""], ["Gales", "Mark", ""]]}, {"id": "1812.02606", "submitter": "Kathrin Grosse", "authors": "Kathrin Grosse, David Pfaff, Michael Thomas Smith, Michael Backes", "title": "The Limitations of Model Uncertainty in Adversarial Settings", "comments": "Accepted to the Bayesian Deep Learning Workshop 2019 at NeurIPS. For\n  longer version with more background, refer to previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are vulnerable to adversarial examples: minor\nperturbations to input samples intended to deliberately cause\nmisclassification. While an obvious security threat, adversarial examples yield\nas well insights about the applied model itself. We investigate adversarial\nexamples in the context of Bayesian neural network's (BNN's) uncertainty\nmeasures. As these measures are highly non-smooth, we use a smooth Gaussian\nprocess classifier (GPC) as substitute. We show that both confidence and\nuncertainty can be unsuspicious even if the output is wrong. Intriguingly, we\nfind subtle differences in the features influencing uncertainty and confidence\nfor most tasks.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 15:33:46 GMT"}, {"version": "v2", "created": "Sun, 17 Nov 2019 21:25:06 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Grosse", "Kathrin", ""], ["Pfaff", "David", ""], ["Smith", "Michael Thomas", ""], ["Backes", "Michael", ""]]}, {"id": "1812.02710", "submitter": "Milos Manic", "authors": "Craig Rieger, Milos Manic", "title": "On Critical Infrastructures, Their Security and Resilience - Trends and\n  Vision", "comments": "Easy reading material by long time experts in the field", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short paper is presented in observance and promotion of November, the\nNational Month of Critical Infrastructure Security and Resilience (CISR),\nestablished by the United States Department of Homeland Security in 2013. The\nCISR term focuses on essential assets (critical infrastructures) and two\nultimate goals of making them secure and resilient. These assets and goals were\nput together in 2013 in the now well-known Presidential Policy Directive on\nCISR (PPD-21). This paper presents easy-to-ready material laying down the\nbuilding blocks of CISR - what it means to you as a regular citizen,\nprofessional, or government worker. This paper presents concepts behind\nsecurity and resilience pertinent to various types of activities - from every\nday to field-specific activities. This paper also presents basic elements to\nthe field: 1. high-level introduction to the organizational units dealing with\nCISR in the United States; 2. explanation of basic terms and a list of further\nreading material; and 3. several discussion topics on the vision and future of\nCISR in critical infrastructure cyber-physical systems.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 18:43:37 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Rieger", "Craig", ""], ["Manic", "Milos", ""]]}, {"id": "1812.02737", "submitter": "Bo Luo", "authors": "Bo Luo, Min Li, Yu Li, Qiang Xu", "title": "On Configurable Defense against Adversarial Example Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning systems based on deep neural networks (DNNs) have gained\nmainstream adoption in many applications. Recently, however, DNNs are shown to\nbe vulnerable to adversarial example attacks with slight perturbations on the\ninputs. Existing defense mechanisms against such attacks try to improve the\noverall robustness of the system, but they do not differentiate different\ntargeted attacks even though the corresponding impacts may vary significantly.\nTo tackle this problem, we propose a novel configurable defense mechanism in\nthis work, wherein we are able to flexibly tune the robustness of the system\nagainst different targeted attacks to satisfy application requirements. This is\nachieved by refining the DNN loss function with an attack sensitive matrix to\nrepresent the impacts of different targeted attacks. Experimental results on\nCIFAR-10 and GTSRB data sets demonstrate the efficacy of the proposed solution.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 03:12:16 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Luo", "Bo", ""], ["Li", "Min", ""], ["Li", "Yu", ""], ["Xu", "Qiang", ""]]}, {"id": "1812.02761", "submitter": "Joseph Van Name", "authors": "Joseph Van Name", "title": "Generalizations of Laver tables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CR math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We shall generalize the notion of a Laver table to algebras which may have\nmany generators, several fundamental operations, fundamental operations of\narity higher than 2, and to algebras where only some of the operations are\nself-distributive or where the operations satisfy a generalized version of\nself-distributivity. These algebras mimic the algebras of rank-into-rank\nembeddings $\\mathcal{E}_{\\lambda}/\\equiv^{\\gamma}$ in the sense that\ncomposition and the notion of a critical point make sense for these sorts of\nalgebras.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 19:19:48 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Van Name", "Joseph", ""]]}, {"id": "1812.02766", "submitter": "Tribhuvanesh Orekondy", "authors": "Tribhuvanesh Orekondy, Bernt Schiele, Mario Fritz", "title": "Knockoff Nets: Stealing Functionality of Black-Box Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine Learning (ML) models are increasingly deployed in the wild to perform\na wide range of tasks. In this work, we ask to what extent can an adversary\nsteal functionality of such \"victim\" models based solely on blackbox\ninteractions: image in, predictions out. In contrast to prior work, we present\nan adversary lacking knowledge of train/test data used by the model, its\ninternals, and semantics over model outputs. We formulate model functionality\nstealing as a two-step approach: (i) querying a set of input images to the\nblackbox model to obtain predictions; and (ii) training a \"knockoff\" with\nqueried image-prediction pairs. We make multiple remarkable observations: (a)\nquerying random images from a different distribution than that of the blackbox\ntraining data results in a well-performing knockoff; (b) this is possible even\nwhen the knockoff is represented using a different architecture; and (c) our\nreinforcement learning approach additionally improves query sample efficiency\nin certain settings and provides performance gains. We validate model\nfunctionality stealing on a range of datasets and tasks, as well as on a\npopular image analysis API where we create a reasonable knockoff for as little\nas $30.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 19:34:33 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Orekondy", "Tribhuvanesh", ""], ["Schiele", "Bernt", ""], ["Fritz", "Mario", ""]]}, {"id": "1812.02770", "submitter": "Imran Abbasi", "authors": "Imran Hafeez Abbassi, Faiq Khalid, Semeen Rehman, Awais Mehmood\n  Kamboh, Axel Jantsch, Siddharth Garg and Muhammad Shafique", "title": "TrojanZero: Switching Activity-Aware Design of Undetectable Hardware\n  Trojans with Zero Power and Area Footprint", "comments": "Design, Automation and Test in Europe (DATE 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional Hardware Trojan (HT) detection techniques are based on the\nvalidation of integrated circuits to determine changes in their functionality,\nand on non-invasive side-channel analysis to identify the variations in their\nphysical parameters. In particular, almost all the proposed side-channel\npower-based detection techniques presume that HTs are detectable because they\nonly add gates to the original circuit with a noticeable increase in power\nconsumption. This paper demonstrates how undetectable HTs can be realized with\nzero impact on the power and area footprint of the original circuit. Towards\nthis, we propose a novel concept of TrojanZero and a systematic methodology for\ndesigning undetectable HTs in the circuits, which conceals their existence by\ngate-level modifications. The crux is to salvage the cost of the HT from the\noriginal circuit without being detected using standard testing techniques. Our\nmethodology leverages the knowledge of transition probabilities of the circuit\nnodes to identify and safely remove expendable gates, and embeds malicious\ncircuitry at the appropriate locations with zero power and area overheads when\ncompared to the original circuit. We synthesize these designs and then embed in\nmultiple ISCAS85 benchmarks using a 65nm technology library, and perform a\ncomprehensive power and area characterization. Our experimental results\ndemonstrate that the proposed TrojanZero designs are undetectable by the\nstate-of-the-art power-based detection methods.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 10:48:44 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Abbassi", "Imran Hafeez", ""], ["Khalid", "Faiq", ""], ["Rehman", "Semeen", ""], ["Kamboh", "Awais Mehmood", ""], ["Jantsch", "Axel", ""], ["Garg", "Siddharth", ""], ["Shafique", "Muhammad", ""]]}, {"id": "1812.02808", "submitter": "Abraham Hinteregger BSc MSc MSc", "authors": "Abraham Hinteregger, Bernhard Haslhofer", "title": "An Empirical Analysis of Monero Cross-Chain Traceability", "comments": "Conference paper (http://fc19.ifca.ai/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monero is a privacy-centric cryptocurrency that makes payments untraceable by\nadding decoys to every real input spent in a transaction. Two studies from 2017\nfound methods to distinguish decoys from real inputs, which enabled\ntraceability for a majority of transactions. Since then, a number protocol\nchanges have been introduced, but their effectiveness has not yet been\nreassessed. Furthermore, little is known about traceability of Monero\ntransactions across hard fork chains. We formalize a new method for tracing\nMonero transactions, which is based on analyzing currency hard forks. We use\nthat method to perform a (passive) traceability analysis on data from the\nMonero, MoneroV and Monero Original blockchains and find that only a small\namount of inputs are traceable. We then use the results to estimate the\neffectiveness of known heuristics for recent transactions and find that they do\nnot significantly outperform random guessing. Our findings suggest that Monero\nis currently mostly immune to known passive attack vectors and resistant to\ntracking and tracing methods applied to other cryptocurrencies.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 21:19:47 GMT"}, {"version": "v2", "created": "Fri, 4 Jan 2019 13:46:08 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Hinteregger", "Abraham", ""], ["Haslhofer", "Bernhard", ""]]}, {"id": "1812.02834", "submitter": "Jiyang Chen", "authors": "Jiyang Chen, Zhiwei Feng, Jen-Yang Wen, Bo Liu, and Lui Sha", "title": "A Container-based DoS Attack-Resilient Control Framework for Real-Time\n  UAV Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Unmanned aerial vehicles (UAVs) sector is fast-expanding. Protection of\nreal-time UAV applications against malicious attacks has become an urgent\nproblem that needs to be solved. Denial-of-service (DoS) attack aims to exhaust\nsystem resources and cause important tasks to miss deadlines. DoS attack may be\none of the common problems of UAV systems, due to its simple implementation. In\nthis paper, we present a software framework that offers DoS attack-resilient\ncontrol for real-time UAV systems using containers: ContainerDrone. The\nframework provides defense mechanisms for three critical system resources: CPU,\nmemory, and communication channel. We restrict attacker's access to CPU core\nset and utilization. Memory bandwidth throttling limits attacker's memory\nusage. By simulating sensors and drivers in the container, a security monitor\nconstantly checks DoS attacks over communication channels. Upon the detection\nof a security rule violation, the framework switches to the safety controller\nto mitigate the attack. We implemented a prototype quadcopter with commercially\noff-the-shelf (COTS) hardware and open-source software. Our experimental\nresults demonstrated the effectiveness of the proposed framework defending\nagainst various DoS attacks.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 22:19:57 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Chen", "Jiyang", ""], ["Feng", "Zhiwei", ""], ["Wen", "Jen-Yang", ""], ["Liu", "Bo", ""], ["Sha", "Lui", ""]]}, {"id": "1812.02848", "submitter": "Anthony Palladino", "authors": "Anthony Palladino and Christopher J. Thissen", "title": "Cyber Anomaly Detection Using Graph-node Role-dynamics", "comments": null, "journal-ref": "Proceedings of DYnamic and Novel Advances in Machine Learning and\n  Intelligent Cyber Security Workshop (DYNAMICS'18). ACM, New York, NY, USA.\n  (2019)", "doi": "10.1145/3306195.3306198", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrusion detection systems (IDSs) generate valuable knowledge about network\nsecurity, but an abundance of false alarms and a lack of methods to capture the\ninterdependence among alerts hampers their utility for network defense. Here,\nwe explore a graph-based approach for fusing alerts generated by multiple IDSs\n(e.g., Snort, OSSEC, and Bro). Our approach generates a weighted graph of alert\nfields (not network topology) that makes explicit the connections between\nmultiple alerts, IDS systems, and other cyber artifacts. We use this\nmulti-modal graph to identify anomalous changes in the alert patterns of a\nnetwork. To detect the anomalies, we apply the role-dynamics approach, which\nhas successfully identified anomalies in social media, email, and IP\ncommunication graphs. In the cyber domain, each node (alert field) in the fused\nIDS alert graph is assigned a probability distribution across a small set of\nroles based on that node's features. A cyber attack should trigger IDS alerts\nand cause changes in the node features, but rather than track every feature for\nevery alert-field node individually, roles provide a succinct, integrated\nsummary of those feature changes. We measure changes in each node's\nprobabilistic role assignment over time, and identify anomalies as deviations\nfrom expected roles. We test our approach using simulations including three\nweeks of normal background traffic, as well as cyber attacks that occur near\nthe end of the simulations. This paper presents a novel approach to multi-modal\ndata fusion and a novel application of role dynamics within the cyber-security\ndomain. Our results show a drastic decrease in the false-positive rate when\nconsidering our anomaly indicator instead of the IDS alerts themselves, thereby\nreducing alarm fatigue and providing a promising avenue for threat intelligence\nin network defense.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 23:05:00 GMT"}, {"version": "v2", "created": "Wed, 16 Jan 2019 14:33:48 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Palladino", "Anthony", ""], ["Thissen", "Christopher J.", ""]]}, {"id": "1812.02863", "submitter": "Jianfeng Chi", "authors": "Jianfeng Chi, Emmanuel Owusu, Xuwang Yin, Tong Yu, William Chan,\n  Patrick Tague, Yuan Tian", "title": "Privacy Partitioning: Protecting User Data During the Deep Learning\n  Inference Phase", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a practical method for protecting data during the inference phase\nof deep learning based on bipartite topology threat modeling and an interactive\nadversarial deep network construction. We term this approach \\emph{Privacy\nPartitioning}. In the proposed framework, we split the machine learning models\nand deploy a few layers into users' local devices, and the rest of the layers\ninto a remote server. We propose an approach to protect user's data during the\ninference phase, while still achieve good classification accuracy.\n  We conduct an experimental evaluation of this approach on benchmark datasets\nof three computer vision tasks. The experimental results indicate that this\napproach can be used to significantly attenuate the capacity for an adversary\nwith access to the state-of-the-art deep network's intermediate states to learn\nprivacy-sensitive inputs to the network. For example, we demonstrate that our\napproach can prevent attackers from inferring the private attributes such as\ngender from the Face image dataset without sacrificing the classification\naccuracy of the original machine learning task such as Face Identification.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 00:42:06 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Chi", "Jianfeng", ""], ["Owusu", "Emmanuel", ""], ["Yin", "Xuwang", ""], ["Yu", "Tong", ""], ["Chan", "William", ""], ["Tague", "Patrick", ""], ["Tian", "Yuan", ""]]}, {"id": "1812.02885", "submitter": "Andre Nguyen", "authors": "Andre T. Nguyen and Edward Raff", "title": "Adversarial Attacks, Regression, and Numerical Stability Regularization", "comments": "Presented at the AAAI 2019 Workshop on Engineering Dependable and\n  Secure Machine Learning Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks against neural networks in a regression setting are a\ncritical yet understudied problem. In this work, we advance the state of the\nart by investigating adversarial attacks against regression networks and by\nformulating a more effective defense against these attacks. In particular, we\ntake the perspective that adversarial attacks are likely caused by numerical\ninstability in learned functions. We introduce a stability inducing,\nregularization based defense against adversarial attacks in the regression\nsetting. Our new and easy to implement defense is shown to outperform prior\napproaches and to improve the numerical stability of learned functions.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 02:50:20 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Nguyen", "Andre T.", ""], ["Raff", "Edward", ""]]}, {"id": "1812.03087", "submitter": "Aly El Gamal", "authors": "Rajeev Sahay, Rehana Mahfuz, Aly El Gamal", "title": "Combatting Adversarial Attacks through Denoising and Dimensionality\n  Reduction: A Cascaded Autoencoder Approach", "comments": "7 pages, 8 figures, submitted to Conference on Information Sciences\n  and Systems (CISS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning models are vulnerable to adversarial attacks that rely on\nperturbing the input data. This work proposes a novel strategy using\nAutoencoder Deep Neural Networks to defend a machine learning model against two\ngradient-based attacks: The Fast Gradient Sign attack and Fast Gradient attack.\nFirst we use an autoencoder to denoise the test data, which is trained with\nboth clean and corrupted data. Then, we reduce the dimension of the denoised\ndata using the hidden layer representation of another autoencoder. We perform\nthis experiment for multiple values of the bound of adversarial perturbations,\nand consider different numbers of reduced dimensions. When the test data is\npreprocessed using this cascaded pipeline, the tested deep neural network\nclassifier yields a much higher accuracy, thus mitigating the effect of the\nadversarial perturbation.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 16:21:24 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Sahay", "Rajeev", ""], ["Mahfuz", "Rehana", ""], ["Gamal", "Aly El", ""]]}, {"id": "1812.03173", "submitter": "Amir Moradibaad", "authors": "Amir Moradibaad, Ramin Jalilian Mashhoud", "title": "Use Dimensionality Reduction and SVM Methods to Increase the Penetration\n  Rate of Computer Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the world today computer networks have a very important position and most\nof the urban and national infrastructure as well as organizations are managed\nby computer networks, therefore, the security of these systems against the\nplanned attacks is of great importance. Therefore, researchers have been trying\nto find these vulnerabilities so that after identifying ways to penetrate the\nsystem, they will provide system protection through preventive or\ncountermeasures. SVM is one of the major algorithms for intrusion detection. In\nthis research, we studied a variety of malware and methods of intrusion\ndetection, provide an efficient method for detecting attacks and utilizing\ndimension reduction.Thus, we will be able to detect attacks by carefully\ncombining these two algorithms and pre-processes that are performed before the\ntwo on the input data. The main question raised is how we can identify attacks\non computer networks with the above-mentioned method. In anomalies diagnostic\nmethod, by identifying behavior as a normal behavior for the user, the host, or\nthe whole system, any deviation from this behavior is considered as an abnormal\nbehavior, which can be a potential occurrence of an attack. The network\nintrusion detection system is used by anomaly detection method that uses the\nSVM algorithm for classification and SVD to reduce the size. Steps of the\nproposed method include pre-processing of the data set, feature selection,\nsupport vector machine, and evaluation.The NSL-KDD data set has been used to\nteach and test the proposed model. In this study, we inferred the intrusion\ndetection using the SVM algorithm for classification and SVD for diminishing\ndimensions with no classification algorithm.Also the KNN algorithm has been\ncompared in situations with and without diminishing dimensions,the results have\nshown that the proposed method has a better performance than comparable\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 10:21:24 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2018 12:23:45 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Moradibaad", "Amir", ""], ["Mashhoud", "Ramin Jalilian", ""]]}, {"id": "1812.03230", "submitter": "Zhongshu Gu", "authors": "Zhongshu Gu, Hani Jamjoom, Dong Su, Heqing Huang, Jialong Zhang,\n  Tengfei Ma, Dimitrios Pendarakis, Ian Molloy", "title": "Reaching Data Confidentiality and Model Accountability on the CalTrain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed collaborative learning (DCL) paradigms enable building joint\nmachine learning models from distrusting multi-party participants. Data\nconfidentiality is guaranteed by retaining private training data on each\nparticipant's local infrastructure. However, this approach to achieving data\nconfidentiality makes today's DCL designs fundamentally vulnerable to data\npoisoning and backdoor attacks. It also limits DCL's model accountability,\nwhich is key to backtracking the responsible \"bad\" training data\ninstances/contributors. In this paper, we introduce CALTRAIN, a Trusted\nExecution Environment (TEE) based centralized multi-party collaborative\nlearning system that simultaneously achieves data confidentiality and model\naccountability. CALTRAIN enforces isolated computation on centrally aggregated\ntraining data to guarantee data confidentiality. To support building\naccountable learning models, we securely maintain the links between training\ninstances and their corresponding contributors. Our evaluation shows that the\nmodels generated from CALTRAIN can achieve the same prediction accuracy when\ncompared to the models trained in non-protected environments. We also\ndemonstrate that when malicious training participants tend to implant backdoors\nduring model training, CALTRAIN can accurately and precisely discover the\npoisoned and mislabeled training data that lead to the runtime mispredictions.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 22:23:13 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Gu", "Zhongshu", ""], ["Jamjoom", "Hani", ""], ["Su", "Dong", ""], ["Huang", "Heqing", ""], ["Zhang", "Jialong", ""], ["Ma", "Tengfei", ""], ["Pendarakis", "Dimitrios", ""], ["Molloy", "Ian", ""]]}, {"id": "1812.03237", "submitter": "Md Mehedi Hassan Onik", "authors": "Md Mehedi Hassan Onik, Mahdi H. Miraz, Chul-Soo Kim", "title": "A Recruitment and Human Resource Management Technique Using Blockchain\n  Technology for Industry 4.0", "comments": "Onik, M. M. H., Miraz, M. H., & Kim, C. S. (2018, April). A\n  recruitment and human resource management technique using Blockchain\n  technology for Industry 4.0. In Proceedings of the Smart Cities Symposium\n  (SCS-2018), Manama, Bahrain (pp. 11-16). IET", "journal-ref": null, "doi": "10.1049/cp.2018.1371", "report-no": null, "categories": "cs.CR cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Application of Information Technology (IT) in the domain of Human Resource\nManagement (HRM) systems is a sine qua non for any organization for\nsuccessfully adopting and implementing Fourth Industrial Revolution (Industry\n4.0). However, these systems are required to ensure non-biased, efficient,\ntransparent and secure environment. Blockchain, a technology based on\ndistributed digital ledgers, can help facilitate the process of successfully\neffectuating these specifications. A detailed literature review has been\nconducted to identify the current status of usage of Information Technology in\nthe domain of Human Resource Management and how Blockchain can help achieve a\nsmart, cost-effective, efficient, transparent and secure factory management\nsystem. A Blockchain based Recruitment Management System (BcRMS) as well as\nBlockchain based Human Resource Management System (BcHRMS) algorithm have been\nproposed. From the analysis of the results obtained through the case study, it\nis evident that the proposed system holds definite advantages compared to the\nexisting recruitment systems. Future research directions have also been\nidentified and advocated.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 23:09:06 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Onik", "Md Mehedi Hassan", ""], ["Miraz", "Mahdi H.", ""], ["Kim", "Chul-Soo", ""]]}, {"id": "1812.03280", "submitter": "Chaoyue Niu", "authors": "Chaoyue Niu, Zhenzhe Zheng, Fan Wu, Xiaofeng Gao, and Guihai Chen", "title": "Achieving Data Truthfulness and Privacy Preservation in Data Markets", "comments": "The early version of this work appeared as a poster paper in IEEE\n  ICDE 2017, titled \"Trading Data in Good Faith: Integrating Truthfulness and\n  Privacy Preservation in Data Markets\". Later, the longer version was accepted\n  as a regular paper by the journal IEEE TKDE. The current manuscript in arXiv\n  is the full version. Please visit\n  https://github.com/NiuChaoyue/TKDE-2018-TPDM for source code", "journal-ref": "IEEE Transactions on Knowledge and Data Engineering (TKDE), Volume\n  31, Issue 1, Pages 105--119, 2019", "doi": "10.1109/TKDE.2018.2822727", "report-no": null, "categories": "cs.DB cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a significant business paradigm, many online information platforms have\nemerged to satisfy society's needs for person-specific data, where a service\nprovider collects raw data from data contributors, and then offers value-added\ndata services to data consumers. However, in the data trading layer, the data\nconsumers face a pressing problem, i.e., how to verify whether the service\nprovider has truthfully collected and processed data? Furthermore, the data\ncontributors are usually unwilling to reveal their sensitive personal data and\nreal identities to the data consumers. In this paper, we propose TPDM, which\nefficiently integrates data Truthfulness and Privacy preservation in Data\nMarkets. TPDM is structured internally in an Encrypt-then-Sign fashion, using\npartially homomorphic encryption and identity-based signature. It\nsimultaneously facilitates batch verification, data processing, and outcome\nverification, while maintaining identity preservation and data confidentiality.\nWe also instantiate TPDM with a profile matching service and a distribution\nfitting service, and extensively evaluate their performances on Yahoo! Music\nratings dataset and 2009 RECS dataset, respectively. Our analysis and\nevaluation results reveal that TPDM achieves several desirable properties,\nwhile incurring low computation and communication overheads when supporting\nlarge-scale data markets.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2018 08:05:46 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Niu", "Chaoyue", ""], ["Zheng", "Zhenzhe", ""], ["Wu", "Fan", ""], ["Gao", "Xiaofeng", ""], ["Chen", "Guihai", ""]]}, {"id": "1812.03286", "submitter": "Marco Baldi", "authors": "Paolo Santini, Marco Baldi, Franco Chiaraluce", "title": "Cryptanalysis of a One-Time Code-Based Digital Signature Scheme", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a one-time digital signature scheme recently proposed by\nPersichetti and show that a successful key recovery attack can be mounted with\nlimited complexity. The attack we propose exploits a single signature\nintercepted by the attacker, and relies on a statistical analysis performed\nover such a signature, followed by information set decoding. We assess the\nattack complexity and show that a full recovery of the secret key can be\nperformed with a work factor that is far below the claimed security level. The\nefficiency of the attack is motivated by the sparsity of the signature, which\nleads to a significant information leakage about the secret key.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2018 08:34:31 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2019 22:10:32 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Santini", "Paolo", ""], ["Baldi", "Marco", ""], ["Chiaraluce", "Franco", ""]]}, {"id": "1812.03303", "submitter": "Stefanos Pertigkiozoglou", "authors": "Stefanos Pertigkiozoglou, Petros Maragos", "title": "Detecting Adversarial Examples in Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The great success of convolutional neural networks has caused a massive\nspread of the use of such models in a large variety of Computer Vision\napplications. However, these models are vulnerable to certain inputs, the\nadversarial examples, which although are not easily perceived by humans, they\ncan lead a neural network to produce faulty results. This paper focuses on the\ndetection of adversarial examples, which are created for convolutional neural\nnetworks that perform image classification. We propose three methods for\ndetecting possible adversarial examples and after we analyze and compare their\nperformance, we combine their best aspects to develop an even more robust\napproach. The first proposed method is based on the regularization of the\nfeature vector that the neural network produces as output. The second method\ndetects adversarial examples by using histograms, which are created from the\noutputs of the hidden layers of the neural network. These histograms create a\nfeature vector which is used as the input of an SVM classifier, which\nclassifies the original input either as an adversarial or as a real input.\nFinally, for the third method we introduce the concept of the residual image,\nwhich contains information about the parts of the input pattern that are\nignored by the neural network. This method aims at the detection of possible\nadversarial examples, by using the residual image and reinforcing the parts of\nthe input pattern that are ignored by the neural network. Each one of these\nmethods has some novelties and by combining them we can further improve the\ndetection results. For the proposed methods and their combination, we present\nthe results of detecting adversarial examples on the MNIST dataset. The\ncombination of the proposed methods offers some improvements over similar state\nof the art approaches.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2018 11:52:43 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Pertigkiozoglou", "Stefanos", ""], ["Maragos", "Petros", ""]]}, {"id": "1812.03314", "submitter": "Mohammed M. Alani", "authors": "Mohammed M. Alani", "title": "IoT Lotto: Utilizing IoT Devices in Brute-Force Attacks", "comments": "This is a pre-print version of the paper. The original paper is\n  published by the ACM as part of the proceedings of the 2018 The 6th\n  International Conference on Information Technology: IoT and Smart City (ICIT\n  2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The number of IoT devices in use is increasing rapidly and so is the number\nof IoT applications. As in any new technology, the rapid development means\nrapid increase in security threats and attack surfaces. IoT security has proven\nto be challenging throughout the past few years. However, another challenging\ntask is to prevent IoT devices from becoming a tool used by malicious attackers\nto break into other systems. In this paper, we present a conceptual design in\nwhich IoT devices are used as tools in brute-force attacks to break encryption\nkeys of block ciphers. The proposed design shows that with adequate number of\nIoT devices employed in the attack, the attack can succeed in breaking\nlarge-key block ciphers.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2018 12:55:10 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Alani", "Mohammed M.", ""]]}, {"id": "1812.03377", "submitter": "Georgios Bakirtzis", "authors": "Smitha Gautham, Georgios Bakirtzis, Matthew T. Leccadito, Robert H.\n  Klenke, Carl R. Elks", "title": "A Multilevel Cybersecurity and Safety Monitor for Embedded\n  Cyber-Physical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-physical systems (CPS) are composed of various embedded subsystems and\nrequire specialized software, firmware, and hardware to coordinate with the\nrest of the system. These multiple levels of integration expose attack surfaces\nwhich can be susceptible to attack vectors that require novel architectural\nmethods to effectively secure against. We present a multilevel hierarchical\nmonitor architecture cybersecurity approach applied to a flight control system.\nHowever, the principles present in this paper apply to any CPS. Additionally,\nthe real-time nature of these monitors allow for adaptable security, meaning\nthat they mitigate against possible classes of attacks online. This results in\nan appealing bolt-on solution that is independent of different system designs.\nConsequently, employing such monitors leads to strengthened system resiliency\nand dependability of safety-critical CPS.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2018 19:34:00 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Gautham", "Smitha", ""], ["Bakirtzis", "Georgios", ""], ["Leccadito", "Matthew T.", ""], ["Klenke", "Robert H.", ""], ["Elks", "Carl R.", ""]]}, {"id": "1812.03405", "submitter": "Blerta Lindqvist", "authors": "Blerta Lindqvist, Shridatt Sugrim, Rauf Izmailov", "title": "AutoGAN: Robust Classifier Against Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifiers fail to classify correctly input images that have been\npurposefully and imperceptibly perturbed to cause misclassification. This\nsusceptability has been shown to be consistent across classifiers, regardless\nof their type, architecture or parameters. Common defenses against adversarial\nattacks modify the classifer boundary by training on additional adversarial\nexamples created in various ways. In this paper, we introduce AutoGAN, which\ncounters adversarial attacks by enhancing the lower-dimensional manifold\ndefined by the training data and by projecting perturbed data points onto it.\nAutoGAN mitigates the need for knowing the attack type and magnitude as well as\nthe need for having adversarial samples of the attack. Our approach uses a\nGenerative Adversarial Network (GAN) with an autoencoder generator and a\ndiscriminator that also serves as a classifier. We test AutoGAN against\nadversarial samples generated with state-of-the-art Fast Gradient Sign Method\n(FGSM) as well as samples generated with random Gaussian noise, both using the\nMNIST dataset. For different magnitudes of perturbation in training and\ntesting, AutoGAN can surpass the accuracy of FGSM method by up to 25\\% points\non samples perturbed using FGSM. Without an augmented training dataset, AutoGAN\nachieves an accuracy of 89\\% compared to 1\\% achieved by FGSM method on FGSM\ntesting adversarial samples.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2018 23:50:11 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Lindqvist", "Blerta", ""], ["Sugrim", "Shridatt", ""], ["Izmailov", "Rauf", ""]]}, {"id": "1812.03478", "submitter": "Anastasis Keliris", "authors": "Anastasis Keliris and Michail Maniatakos", "title": "ICSREF: A Framework for Automated Reverse Engineering of Industrial\n  Control Systems Binaries", "comments": "To appear in the 26th Annual Network and Distributed System Security\n  Symposium (NDSS), Feb 2019", "journal-ref": "26th Annual Network and Distributed System Security Symposium,\n  NDSS 2019, San Diego, California, USA, February 24-27, 2019. The Internet\n  Society 2019, ISBN 1-891562-55-X", "doi": "10.14722/ndss.2019.23271", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The security of Industrial Control Systems (ICS) has been attracting\nincreased attention over the past years, following the discovery of real\nthreats targeting industrial environments. Despite this attention, automation\nof the reverse engineering process of ICS binaries for programmable logic\ncontrollers remains an open problem, mainly due to the use of proprietary\ncompilers by ICS vendors. Such automation could be a double-edged sword; on the\none hand it could accelerate digital forensic investigations and incident\nresponse actions, while on the other hand it could enable dynamic generation of\nmalicious ICS payloads. In this work, we propose a structured methodology that\nautomates the reverse engineering process for ICS binaries taking into account\ntheir unique domain-specific characteristics. We apply this methodology to\ndevelop the modular Industrial Control Systems Reverse Engineering Framework\n(ICSREF), and instantiate ICSREF modules for reversing binaries compiled with\nCODESYS, a widely used software stack and compiler for PLCs. To evaluate our\nframework we create a database of samples by collecting real PLC binaries from\npublic code repositories, as well as developing binaries in-house. Our results\ndemonstrate that ICSREF can successfully handle diverse PLC binaries from\nvaried industry sectors, irrespective of the programming language used.\nFurthermore, we deploy ICSREF on a commercial smartphone which orchestrates and\nlaunches a completely automated process-aware attack against a chemical process\ntestbed. This example of dynamic payload generation showcases how ICSREF can\nenable sophisticated attacks without any prior knowledge.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2018 12:58:08 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Keliris", "Anastasis", ""], ["Maniatakos", "Michail", ""]]}, {"id": "1812.03492", "submitter": "Mohammadamin Sheikhi", "authors": "Mohammad Amin Sheikhi and S. Mohammad Razavizadeh", "title": "Security Vulnerability of FDD Massive MIMO Systems in Downlink Training\n  Phase", "comments": "Presented in International Symposium on Telecommunication (IST2018)\n  IEEE conference", "journal-ref": "2018 9th International Symposium on Telecommunications (IST),\n  Tehran, Iran, 2018, pp. 492-496", "doi": "10.1109/ISTEL.2018.8661082", "report-no": null, "categories": "cs.CR cs.IT eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider downlink channel training of a frequency division duplex (FDD)\nmassive multiple-input-multiple-output (MIMO) system when a multi-antenna\njammer is present in the network. The jammer intends to degrade mean square\nerror (MSE) of the downlink channel training by designing an attack based on\nsecond-order statistics of its channel. The channels are assumed to be\nspatially correlated. First, a closed-form expression for the channel\nestimation MSE is derived and then the jammer determines the conditions under\nwhich the MSE is maximized. Numerical results demonstrate that the proposed\njamming can severely increase the estimation MSE even if the optimal training\nsignals with a large number of pilot symbols are used by the legitimate system.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2018 14:30:34 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Sheikhi", "Mohammad Amin", ""], ["Razavizadeh", "S. Mohammad", ""]]}, {"id": "1812.03519", "submitter": "Barathi Ganesh HB", "authors": "Vinayakumar R and Barathi Ganesh HB and Prabaharan Poornachandran and\n  Anand Kumar M and Soman KP", "title": "Deep-Net: Deep Neural Network for Cyber Security Use Cases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have witnessed as a powerful approach in this\nyear by solving long-standing Artificial intelligence (AI) supervised and\nunsupervised tasks exists in natural language processing, speech processing,\ncomputer vision and others. In this paper, we attempt to apply DNNs on three\ndifferent cyber security use cases: Android malware classification, incident\ndetection and fraud detection. The data set of each use case contains real\nknown benign and malicious activities samples. The efficient network\narchitecture for DNN is chosen by conducting various trails of experiments for\nnetwork parameters and network structures. The experiments of such chosen\nefficient configurations of DNNs are run up to 1000 epochs with learning rate\nset in the range [0.01-0.5]. Experiments of DNN performed well in comparison to\nthe classical machine learning algorithms in all cases of experiments of cyber\nsecurity use cases. This is due to the fact that DNNs implicitly extract and\nbuild better features, identifies the characteristics of the data that lead to\nbetter accuracy. The best accuracy obtained by DNN and XGBoost on Android\nmalware classification 0.940 and 0.741, incident detection 1.00 and 0.997 fraud\ndetection 0.972 and 0.916 respectively.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2018 16:44:56 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["R", "Vinayakumar", ""], ["HB", "Barathi Ganesh", ""], ["Poornachandran", "Prabaharan", ""], ["M", "Anand Kumar", ""], ["KP", "Soman", ""]]}, {"id": "1812.03598", "submitter": "Ivan Homoliak", "authors": "Ivan Homoliak, Dominik Breitenbacher, Ondrej Hujnak, Pieter Hartel,\n  Alexander Binder, Pawel Szalachowski", "title": "SmartOTPs: An Air-Gapped 2-Factor Authentication for Smart-Contract\n  Wallets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent rise of cryptocurrencies' popularity, the security and\nmanagement of crypto-tokens have become critical. We have witnessed many\nattacks on users and providers, which have resulted in significant financial\nlosses. To remedy these issues, several wallet solutions have been proposed.\nHowever, these solutions often lack either essential security features,\nusability, or do not allow users to customize their spending rules.\n  In this paper, we propose SmartOTPs, a smart-contract wallet framework that\ngives a flexible, usable, and secure way of managing crypto-tokens in a\nself-sovereign fashion. The proposed framework consists of four components\n(i.e., an authenticator, a client, a hardware wallet, and a smart contract),\nand it provides 2-factor authentication (2FA) performed in two stages of\ninteraction with the blockchain. To the best of our knowledge, our framework is\nthe first one that utilizes one-time passwords (OTPs) in the setting of the\npublic blockchain. In SmartOTPs, the OTPs are aggregated by a Merkle tree and\nhash chains whereby for each authentication only a short OTP (e.g., 16B-long)\nis transferred from the authenticator to the client. Such a novel setting\nenables us to make a fully air-gapped authenticator by utilizing small QR codes\nor a few mnemonic words, while additionally offering resilience against quantum\ncryptanalysis. We have made a proof-of-concept based on the Ethereum platform.\nOur cost analysis shows that the average cost of a transfer operation is\ncomparable to existing 2FA solutions using smart contracts with\nmulti-signatures.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 02:28:54 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 06:37:50 GMT"}, {"version": "v3", "created": "Thu, 10 Oct 2019 06:05:33 GMT"}, {"version": "v4", "created": "Thu, 21 May 2020 05:38:51 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Homoliak", "Ivan", ""], ["Breitenbacher", "Dominik", ""], ["Hujnak", "Ondrej", ""], ["Hartel", "Pieter", ""], ["Binder", "Alexander", ""], ["Szalachowski", "Pawel", ""]]}, {"id": "1812.03639", "submitter": "Tram Truong-Huu", "authors": "Akash Raj Narayanadoss, Tram Truong-Huu, Purnima Murali Mohan, Mohan\n  Gurusamy", "title": "Crossfire Attack Detection using Deep Learning in Software Defined ITS\n  Networks", "comments": "This paper has been accepted for publication in the proceeding of\n  IEEE VTC2019-Spring", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in intelligent transport systems (ITS) based on smart\nmobility significantly improves safety and security over roads and highways.\nITS networks are comprised of the Internet-connected vehicles (mobile nodes),\nroadside units (RSU), cellular base stations and conventional core network\nrouters to create a complete data transmission platform that provides real-time\ntraffic information and enable prediction of future traffic conditions.\nHowever, the heterogeneity and complexity of the underlying ITS networks raise\nnew challenges in intrusion prevention of mobile network nodes and detection of\nsecurity attacks due to such highly vulnerable mobile nodes. In this paper, we\nconsider a new type of security attack referred to as crossfire attack, which\ninvolves a large number of compromised nodes that generate low-intensity\ntraffic in a temporally coordinated fashion such that target links or hosts\n(victims) are disconnected from the rest of the network. Detection of such\nattacks is challenging since the attacking traffic flows are indistinguishable\nfrom the legitimate flows. With the support of software-defined networking that\nenables dynamic network monitoring and traffic characteristic extraction, we\ndevelop a machine learning model that can learn the temporal correlation among\ntraffic flows traversing in the ITS network, thus differentiating legitimate\nflows from coordinated attacking flows. We use different deep learning\nalgorithms to train the model and study the performance using Mininet-WiFi\nemulation platform. The results show that our approach achieves a detection\naccuracy of at least 80%.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 05:59:29 GMT"}, {"version": "v2", "created": "Thu, 14 Feb 2019 01:31:38 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Narayanadoss", "Akash Raj", ""], ["Truong-Huu", "Tram", ""], ["Mohan", "Purnima Murali", ""], ["Gurusamy", "Mohan", ""]]}, {"id": "1812.03705", "submitter": "Chaithanya Kumar Mummadi", "authors": "Chaithanya Kumar Mummadi, Thomas Brox, Jan Hendrik Metzen", "title": "Defending Against Universal Perturbations With Shared Adversarial\n  Training", "comments": "ICCV 2019, 8 main pages, 9 appendix pages, 16 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifiers such as deep neural networks have been shown to be vulnerable\nagainst adversarial perturbations on problems with high-dimensional input\nspace. While adversarial training improves the robustness of image classifiers\nagainst such adversarial perturbations, it leaves them sensitive to\nperturbations on a non-negligible fraction of the inputs. In this work, we show\nthat adversarial training is more effective in preventing universal\nperturbations, where the same perturbation needs to fool a classifier on many\ninputs. Moreover, we investigate the trade-off between robustness against\nuniversal perturbations and performance on unperturbed data and propose an\nextension of adversarial training that handles this trade-off more gracefully.\nWe present results for image classification and semantic segmentation to\nshowcase that universal perturbations that fool a model hardened with\nadversarial training become clearly perceptible and show patterns of the target\nscene.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 10:02:45 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 11:58:27 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Mummadi", "Chaithanya Kumar", ""], ["Brox", "Thomas", ""], ["Metzen", "Jan Hendrik", ""]]}, {"id": "1812.03917", "submitter": "Anik Islam", "authors": "Anik Islam, Md. Fazlul Kader, Soo Young Shin", "title": "BSSSQS: A Blockchain Based Smart and Secured Scheme for Question Sharing\n  in the Smart Education System", "comments": "14 pages, 7 figures, Preprint submitted to Journal of Parallel and\n  Distributed Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing education systems are facing a threat of question paper leaking\n(QPL) in the exam which jeopardizes the quality of education. Therefore, it is\nhigh time to think about a more secure and flexible question sharing system\nwhich can prevent QPL issue in the future education system. Blockchain enables\na way of creating and storing transactions, contracts or anything that requires\nprotection against tampering, accessing etc. This paper presents a new scheme\nfor smart education, by utilizing the concept of blockchain, for question\nsharing. A two-phase encryption technique for encrypting question paper (QSP)\nis proposed. In the first phase, QSPs are encrypted using timestamp and in the\nsecond phase, previous encrypted QSPs are encrypted again using a timestamp,\nsalt hash and hashes from previous QSPs. These encrypted QSPs are stored in the\nblockchain along with a smart contract which helps the user to unlock the\nselected QSP. An algorithm is also proposed for selecting a QSP for the exam\nwhich picks a QSP randomly. Moreover, a timestamp based lock is imposed on the\nscheme so that no one can decrypt the QSP before the allowed time. Finally,\nsecurity is analyzed by proving different propositions and the superiority of\nthe proposed scheme over existing schemes is proven through a comparative study\nbased on the different features.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 00:28:30 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Islam", "Anik", ""], ["Kader", "Md. Fazlul", ""], ["Shin", "Soo Young", ""]]}, {"id": "1812.03920", "submitter": "Michael Tschantz", "authors": "Amit Datta, Jianan Lu, Michael Carl Tschantz", "title": "The Effectiveness of Privacy Enhancing Technologies against\n  Fingerprinting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We measure how effective Privacy Enhancing Technologies (PETs) are at\nprotecting users from website fingerprinting. Our measurements use both\nexperimental and observational methods. Experimental methods allow control,\nprecision, and use on new PETs that currently lack a user base. Observational\nmethods enable scale and drawing from the browsers currently in real-world use.\nBy applying experimentally created models of a PET's behavior to an\nobservational data set, our novel hybrid method offers the best of both worlds.\nWe find the Tor Browser Bundle to be the most effective PET amongst the set we\ntested. We find that some PETs have inconsistent behaviors, which can do more\nharm than good.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 17:01:48 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Datta", "Amit", ""], ["Lu", "Jianan", ""], ["Tschantz", "Michael Carl", ""]]}, {"id": "1812.03939", "submitter": "Ebrahim Ansari", "authors": "Kousha Nakhaei, Ebrahim Ansari, Fateme Ansari", "title": "JSSignature: Eliminating Third-Party-Hosted JavaScript Infection Threats\n  Using Digital Signatures", "comments": "18 pages, 2 figures, Submitted to CiDaS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, third-party JavaScript resources are indispensable part of the web\nplatform. More than 88% of world's top websites include at least one JavaScript\nresource from a remote host. However, there is a great security risk behind\nusing a third-party JavaScript resource, if an attacker can infect one of these\nremote JavaScript resources all websites those have included the script would\nbe at risk. In this paper, we present JSSignature, an entirely at the\nclient-side pure JavaScript framework in order to validate third-party\nJavaScript resources using digital signature. Therefore, all included\nJavaScript resources are checked against the integrity, authentication and\nnon-repudiation risks before the execution. In contrary to existing methods,\nJSSignature protects web pages regardless of third-party resource infection\nnature while it does not set any restrictions on trusted JavaScript providers.\nThis approach has an acceptable one-time performance overhead and is an easily\ndeployable add-in. We have validated the proposed solution by applying tests on\nan implemented version\\footnote{The source-code, resources and the working demo\nare available at JSSignature website.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 17:45:24 GMT"}, {"version": "v2", "created": "Fri, 8 Feb 2019 16:50:19 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Nakhaei", "Kousha", ""], ["Ansari", "Ebrahim", ""], ["Ansari", "Fateme", ""]]}, {"id": "1812.03943", "submitter": "Marzieh Gheisari", "authors": "Marzieh Gheisari, Teddy Furon, Laurent Amsaleg, Behrooz Razeghi, Slava\n  Voloshynovskiy", "title": "Aggregation and Embedding for Group Membership Verification", "comments": "accepted at ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a group membership verification protocol preventing the\ncurious but honest server from reconstructing the enrolled signatures and\ninferring the identity of querying clients. The protocol quantizes the\nsignatures into discrete embeddings, making reconstruction difficult. It also\naggregates multiple embeddings into representative values, impeding\nidentification. Theoretical and experimental results show the trade-off between\nthe security and the error rates.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 17:54:14 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 16:33:31 GMT"}, {"version": "v3", "created": "Tue, 23 Apr 2019 17:24:37 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Gheisari", "Marzieh", ""], ["Furon", "Teddy", ""], ["Amsaleg", "Laurent", ""], ["Razeghi", "Behrooz", ""], ["Voloshynovskiy", "Slava", ""]]}, {"id": "1812.03966", "submitter": "Abdullah Al Farooq", "authors": "Abdullah Al Farooq, Ehab Al-Shaer, Thomas Moyer, Krishna Kant", "title": "IoTC2: A Formal Method Approach for Detecting Conflicts in Large Scale\n  IoT Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) has become a common paradigm for different domains\nsuch as health care, transportation infrastructure, smart home, smart shopping,\nand e-commerce. With its interoperable functionality, it is now possible to\nconnect all domains of IoT together for providing competent services to the\nusers. Because numerous IoT devices can connect and communicate at the same\ntime, there can be events that trigger conflicting actions to an actuator or an\nenvironmental feature. However, there have been very few research efforts made\nto detect conflicting situation in IoT system using formal method. This paper\nprovides a formal method approach, IoT Confict Checker (IoTC2), to ensure\nsafety of controller and actuators' behavior with respect to conflicts. Any\npolicy violation results in detection of the conflicts. We defined the safety\npolicies for controller, actions, and triggering events and implemented the\nthose with Prolog to prove the logical completeness and soundness. In addition\nto that, we have implemented the detection policies in Matlab Simulink\nEnvironment with its built-in Model Verification blocks. We created smart home\nenvironment in Simulink and showed how the conflicts affect actions and\ncorresponding features. We have also experimented the scalability, efficiency,\nand accuracy of our method in the simulated environment.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 18:31:11 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Farooq", "Abdullah Al", ""], ["Al-Shaer", "Ehab", ""], ["Moyer", "Thomas", ""], ["Kant", "Krishna", ""]]}, {"id": "1812.04054", "submitter": "Matthew Collison", "authors": "Saulius Venskutonis, Feng Hao, and Matthew Collison", "title": "On legitimate mining of cryptocurrency in the browser - a feasibility\n  study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptocurrency mining in the browser has the potential to provide a new\npay-as-you-go monetisation mechanism for consuming digital media over the Web.\nHowever, browser mining has recently received strong criticism due to\nillegitimate use of mining scripts in several popular websites (a practice\ncalled cryptojacking). Here we provide the first feasibility study of browser\nmining as a legitimate means of monetisation in terms of revenue, user consent\nand user experience within a specially built website. Our results compare\nbrowser mining to display advertisement and indicate browser mining provides a\npreferable user experience to advertising when the hash rate is\nuser-adjustable. Furthermore, over 60% of participants would select browser\nmining over advertisement if they were invested in the ecosystem by obtaining\nhalf of the mined cryptocurrency. Our estimations show that browser mining\ncurrently generates revenue at a rate 46 times less than advertisement, however\nwe would expect that gap to decrease as we observed a significant drop in\nmining difficulty after our tested cryptocurrency implemented ASIC-resistant\nmining measures. Overall, based on our results we find browser mining to be a\nlegitimate alternative to display advertisement and conclude by discussing its\ncurrent limitations and potential applications.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 19:46:13 GMT"}, {"version": "v2", "created": "Fri, 4 Jan 2019 14:31:45 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Venskutonis", "Saulius", ""], ["Hao", "Feng", ""], ["Collison", "Matthew", ""]]}, {"id": "1812.04064", "submitter": "Shen Wang", "authors": "Shen Wang, Zhengzhang Chen, Ding Li, Lu-An Tang, Jingchao Ni, Zhichun\n  Li, Junghwan Rhee, Haifeng Chen, Philip S. Yu", "title": "Attentional Heterogeneous Graph Neural Network: Application to Program\n  Reidentification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program or process is an integral part of almost every IT/OT system. Can we\ntrust the identity/ID (e.g., executable name) of the program? To avoid\ndetection, malware may disguise itself using the ID of a legitimate program,\nand a system tool (e.g., PowerShell) used by the attackers may have the fake ID\nof another common software, which is less sensitive. However, existing\nintrusion detection techniques often overlook this critical program\nreidentification problem (i.e., checking the program's identity). In this\npaper, we propose an attentional heterogeneous graph neural network model\n(DeepHGNN) to verify the program's identity based on its system behaviors. The\nkey idea is to leverage the representation learning of the heterogeneous\nprogram behavior graph to guide the reidentification process. We formulate the\nprogram reidentification as a graph classification problem and develop an\neffective attentional heterogeneous graph embedding algorithm to solve it.\nExtensive experiments --- using real-world enterprise monitoring data and real\nattacks --- demonstrate the effectiveness of DeepHGNN across multiple popular\nmetrics and the robustness to the normal dynamic changes like program version\nupgrades.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 20:08:47 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 02:48:11 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Wang", "Shen", ""], ["Chen", "Zhengzhang", ""], ["Li", "Ding", ""], ["Tang", "Lu-An", ""], ["Ni", "Jingchao", ""], ["Li", "Zhichun", ""], ["Rhee", "Junghwan", ""], ["Chen", "Haifeng", ""], ["Yu", "Philip S.", ""]]}, {"id": "1812.04142", "submitter": "Netanel Raviv", "authors": "Netanel Raviv and David A. Karpuk", "title": "Private Polynomial Computation from Lagrange Encoding", "comments": "To appear in Transactions on Information Forensics and Security", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Private computation is a generalization of private information retrieval, in\nwhich a user is able to compute a function on a distributed dataset without\nrevealing the identity of that function to the servers. In this paper it is\nshown that Lagrange encoding, a powerful technique for encoding Reed-Solomon\ncodes, enables private computation in many cases of interest. In particular, we\npresent a scheme that enables private computation of polynomials of any degree\non Lagrange encoded data, while being robust to Byzantine and straggling\nservers, and to servers colluding to attempt to deduce the identities of the\nfunctions to be evaluated. Moreover, incorporating ideas from the well-known\nShamir secret sharing scheme allows the data itself to be concealed from the\nservers as well. Our results extend private computation to high degree\npolynomials and to data-privacy, and reveal a tight connection between private\ncomputation and coded computation.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 23:10:18 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 19:59:50 GMT"}, {"version": "v3", "created": "Wed, 26 Jun 2019 01:07:50 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Raviv", "Netanel", ""], ["Karpuk", "David A.", ""]]}, {"id": "1812.04168", "submitter": "Farhad Farokhi", "authors": "Carlos Murguia, Farhad Farokhi, Iman Shames", "title": "Secure and Private Implementation of Dynamic Controllers Using\n  Semi-Homomorphic Encryption", "comments": "Improved numerical example", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CR cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a secure and private implementation of linear\ntime-invariant dynamic controllers using Paillier's encryption, a\nsemi-homomorphic encryption method. To avoid overflow or underflow within the\nencryption domain, the state of the controller is reset periodically. A control\ndesign approach is presented to ensure stability and optimize performance of\nthe closed-loop system with encrypted controller.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 01:02:00 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 01:59:50 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Murguia", "Carlos", ""], ["Farokhi", "Farhad", ""], ["Shames", "Iman", ""]]}, {"id": "1812.04191", "submitter": "Lannan Luo", "authors": "Qiang Zeng, Golam Kayas, Emil Mohammed, Lannan Luo, Xiaojiang Du and\n  Junghwan Rhee", "title": "Code-less Patching for Heap Vulnerabilities Using Targeted Calling\n  Context Encoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploitation of heap vulnerabilities has been on the rise, leading to many\ndevastating attacks. Conventional heap patch generation is a lengthy procedure,\nrequiring intensive manual efforts. Worse, fresh patches tend to harm system\ndependability, hence deterring users from deploying them. We propose a heap\npatching system that simultaneously has the following prominent advantages: (1)\ngenerating patches without manual efforts; (2) installing patches without\naltering the code (so called code-less patching); (3) handling various heap\nvulnerability types; (4) imposing a very low overhead; and (5) no dependency on\nspecific heap allocators. As a separate contribution, we propose targeted\ncalling context encoding, which is a suite of algorithms for optimizing calling\ncontext encoding, an important technique with applications in many areas. The\nsystem properly combines heavyweight offline attack analysis with lightweight\nonline defense generation, and provides a new countermeasure against heap\nattacks. The evaluation shows that the system is effective and efficient.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 02:30:27 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Zeng", "Qiang", ""], ["Kayas", "Golam", ""], ["Mohammed", "Emil", ""], ["Luo", "Lannan", ""], ["Du", "Xiaojiang", ""], ["Rhee", "Junghwan", ""]]}, {"id": "1812.04216", "submitter": "Inayat Ali", "authors": "Inayat Ali, Sonia Sabir, Eraj Khan", "title": "Privacy-preserving data aggregation in resource-constrained sensor nodes\n  in Internet of Things: A review", "comments": "9 pages", "journal-ref": "Future Computing and Informatics Journal (2017)", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Privacy problems are lethal and getting more attention than any other issue\nwith the notion of the Internet of Things (IoT). Since IoT has many application\nareas including smart home, smart grids, smart healthcare system, smart and\nintelligent transportation and many more. Most of these applications are fueled\nby the resource-constrained sensor network, such as Smart healthcare system is\npowered by Wireless Body Area Network (WBAN) and Smart home and weather\nmonitoring systems are fueled by Wireless Sensor Networks (WSN). In the\nmentioned application areas sensor node life is a very important aspect of\nthese technologies as it explicitly effects the network life and performance.\nData aggregation techniques are used to increase sensor node life by decreasing\ncommunication overhead. However, when the data is aggregated at intermediate\nnodes to reduce communication overhead, data privacy problems becomes more\nvulnerable. Different Privacy-Preserving Data Aggregation (PPDA) techniques\nhave been proposed to ensure data privacy during data aggregation in\nresource-constrained sensor nodes. We provide a review and comparative analysis\nof the state of the art PPDA techniques in this paper. The comparative analysis\nis based on Computation Cost, Communication overhead, Privacy Level, resistance\nagainst malicious aggregator, sensor node life and energy consumption by the\nsensor node. We have studied the most recent techniques and provide in-depth\nanalysis of the minute steps involved in these techniques. To the best of our\nknowledge, this survey is the most recent and comprehensive study of PPDA\ntechniques.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 04:35:02 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Ali", "Inayat", ""], ["Sabir", "Sonia", ""], ["Khan", "Eraj", ""]]}, {"id": "1812.04234", "submitter": "Tam Nguyen", "authors": "Tam n. Nguyen, Lydia Sbityakov, Samantha Scoggins", "title": "Intelligence-based Cybersecurity Awareness Training- an Exploratory\n  Project", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cybersecurity training should be adaptable to evolving the cyber threat\nlandscape, cost effective and integrated well with other enterprise management\ncomponents. Unfortunately, very few cybersecurity training platforms can\nsatisfy such requirements. This paper proposes a new and novel model for\nconducting cybersecurity training with three main objectives: (i) training\nshould be initiated by emerging relevant threats and delivered first to the\nmost vulnerable members (ii) the process has to be agile (iii) training results\nmust be able to provide actionable intelligence. For the first time, this paper\nestablishes a type system (ontology and associated relationships) that links\nthe domain of cybersecurity awareness training with that of cyber threat\nintelligence. Powered by IBM Watson Knowledge Studio platform, the proposed\nmethod was found to be practical and scalable. Main contributions such as\nexports of the type system, the manually annotated corpus of 100 threat reports\nand 127 cybersecurity assessment results, the dictionaries for pre-annotation,\netc were made publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 06:48:59 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Nguyen", "Tam n.", ""], ["Sbityakov", "Lydia", ""], ["Scoggins", "Samantha", ""]]}, {"id": "1812.04293", "submitter": "Hien Truong", "authors": "Kumar Sharad, Giorgia Azzurra Marson, Hien Thi Thu Truong, Ghassan\n  Karame", "title": "On the Security of Randomized Defenses Against Adversarial Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep Learning has been shown to be particularly vulnerable to adversarial\nsamples. To combat adversarial strategies, numerous defensive techniques have\nbeen proposed. Among these, a promising approach is to use randomness in order\nto make the classification process unpredictable and presumably harder for the\nadversary to control. In this paper, we study the effectiveness of randomized\ndefenses against adversarial samples. To this end, we categorize existing\nstate-of-the-art adversarial strategies into three attacker models of\nincreasing strength, namely blackbox, graybox, and whitebox (a.k.a.~adaptive)\nattackers. We also devise a lightweight randomization strategy for image\nclassification based on feature squeezing, that consists of pre-processing the\nclassifier input by embedding randomness within each feature, before applying\nfeature squeezing. We evaluate the proposed defense and compare it to other\nrandomized techniques in the literature via thorough experiments. Our results\nindeed show that careful integration of randomness can be effective against\nboth graybox and blackbox attacks without significantly degrading the accuracy\nof the underlying classifier. However, our experimental results offer strong\nevidence that in the present form such randomization techniques cannot deter a\nwhitebox adversary that has access to all classifier parameters and has full\nknowledge of the defense. Our work thoroughly and empirically analyzes the\nimpact of randomization techniques against all classes of adversarial\nstrategies.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 09:34:29 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 13:14:29 GMT"}, {"version": "v3", "created": "Wed, 11 Mar 2020 15:49:38 GMT"}, {"version": "v4", "created": "Mon, 16 Mar 2020 22:03:45 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Sharad", "Kumar", ""], ["Marson", "Giorgia Azzurra", ""], ["Truong", "Hien Thi Thu", ""], ["Karame", "Ghassan", ""]]}, {"id": "1812.04659", "submitter": "Samuel Cris Ayo", "authors": "Samuel Cris Ayo, Bonaventure Ngala, Olasunkanmi Amzat, Robin Lal\n  Khoshi, Samarappulige Isuru Madusanka", "title": "Information Security Risks Assessment: A Case Study", "comments": "13 Pages, 2 Figures, 4 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Owing to recorded incidents of Information technology inclined organisations\nfailing to respond effectively to threat incidents, this project outlines the\nbenefits of conducting a comprehensive risk assessment which would aid\nproficiency in responding to potential threats. The ultimate goal is primarily\nto identify, quantify and control the key threats that are detrimental to\nachieving business objectives. This project carries out a detailed risk\nassessment for a case study organisation. It includes a comprehensive\nliterature review analysing several professional views on pressing issues in\nInformation security. In the risk register, five prominent assets were\nidentified in respect to their owners. The work is followed by a qualitative\nanalysis methodology to determine the magnitude of the potential threats and\nvulnerabilities. Collating these parameters enabled the valuation of individual\nrisk per asset, per threat and vulnerability. Evaluating a risk appetite aided\nin prioritising and determining acceptable risks. From the analysis, it was\ndeduced that human being posed the greatest Information security risk through\nintentional/ unintentional human error. In conclusion, effective control\ntechniques based on defence in-depth were devised to mitigate the impact of the\nidentified risks from risk register.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 19:27:14 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Ayo", "Samuel Cris", ""], ["Ngala", "Bonaventure", ""], ["Amzat", "Olasunkanmi", ""], ["Khoshi", "Robin Lal", ""], ["Madusanka", "Samarappulige Isuru", ""]]}, {"id": "1812.04697", "submitter": "Milad Salem", "authors": "Milad Salem, Shayan Taheri, Jiann Shiun Yuan", "title": "Anomaly Generation using Generative Adversarial Networks in Host Based\n  Intrusion Detection", "comments": "Accepted and presented at IEEE Annual Ubiquitous Computing,\n  Electronics, and Mobile Communications Conference (IEEE UEMCON) on 8th-10th\n  November 2018", "journal-ref": null, "doi": "10.1109/UEMCON.2018.8796769", "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks have been able to generate striking results\nin various domains. This generation capability can be general while the\nnetworks gain deep understanding regarding the data distribution. In many\ndomains, this data distribution consists of anomalies and normal data, with the\nanomalies commonly occurring relatively less, creating datasets that are\nimbalanced. The capabilities that generative adversarial networks offer can be\nleveraged to examine these anomalies and help alleviate the challenge that\nimbalanced datasets propose via creating synthetic anomalies. This anomaly\ngeneration can be specifically beneficial in domains that have costly data\ncreation processes as well as inherently imbalanced datasets. One of the\ndomains that fits this description is the host-based intrusion detection\ndomain. In this work, ADFA-LD dataset is chosen as the dataset of interest\ncontaining system calls of small foot-print next generation attacks. The data\nis first converted into images, and then a Cycle-GAN is used to create images\nof anomalous data from images of normal data. The generated data is combined\nwith the original dataset and is used to train a model to detect anomalies. By\ndoing so, it is shown that the classification results are improved, with the\nAUC rising from 0.55 to 0.71, and the anomaly detection rate rising from 17.07%\nto 80.49%. The results are also compared to SMOTE, showing the potential\npresented by generative adversarial networks in anomaly generation.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 21:21:09 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Salem", "Milad", ""], ["Taheri", "Shayan", ""], ["Yuan", "Jiann Shiun", ""]]}, {"id": "1812.04715", "submitter": "Vahid Pourahmadi Dr.", "authors": "Amirhossein Yazdani Abyaneh, Ali Hosein Gharari Foumani, Vahid\n  Pourahmadi", "title": "Deep Neural Networks Meet CSI-Based Authentication", "comments": "7 pages, 14 Figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The first step of a secure communication is authenticating legible users and\ndetecting the malicious ones. In the last recent years, some promising schemes\nproposed using wireless medium network's features, in particular, channel state\ninformation (CSI) as a means for authentication. These schemes mainly compare\nuser's previous CSI with the new received CSI to determine if the user is in\nfact what it is claiming to be. Despite high accuracy, these approaches lack\nthe stability in authentication when the users rotate in their positions. This\nis due to a significant change in CSI when a user rotates which mislead the\nauthenticator when it compares the new CSI with the previous ones. Our approach\npresents a way of extracting features from raw CSI measurements which are\nstable towards rotation. We extract these features by the means of a deep\nneural network. We also present a scenario in which users can be {efficiently}\nauthenticated while they are at certain locations in an environment (even if\nthey rotate); and, they will be rejected if they change their location. Also,\nexperimental results are presented to show the performance of the proposed\nscheme.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 16:23:55 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Abyaneh", "Amirhossein Yazdani", ""], ["Foumani", "Ali Hosein Gharari", ""], ["Pourahmadi", "Vahid", ""]]}, {"id": "1812.04738", "submitter": "Takehisa Iwakoshi", "authors": "Takehisa Iwakoshi", "title": "Guessing probability under unlimited known-plaintext attack on secret\n  keys for Y00 quantum stream cipher by quantum multiple hypotheses testing", "comments": "Not exactly same as the submitted version, rather close to before the\n  revision. The open-access published version is on the publisher's site.\n  https://doi.org/10.1117/1.OE.57.12.126103", "journal-ref": "Optical Engineering 57(12), 126103 (10 December 2018)", "doi": "10.1117/1.OE.57.12.126103", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although quantum key distribution is regarded as promising secure\ncommunication, security of Y00 protocol proposed by Yuen in 2000 for the\naffinity to conventional optical communication is not well-understood yet; its\nsecurity has been evaluated only by the eavesdropper's error probabilities of\ndetecting individual signals or masking size, the number of hidden signal\nlevels under quantum and classical noise. Our study is the first challenge of\nevaluating the guessing probabilities on shared secret keys for pseudorandom\nnumber generators in a simplified Y00 communication system based on quantum\nmultiple hypotheses testing theory. The result is that even unlimitedly long\nknown-plaintext attack only lets the eavesdropper guess the shared secret keys\nof limited lengths with a probability strictly < 1. This study will give some\ninsights for detailed future works on this quantum communication protocol.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 23:07:20 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Iwakoshi", "Takehisa", ""]]}, {"id": "1812.04829", "submitter": "Asaf Shabtai", "authors": "Nir Sivan, Ron Bitton, Asaf Shabtai", "title": "Analysis of Location Data Leakage in the Internet Traffic of\n  Android-based Mobile Devices", "comments": "11 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years we have witnessed a shift towards personalized, context-based\napplications and services for mobile device users. A key component of many of\nthese services is the ability to infer the current location and predict the\nfuture location of users based on location sensors embedded in the devices.\nSuch knowledge enables service providers to present relevant and timely offers\nto their users and better manage traffic congestion control, thus increasing\ncustomer satisfaction and engagement. However, such services suffer from\nlocation data leakage which has become one of today's most concerning privacy\nissues for smartphone users. In this paper we focus specifically on location\ndata that is exposed by Android applications via Internet network traffic in\nplaintext (i.e., without encryption) without the user's awareness. We present\nan empirical evaluation, involving the network traffic of real mobile device\nusers, aimed at: (1) measuring the extent of location data leakage in the\nInternet traffic of Android-based smartphone devices; and (2) understanding the\nvalue of this data by inferring users' points of interests (POIs). This was\nachieved by analyzing the Internet traffic recorded from the smartphones of a\ngroup of 71 participants for an average period of 37 days. We also propose a\nprocedure for mining and filtering location data from raw network traffic and\nutilize geolocation clustering methods to infer users' POIs. The key findings\nof this research center on the extent of this phenomenon in terms of both\nubiquity and severity; we found that over 85\\% of devices of users are leaking\nlocation data, and the exposure rate of users' POIs, derived from the\nrelatively sparse leakage indicators, is around 61%.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 07:09:33 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Sivan", "Nir", ""], ["Bitton", "Ron", ""], ["Shabtai", "Asaf", ""]]}, {"id": "1812.04852", "submitter": "Martin Sablotny", "authors": "Martin Sablotny, Bj{\\o}rn Sand Jensen and Chris W. Johnson", "title": "Recurrent Neural Networks for Fuzz Testing Web Browsers", "comments": "Preprint of the paper presented at ICISC 2018 in Korea", "journal-ref": null, "doi": "10.1007/978-3-030-12146-4_22", "report-no": null, "categories": "cs.CR cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generation-based fuzzing is a software testing approach which is able to\ndiscover different types of bugs and vulnerabilities in software. It is,\nhowever, known to be very time consuming to design and fine tune classical\nfuzzers to achieve acceptable coverage, even for small-scale software systems.\nTo address this issue, we investigate a machine learning-based approach to fuzz\ntesting in which we outline a family of test-case generators based on Recurrent\nNeural Networks (RNNs) and train those on readily available datasets with a\nminimum of human fine tuning. The proposed generators do, in contrast to\nprevious work, not rely on heuristic sampling strategies but principled\nsampling from the predictive distributions. We provide a detailed analysis to\ndemonstrate the characteristics and efficacy of the proposed generators in a\nchallenging web browser testing scenario. The empirical results show that the\nRNN-based generators are able to provide better coverage than a mutation based\nmethod and are able to discover paths not discovered by a classical fuzzer. Our\nresults supplement findings in other domains suggesting that generation based\nfuzzing with RNNs is a viable route to better software quality conditioned on\nthe use of a suitable model selection/analysis procedure.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 08:54:29 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Sablotny", "Martin", ""], ["Jensen", "Bj\u00f8rn Sand", ""], ["Johnson", "Chris W.", ""]]}, {"id": "1812.04892", "submitter": "Julian Renner", "authors": "Julian Renner, Sven Puchinger, Antonia Wachter-Zeh", "title": "LIGA: A Cryptosystem Based on the Hardness of Rank-Metric List and\n  Interleaved Decoding", "comments": "Extended version of arXiv:1801.03688", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the new rank-metric code-based cryptosystem LIGA which is based on\nthe hardness of list decoding and interleaved decoding of Gabidulin codes. LIGA\nis an improved variant of the Faure-Loidreau (FL) system, which was broken in a\nstructural attack by Gaborit, Otmani, and Tal\\'e Kalachi (GOT, 2018). We keep\nthe FL encryption and decryption algorithms, but modify the insecure key\ngeneration algorithm. Our crucial observation is that the GOT attack is\nequivalent to decoding an interleaved Gabidulin code. The new key generation\nalgorithm constructs public keys for which all polynomial-time interleaved\ndecoders fail---hence LIGA resists the GOT attack. We also prove that the\npublic-key encryption version of LIGA is IND-CPA secure in the standard model\nand the KEM version is IND-CCA2 secure in the random oracle model, both under\nhardness assumptions of formally defined problems related to list decoding and\ninterleaved decoding of Gabidulin codes. We propose and analyze various\nexponential-time attacks on these problems, calculate their work factors, and\ncompare the resulting parameters to NIST proposals. The strengths of LIGA are\nshort ciphertext sizes and (relatively) small key sizes. Further, LIGA\nguarantees correct decryption and has no decryption failure rate. It is not\nbased on hiding the structure of a code. Since there are efficient and\nconstant-time algorithms for encoding and decoding Gabidulin codes, timing\nattacks on the encryption and decryption algorithms can be easily prevented.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 11:03:09 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 08:30:42 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Renner", "Julian", ""], ["Puchinger", "Sven", ""], ["Wachter-Zeh", "Antonia", ""]]}, {"id": "1812.04959", "submitter": "Nicholas Mainardi", "authors": "Alessandro Barenghi, Nicholas Mainardi, Gerardo Pelosi", "title": "Systematic Parsing of X.509: Eradicating Security Issues with a Parse\n  Tree", "comments": null, "journal-ref": "Journal of Computer Security, Volume 26, Issue 6, 30th October\n  2018", "doi": "10.3233/JCS-171110", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  X.509 certificate parsing and validation is a critical task which has shown\nconsistent lack of effectiveness, with practical attacks being reported with a\nsteady rate during the last 10 years. In this work we analyze the X.509\nstandard and provide a grammar description of it amenable to the automated\ngeneration of a parser with strong termination guarantees, providing\nunambiguous input parsing. We report the results of analyzing a 11M X.509\ncertificate dump of the HTTPS servers running on the entire IPv4 space, showing\nthat 21.5% of the certificates in use are syntactically invalid. We compare the\nresults of our parsing against 7 widely used TLS libraries showing that 631k to\n1,156k syntactically incorrect certificates are deemed valid by them\n(5.7%--10.5%), including instances with security critical mis-parsings. We\nprove the criticality of such mis-parsing exploiting one of the syntactic flaws\nfound in existing certificates to perform an impersonation attack.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 14:16:02 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Barenghi", "Alessandro", ""], ["Mainardi", "Nicholas", ""], ["Pelosi", "Gerardo", ""]]}, {"id": "1812.04967", "submitter": "Wenjun Xiong", "authors": "Wenjun Xiong and Robert Lagerstr\\\"om", "title": "Security and Privacy Issues for Connected Vehicles", "comments": "There is a crucial mistake with the code, and the model is far from\n  completion. With the agreement of all of the author, we decide to withdraw\n  this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern vehicles contain more than a hundred Electronic Control Units (ECUs)\nthat communicate over different in-vehicle networks, and they are often\nconnected to the Internet, which makes them vulnerable to various\ncyber-attacks. Besides, data collected by the connected vehicles is directly\nconnected to the vehicular network. Thus, big vehicular data are collected,\nwhich are valuable and generate insights into driver behavior. Previously, a\nprobabilistic modeling and simulation language named vehicleLang is presented\nto analyze the security of connected vehicles. However, the privacy issues of\nvehicular data have not been addressed. To fill in the gap, this work present a\nprivacy specification for vehicles based on vehicleLang, which uses the Meta\nAttack Language (MAL) to assess the security of connected vehicles in a formal\nway, with a special focus on the privacy aspect. To evaluate this work, test\ncases are also presented.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 14:27:17 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2018 18:59:19 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Xiong", "Wenjun", ""], ["Lagerstr\u00f6m", "Robert", ""]]}, {"id": "1812.04975", "submitter": "Mohammad Rahmani Fadiheh", "authors": "Mohammad Rahmani Fadiheh, Dominik Stoffel, Clark Barrett, Subhasish\n  Mitra, Wolfgang Kunz", "title": "Processor Hardware Security Vulnerabilities and their Detection by\n  Unique Program Execution Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent discovery of security attacks in advanced processors, known as Spectre\nand Meltdown, has resulted in high public alertness about security of hardware.\nThe root cause of these attacks is information leakage across \"covert channels\"\nthat reveal secret data without any explicit information flow between the\nsecret and the attacker. Many sources believe that such covert channels are\nintrinsic to highly advanced processor architectures based on speculation and\nout-of-order execution, suggesting that such security risks can be avoided by\nstaying away from high-end processors. This paper, however, shows that the\nproblem is of wider scope: we present new classes of covert channel attacks\nwhich are possible in average-complexity processors with in-order pipelining,\nas they are mainstream in applications ranging from Internet-of-Things to\nAutonomous Systems.\n  We present a new approach as a foundation for remedy against covert channels:\nwhile all previous attacks were found by clever thinking of human attackers,\nthis paper presents an automated and exhaustive method called \"Unique Program\nExecution Checking\" which detects and locates vulnerabilities to covert\nchannels systematically, including those to covert channels unknown so far.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 17:29:11 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Fadiheh", "Mohammad Rahmani", ""], ["Stoffel", "Dominik", ""], ["Barrett", "Clark", ""], ["Mitra", "Subhasish", ""], ["Kunz", "Wolfgang", ""]]}, {"id": "1812.05008", "submitter": "Jon-Lark Kim", "authors": "Jon-Lark Kim, Young-Sik Kim, Lucky Galvez, Myeong Jae Kim, Nari Lee", "title": "McNie: A code-based public-key cryptosystem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we suggest a code-based public key encryption scheme, called\nMcNie. McNie is a hybrid version of the McEliece and Niederreiter cryptosystems\nand its security is reduced to the hard problem of syndrome decoding. The\npublic key involves a random generator matrix which is also used to mask the\ncode used in the secret key. This makes the system safer against known\nstructural attacks. In particular, we apply rank-metric codes to McNie.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 16:27:38 GMT"}, {"version": "v2", "created": "Sun, 27 Jan 2019 04:33:33 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Kim", "Jon-Lark", ""], ["Kim", "Young-Sik", ""], ["Galvez", "Lucky", ""], ["Kim", "Myeong Jae", ""], ["Lee", "Nari", ""]]}, {"id": "1812.05013", "submitter": "Nikhil Vyas", "authors": "Mitali Bafna, Jack Murtagh and Nikhil Vyas", "title": "Thwarting Adversarial Examples: An $L_0$-RobustSparse Fourier Transform", "comments": "Accepted at 32nd Conference on Neural Information Processing Systems\n  (NeurIPS 2018), Montr\\'eal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new algorithm for approximating the Discrete Fourier transform of\nan approximately sparse signal that has been corrupted by worst-case $L_0$\nnoise, namely a bounded number of coordinates of the signal have been corrupted\narbitrarily. Our techniques generalize to a wide range of linear\ntransformations that are used in data analysis such as the Discrete Cosine and\nSine transforms, the Hadamard transform, and their high-dimensional analogs. We\nuse our algorithm to successfully defend against well known $L_0$ adversaries\nin the setting of image classification. We give experimental results on the\nJacobian-based Saliency Map Attack (JSMA) and the Carlini Wagner (CW) $L_0$\nattack on the MNIST and Fashion-MNIST datasets as well as the Adversarial Patch\non the ImageNet dataset.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 16:36:14 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Bafna", "Mitali", ""], ["Murtagh", "Jack", ""], ["Vyas", "Nikhil", ""]]}, {"id": "1812.05015", "submitter": "Jon-Lark Kim", "authors": "Jon-Lark Kim, Young-Sik Kim, Lucky Galvez, Myeong Jae Kim", "title": "McNie2-Gabidulin: An improvement of McNie public key encryption using\n  Gabidulin code", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  McNie is a code-based public key encryption scheme submitted as a candidate\nto the NIST Post-Quantum Cryptography standardization. In this paper, we\npresent McNie2-Gabidulin, an improvement of McNie. By using Gabidulin code, we\neliminate the decoding failure, which is one of the limitations of the McNie\npublic key cryptosystem that uses LRPC codes. We prove that this new\ncryptosystem is IND-CPA secure. Suggested parameters are also given which\nprovides low key sizes compared to other known code based cryptosystems with\nzero decryption failure probability.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 16:37:22 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Kim", "Jon-Lark", ""], ["Kim", "Young-Sik", ""], ["Galvez", "Lucky", ""], ["Kim", "Myeong Jae", ""]]}, {"id": "1812.05032", "submitter": "Ke Liang", "authors": "Ke Liang", "title": "Fission: A Provably Fast, Scalable, and Secure Permissionless Blockchain", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Fission, a new permissionless blockchain that achieves scalability\nin both terms of system throughput and transaction confirmation time, while at\nthe same time, retaining blockchain's core values of equality and\ndecentralization. Fission overcomes the system throughput bottleneck by\nemploying a novel Eager-Lazy pipeling model that achieves very high system\nthroughputs via block pipelining, an adaptive partitioning mechanism that\nauto-scales to transaction volumes, and a provably secure energy-efficient\nconsensus protocol to ensure security and robustness. Fission applies a hybrid\nnetwork which consists of a relay network, and a peer-to-peer network. The goal\nof the relay network is to minimize the transaction confirmation time by\nminimizing the information propagation latency. To optimize the performance on\nthe relay network in the presence of churn, dynamic network topologies, and\nnetwork heterogeneity, we propose an ultra-fast game-theoretic relay selection\nalgorithm that achieves near-optimal performance in a fully distributed manner.\nFission's peer-to-peer network complements the relay network and provides a\nvery high data availability via enabling users to contribute their storage and\nbandwidth for information dissemination (with incentive). We propose a\ndistributed online data retrieval strategy that optimally offloads the relay\nnetwork without degrading the system performance. By re-innovating all the core\nelements of the blockchain technology - computation, networking, and storage -\nin a holistic manner, Fission aims to achieve the best balance among\nscalability, security and decentralization.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 17:08:37 GMT"}, {"version": "v2", "created": "Fri, 14 Dec 2018 06:29:06 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Liang", "Ke", ""]]}, {"id": "1812.05271", "submitter": "Tianyu Du", "authors": "Jinfeng Li, Shouling Ji, Tianyu Du, Bo Li, Ting Wang", "title": "TextBugger: Generating Adversarial Text Against Real-world Applications", "comments": "To appear in NDSS 2019", "journal-ref": null, "doi": "10.14722/ndss.2019.23138", "report-no": null, "categories": "cs.CR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning-based Text Understanding (DLTU) is the backbone technique\nbehind various applications, including question answering, machine translation,\nand text classification. Despite its tremendous popularity, the security\nvulnerabilities of DLTU are still largely unknown, which is highly concerning\ngiven its increasing use in security-sensitive applications such as sentiment\nanalysis and toxic content detection. In this paper, we show that DLTU is\ninherently vulnerable to adversarial text attacks, in which maliciously crafted\ntexts trigger target DLTU systems and services to misbehave. Specifically, we\npresent TextBugger, a general attack framework for generating adversarial\ntexts. In contrast to prior works, TextBugger differs in significant ways: (i)\neffective -- it outperforms state-of-the-art attacks in terms of attack success\nrate; (ii) evasive -- it preserves the utility of benign text, with 94.9\\% of\nthe adversarial text correctly recognized by human readers; and (iii) efficient\n-- it generates adversarial text with computational complexity sub-linear to\nthe text length. We empirically evaluate TextBugger on a set of real-world DLTU\nsystems and services used for sentiment analysis and toxic content detection,\ndemonstrating its effectiveness, evasiveness, and efficiency. For instance,\nTextBugger achieves 100\\% success rate on the IMDB dataset based on Amazon AWS\nComprehend within 4.61 seconds and preserves 97\\% semantic similarity. We\nfurther discuss possible defense mechanisms to mitigate such attack and the\nadversary's potential countermeasures, which leads to promising directions for\nfurther research.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 05:32:43 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Li", "Jinfeng", ""], ["Ji", "Shouling", ""], ["Du", "Tianyu", ""], ["Li", "Bo", ""], ["Wang", "Ting", ""]]}, {"id": "1812.05293", "submitter": "Jukka Ruohonen", "authors": "Jukka Ruohonen", "title": "A Demand-Side Viewpoint to Software Vulnerabilities in WordPress Plugins", "comments": "Forthcoming in: Proceedings of Evaluation and Assessment in Software\n  Engineering (EASE 2019), Copenhagen, ACM", "journal-ref": null, "doi": "10.1145/3319008.3319029", "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  WordPress has long been the most popular content management system (CMS).\nThis CMS powers millions and millions of websites. Although WordPress has had a\nparticularly bad track record in terms of security, in recent years many of the\nwell-known security risks have transmuted from the core WordPress to the\nnumerous plugins and themes written for the CMS. Given this background, the\npaper analyzes known software vulnerabilities discovered from WordPress\nplugins. A demand-side viewpoint was used to motivate the analysis; the basic\nhypothesis is that plugins with large installation bases have been affected by\nmultiple vulnerabilities. As the hypothesis also holds according to the\nempirical results, the paper contributes to the recent discussion about common\nsecurity folklore. A few general insights are also provided about the relation\nbetween software vulnerabilities and software maintenance.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 07:22:07 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 16:46:02 GMT"}, {"version": "v3", "created": "Wed, 13 Mar 2019 08:14:51 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Ruohonen", "Jukka", ""]]}, {"id": "1812.05339", "submitter": "Lei Ma", "authors": "Xiaoning Du, Xiaofei Xie, Yi Li, Lei Ma, Jianjun Zhao, Yang Liu", "title": "DeepCruiser: Automated Guided Testing for Stateful Deep Learning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) defines a data-driven programming paradigm that\nautomatically composes the system decision logic from the training data. In\ncompany with the data explosion and hardware acceleration during the past\ndecade, DL achieves tremendous success in many cutting-edge applications.\nHowever, even the state-of-the-art DL systems still suffer from quality and\nreliability issues. It was only until recently that some preliminary progress\nwas made in testing feed-forward DL systems. In contrast to feed-forward DL\nsystems, recurrent neural networks (RNN) follow a very different architectural\ndesign, implementing temporal behaviors and memory with loops and internal\nstates. Such stateful nature of RNN contributes to its success in handling\nsequential inputs such as audio, natural languages and video processing, but\nalso poses new challenges for quality assurance.\n  In this paper, we initiate the very first step towards testing RNN-based\nstateful DL systems. We model RNN as an abstract state transition system, based\non which we define a set of test coverage criteria specialized for stateful DL\nsystems. Moreover, we propose an automated testing framework, DeepCruiser,\nwhich systematically generates tests in large scale to uncover defects of\nstateful DL systems with coverage guidance. Our in-depth evaluation on a\nstate-of-the-art speech-to-text DL system demonstrates the effectiveness of our\ntechnique in improving quality and reliability of stateful DL systems.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 09:49:58 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Du", "Xiaoning", ""], ["Xie", "Xiaofei", ""], ["Li", "Yi", ""], ["Ma", "Lei", ""], ["Zhao", "Jianjun", ""], ["Liu", "Yang", ""]]}, {"id": "1812.05347", "submitter": "Nimesh Shah", "authors": "Nimesh Shah and Manaar Alam and Durga Prasad Sahoo and Debdeep\n  Mukhopadhyay and Arindam Basu", "title": "A 0.16pJ/bit Recurrent Neural Network Based PUF for Enhanced Machine\n  Learning Atack Resistance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physically Unclonable Function (PUF) circuits are finding widespread use due\nto increasing adoption of IoT devices. However, the existing strong PUFs such\nas Arbiter PUFs (APUF) and its compositions are susceptible to machine learning\n(ML) attacks because the challenge-response pairs have a linear relationship.\nIn this paper, we present a Recurrent-Neural-Network PUF (RNN-PUF) which uses a\ncombination of feedback and XOR function to significantly improve resistance to\nML attack, without significant reduction in the reliability. ML attack is also\npartly reduced by using a shared comparator with offset-cancellation to remove\nbias and save power. From simulation results, we obtain ML attack accuracy of\n62% for different ML algorithms, while reliability stays above 93%. This\nrepresents a 33.5% improvement in our Figure-of-Merit. Power consumption is\nestimated to be 12.3uW with energy/bit of ~ 0.16pJ.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 10:10:46 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Shah", "Nimesh", ""], ["Alam", "Manaar", ""], ["Sahoo", "Durga Prasad", ""], ["Mukhopadhyay", "Debdeep", ""], ["Basu", "Arindam", ""]]}, {"id": "1812.05388", "submitter": "Diego Sempreboni", "authors": "Diego Sempreboni and Luca Vigan\\`o", "title": "MMM: May I Mine Your Mind?", "comments": "4 pages, 0 figure, Accepted at the \"Re-Coding Black Mirror\" workshop\n  of the International World Wide Web Conferences (WWW)", "journal-ref": null, "doi": "10.1145/3184558.3191613", "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the following set-up for the plot of a possible future episode of\nthe TV series Black Mirror: human brains can be connected directly to the net\nand MiningMind Inc. has developed a technology that merges a reward system with\na cryptojacking engine that uses the human brain to mine cryptocurrency (or to\ncarry out some other mining activity). Part of our brain will be committed to\ncryptographic calculations (mining), leaving the remaining part untouched for\neveryday operations, i.e., for our brain's normal daily activity. In this short\npaper, we briefly argue why this set-up might not be so far fetched after all,\nand explore the impact that such a technology could have on our lives and our\nsociety.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 12:42:12 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Sempreboni", "Diego", ""], ["Vigan\u00f2", "Luca", ""]]}, {"id": "1812.05440", "submitter": "Fabiano Ferrari", "authors": "Warley M.S. Alves, Thiago L. Prado, Antonio M. Batista and Fabiano\n  A.S. Ferrari", "title": "The dangerous path towards your own cryptography method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Would you like to have your own cryptography method? Experts say you should\nnot do it. If you think you can develop a better cryptography method anyway. We\npresent a brief discussion about some well known cryptography methods and how\nour model fails against the traditional attacks. We do not want to discourage\nanybody, we just want to show that, despite of the importance of developing\nbetter cryptography models, it is a very hard task.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 13:52:28 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Alves", "Warley M. S.", ""], ["Prado", "Thiago L.", ""], ["Batista", "Antonio M.", ""], ["Ferrari", "Fabiano A. S.", ""]]}, {"id": "1812.05441", "submitter": "Robert Viglione", "authors": "Alberto Garoffolo and Robert Viglione", "title": "Sidechains: Decoupled Consensus Between Chains", "comments": "Experimental blockchain technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel sidechain construction tailored to be compatible with the\nHorizen blockchain and designed for conducting secure and decentralized\ncross-chain transfers without requiring the mainchain nodes to track sidechains\nto verify them. The proposed scheme can also be adopted for other similar\nblockchain systems. We show that our cross-ledger transfer mechanism is secure\nunder certain plausible assumptions.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 17:07:05 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Garoffolo", "Alberto", ""], ["Viglione", "Robert", ""]]}, {"id": "1812.05443", "submitter": "Tara Salman", "authors": "Tara Salman, Deval Bhamare, Aiman Erbad, Raj Jain, and Mohammed Samaka", "title": "Machine Learning for Anomaly Detection and Categorization in Multi-cloud\n  Environments", "comments": "CSCLoud17", "journal-ref": "CSCLOUD 2017", "doi": "10.1109/CSCloud.2017.15", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, advances in machine learning techniques have attracted the\nattention of the research community to build intrusion detection systems (IDS)\nthat can detect anomalies in the network traffic. Most of the research works,\nhowever, do not differentiate among different types of attacks. This is, in\nfact, necessary for appropriate countermeasures and defense against attacks. In\nthis paper, we investigate both detecting and categorizing anomalies rather\nthan just detecting, which is a common trend in the contemporary research\nworks. We have used a popular publicly available dataset to build and test\nlearning models for both detection and categorization of different attacks. To\nbe precise, we have used two supervised machine learning techniques, namely\nlinear regression (LR) and random forest (RF). We show that even if detection\nis perfect, categorization can be less accurate due to similarities between\nattacks. Our results demonstrate more than 99% detection accuracy and\ncategorization accuracy of 93.6%, with the inability to categorize some\nattacks. Further, we argue that such categorization can be applied to\nmulti-cloud environments using the same machine learning techniques.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 14:39:24 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Salman", "Tara", ""], ["Bhamare", "Deval", ""], ["Erbad", "Aiman", ""], ["Jain", "Raj", ""], ["Samaka", "Mohammed", ""]]}, {"id": "1812.05444", "submitter": "Antonella Del Pozzo", "authors": "Zaynah Dargaye (DILS), Antonella Pozzo (DILS), Sara Tucci-Piergiovanni\n  (DILS)", "title": "Pluralize: a Trustworthy Framework for High-Level Smart Contract-Draft", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents Pluralize a formal logical framework able to extend the\nexecution of blockchain transactions to events coming from external oracles,\nlike external time, sensor data, human-made declarations, etc. These events are\nby essence non-reliable, since transaction execution can be triggered by\ninformation whose veracity cannot be established by the blockchain. To overcome\nthis problem, the language features a first-order logic and an authority\nalgebra to allow formal reasoning and establish accountability of agents for\nblockchain-enabled transactions. We provide an accountability model that allows\nto formally prove the accountability of agents by a formal proof locally\nexecutable by each agent of the blockchain.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 06:30:10 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Dargaye", "Zaynah", "", "DILS"], ["Pozzo", "Antonella", "", "DILS"], ["Tucci-Piergiovanni", "Sara", "", "DILS"]]}, {"id": "1812.05445", "submitter": "Amar  Prasad Misra", "authors": "A. Roy, A. P. Misra and S. Banerjee", "title": "Discrete model for cloud computing: Analysis of data security and data\n  loss", "comments": "12 pages, 3 tables, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing is recognized as one of the most promising solutions to\ninformation technology, e.g., for storing and sharing data in the web service\nwhich is sustained by a company or third party instead of storing data in a\nhard drive or other devices. It is essentially a physical storage system which\nprovides large storage of data and faster computing to users over the Internet.\nIn this cloud system, the third party allows to preserve data of clients or\nusers only for business purpose and also for a limited period of time. The\nusers are used to share data confidentially among themselves and to store data\nvirtually to save the cost of physical devices as well as the time. In this\npaper, we propose a discrete dynamical system for cloud computing and data\nmanagement of the storage service between a third party and users. A framework,\ncomprised of different techniques and procedures for distribution of storage\nand their implementation with users and the third party is given. For\nillustration purpose, the model is considered for two users and a third party,\nand its dynamical properties are briefly analyzed and discussed. It is shown\nthat the discrete system exhibits periodic, quasiperiodic and chaotic states.\nThe latter discerns that the cloud computing system with distribution of data\nand storage between users and the third party may be secured. Some issues of\ndata security are discussed and a random replication scheme is proposed to\nensure that the data loss can be highly reduced compared to the existing\nschemes in the literature.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 13:06:16 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Roy", "A.", ""], ["Misra", "A. P.", ""], ["Banerjee", "S.", ""]]}, {"id": "1812.05446", "submitter": "Faiq Khalid", "authors": "Faiq Khalid, Imran Hafeez Abbassi, Semeen Rehman, Awais Mehmood\n  Kamboh, Osman Hasan, Muhammad Shafique", "title": "ForASec: Formal Analysis of Security Vulnerabilities in Sequential\n  Circuits", "comments": "(Accepted in 2021)", "journal-ref": "IEEE Transactions on Computer-Aided Design of Integrated Circuits\n  and Systems 2021", "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security vulnerability analysis of Integrated Circuits using conventional\ndesign-time validation and verification techniques (like simulations,\nemulations, etc.) is generally a computationally intensive task and incomplete\nby nature, especially under limited resources and time constraints. To overcome\nthis limitation, we propose a novel methodology based on model checking to\nformally analyze security vulnerabilities in sequential circuits while\nconsidering side-channel parameters like propagation delay, switching power,\nand leakage power. In particular, we present a novel algorithm to efficiently\npartition the state-space into corresponding smaller state-spaces to enable\ndistributed security analysis of complex sequential circuits and thereby\nmitigating the associated state-space explosion due to their feedback loops. We\nanalyze multiple ISCAS89 and trust-hub benchmarks to demonstrate the efficacy\nof our framework in identifying security vulnerabilities. The experimental\nresults show that ForASec successfully performs the complete analysis of the\ngiven complex and large sequential circuits, and provides approximately 11x to\n16x speedup in analysis time compared to state-of-the-art model checking-based\ntechniques. Moreover, it also identifies the number of gates required by an HT\nthat can go undetected for a given design and variability conditions.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 00:22:15 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 07:51:04 GMT"}, {"version": "v3", "created": "Wed, 21 Apr 2021 11:03:48 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Khalid", "Faiq", ""], ["Abbassi", "Imran Hafeez", ""], ["Rehman", "Semeen", ""], ["Kamboh", "Awais Mehmood", ""], ["Hasan", "Osman", ""], ["Shafique", "Muhammad", ""]]}, {"id": "1812.05450", "submitter": "Petar Bojovi\\'c D.", "authors": "P.D. Bojovic, I. Basicevic, S. Ocovaj, M. Popovic", "title": "A practical approach to detection of distributed denial-of-service\n  attacks using a hybrid detection method", "comments": "20 pages, 14 figures, 6 tables", "journal-ref": null, "doi": "10.1016/j.compeleceng.2018.11.004", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a hybrid method for the detection of distributed\ndenial-of-service (DDoS) attacks that combines feature-based and volume-based\ndetection. Our approach is based on an exponential moving average algorithm for\ndecision-making, applied to both entropy and packet number time series. The\napproach has been tested by performing a controlled DDoS experiment in a real\nacademic network. The network setup and test scenarios including both high-rate\nand low-rate attacks are described in the paper. The performance of the\nproposed method is compared to the performance of two methods that are already\nknown in the literature. One is based on the counting of SYN packets and is\nused for detection of SYN flood attacks, while the other is based on a CUSUM\nalgorithm applied to the entropy time series. The results show the advantage of\nour approach compared to methods that are based on either entropy or number of\npackets only.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 11:07:52 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Bojovic", "P. D.", ""], ["Basicevic", "I.", ""], ["Ocovaj", "S.", ""], ["Popovic", "M.", ""]]}, {"id": "1812.05451", "submitter": "Sebastien Blandin", "authors": "Marc Jourdan, Sebastien Blandin, Laura Wynter, Pralhad Deshpande", "title": "A Probabilistic Model of the Bitcoin Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bitcoin transaction graph is a public data structure organized as\ntransactions between addresses, each associated with a logical entity. In this\nwork, we introduce a complete probabilistic model of the Bitcoin Blockchain. We\nfirst formulate a set of conditional dependencies induced by the Bitcoin\nprotocol at the block level and derive a corresponding fully observed graphical\nmodel of a Bitcoin block. We then extend the model to include hidden entity\nattributes such as the functional category of the associated logical agent and\nderive asymptotic bounds on the privacy properties implied by this model. At\nthe network level, we show evidence of complex transaction-to-transaction\nbehavior and present a relevant discriminative model of the agent categories.\nPerformance of both the block-based graphical model and the network-level\ndiscriminative model is evaluated on a subset of the public Bitcoin Blockchain.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 02:35:24 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Jourdan", "Marc", ""], ["Blandin", "Sebastien", ""], ["Wynter", "Laura", ""], ["Deshpande", "Pralhad", ""]]}, {"id": "1812.05452", "submitter": "Ameer Tamoor Khan", "authors": "Ameer Tamoor Khan, Xinwei Cao, and Shuai Li", "title": "A Survey on Blockchain Technology and Its Potential Applications in\n  Distributed Control and Cooperative Robots", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a disruptive technology, blockchain, particularly its original form of\nbitcoin as a type of digital currency, has attracted great attentions. The\ninnovative distributed decision making and security mechanism lay the technical\nfoundation for its success, making us consider to penetrate the power of\nblockchain technology to distributed control and cooperative robotics, in which\nthe distributed and secure mechanism is also highly demanded. Actually,\nsecurity and distributed communication have long been unsolved problems in the\nfield of distributed control and cooperative robotics. It has been reported on\nthe network failure and intruder attacks of distributed control and\nmulti-robotic systems. Blockchain technology provides promise to remedy this\nsituation thoroughly. This work is intended to create a global picture of\nblockchain technology on its working principle and key elements in the language\nof control and robotics, to provide a shortcut for beginners to step into this\nresearch field.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 05:40:15 GMT"}, {"version": "v2", "created": "Fri, 14 Dec 2018 17:57:37 GMT"}, {"version": "v3", "created": "Thu, 20 Dec 2018 17:04:32 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Khan", "Ameer Tamoor", ""], ["Cao", "Xinwei", ""], ["Li", "Shuai", ""]]}, {"id": "1812.05454", "submitter": "Pedro Hecht", "authors": "P. Hecht", "title": "PQC: Extended Triple Decomposition Problem (XTDP) Applied To GL(d,\n  Fp)-An Evolved Framework For Canonical Non-Commutative Cryptography", "comments": "4 pages, 9 Tables. arXiv admin note: substantial text overlap with\n  arXiv:1810.08983", "journal-ref": null, "doi": "10.13140/RG.2.2.20242.09926", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Post-Quantum Cryptography (PQC) attempts to find cryptographic protocols\nresistant to attacks using Shor polynomial time algorithm for numerical field\nproblems or Grover search algorithm. A mostly overlooked but valuable line of\nsolutions is provided by non-commutative algebraic structures, specifically\ncanonical protocols that rely on one-way trapdoor functions (OWTF). Here we\ndevelop an evolved algebraic framework who could be applied to different\nasymmetric protocols. The (canonic) trapdoor one-way function here selected is\na fortified version of the Triple decomposition Problem (TDP) developed by\nKurt. The original protocol relies on two linear and one quadratic algebraic\npublic equation. As quadratic equations are much more difficult to\ncryptanalyze, an Algebraic Span Attack (ASA) developed by Boaz Tsaban, focus on\nthe linear ones. This seems to break our previous work. As a countermeasure, we\npresent here an Extended TDP (cited as XTDP in this work). The main point is\nthat the original public linear equations are transformed into quadratic ones\nand the same is accomplished for exchanged tokens between the entities. All\ndetails not presented here could be found at the cited references.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 18:48:31 GMT"}, {"version": "v2", "created": "Fri, 19 Apr 2019 14:33:14 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Hecht", "P.", ""]]}, {"id": "1812.05558", "submitter": "Muhammad Azizul Hakim", "authors": "Muhammad A. Hakim, Hidayet Aksu, A. Selcuk Uluagac, Kemal Akkaya", "title": "U-PoT: A Honeypot Framework for UPnP-Based IoT Devices", "comments": "International Performance Computing and Communications Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ubiquitous nature of the IoT devices has brought serious security\nimplications to its users. A lot of consumer IoT devices have little to no\nsecurity implementation at all, thus risking user's privacy and making them\ntarget of mass cyber-attacks. Indeed, recent outbreak of Mirai botnet and its\nvariants have already proved the lack of security on the IoT world. Hence, it\nis important to understand the security issues and attack vectors in the IoT\ndomain. Though significant research has been done to secure traditional\ncomputing systems, little focus was given to the IoT realm. In this work, we\nreduce this gap by developing a honeypot framework for IoT devices.\nSpecifically, we introduce U-PoT: a novel honeypot framework for capturing\nattacks on IoT devices that use Universal Plug and Play (UPnP) protocol. A\nmyriad of smart home devices including smart switches, smart bulbs,\nsurveillance cameras, smart hubs, etc. uses the UPnP protocol. Indeed, a simple\nsearch on Shodan IoT search engine lists 1,676,591 UPnP devices that are\nexposed to public network. The popularity and ubiquitous nature of UPnP-based\nIoT device necessitates a full-fledged IoT honeypot system for UPnP devices.\nOur novel framework automatically creates a honeypot from UPnP device\ndescription documents and is extendable to any device types or vendors that use\nUPnP for communication. To the best of our knowledge, this is the first work\ntowards a flexible and configurable honeypot framework for UPnP-based IoT\ndevices. We released U-PoT under an open source license for further research\nand created a database of UPnP device descriptions. We also evaluated our\nframework on two emulated deices. Our experiments show that the emulated\ndevices are able to mimic the behavior of a real IoT device and trick\nvendor-provided device management applications or popular IoT search engines\nwhile having minimal performance ovherhead.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 18:17:06 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Hakim", "Muhammad A.", ""], ["Aksu", "Hidayet", ""], ["Uluagac", "A. Selcuk", ""], ["Akkaya", "Kemal", ""]]}, {"id": "1812.05638", "submitter": "Christiane Kuhn", "authors": "Christiane Kuhn, Martin Beck, Stefan Schiffner, Eduard Jorswieck,\n  Thorsten Strufe", "title": "On Privacy Notions in Anonymous Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many anonymous communication networks (ACNs) with different privacy goals\nhave been developed. However, there are no accepted formal definitions of\nprivacy and ACNs often define their goals and adversary models ad hoc. However,\nfor the understanding and comparison of different flavors of privacy, a common\nfoundation is needed. In this paper, we introduce an analysis framework for\nACNs that captures the notions and assumptions known from different analysis\nframeworks. Therefore, we formalize privacy goals as notions and identify their\nbuilding blocks. For any pair of notions we prove whether one is strictly\nstronger, and, if so, which. Hence, we are able to present a complete\nhierarchy. Further, we show how to add practical assumptions, e.g. regarding\nthe protocol model or user corruption as options to our notions. This way, we\ncapture the notions and assumptions of, to the best of our knowledge, all\nexisting analytical frameworks for ACNs and are able to revise inconsistencies\nbetween them. Thus, our new framework builds a common ground and allows for\nsharper analysis, since new combinations of assumptions are possible and the\nrelations between the notions are known.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 19:16:15 GMT"}, {"version": "v2", "created": "Wed, 16 Jan 2019 15:24:51 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Kuhn", "Christiane", ""], ["Beck", "Martin", ""], ["Schiffner", "Stefan", ""], ["Jorswieck", "Eduard", ""], ["Strufe", "Thorsten", ""]]}, {"id": "1812.05671", "submitter": "Fang Liu", "authors": "Evercita C. Eugenio and Fang Liu", "title": "Construction of Differentially Private Empirical Distributions from a\n  low-order Marginals Set through Solving Linear Equations with l2\n  Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new algorithm, Construction of dIfferentially Private\nEmpirical Distributions from a low-order marginals set tHrough solving linear\nEquations with l2 Regularization (CIPHER), that produces differentially private\nempirical joint distributions from a set of low-order marginals. CIPHER is\nconceptually simple and requires no more than decomposing joint probabilities\nvia basic probability rules to construct a linear equation set and subsequently\nsolving the equations. Compared to the full-dimensional histogram (FDH)\nsanitization, CIPHER has drastic\\-ally lower requirements on computational\nstorage and memory, which is practically attractive especially considering that\nthe high-order signals preserved by the FDH sanitization are likely just sample\nrandomness and rarely of interest. Our experiments demonstrate that CIPHER\noutperforms the multiplicative weighting exponential mechanism in preserving\noriginal information and has similar or superior cost-normalized utility to FDH\nsanitization at the same privacy budget.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 14:50:36 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 00:33:03 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2021 07:41:38 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Eugenio", "Evercita C.", ""], ["Liu", "Fang", ""]]}, {"id": "1812.05725", "submitter": "Ayon Sen", "authors": "Ayon Sen, Scott Alfeld, Xuezhou Zhang, Ara Vartanian, Yuzhe Ma and\n  Xiaojin Zhu", "title": "Training Set Camouflage", "comments": null, "journal-ref": "GameSec 2018", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a form of steganography in the domain of machine learning which\nwe call training set camouflage. Imagine Alice has a training set on an illicit\nmachine learning classification task. Alice wants Bob (a machine learning\nsystem) to learn the task. However, sending either the training set or the\ntrained model to Bob can raise suspicion if the communication is monitored.\nTraining set camouflage allows Alice to compute a second training set on a\ncompletely different -- and seemingly benign -- classification task. By\nconstruction, sending the second training set will not raise suspicion. When\nBob applies his standard (public) learning algorithm to the second training\nset, he approximately recovers the classifier on the original task. Training\nset camouflage is a novel form of steganography in machine learning. We\nformulate training set camouflage as a combinatorial bilevel optimization\nproblem and propose solvers based on nonlinear programming and local search.\nExperiments on real classification tasks demonstrate the feasibility of such\ncamouflage.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 23:06:39 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Sen", "Ayon", ""], ["Alfeld", "Scott", ""], ["Zhang", "Xuezhou", ""], ["Vartanian", "Ara", ""], ["Ma", "Yuzhe", ""], ["Zhu", "Xiaojin", ""]]}, {"id": "1812.05745", "submitter": "Yue Shi", "authors": "Yue Shi", "title": "Data Security and Privacy Protection Data Security and Privacy\n  Protection in Public Cloud", "comments": "Accepted version in Big-Cyber Workshop in 2018 Big Data Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses about the challenges, advantages and shortcomings of\nexisting solutions in data security and privacy in public cloud computing. As\nin cloud computing, oceans of data will be stored. Data stored in public cloud\nwould face both outside attacks and inside attacks since public cloud provider\nthemselves are untrusted. Conventional encryption could be used for storage,\nhowever most data in cloud needs further computation. Decryption before\ncomputation will cause large overheads for data operation and lots of\ninconvenience. Thus, efficient methods to protect data security as well as\nprivacy for large amount of data in cloud are necessary.\n  In the paper, different mechanisms to protect data security and privacy in\npublic cloud are discussed. A data security and privacy enabled multi-cloud\narchitecture is proposed.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 00:12:55 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Shi", "Yue", ""]]}, {"id": "1812.05820", "submitter": "Lei Zhang", "authors": "Derek Zhang, Alex Su, Felix Xu, and Jiang Chen", "title": "ARPA Whitepaper", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a secure computation solution for blockchain networks. The\ncorrectness of computation is verifiable even under malicious majority\ncondition using information-theoretic Message Authentication Code (MAC), and\nthe privacy is preserved using Secret-Sharing. With state-of-the-art multiparty\ncomputation protocol and a layer2 solution, our privacy-preserving computation\nguarantees data security on blockchain, cryptographically, while reducing the\nheavy-lifting computation job to a few nodes. This breakthrough has several\nimplications on the future of decentralized networks. First, secure computation\ncan be used to support Private Smart Contracts, where consensus is reached\nwithout exposing the information in the public contract. Second, it enables\ndata to be shared and used in trustless network, without disclosing the raw\ndata during data-at-use, where data ownership and data usage is safely\nseparated. Last but not least, computation and verification processes are\nseparated, which can be perceived as computational sharding, this effectively\nmakes the transaction processing speed linear to the number of participating\nnodes. Our objective is to deploy our secure computation network as an layer2\nsolution to any blockchain system. Smart Contracts\\cite{smartcontract} will be\nused as bridge to link the blockchain and computation networks. Additionally,\nthey will be used as verifier to ensure that outsourced computation is\ncompleted correctly. In order to achieve this, we first develop a general MPC\nnetwork with advanced features, such as: 1) Secure Computation, 2) Off-chain\nComputation, 3) Verifiable Computation, and 4)Support dApps' needs like\nprivacy-preserving data exchange.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 08:25:52 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Zhang", "Derek", ""], ["Su", "Alex", ""], ["Xu", "Felix", ""], ["Chen", "Jiang", ""]]}, {"id": "1812.05934", "submitter": "Michael Rodler", "authors": "Michael Rodler, Wenting Li, Ghassan O. Karame, Lucas Davi", "title": "Sereum: Protecting Existing Smart Contracts Against Re-Entrancy Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a number of existing blockchain systems have witnessed major bugs\nand vulnerabilities within smart contracts. Although the literature features a\nnumber of proposals for securing smart contracts, these proposals mostly focus\non proving the correctness or absence of a certain type of vulnerability within\na contract, but cannot protect deployed (legacy) contracts from being\nexploited. In this paper, we address this problem in the context of re-entrancy\nexploits and propose a novel smart contract security technology, dubbed Sereum\n(Secure Ethereum), which protects existing, deployed contracts against\nre-entrancy attacks in a backwards compatible way based on run-time monitoring\nand validation. Sereum does neither require any modification nor any semantic\nknowledge of existing contracts. By means of implementation and evaluation\nusing the Ethereum blockchain, we show that Sereum covers the actual execution\nflow of a smart contract to accurately detect and prevent attacks with a false\npositive rate as small as 0.06% and with negligible run-time overhead. As a\nby-product, we develop three advanced re-entrancy attacks to demonstrate the\nlimitations of existing offline vulnerability analysis tools.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 13:54:34 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Rodler", "Michael", ""], ["Li", "Wenting", ""], ["Karame", "Ghassan O.", ""], ["Davi", "Lucas", ""]]}, {"id": "1812.05979", "submitter": "Jan Leike", "authors": "Miljan Martic and Jan Leike and Andrew Trask and Matteo Hessel and\n  Shane Legg and Pushmeet Kohli", "title": "Scaling shared model governance via model splitting", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Currently the only techniques for sharing governance of a deep learning model\nare homomorphic encryption and secure multiparty computation. Unfortunately,\nneither of these techniques is applicable to the training of large neural\nnetworks due to their large computational and communication overheads. As a\nscalable technique for shared model governance, we propose splitting deep\nlearning model between multiple parties. This paper empirically investigates\nthe security guarantee of this technique, which is introduced as the problem of\nmodel completion: Given the entire training data set or an environment\nsimulator, and a subset of the parameters of a trained deep learning model, how\nmuch training is required to recover the model's original performance? We\ndefine a metric for evaluating the hardness of the model completion problem and\nstudy it empirically in both supervised learning on ImageNet and reinforcement\nlearning on Atari and DeepMind~Lab. Our experiments show that (1) the model\ncompletion problem is harder in reinforcement learning than in supervised\nlearning because of the unavailability of the trained agent's trajectories, and\n(2) its hardness depends not primarily on the number of parameters of the\nmissing part, but more so on their type and location. Our results suggest that\nmodel splitting might be a feasible technique for shared model governance in\nsome settings where training is very expensive.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 15:29:21 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Martic", "Miljan", ""], ["Leike", "Jan", ""], ["Trask", "Andrew", ""], ["Hessel", "Matteo", ""], ["Legg", "Shane", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1812.06050", "submitter": "Min Liang", "authors": "Min Liang and Li Yang", "title": "Block encryption of quantum messages", "comments": "13 pages, 1 figure. Prior version appears in\n  eprint.iacr.org(iacr/2017/1247). This version adds some analysis about\n  multiple-message encryption, and modifies lots of contents. There are no\n  changes about the fundamental results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern cryptography, block encryption is a fundamental cryptographic\nprimitive. However, it is impossible for block encryption to achieve the same\nsecurity as one-time pad. Quantum mechanics has changed the modern\ncryptography, and lots of researches have shown that quantum cryptography can\noutperform the limitation of traditional cryptography.\n  This article proposes a new constructive mode for private quantum encryption,\nnamed $\\mathcal{EHE}$, which is a very simple method to construct quantum\nencryption from classical primitive. Based on $\\mathcal{EHE}$ mode, we\nconstruct a quantum block encryption (QBE) scheme from pseudorandom functions.\nIf the pseudorandom functions are standard secure, our scheme is\nindistinguishable encryption under chosen plaintext attack. If the pseudorandom\nfunctions are permutation on the key space, our scheme can achieve perfect\nsecurity. In our scheme, the key can be reused and the randomness cannot, so a\n$2n$-bit key can be used in an exponential number of encryptions, where the\nrandomness will be refreshed in each time of encryption. Thus $2n$-bit key can\nperfectly encrypt $O(n2^n)$ qubits, and the perfect secrecy would not be broken\nif the $2n$-bit key is reused for only exponential times.\n  Comparing with quantum one-time pad (QOTP), our scheme can be the same secure\nas QOTP, and the secret key can be reused (no matter whether the eavesdropping\nexists or not). Thus, the limitation of perfectly secure encryption (Shannon's\ntheory) is broken in the quantum setting. Moreover, our scheme can be viewed as\na positive answer to the open problem in quantum cryptography \"how to\nunconditionally reuse or recycle the whole key of private-key quantum\nencryption\". In order to physically implement the QBE scheme, we only need to\nimplement two kinds of single-qubit gates (Pauli $X$ gate and Hadamard gate),\nso it is within reach of current quantum technology.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 17:50:35 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Liang", "Min", ""], ["Yang", "Li", ""]]}, {"id": "1812.06140", "submitter": "Ya\\u{g}mur \\c{C}ak{\\i}ro\\u{g}lu", "authors": "Ya\\v{g}mur \\c{C}ak{\\i}ro\\v{g}lu and O\\v{g}uz Yayla", "title": "Improved lower bound on the family complexity of Legendre sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study a family of binary Legendre sequences and its family\ncomplexity. Family complexity is a pseudorandomness measure introduced by\nAhlswede et.~al.~in 2003. A lower bound on the family complexity of a family\nbased on the Legendre symbol of polynomials over a finite field was given by\nGyarmati in 2015. In this article we improve the bound given by Gyarmati on\nfamily complexity of binary Legendre sequences. The bound depends on the\nLambert W function and the number of elements in a finite field belonging to\nits proper subfield. Moreover, we present a fast method for calculating the\nbound.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 19:52:39 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2018 14:34:15 GMT"}, {"version": "v3", "created": "Thu, 12 Sep 2019 10:22:43 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["\u00c7ak\u0131ro\u01e7lu", "Ya\u01e7mur", ""], ["Yayla", "O\u01e7uz", ""]]}, {"id": "1812.06156", "submitter": "Alvaro Garcia Recuero", "authors": "Alvaro Garcia-Recuero, Aneta Morawin, Gareth Tyson", "title": "Trollslayer: Crowdsourcing and Characterization of Abusive Birds in\n  Twitter", "comments": "SNAMS 2018", "journal-ref": null, "doi": "10.1109/SNAMS.2018.8554898", "report-no": null, "categories": "cs.CY cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As of today, abuse is a pressing issue to participants and administrators of\nOnline Social Networks (OSN). Abuse in Twitter can spawn from arguments\ngenerated for influencing outcomes of a political election, the use of bots to\nautomatically spread misinformation, and generally speaking, activities that\ndeny, disrupt, degrade or deceive other participants and, or the network. Given\nthe difficulty in finding and accessing a large enough sample of abuse ground\ntruth from the Twitter platform, we built and deployed a custom crawler that we\nuse to judiciously collect a new dataset from the Twitter platform with the aim\nof characterizing the nature of abusive users, a.k.a abusive birds, in the\nwild. We provide a comprehensive set of features based on users' attributes, as\nwell as social-graph metadata. The former includes metadata about the account\nitself, while the latter is computed from the social graph among the sender and\nthe receiver of each message. Attribute-based features are useful to\ncharacterize user's accounts in OSN, while graph-based features can reveal the\ndynamics of information dissemination across the network. In particular, we\nderive the Jaccard index as a key feature to reveal the benign or malicious\nnature of directed messages in Twitter. To the best of our knowledge, we are\nthe first to propose such a similarity metric to characterize abuse in Twitter.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 20:38:25 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Garcia-Recuero", "Alvaro", ""], ["Morawin", "Aneta", ""], ["Tyson", "Gareth", ""]]}, {"id": "1812.06226", "submitter": "Xiang Zhang", "authors": "Tian Yunfan, Zhang Xiang", "title": "A Survey of Privacy Infrastructures and Their Vulnerabilities", "comments": "Northeastern University, CS6740 PS5", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last two decades, the scale and complexity of Anonymous networks and\nits associated technologies grows exponentially as privacy has become a major\nconcern of individuals. Also, some cyber attackers make use of privacy\ninfrastructures including botnets and Tor to do illegal activities like drug,\ncontraband or DDoS attack. However, anonymous networks are not perfect, there\nare some methods could exploit the vulnerabilities and track user information.\nIn this paper, we analyze few of privacy infrastructures and their\nvulnerabilities.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2018 03:06:45 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Yunfan", "Tian", ""], ["Xiang", "Zhang", ""]]}, {"id": "1812.06292", "submitter": "Vinayakumar R", "authors": "Mohammed Harun Babu R, Vinayakumar R, Soman KP", "title": "A short review on Applications of Deep learning for Cyber security", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep learning is an advanced model of traditional machine learning. This has\nthe capability to extract optimal feature representation from raw input\nsamples. This has been applied towards various use cases in cyber security such\nas intrusion detection, malware classification, android malware detection, spam\nand phishing detection and binary analysis. This paper outlines the survey of\nall the works related to deep learning based solutions for various cyber\nsecurity use cases. Keywords: Deep learning, intrusion detection, malware\ndetection, Android malware detection, spam & phishing detection, traffic\nanalysis, binary analysis.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2018 14:17:40 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 04:47:40 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["R", "Mohammed Harun Babu", ""], ["R", "Vinayakumar", ""], ["KP", "Soman", ""]]}, {"id": "1812.06371", "submitter": "Amir Gholami", "authors": "Zhewei Yao and Amir Gholami and Peng Xu and Kurt Keutzer and Michael\n  Mahoney", "title": "Trust Region Based Adversarial Attack on Neural Networks", "comments": null, "journal-ref": "CVPR 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks are quite vulnerable to adversarial perturbations.\nCurrent state-of-the-art adversarial attack methods typically require very time\nconsuming hyper-parameter tuning, or require many iterations to solve an\noptimization based adversarial attack. To address this problem, we present a\nnew family of trust region based adversarial attacks, with the goal of\ncomputing adversarial perturbations efficiently. We propose several attacks\nbased on variants of the trust region optimization method. We test the proposed\nmethods on Cifar-10 and ImageNet datasets using several different models\nincluding AlexNet, ResNet-50, VGG-16, and DenseNet-121 models. Our methods\nachieve comparable results with the Carlini-Wagner (CW) attack, but with\nsignificant speed up of up to $37\\times$, for the VGG-16 model on a Titan Xp\nGPU. For the case of ResNet-50 on ImageNet, we can bring down its\nclassification accuracy to less than 0.1\\% with at most $1.5\\%$ relative\n$L_\\infty$ (or $L_2$) perturbation requiring only $1.02$ seconds as compared to\n$27.04$ seconds for the CW attack. We have open sourced our method which can be\naccessed at [1].\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 00:52:18 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Yao", "Zhewei", ""], ["Gholami", "Amir", ""], ["Xu", "Peng", ""], ["Keutzer", "Kurt", ""], ["Mahoney", "Michael", ""]]}, {"id": "1812.06626", "submitter": "Kevin Eykholt", "authors": "Kevin Eykholt and Atul Prakash", "title": "Designing Adversarially Resilient Classifiers using Resilient Feature\n  Engineering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a methodology, resilient feature engineering, for creating\nadversarially resilient classifiers. According to existing work, adversarial\nattacks identify weakly correlated or non-predictive features learned by the\nclassifier during training and design the adversarial noise to utilize these\nfeatures. Therefore, highly predictive features should be used first during\nclassification in order to determine the set of possible output labels. Our\nmethodology focuses the problem of designing resilient classifiers into a\nproblem of designing resilient feature extractors for these highly predictive\nfeatures. We provide two theorems, which support our methodology. The Serial\nComposition Resilience and Parallel Composition Resilience theorems show that\nthe output of adversarially resilient feature extractors can be combined to\ncreate an equally resilient classifier. Based on our theoretical results, we\noutline the design of an adversarially resilient classifier.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 06:28:17 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Eykholt", "Kevin", ""], ["Prakash", "Atul", ""]]}, {"id": "1812.06799", "submitter": "Warit Sirichotedumrong", "authors": "Warit Sirichotedumrong, Tatsuya Chuman, Hitoshi Kiya", "title": "Grayscale-Based Image Encryption Considering Color Sub-sampling\n  Operation for Encryption-then-Compression Systems", "comments": "Accepted in 2018 IEEE 7th Global Conference on Consumer Electronics\n  (GCCE 2018). arXiv admin note: text overlap with arXiv:1810.13067", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.MM eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new grayscale-based block scrambling image encryption scheme is presented\nto enhance the security of Encryption-then-Compression (EtC) systems, which are\nused to securely transmit images through an untrusted channel provider. The\nproposed scheme enables the use of a smaller block size and a larger number of\nblocks than the conventional scheme. Images encrypted using the proposed scheme\ninclude less color information due to the use of grayscale images even when the\noriginal image has three color channels. These features enhance security\nagainst various attacks, such as jigsaw puzzle solver and brute-force attacks.\nMoreover, it allows the use of color sub-sampling, which can improve the\ncompression performance, although the encrypted images have no color\ninformation. In an experiment, encrypted images were uploaded to and then\ndownloaded from Facebook and Twitter, and the results demonstrated that the\nproposed scheme is effective for EtC systems, while maintaining a high\ncompression performance.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 05:15:25 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Sirichotedumrong", "Warit", ""], ["Chuman", "Tatsuya", ""], ["Kiya", "Hitoshi", ""]]}, {"id": "1812.06815", "submitter": "Fran\\c{c}ois Menet", "authors": "Fran\\c{c}ois Menet, Paul Berthier, Jos\\'e M. Fernandez, Michel Gagnon", "title": "Spartan Networks: Self-Feature-Squeezing Neural Networks for increased\n  robustness in adversarial settings", "comments": "Poster previously accepted at ACM CCS 2018 Toronto, Submitted to\n  Computers & Security", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models are vulnerable to adversarial examples which are input\nsamples modified in order to maximize the error on the system. We introduce\nSpartan Networks, resistant deep neural networks that do not require input\npreprocessing nor adversarial training. These networks have an adversarial\nlayer designed to discard some information of the network, thus forcing the\nsystem to focus on relevant input. This is done using a new activation function\nto discard data. The added layer trains the neural network to filter-out\nusually-irrelevant parts of its input. Our performance evaluation shows that\nSpartan Networks have a slightly lower precision but report a higher robustness\nunder attack when compared to unprotected models. Results of this study of\nAdversarial AI as a new attack vector are based on tests conducted on the MNIST\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 14:55:41 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Menet", "Fran\u00e7ois", ""], ["Berthier", "Paul", ""], ["Fernandez", "Jos\u00e9 M.", ""], ["Gagnon", "Michel", ""]]}, {"id": "1812.06825", "submitter": "Di Wang", "authors": "Di Wang and Adam Smith and Jinhui Xu", "title": "Noninteractive Locally Private Learning of Linear Models via Polynomial\n  Approximations", "comments": "Extended abstract will appear in Algorithmic Learning Theory 2019\n  (ALT 2019), this is the final full version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimizing a convex risk function is the main step in many basic learning\nalgorithms. We study protocols for convex optimization which provably leak very\nlittle about the individual data points that constitute the loss function.\nSpecifically, we consider differentially private algorithms that operate in the\nlocal model, where each data record is stored on a separate user device and\nrandomization is performed locally by those devices. We give new protocols for\n\\emph{noninteractive} LDP convex optimization---i.e., protocols that require\nonly a single randomized report from each user to an untrusted aggregator.\n  We study our algorithms' performance with respect to expected loss---either\nover the data set at hand (empirical risk) or a larger population from which\nour data set is assumed to be drawn. Our error bounds depend on the form of\nindividuals' contribution to the expected loss. For the case of\n\\emph{generalized linear losses} (such as hinge and logistic losses), we give\nan LDP algorithm whose sample complexity is only linear in the dimensionality\n$p$ and quasipolynomial in other terms (the privacy parameters $\\epsilon$ and\n$\\delta$, and the desired excess risk $\\alpha$). This is the first algorithm\nfor nonsmooth losses with sub-exponential dependence on $p$.\n  For the Euclidean median problem, where the loss is given by the Euclidean\ndistance to a given data point, we give a protocol whose sample complexity\ngrows quasipolynomially in $p$. This is the first protocol with sub-exponential\ndependence on $p$ for a loss that is not a generalized linear loss .\n  Our result for the hinge loss is based on a technique, dubbed polynomial of\ninner product approximation, which may be applicable to other problems. Our\nresults for generalized linear losses and the Euclidean median are based on new\nreductions to the case of hinge loss.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 15:12:11 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 04:24:39 GMT"}, {"version": "v3", "created": "Sun, 9 Aug 2020 19:27:20 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Wang", "Di", ""], ["Smith", "Adam", ""], ["Xu", "Jinhui", ""]]}, {"id": "1812.07030", "submitter": "Saber Malekzadeh", "authors": "Saber Malekzadeh", "title": "A Fast Combination of AES Encryption and LZ4 Compression Algorithms", "comments": "Submitted to the 3rd International Conference on applied research in\n  Computer Science and Information Technology. in Farsi", "journal-ref": null, "doi": "10.13140/RG.2.2.33644.56960", "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From a long time ago, beside encryption of data and making it secure,\ncompression packing it was also important that could make transmission of data\nfaster. In the past years need for improvement of encryption and compression\nfor a fast and easy transmission is more necessary. In this paper, a new method\nfor combination of LZ4 combination and AES encryption algorithms for a fast and\neasy packing, securing and compressing of data is presented. Choose of these\ntwo algorithms was for some special features of them about aim of this paper.\nThis paper also is introducing a method for Parallelism of compression and\nencryption in a special way for improvement of speed and security of data.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 19:59:44 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Malekzadeh", "Saber", ""]]}, {"id": "1812.07071", "submitter": "Ari Azarafrooz", "authors": "Ari Azarafrooz, John Brock", "title": "Fuzzy Hashing as Perturbation-Consistent Adversarial Kernel Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": "AICS/2019/05", "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring the similarity of two files is an important task in malware\nanalysis, with fuzzy hash functions being a popular approach. Traditional fuzzy\nhash functions are data agnostic: they do not learn from a particular dataset\nhow to determine similarity; their behavior is fixed across all datasets. In\nthis paper, we demonstrate that fuzzy hash functions can be learned in a novel\nminimax training framework and that these learned fuzzy hash functions\noutperform traditional fuzzy hash functions at the file similarity task for\nPortable Executable files. In our approach, hash digests can be extracted from\nthe kernel embeddings of two kernel networks, trained in a minimax framework,\nwhere the roles of players during training (i.e adversary versus generator)\nalternate along with the input data. We refer to this new minimax architecture\nas perturbation-consistent. The similarity score for a pair of files is the\nutility of the minimax game in equilibrium. Our experiments show that learned\nfuzzy hash functions generalize well, capable of determining that two files are\nsimilar even when one of those files was generated using insertion and deletion\noperations.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 22:02:41 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Azarafrooz", "Ari", ""], ["Brock", "John", ""]]}, {"id": "1812.07107", "submitter": "Min Liang", "authors": "Min Liang", "title": "Teleportation-based quantum homomorphic encryption scheme with\n  quasi-compactness and perfect security", "comments": "32 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article defines encrypted gate, which is denoted by\n$EG[U]:|\\alpha\\rangle\\rightarrow\\left((a,b),Enc_{a,b}(U|\\alpha\\rangle)\\right)$.\nWe present a gate-teleportation-based two-party computation scheme for $EG[U]$,\nwhere one party gives arbitrary quantum state $|\\alpha\\rangle$ as input and\nobtains the encrypted $U$-computing result $Enc_{a,b}(U|\\alpha\\rangle)$, and\nthe other party obtains the random bits $a,b$. Based on $EG[P^x](x\\in\\{0,1\\})$,\nwe propose a method to remove the $P$-error generated in the homomorphic\nevaluation of $T/T^\\dagger$-gate. Using this method, we design two\nnon-interactive and perfectly secure QHE schemes named \\texttt{GT} and\n\\texttt{VGT}. Both of them are $\\mathcal{F}$-homomorphic and quasi-compact (the\ndecryption complexity depends on the $T/T^\\dagger$-gate complexity).\n  Assume $\\mathcal{F}$-homomorphism, non-interaction and perfect security are\nnecessary property, the quasi-compactness is proved to be bounded by $O(M)$,\nwhere $M$ is the total number of $T/T^\\dagger$-gates in the evaluated circuit.\n\\texttt{VGT} is proved to be optimal and has $M$-quasi-compactness. According\nto our QHE schemes, the decryption would be inefficient if the evaluated\ncircuit contains exponential number of $T/T^\\dagger$-gates. Thus our schemes\nare suitable for homomorphic evaluation of any quantum circuit with low\n$T/T^\\dagger$-gate complexity, such as any polynomial-size quantum circuit or\nany quantum circuit with polynomial number of $T/T^\\dagger$-gates.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 17:27:33 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Liang", "Min", ""]]}, {"id": "1812.07219", "submitter": "Anshu Shukla", "authors": "Anshu Shukla, Swarup Kumar Mohalik, Ramamurthy Badrinath", "title": "Smart Contracts for Multiagent Plan Execution in Untrusted\n  Cyber-physical Systems", "comments": "Planning, Artificial intelligence, Blockchain, Smart Contract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent Cyber-physical systems can be modelled as multi-agent systems\nwith planning capability to impart adaptivity for changing contexts. In such\nmulti-agent systems, the protocol for plan execution must result in the proper\ncompletion and ordering of actions in spite of their distributed execution.\nHowever, in untrusted scenarios, there is a possibility of agents not\nrespecting the protocol either due to faults or due to malicious reasons\nthereby resulting in plan failure. In order to prevent such situations, we\npropose to implement the execution of agents through smart contracts. This\npoints to a generic architecture seamlessly integrating intelligent\nplanning-based CPS and smart-contracts.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 08:06:06 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Shukla", "Anshu", ""], ["Mohalik", "Swarup Kumar", ""], ["Badrinath", "Ramamurthy", ""]]}, {"id": "1812.07469", "submitter": "Brad Dillman", "authors": "William W. Streilein, and Brad Dillman", "title": "Proceedings of the Artificial Intelligence for Cyber Security (AICS)\n  Workshop 2019", "comments": "AICS 2019 included 9 workshop papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume represents the proceedings of the Artificial Intelligence for\nCyber Security (AICS) Workshop 2019, held on January 27, 2019 in Honolulu,\nHawaii.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 18:51:48 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 13:54:04 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Streilein", "William W.", ""], ["Dillman", "Brad", ""]]}, {"id": "1812.07606", "submitter": "Li Chen", "authors": "Li Chen", "title": "Deep Transfer Learning for Static Malware Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to apply deep transfer learning from computer vision to static\nmalware classification. In the transfer learning scheme, we borrow knowledge\nfrom natural images or objects and apply to the target domain of static malware\ndetection. As a result, training time of deep neural networks is accelerated\nwhile high classification performance is still maintained. We demonstrate the\neffectiveness of our approach on three experiments and show that our proposed\nmethod outperforms other classical machine learning methods measured in\naccuracy, false positive rate, true positive rate and $F_1$ score (in binary\nclassification). We instrument an interpretation component to the algorithm and\nprovide interpretable explanations to enhance security practitioners' trust to\nthe model. We further discuss a convex combination scheme of transfer learning\nand training from scratch for enhanced malware detection, and provide insights\nof the algorithmic interpretation of vision-based malware classification\ntechniques.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 19:18:15 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Chen", "Li", ""]]}, {"id": "1812.07702", "submitter": "Ao Li", "authors": "Ao Li and Fan Long", "title": "Detecting Standard Violation Errors in Smart Contracts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SOLAR, a new analysis tool for automatically detecting standard\nviolation errors in Ethereum smart contracts.Given the Ethereum Virtual Machine\n(EVM) bytecode of a smart contract and a user specified constraint or invariant\nderived from a technical standard such as ERC-20,SOLAR symbolically executes\nthe contract, explores all possible execution paths, and checks whether it is\npossible to initiate a sequence of malicious transactions to violate the\nspecified constraint or invariant. Our experimental results highlight the\neffectiveness of SOLAR in finding new errors in smart con-tracts. Out of the\nevaluated 779 ERC-20 and 310 ERC-721smart contracts, SOLAR found 255 standard\nviolation errors in 197 vulnerable contracts with only three false\npositives.237 out of the 255 errors are zero-day errors that are not re-ported\nbefore. Our results sound the alarm on the prevalence of standard violation\nerrors in critical smart contracts that manipulate publicly traded digital\nassets\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 23:54:21 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 21:32:32 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Li", "Ao", ""], ["Long", "Fan", ""]]}, {"id": "1812.07810", "submitter": "Zheng Chen", "authors": "Zheng Chen, Xinli Yu, Chi Zhang, Jin Zhang, Cui Lin, Bo Song,\n  Jianliang Gao, Xiaohua Hu, Wei-Shih Yang, Erjia Yan", "title": "Fast Botnet Detection From Streaming Logs Using Online Lanczos Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.NA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Botnet, a group of coordinated bots, is becoming the main platform of\nmalicious Internet activities like DDOS, click fraud, web scraping, spam/rumor\ndistribution, etc. This paper focuses on design and experiment of a new\napproach for botnet detection from streaming web server logs, motivated by its\nwide applicability, real-time protection capability, ease of use and better\nsecurity of sensitive data. Our algorithm is inspired by a Principal Component\nAnalysis (PCA) to capture correlation in data, and we are first to recognize\nand adapt Lanczos method to improve the time complexity of PCA-based botnet\ndetection from cubic to sub-cubic, which enables us to more accurately and\nsensitively detect botnets with sliding time windows rather than fixed time\nwindows. We contribute a generalized online correlation matrix update formula,\nand a new termination condition for Lanczos iteration for our purpose based on\nerror bound and non-decreasing eigenvalues of symmetric matrices. On our\ndataset of an ecommerce website logs, experiments show the time cost of Lanczos\nmethod with different time windows are consistently only 20% to 25% of PCA.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 08:40:21 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Chen", "Zheng", ""], ["Yu", "Xinli", ""], ["Zhang", "Chi", ""], ["Zhang", "Jin", ""], ["Lin", "Cui", ""], ["Song", "Bo", ""], ["Gao", "Jianliang", ""], ["Hu", "Xiaohua", ""], ["Yang", "Wei-Shih", ""], ["Yan", "Erjia", ""]]}, {"id": "1812.07858", "submitter": "Idan Amit", "authors": "Idan Amit, John Matherly, William Hewlett, Zhi Xu, Yinnon Meshi, Yigal\n  Weinberger", "title": "Machine Learning in Cyber-Security - Problems, Challenges and Data Sets", "comments": null, "journal-ref": "The AAAI-19 Workshop on Engineering Dependable and Secure Machine\n  Learning Systems, 2019.\n  [[REF](https://sites.google.com/view/edsmls2019/home)]", "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present cyber-security problems of high importance. We show that in order\nto solve these cyber-security problems, one must cope with certain machine\nlearning challenges. We provide novel data sets representing the problems in\norder to enable the academic community to investigate the problems and suggest\nmethods to cope with the challenges. We also present a method to generate\nlabels via pivoting, providing a solution to common problems of lack of labels\nin cyber-security.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 10:19:25 GMT"}, {"version": "v2", "created": "Thu, 21 Feb 2019 10:34:03 GMT"}, {"version": "v3", "created": "Mon, 22 Apr 2019 09:14:22 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Amit", "Idan", ""], ["Matherly", "John", ""], ["Hewlett", "William", ""], ["Xu", "Zhi", ""], ["Meshi", "Yinnon", ""], ["Weinberger", "Yigal", ""]]}, {"id": "1812.07927", "submitter": "Josep M. Pujol", "authors": "Alex Catarineu, Philipp Cla{\\ss}en, Konark Modi, and Josep M. Pujol", "title": "Preventing Attacks on Anonymous Data Collection", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anonymous data collection systems allow users to contribute the data\nnecessary to build services and applications while preserving their privacy.\nAnonymity, however, can be abused by malicious agents aiming to subvert or to\nsabotage the data collection, for instance by injecting fabricated data. In\nthis paper we propose an efficient mechanism to rate-limit an attacker without\ncompromising the privacy and anonymity of the users contributing data. The\nproposed system builds on top of Direct Anonymous Attestation, a proven\ncryptographic primitive. We describe how a set of rate-limiting rules can be\nformalized to define a normative space in which messages sent by an attacker\ncan be linked, and consequently, dropped. We present all components needed to\nbuild and deploy such protection on existing data collection systems with\nlittle overhead. Empirical evaluation yields performance up to 125 and 140\nmessages per second for senders and the collector respectively on nominal\nhardware. Latency of communication is bound to 4 seconds in the 95th percentile\nwhen using Tor as network layer.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 13:13:46 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Catarineu", "Alex", ""], ["Cla\u00dfen", "Philipp", ""], ["Modi", "Konark", ""], ["Pujol", "Josep M.", ""]]}, {"id": "1812.08014", "submitter": "Alexander Kott", "authors": "Alexander Kott", "title": "Intelligent Autonomous Agents are Key to Cyber Defense of the Future\n  Army Networks", "comments": "This is a pre-print version of the article appearing in The Cyber\n  Defense Review journal, Fall 2018. arXiv admin note: text overlap with\n  arXiv:1803.11256", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent autonomous agents will be widely present on the battlefield of\nthe future. The proliferation of intelligent agents is the emerging reality of\nwarfare, and they will form an ever growing fraction of total military assets.\nBy necessity, intelligent autonomous cyber defense agents are likely to become\nprimary cyber fighters on the future battlefield. Initial explorations have\nidentified the key functions, components and their interactions for a potential\nreference architecture of such an agent. However, it is beyond the current\nstate of AI to support an agent that could operate intelligently in an\nenvironment as complex as the real battlefield. A number of difficult\nchallenges are yet to be overcome. At the same time, a growing body of research\nin Government and academia demonstrates promising steps towards solving some of\nthe challenges. The industry is beginning to embrace approaches that may\ncontribute to technologies of autonomous intelligent agents for cyber defense\nof the Army networks.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 14:04:59 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Kott", "Alexander", ""]]}, {"id": "1812.08030", "submitter": "Belim Sergey", "authors": "S.V. Belim, N.F. Bogachenko, Y.S. Rakitskiy, A.N. Kabanov", "title": "Using the decision support algorithms combining different security\n  policies", "comments": null, "journal-ref": "2016 Dynamics of Systems, Mechanisms and Machines (Dynamics),\n  Omsk, Russia, 2016, pp. 1-5", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the development of the security subsystem of modern information\nsystems, a problem of the joint implementation of several access control models\narises quite often. Traditionally, a request for the user's access to resources\nis granted in case of simultaneous access permission by all active security\npolicies. When there is a conflict between the decisions of the security\npolicies, the issue of granting access remains open. The proposed method of\ncombining multiple security policies is based on the decision support\nalgorithms and provides a response to the access request, even in case of\nvarious decisions of active security policies. To construct combining algorithm\nwe determine a number of weight coefficients, use a weighted sum of the\nclearance levels of individual security policies and apply the analytic\nhierarchy process. The weight coefficients are adjustable parameters of the\nalgorithm and allow administrator to manage the impact of the various security\nrules flexibly.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 15:43:55 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Belim", "S. V.", ""], ["Bogachenko", "N. F.", ""], ["Rakitskiy", "Y. S.", ""], ["Kabanov", "A. N.", ""]]}, {"id": "1812.08073", "submitter": "Jovonni Pharr", "authors": "Jovonni L. Pharr", "title": "Exposing A Customizable, Decentralized Cryptoeconomy as a Data Type", "comments": "working/active paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.GT cs.MA cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purposely modular, this protocol enables customization of several protocol\nproperties, including the consensus properties implemented, blockchain type,\nthe roots used, and virtual machine opcodes, among others. These modules enable\nimplementing parties to control the behavior of their economy, with a minimal\namount of effort, and no sacrifice in participant cryptoeconomic quality. This\nwork also demonstrates the simplification of the developer experience by\nabstracting away all technological details, except basic CRUD-based operations,\nusing various programming languages. We demonstrate the mechanism design\napproach taken, and formalize a process for deploying populations of blockchain\neconomies at scale. The framework shown includes adequate tooling for\nsimulation, development, deployment, maintenance, and analytic-based decision\nmaking. Lastly, we introduce an expressive programming language for the purpose\nof creating, and interacting with the cryptoeconomy designed by the\nimplementing developer.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 16:49:26 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Pharr", "Jovonni L.", ""]]}, {"id": "1812.08108", "submitter": "Deqiang Li", "authors": "Deqiang Li, Qianmu Li, Yanfang Ye, Shouhuai Xu", "title": "Enhancing Robustness of Deep Neural Networks Against Adversarial Malware\n  Samples: Principles, Framework, and AICS'2019 Challenge", "comments": "8 pages, 4 figures, AICS 2019; for the fully-fledged version, please\n  see arxiv:2004.07919", "journal-ref": null, "doi": null, "report-no": "AICS/2019/10", "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware continues to be a major cyber threat, despite the tremendous effort\nthat has been made to combat them. The number of malware in the wild steadily\nincreases over time, meaning that we must resort to automated defense\ntechniques. This naturally calls for machine learning based malware detection.\nHowever, machine learning is known to be vulnerable to adversarial evasion\nattacks that manipulate a small number of features to make classifiers wrongly\nrecognize a malware sample as a benign one. The state-of-the-art is that there\nare no effective countermeasures against these attacks. Inspired by the\nAICS'2019 Challenge, we systematize a number of principles for enhancing the\nrobustness of neural networks against adversarial malware evasion attacks. Some\nof these principles have been scattered in the literature, but others are\nproposed in this paper for the first time. Under the guidance of these\nprinciples, we propose a framework and an accompanying training algorithm,\nwhich are then applied to the AICS'2019 challenge. Our experimental results\nhave been submitted to the challenge organizer for evaluation.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 17:36:36 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 02:23:39 GMT"}, {"version": "v3", "created": "Wed, 16 Sep 2020 15:32:39 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Li", "Deqiang", ""], ["Li", "Qianmu", ""], ["Ye", "Yanfang", ""], ["Xu", "Shouhuai", ""]]}, {"id": "1812.08223", "submitter": "Siddhartha Das", "authors": "Stefan B\\\"auml, Siddhartha Das, Mark M. Wilde", "title": "Fundamental limits on the capacities of bipartite quantum interactions", "comments": "see companion paper at arXiv:1712.00827", "journal-ref": "Physical Review Letters, vol. 121, issue 25, page 250504, December\n  2018", "doi": "10.1103/PhysRevLett.121.250504", "report-no": null, "categories": "quant-ph cs.CR cs.IT hep-th math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bipartite quantum interactions have applications in a number of different\nareas of quantum physics, reaching from fundamental areas such as quantum\nthermodynamics and the theory of quantum measurements to other applications\nsuch as quantum computers, quantum key distribution, and other information\nprocessing protocols. A particular aspect of the study of bipartite\ninteractions is concerned with the entanglement that can be created from such\ninteractions. In this Letter, we present our work on two basic building blocks\nof bipartite quantum protocols, namely, the generation of maximally entangled\nstates and secret key via bipartite quantum interactions. In particular, we\nprovide a nontrivial, efficiently computable upper bound on the\npositive-partial-transpose-assisted quantum capacity of a bipartite quantum\ninteraction. In addition, we provide an upper bound on the secret-key-agreement\ncapacity of a bipartite quantum interaction assisted by local operations and\nclassical communication. As an application, we introduce a cryptographic\nprotocol for the readout of a digital memory device that is secure against a\npassive eavesdropper.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 20:04:55 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["B\u00e4uml", "Stefan", ""], ["Das", "Siddhartha", ""], ["Wilde", "Mark M.", ""]]}, {"id": "1812.08310", "submitter": "Luis Garcia", "authors": "Sridhar Adepu, Ferdinand Brasser, Luis Garcia, Michael Rodler, Lucas\n  Davi, Ahmad-Reza Sadeghi, Saman Zonouz", "title": "Control Behavior Integrity for Distributed Cyber-Physical Systems", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-physical control systems, such as industrial control systems (ICS), are\nincreasingly targeted by cyberattacks. Such attacks can potentially cause\ntremendous damage, affect critical infrastructure or even jeopardize human life\nwhen the system does not behave as intended. Cyberattacks, however, are not new\nand decades of security research have developed plenty of solutions to thwart\nthem. Unfortunately, many of these solutions cannot be easily applied to\nsafety-critical cyber-physical systems. Further, the attack surface of ICS is\nquite different from what can be commonly assumed in classical IT systems.\n  We present Scadman, a system with the goal to preserve the Control Behavior\nIntegrity (CBI) of distributed cyber-physical systems. By observing the\nsystem-wide behavior, the correctness of individual controllers in the system\ncan be verified. This allows Scadman to detect a wide range of attacks against\ncontrollers, like programmable logic controller (PLCs), including malware\nattacks, code-reuse and data-only attacks. We implemented and evaluated Scadman\nbased on a real-world water treatment testbed for research and training on ICS\nsecurity. Our results show that we can detect a wide range of\nattacks--including attacks that have previously been undetectable by typical\nstate estimation techniques--while causing no false-positive warning for\nnominal threshold values.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 01:43:30 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Adepu", "Sridhar", ""], ["Brasser", "Ferdinand", ""], ["Garcia", "Luis", ""], ["Rodler", "Michael", ""], ["Davi", "Lucas", ""], ["Sadeghi", "Ahmad-Reza", ""], ["Zonouz", "Saman", ""]]}, {"id": "1812.08315", "submitter": "Ali Dorri", "authors": "Ali Dorri, Ambrose Hill, Salil S Kanhere, Raja Jurdak, Fengji Luo,\n  Zhao Yang Dong", "title": "Peer-to-Peer EnergyTrade: A Distributed Private Energy Trading Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain is increasingly being used as a distributed, anonymous, trustless\nframework for energy trading in smart grids. However, most of the existing\nsolutions suffer from reliance on Trusted Third Parties (TTP), lack of privacy,\nand traffic and processing overheads. In our previous work, we have proposed a\nSecure Private Blockchain-based framework (SPB) for energy trading to address\nthe aforementioned challenges. In this paper, we present a proof-on-concept\nimplementation of SPB on the Ethereum private network to demonstrates SPB's\napplicability for energy trading. We benchmark SPB's performance against the\nrelevant state-of-the-art. The implementation results demonstrate that SPB\nincurs lower overheads and monetary cost for end users to trade energy compared\nto existing solutions.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 02:15:19 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Dorri", "Ali", ""], ["Hill", "Ambrose", ""], ["Kanhere", "Salil S", ""], ["Jurdak", "Raja", ""], ["Luo", "Fengji", ""], ["Dong", "Zhao Yang", ""]]}, {"id": "1812.08329", "submitter": "Tsui-Wei Weng", "authors": "Tsui-Wei Weng, Pin-Yu Chen, Lam M. Nguyen, Mark S. Squillante, Ivan\n  Oseledets, Luca Daniel", "title": "PROVEN: Certifying Robustness of Neural Networks with a Probabilistic\n  Approach", "comments": "updated ref [25]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With deep neural networks providing state-of-the-art machine learning models\nfor numerous machine learning tasks, quantifying the robustness of these models\nhas become an important area of research. However, most of the research\nliterature merely focuses on the \\textit{worst-case} setting where the input of\nthe neural network is perturbed with noises that are constrained within an\n$\\ell_p$ ball; and several algorithms have been proposed to compute certified\nlower bounds of minimum adversarial distortion based on such worst-case\nanalysis. In this paper, we address these limitations and extend the approach\nto a \\textit{probabilistic} setting where the additive noises can follow a\ngiven distributional characterization. We propose a novel probabilistic\nframework PROVEN to PRObabilistically VErify Neural networks with statistical\nguarantees -- i.e., PROVEN certifies the probability that the classifier's\ntop-1 prediction cannot be altered under any constrained $\\ell_p$ norm\nperturbation to a given input. Importantly, we show that it is possible to\nderive closed-form probabilistic certificates based on current state-of-the-art\nneural network robustness verification frameworks. Hence, the probabilistic\ncertificates provided by PROVEN come naturally and with almost no overhead when\nobtaining the worst-case certified lower bounds from existing methods such as\nFast-Lin, CROWN and CNN-Cert. Experiments on small and large MNIST and CIFAR\nneural network models demonstrate our probabilistic approach can achieve up to\naround $75\\%$ improvement in the robustness certification with at least a\n$99.99\\%$ confidence compared with the worst-case robustness certificate\ndelivered by CROWN.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 18:59:38 GMT"}, {"version": "v2", "created": "Mon, 7 Jan 2019 05:34:00 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Weng", "Tsui-Wei", ""], ["Chen", "Pin-Yu", ""], ["Nguyen", "Lam M.", ""], ["Squillante", "Mark S.", ""], ["Oseledets", "Ivan", ""], ["Daniel", "Luca", ""]]}, {"id": "1812.08429", "submitter": "Iain Learmonth", "authors": "Iain R. Learmonth and Karsten Loesing", "title": "Towards Modernising Data Collection and Archive for the Tor Network", "comments": "27pp", "journal-ref": null, "doi": null, "report-no": "Tor Tech Report 2018-12-001", "categories": "cs.OH cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CollecTor is developed by Tor Project's Metrics Team for the purpose of\narchiving data relating to the public Tor network and applications developed by\nTor Project. This report distills the requirements for a prototype modernized\nreplacement of the CollecTor service, and evaluates frameworks and libraries\nthat are available to reduce code maintenance costs for the CollecTor service.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 09:17:45 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Learmonth", "Iain R.", ""], ["Loesing", "Karsten", ""]]}, {"id": "1812.08494", "submitter": "Belim Sergey", "authors": "S.V. Belim, S.Yu. Belim, N.F. Bogachenko, A.N. Kabanov", "title": "User Authorization in a System with a Role-Based Access Control on the\n  Basis of the Analytic Hierarchy Process", "comments": null, "journal-ref": "2017 Dynamics of Systems, Mechanisms and Machines (Dynamics),\n  Omsk, Russia, 2017, pp. 1-5", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of optimal authorization of a user in a system with a role-based\naccess control policy is considered. The main criterion is to minimize the\nrisks of permission leakage. The choice of the role for authorization is based\non the analytic hierarchy process. The substantiation of a choice of criteria\nfor formation of a hierarchy of the first level is given. An algorithm for\ncalculating weight coefficients is presented, based on the quantitative\ncharacteristics of the role graph and not dependent on subjective expert\nevaluations. The complexity is estimated and the scalability of the proposed\nalgorithm is discussed.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 11:34:03 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Belim", "S. V.", ""], ["Belim", "S. Yu.", ""], ["Bogachenko", "N. F.", ""], ["Kabanov", "A. N.", ""]]}, {"id": "1812.08496", "submitter": "Paul Muntean", "authors": "Paul Muntean", "title": "Automated CFI Policy Assessment with Reckon", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protecting programs against control-flow hijacking attacks recently has\nbecome an arms race between defenders and attackers. While certain defenses,\ne.g., \\textit{Control Flow Integrity} (CFI), restrict the targets of indirect\ncontrol-flow transfers through static and dynamic analysis, attackers could\nsearch the program for available gadgets that fall into the legitimate target\nsets to bypass the defenses. There are several tools helping both attackers in\ndeveloping exploits and analysts in strengthening their defenses. Yet, these\ntools fail to adequately (1) model the deployed defenses, (2) compare them in a\nhead-to-head way, and (3) use program semantic information to help craft the\nattack and the countermeasures.\n  Control Flow Integrity (CFI) has proved to be one of the promising defenses\nagainst control flow hijacks and tons of efforts have been made to improve CFI\nin various ways in the past decade. However, there is a lack of a systematic\nassessment of the existing CFI defenses. In this paper, we present Reckon, a\nstatic source code analysis tool for assessing state-of-the-art static CFI\ndefenses, by first precisely modeling them and then evaluating them in a\nunified framework. Reckon helps determine the level of security offered by\ndifferent CFI defenses, and find usable code gadgets even after the CFI\ndefenses were applied, thus providing an important step towards successful\nexploits and stronger defenses. We have used Reckon to assess eight\nstate-of-the-art static CFI defenses on real-world programs such as Google's\nChrome and Apache Httpd. Reckon provides precise measurements of the residual\nattack surfaces, and accordingly ranks CFI policies against each other. It also\nsuccessfully paves the way to construct code reuse attacks and to eliminate the\nremaining attack surface, by disclosing calltargets under one of the most\nrestrictive CFI defenses.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 11:36:30 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Muntean", "Paul", ""]]}, {"id": "1812.08497", "submitter": "Ali Dorri", "authors": "Ali Dorri, Fengji Luo, Salil S Kanhere, Raja Jurdak, Zhao Yang Dong", "title": "A Secure and Efficient Direct Power Load Control Framework Based on\n  Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security and privacy in Direct Load Control (DLC) is a fundamental challenge\nin smart grids. In this paper, we propose a blockchain-based framework to\nincrease security and privacy of DLC. We propose a method whereby participating\nnodes share their data with the distribution company in an anonymous and secure\nmanner. To reduce the associated overhead for data dissemination, we propose a\nhash-based transaction generation method. We also outline the DLC process for\nmanaging the load in consumer site. Qualitative analysis demonstrates the\nsecurity and privacy of the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 11:38:20 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Dorri", "Ali", ""], ["Luo", "Fengji", ""], ["Kanhere", "Salil S", ""], ["Jurdak", "Raja", ""], ["Dong", "Zhao Yang", ""]]}, {"id": "1812.08603", "submitter": "Ziqing Guo", "authors": "Ziqing Guo, Hua Zhang, Xin Zhang, Zhengping Jin, and Qiaoyan Wen", "title": "Secure and Efficiently Searchable IoT Communication Data Management\n  Model: Using Blockchain as a new tool", "comments": "11 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of the Internet of things (IoT), more and more IoT\ndevices are connected and communicate frequently. In this background, the\ntraditional centralized security architecture of IoT will be limited in terms\nof data storage space, data reliability, scalability, operating costs and\nliability judgment. In this paper, we propose an new key information storage\nframework based on a small distributed database generated by blockchain\ntechnology and cloud storage. Specifically, all encrypted key communication\ndata will be upload to public could server for enough storage, but the\nabstracts of these data (called \"communication logs\") will be recorded in \"IoT\nledger\" (i.e., an distributed database) that maintained by all IoT devices\naccording to the blockchain generation approach, which could solve the problem\nof data reliability, scalability and liability judgment. Besides, in order to\nefficiently search communication logs and not reveal any sensitive information\nof communication data, we design the secure search scheme for our \"IoT ledger\",\nwhich exploits the Asymmetric Scalar-product Preserving Encryption (ASPE)\napproach to guarantee the data security, and exploits the 2-layers index which\nis tailor-made for blockchain database to improve the search efficiency.\nSecurity analysis and experiments on synthetic dataset show that our schemes\nare secure and efficient.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 14:37:55 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Guo", "Ziqing", ""], ["Zhang", "Hua", ""], ["Zhang", "Xin", ""], ["Jin", "Zhengping", ""], ["Wen", "Qiaoyan", ""]]}, {"id": "1812.08639", "submitter": "Marco Guarnieri", "authors": "Marco Guarnieri, Boris K\\\"opf, Jos\\'e F. Morales, Jan Reineke,\n  Andr\\'es S\\'anchez", "title": "SPECTECTOR: Principled Detection of Speculative Information Flows", "comments": "40 pages, technical report with proofs. To appear at IEEE Symposium\n  on Security and Privacy, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the advent of SPECTRE, a number of countermeasures have been proposed\nand deployed. Rigorously reasoning about their effectiveness, however, requires\na well-defined notion of security against speculative execution attacks, which\nhas been missing until now. In this paper (1) we put forward speculative\nnon-interference, the first semantic notion of security against speculative\nexecution attacks, and (2) we develop SPECTECTOR, an algorithm based on\nsymbolic execution to automatically prove speculative non-interference, or to\ndetect violations. We implement SPECTECTOR in a tool, which we use to detect\nsubtle leaks and optimizations opportunities in the way major compilers place\nSPECTRE countermeasures. A scalability analysis indicates that checking\nspeculative non-interference does not exhibit fundamental bottlenecks beyond\nthose inherited by symbolic execution.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 15:38:21 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 14:30:46 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Guarnieri", "Marco", ""], ["K\u00f6pf", "Boris", ""], ["Morales", "Jos\u00e9 F.", ""], ["Reineke", "Jan", ""], ["S\u00e1nchez", "Andr\u00e9s", ""]]}, {"id": "1812.08806", "submitter": "Martin Garriga", "authors": "Martin Garriga, Maximiliano Arias, Alan De Renzis", "title": "Blockchain and Cryptocurrency: A comparative framework of the main\n  Architectural Drivers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain is a decentralized transaction and data management solution, the\ntechnological weapon-of-choice behind the success of Bitcoin and other\ncryptocurrencies. As the number and variety of existing blockchain\nimplementations continues to increase, adopters should focus on selecting the\nbest one to support their decentralized applications (dApps), rather than\ndeveloping new ones from scratch. In this paper we present a framework to aid\nsoftware architects, developers, tool selectors and decision makers to adopt\nthe right blockchain technology for their problem at hand. The framework\nexposes the correlation between technological decisions and architectural\nfeatures, capturing the knowledge from existing industrial products, technical\nforums/blogs, experts' feedback and academic literature; plus our own\nexperience using and developing blockchain-based applications. We validate our\nframework by applying it to dissect the most outstanding blockchain platforms,\ni.e., the ones behind the top 10 cryptocurrencies apart from Bitcoin. Then, we\nshow how we applied it to a real-world case study in the insurtech domain.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 15:35:22 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Garriga", "Martin", ""], ["Arias", "Maximiliano", ""], ["De Renzis", "Alan", ""]]}, {"id": "1812.08970", "submitter": "Ali Dorri", "authors": "Ali Dorri, Clemence Roulin, Raja Jurdak, Salil Kanhere", "title": "On the Activity Privacy of Blockchain for IoT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security is one of the fundamental challenges in the Internet of Things (IoT)\ndue to the heterogeneity and resource constraints of the IoT devices. Device\nclassification methods are employed to enhance the security of IoT by detecting\nunregistered devices or traffic patterns. In recent years, blockchain has\nreceived tremendous attention as a distributed trustless platform to enhance\nthe security of IoT. Conventional device identification methods are not\ndirectly applicable in blockchain-based IoT as network layer packets are not\nstored in the blockchain. Moreover, the transactions are broadcast and thus\nhave no destination IP address and contain a public key as the user identity,\nand are stored permanently in blockchain which can be read by any entity in the\nnetwork. We show that device identification in blockchain introduces privacy\nrisks as the malicious nodes can identify users' activity pattern by analyzing\nthe temporal pattern of their transactions in the blockchain. We study the\nlikelihood of classifying IoT devices by analyzing their information stored in\nthe blockchain, which to the best of our knowledge, is the first work of its\nkind. We use a smart home as a representative IoT scenario. First, a blockchain\nis populated according to a real-world smart home traffic dataset. We then\napply machine learning algorithms on the data stored in the blockchain to\nanalyze the success rate of device classification, modeling both an informed\nand a blind attacker. Our results demonstrate success rates over 90\\% in\nclassifying devices. We propose three timestamp obfuscation methods, namely\ncombining multiple packets into a single transaction, merging ledgers of\nmultiple devices, and randomly delaying transactions, to reduce the success\nrate in classifying devices. The proposed timestamp obfuscation methods can\nreduce the classification success rates to as low as 20%.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 06:46:20 GMT"}, {"version": "v2", "created": "Thu, 14 Mar 2019 13:34:44 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Dorri", "Ali", ""], ["Roulin", "Clemence", ""], ["Jurdak", "Raja", ""], ["Kanhere", "Salil", ""]]}, {"id": "1812.09053", "submitter": "Abdelhafid Zitouni", "authors": "Lynda kacha, Abdelhafid Zitouni", "title": "An Overview on Data Security in Cloud Computing", "comments": "12 pages, 2 figures, 2 Tables", "journal-ref": null, "doi": "10.1007/978-3-319-67618-0_23", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud Computing refers to the use of computer resources as a service\non-demand via internet. It is mainly based on data and applications\noutsourcing, traditionally stored on users' computers, to remote servers\n(datacenters) owned, administered and managed by third parts. This paper is an\noverview of data security issues in the cloud computing. Its objective is to\nhighlight the principal issues related to data security that raised by cloud\nenvironment. To do this, these issues was classified into three categories:\n1-data security issues raised by single cloud characteristics compared to\ntraditional infrastructure, 2-data security issues raised by data life cycle in\ncloud computing (stored, used and transferred data), 3-data security issues\nassociated to data security attributes (confidentiality, integrity and\navailability). For each category, the common solutions used to secure data in\nthe cloud were emphasized.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 11:15:41 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["kacha", "Lynda", ""], ["Zitouni", "Abdelhafid", ""]]}, {"id": "1812.09059", "submitter": "Leandros Maglaras A", "authors": "Ahmed Ahmim, Leandros Maglaras, Mohamed Amine Ferrag, Makhlouf\n  Derdour, Helge Janicke", "title": "A Novel Hierarchical Intrusion Detection System based on Decision Tree\n  and Rules-based Models", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel intrusion detection system (IDS) that combines\ndifferent classifier approaches which are based on decision tree and\nrules-based concepts, namely, REP Tree, JRip algorithm and Forest PA.\nSpecifically, the first and second method take as inputs features of the data\nset, and classify the network traffic as Attack/Benign. The third classifier\nuses features of the initial data set in addition to the outputs of the first\nand the second classifier as inputs. The experimental results obtained by\nanalyzing the proposed IDS using the CICIDS2017 dataset, attest their\nsuperiority in terms of accuracy, detection rate, false alarm rate and time\noverhead as compared to state of the art existing schemes.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 11:28:27 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Ahmim", "Ahmed", ""], ["Maglaras", "Leandros", ""], ["Ferrag", "Mohamed Amine", ""], ["Derdour", "Makhlouf", ""], ["Janicke", "Helge", ""]]}, {"id": "1812.09116", "submitter": "Benjamin Smith", "authors": "Steven Galbraith, Lorenz Panny (TU/e), Benjamin Smith (GRACE),\n  Frederik Vercauteren (ESAT)", "title": "Quantum Equivalence of the DLP and CDHP for Group Actions", "comments": null, "journal-ref": "Mathematical Cryptology, Florida Online Journals, 2021, 1 (1),\n  pp.40-44", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this short note we give a polynomial-time quantum reduction from the\nvectorization problem (DLP) to the parallelization problem (CDHP) for group\nactions. Combined with the trivial reduction from par-allelization to\nvectorization, we thus prove the quantum equivalence of both problems.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 13:45:09 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 12:18:04 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Galbraith", "Steven", "", "TU/e"], ["Panny", "Lorenz", "", "TU/e"], ["Smith", "Benjamin", "", "GRACE"], ["Vercauteren", "Frederik", "", "ESAT"]]}, {"id": "1812.09130", "submitter": "P\\'eter Kutas", "authors": "S\\'andor Z. Kiss, P\\'eter Kutas", "title": "An identification system based on the explicit isomorphism problem", "comments": "Contains updated grant numbers", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.RA cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose various zero knowledge protocols based on the algorithmic problem\nof finding isomorphisms between central simple algebras over number fields\ngiven by structure constants. We also design a protocol which is based on the\nhardness of finding an element with a prescribed minimal polynomial in a\ncentral simple algebra given by structure constants. This protocol allows\narbitrarily long challenges and thus can be turned into a digital signature\nscheme.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 14:12:20 GMT"}, {"version": "v2", "created": "Sun, 13 Jan 2019 20:54:04 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Kiss", "S\u00e1ndor Z.", ""], ["Kutas", "P\u00e9ter", ""]]}, {"id": "1812.09160", "submitter": "Junaid Arshad", "authors": "Junaid Arshad, Muhammad Ajmal Azad, Khaled Salah, Wei Jie, Razi Iqbal,\n  Mamoun Alazab", "title": "A Review of Performance, Energy and Privacy of Intrusion Detection\n  Systems for IoT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) is a disruptive technology with applications across\ndiverse domains such as transportation and logistics systems, smart grids,\nsmart homes, connected vehicles, and smart cities. Alongside the growth of\nthese infrastructures, the volume and variety of attacks on these\ninfrastructures has increased highlighting the significance of distinct\nprotection mechanisms. Intrusion detection is one of the distinguished\nprotection mechanisms with notable recent efforts made to establish effective\nintrusion detection for IoT and IoV. However, unique characteristics of such\ninfrastructures including battery power, bandwidth and processors overheads,\nand the network dynamics can influence the operation of an intrusion detection\nsystem. This paper presents a comprehensive study of existing intrusion\ndetection systems for IoT systems including emerging systems such as Internet\nof Vehicles (IoV). The paper analyzes existing systems in three aspects:\ncomputational overhead, energy consumption and privacy implications. Based on a\nrigorous analysis of the existing intrusion detection approaches, the paper\nalso identifies open challenges for an effective and collaborative design of\nintrusion detection system for resource-constrained IoT system in general and\nits applications such as IoV. These efforts are envisaged to highlight state of\nthe art with respect to intrusion detection for IoT and open challenges\nrequiring specific efforts to achieve efficient intrusion detection within\nthese systems.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 14:50:27 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Arshad", "Junaid", ""], ["Azad", "Muhammad Ajmal", ""], ["Salah", "Khaled", ""], ["Jie", "Wei", ""], ["Iqbal", "Razi", ""], ["Alazab", "Mamoun", ""]]}, {"id": "1812.09204", "submitter": "Josep Domingo-Ferrer", "authors": "Mark Elliot and Josep Domingo-Ferrer", "title": "The future of statistical disclosure control", "comments": "A contributing article to the National Statistician's Quality Review\n  into Privacy and Data Confidentiality Methods", "journal-ref": "Please cite as : Elliot, M. J. & Domingo Ferrer, J. (2018) 'The\n  future of statistical disclosure control'. Paper published as part of The\n  National Statistician's Quality Review. London, December 2018", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical disclosure control (SDC) was not created in a single seminal\npaper nor following the invention of a new mathematical technique, rather it\ndeveloped slowly in response to the practical challenges faced by data\npractitioners based at national statistical institutes (NSIs). SDC's subsequent\nemergence as a specialised academic field was an outcome of three interrelated\nsocio-technical changes: (i) the advent of accessible computing as a research\ntool in the 1980s meant that it became possible - and then increasingly easy -\nfor researchers to process larger quantities of data automatically; this\nnaturally increased demand for such data; (ii) it became possible for data\nholders to process and disseminate detailed data as digital files and (iii) the\nnumber of organisations holding data about individuals proliferated. This also\nmeant the number of potential adversaries with the resources to attack any\ngiven dataset increased exponentially. In this article, we describe the state\nof the art for SDC and then discuss the core issues and future challenges. In\nparticular, we touch on SDC and big data, on SDC and machine learning, and on\nSDC and anti-discrimination.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 15:42:01 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Elliot", "Mark", ""], ["Domingo-Ferrer", "Josep", ""]]}, {"id": "1812.09233", "submitter": "Shantanu Sharma", "authors": "Sharad Mehrotra, Shantanu Sharma, Jeffrey D. Ullman, and Anurag Mishra", "title": "Partitioned Data Security on Outsourced Sensitive and Non-sensitive Data", "comments": "Accepted in IEEE International Conference on Data Engineering (ICDE),\n  2019. arXiv admin note: text overlap with arXiv:1812.01741", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR cs.DC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite extensive research on cryptography, secure and efficient query\nprocessing over outsourced data remains an open challenge. This paper continues\nalong the emerging trend in secure data processing that recognizes that the\nentire dataset may not be sensitive, and hence, non-sensitivity of data can be\nexploited to overcome limitations of existing encryption-based approaches. We\npropose a new secure approach, entitled query binning (QB) that allows\nnon-sensitive parts of the data to be outsourced in clear-text while\nguaranteeing that no information is leaked by the joint processing of\nnon-sensitive data (in clear-text) and sensitive data (in encrypted form). QB\nmaps a query to a set of queries over the sensitive and non-sensitive data in a\nway that no leakage will occur due to the joint processing over sensitive and\nnon-sensitive data. Interestingly, in addition to improve performance, we show\nthat QB actually strengthens the security of the underlying cryptographic\ntechnique by preventing size, frequency-count, and workload-skew attacks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 03:06:17 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Mehrotra", "Sharad", ""], ["Sharma", "Shantanu", ""], ["Ullman", "Jeffrey D.", ""], ["Mishra", "Anurag", ""]]}, {"id": "1812.09247", "submitter": "Mengshuo Jia", "authors": "Mengshuo Jia, Shaowei Huang, Zhiwen Wang, Chen Shen", "title": "Privacy-Preserving Distributed Parameter Estimation for Probability\n  Distribution of Wind Power Forecast Error", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building the conditional probability distribution of wind power forecast\nerrors benefits both wind farms (WFs) and independent system operators (ISOs).\nEstablishing the joint probability distribution of wind power and the\ncorresponding forecast data of spatially correlated WFs is the foundation for\nderiving the conditional probability distribution. Traditional parameter\nestimation methods for probability distributions require the collection of\nhistorical data of all WFs. However, in the context of multi-regional\ninterconnected grids, neither regional ISOs nor WFs can collect the raw data of\nWFs in other regions due to privacy or competition considerations. Therefore,\nbased on the Gaussian mixture model, this paper first proposes a\nprivacy-preserving distributed expectation-maximization algorithm to estimate\nthe parameters of the joint probability distribution. This algorithm consists\nof two original methods: (1) a privacy-preserving distributed summation\nalgorithm and (2) a privacy-preserving distributed inner product algorithm.\nThen, we derive each WF's conditional probability distribution of forecast\nerror from the joint one. By the proposed algorithms, WFs only need local\ncalculations and privacy-preserving neighboring communications to achieve the\nwhole parameter estimation. These algorithms are verified using the wind\nintegration data set published by the NREL.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 08:44:12 GMT"}, {"version": "v2", "created": "Wed, 24 Apr 2019 13:22:08 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2020 16:02:41 GMT"}, {"version": "v4", "created": "Sat, 29 Feb 2020 18:19:50 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Jia", "Mengshuo", ""], ["Huang", "Shaowei", ""], ["Wang", "Zhiwen", ""], ["Shen", "Chen", ""]]}, {"id": "1812.09400", "submitter": "Li Chen", "authors": "Li Chen, Chih-Yuan Yang, Anindya Paul, Ravi Sahita", "title": "Towards resilient machine learning for ransomware detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a surge of interest in using machine learning (ML) to\nautomatically detect malware through their dynamic behaviors. These approaches\nhave achieved significant improvement in detection rates and lower false\npositive rates at large scale compared with traditional malware analysis\nmethods. ML in threat detection has demonstrated to be a good cop to guard\nplatform security. However it is imperative to evaluate - is ML-powered\nsecurity resilient enough?\n  In this paper, we juxtapose the resiliency and trustworthiness of ML\nalgorithms for security, via a case study of evaluating the resiliency of\nransomware detection via the generative adversarial network (GAN). In this case\nstudy, we propose to use GAN to automatically produce dynamic features that\nexhibit generalized malicious behaviors that can reduce the efficacy of\nblack-box ransomware classifiers. We examine the quality of the GAN-generated\nsamples by comparing the statistical similarity of these samples to real\nransomware and benign software. Further we investigate the latent subspace\nwhere the GAN-generated samples lie and explore reasons why such samples cause\na certain class of ransomware classifiers to degrade in performance. Our focus\nis to emphasize necessary defense improvement in ML-based approaches for\nransomware detection before deployment in the wild. Our results and discoveries\nshould pose relevant questions for defenders such as how ML models can be made\nmore resilient for robust enforcement of security objectives.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 22:38:27 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 23:51:13 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Chen", "Li", ""], ["Yang", "Chih-Yuan", ""], ["Paul", "Anindya", ""], ["Sahita", "Ravi", ""]]}, {"id": "1812.09410", "submitter": "Janne Lindqvist", "authors": "Can Liu, Shridatt Sugrim, Gradeigh D. Clark, Janne Lindqvist", "title": "Quantifying the Security of Recognition Passwords: Gestures and\n  Signatures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gesture and signature passwords are two-dimensional figures created by\ndrawing on the surface of a touchscreen with one or more fingers. Prior results\nabout their security have used resilience to either shoulder surfing, a human\nobservation attack, or dictionary attacks. These evaluations restrict\ngeneralizability since the results are: non-comparable to other password\nsystems (e.g. PINs), harder to reproduce, and attacker-dependent. Strong\nstatements about the security of a password system use an analysis of the\nstatistical distribution of the password space, which models a best-case\nattacker who guesses passwords in order of most likely to least likely.\n  Estimating the distribution of recognition passwords is challenging because\nmany different trials need to map to one password. In this paper, we solve this\ndifficult problem by: (1) representing a recognition password of continuous\ndata as a discrete alphabet set, and (2) estimating the password distribution\nthrough modeling the unseen passwords. We use Symbolic Aggregate approXimation\n(SAX) to represent time series data as symbols and develop Markov chains to\nmodel recognition passwords. We use a partial guessing metric, which\ndemonstrates how many guesses an attacker needs to crack a percentage of the\nentire space, to compare the security of the distributions for gestures,\nsignatures, and Android unlock patterns. We found the lower bounds of the\npartial guessing metric of gestures and signatures are much higher than the\nupper bound of the partial guessing metric of Android unlock patterns.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 23:24:42 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Liu", "Can", ""], ["Sugrim", "Shridatt", ""], ["Clark", "Gradeigh D.", ""], ["Lindqvist", "Janne", ""]]}, {"id": "1812.09423", "submitter": "Matthew Bernhard", "authors": "Matthew Bernhard", "title": "Physical Cryptographic Signatures for Absentee Ballots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Physical signature verification on absentee ballots became a major flashpoint\nin the 2018 midterm elections in the United States, especially in states like\nGeorgia, Florida, and Arizona, where close election margins resulted in\nheightened attention to the counting of absentee ballots. As vote-by-mail\nsolutions are becoming more prevalent across the U.S., these issues are sure to\ncontinue affecting elections in the United States. Signature verification is an\ninexact science; often times guidelines can vary widely from jurisdiction to\njurisdiction. In this paper we provide a cryptographic remedy to this solution\nthat is usable, secure, and easily integrated into existing election\ninfrastructure.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2018 00:43:31 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Bernhard", "Matthew", ""]]}, {"id": "1812.09490", "submitter": "V\\'ictor Mayoral Vilches", "authors": "V\\'ictor Mayoral Vilches, Gorka Olalde Mendia, Xabier Perez Baskaran,\n  Alejandro Hern\\'andez Cordero, Lander Usategui San Juan, Endika Gil-Uriarte,\n  Odei Olalde Saez de Urabain and Laura Alzola Kirschgens", "title": "Aztarna, a footprinting tool for robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industry 4.0 is changing the commonly held assumption that robots are to be\ndeployed in closed and isolated networks. When analyzed from a security point\nof view, the global picture is disheartening: robotics industry has not\nseriously allocated effort to follow good security practices in the robots\nproduced. Instead, most manufacturers keep forwarding the problem to the\nend-users of these machines. As learned in previous technological revolutions,\nsuch as at the dawn of PCs or smartphones, action needs to be taken in time to\navoid disastrous consequences. In an attempt to provide the robotics and\nsecurity communities with the right tools to perform assessments, in this paper\nwe present aztarna, a footprinting tool for robotics. We discuss how such tool\ncan facilitate the process of identifying vestiges of different robots, while\nmaintaining an extensible structure aimed for future fingerprinting extensions.\nWith this contribution, we aim to raise awareness and interest of the robotics\ncommunity, robot manufacturers and robot end-users on the need of starting\nglobal actions to embrace security. We open source the tool and disclose\npreliminary results that demonstrate the current insecurity landscape in\nindustry. We argue that the robotic ecosystem is in need of generating a robot\nsecurity community, conscious about good practices and empowered by the right\ntools.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2018 09:59:16 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 11:14:10 GMT"}, {"version": "v3", "created": "Sat, 21 Sep 2019 06:42:10 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Vilches", "V\u00edctor Mayoral", ""], ["Mendia", "Gorka Olalde", ""], ["Baskaran", "Xabier Perez", ""], ["Cordero", "Alejandro Hern\u00e1ndez", ""], ["Juan", "Lander Usategui San", ""], ["Gil-Uriarte", "Endika", ""], ["de Urabain", "Odei Olalde Saez", ""], ["Kirschgens", "Laura Alzola", ""]]}, {"id": "1812.09492", "submitter": "V\\'ictor Mayoral Vilches", "authors": "V\\'ictor Mayoral Vilches, Laura Alzola Kirschgens, Endika Gil-Uriarte,\n  Alejandro Hern\\'andez and Bernhard Dieber", "title": "Volatile memory forensics for the Robot Operating System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing impact of robotics on industry and on society will unavoidably\nlead to the involvement of robots in incidents and mishaps. In such cases,\nforensic analyses are key techniques to provide useful evidence on what\nhappened, and try to prevent future incidents. This article discusses volatile\nmemory forensics for the Robot Operating System (ROS). The authors start by\nproviding a general overview of forensic techniques in robotics and then\npresent a robotics-specific Volatility plugin named linux_rosnode, packaged\nwithin the ros_volatility project and aimed to extract evidence from robot's\nvolatile memory. They demonstrate how this plugin can be used to detect a\nspecific attack pattern on ROS, where a publisher node is unregistered\nexternally, leading to denial of service and disruption of robotic behaviors.\nStep-by-step, common practices are introduced for performing forensic analysis\nand several techniques to capture memory are described. The authors finalize by\nintroducing some future remarks while providing references to reproduce their\nwork.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2018 10:08:05 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Vilches", "V\u00edctor Mayoral", ""], ["Kirschgens", "Laura Alzola", ""], ["Gil-Uriarte", "Endika", ""], ["Hern\u00e1ndez", "Alejandro", ""], ["Dieber", "Bernhard", ""]]}, {"id": "1812.09638", "submitter": "Fei Zuo", "authors": "Fei Zuo, Bokai Yang, Xiaopeng Li, Lannan Luo, Qiang Zeng", "title": "Exploiting the Inherent Limitation of L0 Adversarial Examples", "comments": "Accepted by the 22nd International Symposium on Research in Attacks,\n  Intrusions and Defenses (RAID 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the great achievements made by neural networks on tasks such as image\nclassification, they are brittle and vulnerable to adversarial example (AE)\nattacks, which are crafted by adding human-imperceptible perturbations to\ninputs in order that a neural-network-based classifier incorrectly labels them.\nIn particular, L0 AEs are a category of widely discussed threats where\nadversaries are restricted in the number of pixels that they can corrupt.\nHowever, our observation is that, while L0 attacks modify as few pixels as\npossible, they tend to cause large-amplitude perturbations to the modified\npixels. We consider this as an inherent limitation of L0 AEs, and thwart such\nattacks by both detecting and rectifying them. The main novelty of the proposed\ndetector is that we convert the AE detection problem into a comparison problem\nby exploiting the inherent limitation of L0 attacks. More concretely, given an\nimage I, it is pre-processed to obtain another image I' . A Siamese network,\nwhich is known to be effective in comparison, takes I and I' as the input pair\nto determine whether I is an AE. A trained Siamese network automatically and\nprecisely captures the discrepancies between I and I' to detect L0\nperturbations. In addition, we show that the pre-processing technique,\ninpainting, used for detection can also work as an effective defense, which has\na high probability of removing the adversarial influence of L0 perturbations.\nThus, our system, called AEPECKER, demonstrates not only high AE detection\naccuracies, but also a notable capability to correct the classification\nresults.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 02:25:34 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2019 16:30:10 GMT"}, {"version": "v3", "created": "Wed, 31 Jul 2019 02:11:24 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Zuo", "Fei", ""], ["Yang", "Bokai", ""], ["Li", "Xiaopeng", ""], ["Luo", "Lannan", ""], ["Zeng", "Qiang", ""]]}, {"id": "1812.09652", "submitter": "Lannan Luo", "authors": "Kimberly Redmond, Lannan Luo, Qiang Zeng", "title": "A Cross-Architecture Instruction Embedding Model for Natural Language\n  Processing-Inspired Binary Code Analysis", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a closed-source program, such as most of proprietary software and\nviruses, binary code analysis is indispensable for many tasks, such as code\nplagiarism detection and malware analysis. Today, source code is very often\ncompiled for various architectures, making cross-architecture binary code\nanalysis increasingly important. A binary, after being disassembled, is\nexpressed in an assembly languages. Thus, recent work starts exploring Natural\nLanguage Processing (NLP) inspired binary code analysis. In NLP, words are\nusually represented in high-dimensional vectors (i.e., embeddings) to\nfacilitate further processing, which is one of the most common and critical\nsteps in many NLP tasks. We regard instructions as words in NLP-inspired binary\ncode analysis, and aim to represent instructions as embeddings as well.\n  To facilitate cross-architecture binary code analysis, our goal is that\nsimilar instructions, regardless of their architectures, have embeddings close\nto each other. To this end, we propose a joint learning approach to generating\ninstruction embeddings that capture not only the semantics of instructions\nwithin an architecture, but also their semantic relationships across\narchitectures. To the best of our knowledge, this is the first work on building\ncross-architecture instruction embedding model. As a showcase, we apply the\nmodel to resolving one of the most fundamental problems for binary code\nsimilarity comparison---semantics-based basic block comparison, and the\nsolution outperforms the code statistics based approach. It demonstrates that\nit is promising to apply the model to other cross-architecture binary code\nanalysis tasks.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 03:44:03 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Redmond", "Kimberly", ""], ["Luo", "Lannan", ""], ["Zeng", "Qiang", ""]]}, {"id": "1812.09660", "submitter": "Sailik Sengupta", "authors": "Ankur Chowdhary, Sailik Sengupta, Dijiang Huang, Subbarao Kambhampati", "title": "Markov Game Modeling of Moving Target Defense for Strategic Detection of\n  Threats in Cloud Networks", "comments": "Author names marked with * contributed equally and are listed in\n  alphabetical order", "journal-ref": null, "doi": null, "report-no": "AICS/2019/01", "categories": "cs.AI cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The processing and storage of critical data in large-scale cloud networks\nnecessitate the need for scalable security solutions. It has been shown that\ndeploying all possible security measures incurs a cost on performance by using\nup valuable computing and networking resources which are the primary selling\npoints for cloud service providers. Thus, there has been a recent interest in\ndeveloping Moving Target Defense (MTD) mechanisms that helps one optimize the\njoint objective of maximizing security while ensuring that the impact on\nperformance is minimized. Often, these techniques model the problem of\nmulti-stage attacks by stealthy adversaries as a single-step attack detection\ngame using graph connectivity measures as a heuristic to measure performance,\nthereby (1) losing out on valuable information that is inherently present in\ngraph-theoretic models designed for large cloud networks, and (2) coming up\nwith certain strategies that have asymmetric impacts on performance. In this\nwork, we leverage knowledge in attack graphs of a cloud network in formulating\na zero-sum Markov Game and use the Common Vulnerability Scoring System (CVSS)\nto come up with meaningful utility values for this game. Then, we show that the\noptimal strategy of placing detecting mechanisms against an adversary is\nequivalent to computing the mixed Min-max Equilibrium of the Markov Game. We\ncompare the gains obtained by using our method to other techniques presently\nused in cloud network security, thereby showing its effectiveness. Finally, we\nhighlight how the method was used for a small real-world cloud system.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 05:16:23 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 01:26:02 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Chowdhary", "Ankur", ""], ["Sengupta", "Sailik", ""], ["Huang", "Dijiang", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "1812.09666", "submitter": "Sihem Mesnager", "authors": "Sihem Mesnager and Kwang Ho Kim and Dujin Jo and Junyop Choe and\n  Munhyon Han and Dok Nam Lee", "title": "A Proof of the Beierle-Kranz-Leander Conjecture related to Lightweight\n  Multiplication in $\\mathds{F}_{2^n}$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lightweight cryptography is a key tool for building strong security solutions\nfor pervasive devices with limited resources. Due to the stringent cost\nconstraints inherent in extremely large applications (ranging from RFIDs and\nsmart cards to mobile devices), the efficient implementation of cryptographic\nhardware and software algorithms is of utmost importance to realize the vision\nof generalized computing.\n  In CRYPTO 2016, Beierle, Kranz and Leander have considered lightweight\nmultiplication in $\\mathds{F}_{2^n}$. Specifically, they have considered the\nfundamental question of optimizing finite field multiplications with one fixed\nelement and investigated which field representation, that is which choice of\nbasis, allows for an optimal implementation. They have left open a conjecture\nrelated to two XOR-count. Using the theory of linear algebra, we prove in the\npresent paper that their conjecture is correct. Consequently, this proved\nconjecture can be used as a reference for further developing and implementing\ncryptography algorithms in lightweight devices.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 07:27:01 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Mesnager", "Sihem", ""], ["Kim", "Kwang Ho", ""], ["Jo", "Dujin", ""], ["Choe", "Junyop", ""], ["Han", "Munhyon", ""], ["Lee", "Dok Nam", ""]]}, {"id": "1812.09721", "submitter": "Nadezda Bogachenko", "authors": "N.F. Bogachenko", "title": "The Equivalent Conversions of the Role-Based Access Control Model", "comments": null, "journal-ref": "CEUR Workshop Proceedings. 2017. Vol. 2081 (Selected Papers of the\n  VIII All-Russian Scientific and Technical Conference on Secure Information\n  Technologies, BIT 2017). P. 11-14", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The problems which are important for the effective functioning of an access\ncontrol policy in a large information system (LIS) are selected. The general\nconcept of a local optimization of a role-based access control (RBAC) model is\nformulated. The optimization criteria are proposed. The algorithms of a local\noptimization of the RBAC model are defined and justified. The developed\nalgorithms are used in the methods of the solution of the following problems:\nthe assessment of risks of the leakage of permissions in the RBAC policy, the\naccess control in the distributed hierarchical systems, the combining of\nrole-based and mandatory access control models. In the first problem the\nquestion of the permissions distribution in the role hierarchy is researched.\nThe analytic hierarchy process (AHP) is applied to creation of the estimates.\nThe method is based on the hierarchical structure of a role set. The offered\ntechnique can order the permissions according to the value of the risks of\ntheir leakage. In the second problem the algorithm of the distribution of the\ncryptographic keys in the system with a hierarchical arrangement of the objects\nis offered. The cryptography protocols for the practical use of this algorithm\nare defined. The conditions of the implementation of the discretionary and\nmandatory principles of the access control on the basis of the developed\nalgorithm are formulated.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 14:49:42 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Bogachenko", "N. F.", ""]]}, {"id": "1812.09790", "submitter": "Mehdi Zakroum", "authors": "Mehdi Zakroum, Abdellah Houmz, Mounir Ghogho, Ghita Mezzour,\n  Abdelkader Lahmadi, J\\'er\\^ome Fran\\c{c}ois and Mohammed El Koutbi", "title": "Exploratory Data Analysis of a Network Telescope Traffic and Prediction\n  of Port Probing Rates", "comments": "IEEE Intelligence and Security Informatics", "journal-ref": null, "doi": "10.1109/ISI.2018.8587323", "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the properties exhibited by large scale network probing traffic\nwould improve cyber threat intelligence. In addition, the prediction of probing\nrates is a key feature for security practitioners in their endeavors for making\nbetter operational decisions and for enhancing their defense strategy skills.\nIn this work, we study different aspects of the traffic captured by a /20\nnetwork telescope. First, we perform an exploratory data analysis of the\ncollected probing activities. The investigation includes probing rates at the\nport level, services interesting top network probers and the distribution of\nprobing rates by geolocation. Second, we extract the network probers\nexploration patterns. We model these behaviors using transition graphs\ndecorated with probabilities of switching from a port to another. Finally, we\nassess the capacity of Non-stationary Autoregressive and Vector Autoregressive\nmodels in predicting port probing rates as a first step towards using more\nrobust models for better forecasting performance.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2018 22:46:50 GMT"}, {"version": "v2", "created": "Sat, 27 Apr 2019 11:23:30 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Zakroum", "Mehdi", ""], ["Houmz", "Abdellah", ""], ["Ghogho", "Mounir", ""], ["Mezzour", "Ghita", ""], ["Lahmadi", "Abdelkader", ""], ["Fran\u00e7ois", "J\u00e9r\u00f4me", ""], ["Koutbi", "Mohammed El", ""]]}, {"id": "1812.09803", "submitter": "Thomas Brunner", "authors": "Thomas Brunner, Frederik Diehl, Michael Truong Le, Alois Knoll", "title": "Guessing Smart: Biased Sampling for Efficient Black-Box Adversarial\n  Attacks", "comments": "For source code and videos, see\n  https://github.com/ttbrunner/biased_boundary_attack", "journal-ref": null, "doi": "10.1109/ICCV.2019.00506", "report-no": null, "categories": "stat.ML cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider adversarial examples for image classification in the black-box\ndecision-based setting. Here, an attacker cannot access confidence scores, but\nonly the final label. Most attacks for this scenario are either unreliable or\ninefficient. Focusing on the latter, we show that a specific class of attacks,\nBoundary Attacks, can be reinterpreted as a biased sampling framework that\ngains efficiency from domain knowledge. We identify three such biases, image\nfrequency, regional masks and surrogate gradients, and evaluate their\nperformance against an ImageNet classifier. We show that the combination of\nthese biases outperforms the state of the art by a wide margin. We also\nshowcase an efficient way to attack the Google Cloud Vision API, where we craft\nconvincing perturbations with just a few hundred queries. Finally, the methods\nwe propose have also been found to work very well against strong defenses: Our\ntargeted attack won second place in the NeurIPS 2018 Adversarial Vision\nChallenge.\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2018 00:48:31 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 13:39:59 GMT"}, {"version": "v3", "created": "Sun, 5 May 2019 13:05:16 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Brunner", "Thomas", ""], ["Diehl", "Frederik", ""], ["Le", "Michael Truong", ""], ["Knoll", "Alois", ""]]}, {"id": "1812.09822", "submitter": "Srinivas Devadas", "authors": "Thomas Bourgeat, Ilia Lebedev, Andrew Wright, Sizhuo Zhang, Arvind,\n  Srinivas Devadas", "title": "MI6: Secure Enclaves in a Speculative Out-of-Order Processor", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent attacks have broken process isolation by exploiting microarchitectural\nside channels that allow indirect access to shared microarchitectural state.\nEnclaves strengthen the process abstraction to restore isolation guarantees.\n  We propose MI6, an aggressive, speculative out-of-order processor capable of\nproviding secure enclaves under a threat model that includes an untrusted OS\nand an attacker capable of mounting any software attack currently considered\npractical, including control flow speculation attacks. MI6 is inspired by\nSanctum [16] and extends its isolation guarantee to more realistic memory\nhierarchies. It also introduces a purge instruction, which is used only when a\nsecure process is scheduled, and implements it for a complex processor\nmicroarchitecture. We model the performance impact of enclaves in MI6 through\nFPGA emulation on AWS F1 FPGAs by running SPEC CINT2006 benchmarks on top of an\nuntrusted Linux OS. Security comes at the cost of approximately 16.4% average\nslowdown for protected programs.\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2018 03:55:32 GMT"}, {"version": "v2", "created": "Sat, 16 Feb 2019 02:33:11 GMT"}, {"version": "v3", "created": "Fri, 26 Jul 2019 03:23:13 GMT"}, {"version": "v4", "created": "Sat, 3 Aug 2019 02:13:34 GMT"}, {"version": "v5", "created": "Thu, 29 Aug 2019 04:53:09 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Bourgeat", "Thomas", ""], ["Lebedev", "Ilia", ""], ["Wright", "Andrew", ""], ["Zhang", "Sizhuo", ""], ["Arvind", "", ""], ["Devadas", "Srinivas", ""]]}, {"id": "1812.09920", "submitter": "Igor Korkin", "authors": "Igor Korkin", "title": "Divide et Impera: MemoryRanger Runs Drivers in Isolated Kernel Spaces", "comments": "Korkin, I. (2018, December 5-6). Divide et Impera: MemoryRanger Runs\n  Drivers in Isolated Kernel Spaces. In Proceedings of the BlackHat Europe\n  Conference, London, UK. 23 pages, 4 figures, 2 tables, 49 references.\n  Retrieved from\n  https://www.blackhat.com/eu-18/briefings/schedule/#divide-et-impera-memoryranger-runs-drivers-in-isolated-kernel-spaces-12668", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main issues in the OS security is to provide trusted code\nexecution in an untrusted environment. During executing, kernel-mode drivers\nallocate and process memory data: OS internal structures, users private\ninformation, and sensitive data of third-party drivers. All this data and the\ndrivers code can be tampered with by kernel-mode malware. Microsoft security\nexperts integrated new features to fill this gap, but they are not enough:\nallocated data can be stolen and patched and the drivers code can be dumped\nwithout any security reaction. The proposed hypervisor-based system\n(MemoryRanger) tackles this issue by executing drivers in separate kernel\nenclaves with specific memory attributes. MemoryRanger protects code and data\nusing Intel VT-x and EPT features with low performance degradation on Windows\n10 x64.\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2018 13:30:40 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Korkin", "Igor", ""]]}, {"id": "1812.09940", "submitter": "Federico Spini", "authors": "Marco Conoscenti, Antonio Vetr\\`o, Juan Carlos De Martin, Federico\n  Spini, Fabio Castaldo, Sebastiano Scr\\`ofina", "title": "CLoTH: a Simulator for HTLC Payment Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Lightning Network (LN) is one of the most promising off-chain scaling\nsolutions for Bitcoin, as it enables off-chain payments which are not subject\nto the well-known blockchain scalability limit. In this work, we introduce\nCLoTH, a simulator for HTLC payment networks, of which LN is the best working\nexample. It simulates input-defined payments on an input-defined HTLC network\nand produces performance measures in terms of payment-related statistics, such\nas time to complete payments and probability of payment failure. CLoTH helps to\npredict issues that might arise in the development of an HTLC payment network,\nand to estimate the effects of an optimisation before deploying it. In upcoming\nworks we'll publish the results of CLoTH simulations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2018 15:37:21 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Conoscenti", "Marco", ""], ["Vetr\u00f2", "Antonio", ""], ["De Martin", "Juan Carlos", ""], ["Spini", "Federico", ""], ["Castaldo", "Fabio", ""], ["Scr\u00f2fina", "Sebastiano", ""]]}, {"id": "1812.09966", "submitter": "Carlos Sarraute", "authors": "Matias Travizano, Carlos Sarraute, Gustavo Ajzenman, Martin Minnoni", "title": "Wibson: A Decentralized Data Marketplace", "comments": "SIGBPS 2018 Workshop on Blockchain and Smart Contract. December 13,\n  2018, San Francisco, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Our aim is for Wibson to be a blockchain-based, decentralized data\nmarketplace that provides individuals a way to securely and anonymously sell\ninformation in a trusted environment. The combination of the Wibson token and\nblockchain-enabled smart contracts hopes to allow Data Sellers and Data Buyers\nto transact with each other directly while providing individuals the ability to\nmaintain anonymity as desired.\n  Wibson intends that its data marketplace will provide infrastructure and\nfinancial incentives for individuals to securely sell personal information\nwithout sacrificing personal privacy. Data Buyers receive information from\nwilling and actively participating individuals with the benefit of knowing that\nthe personal information should be accurate and current.\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2018 18:45:37 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Travizano", "Matias", ""], ["Sarraute", "Carlos", ""], ["Ajzenman", "Gustavo", ""], ["Minnoni", "Martin", ""]]}, {"id": "1812.10049", "submitter": "Mehdi Jafarnia-Jahromi", "authors": "Mehdi Jafarnia-Jahromi, Tasmin Chowdhury, Hsin-Tai Wu, Sayandev\n  Mukherjee", "title": "PPD: Permutation Phase Defense Against Adversarial Examples in Deep\n  Learning", "comments": "Code is added. Small revisions made", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have demonstrated cutting edge performance on various\ntasks including classification. However, it is well known that adversarially\ndesigned imperceptible perturbation of the input can mislead advanced\nclassifiers. In this paper, Permutation Phase Defense (PPD), is proposed as a\nnovel method to resist adversarial attacks. PPD combines random permutation of\nthe image with phase component of its Fourier transform. The basic idea behind\nthis approach is to turn adversarial defense problems analogously into\nsymmetric cryptography, which relies solely on safekeeping of the keys for\nsecurity. In PPD, safe keeping of the selected permutation ensures\neffectiveness against adversarial attacks. Testing PPD on MNIST and CIFAR-10\ndatasets yielded state-of-the-art robustness against the most powerful\nadversarial attacks currently available.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2018 06:17:54 GMT"}, {"version": "v2", "created": "Sat, 4 Jan 2020 08:24:04 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Jafarnia-Jahromi", "Mehdi", ""], ["Chowdhury", "Tasmin", ""], ["Wu", "Hsin-Tai", ""], ["Mukherjee", "Sayandev", ""]]}, {"id": "1812.10061", "submitter": "Krishan Rajaratnam", "authors": "Krishan Rajaratnam and Jugal Kalita", "title": "Noise Flooding for Detecting Audio Adversarial Examples Against\n  Automatic Speech Recognition", "comments": "Orally presented at the 18th IEEE International Symposium on Signal\n  Processing and Information Technology (ISSPIT) in Louisville, Kentucky, USA,\n  December 2018. 5 pages, 2 figures", "journal-ref": null, "doi": "10.1109/ISSPIT.2018.8642623", "report-no": null, "categories": "cs.SD cs.CL cs.CR cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural models enjoy widespread use across a variety of tasks and have grown\nto become crucial components of many industrial systems. Despite their\neffectiveness and extensive popularity, they are not without their exploitable\nflaws. Initially applied to computer vision systems, the generation of\nadversarial examples is a process in which seemingly imperceptible\nperturbations are made to an image, with the purpose of inducing a deep\nlearning based classifier to misclassify the image. Due to recent trends in\nspeech processing, this has become a noticeable issue in speech recognition\nmodels. In late 2017, an attack was shown to be quite effective against the\nSpeech Commands classification model. Limited-vocabulary speech classifiers,\nsuch as the Speech Commands model, are used quite frequently in a variety of\napplications, particularly in managing automated attendants in telephony\ncontexts. As such, adversarial examples produced by this attack could have\nreal-world consequences. While previous work in defending against these\nadversarial examples has investigated using audio preprocessing to reduce or\ndistort adversarial noise, this work explores the idea of flooding particular\nfrequency bands of an audio signal with random noise in order to detect\nadversarial examples. This technique of flooding, which does not require\nretraining or modifying the model, is inspired by work done in computer vision\nand builds on the idea that speech classifiers are relatively robust to natural\nnoise. A combined defense incorporating 5 different frequency bands for\nflooding the signal with noise outperformed other existing defenses in the\naudio space, detecting adversarial examples with 91.8% precision and 93.5%\nrecall.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2018 08:02:01 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Rajaratnam", "Krishan", ""], ["Kalita", "Jugal", ""]]}, {"id": "1812.10113", "submitter": "Lingchen Zhao", "authors": "Lingchen Zhao, Qian Wang, Qin Zou, Yan Zhang and Yanjiao Chen", "title": "Privacy-Preserving Collaborative Deep Learning with Unreliable\n  Participants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With powerful parallel computing GPUs and massive user data,\nneural-network-based deep learning can well exert its strong power in problem\nmodeling and solving, and has archived great success in many applications such\nas image classification, speech recognition and machine translation etc. While\ndeep learning has been increasingly popular, the problem of privacy leakage\nbecomes more and more urgent. Given the fact that the training data may contain\nhighly sensitive information, e.g., personal medical records, directly sharing\nthem among the users (i.e., participants) or centrally storing them in one\nsingle location may pose a considerable threat to user privacy.\n  In this paper, we present a practical privacy-preserving collaborative deep\nlearning system that allows users to cooperatively build a collective deep\nlearning model with data of all participants, without direct data sharing and\ncentral data storage. In our system, each participant trains a local model with\ntheir own data and only shares model parameters with the others. To further\navoid potential privacy leakage from sharing model parameters, we use\nfunctional mechanism to perturb the objective function of the neural network in\nthe training process to achieve $\\epsilon$-differential privacy. In particular,\nfor the first time, we consider the existence of~\\textit{unreliable\nparticipants}, i.e., the participants with low-quality data, and propose a\nsolution to reduce the impact of these participants while protecting their\nprivacy. We evaluate the performance of our system on two well-known real-world\ndatasets for regression and classification tasks. The results demonstrate that\nthe proposed system is robust against unreliable participants, and achieves\nhigh accuracy close to the model trained in a traditional centralized manner\nwhile ensuring rigorous privacy protection.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2018 14:46:46 GMT"}, {"version": "v2", "created": "Sat, 12 Oct 2019 02:08:22 GMT"}, {"version": "v3", "created": "Fri, 25 Oct 2019 06:50:05 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Zhao", "Lingchen", ""], ["Wang", "Qian", ""], ["Zou", "Qin", ""], ["Zhang", "Yan", ""], ["Chen", "Yanjiao", ""]]}, {"id": "1812.10193", "submitter": "Aria Rezaei", "authors": "Aria Rezaei, Chaowei Xiao, Jie Gao, Bo Li, Sirajum Munir", "title": "Application-driven Privacy-preserving Data Publishing with Correlated\n  Attributes", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in computing have allowed for the possibility to collect\nlarge amounts of data on personal activities and private living spaces. To\naddress the privacy concerns of users in this environment, we propose a novel\nframework called PR-GAN that offers privacy-preserving mechanism using\ngenerative adversarial networks. Given a target application, PR-GAN\nautomatically modifies the data to hide sensitive attributes -- which may be\nhidden and can be inferred by machine learning algorithms -- while preserving\nthe data utility in the target application. Unlike prior works, the public's\npossible knowledge of the correlation between the target application and\nsensitive attributes is built into our modeling. We formulate our problem as an\noptimization problem, show that an optimal solution exists and use generative\nadversarial networks (GAN) to create perturbations. We further show that our\nmethod provides privacy guarantees under the Pufferfish framework, an elegant\ngeneralization of the differential privacy that allows for the modeling of\nprior knowledge on data and correlations. Through experiments, we show that our\nmethod outperforms conventional methods in effectively hiding the sensitive\nattributes while guaranteeing high performance in the target application, for\nboth property inference and training purposes. Finally, we demonstrate through\nfurther experiments that once our model learns a privacy-preserving task, such\nas hiding subjects' identity, on a group of individuals, it can perform the\nsame task on a separate group with minimal performance drops.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 01:01:16 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 02:43:15 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Rezaei", "Aria", ""], ["Xiao", "Chaowei", ""], ["Gao", "Jie", ""], ["Li", "Bo", ""], ["Munir", "Sirajum", ""]]}, {"id": "1812.10199", "submitter": "Lannan Luo", "authors": "Qiang Zeng, Jianhai Su, Chenglong Fu, Golam Kayas, Lannan Luo", "title": "A Multiversion Programming Inspired Approach to Detecting Audio\n  Adversarial Examples", "comments": "8 pages, 4 figures, AICS 2019, The AAAI-19 Workshop on Artificial\n  Intelligence for Cyber Security (AICS), 2019", "journal-ref": "The AAAI-19 Workshop on Artificial Intelligence for Cyber Security\n  (AICS), 2019", "doi": null, "report-no": "AICS/2019/06", "categories": "cs.SD cs.CR eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples (AEs) are crafted by adding human-imperceptible\nperturbations to inputs such that a machine-learning based classifier\nincorrectly labels them. They have become a severe threat to the\ntrustworthiness of machine learning. While AEs in the image domain have been\nwell studied, audio AEs are less investigated. Recently, multiple techniques\nare proposed to generate audio AEs, which makes countermeasures against them an\nurgent task. Our experiments show that, given an AE, the transcription results\nby different Automatic Speech Recognition (ASR) systems differ significantly,\nas they use different architectures, parameters, and training datasets.\nInspired by Multiversion Programming, we propose a novel audio AE detection\napproach, which utilizes multiple off-the-shelf ASR systems to determine\nwhether an audio input is an AE. The evaluation shows that the detection\nachieves accuracies over 98.6%.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 01:46:53 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 19:51:36 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Zeng", "Qiang", ""], ["Su", "Jianhai", ""], ["Fu", "Chenglong", ""], ["Kayas", "Golam", ""], ["Luo", "Lannan", ""]]}, {"id": "1812.10217", "submitter": "Yue Zhao", "authors": "Yue Zhao, Hong Zhu, Ruigang Liang, Qintao Shen, Shengzhi Zhang, Kai\n  Chen", "title": "Seeing isn't Believing: Practical Adversarial Attack Against Object\n  Detectors", "comments": "13 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we presented systematic solutions to build robust and\npractical AEs against real world object detectors. Particularly, for Hiding\nAttack (HA), we proposed the feature-interference reinforcement (FIR) method\nand the enhanced realistic constraints generation (ERG) to enhance robustness,\nand for Appearing Attack (AA), we proposed the nested-AE, which combines two\nAEs together to attack object detectors in both long and short distance. We\nalso designed diverse styles of AEs to make AA more surreptitious. Evaluation\nresults show that our AEs can attack the state-of-the-art real-time object\ndetectors (i.e., YOLO V3 and faster-RCNN) at the success rate up to 92.4% with\nvarying distance from 1m to 25m and angles from -60{\\deg} to 60{\\deg}. Our AEs\nare also demonstrated to be highly transferable, capable of attacking another\nthree state-of-the-art black-box models with high success rate.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 04:14:08 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 01:26:10 GMT"}, {"version": "v3", "created": "Wed, 4 Sep 2019 08:54:39 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Zhao", "Yue", ""], ["Zhu", "Hong", ""], ["Liang", "Ruigang", ""], ["Shen", "Qintao", ""], ["Zhang", "Shengzhi", ""], ["Chen", "Kai", ""]]}, {"id": "1812.10327", "submitter": "ElMouatez Billah Karbab", "authors": "ElMouatez Billah Karbab, Mourad Debbabi", "title": "Portable, Data-Driven Malware Detection using Language Processing and\n  Machine Learning Techniques on Behavioral Analysis Reports", "comments": "13 pages, Research report Corrected typos. Revised arguments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In response to the volume and sophistication of malicious software or\nmalware, security investigators rely on dynamic analysis for malware detection\nto thwart obfuscation and packing issues. Dynamic analysis is the process of\nexecuting binary samples to produce reports that summarise their runtime\nbehaviors. The investigator uses these reports to detect malware and attribute\nthreat type leveraging manually chosen features. However, the diversity of\nmalware and the execution environments makes manual approaches not scalable\nbecause the investigator needs to manually engineer fingerprinting features for\nnew environments. In this paper, we propose, MalDy (mal~die), a portable (plug\nand play) malware detection and family threat attribution framework using\nsupervised machine learning techniques. The key idea of MalDy portability is\nthe modeling of the behavioral reports into a sequence of words, along with\nadvanced natural language processing (NLP) and machine learning (ML) techniques\nfor automatic engineering of relevant security features to detect and attribute\nmalware without the investigator intervention. More precisely, we propose to\nuse bag-of-words (BoW) NLP model to formulate the behavioral reports.\nAfterward, we build ML ensembles on top of BoW features. We extensively\nevaluate MalDy on various datasets from different platforms (Android and Win32)\nand execution environments. The evaluation shows the effectiveness and the\nportability MalDy across the spectrum of the analyses and settings.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 14:29:52 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2019 00:15:24 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Karbab", "ElMouatez Billah", ""], ["Debbabi", "Mourad", ""]]}, {"id": "1812.10334", "submitter": "Sergey Belim", "authors": "S.V. Belim, S.Yu. Belim", "title": "Implementation of Simplex Channels in the Blom's Keys Pre-Distribution\n  Scheme", "comments": null, "journal-ref": null, "doi": "10.1088/1742-6596/1210/1/012008", "report-no": null, "categories": "cs.CR cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In article the modification of the Blom's keys preliminary distribution\nscheme, considering the direction of information streams is suggested. For this\nmodification it is necessary to use function from three variables. Function of\nformation of key materials will be the asymmetrical. The exponential form of\nthis function which does not increase the volume of key materials is suggested.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 14:56:48 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Belim", "S. V.", ""], ["Belim", "S. Yu.", ""]]}, {"id": "1812.10345", "submitter": "Christopher Hannon", "authors": "Christopher Hannon and Dong Jin", "title": "Bitcoin Payment-channels for Resource Limited IoT Devices", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resource-constrained devices are unable to maintain a full copy of the\nBitcoin Blockchain in memory. This paper proposes a bidirectional payment\nchannel framework for IoT devices. This framework utilizes Bitcoin\nLightning-Network-like payment channels with low processing and storage\nrequirements. This protocol enables IoT devices to open and maintain payment\nchannels with traditional Bitcoin nodes without a view of the blockchain.\nUnlike existing solutions, it does not require a trusted third party to\ninteract with the blockchain nor does it burden the peer-to-peer network in the\nway SPV clients do. The contribution of this paper includes a secure and\ncrypto-economically fair protocol for bidirectional Bitcoin payment channels.\nIn addition, we demonstrate the security and fairness of the protocol by\nformulating it as a game in which the equilibrium is reached when all players\nfollow the protocol.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 15:41:20 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Hannon", "Christopher", ""], ["Jin", "Dong", ""]]}, {"id": "1812.10360", "submitter": "Abdelmonim Naway", "authors": "Abdelmonim Naway, Yuancheng LI", "title": "A Review on The Use of Deep Learning in Android Malware Detection", "comments": "15 pages, 4 tables", "journal-ref": "International Journal of Computer Science and Mobile Computing,\n  Vol.7 Issue.12, December- 2018, pg. 42-58", "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Android is the predominant mobile operating system for the past few years.\nThe prevalence of devices that can be powered by Android magnetized not merely\napplication developers but also malware developers with criminal intention to\ndesign and spread malicious applications that can affect the normal work of\nAndroid phones and tablets, steal personal information and credential data, or\neven worse lock the phone and ask for ransom. Researchers persistently devise\ncountermeasures strategies to fight back malware. One of these strategies\napplied in the past five years is the use of deep learning methods in Android\nmalware detection. This necessitates a review to inspect the accomplished work\nin order to know where the endeavors have been established, identify unresolved\nproblems, and motivate future research directions. In this work, an extensive\nsurvey of static analysis, dynamic analysis, and hybrid analysis that utilized\ndeep learning methods are reviewed with an elaborated discussion on their key\nconcepts, contributions, and limitations.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 16:18:51 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Naway", "Abdelmonim", ""], ["LI", "Yuancheng", ""]]}, {"id": "1812.10427", "submitter": "Erivelton Geraldo Nepomuceno", "authors": "L. G. Nardo, A. M. Lima, E. G. Nepomuceno, J. Arias-Garcia", "title": "Image Encryption Algorithm Using Natural Interval Extensions", "comments": "BTSym'18 - Brazilian Techonology Symposium, 2018, Campinas. 5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that chaotic systems have widely been used in cryptography.\nGenerally, floating point simulations are used to generate pseudo-random\nsequence of numbers. Although, it is possible to find some works on the\ndegradation of chaotic systems due to finite precision of digital computers,\nlittle attention has been paid to exploit this limitation to formulate\nefficient process for image encode. This article proposes a novel image\nencryption method using natural interval extensions. The sequence of arithmetic\noperations is different in each natural interval extension. This is what we\nneed to produce two different sequences; the difference between these sequences\nis used to generate the lower bound error, which has been shown to present\nsatisfactory pseudo-random properties. The approach has been successfully\ntested using the Chua's circuit as the chaotic system. The secret key has\npresented good properties for encrypting the Lena image.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 17:38:08 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Nardo", "L. G.", ""], ["Lima", "A. M.", ""], ["Nepomuceno", "E. G.", ""], ["Arias-Garcia", "J.", ""]]}, {"id": "1812.10450", "submitter": "Sergey Belim", "authors": "S.V. Belim, S.Yu. Belim", "title": "Use the Keys Pre-Distribution KDP-scheme for Mandatory Access Control\n  Implementation", "comments": null, "journal-ref": null, "doi": "10.1088/1742-6596/1210/1/012009", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The possibility of use the keys preliminary distribution KDP-scheme for\nmandatory access control realization in the distributed systems with user's\nhierarchy is considered. The modified keys preliminary distribution algorithm\nis suggested. It is developed a method for creation of subsets family for\nsolution this task.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 18:31:35 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Belim", "S. V.", ""], ["Belim", "S. Yu.", ""]]}, {"id": "1812.10528", "submitter": "Lichao Sun", "authors": "Lichao Sun, Yingtong Dou, Carl Yang, Ji Wang, Philip S. Yu, Lifang He,\n  Bo Li", "title": "Adversarial Attack and Defense on Graph Data: A Survey", "comments": "In submission to Journal. For more open-source and up-to-date\n  information, please check our Github repository:\n  https://github.com/YingtongDou/graph-adversarial-learning-literature", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have been widely applied to various applications\nincluding image classification, text generation, audio recognition, and graph\ndata analysis. However, recent studies have shown that DNNs are vulnerable to\nadversarial attacks. Though there are several works studying adversarial attack\nand defense strategies on domains such as images and natural language\nprocessing, it is still difficult to directly transfer the learned knowledge to\ngraph structure data due to its representation challenges. Given the importance\nof graph analysis, an increasing number of works start to analyze the\nrobustness of machine learning models on graph data. Nevertheless, current\nstudies considering adversarial behaviors on graph data usually focus on\nspecific types of attacks with certain assumptions. In addition, each work\nproposes its own mathematical formulation which makes the comparison among\ndifferent methods difficult. Therefore, in this paper, we aim to survey\nexisting adversarial learning strategies on graph data and first provide a\nunified formulation for adversarial learning on graph data which covers most\nadversarial learning studies on graph. Moreover, we also compare different\nattacks and defenses on graph data and discuss their corresponding\ncontributions and limitations. In this work, we systemically organize the\nconsidered works based on the features of each topic. This survey not only\nserves as a reference for the research community, but also brings a clear image\nresearchers outside this research domain. Besides, we also create an online\nresource and keep updating the relevant papers during the last two years. More\ndetails of the comparisons of various studies based on this survey are\nopen-sourced at\nhttps://github.com/YingtongDou/graph-adversarial-learning-literature.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 20:27:42 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 03:49:29 GMT"}, {"version": "v3", "created": "Tue, 14 Jul 2020 22:11:52 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Sun", "Lichao", ""], ["Dou", "Yingtong", ""], ["Yang", "Carl", ""], ["Wang", "Ji", ""], ["Yu", "Philip S.", ""], ["He", "Lifang", ""], ["Li", "Bo", ""]]}, {"id": "1812.10605", "submitter": "Ilia Lebedev", "authors": "Ilia Lebedev and Kyle Hogan and Jules Drean and David Kohlbrenner and\n  Dayeol Lee and Krste Asanovi\\'c and Dawn Song and Srinivas Devadas", "title": "Sanctorum: A lightweight security monitor for secure enclaves", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enclaves have emerged as a particularly compelling primitive to implement\ntrusted execution environments: strongly isolated sensitive user-mode processes\nin a largely untrusted software environment. While the threat models employed\nby various enclave systems differ, the high-level guarantees they offer are\nessentially the same: attestation of an enclave's initial state, as well as a\nguarantee of enclave integrity and privacy in the presence of an adversary.\n  This work describes Sanctorum, a small trusted code base (TCB), consisting of\na generic enclave-capable system, which is sufficient to implement secure\nenclaves akin to the primitive offered by Intel's SGX. While enclaves may be\nimplemented via unconditionally trusted hardware and microcode, as it is the\ncase in SGX, we employ a smaller TCB principally consisting of authenticated,\nprivileged software, which may be replaced or patched as needed. Sanctorum\nimplements a formally verified specification for generic enclaves on an\nin-order multiprocessor system meeting baseline security requirements, e.g.,\nthe MIT Sanctum processor and the Keystone enclave framework. Sanctorum\nrequires trustworthy hardware including a random number generator, a private\ncryptographic key pair derived via a secure bootstrapping protocol, and a\nrobust isolation primitive to safeguard sensitive information. Sanctorum's\nthreat model is informed by the threat model of the isolation primitive, and is\nsuitable for adding enclaves to a variety of processor systems.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 03:15:30 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Lebedev", "Ilia", ""], ["Hogan", "Kyle", ""], ["Drean", "Jules", ""], ["Kohlbrenner", "David", ""], ["Lee", "Dayeol", ""], ["Asanovi\u0107", "Krste", ""], ["Song", "Dawn", ""], ["Devadas", "Srinivas", ""]]}, {"id": "1812.10729", "submitter": "Olga Gadyatskaya", "authors": "Aleksandr Pilgun, Olga Gadyatskaya, Stanislav Dashevskyi, Yury\n  Zhauniarovich and Artsiom Kushniarou", "title": "Fine-grained Code Coverage Measurement in Automated Black-box Android\n  Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, there are millions of third-party Android applications. Some of these\napplications are buggy or even malicious. To identify such applications, novel\nframeworks for automated black-box testing and dynamic analysis are being\ndeveloped by the Android community, including Google. Code coverage is one of\nthe most common metrics for evaluating effectiveness of these frameworks.\nFurthermore, code coverage is used as a fitness function for guiding\nevolutionary and fuzzy testing techniques. However, there are no reliable tools\nfor measuring fine-grained code coverage in black-box Android app testing.\n  We present the Android Code coVerage Tool, ACVTool for short, that\ninstruments Android apps and measures the code coverage in the black-box\nsetting at the class, method and instruction granularities. ACVTool has\nsuccessfully instrumented 96.9% of apps in our experiments. It introduces a\nnegligible instrumentation time overhead, and its runtime overhead is\nacceptable for automated testing tools. We show in a large-scale experiment\nwith Sapienz, a state-of-art testing tool, that the fine-grained\ninstruction-level code coverage provided by ACVTool helps to uncover a larger\namount of faults than coarser-grained code coverage metrics.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 14:20:42 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Pilgun", "Aleksandr", ""], ["Gadyatskaya", "Olga", ""], ["Dashevskyi", "Stanislav", ""], ["Zhauniarovich", "Yury", ""], ["Kushniarou", "Artsiom", ""]]}, {"id": "1812.10748", "submitter": "Stavros Nikolopoulos D.", "authors": "Anna Mpanti and Stavros D. Nikolopoulos and Iosif Polenakis", "title": "Malicious Software Detection and Classification utilizing\n  Temporal-Graphs of System-call Group Relations", "comments": "23 pages, 15 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a graph-based model that, utilizing relations between\ngroups of System-calls, distinguishes malicious from benign software samples\nand classifies the detected malicious samples to one of a set of known malware\nfamilies. More precisely, given a System-call Dependency Graph (ScDG) that\ndepicts the malware's behavior, we first transform it to a more abstract\nrepresentation, utilizing the indexing of System-calls to a set of groups of\nsimilar functionality, constructing thus an abstract and mutation-tolerant\ngraph that we call Group Relation Graph (GrG); then, we construct another graph\nrepresentation, which we call Coverage Graph (CvG), that depicts the dominating\nrelations between the nodes of a GrG graph. Based on the research so far in the\nfield, we pointed out that behavior-based graph representations had not\nleveraged the aspect of the temporal evolution of the graph. Hence, the novelty\nof our work is that, preserving the initial representations of GrG and CvG\ngraphs, we focus on augmenting the potentials of theses graphs by adding\nfurther features that enhance its abilities on detecting and further\nclassifying to a known malware family an unknown malware sample. To that end,\nwe construct periodical instances of the graph that represent its temporal\nevolution concerning its structural modifications, creating another graph\nrepresentation that we call Temporal Graphs. In this paper, we present the\ntheoretical background behind our approach, discuss the current technological\nstatus on malware detection and classification and demonstrate the overall\narchitecture of our proposed detection and classification model alongside with\nits underlying main principles and its structural key-components.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 15:56:07 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Mpanti", "Anna", ""], ["Nikolopoulos", "Stavros D.", ""], ["Polenakis", "Iosif", ""]]}, {"id": "1812.10754", "submitter": "Olga Gadyatskaya", "authors": "Ahto Buldas, Olga Gadyatskaya, Aleksandr Lenin, Sjouke Mauw and\n  Rolando Trujillo-Rasua", "title": "Attribute Evaluation on Attack Trees with Incomplete Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attack trees are considered a useful tool for security modelling because they\nsupport qualitative as well as quantitative analysis. The quantitative approach\nis based on values associated to each node in the tree, expressing, for\ninstance, the minimal cost or probability of an attack. Current quantitative\nmethods for attack trees allow the analyst to, based on an initial assignment\nof values to the leaf nodes, derive the values of the higher nodes in the tree.\nIn practice, however, it shows to be very difficult to obtain reliable values\nfor all leaf nodes. The main reasons are that data is only available for some\nof the nodes, that data is available for intermediate nodes rather than for the\nleaf nodes, or even that the available data is inconsistent. We address these\nproblems by developing a generalisation of the standard bottom-up calculation\nmethod in three ways. First, we allow initial attributions of non-leaf nodes.\nSecond, we admit additional relations between attack steps beyond those\nprovided by the underlying attack tree semantics. Third, we support the\ncalculation of an approximative solution in case of inconsistencies. We\nillustrate our method, which is based on constraint programming, by a\ncomprehensive case study.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 16:13:45 GMT"}, {"version": "v2", "created": "Thu, 10 Jan 2019 16:16:33 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Buldas", "Ahto", ""], ["Gadyatskaya", "Olga", ""], ["Lenin", "Aleksandr", ""], ["Mauw", "Sjouke", ""], ["Trujillo-Rasua", "Rolando", ""]]}, {"id": "1812.10792", "submitter": "Daniel Fullmer", "authors": "Daniel Fullmer, A. S. Morse", "title": "Analysis of Difficulty Control in Bitcoin and Proof-of-Work Blockchains", "comments": "57th IEEE Conference on Decision and Control", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a stochastic model for block arrival times based on the\ndifficulty retargeting rule used in Bitcoin, as well as other proof-of-work\nblockchains. Unlike some previous work, this paper explicitly models the\ndifficulty target as a random variable which is a function of the previous\nblock arrival times and affecting the block times in the next retargeting\nperiod. An explicit marginal distribution is derived for the time between\nsuccessive blocks (the blocktime), while allowing for randomly changing\ndifficulty. This paper also aims to serve as an introduction to Bitcoin and\nproof-of-work blockchains for the controls community, focusing on the\ndifficulty retargeting procedure used in Bitcoin.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 18:42:10 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Fullmer", "Daniel", ""], ["Morse", "A. S.", ""]]}, {"id": "1812.10875", "submitter": "Ryan Shah", "authors": "Ryan Shah, Shishir Nagaraja", "title": "Do we have the time for IRM?: Service denial attacks and SDN-based\n  defences", "comments": "7 pages, 3 figures, workshop paper, ICDCN 2019 PerSec workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Distributed sensor networks such as IoT deployments generate large quantities\nof measurement data. Often, the analytics that runs on this data is available\nas a web service which can be purchased for a fee. A major concern in the\nanalytics ecosystem is ensuring the security of the data. Often, companies\noffer Information Rights Management (IRM) as a solution to the problem of\nmanaging usage and access rights of the data that transits administrative\nboundaries. IRM enables individuals and corporations to create restricted IoT\ndata, which can have its flow from organisation to individual control --\ndisabling copying, forwarding, and allowing timed expiry. We describe our\ninvestigations into this functionality and uncover a weak-spot in the\narchitecture -- its dependence upon the accurate global availability of\n\\emph{time}. We present an amplified denial-of-service attack which attacks\ntime synchronisation and could prevent all the users in an organisation from\nreading any sort of restricted data until their software has been re-installed\nand re-configured. We argue that IRM systems built on current technology will\nbe too fragile for businesses to risk widespread use. We also present defences\nthat leverage the capabilities of Software-Defined Networks to apply a simple\nfilter-based approach to detect and isolate attack traffic.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 02:53:47 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Shah", "Ryan", ""], ["Nagaraja", "Shishir", ""]]}, {"id": "1812.10955", "submitter": "Violetta Weger", "authors": "Carmelo Interlando, Karan Khathuria, Nicole Rohrer, Joachim Rosenthal,\n  Violetta Weger", "title": "Generalization of the Ball-Collision Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we generalize the Ball-Collision Algorithm by Bernstein, Lange,\nPeters from the binary field to a general finite field. We also provide a\ncomplexity analysis and compare the asymptotic complexity to other generalized\ninformation set decoding algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 11:27:27 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Interlando", "Carmelo", ""], ["Khathuria", "Karan", ""], ["Rohrer", "Nicole", ""], ["Rosenthal", "Joachim", ""], ["Weger", "Violetta", ""]]}, {"id": "1812.10961", "submitter": "Sergey Belim", "authors": "S.V. Belim, N.F. Bogachenko, A.N. Kabanov", "title": "A Precedent Approach to Assigning Access Rights", "comments": null, "journal-ref": null, "doi": "10.1088/1742-6596/1210/1/012010", "report-no": null, "categories": "cs.CR cs.AI cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To design a discretionary access control policy, a technique is proposed that\nuses the principle of analogies and is based on both the properties of objects\nand the properties of subjects. As attributes characterizing these properties,\nthe values of the security attributes of subjects and objects are chosen. The\nconcept of precedent is defined as an access rule explicitly specified by the\nsecurity administrator. The problem of interpolation of the access matrix is\nformulated: the security administrator defines a sequence of precedents, it is\nrequired to automate the process of filling the remaining cells of the access\nmatrix. On the family of sets of security attributes, a linear order is\nintroduced. The principles of filling the access matrix on the basis of analogy\nwith the dominant precedent in accordance with a given order relation are\ndeveloped. The analysis of the proposed methodology is performed and its main\nadvantages are revealed.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 11:51:14 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Belim", "S. V.", ""], ["Bogachenko", "N. F.", ""], ["Kabanov", "A. N.", ""]]}, {"id": "1812.11080", "submitter": "Stavros Nikolopoulos D.", "authors": "Anna Mpanti and Stavros D. Nikolopoulos and Leonidas Palios", "title": "Characterizing Watermark Numbers encoded as Reducible Permutation Graphs\n  against Malicious Attacks", "comments": "17 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the domain of software watermarking, we have proposed several graph\ntheoretic watermarking codec systems for encoding watermark numbers $w$ as\nreducible permutation flow-graphs $F[\\pi^*]$ through the use of self-inverting\npermutations $\\pi^*$. Following up on our proposed methods, we theoretically\nstudy the oldest one, which we call W-RPG, in order to investigate and prove\nits resilience to edge-modification attacks on the flow-graphs $F[\\pi^*]$. In\nparticular, we characterize the integer $w\\equiv\\pi^*$ as strong or weak\nwatermark through the structure of self-inverting permutations $\\pi^*$ which\nencodes it. To this end, for any integer watermark $w \\in R_n=[2^{n-1},\n2^n-1]$, where $n$ is the length of the binary representation $b(w)$ of $w$, we\ncompute the minimum number of 01-modifications needed to be applied on $b(w)$\nso that the resulting $b(w')$ represents the valid watermark number $w'$; note\nthat a number $w'$ is called valid (or, true-incorrect watermark number) if\n$w'$ can be produced by the W-RPG codec system and, thus, it incorporates all\nthe structural properties of $\\pi^* \\equiv w$.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 16:07:59 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Mpanti", "Anna", ""], ["Nikolopoulos", "Stavros D.", ""], ["Palios", "Leonidas", ""]]}, {"id": "1812.11128", "submitter": "Zuzana Hanikov\\'a", "authors": "Zuzana Hanikov\\'a", "title": "Blind proxy voting", "comments": "technical report, 13 pages", "journal-ref": null, "doi": null, "report-no": "V 1250 (ICS CAS)", "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A secret ballot mechanism that enables voting in absence is proposed. It\namends standard vote collection methods that use ballot box as anonymizer,\nadding the option for absent voters to vote by a proxy blinded to the content\nof the ballot paper. Votes are cast under unique and hidden identification\nnumbers generated solely for the purpose of that election. Voters prepare their\nballot papers from scratch and submit them to the tallying authority in two\nparts via separate routes, each part being meaningless without the other.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 17:41:13 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Hanikov\u00e1", "Zuzana", ""]]}, {"id": "1812.11377", "submitter": "Haishan Ye", "authors": "Haishan Ye, Zhichao Huang, Cong Fang, Chris Junchi Li, Tong Zhang", "title": "Hessian-Aware Zeroth-Order Optimization for Black-Box Adversarial Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Zeroth-order optimization is an important research topic in machine learning.\nIn recent years, it has become a key tool in black-box adversarial attack to\nneural network based image classifiers. However, existing zeroth-order\noptimization algorithms rarely extract second-order information of the model\nfunction. In this paper, we utilize the second-order information of the\nobjective function and propose a novel \\textit{Hessian-aware zeroth-order\nalgorithm} called \\texttt{ZO-HessAware}. Our theoretical result shows that\n\\texttt{ZO-HessAware} has an improved zeroth-order convergence rate and query\ncomplexity under structured Hessian approximation, where we propose a few\napproximation methods for estimating Hessian. Our empirical studies on the\nblack-box adversarial attack problem validate that our algorithm can achieve\nimproved success rates with a lower query complexity.\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2018 15:18:58 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 09:19:44 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Ye", "Haishan", ""], ["Huang", "Zhichao", ""], ["Fang", "Cong", ""], ["Li", "Chris Junchi", ""], ["Zhang", "Tong", ""]]}, {"id": "1812.11393", "submitter": "Konstantinos Solomos", "authors": "Konstantinos Solomos, Panagiotis Ilia, Sotiris Ioannidis and Nicolas\n  Kourtellis", "title": "Talon: An Automated Framework for Cross-Device Tracking Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although digital advertising fuels much of today's free Web, it typically\ndoes so at the cost of online users' privacy, due to the continuous tracking\nand leakage of users' personal data. In search for new ways to optimize the\neffectiveness of ads, advertisers have introduced new advanced paradigms such\nas cross-device tracking (CDT), to monitor users' browsing on multiple devices\nand screens, and deliver (re)targeted ads in the most appropriate\nscreen.Unfortunately, this practice leads to greater privacy concerns for the\nend-user. Going beyond the state-of-the-art, we propose a novel methodology for\ndetecting CDT and measuring the factors affecting its performance, in a\nrepeatable and systematic way. This new methodology is based on emulating\nrealistic browsing activity of end-users, from different devices, and thus\ntriggering and detecting cross-device targeted ads. We design and build Talon a\nCDT measurement framework that implements our methodology and allows\nexperimentation with multiple parallel devices, experimental setups and\nsettings. By employing Talon, we perform several critical experiments, and we\nare able to not only detect and measure CDT with average AUC score of\n0.78-0.96, but also to provide significant insights about the behavior of CDT\nentities and the impact on users' privacy. In the hands of privacy researchers,\npolicy makers and end-users, Talon can be an invaluable tool for raising\nawareness and increasing transparency on tracking practices used by the\nad-ecosystem.\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2018 16:25:45 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 15:26:02 GMT"}, {"version": "v3", "created": "Mon, 29 Jul 2019 09:54:47 GMT"}, {"version": "v4", "created": "Tue, 30 Jul 2019 10:50:37 GMT"}, {"version": "v5", "created": "Wed, 31 Jul 2019 09:41:20 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Solomos", "Konstantinos", ""], ["Ilia", "Panagiotis", ""], ["Ioannidis", "Sotiris", ""], ["Kourtellis", "Nicolas", ""]]}, {"id": "1812.11404", "submitter": "Nadezda Bogachenko", "authors": "S.V. Belim, N.F. Bogachenko, A.N. Kabanov", "title": "Severity Level of Permissions in Role-Based Access Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The analysis of hidden channels of information leakage with respect to\nrole-based access control includes monitoring of excessive permissions among\nusers. It is not always possible to completely eliminate redundancy. The\nproblem of ranking permissions arises in order to identify the most\nsignificant, for which redundancy is most not desirable. A numerical\ncharacteristic that reflects the value or importance of permissions is called\nthe \"severity level\". A number of heuristic assumptions have been formulated\nthat make it possible to establish the dependence of the severity level of\npermissions on the structure of the role hierarchy. A methodology for solving\nthe problem is proposed, using analytic hierarchy process and taking into\naccount these assumptions. The main idea is that the decision tree of the\nprocess will be the role graph.\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2018 17:30:07 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Belim", "S. V.", ""], ["Bogachenko", "N. F.", ""], ["Kabanov", "A. N.", ""]]}, {"id": "1812.11479", "submitter": "Steve Thakur", "authors": "Steve Thakur", "title": "Abelian varieties in pairing-based cryptography", "comments": "Typos fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of the embedding degree of an abelian variety over a\nfinite field which is vital in pairing-based cryptography. In particular, we\nshow that for a prescribed CM field $L$ of degree $\\geq 4$, prescribed integers\n$m$, $n$ and any prime $l\\equiv 1 \\pmod{mn}$, there exists an ordinary abelian\nvariety over a finite field with endomorphism algebra $L$, embedding degree $n$\nwith respect to $l$ and the field extension generated by the $l$-torsion points\nof degree $mn$ over the field of definition. We also study a class of\nabsolutely simple higher dimensional abelian varieties whose endomorphism\nalgebras are central over imaginary quadratic fields.\n", "versions": [{"version": "v1", "created": "Sun, 30 Dec 2018 07:05:27 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 21:06:39 GMT"}, {"version": "v3", "created": "Wed, 8 Apr 2020 17:29:27 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Thakur", "Steve", ""]]}, {"id": "1812.11596", "submitter": "Krzysztof Pawelec", "authors": "Krzysztof Pawelec, Robert A. Bridges, Frank L. Combs", "title": "Towards a CAN IDS based on a neural-network data field predictor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern vehicles contain a few controller area networks (CANs), which allow\nscores of on-board electronic control units (ECUs) to communicate messages\ncritical to vehicle functions and driver safety. CAN provide a lightweight and\nreliable broadcast protocol but is bereft of security features. As evidenced by\nmany recent research works, CAN exploits are possible both remotely and with\ndirect access, fueling a growing CAN intrusion detection system (IDS) body of\nresearch. A challenge for pioneering vehicle-agnostic IDSs is that passenger\nvehicles' CAN message encodings are proprietary, defined and held secret by\noriginal equipment manufacturers (OEMs). Targeting detection of next-generation\nattacks, in which messages are sent from the expected ECU at the expected time\nbut with malicious content, researchers are now seeking to leverage \"CAN data\nmodels\", which predict future CAN message contents and use prediction error to\nidentify anomalous, hopefully malicious CAN messages. Yet, current works model\nCAN signals post-translation, i.e., after applying OEM-donated or\nreverse-engineered translations from raw data. In this work, we present initial\nIDS results testing deep neural networks used to predict CAN data at the bit\nlevel, thereby providing IDS capabilities but avoiding reverse engineering\nproprietary encodings. Our results suggest the method is promising for\ncontinuous signals in CAN data, but struggles for discrete, e.g., binary,\nsignals.\n", "versions": [{"version": "v1", "created": "Sun, 30 Dec 2018 19:54:05 GMT"}, {"version": "v2", "created": "Fri, 4 Jan 2019 22:13:53 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Pawelec", "Krzysztof", ""], ["Bridges", "Robert A.", ""], ["Combs", "Frank L.", ""]]}, {"id": "1812.11693", "submitter": "Feng Yu", "authors": "Feng Yu, Xinhui Gong, Hanpeng Li, Xiaohong Zhao", "title": "Differential cryptanalysis of image cipher using block-based scrambling\n  and image filtering", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, an image encryption algorithm using block-based scrambling and\nimage filtering has been proposed by Hua et al. In this paper, we analyze the\nsecurity problems of the encryption algorithm in detail and break the\nencryption by a codebook attack. We construct an linear relation between\nplain-images and cipher-images by differential cryptanalysis. With this linear\nrelation, we build a codebook containing $(M \\times N + 1)$ pairs of\nplain-images and cipher-images, where $M\\times N$ is the size of images. The\nproposed codebook attack indicates that the encryption scheme is insecure. To\nresist the codebook attack, an improved algorithm is proposed. Experimental\nresults show that the improved algorithm not only inherits the merits of the\noriginal scheme, but also has stronger security against the differential\ncryptanalysis.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 04:05:21 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Yu", "Feng", ""], ["Gong", "Xinhui", ""], ["Li", "Hanpeng", ""], ["Zhao", "Xiaohong", ""]]}, {"id": "1812.11720", "submitter": "Vasisht Duddu", "authors": "Vasisht Duddu, Debasis Samanta, D Vijay Rao, Valentina E. Balas", "title": "Stealing Neural Networks via Timing Side Channels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is gaining importance in many applications. However, Neural\nNetworks face several security and privacy threats. This is particularly\nsignificant in the scenario where Cloud infrastructures deploy a service with\nNeural Network model at the back end. Here, an adversary can extract the Neural\nNetwork parameters, infer the regularization hyperparameter, identify if a data\npoint was part of the training data, and generate effective transferable\nadversarial examples to evade classifiers. This paper shows how a Neural\nNetwork model is susceptible to timing side channel attack. In this paper, a\nblack box Neural Network extraction attack is proposed by exploiting the timing\nside channels to infer the depth of the network. Although, constructing an\nequivalent architecture is a complex search problem, it is shown how\nReinforcement Learning with knowledge distillation can effectively reduce the\nsearch space to infer a target model. The proposed approach has been tested\nwith VGG architectures on CIFAR10 data set. It is observed that it is possible\nto reconstruct substitute models with test accuracy close to the target models\nand the proposed approach is scalable and independent of type of Neural Network\narchitectures.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 08:19:26 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 10:21:14 GMT"}, {"version": "v3", "created": "Fri, 10 May 2019 06:51:02 GMT"}, {"version": "v4", "created": "Mon, 8 Jul 2019 07:31:01 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Duddu", "Vasisht", ""], ["Samanta", "Debasis", ""], ["Rao", "D Vijay", ""], ["Balas", "Valentina E.", ""]]}, {"id": "1812.11735", "submitter": "Feng Yu", "authors": "Xinhui Gong, Feng Yu, Xiaohong Zhao, Shihong Wang", "title": "Security analysis of a self-embedding fragile image watermark scheme", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a self-embedding fragile watermark scheme based on reference-bits\ninterleaving and adaptive selection of embedding mode was proposed. Reference\nbits are derived from the scrambled MSB bits of a cover image, and then are\ncombined with authentication bits to form the watermark bits for LSB embedding.\nWe find this algorithm has a feature of block independence of embedding\nwatermark such that it is vulnerable to a collage attack. In addition, because\nthe generation of authentication bits via hash function operations is not\nrelated to secret keys, we analyze this algorithm by a multiple stego-image\nattack. We find that the cost of obtaining all the permutation relations of\n$l\\cdot b^2$ watermark bits of each block (i.e., equivalent permutation keys)\nis about $(l\\cdot b^2)!$ for the embedding mode $(m, l)$, where $m$ MSB layers\nof a cover image are used for generating reference bits and $l$ LSB layers for\nembedding watermark, and $b\\times b$ is the size of image block. The simulation\nresults and the statistical results demonstrate our analysis is effective.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 09:37:36 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 09:26:00 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Gong", "Xinhui", ""], ["Yu", "Feng", ""], ["Zhao", "Xiaohong", ""], ["Wang", "Shihong", ""]]}, {"id": "1812.11747", "submitter": "Vincent Gramoli", "authors": "Tyler Crain, Christopher Natoli and Vincent Gramoli", "title": "Evaluating the Red Belly Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we present the most extensive evaluation of blockchain system\nto date. To achieve scalability across servers in more than 10 countries\nlocated on 4 different continents, we drastically revisited Byzantine fault\ntolerant blockchains and verification of signatures. The resulting blockchain,\ncalled the Red Belly Blockchain (RBBC), commits more than a hundred thousand\ntransactions issued by permissionless nodes. These transactions are grouped\ninto blocks within few seconds through a partially synchronous consensus run by\npermissioned nodes. It prevents double spending by guaranteeing that a unique\nblock is decided at any given index of the chain in a deterministic way by all\nparticipants. We compared the performance of RBBC against traditional Byzantine\nfault tolerant alternatives and more recent randomized solutions. In the same\ngeo-distributed environment with low-end machines, we noticed two interesting\ncomparisons: (i) the RBBC throughput scales to hundreds of machines whereas the\nclassic 3-step leader-based BFT state machine used by consortium blockchains\ncannot scale to 40 identically configured nodes; (ii) RBBC guarantees\ntransaction finality in 3 seconds and experiences a third of the latency that\nrandomized-based solutions like HoneyBadgerBFT can offer. This empirical\nevaluation demonstrates that blockchain scalability can be achieved without\nsacrificing security.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 10:19:49 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Crain", "Tyler", ""], ["Natoli", "Christopher", ""], ["Gramoli", "Vincent", ""]]}, {"id": "1812.11811", "submitter": "Leandros Maglaras A", "authors": "Dimitrios Kosmanos, Antonios Argyriou and Leandros Maglaras", "title": "Estimating the Relative Speed of RF Jammers in VANETs", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicular Ad-Hoc Networks (VANETs) aim at enhancing road safety and providing\na comfortable driving environment by delivering early warning and infotainment\nmessages to the drivers. Jamming attacks, however, pose a significant threat to\ntheir performance. In this paper, we propose a novel Relative Speed Estimation\nAlgorithm (RSEA) of a moving interfering vehicle that approaches a Transmitter\n($Tx$) - Receiver ($Rx$) pair, that interferes with their Radio Frequency (RF)\ncommunication by conducting a Denial of Service (DoS) attack. Our scheme is\ncompletely sensorless and passive and uses a pilot-based received signal\nwithout hardware or computational cost in order to, firstly, estimate the\ncombined channel between the transmitter - receiver and jammer - receiver and\nsecondly, to estimate the jamming signal and the relative speed between the\njammer - receiver using the RF Doppler shift. Moreover, the relative speed\nmetric exploits the Angle of Projection (AOP) of the speed vector of the jammer\nin the axis of its motion in order to form a two-dimensional representation of\nthe geographical area. This approach can effectively be applied both for a\njamming signal completely unknown to the receiver and for a jamming signal\npartly known to the receiver. Our speed estimator method is proven to have\nquite accurate performance, with a Mean Absolute Error (MAE) value of\napproximately $10\\%$ compared to the optimal zero MAE value under different\njamming attack scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 14:37:21 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Kosmanos", "Dimitrios", ""], ["Argyriou", "Antonios", ""], ["Maglaras", "Leandros", ""]]}, {"id": "1812.11875", "submitter": "Stefan Nagy", "authors": "Stefan Nagy, Matthew Hicks", "title": "Full-speed Fuzzing: Reducing Fuzzing Overhead through Coverage-guided\n  Tracing", "comments": "To appear in the 40th IEEE Symposium on Security and Privacy, May\n  20--22, 2019, San Francisco, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Of coverage-guided fuzzing's three main components: (1) testcase generation,\n(2) code coverage tracing, and (3) crash triage, code coverage tracing is a\ndominant source of overhead. Coverage-guided fuzzers trace every testcase's\ncode coverage through either static or dynamic binary instrumentation, or more\nrecently, using hardware support. Unfortunately, tracing all testcases incurs\nsignificant performance penalties---even when the overwhelming majority of\ntestcases and their coverage information are discarded because they do not\nincrease code coverage. To eliminate needless tracing by coverage-guided\nfuzzers, we introduce the notion of coverage-guided tracing. Coverage-guided\ntracing leverages two observations: (1) only a fraction of generated testcases\nincrease coverage, and thus require tracing; and (2) coverage-increasing\ntestcases become less frequent over time. Coverage-guided tracing works by\nencoding the current frontier of code coverage in the target binary so that it\nself-reports when a testcase produces new coverage---without tracing. This acts\nas a filter for tracing; restricting the expense of tracing to only\ncoverage-increasing testcases. Thus, coverage-guided tracing chooses to\ntradeoff increased coverage-increasing-testcase handling time for the ability\nto execute testcases initially at native speed. To show the potential of\ncoverage-guided tracing, we create an implementation based on the static binary\ninstrumentor Dyninst called UnTracer. We evaluate UnTracer using eight\nreal-world binaries commonly used by the fuzzing community. Experiments show\nthat after only an hour of fuzzing, UnTracer's average overhead is below 1%,\nand after 24-hours of fuzzing, UnTracer approaches 0% overhead, while tracing\nevery testcase with popular white- and black-box-binary tracers AFL-Clang,\nAFL-QEMU, and AFL-Dyninst incurs overheads of 36%, 612%, and 518%,\nrespectively.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 16:19:19 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2019 21:02:57 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Nagy", "Stefan", ""], ["Hicks", "Matthew", ""]]}, {"id": "1812.11886", "submitter": "Dimitrios Kosmanos", "authors": "Dimitrios Kosmanos, Dimitrios Karagiannis, Antonios Argyriou, Spyros\n  Lalis, Leandros Maglaras", "title": "RF Jamming Classification using Relative Speed Estimation in Vehicular\n  Wireless Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless communications are vulnerable against radio frequency (RF) jamming\nwhich might be caused either intentionally or unintentionally. A particular\nsubset of wireless networks, vehicular ad-hoc networks (VANET) which\nincorporate a series of safety-critical applications, may be a potential target\nof RF jamming with detrimental safety effects. To ensure secure communication\nand defend it against this type of attacks, an accurate detection scheme must\nbe adopted. In this paper we introduce a detection scheme that is based on\nsupervised learning. The machine-learning algorithms, KNearest Neighbors (KNN)\nand Random Forests (RF), utilize a series of features among which is the metric\nof the variations of relative speed (VRS) between the jammer and the receiver\nthat is passively estimated from the combined value of the useful and the\njamming signal at the receiver. To the best of our knowledge, this metric has\nnever been utilized before in a machine-learning detection scheme in the\nliterature. Through offline training and the proposed KNN-VRS, RF-VRS\nclassification algorithms, we are able to efficiently detect various cases of\nDenial of Service Attacks (DoS) jamming attacks, differentiate them from cases\nof interference as well as foresee a potential danger successfully and act\naccordingly.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 16:35:08 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Kosmanos", "Dimitrios", ""], ["Karagiannis", "Dimitrios", ""], ["Argyriou", "Antonios", ""], ["Lalis", "Spyros", ""], ["Maglaras", "Leandros", ""]]}, {"id": "1812.11900", "submitter": "Leandros Maglaras A", "authors": "Michael Robinson, Kevin Jones, Helge Janicke, Leandros Maglaras", "title": "Developing Cyber Buffer Zones", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The United Nations conducts peace operations around the world, aiming\ntomaintain peace and security in conflict torn areas. Whilst early operations\nwerelargely successful, the changing nature of warfare and conflict has often\nleft peaceoperations strugglingto adapt. In this article, we make a\ncontribution towardsefforts to plan for the next evolution in both intra and\ninter-state conflict: cyberwarfare. It is now widely accepted that cyber\nwarfare will be a component offuture conflicts, and much researchhas been\ndevoted to how governments andmilitaries can prepare for and fight in this new\ndomain [1]. Despite the vastamount of research relating to cyber warfare, there\nhas been less discussion onits impact towards successful peace operations. This\nis agap in knowledge thatis important to address, since the restoration of\npeace following conflict of anykind is of global importance. It is however a\ncomplex topic requiring discussionacross multiple domains. Input from the\ntechnical, political, governmental andsocietal domains are critical in forming\nthe concept of cyber peacekeeping.Previous work on this topic has sought to\ndefine the concept of cyber peacekeeping[2, 3, 4]. We build upon this work by\nexploring the practicalities ofstarting up a cyber peacekeeping component and\nsetting up a Cyber Buffer Zone (CBZ).\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 17:06:11 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Robinson", "Michael", ""], ["Jones", "Kevin", ""], ["Janicke", "Helge", ""], ["Maglaras", "Leandros", ""]]}]