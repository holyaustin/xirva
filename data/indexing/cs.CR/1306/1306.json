[{"id": "1306.0018", "submitter": "Peter Breuer", "authors": "Peter T. Breuer and Jonathan P. Bowen", "title": "An Open Question on the Uniqueness of (Encrypted) Arithmetic", "comments": "Withdrawn by authors after acceptance for ICCS 2013 (one of the\n  conjectures that appears in the text was disproved by the authors after\n  submission); 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We ask whether two or more images of arithmetic may inhabit the same space\nvia different encodings. The answers have significance for a class of processor\ndesign that does all its computation in an encrypted form, without ever\nperforming any decryption or encryption itself. Against the possibility of\nalgebraic attacks against the arithmetic in a `crypto-processor' (KPU) we\npropose a defence called `ABC encryption' and show how this kind of encryption\nmakes it impossible for observations of the arithmetic to be used by an\nattacker to discover the actual values. We also show how to construct such\nencrypted arithmetics.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2013 20:07:11 GMT"}], "update_date": "2013-06-04", "authors_parsed": [["Breuer", "Peter T.", ""], ["Bowen", "Jonathan P.", ""]]}, {"id": "1306.0075", "submitter": "Cm Pintea", "authors": "Camelia-M. Pintea, Petrica C. Pop", "title": "Sensitive Ants for Denial Jamming Attack on Wireless Sensor Network", "comments": "- 4 pages - accepted paper", "journal-ref": "Advances in Intelligent and Soft Computing 239:409-418 (2014)", "doi": "10.1007/978-3-319-01854-6_42", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new defence mechanism for different jamming attack on Wireless Sensor\nNetwork (WSN) based on ant system it is introduced. The artificial sensitive\nants react on network attacks in particular based on their sensitivity level.\nThe information is re-directed from the attacked node to its appropriate\ndestination node. It is analyzed how are detected and isolated the jamming\nattacks with mobile agents in general and in particular with the newly\nant-based sensitive approach.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2013 04:22:25 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Pintea", "Camelia-M.", ""], ["Pop", "Petrica C.", ""]]}, {"id": "1306.0281", "submitter": "Oded Regev", "authors": "Zvika Brakerski, Adeline Langlois, Chris Peikert, Oded Regev, and\n  Damien Stehl\\'e", "title": "Classical Hardness of Learning with Errors", "comments": "Preliminary version in STOC'13", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the Learning with Errors (LWE) problem is classically at least\nas hard as standard worst-case lattice problems, even with polynomial modulus.\nPreviously this was only known under quantum reductions.\n  Our techniques capture the tradeoff between the dimension and the modulus of\nLWE instances, leading to a much better understanding of the landscape of the\nproblem. The proof is inspired by techniques from several recent cryptographic\nconstructions, most notably fully homomorphic encryption schemes.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2013 03:04:57 GMT"}], "update_date": "2013-06-04", "authors_parsed": [["Brakerski", "Zvika", ""], ["Langlois", "Adeline", ""], ["Peikert", "Chris", ""], ["Regev", "Oded", ""], ["Stehl\u00e9", "Damien", ""]]}, {"id": "1306.0315", "submitter": "Tommaso Gagliardoni", "authors": "\\\"Ozg\\\"ur Dagdelen and Marc Fischlin Tommaso Gagliardoni", "title": "The Fiat-Shamir Transformation in a Quantum World", "comments": "30 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Fiat-Shamir transformation is a famous technique to turn identification\nschemes into signature schemes. The derived scheme is provably secure in the\nrandom-oracle model against classical adversaries. Still, the technique has\nalso been suggested to be used in connection with quantum-immune identification\nschemes, in order to get quantum-immune signature schemes. However, a recent\npaper by Boneh et al. (Asiacrypt 2011) has raised the issue that results in the\nrandom-oracle model may not be immediately applicable to quantum adversaries,\nbecause such adversaries should be allowed to query the random oracle in\nsuperposition. It has been unclear if the Fiat-Shamir technique is still secure\nin this quantum oracle model (QROM).\n  Here, we discuss that giving proofs for the Fiat-Shamir transformation in the\nQROM is presumably hard. We show that there cannot be black-box extractors, as\nlong as the underlying quantum-immune identification scheme is secure against\nactive adversaries and the first message of the prover is independent of its\nwitness. Most schemes are of this type. We then discuss that for some schemes\none may be able to resurrect the Fiat-Shamir result in the QROM by modifying\nthe underlying protocol first. We discuss in particular a version of the\nLyubashevsky scheme which is provably secure in the QROM.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2013 07:57:33 GMT"}], "update_date": "2013-06-04", "authors_parsed": [["Dagdelen", "\u00d6zg\u00fcr", ""], ["Gagliardoni", "Marc Fischlin Tommaso", ""]]}, {"id": "1306.0388", "submitter": "Michael Wellman", "authors": "Michael P. Wellman, Tae Hyung Kim, Quang Duong", "title": "Analyzing Incentives for Protocol Compliance in Complex Domains: A Case\n  Study of Introduction-Based Routing", "comments": "Presented at the Twelfth Workshop on the Economics of Information\n  Security, Washington, DC, June 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal analyses of incentives for compliance with network protocols often\nappeal to game-theoretic models and concepts. Applications of game-theoretic\nanalysis to network security have generally been limited to highly stylized\nmodels, where simplified environments enable tractable study of key strategic\nvariables. We propose a simulation-based approach to game-theoretic analysis of\nprotocol compliance, for scenarios with large populations of agents and large\npolicy spaces. We define a general procedure for systematically exploring a\nstructured policy space, directed expressly to resolve the qualitative\nclassification of equilibrium behavior as compliant or non-compliant. The\ntechniques are illustrated and exercised through an extensive case study\nanalyzing compliance incentives for introduction-based routing. We find that\nthe benefits of complying with the protocol are particularly strong for nodes\nsubject to attack, and the overall compliance level achieved in equilibrium,\nwhile not universal, is sufficient to support the desired security goals of the\nprotocol.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2013 12:53:36 GMT"}], "update_date": "2013-06-04", "authors_parsed": [["Wellman", "Michael P.", ""], ["Kim", "Tae Hyung", ""], ["Duong", "Quang", ""]]}, {"id": "1306.0497", "submitter": "Givon Zirkind", "authors": "Givon Zirkind", "title": "One Time Pad Password Protection: Using T.E.C. Steganography and Secure\n  Password Transmission Protocols", "comments": "Draft for CAESER 2014 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A while ago, I developed what I called an encryption method. The most\nfavorable of reviews did not see a method but a collection of techniques. Be\nthat as it may, the process used, is described in the paper, Windtalking\nComputers. This paper is about the steganographic method described, the\ncryptanalysis efforts of that method and; a real world application of that\nmethod as an answer to the increasing problem of password file hacking. The\npremise is that the technique is a variant of one time pad, using a novel way\nto produce one time pad output for digital input. There is no record in the\nliterature of such a method being used for encryption at all. Digital\nencryption generally treats the letters of the plaintext as a binary number and\ndoes some mathematical computation to produce ciphertext. The idea of inserting\nbits with a random generated key is new. Therefore (because a uniquely random\ngenerated key is used), the encryption is cryptanalytically unbreakable and/or\ncomputationally secure and/or information theoretic. An academic version was\nmade. Challenges for decryption have not produced to-date a decryption.\nAdvantages and disadvantages of the method are discussed.\n  Hackers are constantly penetrating networks and stealing password files.\nWhich, once in possession of a password file, hackers individually or\ncollectively with distributed processing over the Internet, decrypt the values\nof the hash passwords. Thereby gaining access to systems. This problem has\nbecome sufficiently significant for CAESAR (Competition for Authenticated\nEncryption: Security, Applicability, and Robustness) to make calls for papers\nfor solutions. Herein is one proposed solution. While one time pad presents a\nproblem being computationally intensive, for the relatively short length of\npasswords, the cost of computation may be cost effective for the security\nprovided.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2013 22:02:02 GMT"}], "update_date": "2013-06-04", "authors_parsed": [["Zirkind", "Givon", ""]]}, {"id": "1306.0549", "submitter": "Dimitris Pados", "authors": "Ming Li, Sandipan Kundu, Dimitris A. Pados, and Stella N. Batalama", "title": "Waveform Design for Secure SISO Transmissions and Multicasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless physical-layer security is an emerging field of research aiming at\npreventing eavesdropping in an open wireless medium. In this paper, we propose\na novel waveform design approach to minimize the likelihood that a message\ntransmitted between trusted single-antenna nodes is intercepted by an\neavesdropper. In particular, with knowledge first of the eavesdropper's channel\nstate information (CSI), we find the optimum waveform and transmit energy that\nminimize the signal-to-interference-plus-noise ratio (SINR) at the output of\nthe eavesdropper's maximum-SINR linear filter, while at the same time provide\nthe intended receiver with a required pre-specified SINR at the output of its\nown max-SINR filter. Next, if prior knowledge of the eavesdropper's CSI is\nunavailable, we design a waveform that maximizes the amount of energy available\nfor generating disturbance to eavesdroppers, termed artificial noise (AN),\nwhile the SINR of the intended receiver is maintained at the pre-specified\nlevel. The extensions of the secure waveform design problem to multiple\nintended receivers are also investigated and semidefinite relaxation (SDR) -an\napproximation technique based on convex optimization- is utilized to solve the\narising NP-hard design problems. Extensive simulation studies confirm our\nanalytical performance predictions and illustrate the benefits of the designed\nwaveforms on securing single-input single-output (SISO) transmissions and\nmulticasting.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2013 19:47:29 GMT"}], "update_date": "2013-06-04", "authors_parsed": [["Li", "Ming", ""], ["Kundu", "Sandipan", ""], ["Pados", "Dimitris A.", ""], ["Batalama", "Stella N.", ""]]}, {"id": "1306.1264", "submitter": "Emiliano De Cristofaro", "authors": "Erman Ayday and Emiliano De Cristofaro and Jean-Pierre Hubaux and Gene\n  Tsudik", "title": "The Chills and Thrills of Whole Genome Sequencing", "comments": "A slightly different version of this article appears in IEEE Computer\n  Magazine, Vol. 48, No. 2, February 2015, under the title \"Whole Genome\n  Sequencing: Revolutionary Medicine or Privacy Nightmare\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Whole Genome Sequencing (WGS) evolved from a\nfuturistic-sounding research project to an increasingly affordable technology\nfor determining complete genome sequences of complex organisms, including\nhumans. This prompts a wide range of revolutionary applications, as WGS\npromises to improve modern healthcare and provide a better understanding of the\nhuman genome -- in particular, its relation to diseases and response to\ntreatments. However, this progress raises worrisome privacy and ethical issues,\nsince, besides uniquely identifying its owner, the genome contains a treasure\ntrove of highly personal and sensitive information. In this article, after\nsummarizing recent advances in genomics, we discuss some important privacy\nissues associated with human genomic information and identify a number of\nparticularly relevant research challenges.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2013 23:08:03 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2013 18:07:57 GMT"}, {"version": "v3", "created": "Thu, 5 Sep 2013 15:06:37 GMT"}, {"version": "v4", "created": "Thu, 24 Oct 2013 11:56:53 GMT"}, {"version": "v5", "created": "Mon, 16 Feb 2015 17:36:21 GMT"}], "update_date": "2015-02-17", "authors_parsed": [["Ayday", "Erman", ""], ["De Cristofaro", "Emiliano", ""], ["Hubaux", "Jean-Pierre", ""], ["Tsudik", "Gene", ""]]}, {"id": "1306.1332", "submitter": "Ferdous Barbhuiya Ahmed", "authors": "Ferdous A Barbhuiya, Santosh Biswas, Sukumar Nandi", "title": "An Active Host-Based Intrusion Detection System for ARP-Related Attacks\n  and its Verification", "comments": "International Journal of Network Security & Its Applications (IJNSA),\n  Vol.3, No.3, May 2011", "journal-ref": "Journal of Information Assurance and Security. ISSN 1554-1010\n  Volume 7 (2012) pp. 284-295", "doi": "10.5121/ijnsa.2011.3311", "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoofing with falsified IP-MAC pair is the first step in most of the LAN\nbased-attacks. Address Resolution Protocol (ARP) is stateless, which is the\nmain cause that makes spoofing possible. Several network level and host level\nmechanisms have been proposed to detect and mitigate ARP spoofing but each of\nthem has their own drawback. In this paper we propose a Host-based Intrusion\nDetection system for LAN attacks, which works without any extra constraint like\nstatic IP-MAC, modifying ARP etc. The proposed scheme is verified under all\npossible attack scenarios. The scheme is successfully validated in a test bed\nwith various attack scenarios and the results show the effectiveness of the\nproposed technique.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2013 08:11:25 GMT"}], "update_date": "2013-07-26", "authors_parsed": [["Barbhuiya", "Ferdous A", ""], ["Biswas", "Santosh", ""], ["Nandi", "Sukumar", ""]]}, {"id": "1306.1436", "submitter": "Changlu Lin", "authors": "Lein Harn, Changlu Lin", "title": "An efficient group authentication for group communications", "comments": "8 pages", "journal-ref": "International Journal of Network Security & Its Applications\n  (IJNSA), Vol.5, No.3, May 2013", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Group communication implies a many-to-many communication and it goes beyond\nboth one-to-one communication (i.e., unicast) and one-to-many communication\n(i.e., multicast). Unlike most user authentication protocols that authenticate\na single user each time, we propose a new type of authentication, called group\nauthentication, that authenticates all users in a group at once. The group\nauthentication protocol is specially designed to support group communications.\nThere is a group manager who is responsible to manage the group communication.\nDuring registration, each user of a group obtains an unique token from the\ngroup manager. Users present their tokens to determine whether they all belong\nto the same group or not. The group authentication protocol allows users to\nreuse their tokens without compromising the security of tokens. In addition,\nthe group authentication can protect the identity of each user.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2013 15:25:02 GMT"}], "update_date": "2013-06-07", "authors_parsed": [["Harn", "Lein", ""], ["Lin", "Changlu", ""]]}, {"id": "1306.1519", "submitter": "Laurent Signac", "authors": "Laurent Signac (LAII)", "title": "Lattice Gas Symmetric Cryptography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR nlin.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lattice gas cellular automata (Lgca) are particular cellular automata that\nimitate the behavior of par- ticles moving on a lattice. We used a particular\nset of Lgca rules, called hpp, to mix bits in data blocks and obtain a\nsymmetric cryptographic algorithm. The encryption and decryption keys are the\npositions of perturbation sites on the lattice (walls). Basically, this paper\npresents an original way to perform cryp- tographic operations, based on\ncellular automata. In this paper, we show several characteristics about our\nalgorithm: typical block size (2^(2n-1) ), key-length (2^n ), number of rounds\n(2^(n+1) ). We also evaluate avalanche and strict avalanche properties with\nrespect to key and plain text. Finally, we highlight the underbellies of our\nmethod and give clues to solve them.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2013 19:26:04 GMT"}], "update_date": "2013-06-07", "authors_parsed": [["Signac", "Laurent", "", "LAII"]]}, {"id": "1306.1740", "submitter": "Pankaj Choudhary", "authors": "Pankaj Choudhary, Rajendra Aaseri and Nirmal Roberts", "title": "HTTPI Based Web Service Security over SOAP", "comments": "International Journal of Network Security & Its Applications (IJNSA),\n  Vol.5, No.3, May 2013", "journal-ref": "Choudhary, P., Aaseri, R., Roberts, N., (2013) \"HTTPI Based Web\n  Service Security over SOAP\", IJNSA, Vol.5, No.3, on pp. 55-66", "doi": "10.5121/ijnsa.2013.5306", "report-no": null, "categories": "cs.CR cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Now a days, a new family of web applications open applications, are emerging\n(e.g., Social Networking, News and Blogging). Generally, these open\napplications are non-confidential. The security needs of these applications are\nonly client/server authentication and data integrity. For securing these open\napplications, effectively and efficiently, HTTPI, a new transport protocol is\nproposed, which ensures the entire security requirements of open applications.\nBenefit of using the HTTPI is that it is economical in use, well-suited for\ncache proxies, like HTTP is, and provides security against many Internet\nattacks (Server Impersonation and Message Modification) like HTTPS does. In\nterms of performance HTTPI is very close to the HTTP, but much better than\nHTTPS. A Web service is a method of communication between two ends over the\nInternet. These web services are developed over XML and HTTP. Today, most of\nthe open applications use web services for most of their operations. For\nsecuring these web services, security design based on HTTPI is proposed. Our\nwork involves securing the web services over SOAP, based on the HTTPI. This\nsecure web service might be applicable for open applications, where\nauthentication and integrity is needed, but no confidentiality required. In our\npaper, we introduce a web service security model based on HTTPI protocol over\nSOAP and develop a preliminary implementation of this model. We also analyze\nthe performance of our approach through an experiment and show that our\nproposed approach provides higher throughput, lower average response time and\nlower response size than HTTPS based web service security approach.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2013 15:07:58 GMT"}], "update_date": "2013-06-10", "authors_parsed": [["Choudhary", "Pankaj", ""], ["Aaseri", "Rajendra", ""], ["Roberts", "Nirmal", ""]]}, {"id": "1306.1916", "submitter": "Kirat Pal Er", "authors": "Kirat Pal Singh, Dilip Kumar", "title": "Performance Evaluation of Low Power MIPS Crypto Processor based on\n  Cryptography Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the design and implementation of low power 32-bit\nencrypted and decrypted MIPS processor for Data Encryption Standard (DES),\nTriple DES, Advanced Encryption Standard (AES) based on MIPS pipeline\narchitecture. The organization of pipeline stages has been done in such a way\nthat pipeline can be clocked at high frequency. Encryption and Decryption\nblocks of three standard cryptography algorithms on MIPS processor and\ndependency among themselves are explained in detail with the help of a block\ndiagram. Clock gating technique is used to reduce the power consumption in MIPS\ncrypto processor. This approach results in processor that meets power\nconsumption and performance specification for security applications. Proposed\nImplementation approach concludes higher system performance while reducing\noperating power consumption. Testing results shows that the MIPS crypto\nprocessor operates successfully at a working frequency of 218MHz and a\nbandwidth of 664Mbits/s.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2013 13:18:48 GMT"}], "update_date": "2013-06-11", "authors_parsed": [["Singh", "Kirat Pal", ""], ["Kumar", "Dilip", ""]]}, {"id": "1306.1953", "submitter": "Alexey Markov", "authors": "Alexander Barabanov, Alexey Markov and Valentin Tsirlov", "title": "A Formal Approach To Firewalls Testing Techniques", "comments": "Keywords: information security, firewall, security analysis, test\n  procedures, conformance evaluation, security certification, performance\n  optimization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional technologies of firewall testing are overlooked. A new formalized\napproach is presented. Recommendations on optimization of test procedures are\ngiven.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2013 20:11:45 GMT"}], "update_date": "2013-06-11", "authors_parsed": [["Barabanov", "Alexander", ""], ["Markov", "Alexey", ""], ["Tsirlov", "Valentin", ""]]}, {"id": "1306.1955", "submitter": "Alexey Markov", "authors": "Alexander Barabanov, Maxim Grishin and Alexey Markov", "title": "The Formal Metabasis For Conformity Assessment of Information Security\n  Software and Hardware", "comments": "Keywords: information security, information protection, information\n  security tools, certification, conformity assessment, security testing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An approach to the development of security test procedures for information\nsecurity controls is presented. The recommendations for optimizing the test\nprocedure are obtained\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2013 20:25:58 GMT"}], "update_date": "2013-06-11", "authors_parsed": [["Barabanov", "Alexander", ""], ["Grishin", "Maxim", ""], ["Markov", "Alexey", ""]]}, {"id": "1306.2008", "submitter": "Li Yang", "authors": "Li Yang, Hong-Wei Li", "title": "Investigating the linear structure of Boolean functions based on Simon's\n  period-finding quantum algorithm", "comments": "13 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is believed that there is no efficient classical algorithm to determine\nthe linear structure of Boolean function. We investigate an extension of\nSimon's period-finding quantum algorithm, and propose an efficient quantum\nalgorithm to determine the linear structure of Boolean function.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2013 11:47:42 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2013 12:59:51 GMT"}], "update_date": "2016-11-26", "authors_parsed": [["Yang", "Li", ""], ["Li", "Hong-Wei", ""]]}, {"id": "1306.2083", "submitter": "Aaron Roth", "authors": "Mallesh Pai and Aaron Roth", "title": "Privacy and Mechanism Design", "comments": "This survey appears in SIGecom Exchanges 12.1, 2013", "journal-ref": "SIGecom Exchanges 12.1, 2013", "doi": null, "report-no": null, "categories": "cs.GT cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a survey of recent work at the intersection of mechanism design\nand privacy. The connection is a natural one, but its study has been\njump-started in recent years by the advent of differential privacy, which\nprovides a rigorous, quantitative way of reasoning about the costs that an\nagent might experience because of the loss of his privacy. Here, we survey\nseveral facets of this study, and differential privacy plays a role in more\nthan one way. Of course, it provides us a basis for modeling agent costs for\nprivacy, which is essential if we are to attempt mechanism design in a setting\nin which agents have preferences for privacy. It also provides a toolkit for\ncontrolling those costs. However, perhaps more surprisingly, it provides a\npowerful toolkit for controlling the stability of mechanisms in general, which\nyields a set of tools for designing novel mechanisms even in economic settings\ncompletely unrelated to privacy.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2013 01:41:38 GMT"}], "update_date": "2013-06-11", "authors_parsed": [["Pai", "Mallesh", ""], ["Roth", "Aaron", ""]]}, {"id": "1306.2252", "submitter": "Nitish Salwan", "authors": "Nitish Salwan, Sandeep Singh, Suket Arora, Amarpreet Singh", "title": "An Insight to Covert Channels", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an overview of different concepts regarding covert\nchannels. It discusses the various classifications and the detailing of various\nfields used to manipulate for the covert channel execution.Different evaluation\ncriterias are presented for measuring the strength of covert channels. The\ndefenses and prevention schemes for this covert channel will also be discussed.\nThis paper also discuss about an advanced timing channel i.e.Temperature Based\nCovert Channel.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2013 17:30:07 GMT"}], "update_date": "2013-06-11", "authors_parsed": [["Salwan", "Nitish", ""], ["Singh", "Sandeep", ""], ["Arora", "Suket", ""], ["Singh", "Amarpreet", ""]]}, {"id": "1306.2301", "submitter": "Martin Roetteler", "authors": "Martin Roetteler, Rainer Steinwandt", "title": "A note on quantum related-key attacks", "comments": "8 pages, 4 figures; added figure of quantum circuit for related-key\n  attack against block ciphers", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a basic related-key attack against a block cipher, the adversary has\naccess to encryptions under keys that differ from the target key by bit-flips.\nIn this short note we show that for a quantum adversary such attacks are quite\npowerful: if the secret key is (i) uniquely determined by a small number of\nplaintext-ciphertext pairs, (ii) the block cipher can be evaluated efficiently,\nand (iii) a superposition of related keys can be queried, then the key can be\nextracted efficiently.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2013 19:54:39 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2013 00:26:59 GMT"}], "update_date": "2013-11-15", "authors_parsed": [["Roetteler", "Martin", ""], ["Steinwandt", "Rainer", ""]]}, {"id": "1306.2401", "submitter": "Scott Stoller", "authors": "Zhongyuan Xu and Scott D. Stoller", "title": "Mining Attribute-based Access Control Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribute-based access control (ABAC) provides a high level of flexibility\nthat promotes security and information sharing. ABAC policy mining algorithms\nhave potential to significantly reduce the cost of migration to ABAC, by\npartially automating the development of an ABAC policy from an access control\nlist (ACL) policy or role-based access control (RBAC) policy with accompanying\nattribute data. This paper presents an ABAC policy mining algorithm. To the\nbest of our knowledge, it is the first ABAC policy mining algorithm. Our\nalgorithm iterates over tuples in the given user-permission relation, uses\nselected tuples as seeds for constructing candidate rules, and attempts to\ngeneralize each candidate rule to cover additional tuples in the\nuser-permission relation by replacing conjuncts in attribute expressions with\nconstraints. Our algorithm attempts to improve the policy by merging and\nsimplifying candidate rules, and then it selects the highest-quality candidate\nrules for inclusion in the generated policy.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2013 02:00:07 GMT"}, {"version": "v2", "created": "Wed, 1 Jan 2014 16:39:26 GMT"}, {"version": "v3", "created": "Sun, 5 Jan 2014 00:08:46 GMT"}, {"version": "v4", "created": "Thu, 7 Aug 2014 18:41:08 GMT"}], "update_date": "2014-08-08", "authors_parsed": [["Xu", "Zhongyuan", ""], ["Stoller", "Scott D.", ""]]}, {"id": "1306.2476", "submitter": "Viet Hung Nguyen", "authors": "Viet Hung Nguyen and Fabio Massacci", "title": "A Systematically Empirical Evaluation of Vulnerability Discovery Models:\n  a Study on Browsers' Vulnerabilities", "comments": "15 pages", "journal-ref": "IEEE Transactions on Software Engineering 40(12), 2014", "doi": "10.1109/TSE.2014.2354037", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A precise vulnerability discovery model (VDM) will provide a useful insight\nto assess software security, and could be a good prediction instrument for both\nsoftware vendors and users to understand security trends and plan ahead\npatching schedule accordingly. Thus far, several models have been proposed and\nvalidated. Yet, no systematically independent validation by somebody other than\nthe author exists. Furthermore, there are a number of issues that might bias\nprevious studies in the field. In this work, we fill in the gap by introducing\nan empirical methodology that systematically evaluates the performance of a VDM\nin two aspects: quality and predictability. We further apply this methodology\nto assess existing VDMs. The results show that some models should be rejected\noutright, while some others might be adequate to capture the discovery process\nof vulnerabilities. We also consider different usage scenarios of VDMs and find\nthat the simplest linear model is the most appropriate choice in terms of both\nquality and predictability when browsers are young. Otherwise, logistics-based\nmodels are better choices.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2013 10:17:18 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Nguyen", "Viet Hung", ""], ["Massacci", "Fabio", ""]]}, {"id": "1306.2477", "submitter": "George Grispos", "authors": "George Grispos, William Bradley Glisson and Tim Storer", "title": "Cloud Security Challenges: Investigating Policies, Standards, and\n  Guidelines in a Fortune 500 Organization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing is quickly becoming pervasive in today's globally integrated\nnetworks. The cloud offers organizations opportunities to potentially deploy\nsoftware and data solutions that are accessible through numerous mechanisms, in\na multitude of settings, at a reduced cost with increased reliability and\nscalability. The increasingly pervasive and ubiquitous nature of the cloud\ncreates an environment that is potentially conducive to security risks. While\nprevious discussions have focused on security and privacy issues in the cloud\nfrom the end-users perspective, minimal empirical research has been conducted\nfrom the perspective of a corporate environment case study. This paper presents\nthe results of an initial case study identifying real-world information\nsecurity documentation issues for a Global Fortune 500 organization, should the\norganization decide to implement cloud computing services in the future. The\npaper demonstrates the importance of auditing policies, standards and\nguidelines applicable to cloud computing environments along with highlighting\npotential corporate concerns. The results from this case study has revealed\nthat from the 1123 'relevant' statements found in the organization's security\ndocumentation, 175 statements were considered to be 'inadequate' for cloud\ncomputing. Furthermore, the paper provides a foundation for future analysis and\nresearch regarding implementation concerns for corporate cloud computing\napplications and services\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2013 10:18:02 GMT"}], "update_date": "2013-06-12", "authors_parsed": [["Grispos", "George", ""], ["Glisson", "William Bradley", ""], ["Storer", "Tim", ""]]}, {"id": "1306.2693", "submitter": "EPTCS", "authors": "Tri Minh Ngo (University of Twente), Marieke Huisman (University of\n  Twente)", "title": "Quantitative Security Analysis for Multi-threaded Programs", "comments": "In Proceedings QAPL 2013, arXiv:1306.2413", "journal-ref": "EPTCS 117, 2013, pp. 34-48", "doi": "10.4204/EPTCS.117.3", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantitative theories of information flow give us an approach to relax the\nabsolute confidentiality properties that are difficult to satisfy for many\npractical programs. The classical information-theoretic approaches for\nsequential programs, where the program is modeled as a communication channel\nwith only input and output, and the measure of leakage is based on the notions\nof initial uncertainty and remaining uncertainty after observing the final\noutcomes, are not suitable to multi-threaded programs. Besides, the\ninformation-theoretic approaches have been also shown to conflict with each\nother when comparing programs. Reasoning about the exposed information flow of\nmulti-threaded programs is more complicated, since the outcomes of such\nprograms depend on the scheduler policy, and the leakages in intermediate\nstates also contribute to the overall leakage of the program.\n  This paper proposes a novel model of quantitative analysis for multi-threaded\nprograms that also takes into account the effect of observables in intermediate\nstates along the trace. We define a notion of the leakage of a program trace.\nGiven the fact that the execution of a multi-threaded program is typically\ndescribed by a set of traces, the leakage of a program under a specific\nscheduler is computed as the expected value of the leakages of all possible\ntraces. Examples are given to compare our approach with the existing\napproaches.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2013 01:55:30 GMT"}], "update_date": "2013-06-13", "authors_parsed": [["Ngo", "Tri Minh", "", "University of Twente"], ["Huisman", "Marieke", "", "University of\n  Twente"]]}, {"id": "1306.2833", "submitter": "Domenico Vitali Dr.", "authors": "Roberto Di Pietro, Luigi V.Mancini, Antonio Villani and Domenico\n  Vitali", "title": "Mapping the File Systems Genome: rationales, technique, results and\n  applications", "comments": "16 pages, 5 image", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides evidence of a feature of Hard-Disk Drives (HDDs), that we\ncall File System Genome. Such a feature is originated by the areas where (on\nthe HDD) the file blocks are placed by the operating system during the\ninstallation procedure. It appears from our study that the File System Genome\nis a distinctive and unique feature of each indi- vidual HDD. In particular,\nour extensive set of experiments shows that the installation of the same\noperating system on two identical hardware configurations generates two\ndifferent File System Genomes. Further, the application of sound information\ntheory tools, such as min entropy, show that the differences between two File\nSystem Genome are considerably relevant. The results provided in this paper\nconstitute the scientific basis for a number of applications in various fields\nof information technology, such as forensic identification and security.\nFinally, this work also paves the way for the application of the highlighted\ntechnique to other classes of mass-storage devices (e.g. SSDs, Flash memories).\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2013 14:15:14 GMT"}], "update_date": "2013-06-13", "authors_parsed": [["Di Pietro", "Roberto", ""], ["Mancini", "Luigi V.", ""], ["Villani", "Antonio", ""], ["Vitali", "Domenico", ""]]}, {"id": "1306.2882", "submitter": "Uwe Aickelin", "authors": "Haichang Gao, Zhongjie Ren, Xiuling Chang, Xiyang Liu, Uwe Aickelin", "title": "A New Graphical Password Scheme Resistant to Shoulder-Surfing", "comments": "Proceedings of the International Conference on CyberWorlds, 20-22\n  October 2010, Singapore, 194-199, 2010. arXiv admin note: text overlap with\n  arXiv:1305.7482", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shoulder-surfing is a known risk where an attacker can capture a password by\ndirect observation or by recording the authentication session. Due to the\nvisual interface, this problem has become exacerbated in graphical passwords.\nThere have been some graphical schemes resistant or immune to shoulder-surfing,\nbut they have significant usability drawbacks, usually in the time and effort\nto log in. In this paper, we propose and evaluate a new shoulder-surfing\nresistant scheme which has a desirable usability for PDAs. Our inspiration\ncomes from the drawing input method in DAS and the association mnemonics in\nStory for sequence retrieval. The new scheme requires users to draw a curve\nacross their password images orderly rather than click directly on them. The\ndrawing input trick along with the complementary measures, such as erasing the\ndrawing trace, displaying degraded images, and starting and ending with\nrandomly designated images provide a good resistance to shouldersurfing. A\npreliminary user study showed that users were able to enter their passwords\naccurately and to remember them over time.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2013 16:29:44 GMT"}], "update_date": "2013-06-13", "authors_parsed": [["Gao", "Haichang", ""], ["Ren", "Zhongjie", ""], ["Chang", "Xiuling", ""], ["Liu", "Xiyang", ""], ["Aickelin", "Uwe", ""]]}, {"id": "1306.2885", "submitter": "Uwe Aickelin", "authors": "Haichang Gao, Honggang Liu, Dan Yao, Xiyang Liu, Uwe Aickelin", "title": "An audio CAPTCHA to distinguish humans from computers", "comments": "Third International Symposium on Electronic Commerce and Security,\n  ISECS2010, 265-269, 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CAPTCHAs are employed as a security measure to differentiate human users from\nbots. A new sound-based CAPTCHA is proposed in this paper, which exploits the\ngaps between human voice and synthetic voice rather than relays on the auditory\nperception of human. The user is required to read out a given sentence, which\nis selected randomly from a specified book. The generated audio file will be\nanalyzed automatically to judge whether the user is a human or not. In this\npaper, the design of the new CAPTCHA, the analysis of the audio files, and the\nchoice of the audio frame window function are described in detail. And also,\nsome experiments are conducted to fix the critical threshold and the\ncoefficients of three indicators to ensure the security. The proposed audio\nCAPTCHA is proved accessible to users. The user study has shown that the human\nsuccess rate reaches approximately 97% and the pass rate of attack software\nusing Microsoft SDK 5.1 is only 4%. The experiments also indicated that it\ncould be solved by most human users in less than 14 seconds and the average\ntime is only 7.8 seconds.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2013 16:34:57 GMT"}], "update_date": "2013-06-13", "authors_parsed": [["Gao", "Haichang", ""], ["Liu", "Honggang", ""], ["Yao", "Dan", ""], ["Liu", "Xiyang", ""], ["Aickelin", "Uwe", ""]]}, {"id": "1306.3054", "submitter": "Uwe Aickelin", "authors": "Haichang Gao, Zhongjie Ren, Xiuling Chang, Xiyang Liu, Uwe Aickelin", "title": "The effect of baroque music on the PassPoints graphical password", "comments": "ACM International Conference on Image and Video Retrieval, 129-134,\n  2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphical passwords have been demonstrated to be the possible alternatives to\ntraditional alphanumeric passwords. However, they still tend to follow\npredictable patterns that are easier to attack. The crux of the problem is\nusers' memory limitations. Users are the weakest link in password\nauthentication mechanism. It shows that baroque music has positive effects on\nhuman memorizing and learning. We introduce baroque music to the PassPoints\ngraphical password scheme and conduct a laboratory study in this paper. Results\nshown that there is no statistic difference between the music group and the\ncontrol group without music in short-term recall experiments, both had high\nrecall success rates. But in long-term recall, the music group performed\nsignificantly better. We also found that the music group tended to set\nsignificantly more complicated passwords, which are usually more resistant to\ndictionary and other guess attacks. But compared with the control group, the\nmusic group took more time to log in both in short-term and long-term tests.\nBesides, it appears that background music does not work in terms of hotspots.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2013 08:20:38 GMT"}], "update_date": "2013-06-14", "authors_parsed": [["Gao", "Haichang", ""], ["Ren", "Zhongjie", ""], ["Chang", "Xiuling", ""], ["Liu", "Xiyang", ""], ["Aickelin", "Uwe", ""]]}, {"id": "1306.3055", "submitter": "Uwe Aickelin", "authors": "Haichang Gao, Xiuling Chang, Zhongjie Ren, Uwe Aickelin, Liming Wang", "title": "Can background baroque music help to improve the memorability of\n  graphical passwords?", "comments": "Proceedings of the International Conference on Image Analysis and\n  Recognition, ICIAR2010, Povoa de Varzim, Portugal, 378-387, 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphical passwords have been proposed as an alternative to alphanumeric\npasswords with their advantages in usability and security. However, they still\ntend to follow predictable patterns that are easier for attackers to exploit,\nprobably due to users' memory limitations. Various literatures show that\nbaroque music has positive effects on human learning and memorizing. To\nalleviate users' memory burden, we investigate the novel idea of introducing\nbaroque music to graphical password schemes (specifically DAS, PassPoints and\nStory) and conduct a laboratory study to see whether it is helpful. In a ten\nminutes short-term recall, we found that participants in all conditions had\nhigh recall success rates that were not statistically different from each\nother. After one week, the music group coped PassPoints passwords significantly\nbetter than the group without music. But there was no statistical difference\nbetween two groups in recalling DAS passwords or Story passwords. Further more,\nwe found that the music group tended to set significantly more complicated\nPassPoints passwords but less complicated DAS passwords.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2013 08:33:06 GMT"}], "update_date": "2013-06-14", "authors_parsed": [["Gao", "Haichang", ""], ["Chang", "Xiuling", ""], ["Ren", "Zhongjie", ""], ["Aickelin", "Uwe", ""], ["Wang", "Liming", ""]]}, {"id": "1306.3484", "submitter": "Xun Gong", "authors": "Xun Gong, Negar Kiyavash, and Parv Venkitasubramaniam", "title": "An Information Theoretic Study of Timing Side Channels in Two-user\n  Schedulers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Timing side channels in two-user schedulers are studied. When two users share\na scheduler, one user may learn the other user's behavior from patterns of\nservice timings. We measure the information leakage of the resulting timing\nside channel in schedulers serving a legitimate user and a malicious attacker,\nusing a privacy metric defined as the Shannon equivocation of the user's job\ndensity. We show that the commonly used first-come-first-serve (FCFS) scheduler\nprovides no privacy as the attacker is able to to learn the user's job pattern\ncompletely. Furthermore, we introduce an scheduling policy,\naccumulate-and-serve scheduler, which services jobs from the user and attacker\nin batches after buffering them. The information leakage in this scheduler is\nmitigated at the price of service delays, and the maximum privacy is achievable\nwhen large delays are added.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2013 18:57:08 GMT"}], "update_date": "2013-06-17", "authors_parsed": [["Gong", "Xun", ""], ["Kiyavash", "Negar", ""], ["Venkitasubramaniam", "Parv", ""]]}, {"id": "1306.3546", "submitter": "Jason Spencer", "authors": "Jason Spencer", "title": "Cellular Automata in Cryptographic Random Generators", "comments": "113 pgs, 67 pgs of Content, 6 figures, 9 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptographic schemes using one-dimensional, three-neighbor cellular automata\nas a primitive have been put forth since at least 1985. Early results showed\ngood statistical pseudorandomness, and the simplicity of their construction\nmade them a natural candidate for use in cryptographic applications. Since\nthose early days of cellular automata, research in the field of cryptography\nhas developed a set of tools which allow designers to prove a particular scheme\nto be as hard as solving an instance of a well- studied problem, suggesting a\nlevel of security for the scheme. However, little or no literature is available\non whether these cellular automata can be proved secure under even generous\nassumptions. In fact, much of the literature falls short of providing complete,\ntestable schemes to allow such an analysis.\n  In this thesis, we first examine the suitability of cellular automata as a\nprimitive for building cryptographic primitives. In this effort, we focus on\npseudorandom bit generation and noninvertibility, the behavioral heart of\ncryptography. In particular, we focus on cyclic linear and non-linear au-\ntomata in some of the common configurations to be found in the literature. We\nexamine known attacks against these constructions and, in some cases, improve\nthe results.\n  Finding little evidence of provable security, we then examine whether the\ndesirable properties of cellular automata (i.e. highly parallel, simple\nconstruction) can be maintained as the automata are enhanced to provide a\nfoundation for such proofs. This investigation leads us to a new construction\nof a finite state cellular automaton (FSCA) which is NP-Hard to invert.\nFinally, we introduce the Chasm pseudorandom generator family built on this\nconstruction and provide some initial experimental results using the NIST test\nsuite.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2013 03:33:13 GMT"}], "update_date": "2013-06-18", "authors_parsed": [["Spencer", "Jason", ""]]}, {"id": "1306.3896", "submitter": "Marco Baldi", "authors": "Marco Baldi, Marco Bianchi, Nicola Maturo, Franco Chiaraluce", "title": "Improving the efficiency of the LDPC code-based McEliece cryptosystem\n  through irregular codes", "comments": "6 pages, 3 figures, presented at ISCC 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the framework of the McEliece cryptosystem based on LDPC codes,\nwhich is a promising post-quantum alternative to classical public key\ncryptosystems. The use of LDPC codes in this context allows to achieve good\nsecurity levels with very compact keys, which is an important advantage over\nthe classical McEliece cryptosystem based on Goppa codes. However, only regular\nLDPC codes have been considered up to now, while some further improvement can\nbe achieved by using irregular LDPC codes, which are known to achieve better\nerror correction performance than regular LDPC codes. This is shown in this\npaper, for the first time at our knowledge. The possible use of irregular\ntransformation matrices is also investigated, which further increases the\nefficiency of the system, especially in regard to the public key size.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2013 15:30:57 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2013 08:06:38 GMT"}], "update_date": "2013-07-10", "authors_parsed": [["Baldi", "Marco", ""], ["Bianchi", "Marco", ""], ["Maturo", "Nicola", ""], ["Chiaraluce", "Franco", ""]]}, {"id": "1306.4036", "submitter": "Venkata Sriram Siddhardh (Sid) Nadendla", "authors": "V. Sriram Siddhardh (Sid) Nadendla, Yunghsiang S. Han, Pramod K.\n  Varshney", "title": "Distributed Inference with M-ary Quantized Data in the Presence of\n  Byzantine Attacks", "comments": "15 pages, 8 figures, 1 table, Revision submitted to IEEE Transactions\n  on Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of distributed inference with M-ary quantized data at the sensors\nis investigated in the presence of Byzantine attacks. We assume that the\nattacker does not have knowledge about either the true state of the phenomenon\nof interest, or the quantization thresholds used at the sensors. Therefore, the\nByzantine nodes attack the inference network by modifying modifying the symbol\ncorresponding to the quantized data to one of the other M symbols in the\nquantization alphabet-set and transmitting the false symbol to the fusion\ncenter (FC). In this paper, we find the optimal Byzantine attack that blinds\nany distributed inference network. As the quantization alphabet size increases,\na tremendous improvement in the security performance of the distributed\ninference network is observed.\n  We also investigate the problem of distributed inference in the presence of\nresource-constrained Byzantine attacks. In particular, we focus our attention\non two problems: distributed detection and distributed estimation, when the\nByzantine attacker employs a highly-symmetric attack. For both the problems, we\nfind the optimal attack strategies employed by the attacker to maximally\ndegrade the performance of the inference network. A reputation-based scheme for\nidentifying malicious nodes is also presented as the network's strategy to\nmitigate the impact of Byzantine threats on the inference performance of the\ndistributed sensor network.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2013 22:39:51 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2014 14:34:09 GMT"}], "update_date": "2014-01-15", "authors_parsed": [["Siddhardh", "V. Sriram", "", "Sid"], ["Nadendla", "", ""], ["Han", "Yunghsiang S.", ""], ["Varshney", "Pramod K.", ""]]}, {"id": "1306.4040", "submitter": "Carlos Sarraute", "authors": "Carlos Sarraute (1 and 2), Gerardo Richarte (1), Jorge Lucangeli Obes\n  (3) ((1) Core Security Technologies, (2) ITBA (Instituto Tecnologico Buenos\n  Aires), (3) UBA (Universidad de Buenos Aires))", "title": "An Algorithm to Find Optimal Attack Paths in Nondeterministic Scenarios", "comments": "ACM Workshop on Artificial Intelligence and Security (AISec 2011), at\n  ACM CCS Conference 2011", "journal-ref": null, "doi": "10.1145/2046684.2046695", "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  As penetration testing frameworks have evolved and have become more complex,\nthe problem of controlling automatically the pentesting tool has become an\nimportant question. This can be naturally addressed as an attack planning\nproblem. Previous approaches to this problem were based on modeling the actions\nand assets in the PDDL language, and using off-the-shelf AI tools to generate\nattack plans. These approaches however are limited. In particular, the planning\nis classical (the actions are deterministic) and thus not able to handle the\nuncertainty involved in this form of attack planning.\n  We herein contribute a planning model that does capture the uncertainty about\nthe results of the actions, which is modeled as a probability of success of\neach action. We present efficient planning algorithms, specifically designed\nfor this problem, that achieve industrial-scale runtime performance (able to\nsolve scenarios with several hundred hosts and exploits). These algorithms take\ninto account the probability of success of the actions and their expected cost\n(for example in terms of execution time, or network traffic generated).\n  We thus show that probabilistic attack planning can be solved efficiently for\nthe scenarios that arise when assessing the security of large networks. Two\n\"primitives\" are presented, which are used as building blocks in a framework\nseparating the overall problem into two levels of abstraction. We also present\nthe experimental results obtained with our implementation, and conclude with\nsome ideas for further work.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2013 23:26:23 GMT"}], "update_date": "2017-07-10", "authors_parsed": [["Sarraute", "Carlos", "", "1 and 2"], ["Richarte", "Gerardo", ""], ["Obes", "Jorge Lucangeli", ""]]}, {"id": "1306.4044", "submitter": "Carlos Sarraute", "authors": "Jorge Lucangeli Obes (1), Carlos Sarraute (1 and 2), Gerardo Richarte\n  (1) ((1) Core Security Technologies, (2) ITBA (Instituto Tecnologico Buenos\n  Aires))", "title": "Attack Planning in the Real World", "comments": "SecArt'2010 at AAAI 2010, Atlanta, USA. July 12, 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Assessing network security is a complex and difficult task. Attack graphs\nhave been proposed as a tool to help network administrators understand the\npotential weaknesses of their network. However, a problem has not yet been\naddressed by previous work on this subject; namely, how to actually execute and\nvalidate the attack paths resulting from the analysis of the attack graph. In\nthis paper we present a complete PDDL representation of an attack model, and an\nimplementation that integrates a planner into a penetration testing tool. This\nallows to automatically generate attack paths for penetration testing\nscenarios, and to validate these attacks by executing the corresponding actions\n-including exploits- against the real target network. We present an algorithm\nfor transforming the information present in the penetration testing tool to the\nplanning domain, and show how the scalability issues of attack graphs can be\nsolved using current planners. We include an analysis of the performance of our\nsolution, showing how our model scales to medium-sized networks and the number\nof actions available in current penetration testing tools.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2013 00:06:52 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2013 22:43:15 GMT"}], "update_date": "2013-06-21", "authors_parsed": [["Obes", "Jorge Lucangeli", "", "1 and 2"], ["Sarraute", "Carlos", "", "1 and 2"], ["Richarte", "Gerardo", ""]]}, {"id": "1306.4174", "submitter": "Lachlan Gunn", "authors": "Lachlan J. Gunn, James M. Chappell, Andrew Allison, Derek Abbott", "title": "Physical-layer encryption on the public internet: a stochastic approach\n  to the Kish-Sethuraman cipher", "comments": "7 pages, 3 figures, to be presented at HotPI-2013", "journal-ref": null, "doi": "10.1142/S2010194514603615", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While information-theoretic security is often associated with the one-time\npad and quantum key distribution, noisy transport media leave room for\nclassical techniques and even covert operation. Transit times across the public\ninternet exhibit a degree of randomness, and cannot be determined noiselessly\nby an eavesdropper. We demonstrate the use of these measurements for\ninformation-theoretically secure communication over the public internet.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2013 13:05:57 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Gunn", "Lachlan J.", ""], ["Chappell", "James M.", ""], ["Allison", "Andrew", ""], ["Abbott", "Derek", ""]]}, {"id": "1306.4244", "submitter": "Emmanuel Thome", "authors": "Razvan Barbulescu (INRIA Nancy - Grand Est / LORIA), Pierrick Gaudry\n  (INRIA Nancy - Grand Est / LORIA), Antoine Joux (PRISM), Emmanuel Thom\\'e\n  (INRIA Nancy - Grand Est / LORIA)", "title": "A quasi-polynomial algorithm for discrete logarithm in finite fields of\n  small characteristic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present work, we present a new discrete logarithm algorithm, in the\nsame vein as in recent works by Joux, using an asymptotically more efficient\ndescent approach. The main result gives a quasi-polynomial heuristic complexity\nfor the discrete logarithm problem in finite field of small characteristic. By\nquasi-polynomial, we mean a complexity of type $n^{O(\\log n)}$ where $n$ is the\nbit-size of the cardinality of the finite field. Such a complexity is smaller\nthan any $L(\\varepsilon)$ for $\\epsilon>0$. It remains super-polynomial in the\nsize of the input, but offers a major asymptotic improvement compared to\n$L(1/4+o(1))$.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2013 15:28:56 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2013 07:45:58 GMT"}], "update_date": "2013-11-27", "authors_parsed": [["Barbulescu", "Razvan", "", "INRIA Nancy - Grand Est / LORIA"], ["Gaudry", "Pierrick", "", "INRIA Nancy - Grand Est / LORIA"], ["Joux", "Antoine", "", "PRISM"], ["Thom\u00e9", "Emmanuel", "", "INRIA Nancy - Grand Est / LORIA"]]}, {"id": "1306.4447", "submitter": "Antonio Villani", "authors": "Giuseppe Ateniese, Giovanni Felici, Luigi V. Mancini, Angelo\n  Spognardi, Antonio Villani, Domenico Vitali", "title": "Hacking Smart Machines with Smarter Ones: How to Extract Meaningful Data\n  from Machine Learning Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) algorithms are used to train computers to perform a\nvariety of complex tasks and improve with experience. Computers learn how to\nrecognize patterns, make unintended decisions, or react to a dynamic\nenvironment. Certain trained machines may be more effective than others because\nthey are based on more suitable ML algorithms or because they were trained\nthrough superior training sets. Although ML algorithms are known and publicly\nreleased, training sets may not be reasonably ascertainable and, indeed, may be\nguarded as trade secrets. While much research has been performed about the\nprivacy of the elements of training sets, in this paper we focus our attention\non ML classifiers and on the statistical information that can be unconsciously\nor maliciously revealed from them. We show that it is possible to infer\nunexpected but useful information from ML classifiers. In particular, we build\na novel meta-classifier and train it to hack other classifiers, obtaining\nmeaningful information about their training sets. This kind of information\nleakage can be exploited, for example, by a vendor to build more effective\nclassifiers or to simply acquire trade secrets from a competitor's apparatus,\npotentially violating its intellectual property rights.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2013 07:51:49 GMT"}], "update_date": "2013-06-20", "authors_parsed": [["Ateniese", "Giuseppe", ""], ["Felici", "Giovanni", ""], ["Mancini", "Luigi V.", ""], ["Spognardi", "Angelo", ""], ["Villani", "Antonio", ""], ["Vitali", "Domenico", ""]]}, {"id": "1306.4595", "submitter": "Abdoulaye Diop", "authors": "Abdoulaye Diop, Yue Qi, Qin Wang and Shariq Hussain", "title": "An Advanced Survey on Secure Energy-Efficient Hierarchical Routing\n  Protocols in Wireless Sensor Networks", "comments": "11 pages, 7 tables, 4 figures,30 refences. arXiv admin note: text\n  overlap with arXiv:1011.1529, arXiv:1301.5065 by other authors", "journal-ref": "IJCSI , Volume 10, Issue 1, January 2013", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Wireless Sensor Networks (WSNs) are often deployed in hostile environments,\nwhich make such networks highly vulnerable and increase the risk of attacks\nagainst this type of network. WSN comprise of large number of sensor nodes with\ndifferent hardware abilities and functions. Due to the limited memory resources\nand energy constraints, complex security algorithms cannot be used in sensor\nnetworks. Therefore, it is necessary to balance between the security level and\nthe associated energy consumption overhead to mitigate the security risks.\nHierarchical routing protocol is more energy-efficient than other routing\nprotocols in WSNs. Many secure cluster-based routing protocols have been\nproposed in the literature to overcome these constraints. In this paper, we\ndiscuss Secure Energy-Efficient Hierarchical Routing Protocols in WSNs and\ncompare them in terms of security, performance and efficiency. Security issues\nfor WSNs and their solutions are also discussed.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2013 16:10:39 GMT"}], "update_date": "2013-06-20", "authors_parsed": [["Diop", "Abdoulaye", ""], ["Qi", "Yue", ""], ["Wang", "Qin", ""], ["Hussain", "Shariq", ""]]}, {"id": "1306.4624", "submitter": "Charles Morisset", "authors": "Andreas Griesmayer, Charles Morisset", "title": "Automated Certification of Authorisation Policy Resistance", "comments": "20 pages, 4 figures, version including proofs of the paper that will\n  be presented at ESORICS 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribute-based Access Control (ABAC) extends traditional Access Control by\nconsidering an access request as a set of pairs attribute name-value, making it\nparticularly useful in the context of open and distributed systems, where\nsecurity relevant information can be collected from different sources. However,\nABAC enables attribute hiding attacks, allowing an attacker to gain some access\nby withholding information. In this paper, we first introduce the notion of\npolicy resistance to attribute hiding attacks. We then propose the tool ATRAP\n(Automatic Term Rewriting for Authorisation Policies), based on the recent\nformal ABAC language PTaCL, which first automatically searches for resistance\ncounter-examples using Maude, and then automatically searches for an Isabelle\nproof of resistance. We illustrate our approach with two simple examples of\npolicies and propose an evaluation of ATRAP performances.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2013 17:35:43 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2013 10:33:43 GMT"}], "update_date": "2013-06-21", "authors_parsed": [["Griesmayer", "Andreas", ""], ["Morisset", "Charles", ""]]}, {"id": "1306.4652", "submitter": "Umakant Mishra", "authors": "Umakant Mishra", "title": "Finding and Solving Contradictions of False Positives in Virus Scanning", "comments": "13 pages. Available at TRIZsite Journal, Apr 2012\n  http://trizsite.tk/trizsite/articles/default.asp?month=Apr&year=2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  False positives are equally dangerous as false negatives. Ideally the false\npositive rate should remain 0 or very close to 0. Even a slightest increase in\nfalse positive rate is considered as undesirable.\n  Although the specific methods provide very accurate scanning by comparing\nviruses with their exact signatures, they fail to detect the new and unknown\nviruses. On the other hand the generic methods can detect even new viruses\nwithout using virus signatures. But these methods are more likely to generate\nfalse positives. There is a positive correlation between the capability to\ndetect new and unknown viruses and false positive rate.\n  While a traditional approach tries to achieve a right balance between false\npositives and false negatives a TRIZ approach looks forward to achieve the\nIdeal Final Result. The Ideal final result is to 'detect and prevent viruses\nwith full certainty. The chances of error should be nil and the method should\nnot raise any false positive or false negative.' The article shows many\ncontradictions relating to false positives and their solutions.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2013 19:25:34 GMT"}], "update_date": "2013-06-20", "authors_parsed": [["Mishra", "Umakant", ""]]}, {"id": "1306.4660", "submitter": "Umakant Mishra", "authors": "Umakant Mishra", "title": "Contradictions in Improving Speed of Virus Scanning", "comments": "Available at TRIZsite Journal, May 2012,\n  http://trizsite.tk/trizsite/articles/default.asp?month=May&year=2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although everything in computing industry moves faster including the\nprocessor, memory speed, memory size, storage space etc. there is no\nimprovement in virus scanning time. Although the processing speed has\nsubstantially increased, a typical full scanning is still taking several hours\nfor an average computer. There is a serious need to improve the scanning time.\n  Contradiction is a stage of problem solving where the nature of the actual\nproblem is clearly explained in terms of at least two parameters, one improving\nand another worsening. While emphasizing one parameter strengthens the system\nposition emphasizing another parameter weakens the system.\n  In conventional methods a problem solver has to make a perfect balance\nbetween these conflicting parameters, where the situation is neither too much\non one side nor too much on the other. The results of those methods, although\nincrease the speed of virus scanning, results in disadvantages like load on\nprocessor, increase in false positives and compromise on security. The\nobjective of TRIZ is not to accept a tradeoff between the speed of scanning and\nthose other difficulties but to resolve the contradictions so that the speed of\nscanning increases without compromising with security and other harmful\nresults.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2013 19:38:36 GMT"}], "update_date": "2013-06-20", "authors_parsed": [["Mishra", "Umakant", ""]]}, {"id": "1306.4666", "submitter": "Umakant Mishra", "authors": "Umakant Mishra", "title": "Methods of Repairing Virus Infected Files, A TRIZ based Analysis", "comments": "18 pages, 20 references. (May 15, 2013). Available at SSRN:\n  http://ssrn.com/abstract=2265576", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most viruses are capable of fixing up the first few bytes and repair the\noriginal program because they have to return the control back to the infected\nprogram. This fact is used by a heuristic cleaner to clean the infected file.\nAs the virus knows how to repair the it uses the same virus to repair the\ninfected file.\n  There are some infections where parts of the files are damaged by the virus.\nThese types of infections are caused by 'file modifying viruses'. In these\ncases, the chance of recovery is less, but the anti-virus has to apply various\nmethods with hope. The virus cleaner must know the characteristics of a virus\nin order to remove that virus. It cannot remove an unknown virus whose methods\nof infection are not known. If a virus is wrongly detected to be a different\nvirus, then the cleaner will do wrong operations and build a garbage file.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2013 19:54:49 GMT"}], "update_date": "2013-06-20", "authors_parsed": [["Mishra", "Umakant", ""]]}, {"id": "1306.4714", "submitter": "Carlos Sarraute", "authors": "Carlos Sarraute (1 and 2), Olivier Buffet (3), Joerg Hoffmann (3) ((1)\n  Core Security Technologies, (2) ITBA (Instituto Tecnologico Buenos Aires),\n  (3) INRIA)", "title": "Penetration Testing == POMDP Solving?", "comments": "Proceedings of the 3rd Workshop on Intelligent Security (SecArt'11),\n  at IJCAI'11", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Penetration Testing is a methodology for assessing network security, by\ngenerating and executing possible attacks. Doing so automatically allows for\nregular and systematic testing without a prohibitive amount of human labor. A\nkey question then is how to generate the attacks. This is naturally formulated\nas a planning problem. Previous work (Lucangeli et al. 2010) used classical\nplanning and hence ignores all the incomplete knowledge that characterizes\nhacking. More recent work (Sarraute et al. 2011) makes strong independence\nassumptions for the sake of scaling, and lacks a clear formal concept of what\nthe attack planning problem actually is. Herein, we model that problem in terms\nof partially observable Markov decision processes (POMDP). This grounds\npenetration testing in a well-researched formalism, highlighting important\naspects of this problem's nature. POMDPs allow to model information gathering\nas an integral part of the problem, thus providing for the first time a means\nto intelligently mix scanning actions with actual exploits.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2013 22:39:20 GMT"}], "update_date": "2013-06-21", "authors_parsed": [["Sarraute", "Carlos", "", "1 and 2"], ["Buffet", "Olivier", ""], ["Hoffmann", "Joerg", ""]]}, {"id": "1306.4726", "submitter": "Dawei Zhao", "authors": "Dawei Zhao, Haipeng Peng, Lixiang Li, Yixian Yang", "title": "A secure and effective anonymous authentication scheme for roaming\n  service in global mobility networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Mun et al. analyzed Wu et al.'s authentication scheme and proposed\na enhanced anonymous authentication scheme for roaming service in global\nmobility networks. However, through careful analysis, we find that Mun et al.'s\nscheme is vulnerable to impersonation attacks, off-line password guessing\nattacks and insider attacks, and cannot provide user friendliness, user's\nanonymity, proper mutual authentication and local verification. To remedy these\nweaknesses, in this paper we propose a novel anonymous authentication scheme\nfor roaming service in global mobility networks. Security and performance\nanalyses show the proposed scheme is more suitable for the low-power and\nresource-limited mobile devices, and is secure against various attacks and has\nmany excellent features.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2013 01:18:39 GMT"}], "update_date": "2013-06-21", "authors_parsed": [["Zhao", "Dawei", ""], ["Peng", "Haipeng", ""], ["Li", "Lixiang", ""], ["Yang", "Yixian", ""]]}, {"id": "1306.4828", "submitter": "Muhammad Rizwan Asghar", "authors": "Muhammad Rizwan Asghar and Mihaela Ion and Giovanni Russello and Bruno\n  Crispo", "title": "ESPOON: Enforcing Encrypted Security Policies in Outsourced Environments", "comments": "The final version of this paper has been published at ARES 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The enforcement of security policies in outsourced environments is still an\nopen challenge for policy-based systems. On the one hand, taking the\nappropriate security decision requires access to the policies. However, if such\naccess is allowed in an untrusted environment then confidential information\nmight be leaked by the policies. Current solutions are based on cryptographic\noperations that embed security policies with the security mechanism. Therefore,\nthe enforcement of such policies is performed by allowing the authorised\nparties to access the appropriate keys. We believe that such solutions are far\ntoo rigid because they strictly intertwine authorisation policies with the\nenforcing mechanism.\n  In this paper, we want to address the issue of enforcing security policies in\nan untrusted environment while protecting the policy confidentiality. Our\nsolution ESPOON is aiming at providing a clear separation between security\npolicies and the enforcement mechanism. However, the enforcement mechanism\nshould learn as less as possible about both the policies and the requester\nattributes.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2013 11:41:44 GMT"}], "update_date": "2013-06-21", "authors_parsed": [["Asghar", "Muhammad Rizwan", ""], ["Ion", "Mihaela", ""], ["Russello", "Giovanni", ""], ["Crispo", "Bruno", ""]]}, {"id": "1306.4845", "submitter": "Eitan Menahem", "authors": "Eitan Menahem, Gabi Nakibly, Yuval Elovici", "title": "ACTIDS: An Active Strategy For Detecting And Localizing Network Attacks", "comments": "Full fledged paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we investigate a new approach for detecting attacks which aim to\ndegrade the network's Quality of Service (QoS). To this end, a new\nnetwork-based intrusion detection system (NIDS) is proposed. Most contemporary\nNIDSs take a passive approach by solely monitoring the network's production\ntraffic. This paper explores a complementary approach in which distributed\nagents actively send out periodic probes. The probes are continuously monitored\nto detect anomalous behavior of the network. The proposed approach takes away\nmuch of the variability of the network's production traffic that makes it so\ndifficult to classify. This enables the NIDS to detect more subtle attacks\nwhich would not be detected using the passive approach alone. Furthermore, the\nactive probing approach allows the NIDS to be effectively trained using only\nexamples of the network's normal states, hence enabling an effective detection\nof zero-day attacks. Using realistic experiments, we show that an NIDS which\nalso leverages the active approach is considerably more effective in detecting\nattacks which aim to degrade the network's QoS when compared to an NIDS which\nrelies solely on the passive approach. Lastly, we show that the false positives\nrate remains very low even in the face of Byzantine faults.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2013 12:21:13 GMT"}], "update_date": "2013-06-21", "authors_parsed": [["Menahem", "Eitan", ""], ["Nakibly", "Gabi", ""], ["Elovici", "Yuval", ""]]}, {"id": "1306.4962", "submitter": "Emiliano De Cristofaro", "authors": "Emiliano De Cristofaro", "title": "An Exploratory Ethnographic Study of Issues and Concerns with Whole\n  Genome Sequencing", "comments": "A preliminary version of this paper appears in USEC 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Progress in Whole Genome Sequencing (WGS) will soon allow a large number of\nindividuals to have their genome fully sequenced. This lays the foundations to\nimprove modern healthcare, enabling a new era of personalized medicine where\ndiagnosis and treatment is tailored to the patient's genetic makeup. It also\nallows individuals motivated by personal curiosity to have access to their\ngenetic information, and use it, e.g., to trace their ancestry. However, the\nvery same progress also amplifies a number of ethical and privacy concerns,\nthat stem from the unprecedented sensitivity of genomic information and that\nare not well studied. This paper presents an exploratory ethnographic study of\nusers' perception of privacy and ethical issues with WGS, as well as their\nattitude toward different WGS programs. We report on a series of\nsemi-structured interviews, involving 16 participants, and analyze the results\nboth quantitatively and qualitatively. Our analysis shows that users exhibit\ncommon trust concerns and fear of discrimination, and demand to retain strict\ncontrol over their genetic information. Finally, we highlight the need for\nfurther research in the area and follow-up studies that build on our initial\nfindings.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2013 19:23:42 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2013 06:23:47 GMT"}, {"version": "v3", "created": "Fri, 13 Sep 2013 21:11:37 GMT"}, {"version": "v4", "created": "Thu, 12 Dec 2013 20:22:36 GMT"}, {"version": "v5", "created": "Fri, 31 Jan 2014 08:06:46 GMT"}], "update_date": "2014-02-03", "authors_parsed": [["De Cristofaro", "Emiliano", ""]]}, {"id": "1306.5156", "submitter": "Nadim Kobeissi", "authors": "Nadim Kobeissi and Arlo Breault", "title": "Cryptocat: Adopting Accessibility and Ease of Use as Security Properties", "comments": "Working Draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptocat is a Free and Open Source Software (FL/OSS) browser extension that\nmakes use of web technologies in order to provide easy to use, accessible,\nencrypted instant messaging to the general public. We aim to investigate how to\nbest leverage the accessibility and portability offered by web technologies in\norder to allow encrypted instant messaging an opportunity to better permeate on\na social level. We have found that encrypted communications, while in many\ncases technically well-implemented, suffer from a lack of usage due to their\nbeing unappealing and inaccessible to the \"average end-user\". Our position is\nthat accessibility and ease of use must be treated as security properties. Even\nif a cryptographic system is technically highly qualified, securing user\nprivacy is not achieved without addressing the problem of accessibility. Our\ngoal is to investigate the feasibility of implementing cryptographic systems in\nhighly accessible mediums, and to address the technical and social challenges\nof making encrypted instant messaging accessible and portable.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2013 14:42:55 GMT"}], "update_date": "2013-06-24", "authors_parsed": [["Kobeissi", "Nadim", ""], ["Breault", "Arlo", ""]]}, {"id": "1306.5192", "submitter": "Sindhu Chitikela", "authors": "Sindhu Chitikela", "title": "State Decoding in Multi-Stage Cryptography Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a practical method of quantum tomography for decoding the\nstate of photons in a multistage cryptography protocol. This method works if\nthe polarization angles are defined on a fixed plane, as is assumed in several\nquantum cryptography protocols. We show if there are 2m polarization angles in\na fixed plane, we need m number of filters and m2 number of photons through\neach filter.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2013 22:28:18 GMT"}], "update_date": "2013-06-24", "authors_parsed": [["Chitikela", "Sindhu", ""]]}, {"id": "1306.5326", "submitter": "Giacomo Micheli", "authors": "Giacomo Micheli", "title": "Cryptanalysis of a non-commutative key exchange protocol", "comments": null, "journal-ref": null, "doi": "10.3934/amc.2015.9.247", "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the papers by Alvarez et al. and Pathak and Sanghi a non-commutative based\npublic key exchange is described. A similiar version of it has also been\npatented (US7184551). In this paper we present a polynomial time attack that\nbreaks the variants of the protocol presented in the two papers. Moreover we\nshow that breaking the patented cryptosystem US7184551 can be easily reduced to\nfactoring. We also give some examples to show how efficiently the attack works.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2013 14:43:28 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Micheli", "Giacomo", ""]]}, {"id": "1306.5507", "submitter": "Pallab  Dutta Mr", "authors": "Pallab Dutta", "title": "Java Card for PayTv Application", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart cards are widely used along with PayTV receivers to store secret user\nkeys and to perform security functions to prevent any unauthorized viewing of\nPayTV channels. Java Card technology enables programs written in the Java\nprogramming language to run on smart cards. Smart cards represent one of the\nsmallest computing platforms in use today. The memory configuration of a smart\ncard are of the order of 4K of RAM, 72K of EEPROM, and 24K of ROM. Using Java\ncard provides advantages to the industry in terms of ease of coding, faster\ntime to market and faster upgrades as compared to plain smart cards . Also\ndifferent applications like payTV, e-commerce, health-card can easily be\nimplemented in a single java card as multiple applets corresponding to each\napplication can coexists in a single java card. But there are security concerns\nin java cards and also the performance issues. In this paper, we analyse the\nsuitability of using Java card for PayTV applications as part of conditional\naccess system in place of plain smart cards.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2013 04:01:52 GMT"}], "update_date": "2013-06-25", "authors_parsed": [["Dutta", "Pallab", ""]]}, {"id": "1306.5547", "submitter": "Ji Won Yoon Ph.D.", "authors": "Chae Chang Lee and Ji Won yoon", "title": "A data mining approach using transaction patterns for card fraud\n  detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Credit and debit cards, rather than actual money, have become the universal\npayment means. With these cards, it has become possible to buy expensive items\neasily without an additional complex authentication procedure being conducted.\nHowever, card transaction features are targeted by criminals seeking to use a\nlost or stolen card and looking for a chance to replicate it. Accidents,\nwhether caused by the negligence of users or not, that lead to a transaction\nbeing performed by a criminal rather than the authorized card user should be\nprevented. Therefore, card companies are providing their clients with a variety\nof policies and standards to cover this eventuality. Card companies must\ntherefore be able to distinguish between the rightful user and illegal users\naccording to these standards in order to minimize damage resulting from\nunauthorized transactions.\n  However, there is a limit to applying the same fixed standards to all card\nusers, since the transaction patterns of people differ and even individuals'\ntransaction patterns may change frequently due to changes income and\nconsumption preference. Therefore, when only a specific threshold is applied,\nit is difficult to distinguish a fraudulent card transaction from a legitimate\none.\n  In this paper, we present methods for learning the individual patterns of a\ncard user's transaction amount and the region in which he or she uses the card,\nfor a given period, and for determining whether the specified transaction is\nallowable in accordance with these learned user transaction patterns. Then, we\nclassify legitimate transactions and fraudulent transactions by setting\nthresholds based on the learned individual patterns.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2013 09:21:23 GMT"}], "update_date": "2013-06-25", "authors_parsed": [["Lee", "Chae Chang", ""], ["yoon", "Ji Won", ""]]}, {"id": "1306.5615", "submitter": "Chengqing Li", "authors": "Chengqing Li, Yuansheng Liu, Leo Yu Zhang, Kwok-wo Wong", "title": "Cryptanalyzing a class of image encryption schemes based on Chinese\n  Remainder Theorem", "comments": "7 pages", "journal-ref": "Signal Processing: Image Communication, 29(8): 914-920, 2014", "doi": "10.1016/j.image.2014.06.011", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a fundamental theorem in number theory, the Chinese Reminder Theorem (CRT)\nis widely used to construct cryptographic primitives. This paper investigates\nthe security of a class of image encryption schemes based on CRT, referred to\nas CECRT. Making use of some properties of CRT, the equivalent secret key of\nCECRT can be recovered efficiently. The required number of pairs of chosen\nplaintext and the corresponding ciphertext is only $(1+\\lceil (\\log_2L)/l\n\\rceil)$. The attack complexity is only $O(L)$, where $L$ is the plaintext\nlength and $l$ is the number of bits representing a plaintext symbol. In\naddition, other defects of CECRT such as invalid compression function and low\nsensitivity to plaintext, are reported. The work in this paper will help\nclarify positive role of CRT in cryptology.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2013 13:22:19 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2013 15:57:11 GMT"}, {"version": "v3", "created": "Thu, 29 Sep 2016 06:43:08 GMT"}], "update_date": "2016-09-30", "authors_parsed": [["Li", "Chengqing", ""], ["Liu", "Yuansheng", ""], ["Zhang", "Leo Yu", ""], ["Wong", "Kwok-wo", ""]]}, {"id": "1306.5646", "submitter": "Boaz Tsaban", "authors": "Ciaran Mullan, Boaz Tsaban", "title": "SL2 homomorphic hash functions: Worst case to average case reduction and\n  short collision search", "comments": "Final version. To appear in Design Codes Cryptography", "journal-ref": "Designs Codes and Cryptography 81 (2006), 83--107", "doi": "10.1007/s10623-015-0129-8", "report-no": null, "categories": "cs.CR math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study homomorphic hash functions into SL(2,q), the 2x2 matrices with\ndeterminant 1 over the field with $q$ elements. Modulo a well supported number\ntheoretic hypothesis, which holds in particular for concrete homomorphisms\nproposed thus far, we provide a worst case to average case reduction for these\nhash functions: upto a logarithmic factor, a random homomorphism is as secure\nas _any_ concrete homomorphism. For a family of homomorphisms containing\nseveral concrete proposals in the literature, we prove that collisions of\nlength O(log(q)) can be found in running time O(sqrt(q)). For general\nhomomorphisms we offer an algorithm that, heuristically and according to\nexperiments, in running time O(sqrt(q)) finds collisions of length O(log(q))\nfor q even, and length O(log^2(q)/loglog(q))$ for arbitrary q. While exponetial\ntime, our algorithms are faster in practice than all earlier generic\nalgorithms, and produce much shorter collisions.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2013 14:55:08 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2013 14:56:53 GMT"}, {"version": "v3", "created": "Wed, 23 Dec 2015 17:40:07 GMT"}], "update_date": "2016-07-26", "authors_parsed": [["Mullan", "Ciaran", ""], ["Tsaban", "Boaz", ""]]}, {"id": "1306.5648", "submitter": "Zhixiong Chen", "authors": "Zhixiong Chen", "title": "Trace representation and linear complexity of binary sequences derived\n  from Fermat quotients", "comments": "14 pages, no figures", "journal-ref": null, "doi": "10.1007/s11432-014-5092-x", "report-no": null, "categories": "math.NT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the trace representations of two families of binary sequences\nderived from Fermat quotients modulo an odd prime $p$ (one is the binary\nthreshold sequences, the other is the Legendre-Fermat quotient sequences) via\ndetermining the defining pairs of all binary characteristic sequences of\ncosets, which coincide with the sets of pre-images modulo $p^2$ of each fixed\nvalue of Fermat quotients. From the defining pairs, we can obtain an earlier\nresult of linear complexity for the binary threshold sequences and a new result\nof linear complexity for the Legendre-Fermat quotient sequences under the\nassumption of $2^{p-1}\\not\\equiv 1 \\bmod {p^2}$.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2013 18:19:34 GMT"}], "update_date": "2016-03-15", "authors_parsed": [["Chen", "Zhixiong", ""]]}, {"id": "1306.5678", "submitter": "Michael Clarkson", "authors": "Masoud Koleini and Michael R. Clarkson and Kristopher K. Micinski", "title": "A Temporal Logic of Security", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new logic for verification of security policies is proposed. The logic,\nHyperLTL, extends linear-time temporal logic (LTL) with connectives for\nexplicit and simultaneous quantification over multiple execution paths, thereby\nenabling HyperLTL to express information-flow security policies that LTL\ncannot. A model-checking algorithm for a fragment of HyperLTL is given, and the\nalgorithm is implemented in a prototype model checker. The class of security\npolicies expressible in HyperLTL is characterized by an arithmetic hierarchy of\nhyperproperties.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2013 17:17:29 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2013 18:09:18 GMT"}], "update_date": "2013-07-10", "authors_parsed": [["Koleini", "Masoud", ""], ["Clarkson", "Michael R.", ""], ["Micinski", "Kristopher K.", ""]]}, {"id": "1306.5863", "submitter": "Li Yang", "authors": "Li Yang", "title": "Quantum oblivious transfer and bit commitment protocols based on two\n  non-orthogonal states coding", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Oblivious transfer protocols (R-OT and OT$_{1}^{2}$) are presented based on\nnon-orthogonal states transmission, and the bit commitment protocols on the top\nof OT$_{1}^{2}$ are constructed. Although these OT protocols are all\nunconditional secure, the bit commitment protocols based on OT protocols are\nnot secure against attack similar to that presented by no-go theorem.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2013 07:15:51 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2013 04:18:33 GMT"}, {"version": "v3", "created": "Sun, 8 Feb 2015 12:16:20 GMT"}, {"version": "v4", "created": "Sun, 1 Mar 2015 08:09:44 GMT"}, {"version": "v5", "created": "Thu, 12 Mar 2015 02:15:16 GMT"}, {"version": "v6", "created": "Thu, 9 Mar 2017 10:49:58 GMT"}, {"version": "v7", "created": "Mon, 20 Mar 2017 09:01:13 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Yang", "Li", ""]]}, {"id": "1306.5898", "submitter": "Harald Lampesberger", "authors": "Harald Lampesberger", "title": "A Grammatical Inference Approach to Language-Based Anomaly Detection in\n  XML", "comments": "Paper accepted at First Int. Workshop on Emerging Cyberthreats and\n  Countermeasures ECTCM 2013", "journal-ref": null, "doi": "10.1109/ARES.2013.90", "report-no": null, "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  False-positives are a problem in anomaly-based intrusion detection systems.\nTo counter this issue, we discuss anomaly detection for the eXtensible Markup\nLanguage (XML) in a language-theoretic view. We argue that many XML-based\nattacks target the syntactic level, i.e. the tree structure or element content,\nand syntax validation of XML documents reduces the attack surface. XML offers\nso-called schemas for validation, but in real world, schemas are often\nunavailable, ignored or too general. In this work-in-progress paper we describe\na grammatical inference approach to learn an automaton from example XML\ndocuments for detecting documents with anomalous syntax.\n  We discuss properties and expressiveness of XML to understand limits of\nlearnability. Our contributions are an XML Schema compatible lexical datatype\nsystem to abstract content in XML and an algorithm to learn visibly pushdown\nautomata (VPA) directly from a set of examples. The proposed algorithm does not\nrequire the tree representation of XML, so it can process large documents or\nstreams. The resulting deterministic VPA then allows stream validation of\ndocuments to recognize deviations in the underlying tree structure or\ndatatypes.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2013 09:40:48 GMT"}], "update_date": "2013-11-13", "authors_parsed": [["Lampesberger", "Harald", ""]]}, {"id": "1306.6020", "submitter": "Robert Primmer", "authors": "Robert Primmer, Carl D'Halluin", "title": "Collision and Preimage Resistance of the Centera Content Address", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Centera uses cryptographic hash functions as a means of addressing stored\nobjects, thus creating a new class of data storage referred to as CAS (content\naddressed storage). Such hashing serves the useful function of providing a\nmeans of uniquely identifying data and providing a global handle to that data,\nreferred to as the Content Address or CA. However, such a model begs the\nquestion: how certain can one be that a given CA is indeed unique?\n  In this paper we describe fundamental concepts of cryptographic hash\nfunctions, such as collision resistance, pre-image resistance, and\nsecond-preimage resistance. We then map these properties to the MD5 and SHA-256\nhash algorithms, which are used to generate the Centera content address.\nFinally, we present a proof of the collision resistance of the Centera Content\nAddress.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2013 16:23:16 GMT"}], "update_date": "2013-06-26", "authors_parsed": [["Primmer", "Robert", ""], ["D'Halluin", "Carl", ""]]}, {"id": "1306.6260", "submitter": "Oleksandr Nikitin", "authors": "Oleksandr Nikitin", "title": "Information-Theoretic Security for the Masses", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.IT math.IT", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We combine interactive zero-knowledge protocols and weak physical layer\nrandomness properties to construct a protocol which allows bootstrapping an\nIT-secure and PF-secure channel from a memorizable shared secret. The protocol\nalso tolerates failures of its components, still preserving most of its\nsecurity properties, which makes it accessible to regular users.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2013 14:34:05 GMT"}], "update_date": "2013-06-27", "authors_parsed": [["Nikitin", "Oleksandr", ""]]}, {"id": "1306.6265", "submitter": "Alain Patey", "authors": "Herv\\'e Chabanne, G\\'erard Cohen, Alain Patey", "title": "Towards Secure Two-Party Computation from the Wire-Tap Channel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new protocol for secure two-party computation of linear\nfunctions in the semi-honest model, based on coding techniques. We first\nestablish a parallel between the second version of the wire-tap channel model\nand secure two-party computation. This leads us to our protocol, that combines\nlinear coset coding and oblivious transfer techniques. Our construction\nrequires the use of binary intersecting codes or $q$-ary minimal codes, which\nare also studied in this paper.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2013 15:00:34 GMT"}], "update_date": "2013-06-27", "authors_parsed": [["Chabanne", "Herv\u00e9", ""], ["Cohen", "G\u00e9rard", ""], ["Patey", "Alain", ""]]}, {"id": "1306.6531", "submitter": "Laszlo Kish", "authors": "Laszlo B. Kish, Derek Abbott, Claes-Goran Granqvist", "title": "Critical analysis of the Bennett-Riedel attack on secure cryptographic\n  key distributions via the Kirchhoff-law-Johnson-noise scheme", "comments": "Accepted for publication at PLOS ONE on October 16, 2013. (The simple\n  explanation of why the technically-unlimited Eve is still information\n  theoretically limited is given in Sec.1.1.4)", "journal-ref": "PLoS ONE 8 (2013) e81810", "doi": "10.1371/journal.pone.0081810", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Recently, Bennett and Riedel (BR) (http://arxiv.org/abs/1303.7435v1) argued\nthat thermodynamics is not essential in the Kirchhoff-law-Johnson-noise (KLJN)\nclassical physical cryptographic exchange method in an effort to disprove the\nsecurity of the KLJN scheme. They attempted to demonstrate this by introducing\na dissipation-free deterministic key exchange method with two batteries and two\nswitches. In the present paper, we first show that BR's scheme is unphysical\nand that some elements of its assumptions violate basic protocols of secure\ncommunication. All our analyses are based on a technically-unlimited Eve with\ninfinitely accurate and fast measurements limited only by the laws of physics\nand statistics. For non-ideal situations and at active (invasive) attacks, the\nuncertainly principle between measurement duration and statistical errors makes\nit impossible for Eve to extract the key regardless of the accuracy or speed of\nher measurements. To show that thermodynamics and noise are essential for the\nsecurity, we crack the BR system with 100% success via passive attacks, in ten\ndifferent ways, and demonstrate that the same cracking methods do not function\nfor the KLJN scheme that employs Johnson noise to provide security underpinned\nby the Second Law of Thermodynamics. We also present a critical analysis of\nsome other claims by BR; for example, we prove that their equations for\ndescribing zero security do not apply to the KLJN scheme. Finally we give\nmathematical security proofs for each BR-attack against the KLJN scheme and\nconclude that the information theoretic (unconditional) security of the KLJN\nmethod has not been successfully challenged.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2013 14:57:18 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2013 07:21:06 GMT"}, {"version": "v3", "created": "Sun, 11 Aug 2013 03:07:10 GMT"}, {"version": "v4", "created": "Sun, 8 Sep 2013 21:09:17 GMT"}, {"version": "v5", "created": "Mon, 14 Oct 2013 15:41:26 GMT"}, {"version": "v6", "created": "Sun, 20 Oct 2013 05:12:25 GMT"}], "update_date": "2013-12-18", "authors_parsed": [["Kish", "Laszlo B.", ""], ["Abbott", "Derek", ""], ["Granqvist", "Claes-Goran", ""]]}, {"id": "1306.6657", "submitter": "Markus Rabe", "authors": "Bernd Finkbeiner, Markus N. Rabe, and C\\'esar S\\'anchez", "title": "A Temporal Logic for Hyperproperties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperproperties, as introduced by Clarkson and Schneider, characterize the\ncorrectness of a computer program as a condition on its set of computation\npaths. Standard temporal logics can only refer to a single path at a time, and\ntherefore cannot express many hyperproperties of interest, including\nnoninterference and other important properties in security and coding theory.\nIn this paper, we investigate an extension of temporal logic with explicit path\nvariables. We show that the quantification over paths naturally subsumes other\nextensions of temporal logic with operators for information flow and knowledge.\nThe model checking problem for temporal logic with path quantification is\ndecidable. For alternation depth 1, the complexity is PSPACE in the length of\nthe formula and NLOGSPACE in the size of the system, as for linear-time\ntemporal logic.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2013 20:39:03 GMT"}], "update_date": "2013-07-01", "authors_parsed": [["Finkbeiner", "Bernd", ""], ["Rabe", "Markus N.", ""], ["S\u00e1nchez", "C\u00e9sar", ""]]}, {"id": "1306.6729", "submitter": "Sebastiano Gottardo", "authors": "Mauro Conti, Nicola Dragoni and Sebastiano Gottardo", "title": "MITHYS: Mind The Hand You Shake - Protecting mobile devices from SSL\n  usage vulnerabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that a significant number of mobile applications,\noften handling sensitive data such as bank accounts and login credentials,\nsuffers from SSL vulnerabilities. Most of the time, these vulnerabilities are\ndue to improper use of the SSL protocol (in particular, in its \\emph{handshake}\nphase), resulting in applications exposed to man-in-the-middle attacks. In this\npaper, we present MITHYS, a system able to: (i) detect applications vulnerable\nto man-in-the-middle attacks, and (ii) protect them against these attacks. We\ndemonstrate the feasibility of our proposal by means of a prototype\nimplementation in Android, named MITHYSApp. A thorough set of experiments\nassesses the validity of our solution in detecting and protecting mobile\napplications from man-in-the-middle attacks, without introducing significant\noverheads. Finally, MITHYSApp does not require any special permissions nor OS\nmodifications, as it operates at the application level. These features make\nMITHYSApp immediately deployable on a large user base.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2013 06:45:01 GMT"}], "update_date": "2013-07-01", "authors_parsed": [["Conti", "Mauro", ""], ["Dragoni", "Nicola", ""], ["Gottardo", "Sebastiano", ""]]}, {"id": "1306.6737", "submitter": "Minati Mishra", "authors": "Minati Mishra, Flt. Lt. Dr. M. C. Adhikary", "title": "Digital Image Tamper Detection Techniques - A Comprehensive Study", "comments": "12 pages available online via\n  http://ijcsbi.org/index.php/ijcsbi/article/view/50", "journal-ref": "IJCSBI Vol. 2, No. 1. June 2013", "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photographs are considered to be the most powerful and trustworthy media of\nexpression. For a long time, those were accepted as proves of evidences in\nvaried fields such as journalism, forensic investigations, military\nintelligence, scientific research and publications, crime detection and legal\nproceedings, investigation of insurance claims, medical imaging etc. Today,\ndigital images have completely replaced the conventional photographs from every\nsphere of life but unfortunately, they seldom enjoy the credibility of their\nconventional counterparts, thanks to the rapid advancements in the field of\ndigital image processing. The increasing availability of low cost and sometimes\nfree of cost image editing software such as Photoshop, Corel Paint Shop,\nPhotoscape, PhotoPlus, GIMP and Pixelmator have made the tampering of digital\nimages even more easier and a common practice. Now it has become quite\nimpossible to say whether a photograph is a genuine camera output or a\nmanipulated version of it just by looking at it. As a result, photographs have\nalmost lost their reliability and place as proves of evidences in all fields.\nThis is why digital image tamper detection has emerged as an important research\narea to establish the authenticity of digital photographs by separating the\ntampered lots from the original ones. This paper gives a brief history of image\ntampering and a state-of-the-art review of the tamper detection techniques.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2013 07:22:20 GMT"}], "update_date": "2013-07-01", "authors_parsed": [["Mishra", "Minati", ""], ["Adhikary", "Flt. Lt. Dr. M. C.", ""]]}, {"id": "1306.6805", "submitter": "Sara Hajian", "authors": "Sara Hajian", "title": "Simultaneous Discrimination Prevention and Privacy Protection in Data\n  Publishing and Mining", "comments": "PhD Thesis defended on June 10, 2013, at the Department of Computer\n  Engineering and Mathematics of Universitat Rovira i Virgili. Advisors: Josep\n  Domingo-Ferrer and Dino Pedreschi", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data mining is an increasingly important technology for extracting useful\nknowledge hidden in large collections of data. There are, however, negative\nsocial perceptions about data mining, among which potential privacy violation\nand potential discrimination. Automated data collection and data mining\ntechniques such as classification have paved the way to making automated\ndecisions, like loan granting/denial, insurance premium computation. If the\ntraining datasets are biased in what regards discriminatory attributes like\ngender, race, religion, discriminatory decisions may ensue. In the first part\nof this thesis, we tackle discrimination prevention in data mining and propose\nnew techniques applicable for direct or indirect discrimination prevention\nindividually or both at the same time. We discuss how to clean training\ndatasets and outsourced datasets in such a way that direct and/or indirect\ndiscriminatory decision rules are converted to legitimate (non-discriminatory)\nclassification rules. In the second part of this thesis, we argue that privacy\nand discrimination risks should be tackled together. We explore the\nrelationship between privacy preserving data mining and discrimination\nprevention in data mining to design holistic approaches capable of addressing\nboth threats simultaneously during the knowledge discovery process. As part of\nthis effort, we have investigated for the first time the problem of\ndiscrimination and privacy aware frequent pattern discovery, i.e. the\nsanitization of the collection of patterns mined from a transaction database in\nsuch a way that neither privacy-violating nor discriminatory inferences can be\ninferred on the released patterns. Moreover, we investigate the problem of\ndiscrimination and privacy aware data publishing, i.e. transforming the data,\ninstead of patterns, in order to simultaneously fulfill privacy preservation\nand discrimination prevention.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2013 12:00:56 GMT"}], "update_date": "2013-07-01", "authors_parsed": [["Hajian", "Sara", ""]]}, {"id": "1306.6839", "submitter": "Sowmya Kamath S", "authors": "Karthik R, Raghavendra Karthik, Pramod S and Sowmya Kamath", "title": "W3-Scrape - A Windows based Reconnaissance Tool for Web Application\n  Fingerprinting", "comments": "International Conference on Emerging Trends in Electrical,\n  Communication and Information Technologies (ICECIT 2012), 6 pages; Organised\n  by SRIT, Ananthpur, India during Dec 21 - 23, 2012. (Publisher - Elsevier\n  Science & Technology; ISBN 8131234118, 9788131234112)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web Application finger printing is a quintessential part of the Information\nGathering phase of (ethical) hacking. It allows narrowing down the specifics\ninstead of looking for all clues. Also an application that has been correctly\nrecognized can help in quickly analyzing known weaknesses and then moving ahead\nwith remaining aspects. This step is also essential to allow a pen tester to\ncustomize its payload or exploitation techniques based on the identification so\nto increase the chances of successful intrusion. This paper presents a new tool\n\"W3-Scrape\" for the relatively nascent field of Web Application finger printing\nthat helps automate web application fingerprinting when performed in the\ncurrent scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2013 18:14:03 GMT"}], "update_date": "2013-07-01", "authors_parsed": [["R", "Karthik", ""], ["Karthik", "Raghavendra", ""], ["S", "Pramod", ""], ["Kamath", "Sowmya", ""]]}, {"id": "1306.6920", "submitter": "Deepali Virmani", "authors": "Deepali Virmani, Nidhi Beniwal, Gargi Mandal, Saloni Talwar", "title": "Enhanced Tiny Encryption Algorithm with Embedding (ETEA)", "comments": "9 pages, 3 figures, International Journal of Computers & Technology,\n  Vol 7, No 1, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As computer systems become more pervasive and complex, security is\nincreasingly important. Secure Transmission refers to the transfer of data such\nas confidential or proprietary information over a secure channel. Many secure\ntransmission methods require a type of encryption. Secure transmissions are put\nin place to prevent attacks such as ARP spoofing and general data loss. Hence,\nin order to provide a better security mechanism, in this paper we propose\nEnhanced Tiny Encryption Algorithm with Embedding (ETEA), a data hiding\ntechnique called steganography along with the technique of encryption\n(Cryptography). The advantage of ETEA is that it incorporates cryptography and\nsteganography. The advantage proposed algorithm is that it hides the messages.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2013 10:23:38 GMT"}], "update_date": "2013-07-01", "authors_parsed": [["Virmani", "Deepali", ""], ["Beniwal", "Nidhi", ""], ["Mandal", "Gargi", ""], ["Talwar", "Saloni", ""]]}]