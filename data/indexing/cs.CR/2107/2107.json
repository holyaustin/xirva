[{"id": "2107.00183", "submitter": "Quan-Lin Li", "authors": "Fan-Qi Ma, Quan-Lin Li, Yi-Han Liu, Yan-Xia Chang", "title": "Stochastic Performance Modeling for Practical Byzantine Fault Tolerance\n  Consensus in Blockchain", "comments": "24 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.PF math.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The practical Byzantine fault tolerant (PBFT) consensus mechanism is one of\nthe most basic consensus algorithms (or protocols) in blockchain technologies,\nthus its performance evaluation is an interesting and challenging topic due to\na higher complexity of its consensus work in the peer-to-peer network. This\npaper describes a simple stochastic performance model of the PBFT consensus\nmechanism, which is refined as not only a queueing system with complicated\nservice times but also a level-independent quasi-birth-and-death (QBD) process.\nFrom the level-independent QBD process, we apply the matrix-geometric solution\nto obtain a necessary and sufficient condition under which the PBFT consensus\nsystem is stable, and to be able to numerically compute the stationary\nprobability vector of the QBD process. Thus we provide four useful performance\nmeasures of the PBFT consensus mechanism, and can numerically calculate the\nfour performance measures. Finally, we use some numerical examples to verify\nthe validity of our theoretical results, and show how the four performance\nmeasures are influenced by some key parameters of the PBFT consensus. By means\nof the theory of multi-dimensional Markov processes, we are optimistic that the\nmethodology and results given in this paper are applicable in a wide range\nresearch of PBFT consensus mechanism and even other types of consensus\nmechanisms.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 02:24:45 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Ma", "Fan-Qi", ""], ["Li", "Quan-Lin", ""], ["Liu", "Yi-Han", ""], ["Chang", "Yan-Xia", ""]]}, {"id": "2107.00347", "submitter": "Mariia Bakhtina", "authors": "Mariia Bakhtina, Raimundas Matulevi\\v{c}ius", "title": "Information Security Analysis in the Passenger-Autonomous Vehicle\n  Interaction", "comments": null, "journal-ref": null, "doi": "10.1145/3465481.3470045", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Autonomous vehicles (AV) are becoming a part of humans' everyday life. There\nare numerous pilot projects of driverless public buses; some car manufacturers\ndeliver their premium-level automobiles with advanced self-driving features.\nThus, assuring the security of a Passenger-Autonomous Vehicle interaction\narises as an important research topic, as along with opportunities, new\ncybersecurity risks and challenges occur that potentially may threaten\nPassenger's privacy and safety on the roads. This study proposes an approach of\nthe security requirements elicitation based on the developed threat model.\nThus, information security risk management helps to fulfil one of the\nprinciples needed to protect data privacy - information security. We\ndemonstrate the process of security requirements elicitation to mitigate\narising security risks. The findings of the paper are case-oriented and are\nbased on the literature review. They are applicable for AV system\nimplementation used by ride-hailing service providers that enable supervisory\nAV control.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 10:20:02 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Bakhtina", "Mariia", ""], ["Matulevi\u010dius", "Raimundas", ""]]}, {"id": "2107.00495", "submitter": "Boxiang Dong", "authors": "Boxiang Dong, Bo Zhang, Hui (Wendy) Wang", "title": "VeriDL: Integrity Verification of Outsourced Deep Learning Services\n  (Extended Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Deep neural networks (DNNs) are prominent due to their superior performance\nin many fields. The deep-learning-as-a-service (DLaaS) paradigm enables\nindividuals and organizations (clients) to outsource their DNN learning tasks\nto the cloud-based platforms. However, the DLaaS server may return incorrect\nDNN models due to various reasons (e.g., Byzantine failures). This raises the\nserious concern of how to verify if the DNN models trained by potentially\nuntrusted DLaaS servers are indeed correct. To address this concern, in this\npaper, we design VeriDL, a framework that supports efficient correctness\nverification of DNN models in the DLaaS paradigm. The key idea of VeriDL is the\ndesign of a small-size cryptographic proof of the training process of the DNN\nmodel, which is associated with the model and returned to the client. Through\nthe proof, VeriDL can verify the correctness of the DNN model returned by the\nDLaaS server with a deterministic guarantee and cheap overhead. Our experiments\non four real-world datasets demonstrate the efficiency and effectiveness of\nVeriDL.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 14:37:49 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Dong", "Boxiang", "", "Wendy"], ["Zhang", "Bo", "", "Wendy"], ["Hui", "", "", "Wendy"], ["Wang", "", ""]]}, {"id": "2107.00561", "submitter": "Ryan Feng", "authors": "Nelson Manohar-Alers, Ryan Feng, Sahib Singh, Jiguo Song, Atul Prakash", "title": "Using Anomaly Feature Vectors for Detecting, Classifying and Warning of\n  Outlier Adversarial Examples", "comments": "ICML 2021 workshop on A Blessing in Disguise: The Prospects and\n  Perils of Adversarial Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present DeClaW, a system for detecting, classifying, and warning of\nadversarial inputs presented to a classification neural network. In contrast to\ncurrent state-of-the-art methods that, given an input, detect whether an input\nis clean or adversarial, we aim to also identify the types of adversarial\nattack (e.g., PGD, Carlini-Wagner or clean). To achieve this, we extract\nstatistical profiles, which we term as anomaly feature vectors, from a set of\nlatent features. Preliminary findings suggest that AFVs can help distinguish\namong several types of adversarial attacks (e.g., PGD versus Carlini-Wagner)\nwith close to 93% accuracy on the CIFAR-10 dataset. The results open the door\nto using AFV-based methods for exploring not only adversarial attack detection\nbut also classification of the attack type and then design of attack-specific\nmitigation strategies.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 16:00:09 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Manohar-Alers", "Nelson", ""], ["Feng", "Ryan", ""], ["Singh", "Sahib", ""], ["Song", "Jiguo", ""], ["Prakash", "Atul", ""]]}, {"id": "2107.00577", "submitter": "Ilias Politis Dr", "authors": "Anna Angelogianni, Ilias Politis and Christos Xenakis (University of\n  Piraeus, Greece)", "title": "How many FIDO protocols are needed? Surveying the design, security and\n  market perspectives", "comments": "This paper is submitted for publication to ACM Computing Surveys", "journal-ref": null, "doi": "10.1145/1122445.1122456", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unequivocally, a single man in possession of a strong password is not enough\nto solve the issue of security. Studies indicate that passwords have been\nsubjected to various attacks, regardless of the applied protection mechanisms\ndue to the human factor. The keystone for the adoption of more efficient\nauthentication methods by the different markets is the trade-off between\nsecurity and usability. To bridge the gap between user-friendly interfaces and\nadvanced security features, the Fast Identity Online (FIDO) alliance defined\nseveral authentication protocols. Although FIDO's biometric-based\nauthentication is not a novel concept, still daunts end users and developers,\nwhich may be a contributor factor obstructing FIDO's complete dominance of the\ndigital authentication market. This paper traces the evolution of FIDO\nprotocols, by identifying the technical characteristics and security\nrequirements of the FIDO protocols throughout the different versions while\nproviding a comprehensive study on the different markets (e.g., digital\nbanking, social networks, e-government, etc.), applicability, ease of use,\nextensibility and future security considerations. From the analysis, we\nconclude that there is currently no dominant version of a FIDO protocol and\nmore importantly, earlier FIDO protocols are still applicable to emerging\nvertical services.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 13:56:41 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Angelogianni", "Anna", "", "University of\n  Piraeus, Greece"], ["Politis", "Ilias", "", "University of\n  Piraeus, Greece"], ["Xenakis", "Christos", "", "University of\n  Piraeus, Greece"]]}, {"id": "2107.00580", "submitter": "Hannes Salin", "authors": "Hannes Salin, Dennis Fokin", "title": "Mission Impossible: Securing Master Keys", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Securing a secret master key is a non-trivial task, we even argue it is\nimpossible to fully secure it, hence we must make it as difficult as possible\nfor any powerful adversary to steal or use the key. We introduce the reader to\ninteresting cryptography which is starting to get more attention in terms of\naddressing the above problem, and we briefly overview some commercial and\nopen-source products that can be used. Finally, we propose a set of solutions\non how to secure master keys, more as guidelines rather than exact technical\nspecifications, with aim to inspire and raise awareness of how to increase the\nsecurity as much as possible.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 16:23:37 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Salin", "Hannes", ""], ["Fokin", "Dennis", ""]]}, {"id": "2107.00679", "submitter": "Terry Guo", "authors": "Yang Liu, Terry Guo, Zhe Chen and Xueying Jiang", "title": "Efficient Attribute-Based Smart Contract Access Control Enhanced by\n  Reputation Assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Blockchain's immutability can resist unauthorized changes of ledgers, thus it\ncan be used as a trust enhancement mechanism to a shared system. Indeed,\nblockchain has been considered to solve the security and privacy issues of the\nInternet of Things (IoT). In this regard, most researches currently focus on\nthe realization of various access control models and architectures, and are\nworking towards making full use of the blockchain to secure IoT systems. It is\nworth noting that there has been an increasingly heavy pressure on the\nblockchain storage caused by dealing with massive IoT data and handling\nmalicious access behaviors in the system, and not many countermeasures have\nbeen seen to curb the increase. However, this problem has not been paid enough\nattention. In this paper, we implement an attribute-based access control scheme\nusing smart contracts in Quorum blockchain. It provides basic access control\nfunctions and conserves storage by reducing the number of smart contracts. In\naddition, a reputation-based technique is introduced to cope with malicious\nbehaviors. Certain illegal transactions can be blocked by the credit-assessment\nalgorithm, which deters possibly malicious nodes and gives more chance to\nwell-behaved nodes. The feasibility of our proposed scheme is demonstrated by\ndoing experiment on a testbed and conducting a case study. Finally, the system\nperformance is assessed based on experimental measurement.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 18:07:00 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Liu", "Yang", ""], ["Guo", "Terry", ""], ["Chen", "Zhe", ""], ["Jiang", "Xueying", ""]]}, {"id": "2107.00783", "submitter": "Yunhan Huang", "authors": "Yunhan Huang, Linan Huang, Quanyan Zhu", "title": "Reinforcement Learning for Feedback-Enabled Cyber Resilience", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth in the number of devices and their connectivity has enlarged\nthe attack surface and weakened cyber systems. As attackers become increasingly\nsophisticated and resourceful, mere reliance on traditional cyber protection,\nsuch as intrusion detection, firewalls, and encryption, is insufficient to\nsecure cyber systems. Cyber resilience provides a new security paradigm that\ncomplements inadequate protection with resilience mechanisms. A Cyber-Resilient\nMechanism (CRM) adapts to the known or zero-day threats and uncertainties in\nreal-time and strategically responds to them to maintain the critical functions\nof the cyber systems. Feedback architectures play a pivotal role in enabling\nthe online sensing, reasoning, and actuation of the CRM. Reinforcement Learning\n(RL) is an important class of algorithms that epitomize the feedback\narchitectures for cyber resiliency, allowing the CRM to provide dynamic and\nsequential responses to attacks with limited prior knowledge of the attacker.\nIn this work, we review the literature on RL for cyber resiliency and discuss\nthe cyber-resilient defenses against three major types of vulnerabilities,\ni.e., posture-related, information-related, and human-related vulnerabilities.\nWe introduce moving target defense, defensive cyber deception, and assistive\nhuman security technologies as three application domains of CRMs to elaborate\non their designs. The RL technique also has vulnerabilities itself. We explain\nthe major vulnerabilities of RL and present several attack models in which the\nattacks target the rewards, the measurements, and the actuators. We show that\nthe attacker can trick the RL agent into learning a nefarious policy with\nminimum attacking effort, which shows serious security concerns for RL-enabled\nsystems. Finally, we discuss the future challenges of RL for cyber security and\nresiliency and emerging applications of RL-based CRMs.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 01:08:45 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Huang", "Yunhan", ""], ["Huang", "Linan", ""], ["Zhu", "Quanyan", ""]]}, {"id": "2107.00881", "submitter": "Geet Shingi", "authors": "Geet Shingi, Harsh Saglani, Preeti Jain", "title": "Segmented Federated Learning for Adaptive Intrusion Detection System", "comments": "Accepted at the Workshop on Artificial Intelligence for Social Good\n  (AI4SG) at the 30th International Joint Conference on Artificial Intelligence\n  (IJCAI), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Cyberattacks are a major issues and it causes organizations great financial,\nand reputation harm. However, due to various factors, the current network\nintrusion detection systems (NIDS) seem to be insufficent. Predominant NIDS\nidentifies Cyberattacks through a handcrafted dataset of rules. Although the\nrecent applications of machine learning and deep learning have alleviated the\nenormous effort in NIDS, the security of network data has always been a prime\nconcern. However, to encounter the security problem and enable sharing among\norganizations, Federated Learning (FL) scheme is employed. Although the current\nFL systems have been successful, a network's data distribution does not always\nfit into a single global model as in FL. Thus, in such cases, having a single\nglobal model in FL is no feasible. In this paper, we propose a\nSegmented-Federated Learning (Segmented-FL) learning scheme for a more\nefficient NIDS. The Segmented-FL approach employs periodic local model\nevaluation based on which the segmentation occurs. We aim to bring similar\nnetwork environments to the same group. Further, the Segmented-FL system is\ncoupled with a weighted aggregation of local model parameters based on the\nnumber of data samples a worker possesses to further augment the performance.\nThe improved performance by our system as compared to the FL and centralized\nsystems on standard dataset further validates our system and makes a strong\ncase for extending our technique across various tasks. The solution finds its\napplication in organizations that want to collaboratively learn on diverse\nnetwork environments and protect the privacy of individual datasets.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 07:47:05 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Shingi", "Geet", ""], ["Saglani", "Harsh", ""], ["Jain", "Preeti", ""]]}, {"id": "2107.00911", "submitter": "Katrine Tjell", "authors": "Katrine Tjell and Rafael Wisniewski", "title": "Privacy in Distributed Computations based on Real Number Secret Sharing", "comments": "Submitted to Information Sciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Privacy preservation in distributed computations is an important subject as\ndigitization and new technologies enable collection and storage of vast amounts\nof data, including private data belonging to individuals. To this end, there is\na need for a privacy preserving computation framework that minimises the leak\nof private information during computations while being efficient enough for\npractical usage. This paper presents a step towards such a framework with the\nproposal of a real number secret sharing scheme that works directly on real\nnumbers without the need for conversion to integers which is the case in\nrelated schemes. The scheme offers computations like addition, multiplication,\nand division to be performed directly on secret shared data (the cipher text\nversion of the data). Simulations show that the scheme is much more efficient\nin terms of accuracy than its counterpart version based on integers and finite\nfield arithmetic. The drawback with the proposed scheme is that it is not\nperfectly secure. However, we provide a privacy analysis of the scheme, where\nwe show that the leaked information can be upper bounded and asymptotically\ngoes to zero. To demonstrate the scheme, we use it to perform Kalman filtering\ndirectly on secret shared data.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 09:00:38 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Tjell", "Katrine", ""], ["Wisniewski", "Rafael", ""]]}, {"id": "2107.00925", "submitter": "Mohammad Javad Shayegan", "authors": "Mohammad Javad Shayegan, Hamid Reza Sabor", "title": "A Collective Anomaly Detection Method Over Bitcoin Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The popularity and amazing attractiveness of cryptocurrencies, and especially\nBitcoin, absorb countless enthusiasts daily. Although Blockchain technology\nprevents fraudulent behavior, it cannot detect fraud on its own. There are\nalways unimaginable ways to commit fraud, and the need to use anomaly detection\nmethods to identify abnormal and fraudulent behaviors has become a necessity.\nThe main purpose of this study is to present a new method for detecting\nanomalies in Bitcoin with more appropriate efficiency. For this purpose, in\nthis study, the diagnosis of the collective anomaly was used, and instead of\ndiagnosing the anomaly of individual addresses and wallets, the anomaly of\nusers was examined, and the anomaly was more visible among users who had\nmultiple wallets. In addition to using the collective anomaly detection method\nin this study, the Trimmed_Kmeans algorithm was used for clustering and the\nproposed method succeeded in identifying 14 users who had committed theft,\nfraud, and hack with 26 addresses in 9 cases. Compared to previous works, which\ndetected a maximum of 7 addresses in 5 cases of fraud, the proposed method has\nperformed well. Therefore, the proposed method, by presenting a new approach,\nin addition to reducing the processing power to extract features, succeeded in\ndetecting abnormal users and also was able to find more transactions and\naddresses committed a scam.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 09:34:03 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Shayegan", "Mohammad Javad", ""], ["Sabor", "Hamid Reza", ""]]}, {"id": "2107.01007", "submitter": "Carlos Bendicho PhD", "authors": "Carlos Bendicho", "title": "Cyber Security in Cloud: Risk Assessment Models", "comments": "12 pages, 5 figures, 2 tables", "journal-ref": "Intelligent Computing. Computing Conference 2021. Lecture Notes in\n  Networks and Systems, vol 283. Springer, Cham", "doi": "10.1007/978-3-030-80119-9_28", "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper shows a proposal of the characteristics Cloud Risk\nAssessment Models should have and presents the review of the literature\nconsidering those characteristics in order to identify current gaps. This work\nshows a ranking of Cloud RA models and their degree of compliance with the\ntheoretical reference Cloud Risk Assessment model. The review of literature\nshows that RA approaches leveraging CSA (Cloud Security Alliance) STAR Registry\nthat have into account organizations security requirements present higher\ndegree of compliance, but they still lack risk economic quantification. The\nmyriad of conceptual models, methodologies and frameworks although based on\ncurrent NIST SP 800:30, ISO 27001, ISO 27005, ISO 30001, ENISA standards could\nbe enhanced by the use of techno-economic models like UTEM, created by the\nauthor, in order to conceive more simplified models for effective Risk\nAssessment and Mitigation closer to the theoretical reference model for Cloud\nRisk Assessment, available for all cloud models (IaaS, PaaS, SaaS) and easy to\nuse for all stakeholders.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 14:37:31 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Bendicho", "Carlos", ""]]}, {"id": "2107.01154", "submitter": "Wenqi Wei", "authors": "Wenqi Wei, Ling Liu, Yanzhao Wu, Gong Su, Arun Iyengar", "title": "Gradient-Leakage Resilient Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning(FL) is an emerging distributed learning paradigm with\ndefault client privacy because clients can keep sensitive data on their devices\nand only share local training parameter updates with the federated server.\nHowever, recent studies reveal that gradient leakages in FL may compromise the\nprivacy of client training data. This paper presents a gradient leakage\nresilient approach to privacy-preserving federated learning with per training\nexample-based client differential privacy, coined as Fed-CDP. It makes three\noriginal contributions. First, we identify three types of client gradient\nleakage threats in federated learning even with encrypted client-server\ncommunications. We articulate when and why the conventional server coordinated\ndifferential privacy approach, coined as Fed-SDP, is insufficient to protect\nthe privacy of the training data. Second, we introduce Fed-CDP, the per\nexample-based client differential privacy algorithm, and provide a formal\nanalysis of Fed-CDP with the $(\\epsilon, \\delta)$ differential privacy\nguarantee, and a formal comparison between Fed-CDP and Fed-SDP in terms of\nprivacy accounting. Third, we formally analyze the privacy-utility trade-off\nfor providing differential privacy guarantee by Fed-CDP and present a dynamic\ndecay noise-injection policy to further improve the accuracy and resiliency of\nFed-CDP. We evaluate and compare Fed-CDP and Fed-CDP(decay) with Fed-SDP in\nterms of differential privacy guarantee and gradient leakage resilience over\nfive benchmark datasets. The results show that the Fed-CDP approach outperforms\nconventional Fed-SDP in terms of resilience to client gradient leakages while\noffering competitive accuracy performance in federated learning.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 15:51:07 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Wei", "Wenqi", ""], ["Liu", "Ling", ""], ["Wu", "Yanzhao", ""], ["Su", "Gong", ""], ["Iyengar", "Arun", ""]]}, {"id": "2107.01179", "submitter": "Irippuge Milinda Perera", "authors": "Shailesh Bavadekar and Adam Boulanger and John Davis and Damien\n  Desfontaines and Evgeniy Gabrilovich and Krishna Gadepalli and Badih Ghazi\n  and Tague Griffith and Jai Gupta and Chaitanya Kamath and Dennis Kraft and\n  Ravi Kumar and Akim Kumok and Yael Mayer and Pasin Manurangsi and Arti\n  Patankar and Irippuge Milinda Perera and Chris Scott and Tomer Shekel and\n  Benjamin Miller and Karen Smith and Charlotte Stanton and Mimi Sun and Mark\n  Young and Gregory Wellenius", "title": "Google COVID-19 Vaccination Search Insights: Anonymization Process\n  Description", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This report describes the aggregation and anonymization process applied to\nthe COVID-19 Vaccination Search Insights (published at\nhttp://goo.gle/covid19vaccinationinsights), a publicly available dataset\nshowing aggregated and anonymized trends in Google searches related to COVID-19\nvaccination. The applied anonymization techniques protect every user's daily\nsearch activity related to COVID-19 vaccinations with $(\\varepsilon,\n\\delta)$-differential privacy for $\\varepsilon = 2.19$ and $\\delta = 10^{-5}$.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 16:37:04 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 20:30:06 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Bavadekar", "Shailesh", ""], ["Boulanger", "Adam", ""], ["Davis", "John", ""], ["Desfontaines", "Damien", ""], ["Gabrilovich", "Evgeniy", ""], ["Gadepalli", "Krishna", ""], ["Ghazi", "Badih", ""], ["Griffith", "Tague", ""], ["Gupta", "Jai", ""], ["Kamath", "Chaitanya", ""], ["Kraft", "Dennis", ""], ["Kumar", "Ravi", ""], ["Kumok", "Akim", ""], ["Mayer", "Yael", ""], ["Manurangsi", "Pasin", ""], ["Patankar", "Arti", ""], ["Perera", "Irippuge Milinda", ""], ["Scott", "Chris", ""], ["Shekel", "Tomer", ""], ["Miller", "Benjamin", ""], ["Smith", "Karen", ""], ["Stanton", "Charlotte", ""], ["Sun", "Mimi", ""], ["Young", "Mark", ""], ["Wellenius", "Gregory", ""]]}, {"id": "2107.01185", "submitter": "Prajoy Podder", "authors": "Prajoy Podder, Subrato Bharati, M. Rubaiyat Hossain Mondal, Pinto\n  Kumar Paul, Utku Kose", "title": "Artificial Neural Network for Cybersecurity: A Comprehensive Review", "comments": "14 Pages, 8 Figures", "journal-ref": "Journal of Information Assurance and Security, Volume: 16, Issue:\n  1, 2021, pp.010-023", "doi": null, "report-no": null, "categories": "cs.CR cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cybersecurity is a very emerging field that protects systems, networks, and\ndata from digital attacks. With the increase in the scale of the Internet and\nthe evolution of cyber attacks, developing novel cybersecurity tools has become\nimportant, particularly for Internet of things (IoT) networks. This paper\nprovides a systematic review of the application of deep learning (DL)\napproaches for cybersecurity. This paper provides a short description of DL\nmethods which is used in cybersecurity, including deep belief networks,\ngenerative adversarial networks, recurrent neural networks, and others. Next,\nwe illustrate the differences between shallow learning and DL. Moreover, a\ndiscussion is provided on the currently prevailing cyber-attacks in IoT and\nother networks, and the effectiveness of DL methods to manage these attacks.\nBesides, this paper describes studies that highlight the DL technique,\ncybersecurity applications, and the source of datasets. Next, a discussion is\nprovided on the feasibility of DL systems for malware detection and\nclassification, intrusion detection, and other frequent cyber-attacks,\nincluding identifying file type, spam, and network traffic. Our review\nindicates that high classification accuracy of 99.72% is obtained by restricted\nBoltzmann machine (RBM) when applied to a custom dataset, while long short-term\nmemory (LSTM) achieves an accuracy of 99.80% for KDD Cup 99 dataset. Finally,\nthis article discusses the importance of cybersecurity for reliable and\npracticable IoT-driven healthcare systems.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 09:32:48 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Podder", "Prajoy", ""], ["Bharati", "Subrato", ""], ["Mondal", "M. Rubaiyat Hossain", ""], ["Paul", "Pinto Kumar", ""], ["Kose", "Utku", ""]]}, {"id": "2107.01382", "submitter": "Jack Li", "authors": "Jianhua Li, Ximeng Liu, Jiong JIn, Shui Yu", "title": "Too Expensive to Attack: Enlarge the Attack Expense through Joint\n  Defense at the Edge", "comments": "arXiv admin note: text overlap with arXiv:2104.00236", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The distributed denial of service (DDoS) attack is detrimental to businesses\nand individuals as people are heavily relying on the Internet. Due to\nremarkable profits, crackers favor DDoS as cybersecurity weapons to attack a\nvictim. Even worse, edge servers are more vulnerable. Current solutions lack\nadequate consideration to the expense of attackers and inter-defender\ncollaborations. Hence, we revisit the DDoS attack and defense, clarifying the\nadvantages and disadvantages of both parties. We further propose a joint\ndefense framework to defeat attackers by incurring a significant increment of\nrequired bots and enlarging attack expenses. The quantitative evaluation and\nexperimental assessment showcase that such expense can surge up to thousands of\ntimes. The skyrocket of expenses leads to heavy loss to the cracker, which\nprevents further attacks.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 08:47:41 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Li", "Jianhua", ""], ["Liu", "Ximeng", ""], ["JIn", "Jiong", ""], ["Yu", "Shui", ""]]}, {"id": "2107.01475", "submitter": "Binghui Wang", "authors": "Binghui Wang, Jiayi Guo, Ang Li, Yiran Chen, Hai Li", "title": "Privacy-Preserving Representation Learning on Graphs: A Mutual\n  Information Perspective", "comments": "Accepted by SIGKDD'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning with graphs has attracted significant attention recently. Existing\nrepresentation learning methods on graphs have achieved state-of-the-art\nperformance on various graph-related tasks such as node classification, link\nprediction, etc. However, we observe that these methods could leak serious\nprivate information. For instance, one can accurately infer the links (or node\nidentity) in a graph from a node classifier (or link predictor) trained on the\nlearnt node representations by existing methods. To address the issue, we\npropose a privacy-preserving representation learning framework on graphs from\nthe \\emph{mutual information} perspective. Specifically, our framework includes\na primary learning task and a privacy protection task, and we consider node\nclassification and link prediction as the two tasks of interest. Our goal is to\nlearn node representations such that they can be used to achieve high\nperformance for the primary learning task, while obtaining performance for the\nprivacy protection task close to random guessing. We formally formulate our\ngoal via mutual information objectives. However, it is intractable to compute\nmutual information in practice. Then, we derive tractable variational bounds\nfor the mutual information terms, where each bound can be parameterized via a\nneural network. Next, we train these parameterized neural networks to\napproximate the true mutual information and learn privacy-preserving node\nrepresentations. We finally evaluate our framework on various graph datasets.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 18:09:44 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Wang", "Binghui", ""], ["Guo", "Jiayi", ""], ["Li", "Ang", ""], ["Chen", "Yiran", ""], ["Li", "Hai", ""]]}, {"id": "2107.01559", "submitter": "Ao Liu", "authors": "Ao Liu, Lirong Xia", "title": "Smoothed Differential Privacy", "comments": "9 Page main text + Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy (DP) is a widely-accepted and widely-applied notion of\nprivacy based on worst-case analysis. Often, DP classifies most mechanisms\nwithout external noise as non-private [Dwork et al., 2014], and external\nnoises, such as Gaussian noise or Laplacian noise [Dwork et al., 2006], are\nintroduced to improve privacy. In many real-world applications, however, adding\nexternal noise is undesirable and sometimes prohibited. For example,\npresidential elections often require a deterministic rule to be used [Liu et\nal., 2020], and small noises can lead to dramatic decreases in the prediction\naccuracy of deep neural networks, especially the underrepresented classes\n[Bagdasaryan et al., 2019].\n  In this paper, we propose a natural extension and relaxation of DP following\nthe worst average-case idea behind the celebrated smoothed analysis [Spielman\nand Teng, 2004]. Our notion, the smoothed DP, can effectively measure the\nprivacy leakage of mechanisms without external noises under realistic settings.\n  We prove several strong properties of the smoothed DP, including\ncomposability, robustness to post-processing and etc. We proved that any\ndiscrete mechanism with sampling procedures is more private than what DP\npredicts. In comparison, many continuous mechanisms with sampling procedures\nare still non-private under smoothed DP. Experimentally, we first verified that\nthe discrete sampling mechanisms are private in real-world elections. Then, we\napply the smoothed DP notion on quantized gradient descent, which indicates\nsome neural networks can be private without adding any extra noises. We believe\nthat these results contribute to the theoretical foundation of realistic\nprivacy measures beyond worst-case analysis.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 06:55:45 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 18:30:02 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Liu", "Ao", ""], ["Xia", "Lirong", ""]]}, {"id": "2107.01600", "submitter": "Oliver Stengele", "authors": "Oliver Stengele, Markus Raiber, J\\\"orn M\\\"uller-Quade, Hannes\n  Hartenstein", "title": "ETHTID: Deployable Threshold Information Disclosure on Ethereum", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the Threshold Information Disclosure (TID) problem on Ethereum: An\narbitrary number of users commit to the scheduled disclosure of their\nindividual messages recorded on the Ethereum blockchain if and only if all such\nmessages are disclosed. Before a disclosure, only the original sender of each\nmessage should know its contents. To accomplish this, we task a small council\nwith executing a distributed generation and threshold sharing of an asymmetric\nkey pair. The public key can be used to encrypt messages which only become\nreadable once the threshold-shared decryption key is reconstructed at a\npredefined point in time and recorded on-chain. With blockchains like Ethereum,\nit is possible to coordinate such procedures and attach economic stakes to the\nactions of participating individuals. In this paper, we present ETHTID, an\nEthereum smart contract application to coordinate Threshold Information\nDisclosure. We base our implementation on ETHDKG [1], a smart contract\napplication for distributed key generation and threshold sharing, and adapt it\nto fit our differing use case as well as add functionality to oversee a\nscheduled reconstruction of the decryption key. For our main cost saving\noptimisation, we show that the security of the underlying cryptographic scheme\nis maintained. We evaluate how the execution costs depend on the size of the\ncouncil and the threshold and show that the presented protocol is deployable on\nEthereum with a council of more than 200 members with gas savings of 20-40%\ncompared to ETHDKG.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 12:09:03 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Stengele", "Oliver", ""], ["Raiber", "Markus", ""], ["M\u00fcller-Quade", "J\u00f6rn", ""], ["Hartenstein", "Hannes", ""]]}, {"id": "2107.01620", "submitter": "Mark Stamp", "authors": "Rakesh Nagaraju and Mark Stamp", "title": "Auxiliary-Classifier GAN for Malware Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative adversarial networks (GAN) are a class of powerful machine\nlearning techniques, where both a generative and discriminative model are\ntrained simultaneously. GANs have been used, for example, to successfully\ngenerate \"deep fake\" images. A recent trend in malware research consists of\ntreating executables as images and employing image-based analysis techniques.\nIn this research, we generate fake malware images using auxiliary classifier\nGANs (AC-GAN), and we consider the effectiveness of various techniques for\nclassifying the resulting images. Our results indicate that the resulting\nmulticlass classification problem is challenging, yet we can obtain strong\nresults when restricting the problem to distinguishing between real and fake\nsamples. While the AC-GAN generated images often appear to be very similar to\nreal malware images, we conclude that from a deep learning perspective, the\nAC-GAN generated samples do not rise to the level of deep fake malware images.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 13:15:03 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Nagaraju", "Rakesh", ""], ["Stamp", "Mark", ""]]}, {"id": "2107.01627", "submitter": "Mark Stamp", "authors": "Lolitha Sresta Tupadha and Mark Stamp", "title": "Machine Learning for Malware Evolution Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Malware evolves over time and antivirus must adapt to such evolution. Hence,\nit is critical to detect those points in time where malware has evolved so that\nappropriate countermeasures can be undertaken. In this research, we perform a\nvariety of experiments on a significant number of malware families to determine\nwhen malware evolution is likely to have occurred. All of the evolution\ndetection techniques that we consider are based on machine learning and can be\nfully automated -- in particular, no reverse engineering or other\nlabor-intensive manual analysis is required. Specifically, we consider analysis\nbased on hidden Markov models (HMM) and the word embedding techniques HMM2Vec\nand Word2Vec.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 13:47:06 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Tupadha", "Lolitha Sresta", ""], ["Stamp", "Mark", ""]]}, {"id": "2107.01640", "submitter": "Gamage Dumindu Samaraweera", "authors": "G. Dumindu Samaraweera and J. Morris Chang", "title": "SEC-NoSQL: Towards Implementing High Performance Security-as-a-Service\n  for NoSQL Databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  During the last few years, the explosion of Big Data has prompted cloud\ninfrastructures to provide cloud-based database services as cost effective,\nefficient and scalable solutions to store and process large volume of data.\nHence, NoSQL databases became more and more popular because of their inherent\nfeatures of better performance and high scalability compared to other\nrelational databases. However, with this deployment architecture where the\ninformation is stored in a public cloud, protection against the sensitive data\nis still being a major concern. Since the data owner does not have the full\ncontrol over his sensitive data in a cloud-based database solution, many\norganizations are reluctant to move forward with Database-as-a-Service (DBaaS)\nsolutions. Some of the recent work addressed this issue by introducing\nadditional layers to provide encryption mechanisms to encrypt data, however,\nthese approaches are more application specific and they need to be properly\nevaluated to ensure whether they can achieve high performance with the\nscalability when it comes to large volume of data in a cloud-based production\nenvironment. This paper proposes a practical system design and implementation\nto provide Security-as-a-Service for NoSQL databases (SEC-NoSQL) while\nsupporting the execution of query over encrypted data with guaranteed level of\nsystem performance. Several different models of implementations are proposed,\nand their performance is evaluated using YCSB benchmark considering large\nnumber of clients processing simultaneously. Experimental results show that our\ndesign fits well on encrypted data while maintaining the high performance and\nscalability. Moreover, to deploy our solution as a cloud-based service, a\npractical guide establishing Service Level Agreement (SLA) is also included.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 14:11:40 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Samaraweera", "G. Dumindu", ""], ["Chang", "J. Morris", ""]]}, {"id": "2107.01678", "submitter": "Md Morshed Alam", "authors": "Md Morshed Alam and Weichao Wang (Department of Software and\n  Information Systems, University of North Carolina at Charlotte, NC, USA)", "title": "A Comprehensive Survey on the State-of-the-art Data Provenance\n  Approaches for Security Enforcement", "comments": null, "journal-ref": "Journal of Computer Security. 29(4). 423-446 (2021)", "doi": "10.3233/JCS-200108", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data provenance collects comprehensive information about the events and\noperations in a computer system at both application and system levels. It\nprovides a detailed and accurate history of transactions that help delineate\nthe data flow scenario across the whole system. Data provenance helps achieve\nsystem resilience by uncovering several malicious attack traces after a system\ncompromise that are leveraged by the analyzer to understand the attack behavior\nand discover the level of damage. Existing literature demonstrates a number of\nresearch efforts on information capture, management, and analysis of data\nprovenance. In recent years, provenance in IoT devices attracts several\nresearch efforts because of the proliferation of commodity IoT devices. In this\nsurvey paper, we present a comparative study of the state-of-the-art approaches\nto provenance by classifying them based on frameworks, deployed techniques, and\nsubjects of interest. We also discuss the emergence and scope of data\nprovenance in IoT networks. Finally, we present the urgency in several\ndirections that data provenance needs to pursue, including data management and\nanalysis.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 16:31:57 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Alam", "Md Morshed", "", "Department of Software and\n  Information Systems, University of North Carolina at Charlotte, NC, USA"], ["Wang", "Weichao", "", "Department of Software and\n  Information Systems, University of North Carolina at Charlotte, NC, USA"]]}, {"id": "2107.01707", "submitter": "Rasheed el-Bouri", "authors": "Rasheed el-Bouri, Tingting Zhu, David A. Clifton", "title": "Towards Scheduling Federated Deep Learning using Meta-Gradients for\n  Inter-Hospital Learning", "comments": "11 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given the abundance and ease of access of personal data today, individual\nprivacy has become of paramount importance, particularly in the healthcare\ndomain. In this work, we aim to utilise patient data extracted from multiple\nhospital data centres to train a machine learning model without sacrificing\npatient privacy. We develop a scheduling algorithm in conjunction with a\nstudent-teacher algorithm that is deployed in a federated manner. This allows a\ncentral model to learn from batches of data at each federal node. The teacher\nacts between data centres to update the main task (student) algorithm using the\ndata that is stored in the various data centres. We show that the scheduler,\ntrained using meta-gradients, can effectively organise training and as a result\ntrain a machine learning model on a diverse dataset without needing explicit\naccess to the patient data. We achieve state-of-the-art performance and show\nhow our method overcomes some of the problems faced in the federated learning\nsuch as node poisoning. We further show how the scheduler can be used as a\nmechanism for transfer learning, allowing different teachers to work together\nin training a student for state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 18:45:58 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["el-Bouri", "Rasheed", ""], ["Zhu", "Tingting", ""], ["Clifton", "David A.", ""]]}, {"id": "2107.01709", "submitter": "Paul Staat", "authors": "Paul Staat, Harald Elders-Boll, Christian Zenger, Christof Paar", "title": "Mirror Mirror on the Wall: Next-Generation Wireless Jamming Attacks\n  Based on Software-Controlled Surfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The intelligent reflecting surface (IRS) is a promising new paradigm in\nwireless communications to meet the growing demand for high-speed connectivity\nin next-generation mobile networks. IRS, also known as software-controlled\nmetasurfaces, consist of an array of adjustable radio wave reflectors, enabling\nsmart radio environments, e.g., for enhancing the signal-to-noise ratio (SNR)\nand spatial diversity of wireless channels.\n  Research on IRS to date has been largely focused on constructive\napplications. In this work, we show for the first time that the IRS provides a\npractical low-cost toolkit for attackers to easily perform complex signal\nmanipulation attacks on the physical layer in real time. We introduce the\nenvironment reconfiguration attack (ERA) as a novel class of jamming attacks in\nwireless radio networks. Here, an adversary leverages an IRS to rapidly vary\nthe electromagnetic propagation environment to disturb legitimate receivers.\nThe IRS gives the adversary a key advantage over traditional jamming: It no\nlonger has to actively emit a jamming signal itself while the jamming signal is\ncorrelated to the legitimate communication signal.\n  We thoroughly investigate the ERA using the popular orthogonal frequency\ndivision multiplexing~(OFDM) modulation as an example. We show that the ERA\nallows to severely degrade the available data rates even in entire networks. We\npresent insights to the attack through analytical analysis, simulations, as\nwell as experiments. Our results highlight that the attack also works with\nreasonably small IRS sizes. Finally, we implement an attacker setup and\ndemonstrate a practical ERA to slow down a Wi-Fi network.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 18:58:56 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Staat", "Paul", ""], ["Elders-Boll", "Harald", ""], ["Zenger", "Christian", ""], ["Paar", "Christof", ""]]}, {"id": "2107.01725", "submitter": "Pantea Kiaei", "authors": "Pantea Kiaei, Yuan Yao, Patrick Schaumont", "title": "Real-time Detection and Adaptive Mitigation of Power-based Side-Channel\n  Leakage in SoC", "comments": null, "journal-ref": "Boston (and Beyond) Area Architecture Workshop 2021", "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Power-based side-channel is a serious security threat to the System on Chip\n(SoC). The secret information is leaked from the power profile of the system\nwhile a cryptographic algorithm is running. The mitigation requires efforts\nfrom both the software level and hardware level. Currently, there is no\ncomprehensive solution that can guarantee the whole complex system is free of\nleakage and can generically protect all cryptographic algorithms. In this\npaper, we propose a real-time leakage detection and mitigation system which\nenables the system to monitor the side-channel leakage effects of the hardware.\nOur proposed system has extensions that provide a real-time monitor of power\nconsumption, detection of side-channel leakage, and real-time adaptive\nmitigation of detected side-channel leakage. Our proposed system is generic and\ncan protect any algorithm running on it.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 20:17:53 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Kiaei", "Pantea", ""], ["Yao", "Yuan", ""], ["Schaumont", "Patrick", ""]]}, {"id": "2107.01786", "submitter": "Chao Jin", "authors": "Jun Wang, Chao Jin, Souhail Meftah, Khin Mi Mi Aung", "title": "Popcorn: Paillier Meets Compression For Efficient Oblivious Neural\n  Network Inference", "comments": "This version corrects a naive but significant typo in Table 8 in our\n  previous version. Previously, we mistakenly indicated the communication cost\n  in COM(g), i.e., communication bandwidth in gigabyte. In fact, it should be\n  COM as in this version, and COM presents the communication bandwidth in\n  megabyte. It is megabyte, not gigabyte", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Oblivious inference enables the cloud to provide neural network\ninference-as-a-service (NN-IaaS), whilst neither disclosing the client data nor\nrevealing the server's model. However, the privacy guarantee under oblivious\ninference usually comes with a heavy cost of efficiency and accuracy.\n  We propose Popcorn, a concise oblivious inference framework entirely built on\nthe Paillier homomorphic encryption scheme. We design a suite of novel\nprotocols to compute non-linear activation and max-pooling layers. We leverage\nneural network compression techniques (i.e., neural weights pruning and\nquantization) to accelerate the inference computation. To implement the Popcorn\nframework, we only need to replace algebraic operations of existing networks\nwith their corresponding Paillier homomorphic operations, which is extremely\nfriendly for engineering development.\n  We first conduct the performance evaluation and comparison based on the MNIST\nand CIFAR-10 classification tasks. Compared with existing solutions, Popcorn\nbrings a significant communication overhead deduction, with a moderate runtime\nincrease. Then, we benchmark the performance of oblivious inference on\nImageNet. To our best knowledge, this is the first report based on a\ncommercial-level dataset, taking a step towards the deployment to production.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 04:36:02 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 14:44:35 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Wang", "Jun", ""], ["Jin", "Chao", ""], ["Meftah", "Souhail", ""], ["Aung", "Khin Mi Mi", ""]]}, {"id": "2107.01806", "submitter": "Asaf Shabtai", "authors": "Ron Bitton, Nadav Maman, Inderjeet Singh, Satoru Momiyama, Yuval\n  Elovici, Asaf Shabtai", "title": "A Framework for Evaluating the Cybersecurity Risk of Real World, Machine\n  Learning Production Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although cyberattacks on machine learning (ML) production systems can be\ndestructive, many industry practitioners are ill equipped, lacking tactical and\nstrategic tools that would allow them to analyze, detect, protect against, and\nrespond to cyberattacks targeting their ML-based systems. In this paper, we\ntake a significant step toward securing ML production systems by integrating\nthese systems and their vulnerabilities into cybersecurity risk assessment\nframeworks. Specifically, we performed a comprehensive threat analysis of ML\nproduction systems and developed an extension to the MulVAL attack graph\ngeneration and analysis framework to incorporate cyberattacks on ML production\nsystems. Using the proposed extension, security practitioners can apply attack\ngraph analysis methods in environments that include ML components, thus\nproviding security experts with a practical tool for evaluating the impact and\nquantifying the risk of a cyberattack targeting an ML production system.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 05:58:11 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Bitton", "Ron", ""], ["Maman", "Nadav", ""], ["Singh", "Inderjeet", ""], ["Momiyama", "Satoru", ""], ["Elovici", "Yuval", ""], ["Shabtai", "Asaf", ""]]}, {"id": "2107.01810", "submitter": "Ashutosh Bhatia Dr.", "authors": "Bilwasiva Basu Mallick, Ashutosh Bhatia", "title": "Comparative Analysis of Impact of Cryptography Algorithms on Wireless\n  Sensor Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cryptography techniques are essential for a robust and stable security design\nof a system to mitigate the risk of external attacks and thus improve its\nefficiency. Wireless Sensor Networks (WSNs) play a pivotal role in sensing,\nmonitoring, processing, and accumulating raw data to enhance the performance of\nthe actuators, micro-controllers, embedded architectures, IoT devices, and\ncomputing machines to which they are connected. With so much threat of\npotential adversaries, it is essential to scale up the security level of WSN\nwithout affecting its primary goal of seamless data collection and\ncommunication with relay devices. This paper intends to explore the past and\nongoing research activities in this domain. An extensive study of these\nalgorithms referred here, are studied and analyzed. Based on these findings\nthis paper will illustrate the best possible cryptography algorithms which will\nbe most suited to implement the security aspects of the WSN and protect it from\nany threat and reduce its vulnerabilities. This study will pave the way for\nfuture research on this topic since it will provide a comprehensive and\nholistic view of the subject.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 06:27:49 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Mallick", "Bilwasiva Basu", ""], ["Bhatia", "Ashutosh", ""]]}, {"id": "2107.01854", "submitter": "Ke Ma", "authors": "Ke Ma and Qianqian Xu and Jinshan Zeng and Xiaochun Cao and Qingming\n  Huang", "title": "Poisoning Attack against Estimating from Pairwise Comparisons", "comments": "31 pages", "journal-ref": null, "doi": "10.1109/TPAMI.2021.3087514", "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.GT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  As pairwise ranking becomes broadly employed for elections, sports\ncompetitions, recommendations, and so on, attackers have strong motivation and\nincentives to manipulate the ranking list. They could inject malicious\ncomparisons into the training data to fool the victim. Such a technique is\ncalled poisoning attack in regression and classification tasks. In this paper,\nto the best of our knowledge, we initiate the first systematic investigation of\ndata poisoning attacks on pairwise ranking algorithms, which can be formalized\nas the dynamic and static games between the ranker and the attacker and can be\nmodeled as certain kinds of integer programming problems. To break the\ncomputational hurdle of the underlying integer programming problems, we\nreformulate them into the distributionally robust optimization (DRO) problems,\nwhich are computationally tractable. Based on such DRO formulations, we propose\ntwo efficient poisoning attack algorithms and establish the associated\ntheoretical guarantees. The effectiveness of the suggested poisoning attack\nstrategies is demonstrated by a series of toy simulations and several real data\nexperiments. These experimental results show that the proposed methods can\nsignificantly reduce the performance of the ranker in the sense that the\ncorrelation between the true ranking list and the aggregated results can be\ndecreased dramatically.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 08:16:01 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Ma", "Ke", ""], ["Xu", "Qianqian", ""], ["Zeng", "Jinshan", ""], ["Cao", "Xiaochun", ""], ["Huang", "Qingming", ""]]}, {"id": "2107.01885", "submitter": "Fernando Martin-Rodriguez Ph.D.", "authors": "Fernando Martin-Rodriguez", "title": "PRNU Based Source Camera Identification for Webcam Videos", "comments": "4 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This communication is about an application of image forensics where we use\ncamera sensor fingerprints to identify source camera (SCI: Source Camera\nIdentification) in webcam videos. Sensor or camera fingerprints are based on\ncomputing the intrinsic noise that is always present in this kind of sensors\ndue to manufacturing imperfections. This is an unavoidable characteristic that\nlinks each sensor with its noise pattern. PRNU (Photo Response Non-Uniformity)\nhas become the default technique to compute a camera fingerprint. There are\nmany applications nowadays dealing with PRNU patterns for camera identification\nusing still images. In this work we focus on video, more specifically on webcam\nvideo, because of the great importance of webcam video nowadays. Three possible\nmethods for SCI are implemented and assessed in this work.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 09:15:24 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Martin-Rodriguez", "Fernando", ""]]}, {"id": "2107.01895", "submitter": "Yipeng Zhou", "authors": "Yipeng Zhou and Xuezheng Liu and Yao Fu and Di Wu and Chao Li and Shui\n  Yu", "title": "Optimizing the Numbers of Queries and Replies in Federated Learning with\n  Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) empowers distributed clients to collaboratively train\na shared machine learning model through exchanging parameter information.\nDespite the fact that FL can protect clients' raw data, malicious users can\nstill crack original data with disclosed parameters. To amend this flaw,\ndifferential privacy (DP) is incorporated into FL clients to disturb original\nparameters, which however can significantly impair the accuracy of the trained\nmodel. In this work, we study a crucial question which has been vastly\noverlooked by existing works: what are the optimal numbers of queries and\nreplies in FL with DP so that the final model accuracy is maximized. In FL, the\nparameter server (PS) needs to query participating clients for multiple global\niterations to complete training. Each client responds a query from the PS by\nconducting a local iteration. Our work investigates how many times the PS\nshould query clients and how many times each client should reply the PS. We\ninvestigate two most extensively used DP mechanisms (i.e., the Laplace\nmechanism and Gaussian mechanisms). Through conducting convergence rate\nanalysis, we can determine the optimal numbers of queries and replies in FL\nwith DP so that the final model accuracy can be maximized. Finally, extensive\nexperiments are conducted with publicly available datasets: MNIST and FEMNIST,\nto verify our analysis and the results demonstrate that properly setting the\nnumbers of queries and replies can significantly improve the final model\naccuracy in FL with DP.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 09:42:56 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Zhou", "Yipeng", ""], ["Liu", "Xuezheng", ""], ["Fu", "Yao", ""], ["Wu", "Di", ""], ["Li", "Chao", ""], ["Yu", "Shui", ""]]}, {"id": "2107.01912", "submitter": "Prajwol Kumar Nakarmi", "authors": "Srinath Potnuru and Prajwol Kumar Nakarmi", "title": "Berserker: ASN.1-based Fuzzing of Radio Resource Control Protocol for 4G\n  and 5G", "comments": "19 pages, 9 figures, 17 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Telecom networks together with mobile phones must be rigorously tested for\nrobustness against vulnerabilities in order to guarantee availability. RRC\nprotocol is responsible for the management of radio resources and is among the\nmost important telecom protocols whose extensive testing is warranted. To that\nend, we present a novel RRC fuzzer, called Berserker, for 4G and 5G.\nBerserker's novelty comes from being backward and forward compatible to any\nversion of 4G and 5G RRC technical specifications. It is based on RRC message\nformat definitions in ASN.1 and additionally covers fuzz testing of another\nprotocol, called NAS, tunneled in RRC. Berserker uses concrete implementations\nof telecom protocol stack and is unaffected by lower layer protocol handlings\nlike encryption and segmentation. It is also capable of evading size and type\nconstraints in RRC message format definitions. Berserker discovered two\npreviously unknown serious vulnerabilities in srsLTE -- one of which also\naffects openLTE -- confirming its applicability to telecom robustness.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 10:06:25 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Potnuru", "Srinath", ""], ["Nakarmi", "Prajwol Kumar", ""]]}, {"id": "2107.01915", "submitter": "Dominik Sisejkovic", "authors": "Dominik Sisejkovic, Lennart M. Reimann, Elmira Moussavi, Farhad\n  Merchant, Rainer Leupers", "title": "Logic Locking at the Frontiers of Machine Learning: A Survey on\n  Developments and Opportunities", "comments": "6 pages, 3 figures, accepted at VLSI-SOC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the past decade, a lot of progress has been made in the design and\nevaluation of logic locking; a premier technique to safeguard the integrity of\nintegrated circuits throughout the electronics supply chain. However, the\nwidespread proliferation of machine learning has recently introduced a new\npathway to evaluating logic locking schemes. This paper summarizes the recent\ndevelopments in logic locking attacks and countermeasures at the frontiers of\ncontemporary machine learning models. Based on the presented work, the key\ntakeaways, opportunities, and challenges are highlighted to offer\nrecommendations for the design of next-generation logic locking.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 10:18:26 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 09:19:20 GMT"}, {"version": "v3", "created": "Wed, 21 Jul 2021 15:41:04 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Sisejkovic", "Dominik", ""], ["Reimann", "Lennart M.", ""], ["Moussavi", "Elmira", ""], ["Merchant", "Farhad", ""], ["Leupers", "Rainer", ""]]}, {"id": "2107.01917", "submitter": "Vedad Hadzic", "authors": "Vedad Hadzic, Robert Primas and Roderick Bloem", "title": "Proving SIFA Protection of Masked Redundant Circuits", "comments": "This is the extended version of the paper published at ATVA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implementation attacks like side-channel and fault attacks pose a\nconsiderable threat to cryptographic devices that are physically accessible by\nan attacker. As a consequence, devices like smart cards implement corresponding\ncountermeasures like redundant computation and masking. Recently, statistically\nineffective fault attacks (SIFA) were shown to be able to circumvent these\nclassical countermeasure techniques. We present a new approach for verifying\nthe SIFA protection of arbitrary masked implementations in both hardware and\nsoftware. The proposed method uses Boolean dependency analysis, factorization,\nand known properties of masked computations to show whether the fault detection\nmechanism of redundant masked circuits can leak information about the processed\nsecret values. We implemented this new method in a tool called Danira, which\ncan show the SIFA resistance of cryptographic implementations like AES S-Boxes\nwithin minutes.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 10:20:45 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Hadzic", "Vedad", ""], ["Primas", "Robert", ""], ["Bloem", "Roderick", ""]]}, {"id": "2107.01927", "submitter": "Ahmed Hashem El Fiky", "authors": "Ahmed Hashem El Fiky, Ayman El Shenawy, Mohamed Ashraf Madkour", "title": "Android Malware Category and Family Detection and Identification using\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Android malware is one of the most dangerous threats on the internet, and\nit's been on the rise for several years. Despite significant efforts in\ndetecting and classifying android malware from innocuous android applications,\nthere is still a long way to go. As a result, there is a need to provide a\nbasic understanding of the behavior displayed by the most common Android\nmalware categories and families. Each Android malware family and category has a\ndistinct objective. As a result, it has impacted every corporate area,\nincluding healthcare, banking, transportation, government, and e-commerce. In\nthis paper, we presented two machine-learning approaches for Dynamic Analysis\nof Android Malware: one for detecting and identifying Android Malware\nCategories and the other for detecting and identifying Android Malware\nFamilies, which was accomplished by analyzing a massive malware dataset with 14\nprominent malware categories and 180 prominent malware families of\nCCCS-CIC-AndMal2020 dataset on Dynamic Layers. Our approach achieves in Android\nMalware Category detection more than 96 % accurate and achieves in Android\nMalware Family detection more than 99% accurate. Our approach provides a method\nfor high-accuracy Dynamic Analysis of Android Malware while also shortening the\ntime required to analyze smartphone malware.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 10:48:40 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Fiky", "Ahmed Hashem El", ""], ["Shenawy", "Ayman El", ""], ["Madkour", "Mohamed Ashraf", ""]]}, {"id": "2107.01943", "submitter": "Jon Vadillo Jueguen", "authors": "Jon Vadillo, Roberto Santana and Jose A. Lozano", "title": "When and How to Fool Explainable Models (and Humans) with Adversarial\n  Examples", "comments": "12 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reliable deployment of machine learning models such as neural networks\ncontinues to be challenging due to several limitations. Some of the main\nshortcomings are the lack of interpretability and the lack of robustness\nagainst adversarial examples or out-of-distribution inputs. In this paper, we\nexplore the possibilities and limits of adversarial attacks for explainable\nmachine learning models. First, we extend the notion of adversarial examples to\nfit in explainable machine learning scenarios, in which the inputs, the output\nclassifications and the explanations of the model's decisions are assessed by\nhumans. Next, we propose a comprehensive framework to study whether (and how)\nadversarial examples can be generated for explainable models under human\nassessment, introducing novel attack paradigms. In particular, our framework\nconsiders a wide range of relevant (yet often ignored) factors such as the type\nof problem, the user expertise or the objective of the explanations in order to\nidentify the attack strategies that should be adopted in each scenario to\nsuccessfully deceive the model (and the human). These contributions intend to\nserve as a basis for a more rigorous and realistic study of adversarial\nexamples in the field of explainable machine learning.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 11:20:55 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Vadillo", "Jon", ""], ["Santana", "Roberto", ""], ["Lozano", "Jose A.", ""]]}, {"id": "2107.01979", "submitter": "Niek Tax", "authors": "Niek Tax, Kees Jan de Vries, Mathijs de Jong, Nikoleta Dosoula, Bram\n  van den Akker, Jon Smith, Olivier Thuong, Lucas Bernardi", "title": "Machine Learning for Fraud Detection in E-Commerce: A Research Agenda", "comments": "Accepted and to appear in the proceedings of the KDD 2021 co-located\n  workshop: the 2nd International Workshop on Deployable Machine Learning for\n  Security Defense (MLHat)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fraud detection and prevention play an important part in ensuring the\nsustained operation of any e-commerce business. Machine learning (ML) often\nplays an important role in these anti-fraud operations, but the organizational\ncontext in which these ML models operate cannot be ignored. In this paper, we\ntake an organization-centric view on the topic of fraud detection by\nformulating an operational model of the anti-fraud departments in e-commerce\norganizations. We derive 6 research topics and 12 practical challenges for\nfraud detection from this operational model. We summarize the state of the\nliterature for each research topic, discuss potential solutions to the\npractical challenges, and identify 22 open research challenges.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 12:37:29 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Tax", "Niek", ""], ["de Vries", "Kees Jan", ""], ["de Jong", "Mathijs", ""], ["Dosoula", "Nikoleta", ""], ["Akker", "Bram van den", ""], ["Smith", "Jon", ""], ["Thuong", "Olivier", ""], ["Bernardi", "Lucas", ""]]}, {"id": "2107.02005", "submitter": "Francesc Wilhelmi", "authors": "Lorenza Giupponi and Francesc Wilhelmi", "title": "Blockchain-enabled Network Sharing for O-RAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The innovation provided by network virtualization in 5G, together with\nstandardization and openness boosted by the Open Radio Access Network (O-RAN)\nAlliance, has paved the way to a collaborative future in cellular systems,\ndriven by flexible network sharing. Such advents are expected to attract new\nplayers like content providers and verticals, increasing competitiveness in the\ntelecom market. However, scalability and trust issues are expected to arise,\ngiven the criticality of ownership traceability and resource exchanging in an\nopen RAN sharing ecosystem. To address that, we propose the integration of\nBlockchain (BC) technology for enabling mobile operators (OPs) and other\nplayers to exchange RAN resources (e.g., infrastructure, spectrum usage) in the\nform of virtual network functions (VNF) autonomously and dynamically. BC will\nprovide automation, robustness, trustworthiness, and reliability to mobile\nnetworks, so that confidence is generated in an open RAN environment. In\nparticular, we define a novel O-RAN-based BC-enabled architecture that allows\nautomating RAN sharing procedures through either auction or marketplace-based\nmechanisms. The potential advantages of the proposed solution are demonstrated\nthrough simulation results. The used simulation platform is openly released.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 13:24:33 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Giupponi", "Lorenza", ""], ["Wilhelmi", "Francesc", ""]]}, {"id": "2107.02013", "submitter": "Jie Ding", "authors": "Ganghua Wang and Jie Ding", "title": "Subset Privacy: Draw from an Obfuscated Urn", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapidly increasing ability to collect and analyze personal data,\ndata privacy becomes an emerging concern. In this work, we develop a new\nstatistical notion of local privacy to protect each categorical data that will\nbe collected by untrusted entities. The proposed solution, named subset\nprivacy, privatizes the original data value by replacing it with a random\nsubset containing that value. We develop methods for the estimation of\ndistribution functions and independence testing from subset-private data with\ntheoretical guarantees. We also study different mechanisms to realize the\nsubset privacy and evaluation metrics to quantify the amount of privacy in\npractice. Experimental results on both simulated and real-world datasets\ndemonstrate the encouraging performance of the developed concepts and methods.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 16:01:27 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Wang", "Ganghua", ""], ["Ding", "Jie", ""]]}, {"id": "2107.02045", "submitter": "Xiaoyu Cao", "authors": "Xiaoyu Cao and Neil Zhenqiang Gong", "title": "Understanding the Security of Deepfake Detection", "comments": "To appear in SecureComm 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deepfakes pose growing challenges to the trust of information on the\nInternet. Thus, detecting deepfakes has attracted increasing attentions from\nboth academia and industry. State-of-the-art deepfake detection methods consist\nof two key components, i.e., face extractor and face classifier, which extract\nthe face region in an image and classify it to be real/fake, respectively.\nExisting studies mainly focused on improving the detection performance in\nnon-adversarial settings, leaving security of deepfake detection in adversarial\nsettings largely unexplored. In this work, we aim to bridge the gap. In\nparticular, we perform a systematic measurement study to understand the\nsecurity of the state-of-the-art deepfake detection methods in adversarial\nsettings. We use two large-scale public deepfakes data sources including\nFaceForensics++ and Facebook Deepfake Detection Challenge, where the deepfakes\nare fake face images; and we train state-of-the-art deepfake detection methods.\nThese detection methods can achieve 0.94--0.99 accuracies in non-adversarial\nsettings on these datasets. However, our measurement results uncover multiple\nsecurity limitations of the deepfake detection methods in adversarial settings.\nFirst, we find that an attacker can evade a face extractor, i.e., the face\nextractor fails to extract the correct face regions, via adding small Gaussian\nnoise to its deepfake images. Second, we find that a face classifier trained\nusing deepfakes generated by one method cannot detect deepfakes generated by\nanother method, i.e., an attacker can evade detection via generating deepfakes\nusing a new method. Third, we find that an attacker can leverage backdoor\nattacks developed by the adversarial machine learning community to evade a face\nclassifier. Our results highlight that deepfake detection should consider the\nadversarial nature of the problem.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 14:18:21 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 13:04:14 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Cao", "Xiaoyu", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "2107.02096", "submitter": "Roshan Rajapakse", "authors": "Roshan Namal Rajapakse, Mansooreh Zahedi, Muhammad Ali Babar", "title": "An Empirical Analysis of Practitioners' Perspectives on Security Tool\n  Integration into DevOps", "comments": "[v3] Camera-ready version (with a few improvements)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background: Security tools play a vital role in enabling developers to build\nsecure software. However, it can be quite challenging to introduce and fully\nleverage security tools without affecting the speed or frequency of deployments\nin the DevOps paradigm. Aims: We aim to empirically investigate the key\nchallenges practitioners face when integrating security tools into a DevOps\nworkflow in order to provide recommendations to overcome them. Method: We\nconducted a study involving 31 systematically selected webinars on integrating\nsecurity tools in DevOps. We used a qualitative data analysis method, i.e.,\nthematic analysis, to identify the challenges and emerging solutions related to\nintegrating security tools in rapid deployment environments. Results: We find\nthat while traditional security tools are unable to cater for the needs of\nDevOps, the industry is moving towards new generations of tools that have\nstarted focusing on these requirements. We have developed a DevOps workflow\nthat integrates security tools and a set of guidelines by synthesizing\npractitioners' recommendations in the analyzed webinars. Conclusion: While the\nlatest security tools are addressing some of the requirements of DevOps, there\nare many tool-related drawbacks yet to be adequately addressed.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 15:42:15 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 12:15:13 GMT"}, {"version": "v3", "created": "Mon, 19 Jul 2021 08:31:42 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Rajapakse", "Roshan Namal", ""], ["Zahedi", "Mansooreh", ""], ["Babar", "Muhammad Ali", ""]]}, {"id": "2107.02362", "submitter": "Wencheng Yang", "authors": "Jyoti Fakirah, Lauhim Mahfuz Zishan, Roshni Mooruth, Michael N.\n  Johnstone, Wencheng Yang", "title": "A Low-Cost Machine Learning Based Network Intrusion Detection System\n  with Data Privacy Preservation", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network intrusion is a well-studied area of cyber security. Current machine\nlearning-based network intrusion detection systems (NIDSs) monitor network data\nand the patterns within those data but at the cost of presenting significant\nissues in terms of privacy violations which may threaten end-user privacy.\nTherefore, to mitigate risk and preserve a balance between security and\nprivacy, it is imperative to protect user privacy with respect to intrusion\ndata. Moreover, cost is a driver of a machine learning-based NIDS because such\nsystems are increasingly being deployed on resource-limited edge devices. To\nsolve these issues, in this paper we propose a NIDS called PCC-LSM-NIDS that is\ncomposed of a Pearson Correlation Coefficient (PCC) based feature selection\nalgorithm and a Least Square Method (LSM) based privacy-preserving algorithm to\nachieve low-cost intrusion detection while providing privacy preservation for\nsensitive data. The proposed PCC-LSM-NIDS is tested on the benchmark intrusion\ndatabase UNSW-NB15, using five popular classifiers. The experimental results\nshow that the proposed PCC-LSM-NIDS offers advantages in terms of less\ncomputational time, while offering an appropriate degree of privacy protection.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 02:51:00 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Fakirah", "Jyoti", ""], ["Zishan", "Lauhim Mahfuz", ""], ["Mooruth", "Roshni", ""], ["Johnstone", "Michael N.", ""], ["Yang", "Wencheng", ""]]}, {"id": "2107.02408", "submitter": "Shahroz Tariq", "authors": "Minha Kim and Shahroz Tariq and Simon S. Woo", "title": "CoReD: Generalizing Fake Media Detection with Continual Representation\n  using Distillation", "comments": "10 pages, 2 Figures, 10 Tables, Accepted for publication in the 29th\n  ACM International Conference on Multimedia (ACMMM '21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last few decades, artificial intelligence research has made\ntremendous strides, but it still heavily relies on fixed datasets in stationary\nenvironments. Continual learning is a growing field of research that examines\nhow AI systems can learn sequentially from a continuous stream of linked data\nin the same way that biological systems do. Simultaneously, fake media such as\ndeepfakes and synthetic face images have emerged as significant to current\nmultimedia technologies. Recently, numerous method has been proposed which can\ndetect deepfakes with high accuracy. However, they suffer significantly due to\ntheir reliance on fixed datasets in limited evaluation settings. Therefore, in\nthis work, we apply continuous learning to neural networks' learning dynamics,\nemphasizing its potential to increase data efficiency significantly. We propose\nContinual Representation using Distillation (CoReD) method that employs the\nconcept of Continual Learning (CoL), Representation Learning (ReL), and\nKnowledge Distillation (KD). We design CoReD to perform sequential domain\nadaptation tasks on new deepfake and GAN-generated synthetic face datasets,\nwhile effectively minimizing the catastrophic forgetting in a teacher-student\nmodel setting. Our extensive experimental results demonstrate that our method\nis efficient at domain adaptation to detect low-quality deepfakes videos and\nGAN-generated images from several datasets, outperforming the-state-of-art\nbaseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 06:07:17 GMT"}, {"version": "v2", "created": "Sat, 10 Jul 2021 05:27:16 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Kim", "Minha", ""], ["Tariq", "Shahroz", ""], ["Woo", "Simon S.", ""]]}, {"id": "2107.02488", "submitter": "Takami Sato", "authors": "Takami Sato and Qi Alfred Chen", "title": "On Robustness of Lane Detection Models to Physical-World Adversarial\n  Attacks in Autonomous Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After the 2017 TuSimple Lane Detection Challenge, its evaluation based on\naccuracy and F1 score has become the de facto standard to measure the\nperformance of lane detection methods. In this work, we conduct the first\nlarge-scale empirical study to evaluate the robustness of state-of-the-art lane\ndetection methods under physical-world adversarial attacks in autonomous\ndriving. We evaluate 4 major types of lane detection approaches with the\nconventional evaluation and end-to-end evaluation in autonomous driving\nscenarios and then discuss the security proprieties of each lane detection\nmodel. We demonstrate that the conventional evaluation fails to reflect the\nrobustness in end-to-end autonomous driving scenarios. Our results show that\nthe most robust model on the conventional metrics is the least robust in the\nend-to-end evaluation. Although the competition dataset and its metrics have\nplayed a substantial role in developing performant lane detection methods along\nwith the rapid development of deep neural networks, the conventional evaluation\nis becoming obsolete and the gap between the metrics and practicality is\ncritical. We hope that our study will help the community make further progress\nin building a more comprehensive framework to evaluate lane detection models.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 09:04:47 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Sato", "Takami", ""], ["Chen", "Qi Alfred", ""]]}, {"id": "2107.02538", "submitter": "Ashraf Tantawy", "authors": "Ashraf Tantawy", "title": "Automated Malware Design for Cyber Physical Systems", "comments": null, "journal-ref": "9th International Symposium on Digital Forensics and Security,\n  Elazig Turkey, 2021", "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of attacks for cyber physical systems is critical to assess CPS\nresilience at design time and run-time, and to generate rich datasets from\ntestbeds for research. Attacks against cyber physical systems distinguish\nthemselves from IT attacks in that the main objective is to harm the physical\nsystem. Therefore, both cyber and physical system knowledge are needed to\ndesign such attacks. The current practice to generate attacks either focuses on\nthe cyber part of the system using IT cyber security existing body of\nknowledge, or uses heuristics to inject attacks that could potentially harm the\nphysical process. In this paper, we present a systematic approach to\nautomatically generate integrity attacks from the CPS safety and control\nspecifications, without knowledge of the physical system or its dynamics. The\ngenerated attacks violate the system operational and safety requirements, hence\npresent a genuine test for system resilience. We present an algorithm to\nautomate the malware payload development. Several examples are given throughout\nthe paper to illustrate the proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 11:10:10 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Tantawy", "Ashraf", ""]]}, {"id": "2107.02617", "submitter": "Pavel Hub\\'a\\v{c}ek", "authors": "Pavel Hub\\'a\\v{c}ek and Jan V\\'aclavek", "title": "On Search Complexity of Discrete Logarithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study the discrete logarithm problem in the context of TFNP\n- the complexity class of search problems with a syntactically guaranteed\nexistence of a solution for all instances. Our main results establish that\nsuitable variants of the discrete logarithm problem are complete for the\ncomplexity class PPP, respectively PWPP, i.e., the subclasses of TFNP capturing\ntotal search problems with a solution guaranteed by the pigeonhole principle,\nrespectively the weak pigeonhole principle. Besides answering an open problem\nfrom the recent work of Sotiraki, Zampetakis, and Zirdelis (FOCS'18), our\ncompleteness results for PPP and PWPP have implications for the recent line of\nwork proving conditional lower bounds for problems in TFNP under cryptographic\nassumptions. In particular, they highlight that any attempt at basing\naverage-case hardness in subclasses of TFNP (other than PWPP and PPP) on the\naverage-case hardness of the discrete logarithm problem must exploit its\nstructural properties beyond what is necessary for constructions of\ncollision-resistant hash functions.\n  Additionally, our reductions provide new structural insights into the class\nPWPP by establishing two new PWPP-complete problems. First, the problem DOVE, a\nrelaxation of the PPP-complete problem PIGEON. DOVE is the first PWPP-complete\nproblem not defined in terms of an explicitly shrinking function. Second, the\nproblem CLAW, a total search problem capturing the computational complexity of\nbreaking claw-free permutations. In the context of TFNP, the PWPP-completeness\nof CLAW matches the known intrinsic relationship between collision-resistant\nhash functions and claw-free permutations established in the cryptographic\nliterature.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 13:49:04 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Hub\u00e1\u010dek", "Pavel", ""], ["V\u00e1clavek", "Jan", ""]]}, {"id": "2107.02648", "submitter": "Tao Wang", "authors": "Tao Wang and Tongjiang Yan and Yuhua Sun and Shiwen Sun and Xueting\n  Wang", "title": "A new family of quantum synchronizable codes from negacyclic codes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum synchronizable codes are kinds of quantum error-correcting codes that\ncan not only correct the effects of quantum noise on qubits but also the\nmisalignment in block synchronization. In this paper, a new method for\nconstruct quantum synchronizable codes from negacyclic codes are proposed,\nwhere the length of these negacyclic codes are $p$ and $pq$. Through this\nmethod, the quantum synchronizable code possesses optimal or almost optimal\nerror-correcting capability towards bits errors and phase errors, since the\nnegacyclic codes we used are optimal or almost optimal. Moreover, this paper\ncontributes to construct two classes quantum synchronizable codes, whose\nsynchronization capabilities can reach the upper limit under certain\nconditions.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 14:39:31 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Wang", "Tao", ""], ["Yan", "Tongjiang", ""], ["Sun", "Yuhua", ""], ["Sun", "Shiwen", ""], ["Wang", "Xueting", ""]]}, {"id": "2107.02753", "submitter": "Nuno Oliveira", "authors": "Jos\\'e Carneiro, Nuno Oliveira, Norberto Sousa, Eva Maia, Isabel\n  Pra\\c{c}a", "title": "Machine Learning for Network-based Intrusion Detection Systems: an\n  Analysis of the CIDDS-001 Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the increasing amount of reliance on digital data and computer networks\nby corporations and the public in general, the occurrence of cyber attacks has\nbecome a great threat to the normal functioning of our society. Intrusion\ndetection systems seek to address this threat by preemptively detecting attacks\nin real time while attempting to block them or minimizing their damage. These\nsystems can function in many ways being some of them based on artificial\nintelligence methods. Datasets containing both normal network traffic and cyber\nattacks are used for training these algorithms so that they can learn the\nunderlying patterns of network-based data. The CIDDS-001 is one of the most\nused datasets for network-based intrusion detection research. Regarding this\ndataset, in the majority of works published so far, the Class label was used\nfor training machine learning algorithms. However, there is another label in\nthe CIDDS-001, AttackType, that seems very promising for this purpose and\nremains considerably unexplored. This work seeks to make a comparison between\ntwo machine learning models, K-Nearest Neighbours and Random Forest, which were\ntrained with both these labels in order to ascertain whether AttackType can\nproduce reliable results in comparison with the Class label.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 22:24:44 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Carneiro", "Jos\u00e9", ""], ["Oliveira", "Nuno", ""], ["Sousa", "Norberto", ""], ["Maia", "Eva", ""], ["Pra\u00e7a", "Isabel", ""]]}, {"id": "2107.02762", "submitter": "Saeideh Nabipour", "authors": "Saeideh Nabipour, Masoume Gholizade, Nima Nabipour", "title": "Area-Delay-Efficeint FPGA Design of 32-bit Euclid's GCD based on Sum of\n  Absolute Difference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.CR eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Euclids algorithm is widely used in calculating of GCD (Greatest Common\nDivisor) of two positive numbers. There are various fields where this division\nis used such as channel coding, cryptography, and error correction codes. This\nmakes the GCD a fundamental algorithm in number theory, so a number of methods\nhave been discovered to efficiently compute it. The main contribution of this\npaper is to investigate a method that computes the GCD of two 32-bit numbers\nbased on Euclidean algorithm which targets six different Xilinx chips. The\ncomplexity of this method that we call Optimized_GCDSAD is achieved by\nutilizing Sum of Absolute Difference (SAD) block which is based on a fast\ncarry-out generation function. The efficiency of the proposed architecture is\nevaluated based on criteria such as time (latency), area delay product (ADP)\nand space (slice number) complexity. The VHDL codes of these architectures have\nbeen implemented and synthesized through ISE 14.7. A detailed comparative\nanalysis indicates that the proposed Optimized_GCDSAD method based on SAD block\noutperforms previously known results.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 10:40:42 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Nabipour", "Saeideh", ""], ["Gholizade", "Masoume", ""], ["Nabipour", "Nima", ""]]}, {"id": "2107.02783", "submitter": "Azqa Nadeem", "authors": "Azqa Nadeem, Sicco Verwer, Stephen Moskal, Shanchieh Jay Yang", "title": "SAGE: Intrusion Alert-driven Attack Graph Extractor", "comments": "Accepted to appear in the 1st KDD Workshop on AI-enabled\n  Cybersecurity Analytics (AI4cyber), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attack graphs (AG) are used to assess pathways availed by cyber adversaries\nto penetrate a network. State-of-the-art approaches for AG generation focus\nmostly on deriving dependencies between system vulnerabilities based on network\nscans and expert knowledge. In real-world operations however, it is costly and\nineffective to rely on constant vulnerability scanning and expert-crafted AGs.\nWe propose to automatically learn AGs based on actions observed through\nintrusion alerts, without prior expert knowledge. Specifically, we develop an\nunsupervised sequence learning system, SAGE, that leverages the temporal and\nprobabilistic dependence between alerts in a suffix-based probabilistic\ndeterministic finite automaton (S-PDFA) -- a model that accentuates infrequent\nsevere alerts and summarizes paths leading to them. AGs are then derived from\nthe S-PDFA. Tested with intrusion alerts collected through Collegiate\nPenetration Testing Competition, SAGE produces AGs that reflect the strategies\nused by participating teams. The resulting AGs are succinct, interpretable, and\nenable analysts to derive actionable insights, e.g., attackers tend to follow\nshorter paths after they have discovered a longer one.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 17:45:02 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Nadeem", "Azqa", ""], ["Verwer", "Sicco", ""], ["Moskal", "Stephen", ""], ["Yang", "Shanchieh Jay", ""]]}, {"id": "2107.02840", "submitter": "Ren Wang", "authors": "Ren Wang, Tianqi Chen, Stephen Lindsly, Cooper Stansbury, Alnawaz\n  Rehemtulla, Indika Rajapakse, Alfred Hero", "title": "RAILS: A Robust Adversarial Immune-inspired Learning System", "comments": "arXiv admin note: text overlap with arXiv:2012.10485", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks against deep neural networks (DNNs) are continuously\nevolving, requiring increasingly powerful defense strategies. We develop a\nnovel adversarial defense framework inspired by the adaptive immune system: the\nRobust Adversarial Immune-inspired Learning System (RAILS). Initializing a\npopulation of exemplars that is balanced across classes, RAILS starts from a\nuniform label distribution that encourages diversity and debiases a potentially\ncorrupted initial condition. RAILS implements an evolutionary optimization\nprocess to adjust the label distribution and achieve specificity towards ground\ntruth. RAILS displays a tradeoff between robustness (diversity) and accuracy\n(specificity), providing a new immune-inspired perspective on adversarial\nlearning. We empirically validate the benefits of RAILS through several\nadversarial image classification experiments on MNIST, SVHN, and CIFAR-10\ndatasets. For the PGD attack, RAILS is found to improve the robustness over\nexisting methods by >= 5.62%, 12.5% and 10.32%, respectively, without\nappreciable loss of standard accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 17:57:45 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Wang", "Ren", ""], ["Chen", "Tianqi", ""], ["Lindsly", "Stephen", ""], ["Stansbury", "Cooper", ""], ["Rehemtulla", "Alnawaz", ""], ["Rajapakse", "Indika", ""], ["Hero", "Alfred", ""]]}, {"id": "2107.02894", "submitter": "Bowei Xi", "authors": "Bowei Xi", "title": "Adversarial Machine Learning for Cybersecurity and Computer Vision:\n  Current Developments and Challenges", "comments": "Published in WIREs Computational Statistics", "journal-ref": "Wiley Interdisciplinary Reviews (WIREs) Computational Statistics,\n  12(5), 1-16, e1511, 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We provide a comprehensive overview of adversarial machine learning focusing\non two application domains, i.e., cybersecurity and computer vision. Research\nin adversarial machine learning addresses a significant threat to the wide\napplication of machine learning techniques -- they are vulnerable to carefully\ncrafted attacks from malicious adversaries. For example, deep neural networks\nfail to correctly classify adversarial images, which are generated by adding\nimperceptible perturbations to clean images.We first discuss three main\ncategories of attacks against machine learning techniques -- poisoning attacks,\nevasion attacks, and privacy attacks. Then the corresponding defense approaches\nare introduced along with the weakness and limitations of the existing defense\napproaches. We notice adversarial samples in cybersecurity and computer vision\nare fundamentally different. While adversarial samples in cybersecurity often\nhave different properties/distributions compared with training data,\nadversarial images in computer vision are created with minor input\nperturbations. This further complicates the development of robust learning\ntechniques, because a robust learning technique must withstand different types\nof attacks.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 03:05:58 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Xi", "Bowei", ""]]}, {"id": "2107.02895", "submitter": "Bowei Xi", "authors": "Bowei Xi and Yujie Chen and Fan Fei and Zhan Tu and Xinyan Deng", "title": "Bio-Inspired Adversarial Attack Against Deep Neural Networks", "comments": "Published in SafeAI 2020", "journal-ref": "In AAAI Workshop on Artificial Intelligence Safety (SafeAI), Feb.\n  2020, New York City, 1--5", "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The paper develops a new adversarial attack against deep neural networks\n(DNN), based on applying bio-inspired design to moving physical objects. To the\nbest of our knowledge, this is the first work to introduce physical attacks\nwith a moving object. Instead of following the dominating attack strategy in\nthe existing literature, i.e., to introduce minor perturbations to a digital\ninput or a stationary physical object, we show two new successful attack\nstrategies in this paper. We show by superimposing several patterns onto one\nphysical object, a DNN becomes confused and picks one of the patterns to assign\na class label. Our experiment with three flapping wing robots demonstrates the\npossibility of developing an adversarial camouflage to cause a targeted mistake\nby DNN. We also show certain motion can reduce the dependency among consecutive\nframes in a video and make an object detector \"blind\", i.e., not able to detect\nan object exists in the video. Hence in a successful physical attack against\nDNN, targeted motion against the system should also be considered.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 03:23:52 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Xi", "Bowei", ""], ["Chen", "Yujie", ""], ["Fei", "Fan", ""], ["Tu", "Zhan", ""], ["Deng", "Xinyan", ""]]}, {"id": "2107.02896", "submitter": "Javier Velasco-Mata", "authors": "Javier Velasco-Mata, V\\'ictor Gonz\\'alez-Castro, Eduardo Fidalgo,\n  Enrique Alegre", "title": "Efficient Detection of Botnet Traffic by features selection and Decision\n  Trees", "comments": "Submitted to IEEE Access", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Botnets are one of the online threats with the biggest presence, causing\nbillionaire losses to global economies. Nowadays, the increasing number of\ndevices connected to the Internet makes it necessary to analyze large amounts\nof network traffic data. In this work, we focus on increasing the performance\non botnet traffic classification by selecting those features that further\nincrease the detection rate. For this purpose we use two feature selection\ntechniques, Information Gain and Gini Importance, which led to three\npre-selected subsets of five, six and seven features. Then, we evaluate the\nthree feature subsets along with three models, Decision Tree, Random Forest and\nk-Nearest Neighbors. To test the performance of the three feature vectors and\nthe three models we generate two datasets based on the CTU-13 dataset, namely\nQB-CTU13 and EQB-CTU13. We measure the performance as the macro averaged F1\nscore over the computational time required to classify a sample. The results\nshow that the highest performance is achieved by Decision Trees using a five\nfeature set which obtained a mean F1 score of 85% classifying each sample in an\naverage time of 0.78 microseconds.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 11:55:12 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Velasco-Mata", "Javier", ""], ["Gonz\u00e1lez-Castro", "V\u00edctor", ""], ["Fidalgo", "Eduardo", ""], ["Alegre", "Enrique", ""]]}, {"id": "2107.02897", "submitter": "Ziaur Rahman", "authors": "Mustain Billah, Adnan Anwar, Ziaur Rahman and Syed Md. Galib", "title": "Bi-Level Poisoning Attack Model and Countermeasure for Appliance\n  Consumption Data of Smart Homes", "comments": "17 Pages, 7 Figures, 1 table", "journal-ref": "Energies 2021, 14(13), 3887", "doi": "10.3390/en14133887", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Accurate building energy prediction is useful in various applications\nstarting from building energy automation and management to optimal storage\ncontrol. However, vulnerabilities should be considered when designing building\nenergy prediction models, as intelligent attackers can deliberately influence\nthe model performance using sophisticated attack models. These may consequently\ndegrade the prediction accuracy, which may affect the efficiency and\nperformance of the building energy management systems. In this paper, we\ninvestigate the impact of bi-level poisoning attacks on regression models of\nenergy usage obtained from household appliances. Furthermore, an effective\ncountermeasure against the poisoning attacks on the prediction model is\nproposed in this paper. Attacks and defenses are evaluated on a benchmark\ndataset. Experimental results show that an intelligent cyber-attacker can\npoison the prediction model to manipulate the decision. However, our proposed\nsolution successfully ensures defense against such poisoning attacks\neffectively compared to other benchmark techniques.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 00:40:01 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Billah", "Mustain", ""], ["Anwar", "Adnan", ""], ["Rahman", "Ziaur", ""], ["Galib", "Syed Md.", ""]]}, {"id": "2107.02916", "submitter": "Stefan Marksteiner", "authors": "Christian Wolschke, Stefan Marksteiner, Tobias Braun, Markus Wolf", "title": "An Agnostic Domain Specific Language for Implementing Attacks in an\n  Automotive Use Case", "comments": "13 pages, 4 figures, accepted at the 10th International Workshop on\n  Security of Mobile Applications (IWSMA 2021) in conjunction with the 16th\n  International Conference on Availability, Reliability and Security (ARES\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a Domain Specific Language (DSL) for generically\ndescribing cyber attacks, agnostic to specific system-under-test(SUT). The\ncreation of the presented DSL is motivated by an automotive use case. The\nconcepts of the DSL are generic such thatattacks on arbitrary systems can be\naddressed.The ongoing trend to improve the user experience of vehicles with\nconnected services implies an enhanced connectivity as well asremote accessible\ninterface opens potential attack vectors. This might also impact safety and the\nproprietary nature of potential SUTs.Reusing tests of attack vectors to\nindustrialize testing them on multiple SUTs mandates an abstraction mechanism\nto port an attackfrom one system to another. The DSL therefore generically\ndescribes attacks for the usage with a test case generator (and\nexecutionenvironment) also described in this paper. The latter use this\ndescription and a database with SUT-specific information to generateattack\nimplementations for a multitude of different (automotive) SUTs.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 21:39:44 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Wolschke", "Christian", ""], ["Marksteiner", "Stefan", ""], ["Braun", "Tobias", ""], ["Wolf", "Markus", ""]]}, {"id": "2107.02941", "submitter": "Atif Ahmad", "authors": "Ritu Lakshmi, Humza Naseer, Sean Maynard, Atif Ahmad", "title": "Sensemaking in Cybersecurity Incident Response: The Interplay of\n  Organizations, Technology and Individuals", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Sensemaking is a critical activity in organizations. It is a process through\nwhich individuals ascribe meanings to events which forms the basis to\nfacilitate collective action. However, the role of organizations, technology\nand individuals and their interaction in the process of sensemaking has not\nbeen sufficiently explored. This novel study seeks to address this gap by\nproposing a framework that explains how the interplay among organizations,\ntechnology and individuals enables sensemaking in the process of cybersecurity\nincident response. We propose that Organizations, Technology, and Individuals\nare the key components that interact in various ways to facilitate enactment,\nselection and retention activities (Sensemaking activities) in Incident\nResponse. We argue that sensemaking in Incident Response is the outcome of this\ninteraction. This interaction allows organizations to respond to cybersecurity\nincidents in a comprehensive manner.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 23:32:18 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Lakshmi", "Ritu", ""], ["Naseer", "Humza", ""], ["Maynard", "Sean", ""], ["Ahmad", "Atif", ""]]}, {"id": "2107.02961", "submitter": "Minoru Kuribayashi", "authors": "Minoru Kuribayashi, Tatsuya Yasui, Asad Malik, Nobuo Funabiki", "title": "Immunization of Pruning Attack in DNN Watermarking Using Constant Weight\n  Code", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To ensure protection of the intellectual property rights of DNN models,\nwatermarking techniques have been investigated to insert side-information into\nthe models without seriously degrading the performance of original task. One of\nthe threats for the DNN watermarking is the pruning attack such that less\nimportant neurons in the model are pruned to make it faster and more compact as\nwell as to remove the watermark. In this study, we investigate a channel coding\napproach to resist the pruning attack. As the channel model is completely\ndifferent from conventional models like digital images, it has been an open\nproblem what kind of encoding method is suitable for DNN watermarking. A novel\nencoding approach by using constant weight codes to immunize the effects of\npruning attacks is presented. To the best of our knowledge, this is the first\nstudy that introduces an encoding technique for DNN watermarking to make it\nrobust against pruning attacks.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 00:50:27 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Kuribayashi", "Minoru", ""], ["Yasui", "Tatsuya", ""], ["Malik", "Asad", ""], ["Funabiki", "Nobuo", ""]]}, {"id": "2107.02992", "submitter": "Kaiyuan Yang", "authors": "Dai Li, Kaiyuan Yang", "title": "A Dual-Port 8-T CAM-Based Network Intrusion Detection Engine for IoT", "comments": "This work has been accepted by 2020 IEEE Solid-State Circuits Letters\n  (SSCL)", "journal-ref": "IEEE Solid-State Circuits Letters (SSCL), Volume: 3, Pages:\n  358-361, Sep. 2020", "doi": "10.1109/LSSC.2020.3022006", "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This letter presents an energy- and memory-efficient pattern-matching engine\nfor a network intrusion detection system (NIDS) in the Internet of Things.\nTightly coupled architecture and circuit co-designs are proposed to fully\nexploit the statistical behaviors of NIDS pattern matching. The proposed engine\nperforms pattern matching in three phases, where the phase-1 prefix matching\nemploys reconfigurable pipelined automata processing to minimize memory\nfootprint without loss of throughput and efficiency. The processing elements\nutilize 8-T content-addressable memory (CAM) cells for dual-port search by\nleveraging proposed fixed-1s encoding. A 65-nm prototype demonstrates\nbest-in-class 1.54-fJ energy per search per pattern byte and 0.9-byte memory\nusage per pattern byte.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 03:13:48 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Li", "Dai", ""], ["Yang", "Kaiyuan", ""]]}, {"id": "2107.02997", "submitter": "Reza Rahimian", "authors": "Reza Rahimian, Jeremy Clark", "title": "TokenHook: Secure ERC-20 smart contract", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  ERC-20 is the most prominent Ethereum standard for fungible tokens. Tokens\nimplementing the ERC-20 interface can interoperate with a large number of\nalready deployed internet-based services and Ethereum-based smart contracts. In\nrecent years, security vulnerabilities in ERC-20 have received special\nattention due to their widespread use and increased value. We systemize these\nvulnerabilities and their applicability to ERC-20 tokens, which has not been\ndone before. Next, we use our domain expertise to provide a new implementation\nof the ERC-20 interface that is freely available in Vyper and Solidity, and has\nenhanced security properties and stronger compliance with best practices\ncompared to the sole surviving reference implementation (from OpenZeppelin) in\nthe ERC-20 specification. Finally, we use our implementation to study the\neffectiveness of seven static analysis tools, designed for general smart\ncontracts, for identifying ERC-20 specific vulnerabilities. We find large\ninconsistencies across the tools and a high number of false positives which\nshows there is room for further improvement of these tools.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 03:33:50 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Rahimian", "Reza", ""], ["Clark", "Jeremy", ""]]}, {"id": "2107.03072", "submitter": "Sevil Sen", "authors": "Sevil Sen and Burcu Can", "title": "Android Security using NLP Techniques: A Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Android is among the most targeted platform by attackers. While attackers are\nimproving their techniques, traditional solutions based on static and dynamic\nanalysis have been also evolving. In addition to the application code, Android\napplications have some metadata that could be useful for security analysis of\napplications. Unlike traditional application distribution mechanisms, Android\napplications are distributed centrally in mobile markets. Therefore, beside\napplication packages, such markets contain app information provided by app\ndevelopers and app users. The availability of such useful textual data together\nwith the advancement in Natural Language Processing (NLP) that is used to\nprocess and understand textual data has encouraged researchers to investigate\nthe use of NLP techniques in Android security. Especially, security solutions\nbased on NLP have accelerated in the last 5 years and proven to be useful. This\nstudy reviews these proposals and aim to explore possible research directions\nfor future studies by presenting state-of-the-art in this domain. We mainly\nfocus on NLP-based solutions under four categories: description-to-behaviour\nfidelity, description generation, privacy and malware detection.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 08:33:00 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Sen", "Sevil", ""], ["Can", "Burcu", ""]]}, {"id": "2107.03193", "submitter": "Thore Thie{\\ss}en", "authors": "Thore Thie{\\ss}en and Jan Vahrenhold", "title": "Oblivious Median Slope Selection", "comments": "14 pages, to appear in Proceedings of CCCG 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the median slope selection problem in the oblivious RAM model. In\nthis model memory accesses have to be independent of the data processed, i.e.,\nan adversary cannot use observed access patterns to derive additional\ninformation about the input. We show how to modify the randomized algorithm of\nMatou\\v{s}ek (1991) to obtain an oblivious version with O(n log^2 n) expected\ntime for n points in R^2. This complexity matches a theoretical upper bound\nthat can be obtained through general oblivious transformation. In addition,\nresults from a proof-of-concept implementation show that our algorithm is also\npractically efficient.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 13:10:13 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Thie\u00dfen", "Thore", ""], ["Vahrenhold", "Jan", ""]]}, {"id": "2107.03250", "submitter": "Xiao Zhang", "authors": "Xiao Zhang and David Evans", "title": "Incorporating Label Uncertainty in Understanding Adversarial Robustness", "comments": "20 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A fundamental question in adversarial machine learning is whether a robust\nclassifier exists for a given task. A line of research has made progress\ntowards this goal by studying concentration of measure, but without considering\ndata labels. We argue that the standard concentration fails to fully\ncharacterize the intrinsic robustness of a classification problem, since it\nignores data labels which are essential to any classification task. Building on\na novel definition of label uncertainty, we empirically demonstrate that error\nregions induced by state-of-the-art models tend to have much higher label\nuncertainty compared with randomly-selected subsets. This observation motivates\nus to adapt a concentration estimation algorithm to account for label\nuncertainty, resulting in more accurate intrinsic robustness measures for\nbenchmark image classification problems. We further provide empirical evidence\nshowing that adding an abstain option for classifiers based on label\nuncertainty can help improve both the clean and robust accuracies of models.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 14:26:57 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Zhang", "Xiao", ""], ["Evans", "David", ""]]}, {"id": "2107.03311", "submitter": "Hidde Lycklama \\`A Nijeholt", "authors": "Lukas Burkhalter, Hidde Lycklama, Alexander Viand, Nicolas K\\\"uchler,\n  Anwar Hithnawi", "title": "RoFL: Attestable Robustness for Secure Federated Learning", "comments": "20 pages, 15 figures. Updated last name of one author to improve\n  indexability", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning is an emerging decentralized machine learning paradigm\nthat allows a large number of clients to train a joint model without the need\nto share their private data. Participants instead only share ephemeral updates\nnecessary to train the model. To ensure the confidentiality of the client\nupdates, Federated Learning systems employ secure aggregation; clients encrypt\ntheir gradient updates, and only the aggregated model is revealed to the\nserver. Achieving this level of data protection, however, presents new\nchallenges to the robustness of Federated Learning, i.e., the ability to\ntolerate failures and attacks. Unfortunately, in this setting, a malicious\nclient can now easily exert influence on the model behavior without being\ndetected. As Federated Learning is being deployed in practice in a range of\nsensitive applications, its robustness is growing in importance. In this paper,\nwe take a step towards understanding and improving the robustness of secure\nFederated Learning. We start this paper with a systematic study that evaluates\nand analyzes existing attack vectors and discusses potential defenses and\nassesses their effectiveness. We then present RoFL, a secure Federated Learning\nsystem that improves robustness against malicious clients through input checks\non the encrypted model updates. RoFL extends Federated Learning's secure\naggregation protocol to allow expressing a variety of properties and\nconstraints on model updates using zero-knowledge proofs. To enable RoFL to\nscale to typical Federated Learning settings, we introduce several ML and\ncryptographic optimizations specific to Federated Learning. We implement and\nevaluate a prototype of RoFL and show that realistic ML models can be trained\nin a reasonable time while improving robustness.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 15:42:49 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 10:43:02 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Burkhalter", "Lukas", ""], ["Lycklama", "Hidde", ""], ["Viand", "Alexander", ""], ["K\u00fcchler", "Nicolas", ""], ["Hithnawi", "Anwar", ""]]}, {"id": "2107.03726", "submitter": "Nicolas K\\\"uchler", "authors": "Lukas Burkhalter, Nicolas K\\\"uchler, Alexander Viand, Hossein Shafagh,\n  Anwar Hithnawi", "title": "Zeph: Cryptographic Enforcement of End-to-End Data Privacy", "comments": "20 pages, extended version of a paper published at OSDI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As increasingly more sensitive data is being collected to gain valuable\ninsights, the need to natively integrate privacy controls in data analytics\nframeworks is growing in importance. Today, privacy controls are enforced by\ndata curators with full access to data in the clear. However, a plethora of\nrecent data breaches show that even widely trusted service providers can be\ncompromised. Additionally, there is no assurance that data processing and\nhandling comply with the claimed privacy policies. This motivates the need for\na new approach to data privacy that can provide strong assurance and control to\nusers. This paper presents Zeph, a system that enables users to set privacy\npreferences on how their data can be shared and processed. Zeph enforces\nprivacy policies cryptographically and ensures that data available to\nthird-party applications complies with users' privacy policies. Zeph executes\nprivacy-adhering data transformations in real-time and scales to thousands of\ndata sources, allowing it to support large-scale low-latency data stream\nanalytics. We introduce a hybrid cryptographic protocol for privacy-adhering\ntransformations of encrypted data. We develop a prototype of Zeph on Apache\nKafka to demonstrate that Zeph can perform large-scale privacy transformations\nwith low overhead.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 10:11:27 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Burkhalter", "Lukas", ""], ["K\u00fcchler", "Nicolas", ""], ["Viand", "Alexander", ""], ["Shafagh", "Hossein", ""], ["Hithnawi", "Anwar", ""]]}, {"id": "2107.03781", "submitter": "S\\'ergio Pereira", "authors": "S\\'ergio Pereira, David Cerdeira, Cristiano Rodrigues, and Sandro\n  Pinto", "title": "Towards a Trusted Execution Environment via Reconfigurable FPGA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Trusted Execution Environments (TEEs) are used to protect sensitive data and\nrun secure execution for security-critical applications, by providing an\nenvironment isolated from the rest of the system. However, over the last few\nyears, TEEs have been proven weak, as either TEEs built upon security-oriented\nhardware extensions (e.g., Arm TrustZone) or resorting to dedicated secure\nelements were exploited multiple times. In this project, we introduce Trusted\nExecution Environments On-Demand (TEEOD), a novel TEE design that leverages the\nprogrammable logic (PL) in the heterogeneous system on chips (SoC) as the\nsecure execution environment. Unlike other TEE designs, TEEOD can provide\nhigh-bandwidth connections and physical on-chip isolation. We implemented a\nproof-of-concept (PoC) implementation targeting an Ultra96-V2 platform. The\nconducted evaluation demonstrated TEEOD can host up to 6 simultaneous enclaves\nwith a resource usage per enclave of 7.0%, 3.8%, and 15.3% of the total LUTs,\nFFs, and BRAMS, respectively. To demonstrate the practicability of TEEOD in\nreal-world applications, we successfully run a legacy open-source Bitcoin\nwallet.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 11:43:43 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Pereira", "S\u00e9rgio", ""], ["Cerdeira", "David", ""], ["Rodrigues", "Cristiano", ""], ["Pinto", "Sandro", ""]]}, {"id": "2107.03799", "submitter": "Yueming Wu", "authors": "Yueming Wu, Shihan Dou, Deqing Zou, Wei Yang, Weizhong Qiang, Hai Jin", "title": "Obfuscation-resilient Android Malware Analysis Based on Contrastive\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Due to its open-source nature, Android operating system has been the main\ntarget of attackers to exploit. Malware creators always perform different code\nobfuscations on their apps to hide malicious activities. Features extracted\nfrom these obfuscated samples through program analysis contain many useless and\ndisguised features, which leads to many false negatives. To address the issue,\nin this paper, we demonstrate that obfuscation-resilient malware analysis can\nbe achieved through contrastive learning. We take the Android malware\nclassification as an example to demonstrate our analysis. The key insight\nbehind our analysis is that contrastive learning can be used to reduce the\ndifference introduced by obfuscation while amplifying the difference between\nmalware and benign apps (or other types of malware).\n  Based on the proposed analysis, we design a system that can achieve robust\nand interpretable classification of Android malware. To achieve robust\nclassification, we perform contrastive learning on malware samples to learn an\nencoder that can automatically extract robust features from malware samples. To\nachieve interpretable classification, we transform the function call graph of a\nsample into an image by centrality analysis. Then the corresponding heatmaps\nare obtained by visualization techniques. These heatmaps can help users\nunderstand why the malware is classified as this family. We implement IFDroid\nand perform extensive evaluations on two widely used datasets. Experimental\nresults show that IFDroid is superior to state-of-the-art Android malware\nfamilial classification systems. Moreover, IFDroid is capable of maintaining\n98.2% true positive rate on classifying 8,112 obfuscated malware samples.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 12:17:15 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Wu", "Yueming", ""], ["Dou", "Shihan", ""], ["Zou", "Deqing", ""], ["Yang", "Wei", ""], ["Qiang", "Weizhong", ""], ["Jin", "Hai", ""]]}, {"id": "2107.03806", "submitter": "Daniel Park", "authors": "Daniel Park, Haidar Khan, Azer Khan, Alex Gittens, B\\\"ulent Yener", "title": "Output Randomization: A Novel Defense for both White-box and Black-box\n  Adversarial Models", "comments": "This is a substantially changed version of an earlier preprint\n  (arXiv:1905.09871)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adversarial examples pose a threat to deep neural network models in a variety\nof scenarios, from settings where the adversary has complete knowledge of the\nmodel in a \"white box\" setting and to the opposite in a \"black box\" setting. In\nthis paper, we explore the use of output randomization as a defense against\nattacks in both the black box and white box models and propose two defenses. In\nthe first defense, we propose output randomization at test time to thwart\nfinite difference attacks in black box settings. Since this type of attack\nrelies on repeated queries to the model to estimate gradients, we investigate\nthe use of randomization to thwart such adversaries from successfully creating\nadversarial examples. We empirically show that this defense can limit the\nsuccess rate of a black box adversary using the Zeroth Order Optimization\nattack to 0%. Secondly, we propose output randomization training as a defense\nagainst white box adversaries. Unlike prior approaches that use randomization,\nour defense does not require its use at test time, eliminating the Backward\nPass Differentiable Approximation attack, which was shown to be effective\nagainst other randomization defenses. Additionally, this defense has low\noverhead and is easily implemented, allowing it to be used together with other\ndefenses across various model architectures. We evaluate output randomization\ntraining against the Projected Gradient Descent attacker and show that the\ndefense can reduce the PGD attack's success rate down to 12% when using\ncross-entropy loss.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 12:27:19 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Park", "Daniel", ""], ["Khan", "Haidar", ""], ["Khan", "Azer", ""], ["Gittens", "Alex", ""], ["Yener", "B\u00fclent", ""]]}, {"id": "2107.03832", "submitter": "Eduard Marin", "authors": "Eduard Marin, Diego Perino and Roberto Di Pietro", "title": "Serverless Computing: A Security Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Serverless Computing is a virtualisation-related paradigm that promises to\nsimplify application management and to solve one of the last architectural\nchallenges in the field: scale down. The implied cost reduction, coupled with a\nsimplified management of underlying applications, are expected to further push\nthe adoption of virtualisation-based solutions, including cloud-computing.\nHowever, in this quest for efficiency, security is not ranked among the top\npriorities, also because of the (misleading) belief that current solutions\ndeveloped for virtualised environments could be applied to this new paradigm.\nUnfortunately, this is not the case, due to the highlighted idiosyncratic\nfeatures of serverless computing.\n  In this paper, we review the current serverless architectures, abstract their\nfounding principles, and analyse them from the point of view of security. We\nshow the security shortcomings of the analysed serverless architectural\nparadigms, and point to possible countermeasures. We believe that our\ncontribution, other than being valuable on its own, also paves the way for\nfurther research in this domain, a challenging and relevant one for both\nindustry and academia.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 13:21:20 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Marin", "Eduard", ""], ["Perino", "Diego", ""], ["Di Pietro", "Roberto", ""]]}, {"id": "2107.03907", "submitter": "Jason R.C. Nurse Dr", "authors": "Jason R. C. Nurse and Nikki Williams and Emily Collins and Niki\n  Panteli and John Blythe and Ben Koppelman", "title": "Remote Working Pre- and Post-COVID-19: An Analysis of New Threats and\n  Risks to Security and Privacy", "comments": "HCI International 2021 (HCII 2021)", "journal-ref": null, "doi": "10.1007/978-3-030-78645-8_74", "report-no": null, "categories": "cs.CR cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19 has radically changed society as we know it. To reduce the spread of\nthe virus, millions across the globe have been forced to work remotely, often\nin make-shift home offices, and using a plethora of new, unfamiliar digital\ntechnologies. In this article, we critically analyse cyber security and privacy\nconcerns arising due to remote working during the coronavirus pandemic. Through\nour work, we discover a series of security risks emerging because of the\nrealities of this period. For instance, lack of remote-working security\ntraining, heightened stress and anxiety, rushed technology deployment, and the\npresence of untrusted individuals in a remote-working environment (e.g., in\nflatshares), can result in new cyber-risk. Simultaneously, we find that as\norganisations look to manage these and other risks posed by their remote\nworkforces, employee's privacy (including personal information and activities)\nis often compromised. This is apparent in the significant adoption of remote\nworkplace monitoring, management and surveillance technologies. Such\ntechnologies raise several privacy and ethical questions, and further highlight\nthe tension between security and privacy going forward.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 15:39:56 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Nurse", "Jason R. C.", ""], ["Williams", "Nikki", ""], ["Collins", "Emily", ""], ["Panteli", "Niki", ""], ["Blythe", "John", ""], ["Koppelman", "Ben", ""]]}, {"id": "2107.04008", "submitter": "Asifullah Khan", "authors": "Muhammad Asam, Saddam Hussain Khan, Tauseef Jamal, Umme Zahoora,\n  Asifullah Khan", "title": "Malware Classification Using Deep Boosted Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malicious activities in cyberspace have gone further than simply hacking\nmachines and spreading viruses. It has become a challenge for a nations\nsurvival and hence has evolved to cyber warfare. Malware is a key component of\ncyber-crime, and its analysis is the first line of defence against attack. This\nwork proposes a novel deep boosted hybrid learning-based malware classification\nframework and named as Deep boosted Feature Space-based Malware classification\n(DFS-MC). In the proposed framework, the discrimination power is enhanced by\nfusing the feature spaces of the best performing customized CNN architectures\nmodels and its discrimination by an SVM for classification. The discrimination\ncapacity of the proposed classification framework is assessed by comparing it\nagainst the standard customized CNNs. The customized CNN models are implemented\nin two ways: softmax classifier and deep hybrid learning-based malware\nclassification. In the hybrid learning, Deep features are extracted from\ncustomized CNN architectures and fed into the conventional machine learning\nclassifier to improve the classification performance. We also introduced the\nconcept of transfer learning in a customized CNN architecture based malware\nclassification framework through fine-tuning. The performance of the proposed\nmalware classification approaches are validated on the MalImg malware dataset\nusing the hold-out cross-validation technique. Experimental comparisons were\nconducted by employing innovative, customized CNN, trained from scratch and\nfine-tuning the customized CNN using transfer learning. The proposed\nclassification framework DFS-MC showed improved results, Accuracy: 98.61%,\nF-score: 0.96, Precision: 0.96, and Recall: 0.96.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 17:53:33 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Asam", "Muhammad", ""], ["Khan", "Saddam Hussain", ""], ["Jamal", "Tauseef", ""], ["Zahoora", "Umme", ""], ["Khan", "Asifullah", ""]]}, {"id": "2107.04069", "submitter": "Matheus Venturyne Xavier Ferreira", "authors": "Matheus V. X. Ferreira and S. Matthew Weinberg", "title": "Proof-of-Stake Mining Games with Perfect Randomness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR econ.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Proof-of-Stake blockchains based on a longest-chain consensus protocol are an\nattractive energy-friendly alternative to the Proof-of-Work paradigm. However,\nformal barriers to \"getting the incentives right\" were recently discovered,\ndriven by the desire to use the blockchain itself as a source of\npseudorandomness \\cite{brown2019formal}.\n  We consider instead a longest-chain Proof-of-Stake protocol with perfect,\ntrusted, external randomness (e.g. a randomness beacon). We produce two main\nresults.\n  First, we show that a strategic miner can strictly outperform an honest miner\nwith just $32.8\\%$ of the total stake. Note that a miner of this size {\\em\ncannot} outperform an honest miner in the Proof-of-Work model. This establishes\nthat even with access to a perfect randomness beacon, incentives in\nProof-of-Work and Proof-of-Stake longest-chain protocols are fundamentally\ndifferent.\n  Second, we prove that a strategic miner cannot outperform an honest miner\nwith $30.8\\%$ of the total stake. This means that, while not quite as secure as\nthe Proof-of-Work regime, desirable incentive properties of Proof-of-Work\nlongest-chain protocols can be approximately recovered via Proof-of-Stake with\na perfect randomness beacon.\n  The space of possible strategies in a Proof-of-Stake mining game is {\\em\nsignificantly} richer than in a Proof-of-Work game. Our main technical\ncontribution is a characterization of potentially optimal strategies for a\nstrategic miner, and in particular, a proof that the corresponding\ninfinite-state MDP admits an optimal strategy that is positive recurrent.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 19:01:58 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Ferreira", "Matheus V. X.", ""], ["Weinberg", "S. Matthew", ""]]}, {"id": "2107.04075", "submitter": "Alexander Outkin", "authors": "Alexander V. Outkin, Patricia V. Schulz, Timothy Schulz, Thomas D.\n  Tarman, and Ali Pinar", "title": "Defender Policy Evaluation and Resource Allocation Using MITRE ATT&CK\n  Evaluations Data", "comments": null, "journal-ref": null, "doi": null, "report-no": "SAND2021-7713", "categories": "cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protecting against multi-step attacks of uncertain duration and timing forces\ndefenders into an indefinite, always ongoing, resource-intensive response. To\neffectively allocate resources, a defender must be able to analyze multi-step\nattacks under assumption of constantly allocating resources against an\nuncertain stream of potentially undetected attacks. To achieve this goal, we\npresent a novel methodology that applies a game-theoretic approach to the\nattack, attacker, and defender data derived from MITRE's ATT&CK Framework. Time\nto complete attack steps is drawn from a probability distribution determined by\nattacker and defender strategies and capabilities. This constraints attack\nsuccess parameters and enables comparing different defender resource allocation\nstrategies. By approximating attacker-defender games as Markov processes, we\nrepresent the attacker-defender interaction, estimate the attack success\nparameters, determine the effects of attacker and defender strategies, and\nmaximize opportunities for defender strategy improvements against an uncertain\nstream of attacks. This novel representation and analysis of multi-step attacks\nenables defender policy optimization and resource allocation, which we\nillustrate using the data from MITRE's APT3 ATT&CK Evaluations.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 19:26:06 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Outkin", "Alexander V.", ""], ["Schulz", "Patricia V.", ""], ["Schulz", "Timothy", ""], ["Tarman", "Thomas D.", ""], ["Pinar", "Ali", ""]]}, {"id": "2107.04129", "submitter": "Bo Liu", "authors": "Bo Liu, Chaowei Tan, Jiazhou Wang, Tao Zeng, Huasong Shan, Houpu Yao,\n  Huang Heng, Peng Dai, Liefeng Bo, Yanqing Chen", "title": "Fedlearn-Algo: A flexible open-source privacy-preserving machine\n  learning platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present Fedlearn-Algo, an open-source privacy preserving\nmachine learning platform. We use this platform to demonstrate our research and\ndevelopment results on privacy preserving machine learning algorithms. As the\nfirst batch of novel FL algorithm examples, we release vertical federated\nkernel binary classification model and vertical federated random forest model.\nThey have been tested to be more efficient than existing vertical federated\nlearning models in our practice. Besides the novel FL algorithm examples, we\nalso release a machine communication module. The uniform data transfer\ninterface supports transfering widely used data formats between machines. We\nwill maintain this platform by adding more functional modules and algorithm\nexamples.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 21:59:56 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Liu", "Bo", ""], ["Tan", "Chaowei", ""], ["Wang", "Jiazhou", ""], ["Zeng", "Tao", ""], ["Shan", "Huasong", ""], ["Yao", "Houpu", ""], ["Heng", "Huang", ""], ["Dai", "Peng", ""], ["Bo", "Liefeng", ""], ["Chen", "Yanqing", ""]]}, {"id": "2107.04175", "submitter": "Tao Lu", "authors": "Tao Lu", "title": "A Survey on RISC-V Security: Hardware and Architecture", "comments": "39 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The Internet of Things (IoT) is an ongoing technological revolution. Embedded\nprocessors are the processing engines of smart IoT devices. For decades, these\nprocessors were mainly based on the Arm instruction set architecture (ISA). In\nrecent years, the free and open RISC-V ISA standard has attracted the attention\nof industry and academia and is becoming the mainstream. Data security and user\nprivacy protection are common challenges faced by all IoT devices. In order to\ndeal with foreseeable security threats, the RISC-V community is studying\nsecurity solutions aimed at achieving a root of trust (RoT) and ensuring that\nsensitive information on RISC-V devices is not tampered with or leaked. Many\nRISC-V security research projects are underway, but the academic community has\nnot yet conducted a comprehensive survey of RISC-V security solutions. In order\nto fill this research gap, this paper presents an in-depth survey on RISC-V\nsecurity technologies. This paper summarizes the representative security\nmechanisms of RISC-V hardware and architecture. Based on our survey, we predict\nthe future research and development directions of RISC-V security. We hope that\nour research can inspire RISC-V researchers and developers.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 02:04:26 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Lu", "Tao", ""]]}, {"id": "2107.04245", "submitter": "Yang Li", "authors": "Yang Li, Michael Purcell, Thierry Rakotoarivelo, David Smith, Thilina\n  Ranbaduge, Kee Siong Ng", "title": "Private Graph Data Release: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of graph analytics to various domains have yielded tremendous\nsocietal and economical benefits in recent years. However, the increasingly\nwidespread adoption of graph analytics comes with a commensurate increase in\nthe need to protect private information in graph databases, especially in light\nof the many privacy breaches in real-world graph data that was supposed to\npreserve sensitive information. This paper provides a comprehensive survey of\nprivate graph data release algorithms that seek to achieve the fine balance\nbetween privacy and utility, with a specific focus on provably private\nmechanisms. Many of these mechanisms fall under natural extensions of the\nDifferential Privacy framework to graph data, but we also investigate more\ngeneral privacy formulations like Pufferfish Privacy that can deal with the\nlimitations of Differential Privacy. A wide-ranging survey of the applications\nof private graph data release mechanisms to social networks, finance, supply\nchain, health and energy is also provided. This survey paper and the taxonomy\nit provides should benefit practitioners and researchers alike in the\nincreasingly important area of private graph data release and analysis.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 06:38:01 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Li", "Yang", ""], ["Purcell", "Michael", ""], ["Rakotoarivelo", "Thierry", ""], ["Smith", "David", ""], ["Ranbaduge", "Thilina", ""], ["Ng", "Kee Siong", ""]]}, {"id": "2107.04248", "submitter": "Sanket Kanjalkar", "authors": "Sanket Kanjalkar, Ye Zhang, Shreyas Gandlur, Andrew Miller", "title": "Publicly Auditable MPC-as-a-Service with succinct verification and\n  universal setup", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, multiparty computation as a service (MPCaaS) has gained\npopularity as a way to build distributed privacy-preserving systems. We argue\nthat for many such applications, we should also require that the MPC protocol\nis publicly auditable, meaning that anyone can check the given computation is\ncarried out correctly -- even if the server nodes carrying out the computation\nare all corrupt. In a nutshell, the way to make an MPC protocol auditable is to\ncombine an underlying MPC protocol with verifiable computing proof (in\nparticular, a SNARK). Building a general-purpose MPCaaS from existing\nconstructions would require us to perform a costly \"trusted setup\" every time\nwe wish to run a new or modified application. To address this, we provide the\nfirst efficient construction for auditable MPC that has a one-time universal\nsetup. Despite improving the trusted setup, we match the state-of-the-art in\nasymptotic performance: the server nodes incur a linear computation overhead\nand constant round communication overhead compared to the underlying MPC, and\nthe audit size and verification are logarithmic in the application circuit\nsize. We also provide an implementation and benchmarks that support our\nasymptotic analysis in example applications. Furthermore, compared with\nexisting auditable MPC protocols, besides offering a universal setup our\nconstruction also has a 3x smaller proof, 3x faster verification time and\ncomparable prover time.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 06:43:35 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Kanjalkar", "Sanket", ""], ["Zhang", "Ye", ""], ["Gandlur", "Shreyas", ""], ["Miller", "Andrew", ""]]}, {"id": "2107.04265", "submitter": "Alexander Ziller", "authors": "Alexander Ziller, Dmitrii Usynin, Moritz Knolle, Kritika Prakash,\n  Andrew Trask, Rickmer Braren, Marcus Makowski, Daniel Rueckert, Georgios\n  Kaissis", "title": "Sensitivity analysis in differentially private machine learning using\n  hybrid automatic differentiation", "comments": "Accepted to the ICML 2021 Theory and Practice of Differential Privacy\n  Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, formal methods of privacy protection such as differential\nprivacy (DP), capable of deployment to data-driven tasks such as machine\nlearning (ML), have emerged. Reconciling large-scale ML with the closed-form\nreasoning required for the principled analysis of individual privacy loss\nrequires the introduction of new tools for automatic sensitivity analysis and\nfor tracking an individual's data and their features through the flow of\ncomputation. For this purpose, we introduce a novel \\textit{hybrid} automatic\ndifferentiation (AD) system which combines the efficiency of reverse-mode AD\nwith an ability to obtain a closed-form expression for any given quantity in\nthe computational graph. This enables modelling the sensitivity of arbitrary\ndifferentiable function compositions, such as the training of neural networks\non private data. We demonstrate our approach by analysing the individual DP\nguarantees of statistical database queries. Moreover, we investigate the\napplication of our technique to the training of DP neural networks. Our\napproach can enable the principled reasoning about privacy loss in the setting\nof data processing, and further the development of automatic sensitivity\nanalysis and privacy budgeting systems.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 07:19:23 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Ziller", "Alexander", ""], ["Usynin", "Dmitrii", ""], ["Knolle", "Moritz", ""], ["Prakash", "Kritika", ""], ["Trask", "Andrew", ""], ["Braren", "Rickmer", ""], ["Makowski", "Marcus", ""], ["Rueckert", "Daniel", ""], ["Kaissis", "Georgios", ""]]}, {"id": "2107.04284", "submitter": "Shangyu Xie", "authors": "Shangyu Xie, Han Wang, Yu Kong and Yuan Hong", "title": "Universal 3-Dimensional Perturbations for Black-Box Attacks on Video\n  Recognition Systems", "comments": "Accepted to Oakland'2022", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Widely deployed deep neural network (DNN) models have been proven to be\nvulnerable to adversarial perturbations in many applications (e.g., image,\naudio and text classifications). To date, there are only a few adversarial\nperturbations proposed to deviate the DNN models in video recognition systems\nby simply injecting 2D perturbations into video frames. However, such attacks\nmay overly perturb the videos without learning the spatio-temporal features\n(across temporal frames), which are commonly extracted by DNN models for video\nrecognition. To our best knowledge, we propose the first black-box attack\nframework that generates universal 3-dimensional (U3D) perturbations to subvert\na variety of video recognition systems. U3D has many advantages, such as (1) as\nthe transfer-based attack, U3D can universally attack multiple DNN models for\nvideo recognition without accessing to the target DNN model; (2) the high\ntransferability of U3D makes such universal black-box attack easy-to-launch,\nwhich can be further enhanced by integrating queries over the target model when\nnecessary; (3) U3D ensures human-imperceptibility; (4) U3D can bypass the\nexisting state-of-the-art defense schemes; (5) U3D can be efficiently generated\nwith a few pre-learned parameters, and then immediately injected to attack\nreal-time DNN-based video recognition systems. We have conducted extensive\nexperiments to evaluate U3D on multiple DNN models and three large-scale video\ndatasets. The experimental results demonstrate its superiority and\npracticality.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 07:55:21 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Xie", "Shangyu", ""], ["Wang", "Han", ""], ["Kong", "Yu", ""], ["Hong", "Yuan", ""]]}, {"id": "2107.04296", "submitter": "Moritz Knolle", "authors": "Moritz Knolle, Alexander Ziller, Dmitrii Usynin, Rickmer Braren,\n  Marcus R. Makowski, Daniel Rueckert, Georgios Kaissis", "title": "Differentially private training of neural networks with Langevin\n  dynamics forcalibrated predictive uncertainty", "comments": "Accepted to the ICML 2021 Theory and Practice of Differential Privacy\n  Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that differentially private stochastic gradient descent (DP-SGD) can\nyield poorly calibrated, overconfident deep learning models. This represents a\nserious issue for safety-critical applications, e.g. in medical diagnosis. We\nhighlight and exploit parallels between stochastic gradient Langevin dynamics,\na scalable Bayesian inference technique for training deep neural networks, and\nDP-SGD, in order to train differentially private, Bayesian neural networks with\nminor adjustments to the original (DP-SGD) algorithm. Our approach provides\nconsiderably more reliable uncertainty estimates than DP-SGD, as demonstrated\nempirically by a reduction in expected calibration error (MNIST $\\sim{5}$-fold,\nPediatric Pneumonia Dataset $\\sim{2}$-fold).\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 08:14:45 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Knolle", "Moritz", ""], ["Ziller", "Alexander", ""], ["Usynin", "Dmitrii", ""], ["Braren", "Rickmer", ""], ["Makowski", "Marcus R.", ""], ["Rueckert", "Daniel", ""], ["Kaissis", "Georgios", ""]]}, {"id": "2107.04315", "submitter": "Ulrich Haboeck", "authors": "Ulrich Hab\\\"ock and Alberto Garoffolo and Daniele Di Benedetto", "title": "Darlin: A proof carrying data scheme based on Marlin", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this document we describe the Darlin proof carrying data scheme for the\ndistributed computation of block and epoch proofs in a Latus sidechain of\nZendoo (arxive:2002.01847). Recursion as well as base proofs rest on Marlin\n(Chiesa et al. EUROCRYPT 2020) using the Pasta cycle of curves and the \"dlog\"\npolynomial commitment scheme from Bootle et al. We apply the amortization\ntechnique from Halo (Bowe et al., IACR eprint 2019/1021) to the non-succinct\nparts of the verifier, and we adapt their strategy for bivariate circuit\nencoding polynomials to aggregate Marlin's inner sumchecks across the nodes of\nthe proof carrying data scheme. Regarding performance, the advantage of Darlin\nover a scheme without inner sumcheck aggregation is about 30% in a tree-like\nscenario as ours, and beyond when applied to linear recursion.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 09:07:35 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Hab\u00f6ck", "Ulrich", ""], ["Garoffolo", "Alberto", ""], ["Di Benedetto", "Daniele", ""]]}, {"id": "2107.04435", "submitter": "Oliver De Candido", "authors": "Tobias Uelwer, Felix Michels, Oliver De Candido", "title": "Learning to Detect Adversarial Examples Based on Class Scores", "comments": "Accepted at the 44th German Conference on Artificial Intelligence (KI\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the increasing threat of adversarial attacks on deep neural networks\n(DNNs), research on efficient detection methods is more important than ever. In\nthis work, we take a closer look at adversarial attack detection based on the\nclass scores of an already trained classification model. We propose to train a\nsupport vector machine (SVM) on the class scores to detect adversarial\nexamples. Our method is able to detect adversarial examples generated by\nvarious attacks, and can be easily adopted to a plethora of deep classification\nmodels. We show that our approach yields an improved detection rate compared to\nan existing method, whilst being easy to implement. We perform an extensive\nempirical analysis on different deep classification models, investigating\nvarious state-of-the-art adversarial attacks. Moreover, we observe that our\nproposed method is better at detecting a combination of adversarial attacks.\nThis work indicates the potential of detecting various adversarial attacks\nsimply by using the class scores of an already trained classification model.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 13:29:54 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Uelwer", "Tobias", ""], ["Michels", "Felix", ""], ["De Candido", "Oliver", ""]]}, {"id": "2107.04436", "submitter": "Sebastian Garcia PhD.", "authors": "Sebasti\\'an Garc\\'ia, Karel Hynek, Dmtrii Vekshin, Tom\\'a\\v{s}\n  \\v{C}ejka, Armin Wasicek", "title": "Large Scale Measurement on the Adoption of Encrypted DNS", "comments": "16 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Several encryption proposals for DNS have been presented since 2016, but\ntheir adoption was not comprehensively studied yet. This research measured the\ncurrent adoption of DoH (DNS over HTTPS), DoT (DNS over TLS), and DoQ (DNS over\nQUIC) for five months at the beginning of 2021 by three different organizations\nwith global coverage. By comparing the total values, amount of requests per\nuser, and the seasonality of the traffic, it was possible to obtain the current\nadoption trends. Moreover, we actively scanned the Internet for still-unknown\nworking DoH servers and we compared them with a novel curated list of\nwell-known DoH servers. We conclude that despite growing in 2020, during the\nfirst five months of 2021 there was statistically significant evidence that the\naverage amount of Internet traffic for DoH, DoT and DoQ remained stationary.\nHowever, we found that the amount of, still unknown and ready to use, DoH\nservers grew 4 times. These measurements suggest that even though the amount of\nencrypted DNS is currently not growing, there may probably be more connections\nsoon to those unknown DoH servers for benign and malicious purposes.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 13:29:55 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Garc\u00eda", "Sebasti\u00e1n", ""], ["Hynek", "Karel", ""], ["Vekshin", "Dmtrii", ""], ["\u010cejka", "Tom\u00e1\u0161", ""], ["Wasicek", "Armin", ""]]}, {"id": "2107.04506", "submitter": "Jason R.C. Nurse Dr", "authors": "Alice Jaffray and Conor Finn and Jason R.C. Nurse", "title": "SherLOCKED: A Detective-themed Serious Game for Cyber Security Education", "comments": null, "journal-ref": "15th IFIP International Symposium on Human Aspects of Information\n  Security & Assurance (HAISA 2021)", "doi": "10.1007/978-3-030-81111-2_4", "report-no": null, "categories": "cs.CR cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gamification and Serious Games are progressively being used over a host of\nfields, particularly to support education. Such games provide a new way to\nengage students with content and can complement more traditional approaches to\nlearning. This article proposes SherLOCKED, a new serious game created in the\nstyle of a 2D top-down puzzle adventure. The game is situated in the context of\nan undergraduate cyber security course, and is used to consolidate students'\nknowledge of foundational security concepts (e.g. the CIA triad, security\nthreats and attacks and risk management). SherLOCKED was built based on a\nreview of existing serious games and a study of common gamification principles.\nIt was subsequently implemented within an undergraduate course, and evaluated\nwith 112 students. We found the game to be an effective, attractive and fun\nsolution for allowing further engagement with content that students were\nintroduced to during lectures. This research lends additional evidence to the\nuse of serious games in supporting learning about cyber security.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 15:46:47 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Jaffray", "Alice", ""], ["Finn", "Conor", ""], ["Nurse", "Jason R. C.", ""]]}, {"id": "2107.04594", "submitter": "Jawad Ali", "authors": "Amreen Batool, Baoshan Sun, Ali Saleem, and Jawad Ali", "title": "Convergence of 5G with Internet of Things for Enhanced Privacy", "comments": "11 pages, 2 Figures and 4 Tables", "journal-ref": null, "doi": "10.1007/978-3-030-73100-7_22", "report-no": null, "categories": "cs.NI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we address the issue of privacy in 5th generation (5G) driven\nInternet of Things (IoT) and related technologies while presenting a comparison\nwith previous technologies for communication and unaddressed issues in 5G.\nInitially, an overview of 5G driven IoT is presented with details about both\ntechnologies and eventually leading to problems that 5th generation will face.\nDetails about 5G are also presented while comparing them with previous\ntechnologies. The architecture of 5G is presented hence explaining layers of 5G\nand technologies like SDN, NFV and cloud computing that compose these layers.\nThe architecture for 5g based IoT is also presented for providing visual\nunderstanding as well as explained based on how this addresses the issues\npresent in 4G. Privacy is highlighted in 5G driven IoT while providing details\nabout how SDN, NFV and cloud computing helps in elimination of this issue. The\nissues presented will be compared with 4G based IoT and solutions are provided\nabout mitigation of these issues particularly bandwidth and security. Moreover,\ntechniques used by 4G and 5G technologies for handling the issues of privacy in\nIoT are presented in a nutshell as a table. Paper also presents a detailed\noverview of technologies making 5G possible meanwhile giving an explanation\nabout how these technologies resolve privacy issues in 5G.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 04:41:54 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Batool", "Amreen", ""], ["Sun", "Baoshan", ""], ["Saleem", "Ali", ""], ["Ali", "Jawad", ""]]}, {"id": "2107.04743", "submitter": "Yueming Wu", "authors": "Yueming Wu, Deqing Zou, Wei Yang, Xiang Li, and Hai Jin", "title": "HomDroid: Detecting Android Covert Malware by Social-Network Homophily\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Android has become the most popular mobile operating system. Correspondingly,\nan increasing number of Android malware has been developed and spread to steal\nusers' private information. There exists one type of malware whose benign\nbehaviors are developed to camouflage malicious behaviors. The malicious\ncomponent occupies a small part of the entire code of the application (app for\nshort), and the malicious part is strongly coupled with the benign part. In\nthis case, the malware may cause false negatives when malware detectors extract\nfeatures from the entire apps to conduct classification because the malicious\nfeatures of these apps may be hidden among benign features. Moreover, some\nprevious work aims to divide the entire app into several parts to discover the\nmalicious part. However, the premise of these methods to commence app partition\nis that the connections between the normal part and the malicious part are\nweak.\n  In this paper, we call this type of malware as Android covert malware and\ngenerate the first dataset of covert malware. To detect them, we first conduct\nstatic analysis to extract the call graphs. Through the deep analysis on\ngraphs, we observe that although the correlations between the normal part and\nthe malicious part in these graphs are high, the degree of these correlations\nhas a distribution. Based on the observation, we design HomDroid to detect\ncovert malware by analyzing the homophily of call graphs. We identify the ideal\nthreshold of correlation to distinguish the normal part and the malicious part\nbased on the evaluation results on a dataset of 4,840 benign apps and 3,385\ncovert malicious apps. According to our evaluation results, HomDroid is capable\nof detecting 96.8% of covert malware while the False Negative Rates of another\nfour state-of-the-art systems (i.e., PerDroid, Drebin, MaMaDroid, and IntDroid)\nare 30.7%, 16.3%, 15.2%, and 10.4%, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 03:14:21 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Wu", "Yueming", ""], ["Zou", "Deqing", ""], ["Yang", "Wei", ""], ["Li", "Xiang", ""], ["Jin", "Hai", ""]]}, {"id": "2107.04764", "submitter": "Mohamed Nassar", "authors": "Sara Hajj Ibrahim and Mohamed Nassar", "title": "Hack The Box: Fooling Deep Learning Abstraction-Based Monitors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning is a type of machine learning that adapts a deep hierarchy of\nconcepts. Deep learning classifiers link the most basic version of concepts at\nthe input layer to the most abstract version of concepts at the output layer,\nalso known as a class or label. However, once trained over a finite set of\nclasses, some deep learning models do not have the power to say that a given\ninput does not belong to any of the classes and simply cannot be linked.\nCorrectly invalidating the prediction of unrelated classes is a challenging\nproblem that has been tackled in many ways in the literature. Novelty detection\ngives deep learning the ability to output \"do not know\" for novel/unseen\nclasses. Still, no attention has been given to the security aspects of novelty\ndetection. In this paper, we consider the case study of abstraction-based\nnovelty detection and show that it is not robust against adversarial samples.\nMoreover, we show the feasibility of crafting adversarial samples that fool the\ndeep learning classifier and bypass the novelty detection monitoring at the\nsame time. In other words, these monitoring boxes are hackable. We demonstrate\nthat novelty detection itself ends up as an attack surface.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 05:06:04 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 05:19:11 GMT"}, {"version": "v3", "created": "Sun, 18 Jul 2021 20:50:55 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Ibrahim", "Sara Hajj", ""], ["Nassar", "Mohamed", ""]]}, {"id": "2107.04833", "submitter": "Chaojie Gu", "authors": "Chaojie Gu, Linshan Jiang, Rui Tan, Mo Li, Jun Huang", "title": "Attack-Aware Synchronization-Free Data Timestamping in LoRaWAN", "comments": "This paper has been accepted by ACM Transactions on Sensor Networks\n  (TOSN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-power wide-area network technologies such as LoRaWAN are promising for\ncollecting low-rate monitoring data from geographically distributed sensors, in\nwhich timestamping the sensor data is a critical system function. This paper\nconsiders a synchronization-free approach to timestamping LoRaWAN uplink data\nbased on signal arrival time at the gateway, which well matches LoRaWAN's\none-hop star topology and releases bandwidth from transmitting timestamps and\nsynchronizing end devices' clocks at all times. However, we show that this\napproach is susceptible to a {\\em frame delay attack} consisting of malicious\nframe collision and delayed replay. Real experiments show that the attack can\naffect the end devices in large areas up to about $50,000\\,\\text{m}^2$. In a\nbroader sense, the attack threatens any system functions requiring timely\ndeliveries of LoRaWAN frames. To address this threat, we propose a\n$\\mathsf{LoRaTS}$ gateway design that integrates a commodity LoRaWAN gateway\nand a low-power software-defined radio receiver to track the inherent frequency\nbiases of the end devices. Based on an analytic model of LoRa's chirp spread\nspectrum modulation, we develop signal processing algorithms to estimate the\nfrequency biases with high accuracy beyond that achieved by LoRa's default\ndemodulation. The accurate frequency bias tracking capability enables the\ndetection of the attack that introduces additional frequency biases. We also\ninvestigate and implement a more crafty attack that uses advanced radio\napparatuses to eliminate the frequency biases. To address this crafty attack,\nwe propose a pseudorandom interval hopping scheme to enhance our frequency bias\ntracking approach. Extensive experiments show the effectiveness of our approach\nin deployments with real affecting factors such as temperature variations.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 13:09:07 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Gu", "Chaojie", ""], ["Jiang", "Linshan", ""], ["Tan", "Rui", ""], ["Li", "Mo", ""], ["Huang", "Jun", ""]]}, {"id": "2107.04910", "submitter": "Hanan Hindy", "authors": "Elochukwu Ukwandu, Mohamed Amine Ben Farah, Hanan Hindy, Miroslav\n  Bures, Robert Atkinson, Christos Tachtatzis, and Xavier Bellekens", "title": "Cyber-Security Challenges in Aviation Industry: A Review of Current and\n  Future Trends", "comments": "25 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The integration of Information and Communication Technology (ICT) tools into\nmechanical devices found in aviation industry has raised security concerns. The\nmore integrated the system, the more vulnerable due to the inherent\nvulnerabilities found in ICT tools and software that drives the system. The\nsecurity concerns have become more heightened as the concept of\nelectronic-enabled aircraft and smart airports get refined and implemented\nunderway. In line with the above, this paper undertakes a review of\ncyber-security incidence in the aviation sector over the last 20 years. The\nessence is to understand the common threat actors, their motivations, the type\nof attacks, aviation infrastructure that is commonly attacked and then match\nthese so as to provide insight on the current state of the cyber-security in\nthe aviation sector. The review showed that the industry's threats come mainly\nfrom Advance Persistent Threat (APT) groups that work in collaboration with\nsome state actors to steal intellectual property and intelligence, in order to\nadvance their domestic aerospace capabilities as well as possibly monitor,\ninfiltrate and subvert other nations' capabilities. The segment of the aviation\nindustry commonly attacked is the Information Technology infrastructure, and\nthe prominent type of attacks is malicious hacking activities that aim at\ngaining unauthorised access using known malicious password cracking techniques\nsuch as Brute force attacks, Dictionary attacks and so on. The review further\nanalysed the different attack surfaces that exist in aviation industry, threat\ndynamics, and use these dynamics to predict future trends of cyberattacks in\nthe industry. The aim is to provide information for the cybersecurity\nprofessionals and aviation stakeholders for proactive actions in protecting\nthese critical infrastructures against cyberincidence for an optimal customer\nservice oriented industry.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 20:54:29 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Ukwandu", "Elochukwu", ""], ["Farah", "Mohamed Amine Ben", ""], ["Hindy", "Hanan", ""], ["Bures", "Miroslav", ""], ["Atkinson", "Robert", ""], ["Tachtatzis", "Christos", ""], ["Bellekens", "Xavier", ""]]}, {"id": "2107.04940", "submitter": "Jenny Blessing", "authors": "Jenny Blessing, Michael A. Specter, Daniel J. Weitzner", "title": "You Really Shouldn't Roll Your Own Crypto: An Empirical Study of\n  Vulnerabilities in Cryptographic Libraries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The security of the Internet rests on a small number of open-source\ncryptographic libraries: a vulnerability in any one of them threatens to\ncompromise a significant percentage of web traffic. Despite this potential for\nsecurity impact, the characteristics and causes of vulnerabilities in\ncryptographic software are not well understood. In this work, we conduct the\nfirst comprehensive analysis of cryptographic libraries and the vulnerabilities\naffecting them. We collect data from the National Vulnerability Database,\nindividual project repositories and mailing lists, and other relevant sources\nfor eight widely used cryptographic libraries.\n  Among our most interesting findings is that only 27.2% of vulnerabilities in\ncryptographic libraries are cryptographic issues while 37.2% of vulnerabilities\nare memory safety issues, indicating that systems-level bugs are a greater\nsecurity concern than the actual cryptographic procedures. In our investigation\nof the causes of these vulnerabilities, we find evidence of a strong\ncorrelation between the complexity of these libraries and their (in)security,\nempirically demonstrating the potential risks of bloated cryptographic\ncodebases. We further compare our findings with non-cryptographic systems,\nobserving that these systems are, indeed, more complex than similar\ncounterparts, and that this excess complexity appears to produce significantly\nmore vulnerabilities in cryptographic libraries than in non-cryptographic\nsoftware.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 02:09:52 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Blessing", "Jenny", ""], ["Specter", "Michael A.", ""], ["Weitzner", "Daniel J.", ""]]}, {"id": "2107.05054", "submitter": "Thanassis Giannetsos", "authors": "Heini Bergsson Debes, Thanassis Giannetsos, Ioannis Krontiris", "title": "BLINDTRUST: Oblivious Remote Attestation for Secure Service Function\n  Chains", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  With the rapidly evolving next-generation systems-of-systems, we face new\nsecurity, resilience, and operational assurance challenges. In the face of the\nincreasing attack landscape, it is necessary to cater to efficient mechanisms\nto verify software and device integrity to detect run-time modifications.\nTowards this direction, remote attestation is a promising defense mechanism\nthat allows a third party, the verifier, to ensure a remote device's (the\nprover's) integrity. However, many of the existing families of attestation\nsolutions have strong assumptions on the verifying entity's trustworthiness,\nthus not allowing for privacy preserving integrity correctness. Furthermore,\nthey suffer from scalability and efficiency issues. This paper presents a\nlightweight dynamic configuration integrity verification that enables inter and\nintra-device attestation without disclosing any configuration information and\ncan be applied on both resource-constrained edge devices and cloud services.\nOur goal is to enhance run-time software integrity and trustworthiness with a\nscalable solution eliminating the need for federated infrastructure trust.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 14:35:21 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Debes", "Heini Bergsson", ""], ["Giannetsos", "Thanassis", ""], ["Krontiris", "Ioannis", ""]]}, {"id": "2107.05127", "submitter": "Muhammad Azmi Umer", "authors": "Muhammad Azmi Umer, Chuadhry Mujeeb Ahmed, Muhammad Taha Jilani,\n  Aditya P. Mathur", "title": "Attack Rules: An Adversarial Approach to Generate Attacks for Industrial\n  Control Systems using Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial learning is used to test the robustness of machine learning\nalgorithms under attack and create attacks that deceive the anomaly detection\nmethods in Industrial Control System (ICS). Given that security assessment of\nan ICS demands that an exhaustive set of possible attack patterns is studied,\nin this work, we propose an association rule mining-based attack generation\ntechnique. The technique has been implemented using data from a secure Water\nTreatment plant. The proposed technique was able to generate more than 300,000\nattack patterns constituting a vast majority of new attack vectors which were\nnot seen before. Automatically generated attacks improve our understanding of\nthe potential attacks and enable the design of robust attack detection\ntechniques.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 20:20:07 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Umer", "Muhammad Azmi", ""], ["Ahmed", "Chuadhry Mujeeb", ""], ["Jilani", "Muhammad Taha", ""], ["Mathur", "Aditya P.", ""]]}, {"id": "2107.05156", "submitter": "Mahyar Shirvanimoghaddam", "authors": "Mahyar Shirvanimoghaddam", "title": "On the Hamming Weight Distribution of Subsequences of Pseudorandom\n  Sequences", "comments": "The paper has been accepted for publication in IEEE International\n  Symposium on Information Theory (ISIT), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we characterize the average Hamming weight distribution of\nsubsequences of maximum-length sequences ($m$-sequences). In particular, we\nconsider all possible $m$-sequences of dimension $k$ and find the average\nnumber of subsequences of length $n$ that have a Hamming weight $t$. To do so,\nwe first characterize the Hamming weight distribution of the average dual code\nand use the MacWilliams identity to find the average Hamming weight\ndistribution of subsequences of $m$-sequences. We further find a lower bound on\nthe minimum Hamming weight of the subsequences and show that there always\nexists a primitive polynomial to generate an $m$-sequence to meet this bound.\nWe show via simulations that when a proper primitive polynomial is chosen,\nsubsequences of the $m$-sequence can form a good rateless code that can meet\nthe normal approximation benchmark.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 00:59:29 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Shirvanimoghaddam", "Mahyar", ""]]}, {"id": "2107.05166", "submitter": "Soham Pal", "authors": "Soham Pal, Yash Gupta, Aditya Kanade, Shirish Shevade", "title": "Stateful Detection of Model Extraction Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-Learning-as-a-Service providers expose machine learning (ML) models\nthrough application programming interfaces (APIs) to developers. Recent work\nhas shown that attackers can exploit these APIs to extract good approximations\nof such ML models, by querying them with samples of their choosing. We propose\nVarDetect, a stateful monitor that tracks the distribution of queries made by\nusers of such a service, to detect model extraction attacks. Harnessing the\nlatent distributions learned by a modified variational autoencoder, VarDetect\nrobustly separates three types of attacker samples from benign samples, and\nsuccessfully raises an alarm for each. Further, with VarDetect deployed as an\nautomated defense mechanism, the extracted substitute models are found to\nexhibit poor performance and transferability, as intended. Finally, we\ndemonstrate that even adaptive attackers with prior knowledge of the deployment\nof VarDetect, are detected by it.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 02:18:26 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Pal", "Soham", ""], ["Gupta", "Yash", ""], ["Kanade", "Aditya", ""], ["Shevade", "Shirish", ""]]}, {"id": "2107.05172", "submitter": "Ziaur Rahman", "authors": "Sk. Tanzir Mehedi, Adnan Anwar, Ziaur Rahman and Kawsar Ahmed", "title": "Deep Transfer Learning Based Intrusion Detection System for Electric\n  Vehicular Networks", "comments": "23 Pages, 14 Figures, 6 Tables with Appendix", "journal-ref": "MDPI Sensor, 2021, 21(14), 4736", "doi": "10.3390/s21144736", "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Controller Area Network (CAN) bus works as an important protocol in the\nreal-time In-Vehicle Network (IVN) systems for its simple, suitable, and robust\narchitecture. The risk of IVN devices has still been insecure and vulnerable\ndue to the complex data-intensive architectures which greatly increase the\naccessibility to unauthorized networks and the possibility of various types of\ncyberattacks. Therefore, the detection of cyberattacks in IVN devices has\nbecome a growing interest. With the rapid development of IVNs and evolving\nthreat types, the traditional machine learning-based IDS has to update to cope\nwith the security requirements of the current environment. Nowadays, the\nprogression of deep learning, deep transfer learning, and its impactful outcome\nin several areas has guided as an effective solution for network intrusion\ndetection. This manuscript proposes a deep transfer learning-based IDS model\nfor IVN along with improved performance in comparison to several other existing\nmodels. The unique contributions include effective attribute selection which is\nbest suited to identify malicious CAN messages and accurately detect the normal\nand abnormal activities, designing a deep transfer learning-based LeNet model,\nand evaluating considering real-world data. To this end, an extensive\nexperimental performance evaluation has been conducted. The architecture along\nwith empirical analyses shows that the proposed IDS greatly improves the\ndetection accuracy over the mainstream machine learning, deep learning, and\nbenchmark deep transfer learning models and has demonstrated better performance\nfor real-time IVN security.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 03:06:49 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Mehedi", "Sk. Tanzir", ""], ["Anwar", "Adnan", ""], ["Rahman", "Ziaur", ""], ["Ahmed", "Kawsar", ""]]}, {"id": "2107.05220", "submitter": "Yannis Stamatiou", "authors": "Vasiliki Liagkou, Panayotis Nastou, Paul Spirakis, Yannis Stamatiou", "title": "On the undecidability of the Panopticon detection problem", "comments": "13 pages, no figures, technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Panopticon (which means \"watcher of everything\") is a well-known\nstructure of continuous surveillance and discipline proposed by Bentham in\n1785. This device was, later, used by Foucault and other philosophers as a\nparadigm and metaphor for the study of constitutional power and knowledge as\nwell as a model of individuals' deprivation of freedom. Nowadays, technological\nachievements have given rise to new, non-physical (unlike prisons), means of\nconstant surveillance that transcend physical boundaries. This, combined with\nthe confession of some governmental institutions that they actually collaborate\nwith these Internet giants to collect or deduce information about people,\ncreates a worrisome situation of several co-existing Panopticons that can act\nseparately or in close collaboration. Thus, they can only be detected and\nidentified through the expense of (perhaps considerable) effort. In this paper\nwe provide a theoretical framework for studying the detectability status of\nPanopticons that fall under two theoretical, but not unrealistic, definitions.\nWe show, using Oracle Turing Machines, that detecting modern day, ICT-based,\nPanopticons is an undecidable problem. Furthermore, we show that for each\nsufficiently expressive formal system, we can effectively construct a Turing\nMachine for which it is impossible to prove, within the formal system, either\nthat it is a Panopticon or it is not a Panopticon.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 06:48:17 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Liagkou", "Vasiliki", ""], ["Nastou", "Panayotis", ""], ["Spirakis", "Paul", ""], ["Stamatiou", "Yannis", ""]]}, {"id": "2107.05225", "submitter": "Toby Murray", "authors": "Toby Murray, Pengbo Yan, Gidon Ernst", "title": "Incremental Vulnerability Detection via Back-Propagating Symbolic\n  Execution of Insecurity Separation Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first compositional, incremental static analysis for detecting\nmemory-safety and information leakage vulnerabilities in C-like programs. To do\nso, we develop the first under-approximate relational program logics, including\nInsecurity Separation Logic (InsecSL). We show how InsecSL can be automated via\nback-propagating symbolic execution (BPSE) to build a bottom-up,\ninter-procedural and incremental analysis for detecting vulnerabilities. We\nprove our approach sound in Isabelle/HOL and implement it in a proof-of-concept\ntool, Underflow, for analysing C programs, which we apply to various case\nstudies.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 07:11:58 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Murray", "Toby", ""], ["Yan", "Pengbo", ""], ["Ernst", "Gidon", ""]]}, {"id": "2107.05243", "submitter": "Jun Wang", "authors": "Jun Wang, Chang Xu, Francisco Guzman, Ahmed El-Kishky, Yuqing Tang,\n  Benjamin I. P. Rubinstein, Trevor Cohn", "title": "Putting words into the system's mouth: A targeted attack on neural\n  machine translation using monolingual data poisoning", "comments": "Findings of ACL, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation systems are known to be vulnerable to adversarial\ntest inputs, however, as we show in this paper, these systems are also\nvulnerable to training attacks. Specifically, we propose a poisoning attack in\nwhich a malicious adversary inserts a small poisoned sample of monolingual text\ninto the training set of a system trained using back-translation. This sample\nis designed to induce a specific, targeted translation behaviour, such as\npeddling misinformation. We present two methods for crafting poisoned examples,\nand show that only a tiny handful of instances, amounting to only 0.02% of the\ntraining set, is sufficient to enact a successful attack. We outline a defence\nmethod against said attacks, which partly ameliorates the problem. However, we\nstress that this is a blind-spot in modern NMT, demanding immediate attention.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 08:07:09 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Wang", "Jun", ""], ["Xu", "Chang", ""], ["Guzman", "Francisco", ""], ["El-Kishky", "Ahmed", ""], ["Tang", "Yuqing", ""], ["Rubinstein", "Benjamin I. P.", ""], ["Cohn", "Trevor", ""]]}, {"id": "2107.05252", "submitter": "Jiacheng Liang", "authors": "Jiacheng Liang, Wensi Jiang and Songze Li", "title": "OmniLytics: A Blockchain-based Secure Data Market for Decentralized\n  Machine Learning", "comments": "12 pages,5 figures, accepted by International Workshop on Federated\n  Learning for User Privacy and Data Confidentiality in Conjunction with ICML\n  2021(http://federated-learning.org/fl-icml-2021/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose OmniLytics, a blockchain-based secure data trading marketplace for\nmachine learning applications. Utilizing OmniLytics, many distributed data\nowners can contribute their private data to collectively train a ML model\nrequested by some model owners, and get compensated for data contribution.\nOmniLytics enables such model training while simultaneously providing 1) model\nsecurity against curious data owners; 2) data security against curious model\nand data owners; 3) resilience to malicious data owners who provide faulty\nresults to poison model training; and 4) resilience to malicious model owner\nwho intents to evade the payment. OmniLytics is implemented as a smart contract\non the Ethereum blockchain to guarantee the atomicity of payment. In\nOmniLytics, a model owner publishes encrypted initial model on the contract,\nover which the participating data owners compute gradients using their private\ndata, and securely aggregate the gradients through the contract. Finally, the\ncontract reimburses the data owners, and the model owner decrypts the\naggregated model update. We implement a working prototype of OmniLytics on\nEthereum, and perform extensive experiments to measure its gas cost and\nexecution time under various parameter combinations, demonstrating its high\ncomputation and cost efficiency and strong practicality.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 08:28:15 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Liang", "Jiacheng", ""], ["Jiang", "Wensi", ""], ["Li", "Songze", ""]]}, {"id": "2107.05411", "submitter": "Masayuki Tezuka", "authors": "Masayuki Tezuka, Yusuke Yoshida, Keisuke Tanaka", "title": "Weakened Random Oracle Models with Target Prefix", "comments": null, "journal-ref": "SecITC 2018", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weakened random oracle models (WROMs) are variants of the random oracle model\n(ROM). The WROMs have the random oracle and the additional oracle which breaks\nsome property of a hash function. Analyzing the security of cryptographic\nschemes in WROMs, we can specify the property of a hash function on which the\nsecurity of cryptographic schemes depends. Liskov (SAC 2006) proposed WROMs and\nlater Numayama et al. (PKC 2008) formalized them as CT-ROM, SPT-ROM, and\nFPT-ROM. In each model, there is the additional oracle to break collision\nresistance, second preimage resistance, preimage resistance respectively. Tan\nand Wong (ACISP 2012) proposed the generalized FPT-ROM (GFPT-ROM) which\nintended to capture the chosen prefix collision attack suggested by Stevens et\nal. (EUROCRYPT 2007). In this paper, in order to analyze the security of\ncryptographic schemes more precisely, we formalize GFPT-ROM and propose\nadditional three WROMs which capture the chosen prefix collision attack and its\nvariants. In particular, we focus on signature schemes such as RSA-FDH, its\nvariants, and DSA, in order to understand essential roles of WROMs in their\nsecurity proofs.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 13:28:25 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Tezuka", "Masayuki", ""], ["Yoshida", "Yusuke", ""], ["Tanaka", "Keisuke", ""]]}, {"id": "2107.05602", "submitter": "Rohit Dube", "authors": "Rohit Dube", "title": "Understanding the Communist Party of China's Information Operations", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Communist Party of China is known to engage in Information Operations to\ninfluence public opinion. In this paper, we seek to understand the tactics used\nby the Communist Party in a recent Information Operation - the one conducted to\ninfluence the narrative around the pro-democracy movement in Hong Kong. We use\na Twitter dataset containing account information and tweets for the operation.\nOur research shows that the Hong Kong operation was (at least) partially\nconducted manually by humans rather than entirely by automated bots. We also\nshow that the Communist Party mixed in personal attacks on Chinese dissidents\nand messages on COVID-19 with the party's views on the protests during the\noperation. Finally, we conclude that the Information Operation network in the\nTwitter dataset was set up to amplify content generated elsewhere rather than\nto influence the narrative with original content.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 17:34:28 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Dube", "Rohit", ""]]}, {"id": "2107.05675", "submitter": "Onur G\\\"unl\\\"u Dr.-Ing.", "authors": "Onur G\\\"unl\\\"u, Rafael F. Schaefer, and H. Vincent Poor", "title": "Quality of Service Guarantees for Physical Unclonable Functions", "comments": "Submitted to IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CR cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider a secret key agreement problem in which noisy physical unclonable\nfunction (PUF) outputs facilitate reliable, secure, and private key agreement\nwith the help of public, noiseless, and authenticated storage. PUF outputs are\nhighly correlated, so transform coding methods have been combined with scalar\nquantizers to extract uncorrelated bit sequences with reliability guarantees.\nFor PUF circuits with continuous-valued outputs, the models for transformed\noutputs are made more realistic by replacing the fitted distributions with\ncorresponding truncated ones. The state-of-the-art PUF methods that provide\nreliability guarantees to each extracted bit are shown to be inadequate to\nguarantee the same reliability level for all PUF outputs. Thus, a quality of\nservice parameter is introduced to control the percentage of PUF outputs for\nwhich a target reliability level can be guaranteed. A public ring oscillator\n(RO) output dataset is used to illustrate that a truncated Gaussian\ndistribution can be fitted to transformed RO outputs that are inputs to uniform\nscalar quantizers such that reliability guarantees can be provided for each bit\nextracted from any PUF device under additive Gaussian noise components by\neliminating a small subset of PUF outputs. Furthermore, we conversely show that\nit is not possible to provide such reliability guarantees without eliminating\nany PUF output if no extra secrecy and privacy leakage is allowed.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 18:26:08 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["G\u00fcnl\u00fc", "Onur", ""], ["Schaefer", "Rafael F.", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2107.05692", "submitter": "Qipeng Liu", "authors": "Andrea Coladangelo and Jiahui Liu and Qipeng Liu and Mark Zhandry", "title": "Hidden Cosets and Applications to Unclonable Cryptography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study a generalization of hidden subspace states to hidden\ncoset states (first introduced by Aaronson and Christiano [STOC '12]). This\nnotion was considered independently by Vidick and Zhang [Eurocrypt '21], in the\ncontext of proofs of quantum knowledge from quantum money schemes. We explore\nunclonable properties of coset states and several applications:\n  - We show that assuming indistinguishability obfuscation (iO), hidden coset\nstates possess a certain direct product hardness property, which immediately\nimplies a tokenized signature scheme in the plain model. Previously, it was\nknown only relative to an oracle, from a work of Ben-David and Sattath [QCrypt\n'17].\n  - Combining a tokenized signature scheme with extractable witness encryption,\nwe give a construction of an unclonable decryption scheme in the plain model.\nThe latter primitive was recently proposed by Georgiou and Zhandry [ePrint\n'20], who gave a construction relative to a classical oracle.\n  - We conjecture that coset states satisfy a certain natural\n(information-theoretic) monogamy-of-entanglement property. Assuming this\nconjecture is true, we remove the requirement for extractable witness\nencryption in our unclonable decryption construction, by relying instead on\ncompute-and-compare obfuscation for the class of unpredictable distributions.\n  - Finally, we give a construction of a copy-protection scheme for\npseudorandom functions (PRFs) in the plain model. Our scheme is secure either\nassuming iO, OWF, and extractable witness encryption, or assuming iO, OWF,\ncompute-and-compare obfuscation for the class of unpredictable distributions,\nand the conjectured monogamy property mentioned above. This is the first\nexample of a copy-protection scheme with provable security in the plain model\nfor a class of functions that is not evasive.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 19:04:01 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Coladangelo", "Andrea", ""], ["Liu", "Jiahui", ""], ["Liu", "Qipeng", ""], ["Zhandry", "Mark", ""]]}, {"id": "2107.05749", "submitter": "Malte M\\\"oser", "authors": "Malte M\\\"oser and Arvind Narayanan", "title": "Resurrecting Address Clustering in Bitcoin", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain analysis is essential for understanding how cryptocurrencies like\nBitcoin are used in practice, and address clustering is a cornerstone of\nblockchain analysis. However, current techniques rely on heuristics that have\nnot been rigorously evaluated or optimized. In this paper, we tackle several\nchallenges of change address identification and clustering. First, we build a\nground truth set of transactions with known change from the Bitcoin blockchain\nthat can be used to validate the efficacy of individual change address\ndetection heuristics. Equipped with this data set, we develop new techniques to\npredict change outputs with low false positive rates. After applying our\nprediction model to the Bitcoin blockchain, we analyze the resulting clustering\nand develop ways to detect and prevent cluster collapse. Finally, we assess the\nimpact our enhanced clustering has on two exemplary applications.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 21:37:01 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["M\u00f6ser", "Malte", ""], ["Narayanan", "Arvind", ""]]}, {"id": "2107.05754", "submitter": "Andrei Ilie", "authors": "Andrei Ilie, Marius Popescu, Alin Stefanescu", "title": "EvoBA: An Evolution Strategy as a Strong Baseline forBlack-Box\n  Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent work has shown how easily white-box adversarial attacks can be applied\nto state-of-the-art image classifiers. However, real-life scenarios resemble\nmore the black-box adversarial conditions, lacking transparency and usually\nimposing natural, hard constraints on the query budget.\n  We propose $\\textbf{EvoBA}$, a black-box adversarial attack based on a\nsurprisingly simple evolutionary search strategy. $\\textbf{EvoBA}$ is\nquery-efficient, minimizes $L_0$ adversarial perturbations, and does not\nrequire any form of training.\n  $\\textbf{EvoBA}$ shows efficiency and efficacy through results that are in\nline with much more complex state-of-the-art black-box attacks such as\n$\\textbf{AutoZOOM}$. It is more query-efficient than $\\textbf{SimBA}$, a simple\nand powerful baseline black-box attack, and has a similar level of complexity.\nTherefore, we propose it both as a new strong baseline for black-box\nadversarial attacks and as a fast and general tool for gaining empirical\ninsight into how robust image classifiers are with respect to $L_0$ adversarial\nperturbations.\n  There exist fast and reliable $L_2$ black-box attacks, such as\n$\\textbf{SimBA}$, and $L_{\\infty}$ black-box attacks, such as\n$\\textbf{DeepSearch}$. We propose $\\textbf{EvoBA}$ as a query-efficient $L_0$\nblack-box adversarial attack which, together with the aforementioned methods,\ncan serve as a generic tool to assess the empirical robustness of image\nclassifiers. The main advantages of such methods are that they run fast, are\nquery-efficient, and can easily be integrated in image classifiers development\npipelines.\n  While our attack minimises the $L_0$ adversarial perturbation, we also report\n$L_2$, and notice that we compare favorably to the state-of-the-art $L_2$\nblack-box attack, $\\textbf{AutoZOOM}$, and of the $L_2$ strong baseline,\n$\\textbf{SimBA}$.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 21:55:01 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Ilie", "Andrei", ""], ["Popescu", "Marius", ""], ["Stefanescu", "Alin", ""]]}, {"id": "2107.05774", "submitter": "Mahyar Shirvanimoghaddam", "authors": "Mahyar Shirvanimoghaddam", "title": "Primitive Rateless Codes", "comments": "Accepted for publication in IEEE Transaction on Communications, July\n  2021", "journal-ref": null, "doi": "10.1109/TCOMM.2021.3096961", "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we propose primitive rateless (PR) codes. A PR code is\ncharacterized by the message length and a primitive polynomial over\n$\\mathbf{GF}(2)$, which can generate a potentially limitless number of coded\nsymbols. We show that codewords of a PR code truncated at any arbitrary length\ncan be represented as subsequences of a maximum-length sequence ($m$-sequence).\nWe characterize the Hamming weight distribution of PR codes and their duals and\nshow that for a properly chosen primitive polynomial, the Hamming weight\ndistribution of the PR code can be well approximated by the truncated binomial\ndistribution. We further find a lower bound on the minimum Hamming weight of PR\ncodes and show that there always exists a PR code that can meet this bound for\nany desired codeword length. We provide a list of primitive polynomials for\nmessage lengths up to $40$ and show that the respective PR codes closely meet\nthe Gilbert-Varshamov bound at various rates. Simulation results show that PR\ncodes can achieve similar block error rates as their BCH counterparts at\nvarious signal-to-noise ratios (SNRs) and code rates. PR codes are\nrate-compatible and can generate as many coded symbols as required; thus,\ndemonstrating a truly rateless performance.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 23:18:36 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Shirvanimoghaddam", "Mahyar", ""]]}, {"id": "2107.05780", "submitter": "Sid Ahmed Fezza", "authors": "Anouar Kherchouche, Sid Ahmed Fezza, Wassim Hamidouche", "title": "Detect and Defense Against Adversarial Examples in Deep Learning using\n  Natural Scene Statistics and Adaptive Denoising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the enormous performance of deepneural networks (DNNs), recent\nstudies have shown theirvulnerability to adversarial examples (AEs), i.e.,\ncare-fully perturbed inputs designed to fool the targetedDNN. Currently, the\nliterature is rich with many ef-fective attacks to craft such AEs. Meanwhile,\nmany de-fenses strategies have been developed to mitigate thisvulnerability.\nHowever, these latter showed their effec-tiveness against specific attacks and\ndoes not general-ize well to different attacks. In this paper, we proposea\nframework for defending DNN classifier against ad-versarial samples. The\nproposed method is based on atwo-stage framework involving a separate detector\nanda denoising block. The detector aims to detect AEs bycharacterizing them\nthrough the use of natural scenestatistic (NSS), where we demonstrate that\nthese statis-tical features are altered by the presence of\nadversarialperturbations. The denoiser is based on block matching3D (BM3D)\nfilter fed by an optimum threshold valueestimated by a convolutional neural\nnetwork (CNN) toproject back the samples detected as AEs into theirdata\nmanifold. We conducted a complete evaluation onthree standard datasets namely\nMNIST, CIFAR-10 andTiny-ImageNet. The experimental results show that\ntheproposed defense method outperforms the state-of-the-art defense techniques\nby improving the robustnessagainst a set of attacks under black-box, gray-box\nand white-box settings. The source code is available at:\nhttps://github.com/kherchouche-anouar/2DAE\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 23:45:44 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Kherchouche", "Anouar", ""], ["Fezza", "Sid Ahmed", ""], ["Hamidouche", "Wassim", ""]]}, {"id": "2107.05824", "submitter": "March Boedihardjo", "authors": "March Boedihardjo, Thomas Strohmer, Roman Vershynin", "title": "Covariance's Loss is Privacy's Gain: Computationally Efficient, Private\n  and Accurate Synthetic Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The protection of private information is of vital importance in data-driven\nresearch, business, and government. The conflict between privacy and utility\nhas triggered intensive research in the computer science and statistics\ncommunities, who have developed a variety of methods for privacy-preserving\ndata release. Among the main concepts that have emerged are $k$-anonymity\n(often implemented via microaggregation) and differential privacy. Today,\nanother solution is gaining traction, synthetic data. However, the road to\nprivacy is paved with NP-hard problems. In this paper we focus on the NP-hard\nchallenge to develop a synthetic data generation method that is computationally\nefficient, comes with provable privacy guarantees, and rigorously quantifies\ndata utility. We solve a relaxed version of this problem by studying a\nfundamental, but a first glance completely unrelated, problem in probability\nconcerning the concept of covariance loss. Namely, we find a nearly optimal and\nconstructive answer to the question how much information is lost when we take\nconditional expectation. Surprisingly, this excursion into theoretical\nprobability produces mathematical techniques that allow us to derive\nconstructive, approximately optimal solutions to difficult applied problems\nconcerning microaggregation, privacy, and synthetic data.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 03:09:51 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Boedihardjo", "March", ""], ["Strohmer", "Thomas", ""], ["Vershynin", "Roman", ""]]}, {"id": "2107.05863", "submitter": "Aldar C.-F. Chan", "authors": "Aldar C-F. Chan, Jianying Zhou", "title": "Toward Safe Integration of Legacy SCADA Systems in the Smart Grid", "comments": "22 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A SCADA system is a distributed network of cyber-physical devices used for\ninstrumentation and control of critical infrastructures such as a electric\npower grid. With the emergence of the smart grid, SCADA systems are\nincreasingly required to be connected to more open systems and security becomes\ncrucial. However, many of these SCADA systems have been deployed for decades\nand were initially not designed with security in mind. In particular, the field\ndevices in these systems are vulnerable to false command injection from an\nintruding or compromised device. But implementing cryptographic defence on\nthese old-generation devices is challenging due to computation constraints.\nConsequently, solutions to protect legacy SCADA systems have to be an add-on.\nThis paper discusses two add-on defence strategies for legacy SCADA systems --\nthe data diode and detect-and-respond approaches -- and compares their security\nand application scenarios. A generic architectural framework is also proposed\nto implement the detect-and-respond strategy, with an instantiation to\ndemonstrate its practicality.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 06:00:23 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Chan", "Aldar C-F.", ""], ["Zhou", "Jianying", ""]]}, {"id": "2107.05868", "submitter": "Aldar C.-F. Chan", "authors": "Aldar C-F. Chan, Raymond M. H. Chung", "title": "Security and Privacy of Wireless Beacon Systems", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bluetooth Low Energy (BLE) beacons have been increasingly used in smart city\napplications, such as location-based and proximity-based services, to enable\nInternet of Things to interact with people in vicinity or enhance\ncontext-awareness. Their widespread deployment in human-centric applications\nmakes them an attractive target to adversaries for social or economic reasons.\nIn fact, beacons are reportedly exposed to various security issues and privacy\nconcerns. A characterization of attacks against beacon systems is given to help\nunderstand adversary motives, required adversarial capabilities, potential\nimpact and possible defence mechanisms for different threats, with a view to\nfacilitating security evaluation and protection formulation for beacon systems.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 06:23:08 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Chan", "Aldar C-F.", ""], ["Chung", "Raymond M. H.", ""]]}, {"id": "2107.05924", "submitter": "Koji Nuida", "authors": "Keita Suzuki and Koji Nuida", "title": "An Improvement of a Key Exchange Protocol Relying on Polynomial Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Akiyama et al. (Int. J. Math. Indust., 2019) proposed a post-quantum key\nexchange protocol that is based on the hardness of solving a system of\nmultivariate non-linear polynomial equations but has a design strategy\ndifferent from ordinary multivariate cryptography. However, their protocol has\na drawback that the probability of failing to establish a common key is\nimpractically high. In this paper, we improve the success probability of\nAkiyama et al.'s key exchange protocol significantly while keeping the\nsecurity, by restricting each component of the correct common key from the\nwhole of the coefficient field to its small subset. We give theoretical and\nexperimental evaluations showing that our proposed parameter set for our\nprotocol is expected to achieve both failure probability $2^{-120}$ and\n$128$-bit security level.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 08:45:32 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Suzuki", "Keita", ""], ["Nuida", "Koji", ""]]}, {"id": "2107.05939", "submitter": "Yuri Gbur", "authors": "Konrad Yuri Gbur and Florian Tschorsch", "title": "A QUIC(K) Way Through Your Firewall?", "comments": "7 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The QUIC protocol is a new approach to combine encryption and transport layer\nstream abstraction into one protocol to lower latency and improve security.\nHowever, the decision to encrypt transport layer functionality may limit the\ncapabilities of firewalls to protect networks. To identify these limitations we\ncreated a test environment and analyzed generated QUIC traffic from the\nviewpoint of a middlebox. This paper shows that QUIC indeed exposes traditional\nstateful firewalls to UDP hole punching bypass attacks. On the contrary we show\nthe robustness against censorship of QUIC through the encrypted transport layer\ndesign and analyze the capabilities to re-gain stateful tracking capabilities\nby deep packet inspection of the few exposed QUIC header fields.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 09:23:37 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Gbur", "Konrad Yuri", ""], ["Tschorsch", "Florian", ""]]}, {"id": "2107.06024", "submitter": "Stefan Marksteiner", "authors": "Stefan Marksteiner and Peter Priller", "title": "A Model-Driven Methodology for Automotive Cybersecurity Test Case\n  Generation", "comments": "7 pages, 6 figures, accepted for the joint SRCNAS/STRIVE workshop at\n  the 6th IEEE European Symposium on Security and Privacy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through international regulations (most prominently the latest UNECE\nregulation) and standards, the already widely perceived higher need for\ncybersecurity in automotive systems has been recognized and will mandate higher\nefforts for cybersecurity engineering. T he UNECE also demands the\neffectiveness of these engineering to be verified and validated through\ntesting. T his requires both a significantly higher rate and more\ncomprehensiveness of cybersecurity testing that is not effectively to cope with\nusing current, predominantly manual, automotive cybersecurity testing\ntechniques. To allow for comprehensive and efficient testing at all stages of\nthe automotive life cycle, including supply chain parts not at band, and to\nfacilitate efficient third party testing, as well as to test under real-world\nconditions, also methodologies for testing the cybersecurity of vehicular\nsystems as a black box are necessary. T his paper therefore presents a model\nand attack tree-based approach to (semi-)automate automotive cybersecurity\ntesting, as well as considerations for automatically black box-deriving models\nfor the use in attack modeling.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 12:23:18 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Marksteiner", "Stefan", ""], ["Priller", "Peter", ""]]}, {"id": "2107.06049", "submitter": "Xian Zhang", "authors": "Xian Zhang, Xiaobing Guo, Zixuan Zeng, Wenyan Liu, Zhongxin Guo, Yang\n  Chen, Shuo Chen, Qiufeng Yin, Mao Yang, Lidong Zhou", "title": "Argus: A Fully Transparent Incentive System for Anti-Piracy Campaigns\n  (Extended Version)", "comments": "To appear in SRDS 2021. This is an extended version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anti-piracy is fundamentally a procedure that relies on collecting data from\nthe open anonymous population, so how to incentivize credible reporting is a\nquestion at the center of the problem. Industrial alliances and companies are\nrunning anti-piracy incentive campaigns, but their effectiveness is publicly\nquestioned due to the lack of transparency. We believe that full transparency\nof a campaign is necessary to truly incentivize people. It means that every\nrole, e.g., content owner, licensee of the content, or every person in the open\npopulation, can understand the mechanism and be assured about its execution\nwithout trusting any single role.\n  We see this as a distributed system problem. In this paper, we present Argus,\na fully transparent incentive system for anti-piracy campaigns. The groundwork\nof Argus is to formulate the objectives for fully transparent incentive\nmechanisms, which securely and comprehensively consolidate the different\ninterests of all roles. These objectives form the core of the Argus design,\nhighlighted by our innovations about a Sybil-proof incentive function, a\ncommit-and-reveal scheme, and an oblivious transfer scheme. In the\nimplementation, we overcome a set of unavoidable obstacles to ensure security\ndespite full transparency. Moreover, we effectively optimize several\ncryptographic operations so that the cost for a piracy reporting is reduced to\nan equivalent cost of sending about 14 ETH-transfer transactions to run on the\npublic Ethereum network, which would otherwise correspond to thousands of\ntransactions. With the security and practicality of Argus, we hope real-world\nanti-piracy campaigns will be truly effective by shifting to a fully\ntransparent incentive mechanism.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 13:00:00 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Zhang", "Xian", ""], ["Guo", "Xiaobing", ""], ["Zeng", "Zixuan", ""], ["Liu", "Wenyan", ""], ["Guo", "Zhongxin", ""], ["Chen", "Yang", ""], ["Chen", "Shuo", ""], ["Yin", "Qiufeng", ""], ["Yang", "Mao", ""], ["Zhou", "Lidong", ""]]}, {"id": "2107.06090", "submitter": "Itzel Vazquez Sandoval", "authors": "Itzel Vazquez Sandoval, Arash Atashpendar, Gabriele Lenzini and Peter\n  Y.A. Ryan", "title": "PakeMail: authentication and key management in decentralized secure\n  email and messaging via PAKE", "comments": "arXiv admin note: substantial text overlap with arXiv:2005.10787", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the use of PAKE for achieving and enhancing entity authentication\n(EA) and key management (KM) in the context of decentralized end-to-end\nencrypted email and secure messaging, i.e., where neither a public key\ninfrastructure nor trusted third parties are used. This approach not only\nsimplifies the EA process by requiring users to share only a low-entropy\nsecret, e.g., a memorable word, but it also allows us to establish a\nhigh-entropy secret key; this key enables a series of cryptographic\nenhancements and security properties, which are hard to achieve using\nout-of-band (OOB) authentication. We first study a few vulnerabilities in\nvoice-based OOB authentication, in particular a combinatorial attack against\nlazy users, which we analyze in the context of a secure email solution. We then\npropose tackling public key authentication by solving the problem of \"secure\nequality test\" using PAKE, and discuss various protocols and their properties.\nThis method enables the automation of important KM tasks (e.g. key renewal and\nfuture key pair authentications), reduces the impact of human errors, and lends\nitself to the asynchronous nature of email and modern messaging. It also\nprovides cryptographic enhancements including multi-device synchronization and\nsecure secret storage/retrieval, and paves the path for forward secrecy,\ndeniability and post-quantum security. We also discuss the use of auditable\nPAKEs for mitigating a class of online guess and abort attacks in\nauthentication protocols. To demonstrate the feasibility of our proposal, we\npresent PakeMail, an implementation of the core idea, and discuss some of its\ncryptographic details, implemented features and efficiency aspects. We conclude\nwith some design and security considerations, followed by future lines of work.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 13:46:33 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Sandoval", "Itzel Vazquez", ""], ["Atashpendar", "Arash", ""], ["Lenzini", "Gabriele", ""], ["Ryan", "Peter Y. A.", ""]]}, {"id": "2107.06100", "submitter": "Omer Aydin", "authors": "Omer Aydin", "title": "Secure Charging and Payment System for Electric Land Vehicles with\n  Authentication Protocol", "comments": "in Turkish language. 4th INTERNATIONAL CONGRESS ON ECONOMICS FINANCE\n  AND ENERGY (2020). Electric land vehicle, Authentication protocol,\n  Encryption, Security, Payment system, Charging system", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  It is obvious that fossil fuels are a limited resource and will be replaced\nby other energy sources in the future considering economic and en-vironmental\nproblems. Electricity comes to the forefront among the sources that are\ncandidates to replace fossil fuels. In the near future, electric land, air and\nsea vehicles will start to take more place in daily life. For this reason,\nsystems for the charging systems of these devices and post-charge payments have\nbeen developed. There is no general standard on this issue yet. In this study,\na charge and payment system, which is safe against known cyber-attacks for use\nin electric land ve-hicles, and which prioritizes privacy, is proposed. A\nsystem has been proposed to verify each other wired or wirelessly with an\nauthentication protocol, where the data communication is encrypted, and the\npayment transactions are performed securely and invoiced to the vehicle owners.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 21:49:18 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Aydin", "Omer", ""]]}, {"id": "2107.06119", "submitter": "Jeroen van Wier", "authors": "Jeroen van Wier", "title": "On SDVS Sender Privacy In The Multi-Party Setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strong designated verifier signature schemes rely on sender-privacy to hide\nthe identity of the creator of a signature to all but the intended recipient.\nThis property can be invaluable in, for example, the context of deniability,\nwhere the identity of a party should not be deducible from the communication\nsent during a protocol execution. In this work, we explore the technical\ndefinition of sender-privacy and extend it from a 2-party setting to an n-party\nsetting. Afterwards, we show in which cases this extension provides a stronger\nsecurity and in which cases it does not.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 14:20:15 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["van Wier", "Jeroen", ""]]}, {"id": "2107.06183", "submitter": "Kaiyuan Yang", "authors": "Dai Li, Kaiyuan Yang", "title": "A Self-Regulated and Reconfigurable CMOS Physically Unclonable Function\n  Featuring Zero-Overhead Stabilization", "comments": "This work has been accepted by 2020 IEEE Journal of Solid-State\n  Circuits (JSSC)", "journal-ref": "IEEE Journal of Solid-State Circuits (JSSC), Volume: 55, Issue: 1,\n  Pages: 98-107, Jan. 2020", "doi": "10.1109/JSSC.2019.2938133", "report-no": null, "categories": "eess.SP cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a reconfigurable physically unclonable function (PUF)\ndesign fabricated using 65-nm CMOS technology. A subthreshold-inverter-based\nstatic PUF cell achieves 0.3% native bit error rate (BER) at 0.062-fJ per bit\ncore energy efficiency. A flexible, native transistor-based voltage regulation\nscheme achieves low-overhead supply regulation with 6-mV/V line sensitivity,\nmaking the PUF resistant against voltage variations. Additionally, the PUF cell\nis designed to be reconfigurable with no area overhead, which enables\nstabilization without redundancy on chip. Thanks to the highly stable and\nself-regulated PUF cell and the zero-overhead stabilization scheme, a 0.00182%\nnative BER is obtained after reconfiguration. The proposed design shows\n0.12%/10 {\\deg}C and 0.057%/0.1-V bit error across the military-grade\ntemperature range from -55 {\\deg}C to 125 {\\deg}C and supply voltage variation\nfrom 0.7 to 1.4 V. The total energy per bit is 15.3 fJ. Furthermore, the\nunstable bits can be detected by sweeping the body bias instead of temperature\nduring enrollment, thereby significantly reducing the testing costs. Last but\nnot least, the prototype exhibits almost ideal uniqueness and randomness, with\na mean inter-die Hamming distance (HD) of 0.4998 and a 1020x inter-/intra-die\nHD separation. It also passes both NIST 800-22 and 800-90B randomness tests.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 03:10:07 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Li", "Dai", ""], ["Yang", "Kaiyuan", ""]]}, {"id": "2107.06242", "submitter": "Laurent Schmalen", "authors": "Kadir G\\\"um\\\"us and Laurent Schmalen", "title": "Low Rate Protograph-Based LDPC Codes for Continuous Variable Quantum Key\n  Distribution", "comments": "Accepted for publication at ISWCS 2021 (Special session on coding for\n  communications and security)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Error correction plays a major role in the reconciliation of continuous\nvariable quantum key distribution (CV-QKD) and greatly affects the performance\nof the system. CV-QKD requires error correction codes of extremely low rates\nand high reconciliation efficiencies. There are only very few code designs\navailable in this ultra low rate regime. In this paper, we introduce a method\nfor designing protograph-based ultra low rate LDPC codes using differential\nevolution. By proposing type-based protographs, a new way of representing low\nrate protograph-based LDPC codes, we drastically reduce the complexity of the\nprotograph optimization, which enables us to quickly design codes over a wide\nrange of rates. We show that the codes resulting from our optimization\noutperform the codes from the literature both in regards to the threshold and\nin finite-length performance, validated by Monte-Carlo simulations, showing\ngains in the regime relevant for CV-QKD.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 17:02:02 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["G\u00fcm\u00fcs", "Kadir", ""], ["Schmalen", "Laurent", ""]]}, {"id": "2107.06372", "submitter": "Vafa Andalibi", "authors": "Vafa Andalibi, Eliot Lear, DongInn Kim, L. Jean Camp", "title": "On the Analysis of MUD-Files' Interactions, Conflicts, and Configuration\n  Requirements Before Deployment", "comments": "22 pages, 6 figures, 3 algorithms, To be published in 5th EAI\n  International Conference on Safety and Security in Internet of Things\n  (SaSeIoT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Manufacturer Usage Description (MUD) is an Internet Engineering Task Force\n(IETF) standard designed to protect IoT devices and networks by creating an\nout-of-the-box access control list for an IoT device. %The protocol defines a\nconceptually straightforward method to implement an isolation-based defensive\nmechanism based on the rules that are introduced by the manufacturer of the\ndevice. However, in practice, the access control list of each device is defined\nin its MUD-File and may contain possibly hundreds of access control rules. As a\nresult, reading and validating these files is a challenge; and determining how\nmultiple IoT devices interact is difficult for the developer and infeasible for\nthe consumer. To address this we introduce the MUD-Visualizer to provide a\nvisualization of any number of MUD-Files. MUD-Visualizer is designed to enable\ndevelopers to produce correct MUD-Files by providing format correction,\nintegrating them with other MUD-Files, and identifying conflicts through\nvisualization. MUD-Visualizer is scalable and its core task is to merge and\nillustrate ACEs for multiple devices; both within and beyond the local area\nnetwork. MUD-Visualizer is made publicly available and can be found on GitHub.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 20:16:55 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Andalibi", "Vafa", ""], ["Lear", "Eliot", ""], ["Kim", "DongInn", ""], ["Camp", "L. Jean", ""]]}, {"id": "2107.06415", "submitter": "Elias Heftrig", "authors": "Lukas Baumann, Elias Heftrig, Haya Shulman and Michael Waidner", "title": "The Master and Parasite Attack", "comments": "The paper has been accepted for publication at the 51st Annual\n  IEEE/IFIP International Conference on Dependable Systems and Networks (DSN\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore a new type of malicious script attacks: the persistent parasite\nattack. Persistent parasites are stealthy scripts, which persist for a long\ntime in the browser's cache. We show to infect the caches of victims with\nparasite scripts via TCP injection.\n  Once the cache is infected, we implement methodologies for propagation of the\nparasites to other popular domains on the victim client as well as to other\ncaches on the network. We show how to design the parasites so that they stay\nlong time in the victim's cache not restricted to the duration of the user's\nvisit to the web site. We develop covert channels for communication between the\nattacker and the parasites, which allows the attacker to control which scripts\nare executed and when, and to exfiltrate private information to the attacker,\nsuch as cookies and passwords. We then demonstrate how to leverage the\nparasites to perform sophisticated attacks, and evaluate the attacks against a\nrange of applications and security mechanisms on popular browsers. Finally we\nprovide recommendations for countermeasures.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 22:13:05 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Baumann", "Lukas", ""], ["Heftrig", "Elias", ""], ["Shulman", "Haya", ""], ["Waidner", "Michael", ""]]}, {"id": "2107.06578", "submitter": "Stephan Fahrenkrog-Petersen", "authors": "Fabian R\\\"osel, Stephan A. Fahrenkrog-Petersen, Han van der Aa,\n  Matthias Weidlich", "title": "A Distance Measure for Privacy-preserving Process Mining based on\n  Feature Learning", "comments": "Accepted for 17th International Workshop on Business Process\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To enable process analysis based on an event log without compromising the\nprivacy of individuals involved in process execution, a log may be anonymized.\nSuch anonymization strives to transform a log so that it satisfies provable\nprivacy guarantees, while largely maintaining its utility for process analysis.\nExisting techniques perform anonymization using simple, syntactic measures to\nidentify suitable transformation operations. This way, the semantics of the\nactivities referenced by the events in a trace are neglected, potentially\nleading to transformations in which events of unrelated activities are merged.\nTo avoid this and incorporate the semantics of activities during anonymization,\nwe propose to instead incorporate a distance measure based on feature learning.\nSpecifically, we show how embeddings of events enable the definition of a\ndistance measure for traces to guide event log anonymization. Our experiments\nwith real-world data indicate that anonymization using this measure, compared\nto a syntactic one, yields logs that are closer to the original log in various\ndimensions and, hence, have higher utility for process analysis.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 09:44:28 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["R\u00f6sel", "Fabian", ""], ["Fahrenkrog-Petersen", "Stephan A.", ""], ["van der Aa", "Han", ""], ["Weidlich", "Matthias", ""]]}, {"id": "2107.06590", "submitter": "Saskia Nu\\~nez von Voigt", "authors": "S. Nu\\~nez von Voigt, E. Daniel and F. Tschorsch", "title": "Self-Determined Reciprocal Recommender System with Strong Privacy\n  Guarantees", "comments": "Accepted at The 16th International Conference on Availability,\n  Reliability and Security (ARES 2021)", "journal-ref": null, "doi": "10.1145/3465481.3465769", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems are widely used. Usually, recommender systems are based\non a centralized client-server architecture. However, this approach implies\ndrawbacks regarding the privacy of users. In this paper, we propose a\ndistributed reciprocal recommender system with strong, self-determined privacy\nguarantees, i.e., local differential privacy. More precisely, users randomize\ntheir profiles locally and exchange them via a peer-to-peer network.\nRecommendations are then computed and ranked locally by estimating similarities\nbetween profiles. We evaluate recommendation accuracy of a job recommender\nsystem and demonstrate that our method provides acceptable utility under strong\nprivacy requirements.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 10:25:53 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["von Voigt", "S. Nu\u00f1ez", ""], ["Daniel", "E.", ""], ["Tschorsch", "F.", ""]]}, {"id": "2107.06662", "submitter": "Zhang Xiaohui", "authors": "Zhang Xiaohui, Miao Xianghua", "title": "A Reputation-based Approach using Consortium Blockchain for Cyber Threat\n  Intelligence Sharing", "comments": "16 pages,8 figures and 8 tables,submitted to journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The CTI (Cyber Threat Intelligence) sharing and exchange is an effective\nmethod to improve the responsiveness of the protection party. Blockchain\ntechnology enables sharing collaboration consortium to conduct a trusted CTI\nsharing and exchange without a trusted centralized institution. However, the\ndistributed connectivity of the blockchain-based CTI sharing model proposed\nbefore exposes the systems into byzantine attacks, the compromised members of\npartner organizations will further decrease the accuracy and trust level of CTI\nby generating false reporting. To address the unbalance issues of performance\nin speed, scalability and security, this paper proposes a new blockchain-based\nCTI model, which combines consortium blockchain and distributed reputation\nmanagement systems to achieve automated analysis and response of tactical\nthreat intelligence. In addition, the novel consensus algorithm of consortium\nblockchain that is fit for CTI sharing and exchange introduced in this paper.\nThe new consensus algorithm is called 'Proof-of Reputation' (PoR) consensus,\nwhich meets the requirements of transaction rate and makes the consensus in a\ncreditable network environment through constructing a reputation model.\nFinally, the effectiveness and security performance of the proposed model and\nconsensus algorithm is verified by experiments.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 14:47:57 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Xiaohui", "Zhang", ""], ["Xianghua", "Miao", ""]]}, {"id": "2107.06732", "submitter": "Andrea Pinna", "authors": "Fabio Caddeo and Andrea Pinna", "title": "Opportunities and challenges of Blockchain-Oriented systems in the\n  tourism industry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tourism industry is increasingly influenced by the evolution of\ninformation and communication technologies (ICT), which are revolutionizing the\nway people travel. In this work we want to nvestigate the use of innovative IT\ntechnologies by DMOs (Destination Management Organizations), focusing on\nblockchain technology, both from the point of view of research in the field,\nand in the study of the most relevant software projects. In particular, we\nintend to verify the benefits offered by these IT tools in the management and\nmonitoring of a destination, without forgetting the implications for the other\nstakeholders involved. These technologies, in fact, can offer a wide range of\nservices that can be useful throughout the life cycle of the destination.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 23:22:03 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Caddeo", "Fabio", ""], ["Pinna", "Andrea", ""]]}, {"id": "2107.06790", "submitter": "Mirko Zichichi", "authors": "Mirko Zichichi, Luca Serena, Stefano Ferretti, Gabriele D'Angelo", "title": "Governing Decentralized Complex Queries Through a DAO", "comments": "To appear in the ACM International Conference on Information\n  Technology for Social Good (GoodIT 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.NI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a new generation of P2P systems capable of addressing data\nintegrity and authenticity has emerged for the development of new applications\nfor a \"more\" decentralized Internet, i.e., Distributed Ledger Technologies\n(DLT) and Decentralized File Systems (DFS). However, these technologies still\nhave some unanswered issues, mostly related to data lookup and discovery. In\nthis paper, first, we propose a Distributed Hash Table (DHT) system that\nefficiently manages decentralized keyword-based queries executed on data stored\nin DFS. Through a hypercube logical layout, queries are efficiently routed\namong the network, where each node is responsible for a specific keywords set\nand the related contents. Second, we provide a framework for the governance of\nthe above network, based on a Decentralized Autonomous Organization (DAO)\nimplementation. We show how the use of smart contracts enables organizational\ndecision making and rewards for nodes that have actively contributed to the\nDHT. Finally, we provide experimental validation of an implementation of our\nproposal, where the execution of the same protocol for different logical nodes\nof the hypercube allows us to evaluate the efficiency of communication within\nthe network.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 15:46:01 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Zichichi", "Mirko", ""], ["Serena", "Luca", ""], ["Ferretti", "Stefano", ""], ["D'Angelo", "Gabriele", ""]]}, {"id": "2107.06833", "submitter": "Tarik A. Rashid", "authors": "Ravi Teja Batchu, Abeer Alsadoon, P.W.C. Prasad, Rasha S. Ali, Tarik\n  A. Rashid, Ghossoon Alsadoon, Oday D. Jerew", "title": "A Review-based Taxonomy for Secure Health Care Monitoring: Wireless\n  Smart Cameras", "comments": "29 pages", "journal-ref": "Journal of Applied Security Research, 2021", "doi": "10.1080/19361610.2021.1947112", "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Health records data security is one of the main challenges in e-health\nsystems. Authentication is one of the essential security services to support\nthe stored data confidentiality, integrity, and availability. This research\nfocuses on the secure storage of patient and medical records in the healthcare\nsector where data security and unauthorized access is an ongoing issue. A\npotential solution comes from biometrics, although their use may be\ntime-consuming and can slow down data retrieval. This research aims to overcome\nthese challenges and enhance data access control in the healthcare sector\nthrough the addition of biometrics in the form of fingerprints. The proposed\nmodel for application in the healthcare sector consists of Collection, Network\ncommunication, and Authentication (CNA) using biometrics, which replaces an\nexisting password-based access control method. A sensor then collects data and\nby using a network (wireless or Zig-bee), a connection is established, after\nconnectivity analytics and data management work which processes and aggregate\nthe data. Subsequently, access is granted to authenticated users of the\napplication. This IoT-based biometric authentication system facilitates\neffective recognition and ensures confidentiality, integrity, and reliability\nof patients, records and other sensitive data. The proposed solution provides\nreliable access to healthcare data and enables secure access through the\nprocess of user and device authentication. The proposed model has been\ndeveloped for access control to data through the authentication of users in\nhealthcare to reduce data manipulation or theft.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 11:59:10 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Batchu", "Ravi Teja", ""], ["Alsadoon", "Abeer", ""], ["Prasad", "P. W. C.", ""], ["Ali", "Rasha S.", ""], ["Rashid", "Tarik A.", ""], ["Alsadoon", "Ghossoon", ""], ["Jerew", "Oday D.", ""]]}, {"id": "2107.06849", "submitter": "Maroof Mushtaq", "authors": "Keenu Chandra, Maroof Mushtaq, Nalini N", "title": "Digital Passport and Visa Asset Management Using Private and\n  Permissioned Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Blockchain is currently one of the fastest-growing technologies in the field\nof Computer Science. It has found a prevalent use in financial applications\nlike cryptocurrency, for example, Bitcoin and Ethereum. They have been able to\nbring an unforeseen disruption in the field of finance. However, permissionless\nBlockchains like these have some downsides, namely the computation cost of the\nProof of Work algorithm, maximum allowed size for a block, decrease in\nintelligibility with the increase of the number of blocks in the chain,\ndomination of nodes with higher computing power as miners and validators. These\nfactors have restricted the adoption of permissionless blockchain technology\noutside the field of finance, such as in medical or legal fields. This paper\nproposes a solution to these problems using a permissioned blockchain. It does\nnot require a computationally expensive consensus mechanism as permissioned\nchains call for trust between participating organizations which is achieved via\nexclusive invitations. We have utilized a third-party orderer to maintain the\ntrust between organizations.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 17:03:55 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 17:57:42 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Chandra", "Keenu", ""], ["Mushtaq", "Maroof", ""], ["N", "Nalini", ""]]}, {"id": "2107.06922", "submitter": "Yacov Manevich", "authors": "Artem Barger, Yacov Manevich, Hagar Meir, Yoav Tock", "title": "A Byzantine Fault-Tolerant Consensus Library for Hyperledger Fabric", "comments": "IEEE International Conference on Blockchain and Cryptocurrency,\n  https://icbc2021.ieee-icbc.org/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hyperledger Fabric is an enterprise grade permissioned distributed ledger\nplatform that offers modularity for a broad set of industry use cases. One\nmodular component is a pluggable ordering service that establishes consensus on\nthe order of transactions and batches them into blocks. However, as of the time\nof this writing, there is no production grade Byzantine Fault-Tolerant (BFT)\nordering service for Fabric, with the latest version (v2.1) supporting only\nCrash Fault-Tolerance (CFT). In our work, we address crucial aspects of BFT\nintegration into Fabric that were left unsolved in all prior works, making them\nunfit for production use. In this work we describe the design and\nimplementation of a BFT ordering service for Fabric, employing a new BFT\nconsensus library. The new library, based on the BFT-Smart protocol and written\nin Go, is tailored to the blockchain use-case, yet is general enough to cater\nto a wide variety of other uses. We evaluate the new BFT ordering service by\ncomparing it with the currently supported Raft-based CFT ordering service in\nHyperledger Fabric.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 18:14:01 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Barger", "Artem", ""], ["Manevich", "Yacov", ""], ["Meir", "Hagar", ""], ["Tock", "Yoav", ""]]}, {"id": "2107.06944", "submitter": "Carlos Pinz'on", "authors": "Carlos Pinz\\'on, Catuscia Palamidessi, Pablo Piantanida, Frank\n  Valencia", "title": "On the impossibility of non-trivial accuracy under fairness constraints", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the main concerns about fairness in machine learning (ML) is that, in\norder to achieve it, one may have to renounce to some accuracy. Having this\ntrade-off in mind, Hardt et al. have proposed the notion of equal opportunities\n(EO), designed so as to be compatible with accuracy. In fact, it can be shown\nthat if the source of input data is deterministic, the two notions go well\nalong with each other. In the probabilistic case, however, things change.\n  As we show, there are probabilistic data sources for which EO can only be\nachieved at the total detriment of accuracy, i.e. among the models that achieve\nEO, those whose prediction does not depend on the input have the highest\naccuracy.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 19:15:50 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Pinz\u00f3n", "Carlos", ""], ["Palamidessi", "Catuscia", ""], ["Piantanida", "Pablo", ""], ["Valencia", "Frank", ""]]}, {"id": "2107.06946", "submitter": "Rakshit Naidu", "authors": "Rakshit Naidu, Harshita Diddee, Ajinkya Mulay, Aleti Vardhan, Krithika\n  Ramesh, Ahmed Zamzam", "title": "Towards Quantifying the Carbon Emissions of Differentially Private\n  Machine Learning", "comments": "4+3 pages; 6 figures; 8 tables. Accepted at SRML workshop at ICML'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, machine learning techniques utilizing large-scale datasets\nhave achieved remarkable performance. Differential privacy, by means of adding\nnoise, provides strong privacy guarantees for such learning algorithms. The\ncost of differential privacy is often a reduced model accuracy and a lowered\nconvergence speed. This paper investigates the impact of differential privacy\non learning algorithms in terms of their carbon footprint due to either longer\nrun-times or failed experiments. Through extensive experiments, further\nguidance is provided on choosing the noise levels which can strike a balance\nbetween desired privacy levels and reduced carbon emissions.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 19:25:25 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Naidu", "Rakshit", ""], ["Diddee", "Harshita", ""], ["Mulay", "Ajinkya", ""], ["Vardhan", "Aleti", ""], ["Ramesh", "Krithika", ""], ["Zamzam", "Ahmed", ""]]}, {"id": "2107.07043", "submitter": "Zuohui Chen", "authors": "Zuohui Chen, Renxuan Wang, Jingyang Xiang, Yue Yu, Xin Xia, Shouling\n  Ji, Qi Xuan, and Xiaoniu Yang", "title": "GGT: Graph-Guided Testing for Adversarial Sample Detection of Deep\n  Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNN) are known to be vulnerable to adversarial samples,\nthe detection of which is crucial for the wide application of these DNN models.\nRecently, a number of deep testing methods in software engineering were\nproposed to find the vulnerability of DNN systems, and one of them, i.e., Model\nMutation Testing (MMT), was used to successfully detect various adversarial\nsamples generated by different kinds of adversarial attacks. However, the\nmutated models in MMT are always huge in number (e.g., over 100 models) and\nlack diversity (e.g., can be easily circumvented by high-confidence adversarial\nsamples), which makes it less efficient in real applications and less effective\nin detecting high-confidence adversarial samples. In this study, we propose\nGraph-Guided Testing (GGT) for adversarial sample detection to overcome these\naforementioned challenges. GGT generates pruned models with the guide of graph\ncharacteristics, each of them has only about 5% parameters of the mutated model\nin MMT, and graph guided models have higher diversity. The experiments on\nCIFAR10 and SVHN validate that GGT performs much better than MMT with respect\nto both effectiveness and efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 12:12:36 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Chen", "Zuohui", ""], ["Wang", "Renxuan", ""], ["Xiang", "Jingyang", ""], ["Yu", "Yue", ""], ["Xia", "Xin", ""], ["Ji", "Shouling", ""], ["Xuan", "Qi", ""], ["Yang", "Xiaoniu", ""]]}, {"id": "2107.07060", "submitter": "Mohammed Bahutair Mr.", "authors": "Mohammed Bahutair, and Athman Bouguettaya", "title": "Blockchain-based Trust Information Storage in Crowdsourced IoT Services", "comments": "10 pages, Accepted and to appear in 2021 IEEE International\n  Conference on Web Services (ICWS). Content may change prior to final\n  publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel distributed integrity-preserving framework for storing\ntrust information in crowdsourced IoT environments. The integrity and\navailability of the trust information is paramount to ensure accurate trust\nassessment. Our proposed framework leverages the blockchain to build a\ndistributed storage medium for trust-related information that ensures its\nintegrity. We propose a geo-scoping approach, which ensures that trust-related\ninformation is only available where needed, thus, enabling fast access and\nstorage space preservation. We conduct several experiments using real datasets\nto highlight the effectiveness of our framework.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 01:02:29 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Bahutair", "Mohammed", ""], ["Bouguettaya", "Athman", ""]]}, {"id": "2107.07063", "submitter": "I Wayan Budi  Sentana", "authors": "I Wayan Budi Sentana, Muhammad Ikram, Mohamed Ali Kaafar", "title": "BlockJack: Towards Improved Prevention of IP Prefix Hijacking Attacks in\n  Inter-Domain Routing Via Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose BlockJack, a system based on a distributed and tamper-proof\nconsortium Blockchain that aims at blocking IP prefix hijacking in the Border\nGateway Protocol (BGP). In essence, BlockJack provides synchronization among\nBlockChain and BGP network through interfaces ensuring operational independence\nand this approach preserving the legacy system and accommodates the impact of a\nrace condition if the Blockchain process exceeds the BGP update interval.\nBlockJack is also resilient to dynamic routing path changes during the\noccurrence of the IP prefix hijacking in the routing tables. We implement\nBlockJack using Hyperledger Fabric Blockchain and Quagga software package and\nwe perform initial sets of experiments to evaluate its efficacy. We evaluate\nthe performance and resilience of BlockJack in various attack scenarios\nincluding single path attacks, multiple path attacks, and attacks from random\nsources in the random network topology. The Evaluation results show that\nBlockJack is able to handle multiple attacks caused by AS paths changes during\na BGP prefix hijacking. In experiment settings with 50 random routers,\nBlockJack takes on average 0.08 seconds (with a standard deviation of 0.04\nseconds) to block BGP prefix hijacking attacks. The test result showing that\nBlockJack conservative approach feasible to handle the IP Prefix hijacking in\nthe Border Gateway Protocol.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 01:11:56 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Sentana", "I Wayan Budi", ""], ["Ikram", "Muhammad", ""], ["Kaafar", "Mohamed Ali", ""]]}, {"id": "2107.07065", "submitter": "Amit Seal Ami", "authors": "Amit Seal Ami, Nathan Cooper, Kaushal Kafle, Kevin Moran, Denys\n  Poshyvanyk, Adwait Nadkarni", "title": "Why Crypto-detectors Fail: A Systematic Evaluation of Cryptographic\n  Misuse Detection Techniques", "comments": "18 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The correct use of cryptography is central to ensuring data security in\nmodern software systems. Hence, several academic and commercial static analysis\ntools have been developed for detecting and mitigating crypto-API misuse. While\ndevelopers are optimistically adopting these crypto-API misuse detectors (or\ncrypto-detectors) in their software development cycles, this momentum must be\naccompanied by a rigorous understanding of their effectiveness at finding\ncrypto-API misuse in practice. This paper presents the MASC framework, which\nenables a systematic and data-driven evaluation of crypto-detectors using\nmutation testing. We ground MASC in a comprehensive view of the problem space\nby developing a data-driven taxonomy of existing crypto-API misuse, containing\n$105$ misuse cases organized among nine semantic clusters. We develop $12$\ngeneralizable usage-based mutation operators and three mutation scopes that can\nexpressively instantiate thousands of compilable variants of the misuse cases\nfor thoroughly evaluating crypto-detectors. Using MASC, we evaluate nine major\ncrypto-detectors and discover $19$ unique, undocumented flaws that severely\nimpact the ability of crypto-detectors to discover misuses in practice. We\nconclude with a discussion on the diverse perspectives that influence the\ndesign of crypto-detectors and future directions towards building\nsecurity-focused crypto-detectors by design.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 01:16:27 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 20:23:24 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Ami", "Amit Seal", ""], ["Cooper", "Nathan", ""], ["Kafle", "Kaushal", ""], ["Moran", "Kevin", ""], ["Poshyvanyk", "Denys", ""], ["Nadkarni", "Adwait", ""]]}, {"id": "2107.07223", "submitter": "Candy Olivia Mawalim", "authors": "Candy Olivia Mawalim and Masashi Unoki", "title": "Improving Security in McAdams Coefficient-Based Speaker Anonymization by\n  Watermarking Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Speaker anonymization aims to suppress speaker individuality to protect\nprivacy in speech while preserving the other aspects, such as speech content.\nOne effective solution for anonymization is to modify the McAdams coefficient.\nIn this work, we propose a method to improve the security for speaker\nanonymization based on the McAdams coefficient by using a speech watermarking\napproach. The proposed method consists of two main processes: one for embedding\nand one for detection. In embedding process, two different McAdams coefficients\nrepresent binary bits ``0\" and ``1\". The watermarked speech is then obtained by\nframe-by-frame bit inverse switching. Subsequently, the detection process is\ncarried out by a power spectrum comparison. We conducted objective evaluations\nwith reference to the VoicePrivacy 2020 Challenge (VP2020) and of the speech\nwatermarking with reference to the Information Hiding Challenge (IHC) and found\nthat our method could satisfy the blind detection, inaudibility, and robustness\nrequirements in watermarking. It also significantly improved the anonymization\nperformance in comparison to the secondary baseline system in VP2020.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 09:56:08 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Mawalim", "Candy Olivia", ""], ["Unoki", "Masashi", ""]]}, {"id": "2107.07240", "submitter": "Xiangyu Qi", "authors": "Xiangyu Qi, Jifeng Zhu, Chulin Xie, Yong Yang", "title": "Subnet Replacement: Deployment-stage backdoor attack against deep neural\n  networks in gray-box setting", "comments": "6 pages, 3 figures, ICLR 2021 Workshop on Security and Safety in\n  Machine Learning System", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the realistic potential of conducting backdoor attack against deep\nneural networks (DNNs) during deployment stage. Specifically, our goal is to\ndesign a deployment-stage backdoor attack algorithm that is both threatening\nand realistically implementable. To this end, we propose Subnet Replacement\nAttack (SRA), which is capable of embedding backdoor into DNNs by directly\nmodifying a limited number of model parameters. Considering the realistic\npracticability, we abandon the strong white-box assumption widely adopted in\nexisting studies, instead, our algorithm works in a gray-box setting, where\narchitecture information of the victim model is available but the adversaries\ndo not have any knowledge of parameter values. The key philosophy underlying\nour approach is -- given any neural network instance (regardless of its\nspecific parameter values) of a certain architecture, we can always embed a\nbackdoor into that model instance, by replacing a very narrow subnet of a\nbenign model (without backdoor) with a malicious backdoor subnet, which is\ndesigned to be sensitive (fire large activation value) to a particular backdoor\ntrigger pattern.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 10:47:13 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Qi", "Xiangyu", ""], ["Zhu", "Jifeng", ""], ["Xie", "Chulin", ""], ["Yang", "Yong", ""]]}, {"id": "2107.07297", "submitter": "Alberto Sonnino", "authors": "Micha{\\l} Kr\\'ol, Onur Ascigil, Sergi Rene, Alberto Sonnino, Mustafa\n  Al-Bassam, Etienne Rivi\\`ere", "title": "Shard Scheduler: object placement and migration in sharded account-based\n  blockchains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose Shard Scheduler, a system for object placement and migration in\naccount-based sharded blockchains. Our system calculates optimal placement and\ndecides of object migrations across shards and supports complex multi-account\ntransactions caused by smart contracts. Placement and migration decisions made\nby Shard Scheduler are fully deterministic, verifiable, and can be made part of\nthe consensus protocol. Shard Scheduler reduces the number of costly\ncross-shard transactions, ensures balanced load distribution and maximizes the\nnumber of processed transactions for the blockchain as a whole. It leverages a\nnovel incentive model motivating miners to maximize the global throughput of\nthe entire blockchain rather than the throughput of a specific shard. Shard\nScheduler reduces the number of costly cross-shard transactions by half in our\nsimulations, ensuring equal load and increasing the throughput 3 fold when\nusing 60 shards. We also implement and evaluate Shard Scheduler on Chainspace,\nmore than doubling its throughput and reducing user-perceived latency by 70%\nwhen using 10 shards.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 13:03:36 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Kr\u00f3l", "Micha\u0142", ""], ["Ascigil", "Onur", ""], ["Rene", "Sergi", ""], ["Sonnino", "Alberto", ""], ["Al-Bassam", "Mustafa", ""], ["Rivi\u00e8re", "Etienne", ""]]}, {"id": "2107.07334", "submitter": "L\\^e Nguy\\^en Hoang", "authors": "L\\^e-Nguy\\^en Hoang, Louis Faucon, Aidan Jungo, Sergei Volodin, Dalia\n  Papuc, Orfeas Liossatos, Ben Crulis, Mariame Tighanimine, Isabela Constantin,\n  Anastasiia Kucherenko, Alexandre Maurer, Felix Grimberg, Vlad Nitu, Chris\n  Vossen, S\\'ebastien Rouault and El-Mahdi El-Mhamdi", "title": "Tournesol: A quest for a large, secure and trustworthy database of\n  reliable human judgments", "comments": "27 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Today's large-scale algorithms have become immensely influential, as they\nrecommend and moderate the content that billions of humans are exposed to on a\ndaily basis. They are the de-facto regulators of our societies' information\ndiet, from shaping opinions on public health to organizing groups for social\nmovements. This creates serious concerns, but also great opportunities to\npromote quality information. Addressing the concerns and seizing the\nopportunities is a challenging, enormous and fabulous endeavor, as intuitively\nappealing ideas often come with unwanted {\\it side effects}, and as it requires\nus to think about what we deeply prefer.\n  Understanding how today's large-scale algorithms are built is critical to\ndetermine what interventions will be most effective. Given that these\nalgorithms rely heavily on {\\it machine learning}, we make the following key\nobservation: \\emph{any algorithm trained on uncontrolled data must not be\ntrusted}. Indeed, a malicious entity could take control over the data, poison\nit with dangerously manipulative fabricated inputs, and thereby make the\ntrained algorithm extremely unsafe. We thus argue that the first step towards\nsafe and ethical large-scale algorithms must be the collection of a large,\nsecure and trustworthy dataset of reliable human judgments.\n  To achieve this, we introduce \\emph{Tournesol}, an open source platform\navailable at \\url{https://tournesol.app}. Tournesol aims to collect a large\ndatabase of human judgments on what algorithms ought to widely recommend (and\nwhat they ought to stop widely recommending). We outline the structure of the\nTournesol database, the key features of the Tournesol platform and the main\nhurdles that must be overcome to make it a successful project. Most\nimportantly, we argue that, if successful, Tournesol may then serve as the\nessential foundation for any safe and ethical large-scale algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 19:21:35 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Hoang", "L\u00ea-Nguy\u00ean", ""], ["Faucon", "Louis", ""], ["Jungo", "Aidan", ""], ["Volodin", "Sergei", ""], ["Papuc", "Dalia", ""], ["Liossatos", "Orfeas", ""], ["Crulis", "Ben", ""], ["Tighanimine", "Mariame", ""], ["Constantin", "Isabela", ""], ["Kucherenko", "Anastasiia", ""], ["Maurer", "Alexandre", ""], ["Grimberg", "Felix", ""], ["Nitu", "Vlad", ""], ["Vossen", "Chris", ""], ["Rouault", "S\u00e9bastien", ""], ["El-Mhamdi", "El-Mahdi", ""]]}, {"id": "2107.07355", "submitter": "Stefan Marksteiner", "authors": "Stefan Marksteiner, Slava Bronfman, Markus Wolf, Eddie Lazebnik", "title": "Using Cyber Digital Twins for Automated Automotive Cybersecurity Testing", "comments": "6 pages, 3 figures, accepted for the joint SRCNAS/STRIVE workshop at\n  the 6th IEEE European Symposium on Security and Privacy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cybersecurity testing of automotive systems has become a practical necessity,\nwith the wide adoption of advanced driving assistance functions and vehicular\ncommunications. These functionalities require the integration of information\nand communication technologies that not only allow for a plethora of on-the-fly\nconfiguration abilities, but also provide a huge surface for attacks. Theses\ncircumstances have also been recognized by standardization and regulation\nbodies, making the need for not only proper cybersecurity engineering but also\nproving the effectiveness of security measures by verification and validation\nthrough testing also a formal necessity. In order to keep pace with the rapidly\ngrowing demand of neutral-party security testing of vehicular systems, novel\napproaches are needed. This paper therefore presents a methodology to create\nand execute cybersecurity test cases on the fly in a black box setting by using\npattern matching-based binary analysis and translation mechanisms to formal\nattack descriptions as well as model-checking techniques. The approach is\nintended to generate meaningful attack vectors on a system with next-to-zero a\npriori knowledge.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 14:32:10 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Marksteiner", "Stefan", ""], ["Bronfman", "Slava", ""], ["Wolf", "Markus", ""], ["Lazebnik", "Eddie", ""]]}, {"id": "2107.07416", "submitter": "Prajwol Kumar Nakarmi", "authors": "Prajwol Kumar Nakarmi", "title": "Cheatsheets for Authentication and Key Agreements in 2G, 3G, 4G, and 5G", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Authentication and Key Agreement (AKA) is a type of security protocol, used\nin 3GPP mobile networks, that provides two security capabilities. The first\ncapability, called authentication, is to cryptographically assert that a mobile\nphone or a network is indeed who it claims to be, and the second capability,\ncalled key agreement, is to put necessary cryptographic keys in place for\nprotection of traffic between the mobile phone and the network. Jointly, these\ntwo capabilities lay the foundation of secure 3GPP mobile networks. From 2G-5G,\nthere are eight main versions of AKA, details of which are spread over and\nembedded deep in multiple technical specifications. It is getting increasingly\ndifficult to quickly check a certain property of a certain AKA, let alone grasp\nthe full picture of all AKAs. Therefore, I have prepared cheatsheets for all\nAKA versions and listed their main properties. I hope these will benefit\nuniversity students, security researchers, and 3GPP standardization community.\nI welcome any corrections and feedback.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 10:09:10 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Nakarmi", "Prajwol Kumar", ""]]}, {"id": "2107.07759", "submitter": "Wei Zhou", "authors": "Wei Zhou, Le Guan, Peng Liu and Yuqing Zhang", "title": "Automatic Firmware Emulation through Invalidity-guided Knowledge\n  Inference (Extended Version)", "comments": "Extended version of Usenix'21 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emulating firmware for microcontrollers is challenging due to the tight\ncoupling between the hardware and firmware. This has greatly impeded the\napplication of dynamic analysis tools to firmware analysis. The\nstate-of-the-art work automatically models unknown peripherals by observing\ntheir access patterns, and then leverages heuristics to calculate the\nappropriate responses when unknown peripheral registers are accessed. However,\nwe empirically found that this approach and the corresponding heuristics are\nfrequently insufficient to emulate firmware. In this work, we propose a new\napproach called uEmu to emulate firmware with unknown peripherals. Unlike\nexisting work that attempts to build a general model for each peripheral, our\napproach learns how to correctly emulate firmware execution at individual\nperipheral access points. It takes the image as input and symbolically executes\nit by representing unknown peripheral registers as symbols. During symbolic\nexecution, it infers the rules to respond to unknown peripheral accesses. These\nrules are stored in a knowledge base, which is referred to during the dynamic\nfirmware analysis. uEmu achieved a passing rate of 95% in a set of unit tests\nfor peripheral drivers without any manual assistance. We also evaluated uEmu\nwith real-world firmware samples and new bugs were discovered.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 08:30:04 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 12:18:54 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Zhou", "Wei", ""], ["Guan", "Le", ""], ["Liu", "Peng", ""], ["Zhang", "Yuqing", ""]]}, {"id": "2107.07784", "submitter": "Igor Ivkic", "authors": "Igor Ivkic, Patrizia Sailer, Antonios Gouglidis, Andreas Mauthe,\n  Markus Tauber", "title": "A Security Cost Modelling Framework for Cyber-Physical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-Physical Systems (CPS) are formed through interconnected components\ncapable of computation, communication, sensing and changing the physical world.\nThe development of these systems poses a significant challenge since they have\nto be designed in a way to ensure cyber-security without impacting their\nperformance. This article presents the Security Cost Modelling Framework (SCMF)\nand shows supported by an experimental study how it can be used to measure,\nnormalise and aggregate the overall performance of a CPS. Unlike previous\nstudies, our approach uses different metrics to measure the overall performance\nof a CPS and provides a methodology for normalising the measurement results of\ndifferent units to a common Cost Unit. Moreover, we show how the Security Costs\ncan be extracted from the overall performance measurements which allows to\nquantify the overhead imposed by performing security-related tasks.\nFurthermore, we describe the architecture of our experimental testbed and\ndemonstrate the applicability of SCMF in an experimental study. Our results\nshow that measuring the overall performance and extracting the security costs\nusing SCMF can serve as basis to redesign interactions to achieve the same\noverall goal at less costs.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 09:19:47 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Ivkic", "Igor", ""], ["Sailer", "Patrizia", ""], ["Gouglidis", "Antonios", ""], ["Mauthe", "Andreas", ""], ["Tauber", "Markus", ""]]}, {"id": "2107.07818", "submitter": "Roman Kolcun", "authors": "Roman Kolcun, Diana Andreea Popescu, Vadim Safronov, Poonam Yadav,\n  Anna Maria Mandalari, Richard Mortier, Hamed Haddadi", "title": "Revisiting IoT Device Identification", "comments": "To appear in TMA 2021 conference. 9 pages, 6 figures. arXiv admin\n  note: text overlap with arXiv:2011.08605", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Internet-of-Things (IoT) devices are known to be the source of many security\nproblems, and as such, they would greatly benefit from automated management.\nThis requires robustly identifying devices so that appropriate network security\npolicies can be applied. We address this challenge by exploring how to\naccurately identify IoT devices based on their network behavior, while\nleveraging approaches previously proposed by other researchers.\n  We compare the accuracy of four different previously proposed machine\nlearning models (tree-based and neural network-based) for identifying IoT\ndevices. We use packet trace data collected over a period of six months from a\nlarge IoT test-bed. We show that, while all models achieve high accuracy when\nevaluated on the same dataset as they were trained on, their accuracy degrades\nover time, when evaluated on data collected outside the training set. We show\nthat on average the models' accuracy degrades after a couple of weeks by up to\n40 percentage points (on average between 12 and 21 percentage points). We argue\nthat, in order to keep the models' accuracy at a high level, these need to be\ncontinuously updated.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 11:01:45 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Kolcun", "Roman", ""], ["Popescu", "Diana Andreea", ""], ["Safronov", "Vadim", ""], ["Yadav", "Poonam", ""], ["Mandalari", "Anna Maria", ""], ["Mortier", "Richard", ""], ["Haddadi", "Hamed", ""]]}, {"id": "2107.07916", "submitter": "Alvi Ataur Khalil", "authors": "Alvi Ataur Khalil, Javier Franco, Imtiaz Parvez, Selcuk Uluagac,\n  Mohammad Ashiqur Rahman", "title": "A Literature Review on Blockchain-enabled Security and Operation of\n  Cyber-Physical Systems", "comments": "6 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blockchain has become a key technology in a plethora of application domains\nowing to its decentralized public nature. The cyber-physical systems (CPS) is\none of the prominent application domains that leverage blockchain for myriad\noperations, where the Internet of Things (IoT) is utilized for data collection.\nAlthough some of the CPS problems can be solved by simply adopting blockchain\nfor its secure and distributed nature, others require complex considerations\nfor overcoming blockchain-imposed limitations while maintaining the core aspect\nof CPS. Even though a number of studies focus on either the utilization of\nblockchains for different CPS applications or the blockchain-enabled security\nof CPS, there is no comprehensive survey including both perspectives together.\nTo fill this gap, we present a comprehensive overview of contemporary\nadvancement in using blockchain for enhancing different CPS operations as well\nas improving CPS security. To the best of our knowledge, this is the first\npaper that presents an in-depth review of research on blockchain-enabled CPS\noperation and security.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 14:13:09 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Khalil", "Alvi Ataur", ""], ["Franco", "Javier", ""], ["Parvez", "Imtiaz", ""], ["Uluagac", "Selcuk", ""], ["Rahman", "Mohammad Ashiqur", ""]]}, {"id": "2107.07923", "submitter": "Ricardo Silva Carvalho", "authors": "Ricardo Silva Carvalho, Theodore Vasiloudis, Oluwaseyi Feyisetan", "title": "BRR: Preserving Privacy of Text Data Efficiently on Device", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the use of personal devices connected to the Internet for tasks such as\nsearches and shopping becoming ubiquitous, ensuring the privacy of the users of\nsuch services has become a requirement in order to build and maintain customer\ntrust. While text privatization methods exist, they require the existence of a\ntrusted party that collects user data before applying a privatization method to\npreserve users' privacy. In this work we propose an efficient mechanism to\nprovide metric differential privacy for text data on-device. With our solution,\nsensitive data never leaves the device and service providers only have access\nto privatized data to train models on and analyze. We compare our algorithm to\nthe state-of-the-art for text privatization, showing similar or better utility\nfor the same privacy guarantees, while reducing the storage costs by orders of\nmagnitude, enabling on-device text privatization.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 14:24:34 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Carvalho", "Ricardo Silva", ""], ["Vasiloudis", "Theodore", ""], ["Feyisetan", "Oluwaseyi", ""]]}, {"id": "2107.07928", "submitter": "Ricardo Silva Carvalho", "authors": "Ricardo Silva Carvalho, Theodore Vasiloudis, Oluwaseyi Feyisetan", "title": "TEM: High Utility Metric Differential Privacy on Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ensuring the privacy of users whose data are used to train Natural Language\nProcessing (NLP) models is necessary to build and maintain customer trust.\nDifferential Privacy (DP) has emerged as the most successful method to protect\nthe privacy of individuals. However, applying DP to the NLP domain comes with\nunique challenges. The most successful previous methods use a generalization of\nDP for metric spaces, and apply the privatization by adding noise to inputs in\nthe metric space of word embeddings. However, these methods assume that one\nspecific distance measure is being used, ignore the density of the space around\nthe input, and assume the embeddings used have been trained on non-sensitive\ndata.\n  In this work we propose Truncated Exponential Mechanism (TEM), a general\nmethod that allows the privatization of words using any distance metric, on\nembeddings that can be trained on sensitive data. Our method makes use of the\nexponential mechanism to turn the privatization step into a \\emph{selection\nproblem}. This allows the noise applied to be calibrated to the density of the\nembedding space around the input, and makes domain adaptation possible for the\nembeddings. In our experiments, we demonstrate that our method significantly\noutperforms the state-of-the-art in terms of utility for the same level of\nprivacy, while providing more flexibility in the metric selection.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 14:38:16 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Carvalho", "Ricardo Silva", ""], ["Vasiloudis", "Theodore", ""], ["Feyisetan", "Oluwaseyi", ""]]}, {"id": "2107.07964", "submitter": "Bosubabu Sambana", "authors": "Bosubabu Sambana", "title": "Blockchain Technology: Bitcoins, Cryptocurrency and Applications", "comments": "7 Pages, 4 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Blockchain is a decentralized ledger used to securely exchange digital\ncurrency, perform deals and transactions efficient manner, each user of the\nnetwork has access to the least copy of the encrypted ledger so that they can\nvalidate a new transaction. The blockchain ledger is a collection of all\nBitcoin transactions executed in the past. Basically, it's distributed database\nthat maintains continuously growing tamper-proof data structure blocks that\nholds batches of individual transactions. The completed blocks are added in a\nlinear and chronological order. Each block contains a timestamp and information\nlink which points to a previous block. Bitcoin is a peer-to-peer permissionless\nnetwork that allows every user to connect to the network and send new\ntransactions to verify and create new blocks. Satoshi Nakamoto described the\ndesign of Bitcoin digital currency in his research paper posted to a\ncryptography listserv 2008. Nakamoto's suggestion has solved the long-pending\nproblem of cryptography and laid the foundation stone for digital currency.\nThis paper explains the concept of bitcoin, its characteristics, the need for\nBlockchain, and how Bitcoin works. It attempts to highlight the role of\nBlockchain in shaping the future of banking , financial services, and the\nadoption of the Internet of Thinks and future Technologies.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 15:27:04 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Sambana", "Bosubabu", ""]]}, {"id": "2107.07972", "submitter": "Ege Erdogan", "authors": "Ege Erdogan, Can Arda Aydin, Oznur Ozkasap, Waris Gill", "title": "Demo -- Zelig: Customizable Blockchain Simulator", "comments": "40th International Symposium on Reliable Distributed Systems (SRDS\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As blockchain-based systems see wider adoption, it becomes increasingly\ncritical to ensure their reliability, security, and efficiency. Running\nsimulations is an effective method of gaining insights on the existing systems\nand analyzing potential improvements. However, many of the existing blockchain\nsimulators have various shortcomings that yield them insufficient for a wide\nrange of scenarios. In this demo paper, we present Zelig: our blockchain\nsimulator designed with the main goals of customizability and extensibility. To\nthe best of our knowledge, Zelig is the only blockchain simulator that enables\nsimulating custom network topologies without modifying the simulator code. We\nexplain our simulator design, validate via experimental analysis against the\nreal-world Bitcoin network, and highlight potential use cases.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 15:36:46 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Erdogan", "Ege", ""], ["Aydin", "Can Arda", ""], ["Ozkasap", "Oznur", ""], ["Gill", "Waris", ""]]}, {"id": "2107.08077", "submitter": "Victor Verdugo", "authors": "Alejandro Jofr\\'e, Angel Pardo, David Salas, Victor Verdugo, Jos\\'e\n  Verschae", "title": "The Convergence Rates of Blockchain Mining Games: A Markovian Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the strategic behavior of miners in a blockchain is of great\nimportance for its proper operation. A common model for mining games considers\nan infinite time horizon, with players optimizing asymptotic average\nobjectives. Implicitly, this assumes that the asymptotic behaviors are realized\nat human-scale times, otherwise invalidating current models. We study the\nmining game utilizing Markov Decision Processes. Our approach allows us to\ndescribe the asymptotic behavior of the game in terms of the stationary\ndistribution of the induced Markov chain. We focus on a model with two players\nunder immediate release, assuming two different objectives: the (asymptotic)\naverage reward per turn and the (asymptotic) percentage of obtained blocks.\n  Using tools from Markov chain analysis, we show the existence of a strategy\nachieving slow mixing times, exponential in the policy parameters. This result\nemphasizes the imperative need to understand convergence rates in mining games,\nvalidating the standard models. Towards this end, we provide upper bounds for\nthe mixing time of certain meaningful classes of strategies. This result yields\ncriteria for establishing that long-term averaged functions are coherent as\npayoff functions. Moreover, by studying hitting times, we provide a criterion\nto validate the common simplification of considering finite states models. For\nboth considered objectives functions, we provide explicit formulae depending on\nthe stationary distribution of the underlying Markov chain. In particular, this\nshows that both mentioned objectives are not equivalent. Finally, we perform a\nmarket share case study in a particular regime of the game. More precisely, we\nshow that an strategic player with a sufficiently large processing power can\nimpose negative revenue on honest players.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 18:44:35 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Jofr\u00e9", "Alejandro", ""], ["Pardo", "Angel", ""], ["Salas", "David", ""], ["Verdugo", "Victor", ""], ["Verschae", "Jos\u00e9", ""]]}, {"id": "2107.08094", "submitter": "Yongqin Wang", "authors": "Rachit Rajat and Yongqin Wang and Murali Annavaram", "title": "Look Ahead ORAM: Obfuscating Addresses in Recommendation Model Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the cloud computing era, data privacy is a critical concern. Memory\naccesses patterns can leak private information. This data leak is particularly\nchallenging for deep learning recommendation models, where data associated with\na user is used to train a model. Recommendation models use embedding tables to\nmap categorical data (embedding table indices) to large vector space, which is\neasier for recommendation systems to learn. Oblivious RAM (ORAM) and its\nenhancements are proposed solutions to prevent memory access patterns from\nleaking information. ORAM solutions hide access patterns by fetching multiple\ndata blocks per each demand fetch and then shuffling the location of blocks\nafter each access. In this paper, we propose a new PathORAM architecture\ndesigned to protect user input privacy when training recommendation models.\nLook Ahead ORAM exploits the fact that during training, embedding table indices\nthat are going to be accessed in a future batch are known beforehand. Look\nAhead ORAM preprocesses future training samples to identify indices that will\nco-occur and groups these accesses into a large superblock. Look Ahead ORAM\nperforms the same-path assignment by grouping multiple data blocks into\nsuperblocks. Accessing a superblock will require fewer fetched data blocks than\naccessing all data blocks without grouping them as superblocks. Effectively,\nLook Ahead ORAM reduces the number of reads/writes per access. Look Ahead ORAM\nalso introduces a fat-tree structure for PathORAM, i.e. a tree with variable\nbucket size. Look Ahead ORAM achieves 2x speedup compared to PathORAM and\nreduces the bandwidth requirement by 3.15x while providing the same security as\nPathORAM.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 19:47:19 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Rajat", "Rachit", ""], ["Wang", "Yongqin", ""], ["Annavaram", "Murali", ""]]}, {"id": "2107.08279", "submitter": "Qin Wang", "authors": "Qin Wang and Shiping Chen and Yang Xiang", "title": "Anonymous Blockchain-based System for Consortium", "comments": "Published in ACM TMIS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blockchain brings various advantages to online transactions. However, the\ntotal transparency of these transactions may leakage users' sensitive\ninformation. Requirements on both cooperation and anonymity for\ncompanies/organizations become necessary. In this paper, we propose a\nMulti-center Anonymous Blockchain-based (MAB) system, with joint management for\nthe consortium and privacy protection for the participants. To achieve that, we\nformalize the syntax used by the MAB system and present a general construction\nbased on a modular design. By applying cryptographic primitives to each module,\nwe instantiate our scheme with anonymity and decentralization. Furthermore, we\ncarry out a comprehensive formal analysis of the proposed solution. The results\ndemonstrate our constructed scheme is secure and efficient.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 16:49:18 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Wang", "Qin", ""], ["Chen", "Shiping", ""], ["Xiang", "Yang", ""]]}, {"id": "2107.08357", "submitter": "Jun Wang", "authors": "Jun Wang, Chang Xu, Francisco Guzman, Ahmed El-Kishky, Benjamin I. P.\n  Rubinstein, Trevor Cohn", "title": "As Easy as 1, 2, 3: Behavioural Testing of NMT Systems for Numerical\n  Translation", "comments": "Findings of ACL, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mistranslated numbers have the potential to cause serious effects, such as\nfinancial loss or medical misinformation. In this work we develop comprehensive\nassessments of the robustness of neural machine translation systems to\nnumerical text via behavioural testing. We explore a variety of numerical\ntranslation capabilities a system is expected to exhibit and design effective\ntest examples to expose system underperformance. We find that numerical\nmistranslation is a general issue: major commercial systems and\nstate-of-the-art research models fail on many of our test examples, for high-\nand low-resource languages. Our tests reveal novel errors that have not\npreviously been reported in NMT systems, to the best of our knowledge. Lastly,\nwe discuss strategies to mitigate numerical mistranslation.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 04:09:47 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Wang", "Jun", ""], ["Xu", "Chang", ""], ["Guzman", "Francisco", ""], ["El-Kishky", "Ahmed", ""], ["Rubinstein", "Benjamin I. P.", ""], ["Cohn", "Trevor", ""]]}, {"id": "2107.08364", "submitter": "Triet Le", "authors": "Triet H. M. Le, Huaming Chen, M. Ali Babar", "title": "A Survey on Data-driven Software Vulnerability Assessment and\n  Prioritization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Software Vulnerabilities (SVs) are increasing in complexity and scale, posing\ngreat security risks to many software systems. Given the limited resources in\npractice, SV assessment and prioritization help practitioners devise optimal SV\nmitigation plans based on various SV characteristics. The surge in SV data\nsources and data-driven techniques such as Machine Learning and Deep Learning\nhave taken SV assessment and prioritization to the next level. Our survey\nprovides a taxonomy of the past research efforts and highlights the best\npractices for data-driven SV assessment and prioritization. We also discuss the\ncurrent limitations and propose potential solutions to address such issues.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 04:49:22 GMT"}, {"version": "v2", "created": "Sun, 25 Jul 2021 05:28:28 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Le", "Triet H. M.", ""], ["Chen", "Huaming", ""], ["Babar", "M. Ali", ""]]}, {"id": "2107.08367", "submitter": "Bowen Tang", "authors": "Bowen Tang, Chenggang Wu, Zhe Wang, Lichen Jia, Pen-Chung Yew,\n  Yueqiang Cheng, Yinqian Zhang, Chenxi Wang, Guoqing Harry Xu", "title": "SpecBox: A Label-Based Transparent Speculation Scheme Against Transient\n  Execution Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speculative execution techniques have been a cornerstone of modern processors\nto improve instruction-level parallelism. However, recent studies showed that\nthis kind of techniques could be exploited by attackers to leak secret data via\ntransient execution attacks, such as Spectre. Many defenses are proposed to\naddress this problem, but they all face various challenges: (1) Tracking data\nflow in the instruction pipeline could comprehensively address this problem,\nbut it could cause pipeline stalls and incur high performance overhead; (2)\nMaking side effect of speculative execution imperceptible to attackers, but it\noften needs additional storage components and complicated data movement\noperations. In this paper, we propose a label-based transparent speculation\nscheme called SpecBox. It dynamically partitions the cache system to isolate\nspeculative data and non-speculative data, which can prevent transient\nexecution from being observed by subsequent execution. Moreover, it uses thread\nownership semaphores to prevent speculative data from being accessed across\ncores. In addition, SpecBox also enhances the auxiliary components in the cache\nsystem against transient execution attacks, such as hardware prefetcher. Our\nsecurity analysis shows that SpecBox is secure and the performance evaluation\nshows that the performance overhead on SPEC CPU 2006 and PARSEC-3.0 benchmarks\nis small.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 05:24:53 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Tang", "Bowen", ""], ["Wu", "Chenggang", ""], ["Wang", "Zhe", ""], ["Jia", "Lichen", ""], ["Yew", "Pen-Chung", ""], ["Cheng", "Yueqiang", ""], ["Zhang", "Yinqian", ""], ["Wang", "Chenxi", ""], ["Xu", "Guoqing Harry", ""]]}, {"id": "2107.08461", "submitter": "Qiyiwen Zhang", "authors": "Qiyiwen Zhang, Zhiqi Bu, Kan Chen, Qi Long", "title": "Differentially Private Bayesian Neural Networks on Accuracy, Privacy and\n  Reliability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian neural network (BNN) allows for uncertainty quantification in\nprediction, offering an advantage over regular neural networks that has not\nbeen explored in the differential privacy (DP) framework. We fill this\nimportant gap by leveraging recent development in Bayesian deep learning and\nprivacy accounting to offer a more precise analysis of the trade-off between\nprivacy and accuracy in BNN. We propose three DP-BNNs that characterize the\nweight uncertainty for the same network architecture in distinct ways, namely\nDP-SGLD (via the noisy gradient method), DP-BBP (via changing the parameters of\ninterest) and DP-MC Dropout (via the model architecture). Interestingly, we\nshow a new equivalence between DP-SGD and DP-SGLD, implying that some\nnon-Bayesian DP training naturally allows for uncertainty quantification.\nHowever, the hyperparameters such as learning rate and batch size, can have\ndifferent or even opposite effects in DP-SGD and DP-SGLD.\n  Extensive experiments are conducted to compare DP-BNNs, in terms of privacy\nguarantee, prediction accuracy, uncertainty quantification, calibration,\ncomputation speed, and generalizability to network architecture. As a result,\nwe observe a new tradeoff between the privacy and the reliability. When\ncompared to non-DP and non-Bayesian approaches, DP-SGLD is remarkably accurate\nunder strong privacy guarantee, demonstrating the great potential of DP-BNN in\nreal-world tasks.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 14:37:07 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Zhang", "Qiyiwen", ""], ["Bu", "Zhiqi", ""], ["Chen", "Kan", ""], ["Long", "Qi", ""]]}, {"id": "2107.08490", "submitter": "Nikolay Ivanov", "authors": "Nikolay Ivanov and Qiben Yan", "title": "System-Wide Security for Offline Payment Terminals", "comments": "17th EAI International Conference on Security and Privacy in\n  Communication Networks (SecureComm 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most self-service payment terminals require network connectivity for\nprocessing electronic payments. The necessity to maintain network connectivity\nincreases costs, introduces cybersecurity risks, and significantly limits the\nnumber of places where the terminals can be installed. Leading payment service\nproviders have proposed offline payment solutions that rely on algorithmically\ngenerated payment tokens. Existing payment token solutions, however, require\ncomplex mechanisms for authentication, transaction management, and most\nimportantly, security risk management. In this paper, we present VolgaPay, a\nblockchain-based system that allows merchants to deploy secure offline payment\nterminal infrastructure that does not require collection and storage of any\nsensitive data. We design a novel payment protocol which mitigates security\nthreats for all the participants of VolgaPay, such that the maximum loss from\ngaining full access to any component by an adversary incurs only a limited\nscope of harm. We achieve significant enhancements in security, operation\nefficiency, and cost reduction via a combination of polynomial multi-hash chain\nmicropayment channels and blockchain grafting for off-chain channel state\ntransition. We implement the VolgaPay payment system, and with thorough\nevaluation and security analysis, we demonstrate that VolgaPay is capable of\ndelivering a fast, secure, and cost-efficient solution for offline payment\nterminals.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 16:50:57 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Ivanov", "Nikolay", ""], ["Yan", "Qiben", ""]]}, {"id": "2107.08590", "submitter": "Zhi Wang", "authors": "Zhi Wang, Chaoge Liu, Xiang Cui", "title": "EvilModel: Hiding Malware Inside of Neural Network Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Delivering malware covertly and evasively is critical to advanced malware\ncampaigns. In this paper, we present a new method to covertly and evasively\ndeliver malware through a neural network model. Neural network models are\npoorly explainable and have a good generalization ability. By embedding malware\nin neurons, the malware can be delivered covertly, with minor or no impact on\nthe performance of neural network. Meanwhile, because the structure of the\nneural network model remains unchanged, it can pass the security scan of\nantivirus engines. Experiments show that 36.9MB of malware can be embedded in a\n178MB-AlexNet model within 1% accuracy loss, and no suspicion is raised by\nanti-virus engines in VirusTotal, which verifies the feasibility of this\nmethod. With the widespread application of artificial intelligence, utilizing\nneural networks for attacks becomes a forwarding trend. We hope this work can\nprovide a reference scenario for the defense on neural network-assisted\nattacks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 02:44:31 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 14:31:13 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Wang", "Zhi", ""], ["Liu", "Chaoge", ""], ["Cui", "Xiang", ""]]}, {"id": "2107.08624", "submitter": "Haemin Lee", "authors": "Haemin Lee and Joongheon Kim", "title": "Trends in Blockchain and Federated Learning for Data Sharing in\n  Distributed Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of communication technologies in 5G networks and the\nInternet of things (IoT), a massive amount of generated data can improve\nmachine learning (ML) inference through data sharing. However, security and\nprivacy concerns are major obstacles in distributed and wireless networks. In\naddition, IoT has a limitation on system resources depending on the purpose of\nservices. In addition, a blockchain technology enables secure transactions\namong participants through consensus algorithms and encryption without a\ncentralized coordinator. In this paper, we first review the federated leaning\n(FL) and blockchain mechanisms, and then, present a survey on the integration\nof blockchain and FL for data sharing in industrial, vehicle, and healthcare\napplications.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 05:49:08 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Lee", "Haemin", ""], ["Kim", "Joongheon", ""]]}, {"id": "2107.08671", "submitter": "Leonard Bradatsch", "authors": "Leonard Bradatsch and Frank Kargl and Oleksandr Miroshkin", "title": "Zero Trust Service Function Chaining", "comments": "3 pages, 2 figures. to be published at the Conference on Networked\n  Systems (NetSys 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the inefficient handling of traditional security\nfunctions in Zero Trust (ZT) networks. For this reason, we propose a novel\nnetwork security concept that combines the ideas of ZT and Service Function\nChaining (SFC). This allows us to efficiently decide which security functions\nto apply to which packets and when.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 08:10:40 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Bradatsch", "Leonard", ""], ["Kargl", "Frank", ""], ["Miroshkin", "Oleksandr", ""]]}, {"id": "2107.08676", "submitter": "Aniruddha Biswas", "authors": "Aniruddha Biswas and Palash Sarkar", "title": "Influence of a Set of Variables on a Boolean Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CC cs.CR math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The influence of a set of variables on a Boolean function has three separate\ndefinitions in the literature, the first due to Ben-Or and Linial (1989), the\nsecond due to Fischer et al. (2002) and Blais (2009) and the third due to Tal\n(2017). The goal of the present work is to carry out a comprehensive study of\nthe notion of influence of a set of variables on a Boolean function. To this\nend, we introduce a definition of this notion using the auto-correlation\nfunction. A modification of the definition leads to the notion of\npseudo-influence. Somewhat surprisingly, it turns out that the auto-correlation\nbased definition of influence is equivalent to the definition introduced by\nFischer et al. (2002) and Blais (2009) and the notion of pseudo-influence is\nequivalent to the definition of influence considered by Tal (2017). Extensive\nanalysis of influence and pseduo-influence as well as the Ben-Or and Linial\nnotion of influence is carried out and the relations between these notions are\nestablished.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 08:25:32 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Biswas", "Aniruddha", ""], ["Sarkar", "Palash", ""]]}, {"id": "2107.08688", "submitter": "Hanzhou Wu", "authors": "Xiangyu Zhao, Yinzhe Yao, Hanzhou Wu and Xinpeng Zhang", "title": "Structural Watermarking to Deep Neural Networks via Network Channel\n  Pruning", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to protect the intellectual property (IP) of deep neural networks\n(DNNs), many existing DNN watermarking techniques either embed watermarks\ndirectly into the DNN parameters or insert backdoor watermarks by fine-tuning\nthe DNN parameters, which, however, cannot resist against various attack\nmethods that remove watermarks by altering DNN parameters. In this paper, we\nbypass such attacks by introducing a structural watermarking scheme that\nutilizes channel pruning to embed the watermark into the host DNN architecture\ninstead of crafting the DNN parameters. To be specific, during watermark\nembedding, we prune the internal channels of the host DNN with the channel\npruning rates controlled by the watermark. During watermark extraction, the\nwatermark is retrieved by identifying the channel pruning rates from the\narchitecture of the target DNN model. Due to the superiority of pruning\nmechanism, the performance of the DNN model on its original task is reserved\nduring watermark embedding. Experimental results have shown that, the proposed\nwork enables the embedded watermark to be reliably recovered and provides a\nhigh watermark capacity, without sacrificing the usability of the DNN model. It\nis also demonstrated that the work is robust against common transforms and\nattacks designed for conventional watermarking approaches.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 08:46:28 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Zhao", "Xiangyu", ""], ["Yao", "Yinzhe", ""], ["Wu", "Hanzhou", ""], ["Zhang", "Xinpeng", ""]]}, {"id": "2107.08695", "submitter": "Dominik Sisejkovic", "authors": "Dominik Sisejkovic, Farhad Merchant, Lennart M. Reimann, Rainer\n  Leupers", "title": "Deceptive Logic Locking for Hardware Integrity Protection against\n  Machine Learning Attacks", "comments": "Accepted at IEEE TCAD 2021", "journal-ref": "IEEE Transactions on Computer-Aided Design of Integrated Circuits\n  and Systems (TCAD), July, 2021", "doi": "10.1109/TCAD.2021.3100275", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Logic locking has emerged as a prominent key-driven technique to protect the\nintegrity of integrated circuits. However, novel machine-learning-based attacks\nhave recently been introduced to challenge the security foundations of locking\nschemes. These attacks are able to recover a significant percentage of the key\nwithout having access to an activated circuit. This paper address this issue\nthrough two focal points. First, we present a theoretical model to test locking\nschemes for key-related structural leakage that can be exploited by machine\nlearning. Second, based on the theoretical model, we introduce D-MUX: a\ndeceptive multiplexer-based logic-locking scheme that is resilient against\nstructure-exploiting machine learning attacks. Through the design of D-MUX, we\nuncover a major fallacy in existing multiplexer-based locking schemes in the\nform of a structural-analysis attack. Finally, an extensive cost evaluation of\nD-MUX is presented. To the best of our knowledge, D-MUX is the first\nmachine-learning-resilient locking scheme capable of protecting against all\nknown learning-based attacks. Hereby, the presented work offers a starting\npoint for the design and evaluation of future-generation logic locking in the\nera of machine learning.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 09:08:14 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Sisejkovic", "Dominik", ""], ["Merchant", "Farhad", ""], ["Reimann", "Lennart M.", ""], ["Leupers", "Rainer", ""]]}, {"id": "2107.08760", "submitter": "Leon Moonen", "authors": "Guru Prasad Bhandari, Amara Naseer and Leon Moonen (Simula Research\n  Laboratory, Norway)", "title": "CVEfixes: Automated Collection of Vulnerabilities and Their Fixes from\n  Open-Source Software", "comments": "Accepted for publication in Proceedings of the 17th International\n  Conference on Predictive Models and Data Analytics in Software Engineering\n  (PROMISE '21), August 19-20, 2021, Athens, Greece", "journal-ref": null, "doi": "10.1145/3475960.3475985", "report-no": null, "categories": "cs.SE cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data-driven research on the automated discovery and repair of security\nvulnerabilities in source code requires comprehensive datasets of real-life\nvulnerable code and their fixes. To assist in such research, we propose a\nmethod to automatically collect and curate a comprehensive vulnerability\ndataset from Common Vulnerabilities and Exposures (CVE) records in the public\nNational Vulnerability Database (NVD). We implement our approach in a fully\nautomated dataset collection tool and share an initial release of the resulting\nvulnerability dataset named CVEfixes.\n  The CVEfixes collection tool automatically fetches all available CVE records\nfrom the NVD, gathers the vulnerable code and corresponding fixes from\nassociated open-source repositories, and organizes the collected information in\na relational database. Moreover, the dataset is enriched with meta-data such as\nprogramming language, and detailed code and security metrics at five levels of\nabstraction. The collection can easily be repeated to keep up-to-date with\nnewly discovered or patched vulnerabilities. The initial release of CVEfixes\nspans all published CVEs up to 9 June 2021, covering 5365 CVE records for 1754\nopen-source projects that were addressed in a total of 5495 vulnerability\nfixing commits.\n  CVEfixes supports various types of data-driven software security research,\nsuch as vulnerability prediction, vulnerability classification, vulnerability\nseverity prediction, analysis of vulnerability-related code changes, and\nautomated vulnerability repair.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 11:34:09 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Bhandari", "Guru Prasad", "", "Simula Research\n  Laboratory, Norway"], ["Naseer", "Amara", "", "Simula Research\n  Laboratory, Norway"], ["Moonen", "Leon", "", "Simula Research\n  Laboratory, Norway"]]}, {"id": "2107.08763", "submitter": "Antonious Girgis", "authors": "Antonious M. Girgis, Deepesh Data, Suhas Diggavi", "title": "Renyi Differential Privacy of the Subsampled Shuffle Model in\n  Distributed Learning", "comments": "arXiv admin note: text overlap with arXiv:2105.05180", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IT math.IT", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We study privacy in a distributed learning framework, where clients\ncollaboratively build a learning model iteratively through interactions with a\nserver from whom we need privacy. Motivated by stochastic optimization and the\nfederated learning (FL) paradigm, we focus on the case where a small fraction\nof data samples are randomly sub-sampled in each round to participate in the\nlearning process, which also enables privacy amplification. To obtain even\nstronger local privacy guarantees, we study this in the shuffle privacy model,\nwhere each client randomizes its response using a local differentially private\n(LDP) mechanism and the server only receives a random permutation (shuffle) of\nthe clients' responses without their association to each client. The principal\nresult of this paper is a privacy-optimization performance trade-off for\ndiscrete randomization mechanisms in this sub-sampled shuffle privacy model.\nThis is enabled through a new theoretical technique to analyze the Renyi\nDifferential Privacy (RDP) of the sub-sampled shuffle model. We numerically\ndemonstrate that, for important regimes, with composition our bound yields\nsignificant improvement in privacy guarantee over the state-of-the-art\napproximate Differential Privacy (DP) guarantee (with strong composition) for\nsub-sampled shuffled models. We also demonstrate numerically significant\nimprovement in privacy-learning performance operating point using real data\nsets.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 11:43:24 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Girgis", "Antonious M.", ""], ["Data", "Deepesh", ""], ["Diggavi", "Suhas", ""]]}, {"id": "2107.08832", "submitter": "Benjamin Smith", "authors": "Mathilde Chenu (GRACE), Benjamin Smith (GRACE)", "title": "Higher-degree supersingular group actions", "comments": "Mathematical Cryptology, Florida Online Journals, In press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the isogeny graphs of supersingular elliptic curves over\n$\\mathbb{F}_{p^2}$ equipped with a $d$-isogeny to their Galois conjugate. These\ncurves are interesting because they are, in a sense, a generalization of curves\ndefined over $\\mathbb{F}_p$, and there is an action of the ideal class group of\n$\\mathbb{Q}(\\sqrt{-dp})$ on the isogeny graphs. We investigate constructive and\ndestructive aspects of these graphs in isogeny-based cryptography, including\ngeneralizations of the CSIDH cryptosystem and the Delfs-Galbraith algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 12:53:41 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Chenu", "Mathilde", "", "GRACE"], ["Smith", "Benjamin", "", "GRACE"]]}, {"id": "2107.08909", "submitter": "Takayuki Miura", "authors": "Takayuki Miura, Satoshi Hasegawa, Toshiki Shibahara", "title": "MEGEX: Data-Free Model Extraction Attack against Gradient-Based\n  Explainable AI", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The advance of explainable artificial intelligence, which provides reasons\nfor its predictions, is expected to accelerate the use of deep neural networks\nin the real world like Machine Learning as a Service (MLaaS) that returns\npredictions on queried data with the trained model. Deep neural networks\ndeployed in MLaaS face the threat of model extraction attacks. A model\nextraction attack is an attack to violate intellectual property and privacy in\nwhich an adversary steals trained models in a cloud using only their\npredictions. In particular, a data-free model extraction attack has been\nproposed recently and is more critical. In this attack, an adversary uses a\ngenerative model instead of preparing input data. The feasibility of this\nattack, however, needs to be studied since it requires more queries than that\nwith surrogate datasets. In this paper, we propose MEGEX, a data-free model\nextraction attack against a gradient-based explainable AI. In this method, an\nadversary uses the explanations to train the generative model and reduces the\nnumber of queries to steal the model. Our experiments show that our proposed\nmethod reconstructs high-accuracy models -- 0.97$\\times$ and 0.98$\\times$ the\nvictim model accuracy on SVHN and CIFAR-10 datasets given 2M and 20M queries,\nrespectively. This implies that there is a trade-off between the\ninterpretability of models and the difficulty of stealing them.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 14:25:06 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Miura", "Takayuki", ""], ["Hasegawa", "Satoshi", ""], ["Shibahara", "Toshiki", ""]]}, {"id": "2107.08928", "submitter": "William Blanzeisky", "authors": "William Blanzeisky, P\\'adraig Cunningham, Kenneth Kennedy", "title": "Introducing a Family of Synthetic Datasets for Research on Bias in\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A significant impediment to progress in research on bias in machine learning\n(ML) is the availability of relevant datasets. This situation is unlikely to\nchange much given the sensitivity of such data. For this reason, there is a\nrole for synthetic data in this research. In this short paper, we present one\nsuch family of synthetic data sets. We provide an overview of the data,\ndescribe how the level of bias can be varied, and present a simple example of\nan experiment on the data.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 14:40:22 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Blanzeisky", "William", ""], ["Cunningham", "P\u00e1draig", ""], ["Kennedy", "Kenneth", ""]]}, {"id": "2107.08970", "submitter": "Alex Shafarenko", "authors": "Alex Shafarenko", "title": "Indexing structures for the PLS blockchain", "comments": "28 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper studies known indexing structures from a new point of view:\nminimisation of data exchange between an IoT device acting as a blockchain\nclient and the blockchain server running a protocol suite that includes two Guy\nFawkes protocols, PLS and SLVP. The PLS blockchain is not a cryptocurrency\ninstrument; it is an immutable ledger offering guaranteed non-repudiation to\nlow-power clients without use of public key crypto. The novelty of the\nsituation is in the fact that every PLS client has to obtain a proof of absence\nin all blocks of the chain to which its counterparty does not contribute, and\nwe show that it is possible without traversing the block's Merkle tree.\n  We obtain weight statistics of a leaf path on a sparse Merkle tree\ntheoretically, as our ground case. Using the theory we quantify the\ncommunication cost of a client interacting with the blockchain. We show that\nlarge savings can be achieved by providing a bitmap index of the tree\ncompressed using Tunstall's method. We further show that even in the case of\ncorrelated access, as in two IoT devices posting messages for each other in\nconsecutive blocks, it is possible to prevent compression degradation by\nre-randomising the IDs using a pseudorandom bijective function. We propose a\nlow-cost function of this kind and evaluate its quality by simulation, using\nthe avalanche criterion.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 15:38:56 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Shafarenko", "Alex", ""]]}, {"id": "2107.09059", "submitter": "Valerii Sopin", "authors": "Valerii Sopin", "title": "Ergodic dynamical systems over the Cartesian power of the ring of p-adic\n  integers", "comments": "T-Functions of several variables: New Criteria for Transitivity", "journal-ref": "P-Adic Num Ultrametr Anal Appl 6, 333-336 (2014)", "doi": "10.1134/S2070046614040086", "report-no": null, "categories": "math.DS cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For any 1-lipschitz ergodic map $F:\\; \\mathbb{Z}^{k}_{p} \\mapsto\n\\mathbb{Z}^{k}_{p},\\;k>1\\in\\mathbb{N},$ there are 1-lipschitz ergodic map $G:\\;\n\\mathbb{Z}_{p} \\mapsto \\mathbb{Z}_{p}$ and two bijection $H_k$, $T_{k,\\;P}$\nthat $$G = H_{k} \\circ T_{k,\\;P}\\circ F\\circ H^{-1}_{k} \\text{ and } F =\nH^{-1}_{k} \\circ T_{k,\\;P^{-1}}\\circ G\\circ H_{k}.$$\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 14:31:39 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Sopin", "Valerii", ""]]}, {"id": "2107.09113", "submitter": "Nicola Fabiano", "authors": "Nicola Fabiano", "title": "The approach with the Data Protection and Privacy Relationships Model\n  (DAPPREMO)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We describe the Data Protection and Privacy Relationships Model (DAPPREMO),\nwhich is based on the set theory, considering that both the data protection and\nprivacy regulation and Ethics principles in those domains belong to a set.\nDAPPREMO is a new and innovative solution to adopt a model in any data\nprotection and privacy activities. We theorise that DAPPREMO is an innovative\napproach to have a broad overview of all the objects related to a specific case\nor more cases from data protection and privacy perspective. We describe\nDAPPREMO as a solution for a multidisciplinary approach to address any data\nprotection and privacy issue.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 19:11:12 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Fabiano", "Nicola", ""]]}, {"id": "2107.09130", "submitter": "Rozhin Yasaei", "authors": "Rozhin Yasaei, Shih-Yuan Yu, Emad Kasaeyan Naeini, Mohammad Abdullah\n  Al Faruque", "title": "GNN4IP: Graph Neural Network for Hardware Intellectual Property Piracy\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aggressive time-to-market constraints and enormous hardware design and\nfabrication costs have pushed the semiconductor industry toward hardware\nIntellectual Properties (IP) core design. However, the globalization of the\nintegrated circuits (IC) supply chain exposes IP providers to theft and illegal\nredistribution of IPs. Watermarking and fingerprinting are proposed to detect\nIP piracy. Nevertheless, they come with additional hardware overhead and cannot\nguarantee IP security as advanced attacks are reported to remove the watermark,\nforge, or bypass it. In this work, we propose a novel methodology, GNN4IP, to\nassess similarities between circuits and detect IP piracy. We model the\nhardware design as a graph and construct a graph neural network model to learn\nits behavior using the comprehensive dataset of register transfer level codes\nand gate-level netlists that we have gathered. GNN4IP detects IP piracy with\n96% accuracy in our dataset and recognizes the original IP in its obfuscated\nversion with 100% accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 20:13:16 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Yasaei", "Rozhin", ""], ["Yu", "Shih-Yuan", ""], ["Naeini", "Emad Kasaeyan", ""], ["Faruque", "Mohammad Abdullah Al", ""]]}, {"id": "2107.09199", "submitter": "Bashir Mohammad Sabquat Bahar Talukder", "authors": "B. M. S. Bahar Talukder, Farah Ferdaus, and Md Tauhidur Rahman", "title": "A Non-invasive Technique to Detect Authentic/Counterfeit SRAM Chips", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many commercially available memory chips are fabricated worldwide in\nuntrusted facilities. Therefore, a counterfeit memory chip can easily enter\ninto the supply chain in different formats. Deploying these counterfeit memory\nchips into an electronic system can severely affect security and reliability\ndomains because of their sub-standard quality, poor performance, and shorter\nlifespan. Therefore, a proper solution is required to identify counterfeit\nmemory chips before deploying them in mission-, safety-, and security-critical\nsystems. However, a single solution to prevent counterfeiting is challenging\ndue to the diversity of counterfeit types, sources, and refinement techniques.\nBesides, the chips can pass initial testing and still fail while being used in\nthe system. Furthermore, existing solutions focus on detecting a single\ncounterfeit type (e.g., detecting recycled memory chips). This work proposes a\nframework that detects major counterfeit static random-access memory (SRAM)\ntypes by attesting/identifying the origin of the manufacturer. The proposed\ntechnique generates a single signature for a manufacturer and does not require\nany exhaustive registration/authentication process. We validate our proposed\ntechnique using 345 SRAM chips produced by major manufacturers. The silicon\nresults show that the test scores ($F_{1}$ score) of our proposed technique of\nidentifying memory manufacturer and part-number are 93% and 71%, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 23:40:03 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Talukder", "B. M. S. Bahar", ""], ["Ferdaus", "Farah", ""], ["Rahman", "Md Tauhidur", ""]]}, {"id": "2107.09323", "submitter": "Wissam Siblini", "authors": "Wissam Siblini, Guillaume Coter, R\\'emy Fabry, Liyun He-Guelton,\n  Fr\\'ed\\'eric Obl\\'e, Bertrand Lebichot, Yann-A\\\"el Le Borgne, Gianluca\n  Bontempi", "title": "Transfer Learning for Credit Card Fraud Detection: A Journey from\n  Research to Production", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The dark face of digital commerce generalization is the increase of fraud\nattempts. To prevent any type of attacks, state of the art fraud detection\nsystems are now embedding Machine Learning (ML) modules. The conception of such\nmodules is only communicated at the level of research and papers mostly focus\non results for isolated benchmark datasets and metrics. But research is only a\npart of the journey, preceded by the right formulation of the business problem\nand collection of data, and followed by a practical integration. In this paper,\nwe give a wider vision of the process, on a case study of transfer learning for\nfraud detection, from business to research, and back to business.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 08:29:04 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Siblini", "Wissam", ""], ["Coter", "Guillaume", ""], ["Fabry", "R\u00e9my", ""], ["He-Guelton", "Liyun", ""], ["Obl\u00e9", "Fr\u00e9d\u00e9ric", ""], ["Lebichot", "Bertrand", ""], ["Borgne", "Yann-A\u00ebl Le", ""], ["Bontempi", "Gianluca", ""]]}, {"id": "2107.09373", "submitter": "Manoranjan Mohanty", "authors": "Waheeb Yaqub, Manoranjan Mohanty, Basem Suleiman", "title": "Image-Hashing-Based Anomaly Detection for Privacy-Preserving Online\n  Proctoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Online proctoring has become a necessity in online teaching. Video-based\ncrowd-sourced online proctoring solutions are being used, where an exam-taking\nstudent's video is monitored by third parties, leading to privacy concerns. In\nthis paper, we propose a privacy-preserving online proctoring system. The\nproposed image-hashing-based system can detect the student's excessive face and\nbody movement (i.e., anomalies) that is resulted when the student tries to\ncheat in the exam. The detection can be done even if the student's face is\nblurred or masked in video frames. Experiment with an in-house dataset shows\nthe usability of the proposed system.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 09:45:05 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Yaqub", "Waheeb", ""], ["Mohanty", "Manoranjan", ""], ["Suleiman", "Basem", ""]]}, {"id": "2107.09470", "submitter": "Alpesh Bhudia", "authors": "Alpesh Bhudia, Daniel O'Keeffe, Daniele Sgandurra, and Darren\n  Hurley-Smith", "title": "RansomClave: Ransomware Key Management using SGX", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern ransomware often generate and manage cryptographic keys on the\nvictim's machine, giving defenders an opportunity to capture exposed keys and\nrecover encrypted data without paying the ransom. However, recent work has\nraised the possibility of future enclave-enhanced malware that could avoid such\nmitigations using emerging support for hardware-enforced secure enclaves in\ncommodity CPUs. Nonetheless, the practicality of such enclave-enhanced malware\nand its potential impact on all phases of the ransomware lifecyle remain\nunclear. Given the demonstrated capacity of ransomware authors to innovate in\norder to better extort their victims (e.g. through the adoption of untraceable\nvirtual currencies and anonymity networks), it is important to better\nunderstand the risks involved and identify potential mitigations.\n  As a basis for comprehensive security and performance analysis of\nenclave-enhanced ransomware, we present RansomClave, a family of ransomware\nthat securely manage their cryptographic keys using an enclave. We use\nRansomClave to explore the implications of enclave-enhanced ransomware for the\nkey generation, encryption and key release phases of the ransomware lifecycle,\nand to identify potential limitations and mitigations.\n  We propose two plausible victim models and analyse, from an attacker's\nperspective, how RansomClave can protect cryptographic keys from each type of\nvictim. We find that some existing mitigations are likely to be effective\nduring the key generation and encryption phases, but that RansomClave enables\nnew trustless key release schemes that could potentially improve attacker's\nprofitability and, by extension, make enclaves an attractive target for future\nattackers.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 13:23:10 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Bhudia", "Alpesh", ""], ["O'Keeffe", "Daniel", ""], ["Sgandurra", "Daniele", ""], ["Hurley-Smith", "Darren", ""]]}, {"id": "2107.09707", "submitter": "David Lajeunesse", "authors": "David Lajeunesse and Hugo D. Scolnik", "title": "A Cooperative Optimal Mining Model for Bitcoin", "comments": "8 pages, 2 figures, Accepted to 2021 3rd Conference on Blockchain\n  Research & Applications for Innovative Networks and Services (BRAINS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze Bitcoin mining from the perspective of a game and propose an\noptimal mining model that maximizes profits of pools and miners. The model is a\ntwo-stage Stackelberg game in which each stage forms a sub-game. In stage I,\npools are the leaders who assign a computing power to be consumed by miners. In\nstage II, miners decide of their power consumption and distribution. They find\nthemselves in a social dilemma in which they must choose between mining in\nsolo, therefore prioritizing their individual preferences, and participating in\na pool for the collective interest. The model relies on a pool protocol based\non a simulated game in which the miners compete for the reward won by the pool.\nThe solutions for the stage I sub-game and the simulated protocol game are\nunique and stable Nash equilibriums while the stage II sub-game leads to a\nstable cooperative equilibrium only when miners choose their strategies\naccording to certain criteria. We conclude that the cooperative optimal mining\nmodel has the potential to favor Bitcoin decentralization and stability.\nMainly, the social dilemma faced by miners together with the balance of\nincentives ensure a certain distribution of the network computing power between\npools and solo miners, while equilibriums in the game solutions provide\nstability to the system.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 18:20:20 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Lajeunesse", "David", ""], ["Scolnik", "Hugo D.", ""]]}, {"id": "2107.09789", "submitter": "Jingtao Li", "authors": "Jingtao Li, Zhezhi He, Adnan Siraj Rakin, Deliang Fan, Chaitali\n  Chakrabarti", "title": "NeurObfuscator: A Full-stack Obfuscation Tool to Mitigate Neural\n  Architecture Stealing", "comments": "Accepted by HOST 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural network stealing attacks have posed grave threats to neural network\nmodel deployment. Such attacks can be launched by extracting neural\narchitecture information, such as layer sequence and dimension parameters,\nthrough leaky side-channels. To mitigate such attacks, we propose\nNeurObfuscator, a full-stack obfuscation tool to obfuscate the neural network\narchitecture while preserving its functionality with very limited performance\noverhead. At the heart of this tool is a set of obfuscating knobs, including\nlayer branching, layer widening, selective fusion and schedule pruning, that\nincrease the number of operators, reduce/increase the latency, and number of\ncache and DRAM accesses. A genetic algorithm-based approach is adopted to\norchestrate the combination of obfuscating knobs to achieve the best\nobfuscating effect on the layer sequence and dimension parameters so that the\narchitecture information cannot be successfully extracted. Results on sequence\nobfuscation show that the proposed tool obfuscates a ResNet-18 ImageNet model\nto a totally different architecture (with 44 layer difference) without\naffecting its functionality with only 2% overall latency overhead. For\ndimension obfuscation, we demonstrate that an example convolution layer with 64\ninput and 128 output channels can be obfuscated to generate a layer with 207\ninput and 93 output channels with only a 2% latency overhead.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 22:36:39 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Li", "Jingtao", ""], ["He", "Zhezhi", ""], ["Rakin", "Adnan Siraj", ""], ["Fan", "Deliang", ""], ["Chakrabarti", "Chaitali", ""]]}, {"id": "2107.09802", "submitter": "Walid Krichene", "authors": "Steve Chien, Prateek Jain, Walid Krichene, Steffen Rendle, Shuang\n  Song, Abhradeep Thakurta, Li Zhang", "title": "Private Alternating Least Squares: Practical Private Matrix Completion\n  with Tighter Rates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of differentially private (DP) matrix completion under\nuser-level privacy. We design a joint differentially private variant of the\npopular Alternating-Least-Squares (ALS) method that achieves: i) (nearly)\noptimal sample complexity for matrix completion (in terms of number of items,\nusers), and ii) the best known privacy/utility trade-off both theoretically, as\nwell as on benchmark data sets. In particular, we provide the first global\nconvergence analysis of ALS with noise introduced to ensure DP, and show that,\nin comparison to the best known alternative (the Private Frank-Wolfe algorithm\nby Jain et al. (2018)), our error bounds scale significantly better with\nrespect to the number of items and users, which is critical in practical\nproblems. Extensive validation on standard benchmarks demonstrate that the\nalgorithm, in combination with carefully designed sampling procedures, is\nsignificantly more accurate than existing techniques, thus promising to be the\nfirst practical DP embedding model.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 23:19:11 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Chien", "Steve", ""], ["Jain", "Prateek", ""], ["Krichene", "Walid", ""], ["Rendle", "Steffen", ""], ["Song", "Shuang", ""], ["Thakurta", "Abhradeep", ""], ["Zhang", "Li", ""]]}, {"id": "2107.09804", "submitter": "Mohammad Samavatian", "authors": "Saikat Majumdar, Mohammad Hossein Samavatian, Kristin Barber, Radu\n  Teodorescu", "title": "Using Undervolting as an On-Device Defense Against Adversarial Machine\n  Learning Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural network (DNN) classifiers are powerful tools that drive a broad\nspectrum of important applications, from image recognition to autonomous\nvehicles. Unfortunately, DNNs are known to be vulnerable to adversarial attacks\nthat affect virtually all state-of-the-art models. These attacks make small\nimperceptible modifications to inputs that are sufficient to induce the DNNs to\nproduce the wrong classification.\n  In this paper we propose a novel, lightweight adversarial correction and/or\ndetection mechanism for image classifiers that relies on undervolting (running\na chip at a voltage that is slightly below its safe margin). We propose using\ncontrolled undervolting of the chip running the inference process in order to\nintroduce a limited number of compute errors. We show that these errors disrupt\nthe adversarial input in a way that can be used either to correct the\nclassification or detect the input as adversarial. We evaluate the proposed\nsolution in an FPGA design and through software simulation. We evaluate 10\nattacks on two popular DNNs and show an average detection rate of 80% to 95%.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 23:21:04 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Majumdar", "Saikat", ""], ["Samavatian", "Mohammad Hossein", ""], ["Barber", "Kristin", ""], ["Teodorescu", "Radu", ""]]}, {"id": "2107.09830", "submitter": "Liangfeng Zhang", "authors": "Lin Zhu, Wen Ming Li, Liang Feng Zhang", "title": "On the Modulus in Matching Vector Codes", "comments": "The Computer Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A $k$-query locally decodable code (LDC) $C$ allows one to encode any\n$n$-symbol message $x$ as a codeword $C(x)$ of $N$ symbols such that each\nsymbol of $x$ can be recovered by looking at $k$ symbols of $C(x)$, even if a\nconstant fraction of $C(x)$ have been corrupted. Currently, the best known LDCs\nare matching vector codes (MVCs). A modulus\n$m=p_1^{\\alpha_1}p_2^{\\alpha_2}\\cdots p_r^{\\alpha_r}$ may result in an MVC with\n$k\\leq 2^r$ and $N=\\exp(\\exp(O((\\log n)^{1-1/r} (\\log\\log n)^{1/r})))$. The $m$\nis {\\em good} if it is possible to have $k<2^r$. The good numbers yield more\nefficient MVCs. Prior to this work, there are only {\\em finitely many} good\nnumbers. All of them were obtained via computer search and have the form\n$m=p_1p_2$. In this paper, we study good numbers of the form\n$m=p_1^{\\alpha_1}p_2^{\\alpha_2}$. We show that if\n$m=p_1^{\\alpha_1}p_2^{\\alpha_2}$ is good, then any multiple of $m$ of the form\n$p_1^{\\beta_1}p_2^{\\beta_2}$ must be good as well. Given a good number\n$m=p_1^{\\alpha_1}p_2^{\\alpha_2}$, we show an explicit method of obtaining\nsmaller good numbers that have the same prime divisors. Our approach yields\n{\\em infinitely many} new good numbers.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 01:48:43 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Zhu", "Lin", ""], ["Li", "Wen Ming", ""], ["Zhang", "Liang Feng", ""]]}, {"id": "2107.09833", "submitter": "Md Hafizul Islam Chowdhuryy", "authors": "Md Hafizul Islam Chowdhuryy, Fan Yao", "title": "Leaking Secrets through Modern Branch Predictor in the Speculative World", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transient execution attacks that exploit speculation have raised significant\nconcerns in computer systems. Typically, branch predictors are leveraged to\ntrigger mis-speculation in transient execution attacks. In this work, we\ndemonstrate a new class of speculation-based attack that targets branch\nprediction unit (BPU). We find that speculative resolution of conditional\nbranches (i.e., in nested speculation) alter the states of pattern history\ntable (PHT) in modern processors, which are not restored after the\ncorresponding branches are later squashed. Such characteristic allows attackers\nto exploit BPU as the secret transmitting medium in transient execution\nattacks. To evaluate the discovered vulnerability, we build a novel attack\nframework, BranchSpectre, that enables exfiltration of unintended secrets\nthrough observing speculative PHT updates (in the form of covert and side\nchannels). We further investigate PHT collision mechanism in the history-based\npredictor as well as the branch prediction mode transitions in Intel\nprocessors. Built upon such knowledge, we implement an ultra high-speed covert\nchannel (BranchSpectre-cc) as well as two side channels (i.e., BranchSpectre-v1\nand BranchSpectre-v2) that merely rely on BPU for mis-speculation trigger and\nsecret inference in the speculative domain. Notably, BranchSpectre side\nchannels can take advantage of much simpler code patterns than the ones used in\nSpectre attacks. We present an extensive BranchSpectre code gadget analysis on\na set of popular real-world application code bases followed by a demonstration\nof real-world side channel attack on OpenSSL. The evaluation results show\nsubstantial wider existence and higher exploitability of BranchSpectre code\npatterns in real-world software. Finally, we discuss several secure branch\nprediction mechanisms that can mitigate transient execution attacks exploiting\nmodern branch predictors.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 02:01:12 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Chowdhuryy", "Md Hafizul Islam", ""], ["Yao", "Fan", ""]]}, {"id": "2107.09856", "submitter": "Mingfeng Xin", "authors": "Mingfeng Xin, Hui Wen, Liting Deng, Hong Li, Qiang Li and Limin Sun", "title": "Firmware Re-hosting Through Static Binary-level Porting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The rapid growth of the Industrial Internet of Things (IIoT) has brought\nembedded systems into focus as major targets for both security analysts and\nmalicious adversaries. Due to the non-standard hardware and diverse software,\nembedded devices present unique challenges to security analysts for the\naccurate analysis of firmware binaries. The diversity in hardware components\nand tight coupling between firmware and hardware makes it hard to perform\ndynamic analysis, which must have the ability to execute firmware code in\nvirtualized environments. However, emulating the large expanse of hardware\nperipherals makes analysts have to frequently modify the emulator for executing\nvarious firmware code in different virtualized environments, greatly limiting\nthe ability of security analysis.\n  In this work, we explore the problem of firmware re-hosting related to the\nreal-time operating system (RTOS). Specifically, developers create a Board\nSupport Package (BSP) and develop device drivers to make that RTOS run on their\nplatform. By providing high-level replacements for BSP routines and device\ndrivers, we can make the minimal modification of the firmware that is to be\nmigrated from its original hardware environment into a virtualized one. We show\nthat an approach capable of offering the ability to execute firmware at scale\nthrough patching firmware in an automated manner without modifying the existing\nemulators. Our approach, called static binary-level porting, first identifies\nthe BSP and device drivers in target firmware, then patches the firmware with\npre-built BSP routines and drivers that can be adapted to the existing\nemulators. Finally, we demonstrate the practicality of the proposed method on\nmultiple hardware platforms and firmware samples for security analysis. The\nresult shows that the approach is flexible enough to emulate firmware for\nvulnerability assessment and exploits development.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 02:53:52 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 12:46:51 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Xin", "Mingfeng", ""], ["Wen", "Hui", ""], ["Deng", "Liting", ""], ["Li", "Hong", ""], ["Li", "Qiang", ""], ["Sun", "Limin", ""]]}, {"id": "2107.09863", "submitter": "Ziqi Xu", "authors": "Ziqi Xu, Jingcheng Li, Yanjun Pan, Loukas Lazos, Ming Li, Nirnimesh\n  Ghose", "title": "PoF: Proof-of-Following for Vehicle Platoons", "comments": "16 pages, 17 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperative vehicle platooning significantly improves highway safety and fuel\nefficiency. In this model, a set of vehicles move in line formation and\ncoordinate functions such as acceleration, braking, and steering using a\ncombination of physical sensing and vehicle-to-vehicle (V2V) messaging. The\nauthenticity and integrity of the V2V messages are paramount to highway safety.\nFor this reason, recent V2V and V2X standards support the integration of a PKI.\nHowever, a PKI cannot bind a vehicle's digital identity to the vehicle's\nphysical state (location, heading, velocity, etc.). As a result, a vehicle with\nvalid cryptographic credentials can impact the platoon by creating \"ghost\"\nvehicles and injecting false state information.\n  In this paper, we seek to provide the missing link between the physical and\nthe digital world in the context of verifying a vehicle's platoon membership.\nWe focus on the property of following, where vehicles follow each other in a\nclose and coordinated manner. We aim at developing a Proof-of-Following (PoF)\nprotocol that enables a candidate vehicle to prove that it follows a verifier\nwithin the typical platooning distance. The main idea of the proposed PoF\nprotocol is to draw security from the common, but constantly changing\nenvironment experienced by the closely traveling vehicles. We use the\nlarge-scale fading effect of ambient RF signals as a common source of\nrandomness to construct a PoF primitive. The correlation of large-scale fading\nis an ideal candidate for the mobile outdoor environment because it\nexponentially decays with distance and time. We evaluate our PoF protocol on an\nexperimental platoon of two vehicles in freeway, highway, and urban driving\nconditions. In such realistic conditions, we demonstrate that the PoF\nwithstands both the pre-recording and following attacks with overwhelming\nprobability.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 03:05:20 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Xu", "Ziqi", ""], ["Li", "Jingcheng", ""], ["Pan", "Yanjun", ""], ["Lazos", "Loukas", ""], ["Li", "Ming", ""], ["Ghose", "Nirnimesh", ""]]}, {"id": "2107.09886", "submitter": "Quang Minh Nguyen", "authors": "Minh Quang Nguyen, Dumitrel Loghin, Tien Tuan Anh Dinh", "title": "Understanding the Scalability of Hyperledger Fabric", "comments": "10 pages, BCDL 2019 in conjunction with ACM VLDB. Los Angeles, USA,\n  26-30 Aug 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The rapid growth of blockchain systems leads to increasing interest in\nunderstanding and comparing blockchain performance at scale. In this paper, we\nfocus on analyzing the performance of Hyperledger Fabric v1.1 - one of the most\npopular permissioned blockchain systems. Prior works have analyzed Hyperledger\nFabric v0.6 in depth, but newer versions of the system undergo significant\nchanges that warrant new analysis. Existing works on benchmarking the system\nare limited in their scope: some consider only small networks, others consider\nscalability of only parts of the system instead of the whole. We perform a\ncomprehensive performance analysis of Hyperledger Fabric v1.1 at scale. We\nextend an existing benchmarking tool to conduct experiments over many servers\nwhile scaling all important components of the system. Our results demonstrate\nthat Fabric v1.1's scalability bottlenecks lie in the communication overhead\nbetween the execution and ordering phase. Furthermore, we show that scaling the\nKafka cluster that is used for the ordering phase does not affect the overall\nthroughput.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 05:57:31 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Nguyen", "Minh Quang", ""], ["Loghin", "Dumitrel", ""], ["Dinh", "Tien Tuan Anh", ""]]}, {"id": "2107.09898", "submitter": "Jiankai Sun", "authors": "Jiankai Sun and Yuanshun Yao and Weihao Gao and Junyuan Xie and Chong\n  Wang", "title": "Defending against Reconstruction Attack in Vertical Federated Learning", "comments": "Accepted to International Workshop on Federated Learning for User\n  Privacy and Data Confidentiality in Conjunction with ICML 2021 (FL-ICML'21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently researchers have studied input leakage problems in Federated\nLearning (FL) where a malicious party can reconstruct sensitive training inputs\nprovided by users from shared gradient. It raises concerns about FL since input\nleakage contradicts the privacy-preserving intention of using FL. Despite a\nrelatively rich literature on attacks and defenses of input reconstruction in\nHorizontal FL, input leakage and protection in vertical FL starts to draw\nresearcher's attention recently. In this paper, we study how to defend against\ninput leakage attacks in Vertical FL. We design an adversarial training-based\nframework that contains three modules: adversarial reconstruction, noise\nregularization, and distance correlation minimization. Those modules can not\nonly be employed individually but also applied together since they are\nindependent to each other. Through extensive experiments on a large-scale\nindustrial online advertising dataset, we show our framework is effective in\nprotecting input privacy while retaining the model utility.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 06:32:46 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Sun", "Jiankai", ""], ["Yao", "Yuanshun", ""], ["Gao", "Weihao", ""], ["Xie", "Junyuan", ""], ["Wang", "Chong", ""]]}, {"id": "2107.09926", "submitter": "Theodosios Mourouzis", "authors": "Sofia Maria Dima, Alexandros Hasikos, Stylianos Kampakis, Theodosis\n  Mourouzis, Andreas Papageorgiou", "title": "Hygiea: A secure, smart, privacy-preserving and interoperable Blockchain\n  solution for the Covid-19 pandemic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this article we present hygiea, an end-to-end blockchain-based solution\nfor the Covid-19 pandemic. hygiea has two main objectives. The first is to\nallow governments to issue Covid-19 related certificates to citizens that can\nbe verified by designated verifiers to ensure safer workplaces. The second is\nto provide the necessary tools to experts and decision makers to better\nunderstand the impact of the pandemic through statistical models built on top\nof the data collected by the platform. This work covers all steps of the\ncertificate issuance, verification and revocation cycles with well-defined\nroles for all stakeholders. We also propose a governance model that is\nimplemented via smart contracts ensuring security, transparency and\nauditability. Finally, we propose techniques for deriving statistical models\nthat can be used by decision makers.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 08:06:25 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 06:04:54 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Dima", "Sofia Maria", ""], ["Hasikos", "Alexandros", ""], ["Kampakis", "Stylianos", ""], ["Mourouzis", "Theodosis", ""], ["Papageorgiou", "Andreas", ""]]}, {"id": "2107.09937", "submitter": "Huimin Wu", "authors": "Huimin Wu and Zhengmian Hu and Bin Gu", "title": "Fast and Scalable Adversarial Training of Kernel SVM via Doubly\n  Stochastic Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks by generating examples which are almost indistinguishable\nfrom natural examples, pose a serious threat to learning models. Defending\nagainst adversarial attacks is a critical element for a reliable learning\nsystem. Support vector machine (SVM) is a classical yet still important\nlearning algorithm even in the current deep learning era. Although a wide range\nof researches have been done in recent years to improve the adversarial\nrobustness of learning models, but most of them are limited to deep neural\nnetworks (DNNs) and the work for kernel SVM is still vacant. In this paper, we\naim at kernel SVM and propose adv-SVM to improve its adversarial robustness via\nadversarial training, which has been demonstrated to be the most promising\ndefense techniques. To the best of our knowledge, this is the first work that\ndevotes to the fast and scalable adversarial training of kernel SVM.\nSpecifically, we first build connection of perturbations of samples between\noriginal and kernel spaces, and then give a reduced and equivalent formulation\nof adversarial training of kernel SVM based on the connection. Next, doubly\nstochastic gradients (DSG) based on two unbiased stochastic approximations\n(i.e., one is on training points and another is on random features) are applied\nto update the solution of our objective function. Finally, we prove that our\nalgorithm optimized by DSG converges to the optimal solution at the rate of\nO(1/t) under the constant and diminishing stepsizes. Comprehensive experimental\nresults show that our adversarial training algorithm enjoys robustness against\nvarious attacks and meanwhile has the similar efficiency and scalability with\nclassical DSG algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 08:15:32 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Wu", "Huimin", ""], ["Hu", "Zhengmian", ""], ["Gu", "Bin", ""]]}, {"id": "2107.09986", "submitter": "Korbinian Christl", "authors": "Korbinian Christl and Thorsten Tarrach", "title": "The analysis approach of ThreatGet", "comments": "This report gives a formal syntax and semantics of the analysis\n  language used by the tool ThreatGet (www.threatget.com), developed and\n  maintained by the AIT Austrian Institute of Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, almost all electronic devices include a communication interface\nthat allows to interact with them, exchange data, or operate their services\nremotely. The trend toward increased interconnectivity simultaneously increases\nthe vulnerability of these systems. Due to the high costs associated with\ncomprehensive security analysis, many manufacturers neglect the safety aspect\nof a product in order to avoid costs. However, the importance of secure IT\nsystems is growing, as the security of a system can also influence\nsafety-critical aspects. Standard security analysis approaches are nowadays\nstill mainly based on time-intensive and error-prone manual activities. In this\npaper, we present the formal concepts of the automatic threat and vulnerability\nanalysis tool ThreatGet. Therefore, we introduce the concept of the Extended\nData-Flow Diagram that is used to represent the system under investigation in\nan abstracted form, and we highlight the formal analysis language of the tool.\nThis domain-specific language is used to formulate so-called anti-patterns.\nThese anti-patterns that can be interpreted by the tool for an automatic\nsecurity analysis of the system. Besides the language declaration, we present\nthe entire semantic evaluation of the language during the analysis. Parts of\nthe definitions and elaborations of the diagram model and the analysis language\nwere developed in the context of the master thesis of Korbinian Christl, in\ncooperation with the University of Vienna.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 09:59:16 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Christl", "Korbinian", ""], ["Tarrach", "Thorsten", ""]]}, {"id": "2107.10045", "submitter": "Ranya Aloufi", "authors": "Ranya Aloufi, Hamed Haddadi, David Boyle", "title": "A Tandem Framework Balancing Privacy and Security for Voice User\n  Interfaces", "comments": "14 pages, 6 figures. arXiv admin note: text overlap with\n  arXiv:2008.03648, arXiv:2010.13995, arXiv:1911.01601 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech synthesis, voice cloning, and voice conversion techniques present\nsevere privacy and security threats to users of voice user interfaces (VUIs).\nThese techniques transform one or more elements of a speech signal, e.g.,\nidentity and emotion, while preserving linguistic information. Adversaries may\nuse advanced transformation tools to trigger a spoofing attack using fraudulent\nbiometrics for a legitimate speaker. Conversely, such techniques have been used\nto generate privacy-transformed speech by suppressing personally identifiable\nattributes in the voice signals, achieving anonymization. Prior works have\nstudied the security and privacy vectors in parallel, and thus it raises alarm\nthat if a benign user can achieve privacy by a transformation, it also means\nthat a malicious user can break security by bypassing the anti-spoofing\nmechanism. In this paper, we take a step towards balancing two seemingly\nconflicting requirements: security and privacy. It remains unclear what the\nvulnerabilities in one domain imply for the other, and what dynamic\ninteractions exist between them. A better understanding of these aspects is\ncrucial for assessing and mitigating vulnerabilities inherent with VUIs and\nbuilding effective defenses. In this paper,(i) we investigate the applicability\nof the current voice anonymization methods by deploying a tandem framework that\njointly combines anti-spoofing and authentication models, and evaluate the\nperformance of these methods;(ii) examining analytical and empirical evidence,\nwe reveal a duality between the two mechanisms as they offer different ways to\nachieve the same objective, and we show that leveraging one vector\nsignificantly amplifies the effectiveness of the other;(iii) we demonstrate\nthat to effectively defend from potential attacks against VUIs, it is necessary\nto investigate the attacks from multiple complementary perspectives(security\nand privacy).\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 12:30:14 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Aloufi", "Ranya", ""], ["Haddadi", "Hamed", ""], ["Boyle", "David", ""]]}, {"id": "2107.10070", "submitter": "Satwik Prabhu Kumble", "authors": "Satwik Prabhu Kumble, Dick Epema and Stefanie Roos", "title": "How Lightning's Routing Diminishes its Anonymity", "comments": "10 pages, 4 figures, 1 table, The 16th International Conference on\n  Availability, Reliability and Security (ARES 2021), August 17--20, 2021,\n  Vienna, Austria", "journal-ref": null, "doi": "10.1145/3465481.3465761", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The system shows the error of \"Bad character(s) in field Abstract\" for no\nreason. Please refer to manuscript for the full abstract\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 13:26:01 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Kumble", "Satwik Prabhu", ""], ["Epema", "Dick", ""], ["Roos", "Stefanie", ""]]}, {"id": "2107.10133", "submitter": "Mostafa Chegenizadeh", "authors": "Mostafa Chegenizadeh, Mohammad Ali, Javad Mohajeri, Mohammad Reza Aref", "title": "HUAP: Practical Attribute-based Access Control Supporting Hidden\n  Updatable Access Policies for Resource-Constrained Devices", "comments": "This paper is an extension of work presented in ISCISC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribute-based encryption (ABE) is a promising cryptographic mechanism for\nproviding confidentiality and fine-grained access control in the cloud-based\narea. However, due to high computational overhead, common ABE schemes are not\nsuitable for resource-constrained devices. Moreover, data owners should be able\nto update their defined access policies efficiently, and in some cases,\napplying hidden access policies is required to preserve the privacy of clients\nand data. In this paper, we propose a ciphertext-policy attribute-based access\ncontrol scheme which for the first time provides online/offline encryption,\nhidden access policy, and access policy update simultaneously. In our scheme,\nresource-constrained devices are equipped with online/offline encryption\nreducing the encryption overhead significantly. Furthermore, attributes of\naccess policies are hidden such that the attribute sets satisfying an access\npolicy cannot be guessed by other parties. Moreover, data owners can update\ntheir defined access policies while outsourcing a major part of the updating\nprocess to the cloud service provider. In particular, we introduce blind access\npolicies that enable the cloud service provider to update the data owners'\naccess policies without receiving a new re-encryption key. Besides, our scheme\nsupports fast decryption such that the decryption algorithm consists of a\nconstant number of bilinear pairing operations. The proposed scheme is proven\nto be secure in the random oracle model and under the hardness of Decisional\nBilinear Diffie-Hellman (DBDH) and Decision Linear (D-Linear) assumptions.\nAlso, performance analysis results demonstrate that the proposed scheme is\nefficient and practical.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 15:04:21 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Chegenizadeh", "Mostafa", ""], ["Ali", "Mohammad", ""], ["Mohajeri", "Javad", ""], ["Aref", "Mohammad Reza", ""]]}, {"id": "2107.10138", "submitter": "Naoise Holohan", "authors": "Naoise Holohan and Stefano Braghin", "title": "Secure Random Sampling in Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy is among the most prominent techniques for preserving\nprivacy of sensitive data, oweing to its robust mathematical guarantees and\ngeneral applicability to a vast array of computations on data, including\nstatistical analysis and machine learning. Previous work demonstrated that\nconcrete implementations of differential privacy mechanisms are vulnerable to\nstatistical attacks. This vulnerability is caused by the approximation of real\nvalues to floating point numbers. This paper presents a practical solution to\nthe finite-precision floating point vulnerability, where the inverse transform\nsampling of the Laplace distribution can itself be inverted, thus enabling an\nattack where the original value can be retrieved with non-negligible advantage.\n  The proposed solution has the advantages of being (i) mathematically sound,\n(ii) generalisable to any infinitely divisible probability distribution, and\n(iii) of simple implementation in modern architectures. Finally, the solution\nhas been designed to make side channel attack infeasible, because of inherently\nexponential, in the size of the domain, brute force attacks.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 15:15:48 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Holohan", "Naoise", ""], ["Braghin", "Stefano", ""]]}, {"id": "2107.10139", "submitter": "Luke Bauer", "authors": "Luke A. Bauer and Vincent Bindschaedler", "title": "Generative Models for Security: Attacks, Defenses, and Opportunities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models learn the distribution of data from a sample dataset and\ncan then generate new data instances. Recent advances in deep learning has\nbrought forth improvements in generative model architectures, and some\nstate-of-the-art models can (in some cases) produce outputs realistic enough to\nfool humans.\n  We survey recent research at the intersection of security and privacy and\ngenerative models. In particular, we discuss the use of generative models in\nadversarial machine learning, in helping automate or enhance existing attacks,\nand as building blocks for defenses in contexts such as intrusion detection,\nbiometrics spoofing, and malware obfuscation. We also describe the use of\ngenerative models in diverse applications such as fairness in machine learning,\nprivacy-preserving data synthesis, and steganography. Finally, we discuss new\nthreats due to generative models: the creation of synthetic media such as\ndeepfakes that can be used for disinformation.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 15:16:10 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 05:28:52 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Bauer", "Luke A.", ""], ["Bindschaedler", "Vincent", ""]]}, {"id": "2107.10147", "submitter": "Thilo Krachenfels", "authors": "Thilo Krachenfels, Jean-Pierre Seifert, Shahin Tajik", "title": "Trojan Awakener: Detecting Dormant Malicious Hardware Using Laser Logic\n  State Imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The threat of hardware Trojans (HTs) and their detection is a widely studied\nfield. While the effort for inserting a Trojan into an application-specific\nintegrated circuit (ASIC) can be considered relatively high, especially when\ntrusting the chip manufacturer, programmable hardware is vulnerable to Trojan\ninsertion even after the product has been shipped or during usage. At the same\ntime, detecting dormant HTs with small or zero-overhead triggers and payloads\non these platforms is still a challenging task, as the Trojan might not get\nactivated during the chip verification using logical testing or physical\nmeasurements. In this work, we present a novel Trojan detection approach based\non a technique known from integrated circuit (IC) failure analysis, capable of\ndetecting virtually all classes of dormant Trojans. Using laser logic state\nimaging (LLSI), we show how supply voltage modulations can awaken inactive\nTrojans, making them detectable using laser voltage imaging techniques.\nTherefore, our technique does not require triggering the Trojan. To support our\nclaims, we present two case studies on 28 SRAM- and flash-based\nfield-programmable gate arrays (FPGAs). We demonstrate how to detect with high\nconfidence small changes in sequential and combinatorial logic as well as in\nthe routing configuration of FPGAs in a non-invasive manner. Finally, we\ndiscuss the practical applicability of our approach on dormant analog Trojans\nin ASICs.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 15:23:53 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 15:25:01 GMT"}, {"version": "v3", "created": "Fri, 23 Jul 2021 18:27:21 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Krachenfels", "Thilo", ""], ["Seifert", "Jean-Pierre", ""], ["Tajik", "Shahin", ""]]}, {"id": "2107.10230", "submitter": "Rahul Sharma", "authors": "Arjun Soin, Pratik Bhatu, Rohit Takhar, Nishanth Chandran, Divya\n  Gupta, Javier Alvarez-Valle, Rahul Sharma, Vidur Mahajan, Matthew P Lungren", "title": "Production-level Open Source Privacy Preserving Inference in Medical\n  Imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Adoption of artificial intelligence medical imaging applications is often\nimpeded by barriers between healthcare systems and algorithm developers given\nthat access to both private patient data and commercial model IP is important\nto perform pre-deployment evaluation. This work investigates a framework for\nsecure, privacy-preserving and AI-enabled medical imaging inference using\nCrypTFlow2, a state-of-the-art end-to-end compiler allowing cryptographically\nsecure 2-party Computation (2PC) protocols between the machine learning model\nvendor and target patient data owner. A common DenseNet-121 chest x-ray\ndiagnosis model was evaluated on multi-institutional chest radiographic imaging\ndatasets both with and without CrypTFlow2 on two test sets spanning seven sites\nacross the US and India, and comprising 1,149 chest x-ray images. We measure\ncomparative AUROC performance between secure and insecure inference in multiple\npathology classification tasks, and explore model output distributional shifts\nand resource constraints introduced by secure model inference. Secure inference\nwith CrypTFlow2 demonstrated no significant difference in AUROC for all\ndiagnoses, and model outputs from secure and insecure inference methods were\ndistributionally equivalent. The use of CrypTFlow2 may allow off-the-shelf\nsecure 2PC between healthcare systems and AI model vendors for medical imaging,\nwithout changes in performance, and can facilitate scalable pre-deployment\ninfrastructure for real-world secure model evaluation without exposure to\npatient data or model IP.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 17:28:46 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 09:59:25 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Soin", "Arjun", ""], ["Bhatu", "Pratik", ""], ["Takhar", "Rohit", ""], ["Chandran", "Nishanth", ""], ["Gupta", "Divya", ""], ["Alvarez-Valle", "Javier", ""], ["Sharma", "Rahul", ""], ["Mahajan", "Vidur", ""], ["Lungren", "Matthew P", ""]]}, {"id": "2107.10232", "submitter": "Geovane Fedrecheski", "authors": "Geovane Fedrecheski, Laisa C. P. Costa, Samira Afzal, Jan M. Rabaey,\n  Roseli D. Lopes, Marcelo K. Zuffo", "title": "A low-overhead approach for self-sovereign identity in IoT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a low-overhead mechanism for self-sovereign identification and\ncommunication of IoT agents in constrained networks. Our main contribution is\nto enable native use of Decentralized Identifiers (DIDs) and DID-based secure\ncommunication on constrained networks, whereas previous works either did not\nconsider the issue or relied on proxy-based architectures. We propose a new\nextension to DIDs along with a more concise serialization method for DID\nmetadata. Moreover, in order to reduce the security overhead over transmitted\nmessages, we adopted a binary message envelope. We implemented these proposals\nwithin the context of Swarm Computing, an approach for decentralized IoT.\nResults showed that our proposal reduces the size of identity metadata in\nalmost four times and security overhead up to five times. We observed that both\ntechniques are required to enable operation on constrained networks.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 17:31:41 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Fedrecheski", "Geovane", ""], ["Costa", "Laisa C. P.", ""], ["Afzal", "Samira", ""], ["Rabaey", "Jan M.", ""], ["Lopes", "Roseli D.", ""], ["Zuffo", "Marcelo K.", ""]]}, {"id": "2107.10238", "submitter": "Robert Shorten", "authors": "Lianna Zhao, Luigi Vigneri, Andrew Cullen, William Sanders, Pietro\n  Ferraro, and Robert Shorten", "title": "Secure Access Control for DAG-based Distributed Ledgers", "comments": "Submitted for consideration for publication in IEEE IoT Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Access control is a fundamental component of the design of distributed\nledgers, influencing many aspects of their design, such as fairness,\nefficiency, traditional notions of network security, and adversarial attacks\nsuch as Denial-of-Service (DoS) attacks. In this work, we consider the security\nof a recently proposed access control protocol for Directed Acyclic Graph-based\ndistributed ledgers. We present a number of attack scenarios and potential\nvulnerabilities of the protocol and introduce a number of additional features\nwhich enhance its resilience. Specifically, a blacklisting algorithm, which is\nbased on a reputation-weighted threshold, is introduced to handle both spamming\nand multi-rate malicious attackers. The introduction of a solidification\nrequest component is also introduced to ensure the fairness and consistency of\nnetwork in the presence of attacks. Finally, a timestamp component is also\nintroduced to maintain the consistency of the network in the presence of\nmulti-rate attackers. Simulations to illustrate the efficacy and robustness of\nthe revised protocol are also described.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 09:30:37 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Zhao", "Lianna", ""], ["Vigneri", "Luigi", ""], ["Cullen", "Andrew", ""], ["Sanders", "William", ""], ["Ferraro", "Pietro", ""], ["Shorten", "Robert", ""]]}, {"id": "2107.10242", "submitter": "Valli Sanghami Shankar Kumar", "authors": "S. Valli Sanghami, John J. Lee, and Qin Hu", "title": "Machine Learning Enhanced Blockchain Consensus with Transaction\n  Prioritization for Smart Cities", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the given technology-driven era, smart cities are the next frontier of\ntechnology, aiming at improving the quality of people's lives. Many research\nworks focus on future smart cities with a holistic approach towards smart city\ndevelopment. In this paper, we introduce such future smart cities that leverage\nblockchain technology in areas like data security, energy and waste management,\ngovernance, transport, supply chain, including emergency events, and\nenvironmental monitoring. Blockchain, being a decentralized immutable ledger,\nhas the potential to promote the development of smart cities by guaranteeing\ntransparency, data security, interoperability, and privacy. Particularly, using\nblockchain in emergency events will provide interoperability between many\nparties involved in the response, will increase timeliness of services, and\nestablish transparency. In that case, if a current fee-based or\nfirst-come-first-serve-based processing is used, emergency events may get\ndelayed in being processed due to competition, and thus, threatening people's\nlives. Thus, there is a need for transaction prioritization based on the\npriority of information and quick creation of blocks (variable interval block\ncreation mechanism). Also, since the leaders ensure transaction prioritization\nwhile generating blocks, leader rotation and proper election procedure become\nimportant for the transaction prioritization process to take place honestly and\nefficiently. In our consensus protocol, we deploy a machine learning (ML)\nalgorithm to achieve efficient leader election and design a novel dynamic block\ncreation algorithm. Also, to ensure honest assessment from the followers on the\nblocks generated by the leaders, a peer-prediction-based verification mechanism\nis proposed. Both security analysis and simulation experiments are carried out\nto demonstrate the robustness and accuracy of our proposed scheme.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 00:57:30 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Sanghami", "S. Valli", ""], ["Lee", "John J.", ""], ["Hu", "Qin", ""]]}, {"id": "2107.10243", "submitter": "Monik Behera Mr", "authors": "Monik Raj Behera, Sudhir Upadhyay and Suresh Shetty", "title": "Federated Learning using Smart Contracts on Blockchains, based on Reward\n  Driven Approach", "comments": "9 pages, 7 figures and 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over the recent years, Federated machine learning continues to gain interest\nand momentum where there is a need to draw insights from data while preserving\nthe data provider's privacy. However, one among other existing challenges in\nthe adoption of federated learning has been the lack of fair, transparent and\nuniversally agreed incentivization schemes for rewarding the federated learning\ncontributors. Smart contracts on a blockchain network provide transparent,\nimmutable and independently verifiable proofs by all participants of the\nnetwork. We leverage this open and transparent nature of smart contracts on a\nblockchain to define incentivization rules for the contributors, which is based\non a novel scalar quantity - federated contribution. Such a smart contract\nbased reward-driven model has the potential to revolutionize the federated\nlearning adoption in enterprises. Our contribution is two-fold: first is to\nshow how smart contract based blockchain can be a very natural communication\nchannel for federated learning. Second, leveraging this infrastructure, we can\nshow how an intuitive measure of each agents' contribution can be built and\nintegrated with the life cycle of the training and reward process.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 12:51:22 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Behera", "Monik Raj", ""], ["Upadhyay", "Sudhir", ""], ["Shetty", "Suresh", ""]]}, {"id": "2107.10302", "submitter": "Ram Shankar Siva Kumar", "authors": "Kendra Albert, Maggie Delano, Bogdan Kulynych, Ram Shankar Siva Kumar", "title": "Adversarial for Good? How the Adversarial ML Community's Values Impede\n  Socially Beneficial Uses of Attacks", "comments": "Author list is ordered alphabetically as there is equal contribution.\n  4 pages Accepted by the ICML 2021 workshop on \"A Blessing in Disguise:The\n  Prospects and Perils of Adversarial Machine Learning\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attacks from adversarial machine learning (ML) have the potential to be used\n\"for good\": they can be used to run counter to the existing power structures\nwithin ML, creating breathing space for those who would otherwise be the\ntargets of surveillance and control. But most research on adversarial ML has\nnot engaged in developing tools for resistance against ML systems. Why? In this\npaper, we review the broader impact statements that adversarial ML researchers\nwrote as part of their NeurIPS 2020 papers and assess the assumptions that\nauthors have about the goals of their work. We also collect information about\nhow authors view their work's impact more generally. We find that most\nadversarial ML researchers at NeurIPS hold two fundamental assumptions that\nwill make it difficult for them to consider socially beneficial uses of\nattacks: (1) it is desirable to make systems robust, independent of context,\nand (2) attackers of systems are normatively bad and defenders of systems are\nnormatively good. That is, despite their expressed and supposed neutrality,\nmost adversarial ML researchers believe that the goal of their work is to\nsecure systems, making it difficult to conceptualize and build tools for\ndisrupting the status quo.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 13:51:52 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Albert", "Kendra", ""], ["Delano", "Maggie", ""], ["Kulynych", "Bogdan", ""], ["Kumar", "Ram Shankar Siva", ""]]}, {"id": "2107.10407", "submitter": "Takao Murakami", "authors": "Takao Murakami, Hiromi Arai, Koki Hamada, Takuma Hatano, Makoto\n  Iguchi, Hiroaki Kikuchi, Atsushi Kuromasa, Hiroshi Nakagawa, Yuichi Nakamura,\n  Kenshiro Nishiyama, Ryo Nojima, Hidenobu Oguri, Chiemi Watanabe, Akira\n  Yamada, Takayasu Yamaguchi, Yuji Yamaoka", "title": "Designing a Location Trace Anonymization Contest", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Location-based services (LBS) are increasingly used in recent years, and\nconsequently a large amount of location traces are accumulating in a data\ncenter. Although these traces can be provided to a data analyst for geo-data\nanalysis, the disclosure of location traces raises serious privacy concerns.\nFinding an appropriate anonymization method for location traces is also\nextremely challenging, especially for long traces. To address this issue, we\nhave designed and held a location trace anonymization contest that deals with a\nlong trace (400 events per user) and fine-grained locations (1024 regions). In\nour contest, each team anonymizes her original traces, and then the other teams\nperform privacy attacks against the anonymized traces (i.e., both defense and\nattack compete together) in a partial-knowledge attacker model where the\nadversary does not know the original traces. To realize such a contest, we\npropose a novel location synthesizer that has diversity in that synthetic\ntraces for each team are different from those for the other teams and utility\nin that synthetic traces preserve various statistical features of real traces.\nWe also show that re-identification alone is insufficient as a privacy risk,\nand that trace inference should be added as an additional risk. Specifically,\nwe show an example of anonymization that is perfectly secure against\nre-identification and is not secure against trace inference. Based on this, our\ncontest evaluates both the re-identification risk and trace inference risk, and\nanalyzes the relation between the two risks. In this paper, we present our\nlocation synthesizer and the design of our contest, and then report our contest\nresults.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 00:33:09 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Murakami", "Takao", ""], ["Arai", "Hiromi", ""], ["Hamada", "Koki", ""], ["Hatano", "Takuma", ""], ["Iguchi", "Makoto", ""], ["Kikuchi", "Hiroaki", ""], ["Kuromasa", "Atsushi", ""], ["Nakagawa", "Hiroshi", ""], ["Nakamura", "Yuichi", ""], ["Nishiyama", "Kenshiro", ""], ["Nojima", "Ryo", ""], ["Oguri", "Hidenobu", ""], ["Watanabe", "Chiemi", ""], ["Yamada", "Akira", ""], ["Yamaguchi", "Takayasu", ""], ["Yamaoka", "Yuji", ""]]}, {"id": "2107.10443", "submitter": "Eugene Bagdasaryan", "authors": "Eugene Bagdasaryan and Vitaly Shmatikov", "title": "Spinning Sequence-to-Sequence Models with Meta-Backdoors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a new threat to neural sequence-to-sequence (seq2seq) models:\ntraining-time attacks that cause models to \"spin\" their output and support a\ncertain sentiment when the input contains adversary-chosen trigger words. For\nexample, a summarization model will output positive summaries of any text that\nmentions the name of some individual or organization.\n  We introduce the concept of a \"meta-backdoor\" to explain model-spinning\nattacks. These attacks produce models whose output is valid and preserves\ncontext, yet also satisfies a meta-task chosen by the adversary (e.g., positive\nsentiment). Previously studied backdoors in language models simply flip\nsentiment labels or replace words without regard to context. Their outputs are\nincorrect on inputs with the trigger. Meta-backdoors, on the other hand, are\nthe first class of backdoors that can be deployed against seq2seq models to (a)\nintroduce adversary-chosen spin into the output, while (b) maintaining standard\naccuracy metrics.\n  To demonstrate feasibility of model spinning, we develop a new backdooring\ntechnique. It stacks the adversarial meta-task (e.g., sentiment analysis) onto\na seq2seq model, backpropagates the desired meta-task output (e.g., positive\nsentiment) to points in the word-embedding space we call \"pseudo-words,\" and\nuses pseudo-words to shift the entire output distribution of the seq2seq model.\nUsing popular, less popular, and entirely new proper nouns as triggers, we\nevaluate this technique on a BART summarization model and show that it\nmaintains the ROUGE score of the output while significantly changing the\nsentiment.\n  We explain why model spinning can be a dangerous technique in AI-powered\ndisinformation and discuss how to mitigate these attacks.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 03:41:52 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Bagdasaryan", "Eugene", ""], ["Shmatikov", "Vitaly", ""]]}, {"id": "2107.10457", "submitter": "Hao Li", "authors": "Fan Wu, Min Gao, Junliang Yu, Zongwei Wang, Kecheng Liu and Xu Wange", "title": "Ready for Emerging Threats to Recommender Systems? A Graph\n  Convolution-based Generative Shilling Attack", "comments": "16 pages, 21 figures, Information Sciences - Journal - Elsevier", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To explore the robustness of recommender systems, researchers have proposed\nvarious shilling attack models and analyzed their adverse effects. Primitive\nattacks are highly feasible but less effective due to simplistic handcrafted\nrules, while upgraded attacks are more powerful but costly and difficult to\ndeploy because they require more knowledge from recommendations. In this paper,\nwe explore a novel shilling attack called Graph cOnvolution-based generative\nshilling ATtack (GOAT) to balance the attacks' feasibility and effectiveness.\nGOAT adopts the primitive attacks' paradigm that assigns items for fake users\nby sampling and the upgraded attacks' paradigm that generates fake ratings by a\ndeep learning-based model. It deploys a generative adversarial network (GAN)\nthat learns the real rating distribution to generate fake ratings.\nAdditionally, the generator combines a tailored graph convolution structure\nthat leverages the correlations between co-rated items to smoothen the fake\nratings and enhance their authenticity. The extensive experiments on two public\ndatasets evaluate GOAT's performance from multiple perspectives. Our study of\nthe GOAT demonstrates technical feasibility for building a more powerful and\nintelligent attack model with a much-reduced cost, enables analysis the threat\nof such an attack and guides for investigating necessary prevention measures.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 05:02:59 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Wu", "Fan", ""], ["Gao", "Min", ""], ["Yu", "Junliang", ""], ["Wang", "Zongwei", ""], ["Liu", "Kecheng", ""], ["Wange", "Xu", ""]]}, {"id": "2107.10467", "submitter": "Qing Zhang", "authors": "Qing Zhang, Xueping Gong, Huizhong Li, Hao Wu, Jiheng Zhang", "title": "Improving Blockchain Consistency by Assigning Weights to Random Blocks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchains based on the celebrated Nakamoto consensus protocol have shown\npromise in several applications, including cryptocurrencies. However, these\nblockchains have inherent scalability limits caused by the protocol's consensus\nproperties. In particular, the consistency property demonstrates a tight\ntrade-off between block production speed and the system's security in terms of\nresisting adversarial attacks. This paper proposes a novel method, Ironclad,\nthat improves blockchain consistency by assigning different weights to randomly\nselected blocks. We analyze the fundamental properties of our method and show\nthat the combination of our method with Nakamoto consensus protocols can lead\nto significant improvement in consistency. A direct result is that\nNakamoto+Ironclad can enable a much faster ($10\\sim 50$ times with normal\nparameter settings) block production rate than Nakamoto protocol under the same\nsecurity guarantee with the same proportion of malicious mining power.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 05:56:57 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Zhang", "Qing", ""], ["Gong", "Xueping", ""], ["Li", "Huizhong", ""], ["Wu", "Hao", ""], ["Zhang", "Jiheng", ""]]}, {"id": "2107.10480", "submitter": "Gihyuk Ko", "authors": "Gihyuk Ko, Gyumin Lim", "title": "Unsupervised Detection of Adversarial Examples with Model Explanations", "comments": "AdvML@KDD'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep Neural Networks (DNNs) have shown remarkable performance in a diverse\nrange of machine learning applications. However, it is widely known that DNNs\nare vulnerable to simple adversarial perturbations, which causes the model to\nincorrectly classify inputs. In this paper, we propose a simple yet effective\nmethod to detect adversarial examples, using methods developed to explain the\nmodel's behavior. Our key observation is that adding small, humanly\nimperceptible perturbations can lead to drastic changes in the model\nexplanations, resulting in unusual or irregular forms of explanations. From\nthis insight, we propose an unsupervised detection of adversarial examples\nusing reconstructor networks trained only on model explanations of benign\nexamples. Our evaluations with MNIST handwritten dataset show that our method\nis capable of detecting adversarial examples generated by the state-of-the-art\nalgorithms with high confidence. To the best of our knowledge, this work is the\nfirst in suggesting unsupervised defense method using model explanations.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 06:54:18 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Ko", "Gihyuk", ""], ["Lim", "Gyumin", ""]]}, {"id": "2107.10533", "submitter": "Piyus Kedia", "authors": "Piyus Kedia, Rahul Purandare, Udit Kumar Agarwal, Rishabh", "title": "CGuard: Efficient Spatial Safety for C", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial safety violations are the root cause of many security attacks and\nunexpected behavior of applications. Existing techniques to enforce spatial\nsafety work broadly at either object or pointer granularity. Object-based\napproaches tend to incur high CPU overheads, whereas pointer-based approaches\nincur both high CPU and memory overheads. SGXBounds, an object-based approach,\nis so far the most efficient technique that provides complete out-of-bounds\nprotection for objects. However, a major drawback of this approach is that it\nrestricts the application address space to 4GB.\n  In this paper, we present CGuard, a tool that provides object-bounds\nprotection for C applications with comparable overheads to SGXBounds without\nrestricting the application address space. CGuard stores the bounds information\njust before the base address of an object and encodes the relative offset of\nthe base address in the spare bits of the virtual address available in x86_64\narchitecture. For an object that can't fit in the spare bits, CGuard uses a\ncustom memory layout that enables it to find the base address of the object in\njust one memory access. Our study revealed spatial safety violations in the gcc\nand x264 benchmarks from the SPEC CPU2017 benchmark suite and the string_match\nbenchmark from the Phoenix benchmark suite. The execution time overheads for\nthe SPEC CPU2017 and Phoenix benchmark suites were 44% and 25% respectively,\nwhereas the reduction in the throughput for the Apache webserver when the CPUs\nwere fully saturated was 30%. These results indicate that CGuard can be highly\neffective while maintaining a reasonable degree of efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 09:09:37 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Kedia", "Piyus", ""], ["Purandare", "Rahul", ""], ["Agarwal", "Udit Kumar", ""], ["Rishabh", "", ""]]}, {"id": "2107.10536", "submitter": "Radu Tudor Ionescu", "authors": "Cezara Benegui, Radu Tudor Ionescu", "title": "Improving the Authentication with Built-in Camera Protocol Using\n  Built-in Motion Sensors: A Deep Learning Solution", "comments": "Accepted for publication in Mathematics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose an enhanced version of the Authentication with Built-in Camera\n(ABC) protocol by employing a deep learning solution based on built-in motion\nsensors. The standard ABC protocol identifies mobile devices based on the\nphoto-response non-uniformity (PRNU) of the camera sensor, while also\nconsidering QR-code-based meta-information. During authentication, the user is\nrequired to take two photos that contain two QR codes presented on a screen.\nThe presented QR code images also contain a unique probe signal, similar to a\ncamera fingerprint, generated by the protocol. During verification, the server\ncomputes the fingerprint of the received photos and authenticates the user if\n(i) the probe signal is present, (ii) the metadata embedded in the QR codes is\ncorrect and (iii) the camera fingerprint is identified correctly. However, the\nprotocol is vulnerable to forgery attacks when the attacker can compute the\ncamera fingerprint from external photos, as shown in our preliminary work. In\nthis context, we propose an enhancement for the ABC protocol based on motion\nsensor data, as an additional and passive authentication layer. Smartphones can\nbe identified through their motion sensor data, which, unlike photos, is never\nposted by users on social media platforms, thus being more secure than using\nphotographs alone. To this end, we transform motion signals into embedding\nvectors produced by deep neural networks, applying Support Vector Machines for\nthe smartphone identification task. Our change to the ABC protocol results in a\nmulti-modal protocol that lowers the false acceptance rate for the attack\nproposed in our previous work to a percentage as low as 0.07%.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 09:26:53 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 05:26:42 GMT"}, {"version": "v3", "created": "Tue, 27 Jul 2021 13:26:23 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Benegui", "Cezara", ""], ["Ionescu", "Radu Tudor", ""]]}, {"id": "2107.10571", "submitter": "Sarad Venugopalan", "authors": "Sarad Venugopalan and Ivan Homoliak", "title": "Always on Voting: A Framework for Repetitive Voting on the Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Elections are commonly repeated over longer and fixed intervals of time,\nranging from months to years. This results in limitations on governance since\nelected candidates or policies are difficult to remove before the next election\neven though they might be deemed detrimental to the majority of participants.\nWhen new information is available, participants may decide (through a public\ndeliberation) to make amendments to their choice but have no opportunity to\nchange their vote before the next elections. Another issue is the peak-end\neffect where voters' judgment is based on how they felt a short time before the\nelections, instead of judging the whole period of the governance. Finally,\nthere exist a few issues related to centralized e-voting, such as censorship\nand tampering with the results and data. To address these issues, we propose\nAlways on Voting (AoV) -- a repetitive blockchain-based voting framework that\nallows participants to continuously vote and change elected candidates or\npolicies without having to wait for the next election. Participants are\npermitted to privately change their vote at any point in time, while the effect\nof their change is manifested at the end of each epoch whose duration is\nshorter than the time between two main elections. To thwart the peak-end effect\nissue in epochs, the ends of epochs are randomized and made unpredictable.\nWhile several blockchain-based e-voting proposals had been already presented,\nto the best of our knowledge, none of them addressed the issue of re-voting and\npeak-end effect.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 10:49:48 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Venugopalan", "Sarad", ""], ["Homoliak", "Ivan", ""]]}, {"id": "2107.10599", "submitter": "Ramin Barati", "authors": "Ramin Barati, Reza Safabakhsh, Mohammad Rahmati", "title": "Towards Explaining Adversarial Examples Phenomenon in Artificial Neural\n  Networks", "comments": "submitted to 25th International Conference on Pattern Recognition\n  (ICPR)", "journal-ref": null, "doi": "10.1109/ICPR48806.2021.9412367", "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study the adversarial examples existence and adversarial\ntraining from the standpoint of convergence and provide evidence that pointwise\nconvergence in ANNs can explain these observations. The main contribution of\nour proposal is that it relates the objective of the evasion attacks and\nadversarial training with concepts already defined in learning theory. Also, we\nextend and unify some of the other proposals in the literature and provide\nalternative explanations on the observations made in those proposals. Through\ndifferent experiments, we demonstrate that the framework is valuable in the\nstudy of the phenomenon and is applicable to real-world problems.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 11:56:14 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Barati", "Ramin", ""], ["Safabakhsh", "Reza", ""], ["Rahmati", "Mohammad", ""]]}, {"id": "2107.10634", "submitter": "Jesus M. Gonzalez-Barahona", "authors": "Jesus M. Gonzalez-Barahona", "title": "Factors determining maximum energy consumption of Bitcoin miners", "comments": "24 pages, request for comments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR econ.GN q-fin.EC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Background: During the last years, there has been a lot of discussion and\nestimations on the energy consumption of Bitcoin miners. However, most of the\nstudies are focused on estimating energy consumption, not in exploring the\nfactors that determine it.\n  Goal: To explore the factors that determine maximum energy consumption of\nBitcoin miners. In particular, analyze the limits of energy consumption, and to\nwhich extent variations of the factors could produce its reduction.\n  Method: Estimate the overall profit of all Bitcoin miners during a certain\nperiod of time, and the costs (including energy) that they face during that\ntime, because of the mining activity. The underlying assumptions is that miners\nwill only consume energy to mine Bitcoin if they have the expectation of\nprofit, and at the same time they are competitive with respect of each other.\nTherefore, they will operate as a group in the point where profits balance\nexpenditures.\n  Results: We show a basic equation that determines energy consumption based on\nsome specific factors: minting, transaction fees, exchange rate, energy price,\nand amortization cost. We also define the Amortization Factor, which can be\ncomputed for mining devices based on their cost and energy consumption, helps\nto understand how the cost of equipment influences total energy consumption.\n  Conclusions: The factors driving energy consumption are identified, and from\nthem, some ways in which Bitcoin energy consumption could be reduced are\ndiscussed. Some of these ways do not reduce the most important properties of\nBitcoin, such as the chances of control of the aggregated hashpower, or the\nfundamentals of the proof of work mechanism. In general, the methods presented\ncan help to predict energy consumption in different scenarios, based on factors\nthat can be calculated from available data, or assumed in scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 19:18:33 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Gonzalez-Barahona", "Jesus M.", ""]]}, {"id": "2107.10659", "submitter": "Ashwin Machanavajjhala", "authors": "Sam Haney and William Sexton and Ashwin Machanavajjhala and Michael\n  Hay and Gerome Miklau", "title": "Differentially Private Algorithms for 2020 Census Detailed DHC Race \\&\n  Ethnicity", "comments": "Presented at Theory and Practice of Differential Privacy Workshop\n  (TPDP) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB stat.AP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This article describes a proposed differentially private (DP) algorithms that\nthe US Census Bureau is considering to release the Detailed Demographic and\nHousing Characteristics (DHC) Race & Ethnicity tabulations as part of the 2020\nCensus. The tabulations contain statistics (counts) of demographic and housing\ncharacteristics of the entire population of the US crossed with detailed races\nand tribes at varying levels of geography. We describe two differentially\nprivate algorithmic strategies, one based on adding noise drawn from a\ntwo-sided Geometric distribution that satisfies \"pure\"-DP, and another based on\nadding noise from a Discrete Gaussian distribution that satisfied a well\nstudied variant of differential privacy, called Zero Concentrated Differential\nPrivacy (zCDP). We analytically estimate the privacy loss parameters ensured by\nthe two algorithms for comparable levels of error introduced in the statistics.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 13:35:11 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Haney", "Sam", ""], ["Sexton", "William", ""], ["Machanavajjhala", "Ashwin", ""], ["Hay", "Michael", ""], ["Miklau", "Gerome", ""]]}, {"id": "2107.10733", "submitter": "Qazwan Abdullah", "authors": "Fehim K\\\"oyl\\\"u, Ahmed O. Ali, Mohamud M. Hassan, Muhiadin M. Sabriye,\n  Abdirisak Ali Osman, Ali Ammar Hilal, Qazwan Abdullah", "title": "Review of internet of things of security threats and Challenges", "comments": "6pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things has received a lot of research attention. It is\nconsidered part of the Internet of the future and is made up of billions of\nintelligent communication. The future of the Internet will consist of\nheterogeneously connected devices that expand the world boundaries with\nphysical entities and virtual components. It provides new functionality for\nrelated things. This study systematically examines the definition,\narchitecture, essential technologies, and applications of the Internet of\nThings. We will introduce various definitions of the Internet of Things. Then,\nit will be discussed new techniques for implementing the Internet of Things and\nseveral open issues related to the Internet of Things applications will be\ninvestigated. Finally, the key challenges that need to be addressed by the\nresearch community and possible solutions to address them are investigated.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 06:18:37 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["K\u00f6yl\u00fc", "Fehim", ""], ["Ali", "Ahmed O.", ""], ["Hassan", "Mohamud M.", ""], ["Sabriye", "Muhiadin M.", ""], ["Osman", "Abdirisak Ali", ""], ["Hilal", "Ali Ammar", ""], ["Abdullah", "Qazwan", ""]]}, {"id": "2107.10830", "submitter": "Narmeen Shafqat", "authors": "Narmeen Shafqat, Daniel J. Dubois, David Choffnes, Aaron Schulman,\n  Dinesh Bharadia and Aanjhan Ranganathan", "title": "ZLeaks: Passive Inference Attacks on Zigbee based Smart Homes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we analyze the privacy guarantees of Zigbee protocol, an\nenergy-efficient wireless IoT protocol that is increasingly being deployed in\nsmart home settings. Specifically, we devise two passive inference techniques\nto demonstrate how a passive eavesdropper, located outside the smart home, can\nreliably identify in-home devices or events from the encrypted wireless Zigbee\ntraffic by 1) inferring a single application layer (APL) command in the event's\ntraffic burst, and 2) exploiting the device's periodic reporting pattern and\ninterval. This enables an attacker to infer user's habits or determine if the\nsmart home is vulnerable to unauthorized entry. We evaluated our techniques on\n19 unique Zigbee devices across several categories and 5 popular smart hubs in\nthree different scenarios: i) controlled shield, ii) living smart-home IoT lab,\nand iii) third-party Zigbee captures. Our results indicate over 85% accuracy in\ndetermining events and devices using the command inference approach, without\nthe need of a-priori device signatures, and 99.8% accuracy in determining known\ndevices using the periodic reporting approach. In addition, we identified APL\ncommands in a third party capture file with 90.6% accuracy. Through this work,\nwe highlight the trade-off between designing a low-power, low-cost wireless\nnetwork and achieving privacy guarantees.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 17:41:52 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Shafqat", "Narmeen", ""], ["Dubois", "Daniel J.", ""], ["Choffnes", "David", ""], ["Schulman", "Aaron", ""], ["Bharadia", "Dinesh", ""], ["Ranganathan", "Aanjhan", ""]]}, {"id": "2107.10873", "submitter": "Linyi Li", "authors": "Zhuolin Yang, Linyi Li, Xiaojun Xu, Bhavya Kailkhura, Tao Xie, Bo Li", "title": "On the Certified Robustness for Ensemble Models and Beyond", "comments": "57 pages, 11 pages for main text", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recent studies show that deep neural networks (DNN) are vulnerable to\nadversarial examples, which aim to mislead DNNs by adding perturbations with\nsmall magnitude. To defend against such attacks, both empirical and theoretical\ndefense approaches have been extensively studied for a single ML model. In this\nwork, we aim to analyze and provide the certified robustness for ensemble ML\nmodels, together with the sufficient and necessary conditions of robustness for\ndifferent ensemble protocols. Although ensemble models are shown more robust\nthan a single model empirically; surprisingly, we find that in terms of the\ncertified robustness the standard ensemble models only achieve marginal\nimprovement compared to a single model. Thus, to explore the conditions that\nguarantee to provide certifiably robust ensemble ML models, we first prove that\ndiversified gradient and large confidence margin are sufficient and necessary\nconditions for certifiably robust ensemble models under the model-smoothness\nassumption. We then provide the bounded model-smoothness analysis based on the\nproposed Ensemble-before-Smoothing strategy. We also prove that an ensemble\nmodel can always achieve higher certified robustness than a single base model\nunder mild conditions. Inspired by the theoretical findings, we propose the\nlightweight Diversity Regularized Training (DRT) to train certifiably robust\nensemble ML models. Extensive experiments show that our DRT enhanced ensembles\ncan consistently achieve higher certified robustness than existing single and\nensemble ML models, demonstrating the state-of-the-art certified L2-robustness\non MNIST, CIFAR-10, and ImageNet datasets.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 18:10:41 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Yang", "Zhuolin", ""], ["Li", "Linyi", ""], ["Xu", "Xiaojun", ""], ["Kailkhura", "Bhavya", ""], ["Xie", "Tao", ""], ["Li", "Bo", ""]]}, {"id": "2107.10881", "submitter": "Cosimo Sguanci", "authors": "Cosimo Sguanci, Roberto Spatafora, Andrea Mario Vergani", "title": "Layer 2 Blockchain Scaling: a Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Blockchain technology is affected by massive limitations in scalability with\nconsequent repercussions on performance. This discussion aims at analyzing the\nstate of the art of current available Layer II solutions to overcome these\nlimitations, both focusing on theoretical and practical aspects and\nhighlighting the main differences among the examined frameworks. The structure\nof the work is based on three major sections. In particular, the first one is\nan introductory part about the technology, the scalability issue and Layer II\nas a solution. The second section represents the core of the discussion and\nconsists of three different subsections, each with a detailed examination of\nthe respective solution (Lightning Network, Plasma, Rollups); the analysis of\neach solution is based on how it affects five key aspects of blockchain\ntechnology and Layer II: scalability, security, decentralization, privacy, fees\nand micropayments (the last two are analyzed together given their high\ncorrelation). Finally, the third section includes a tabular summary, followed\nby a detailed description of a use-case specifically thought for a practical\nevaluation of the presented frameworks. The results of the work met\nexpectations: all solutions effectively contribute to increasing scalability. A\ncrucial clarification is that none of the three dominates the others in all\npossible fields of application, and the consequences in adopting each, are\ndifferent. Therefore, the choice depends on the application context, and a\ntrade-off must be found between the aspects previously mentioned.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 18:40:14 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Sguanci", "Cosimo", ""], ["Spatafora", "Roberto", ""], ["Vergani", "Andrea Mario", ""]]}, {"id": "2107.10906", "submitter": "Elena Fuchs", "authors": "Elena Fuchs, Kristin Lauter, Matthew Litman, Austin Tran", "title": "A Cryptographic Hash Function from Markoff Triples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.NT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cryptographic hash functions from expander graphs were proposed by Charles,\nGoren, and Lauter in [CGL] based on the hardness of finding paths in the graph.\nIn this paper, we propose a new candidate for a hash function based on the\nhardness of finding paths in the graph of Markoff triples modulo p. These\ngraphs have been studied extensively in number theory and various other fields,\nand yet finding paths in the graphs remains difficult. We discuss the hardness\nof finding paths between points, based on the structure of the Markoff graphs.\nWe investigate several possible avenues for attack and estimate their running\ntime to be greater than O(p). In particular, we analyze a recent groundbreaking\nproof in [BGS1] that such graphs are connected and discuss how this proof gives\nan algorithm for finding paths\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 20:05:50 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Fuchs", "Elena", ""], ["Lauter", "Kristin", ""], ["Litman", "Matthew", ""], ["Tran", "Austin", ""]]}, {"id": "2107.10979", "submitter": "Nikolay Ivanov", "authors": "Nikolay Ivanov, Hanqing Guo, and Qiben Yan", "title": "Rectifying Administrated ERC20 Tokens", "comments": "23rd International Conference on Information and Communications\n  Security (ICICS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The developers of Ethereum smart contracts often implement administrating\npatterns, such as censoring certain users, creating or destroying balances on\ndemand, destroying smart contracts, or injecting arbitrary code. These routines\nturn an ERC20 token into an administrated token - the type of Ethereum smart\ncontract that we scrutinize in this research. We discover that many smart\ncontracts are administrated, and the owners of these tokens carry lesser social\nand legal responsibilities compared to the traditional centralized actors that\nthose tokens intend to disrupt. This entails two major problems: a) the owners\nof the tokens have the ability to quickly steal all the funds and disappear\nfrom the market; and b) if the private key of the owner's account is stolen,\nall the assets might immediately turn into the property of the attacker. We\ndevelop a pattern recognition framework based on 9 syntactic features\ncharacterizing administrated ERC20 tokens, which we use to analyze existing\nsmart contracts deployed on Ethereum Mainnet. Our analysis of 84,062 unique\nEthereum smart contracts reveals that nearly 58% of them are administrated\nERC20 tokens, which accounts for almost 90% of all ERC20 tokens deployed on\nEthereum. To protect users from the frivolousness of unregulated token owners\nwithout depriving the ability of these owners to properly manage their tokens,\nwe introduce SafelyAdministrated - a library that enforces a responsible\nownership and management of ERC20 tokens. The library introduces three\nmechanisms: deferred maintenance, board of trustees and safe pause. We\nimplement and test SafelyAdministrated in the form of Solidity abstract\ncontract, which is ready to be used by the next generation of safely\nadministrated ERC20 tokens.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 18:40:34 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Ivanov", "Nikolay", ""], ["Guo", "Hanqing", ""], ["Yan", "Qiben", ""]]}, {"id": "2107.11082", "submitter": "Giordano Santilli", "authors": "Nicola Di Chiano, Riccardo Longo, Alessio Meneghetti and Giordano\n  Santilli", "title": "A survey on NIST PQ signatures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shor's shockingly fast quantum algorithm for solving the period-finding\nproblem is a threat for the most common public-key primitives, as it can be\nefficiently applied to solve both the Integer Factorisation Problem and the\nDiscrete Logarithm Problem. In other words, many once-secure protocols have to\nbe replaced by still-secure alternatives. Instead of relying, for example, on\nthe RSA protocol, the Diffie-Hellman key-exchange or the (Elliptic Curve)\nDigital Signature Algorithm, many researchers moved their attention to the\ndesign and analysis of primitives which are yet to be broken by quantum\nalgorithms. The urgency of the threat imposed by quantum computers led the U.S.\nNational Institute of Standards and Technology (NIST) to open calls for both\nPost-Quantum Public-Keys Exchange Algorithms and Post-Quantum Digital Signature\nAlgorithms. In this brief survey we focus on the round 3 finalists and\nalternate candidates for Digital Signatures: CRYSTALS-DILITHIUM, FALCON,\nRainbow, SPHINCS+, GeMSS, Picnic.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 08:46:40 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Di Chiano", "Nicola", ""], ["Longo", "Riccardo", ""], ["Meneghetti", "Alessio", ""], ["Santilli", "Giordano", ""]]}, {"id": "2107.11100", "submitter": "Benjamin Marais", "authors": "Benjamin Marais, Tony Quertier, Christophe Chesneau", "title": "Malware Analysis with Artificial Intelligence and a Particular Attention\n  on Results Interpretability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Malware detection and analysis are active research subjects in cybersecurity\nover the last years. Indeed, the development of obfuscation techniques, as\npacking, for example, requires special attention to detect recent variants of\nmalware. The usual detection methods do not necessarily provide tools to\ninterpret the results. Therefore, we propose a model based on the\ntransformation of binary files into grayscale image, which achieves an accuracy\nrate of 88%. Furthermore, the proposed model can determine if a sample is\npacked or encrypted with a precision of 85%. It allows us to analyze results\nand act appropriately. Also, by applying attention mechanisms on detection\nmodels, we have the possibility to identify which part of the files looks\nsuspicious. This kind of tool should be very useful for data analysts, it\ncompensates for the lack of interpretability of the common detection models,\nand it can help to understand why some malicious files are undetected.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 09:40:05 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Marais", "Benjamin", ""], ["Quertier", "Tony", ""], ["Chesneau", "Christophe", ""]]}, {"id": "2107.11102", "submitter": "Ivan Kova\\v{c}evi\\'c", "authors": "Ivan Kova\\v{c}evi\\'c, Stjepan Gro\\v{s}, Ante {\\DJ}erek, Bruno\n  Bijeli\\'c", "title": "Automatically generating models of IT systems", "comments": "18 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Information technology system (ITS), informally, is a set of workstations,\nservers, laptops, installed software, databases, LANs, firewalls, etc.\nNowadays, every company has an ITS, but rarely is information about it\navailable outside the company that owns it. However, there are many situations\nwhere the availability of such data would be beneficial. For example, cyber\nranges emulate IT systems and need their description. Machine learning, and in\nparticular the use of ML to automate attack and defense, would also benefit\nfrom descriptions of ITSs. In this paper, we describe a system we call the\nGenerator, that as inputs takes requirements such as the number of employees\nand the vertical to which the company belongs, and produces as output a model\nof an ITS that satisfies the given requirements. A very important property that\nwe have put special emphasis on is that the generated ITS looks like a model of\na real system to anyone who analyzes it. To the best of our knowledge, we are\nthe first to have attempted to build something like this. We validate the\nGenerator by generating an ITS model for a fictional financial institution, and\nanalyze its performance with respect to the problem size. The conducted\nexperiments show that our approach is feasible. In the future, we intend to\nextend this prototype to allow probabilistic generation of IT systems when only\na subset of parameters is explicitly defined.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 09:44:23 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Kova\u010devi\u0107", "Ivan", ""], ["Gro\u0161", "Stjepan", ""], ["\u0110erek", "Ante", ""], ["Bijeli\u0107", "Bruno", ""]]}, {"id": "2107.11136", "submitter": "Di Wang", "authors": "Lijie Hu and Shuo Ni and Hanshen Xiao and Di Wang", "title": "High Dimensional Differentially Private Stochastic Optimization with\n  Heavy-tailed Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As one of the most fundamental problems in machine learning, statistics and\ndifferential privacy, Differentially Private Stochastic Convex Optimization\n(DP-SCO) has been extensively studied in recent years. However, most of the\nprevious work can only handle either regular data distribution or irregular\ndata in the low dimensional space case. To better understand the challenges\narising from irregular data distribution, in this paper we provide the first\nstudy on the problem of DP-SCO with heavy-tailed data in the high dimensional\nspace. In the first part we focus on the problem over some polytope constraint\n(such as the $\\ell_1$-norm ball). We show that if the loss function is smooth\nand its gradient has bounded second order moment, it is possible to get a (high\nprobability) error bound (excess population risk) of $\\tilde{O}(\\frac{\\log\nd}{(n\\epsilon)^\\frac{1}{3}})$ in the $\\epsilon$-DP model, where $n$ is the\nsample size and $d$ is the dimensionality of the underlying space. Next, for\nLASSO, if the data distribution that has bounded fourth-order moments, we\nimprove the bound to $\\tilde{O}(\\frac{\\log d}{(n\\epsilon)^\\frac{2}{5}})$ in the\n$(\\epsilon, \\delta)$-DP model. In the second part of the paper, we study sparse\nlearning with heavy-tailed data. We first revisit the sparse linear model and\npropose a truncated DP-IHT method whose output could achieve an error of\n$\\tilde{O}(\\frac{s^{*2}\\log d}{n\\epsilon})$, where $s^*$ is the sparsity of the\nunderlying parameter. Then we study a more general problem over the sparsity\n({\\em i.e.,} $\\ell_0$-norm) constraint, and show that it is possible to achieve\nan error of $\\tilde{O}(\\frac{s^{*\\frac{3}{2}}\\log d}{n\\epsilon})$, which is\nalso near optimal up to a factor of $\\tilde{O}{(\\sqrt{s^*})}$, if the loss\nfunction is smooth and strongly convex.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 11:03:21 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Hu", "Lijie", ""], ["Ni", "Shuo", ""], ["Xiao", "Hanshen", ""], ["Wang", "Di", ""]]}, {"id": "2107.11167", "submitter": "Sebastian Panman De Wit", "authors": "J.S. Panman de Wit, J. van der Ham, D. Bucur", "title": "Dynamic detection of mobile malware using smartphone data and machine\n  learning", "comments": "14 pages content, 22 pages total, to be published in ACM DTRAP\n  (currently in last revision phase)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Mobile malware are malicious programs that target mobile devices. They are an\nincreasing problem, as seen in the rise of detected mobile malware samples per\nyear. The number of active smartphone users is expected to grow, stressing the\nimportance of research on the detection of mobile malware. Detection methods\nfor mobile malware exist but are still limited.\n  In this paper, we provide an overview of the performance of machine learning\n(ML) techniques to detect malware on Android, without using privileged access.\nThe ML-classifiers use device information such as the CPU usage, battery usage,\nand memory usage for the detection of 10 subtypes of Mobile Trojans on the\nAndroid Operating System (OS).\n  We use a real-life dataset containing device and malware data from 47 users\nfor a year (2016). We examine which features, i.e. aspects, of a device, are\nmost important to monitor to detect (subtypes of) Mobile Trojans. The focus of\nthis paper is on dynamic hardware features. Using these dynamic features we\napply state-of-the-art machine learning classifiers: Random Forest, K-Nearest\nNeighbour, and AdaBoost. We show classification results on different feature\nsets, making a distinction between global device features, and specific app\nfeatures. None of the measured feature sets require privileged access.\n  Our results show that the Random Forest classifier performs best as a general\nmalware classifier: across 10 subtypes of Mobile Trojans, it achieves an F1\nscore of 0.73 with a False Positive Rate (FPR) of 0.009 and a False Negative\nRate (FNR) of 0.380. The Random Forest, K-Nearest Neighbours, and AdaBoost\nclassifiers achieve F1 scores above 0.72, an FPR below 0.02 and, an FNR below\n0.33, when trained separately to detect each subtype of Mobile Trojans.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 12:33:14 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["de Wit", "J. S. Panman", ""], ["van der Ham", "J.", ""], ["Bucur", "D.", ""]]}, {"id": "2107.11202", "submitter": "Dilara Acarali", "authors": "Dilara Acarali, Muttukrishnan Rajarajan, Doron Chema, Mark Ginzburg", "title": "A Characterisation of Smart Grid DoS Attacks", "comments": "Published in International Conference on Security and Privacy in New\n  Computing Environments", "journal-ref": "In International Conference on Security and Privacy in New\n  Computing Environments (pp. 3-21). Springer, Cham (2020)", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional power grids are evolving to keep pace with the demands of the\nmodern age. Smart grids contain integrated IT systems for better management and\nefficiency, but in doing so, also inherit a plethora of cyber-security threats\nand vulnerabilities. Denial-of-Service (DoS) is one such threat. At the same\ntime, the smart grid has particular characteristics (e.g. minimal delay\ntolerance), which can influence the nature of threats and so require special\nconsideration. In this paper, we identify a set of possible smart grid-specific\nDoS scenarios based on current research, and analyse them in the context of the\ngrid components they target. Based on this, we propose a novel target-based\nclassification scheme and further characterise each scenario by qualitatively\nexploring it in the context of the underlying grid infrastructure. This\nculminates in a smart grid-centric analysis of the threat to reveal the nature\nof DoS in this environment.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 13:00:13 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Acarali", "Dilara", ""], ["Rajarajan", "Muttukrishnan", ""], ["Chema", "Doron", ""], ["Ginzburg", "Mark", ""]]}, {"id": "2107.11205", "submitter": "Subhamoy Maitra", "authors": "Subhamoy Maitra, Chandra Sekhar Mukherjee, Pantelimon Stanica and Deng\n  Tang", "title": "On Boolean Functions with Low Polynomial Degree and Higher Order\n  Sensitivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Boolean functions are important primitives in different domains of\ncryptology, complexity and coding theory. In this paper, we connect the tools\nfrom cryptology and complexity theory in the domain of Boolean functions with\nlow polynomial degree and high sensitivity. It is well known that the\npolynomial degree of of a Boolean function and its resiliency are directly\nconnected. Using this connection we analyze the polynomial degree-sensitivity\nvalues through the lens of resiliency, demonstrating existence and\nnon-existence results of functions with low polynomial degree and high\nsensitivity on small number of variables (upto 10). In this process, borrowing\nan idea from complexity theory, we show that one can implement resilient\nBoolean functions on a large number of variables with linear size and\nlogarithmic depth. Finally, we extend the notion of sensitivity to higher order\nand note that the existing construction idea of Nisan and Szegedy (1994) can\nprovide only constant higher order sensitivity when aiming for polynomial\ndegree of $n-\\omega(1)$. In this direction, we present a construction with low\n($n-\\omega(1)$) polynomial degree and super-constant $\\omega(1)$ order\nsensitivity exploiting Maiorana-McFarland constructions, that we borrow from\nconstruction of resilient functions. The questions we raise identify novel\ncombinatorial problems in the domain of Boolean functions.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 13:02:02 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Maitra", "Subhamoy", ""], ["Mukherjee", "Chandra Sekhar", ""], ["Stanica", "Pantelimon", ""], ["Tang", "Deng", ""]]}, {"id": "2107.11309", "submitter": "Sandra Siby", "authors": "Sandra Siby, Umar Iqbal, Steven Englehardt, Zubair Shafiq, Carmela\n  Troncoso", "title": "WebGraph: Capturing Advertising and Tracking Information Flows for\n  Robust Blocking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millions of web users directly depend on ad and tracker blocking tools to\nprotect their privacy. However, existing ad and tracker blockers fall short\nbecause of their reliance on trivially susceptible advertising and tracking\ncontent. In this paper, we first demonstrate that the state-of-the-art machine\nlearning based ad and tracker blockers, such as AdGraph, are susceptible to\nadversarial evasions deployed in real-world. Second, we introduce WebGraph, the\nfirst graph-based machine learning blocker that detects ads and trackers based\non their action rather than their content. By building features around the\nactions that are fundamental to advertising and tracking - storing an\nidentifier in the browser, or sharing an identifier with another tracker -\nWebGraph performs nearly as well as prior approaches, but is significantly more\nrobust to adversarial evasions. In particular, we show that WebGraph achieves\ncomparable accuracy to AdGraph, while significantly decreasing the success rate\nof an adversary from near-perfect under AdGraph to around 8% under WebGraph.\nFinally, we show that WebGraph remains robust to a more sophisticated adversary\nthat uses evasion techniques beyond those currently deployed on the web.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 15:40:31 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Siby", "Sandra", ""], ["Iqbal", "Umar", ""], ["Englehardt", "Steven", ""], ["Shafiq", "Zubair", ""], ["Troncoso", "Carmela", ""]]}, {"id": "2107.11336", "submitter": "Trevor E. Carlson", "authors": "Yun Chen, Ali Hajiabadi, Romain Poussier, Andreas Diavastos, Shivam\n  Bhasin, Trevor E. Carlson", "title": "Mitigating Power Attacks through Fine-Grained Instruction Reordering", "comments": "13 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Side-channel attacks are a security exploit that take advantage of\ninformation leakage. They use measurement and analysis of physical parameters\nto reverse engineer and extract secrets from a system. Power analysis attacks\nin particular, collect a set of power traces from a computing device and use\nstatistical techniques to correlate this information with the attacked\napplication data and source code. Counter measures like just-in-time\ncompilation, random code injection and instruction descheduling obfuscate the\nexecution of instructions to reduce the security risk. Unfortunately, due to\nthe randomness and excess instructions executed by these solutions, they\nintroduce large overheads in performance, power and area.\n  In this work we propose a scheduling algorithm that dynamically reorders\ninstructions in an out-of-order processor to provide obfuscated execution and\nmitigate power analysis attacks with little-to-no effect on the performance,\npower or area of the processor. We exploit the time between operand\navailability of critical instructions (slack) to create high-performance random\nschedules without requiring additional instructions or static prescheduling.\nFurther, we perform an extended security analysis using different attacks. We\nhighlight the dangers of using incorrect adversarial assumptions, which can\noften lead to a false sense of security. In that regard, our advanced security\nmetric demonstrates improvements of 34$\\times$, while our basic security\nevaluation shows results up to 261$\\times$. Moreover, our system achieves\nperformance within 96% on average, of the baseline unprotected processor.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 16:27:01 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Chen", "Yun", ""], ["Hajiabadi", "Ali", ""], ["Poussier", "Romain", ""], ["Diavastos", "Andreas", ""], ["Bhasin", "Shivam", ""], ["Carlson", "Trevor E.", ""]]}, {"id": "2107.11514", "submitter": "Li Yang", "authors": "Li Yang, Abdallah Moubayed, Abdallah Shami, Parisa Heidari, Amine\n  Boukhtouta, Adel Larabi, Richard Brunner, Stere Preda, Daniel Migault", "title": "Multi-Perspective Content Delivery Networks Security Framework Using\n  Optimized Unsupervised Anomaly Detection", "comments": "Accepted and to Appear in IEEE Transactions on Network and Service\n  Management", "journal-ref": null, "doi": "10.1109/TNSM.2021.3100308", "report-no": null, "categories": "cs.CR cs.AI cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Content delivery networks (CDNs) provide efficient content distribution over\nthe Internet. CDNs improve the connectivity and efficiency of global\ncommunications, but their caching mechanisms may be breached by\ncyber-attackers. Among the security mechanisms, effective anomaly detection\nforms an important part of CDN security enhancement. In this work, we propose a\nmulti-perspective unsupervised learning framework for anomaly detection in\nCDNs. In the proposed framework, a multi-perspective feature engineering\napproach, an optimized unsupervised anomaly detection model that utilizes an\nisolation forest and a Gaussian mixture model, and a multi-perspective\nvalidation method, are developed to detect abnormal behaviors in CDNs mainly\nfrom the client Internet Protocol (IP) and node perspectives, therefore to\nidentify the denial of service (DoS) and cache pollution attack (CPA) patterns.\nExperimental results are presented based on the analytics of eight days of\nreal-world CDN log data provided by a major CDN operator. Through experiments,\nthe abnormal contents, compromised nodes, malicious IPs, as well as their\ncorresponding attack types, are identified effectively by the proposed\nframework and validated by multiple cybersecurity experts. This shows the\neffectiveness of the proposed method when applied to real-world CDN data.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 02:43:23 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Yang", "Li", ""], ["Moubayed", "Abdallah", ""], ["Shami", "Abdallah", ""], ["Heidari", "Parisa", ""], ["Boukhtouta", "Amine", ""], ["Larabi", "Adel", ""], ["Brunner", "Richard", ""], ["Preda", "Stere", ""], ["Migault", "Daniel", ""]]}, {"id": "2107.11526", "submitter": "Uri Stemmer", "authors": "Menachem Sadigurschi, Uri Stemmer", "title": "On the Sample Complexity of Privately Learning Axis-Aligned Rectangles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the fundamental problem of learning Axis-Aligned-Rectangles over a\nfinite grid $X^d\\subseteq{\\mathbb{R}}^d$ with differential privacy. Existing\nresults show that the sample complexity of this problem is at most $\\min\\left\\{\nd{\\cdot}\\log|X| \\;,\\; d^{1.5}{\\cdot}\\left(\\log^*|X| \\right)^{1.5}\\right\\}$.\nThat is, existing constructions either require sample complexity that grows\nlinearly with $\\log|X|$, or else it grows super linearly with the dimension\n$d$. We present a novel algorithm that reduces the sample complexity to only\n$\\tilde{O}\\left\\{d{\\cdot}\\left(\\log^*|X|\\right)^{1.5}\\right\\}$, attaining a\ndimensionality optimal dependency without requiring the sample complexity to\ngrow with $\\log|X|$.The technique used in order to attain this improvement\ninvolves the deletion of \"exposed\" data-points on the go, in a fashion designed\nto avoid the cost of the adaptive composition theorems. The core of this\ntechnique may be of individual interest, introducing a new method for\nconstructing statistically-efficient private algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 04:06:11 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Sadigurschi", "Menachem", ""], ["Stemmer", "Uri", ""]]}, {"id": "2107.11537", "submitter": "Roopak Sinha", "authors": "Awais Tanveer, Roopak Sinha and Matthew M. Y. Kuo", "title": "Secure Links: Secure-by-Design Communications in IEC 61499 Industrial\n  Control Applications", "comments": "Journal paper, 11 pages, 10 figures, 3 tables", "journal-ref": "IEEE Transactions on Industrial Informatics 17(6)(2021),\n  pp.3992-4002", "doi": "10.1109/TII.2020.3009133.", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing automation and external connectivity in industrial control systems\n(ICS) demand a greater emphasis on software-level communication security. In\nthis article, we propose a secure-by-design development method for building ICS\napplications, where requirements from security standards like ISA/IEC 62443 are\nfulfilled by design-time abstractions called secure links. Proposed as an\nextension to the IEC 61499 development standard, secure links incorporate both\nlight-weight and traditional security mechanisms into applications with\nnegligible effort. Applications containing secure links can be automatically\ncompiled into fully IEC 61499-compliant software. Experimental results show\nsecure links significantly reduce design and code complexity and improve\napplication maintainability and requirements traceability.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 05:37:31 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Tanveer", "Awais", ""], ["Sinha", "Roopak", ""], ["Kuo", "Matthew M. Y.", ""]]}, {"id": "2107.11592", "submitter": "Suyash Gupta", "authors": "Suyash Gupta, Mohammad Sadoghi", "title": "Blockchain Transaction Processing", "comments": null, "journal-ref": "Encyclopedia of Big Data Technologies 2019", "doi": "10.1007/978-3-319-77525-8_333", "report-no": null, "categories": "cs.DB cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A blockchain is a linked list of immutable tamper-proof blocks, which is\nstored at each participating node. Each block records a set of transactions and\nthe associated metadata. Blockchain transactions act on the identical ledger\ndata stored at each node. Blockchain was first perceived by Satoshi Nakamoto,\nas a peer-to-peer money exchange system. Nakamoto referred to the transactional\ntokens exchanged among clients in his system as Bitcoins.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 12:20:36 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Gupta", "Suyash", ""], ["Sadoghi", "Mohammad", ""]]}, {"id": "2107.11598", "submitter": "Peng Qian", "authors": "Zhenguang Liu, Peng Qian, Xiaoyang Wang, Yuan Zhuang, Lin Qiu, Xun\n  Wang", "title": "Combining Graph Neural Networks with Expert Knowledge for Smart Contract\n  Vulnerability Detection", "comments": "This paper has been accepted by TKDE 2021", "journal-ref": null, "doi": "10.1109/TKDE.2021.3095196", "report-no": null, "categories": "cs.CR cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart contract vulnerability detection draws extensive attention in recent\nyears due to the substantial losses caused by hacker attacks. Existing efforts\nfor contract security analysis heavily rely on rigid rules defined by experts,\nwhich are labor-intensive and non-scalable. More importantly, expert-defined\nrules tend to be error-prone and suffer the inherent risk of being cheated by\ncrafty attackers. Recent researches focus on the symbolic execution and formal\nanalysis of smart contracts for vulnerability detection, yet to achieve a\nprecise and scalable solution. Although several methods have been proposed to\ndetect vulnerabilities in smart contracts, there is still a lack of effort that\nconsiders combining expert-defined security patterns with deep neural networks.\nIn this paper, we explore using graph neural networks and expert knowledge for\nsmart contract vulnerability detection. Specifically, we cast the rich control-\nand data- flow semantics of the source code into a contract graph. To highlight\nthe critical nodes in the graph, we further design a node elimination phase to\nnormalize the graph. Then, we propose a novel temporal message propagation\nnetwork to extract the graph feature from the normalized graph, and combine the\ngraph feature with designed expert patterns to yield a final detection system.\nExtensive experiments are conducted on all the smart contracts that have source\ncode in Ethereum and VNT Chain platforms. Empirical results show significant\naccuracy improvements over the state-of-the-art methods on three types of\nvulnerabilities, where the detection accuracy of our method reaches 89.15%,\n89.02%, and 83.21% for reentrancy, timestamp dependence, and infinite loop\nvulnerabilities, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 13:16:30 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Liu", "Zhenguang", ""], ["Qian", "Peng", ""], ["Wang", "Xiaoyang", ""], ["Zhuang", "Yuan", ""], ["Qiu", "Lin", ""], ["Wang", "Xun", ""]]}, {"id": "2107.11630", "submitter": "Florian Tram\\`er", "authors": "Florian Tram\\`er", "title": "Detecting Adversarial Examples Is (Nearly) As Hard As Classifying Them", "comments": "ICML 2021 Workshop on the Prospects and Perils of Adversarial Machine\n  Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making classifiers robust to adversarial examples is hard. Thus, many\ndefenses tackle the seemingly easier task of detecting perturbed inputs. We\nshow a barrier towards this goal. We prove a general hardness reduction between\ndetection and classification of adversarial examples: given a robust detector\nfor attacks at distance {\\epsilon} (in some metric), we can build a similarly\nrobust (but inefficient) classifier for attacks at distance {\\epsilon}/2. Our\nreduction is computationally inefficient, and thus cannot be used to build\npractical classifiers. Instead, it is a useful sanity check to test whether\nempirical detection results imply something much stronger than the authors\npresumably anticipated. To illustrate, we revisit 13 detector defenses. For\n11/13 cases, we show that the claimed detection results would imply an\ninefficient classifier with robustness far beyond the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 15:14:53 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Tram\u00e8r", "Florian", ""]]}, {"id": "2107.11636", "submitter": "Tanguy Gernot", "authors": "Tanguy Gernot and Patrick Lacharme", "title": "Biometric Masterkeys", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biometric authentication is used to secure digital or physical access. Such\nan authentication system uses a biometric database, where data are sometimes\nprotected by cancelable transformations. This paper introduces the notion of\nbiometric masterkeys. A masterkey is a feature vector such that the\ncorresponding template matches with a significant number of templates stored in\na cancelable biometric database. Such a masterkey is directly researched from a\ncancelable biometric database, but we also investigate another scenario in\nwhich the masterkey is fixed before the creation of the cancelable biometric\ndatabase, providing additional access rights in the system for the masterkey's\nowner. Experimental results on the fingerprint database FVC and the face image\ndatabase LFW show the effectiveness and the efficiency of such masterkeys in\nboth scenarios. In particular, from any given feature vector, we are able to\nconstruct a cancelable database, for which the biometric template matches with\nall the templates of the database.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 15:38:44 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Gernot", "Tanguy", ""], ["Lacharme", "Patrick", ""]]}, {"id": "2107.11671", "submitter": "Ali Rahmati", "authors": "Ali Rahmati, Seyed-Mohsen Moosavi-Dezfooli, Huaiyu Dai", "title": "Adversarial training may be a double-edged sword", "comments": "Presented as a RobustML workshop paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adversarial training has been shown as an effective approach to improve the\nrobustness of image classifiers against white-box attacks. However, its\neffectiveness against black-box attacks is more nuanced. In this work, we\ndemonstrate that some geometric consequences of adversarial training on the\ndecision boundary of deep networks give an edge to certain types of black-box\nattacks. In particular, we define a metric called robustness gain to show that\nwhile adversarial training is an effective method to dramatically improve the\nrobustness in white-box scenarios, it may not provide such a good robustness\ngain against the more realistic decision-based black-box attacks. Moreover, we\nshow that even the minimal perturbation white-box attacks can converge faster\nagainst adversarially-trained neural networks compared to the regular ones.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 19:09:16 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Rahmati", "Ali", ""], ["Moosavi-Dezfooli", "Seyed-Mohsen", ""], ["Dai", "Huaiyu", ""]]}, {"id": "2107.11677", "submitter": "Jafar Pourbemany", "authors": "Jafar Pourbemany, Ye Zhu, and Riccardo Bettati", "title": "Breath to Pair (B2P): Respiration-Based Pairing Protocol for Wearable\n  Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We propose Breath to Pair (B2P), a protocol for pairing and shared-key\ngeneration for wearable devices that leverages the wearer's respiration\nactivity to ensure that the devices are part of the same body-area network. We\nassume that the devices exploit different types of sensors to extract and\nprocess the respiration signal. We illustrate B2P for the case of two devices\nthat use respiratory inductance plethysmography (RIP) and accelerometer\nsensors, respectively. Allowing for different types of sensors in pairing\nallows us to include wearable devices that use a variety of different sensors.\nIn practice, this form of sensor variety creates a number of challenges that\nlimit the ability of the shared-key establishment algorithm to generate\nmatching keys. The two main obstacles are the lack of synchronization across\nthe devices and the need for correct noise-induced mismatches between the\ngenerated key bit-strings.\n  B2P addresses the synchronization challenge by utilizing Change Point\nDetection (CPD) to detect abrupt changes in the respiration signal and consider\ntheir occurrences as synchronizing points. Any potential mismatches are handled\nby optimal quantization and encoding of the respiration signal in order to\nmaximize the error correction rate and minimize the message overheads.\nExtensive evaluation on a dataset collected from 30 volunteers demonstrates\nthat our protocol can generate a secure 256-bit key every 2.85 seconds (around\none breathing cycle). Particular attention is given to secure B2P against\ndevice impersonation attacks.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 19:49:29 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Pourbemany", "Jafar", ""], ["Zhu", "Ye", ""], ["Bettati", "Riccardo", ""]]}, {"id": "2107.11685", "submitter": "Jafar Pourbemany", "authors": "Jafar Pourbemany, Ye Zhu, and Riccardo Bettati", "title": "A Survey of Wearable Devices Pairing Based on Biometric Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  With the growth of wearable devices, which are usually constrained in\ncomputational power and user interface, this pairing has to be autonomous.\nConsidering devices that do not have prior information about each other, a\nsecure communication should be established by generating a shared secret key\nderived from a common context between the devices. Context-based pairing\nsolutions increase the usability of wearable device pairing by eliminating any\nhuman involvement in the pairing process. This is possible by utilizing onboard\nsensors (with the same sensing modalities) to capture a common physical context\n(e.g., body motion, gait, heartbeat, respiration, and EMG signal). A wide range\nof approaches has been proposed to address autonomous pairing in wearable\ndevices. This paper surveys context-based pairing in wearable devices by\nfocusing on the signals and sensors exploited. We review the steps needed for\ngenerating a common key and provide a survey of existing techniques utilized in\neach step.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 20:39:05 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Pourbemany", "Jafar", ""], ["Zhu", "Ye", ""], ["Bettati", "Riccardo", ""]]}, {"id": "2107.11839", "submitter": "Albert Cheu", "authors": "Albert Cheu", "title": "Differential Privacy in the Shuffle Model: A Survey of Separations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Differential privacy is often studied in one of two models. In the central\nmodel, a single analyzer has the responsibility of performing a\nprivacy-preserving computation on data. But in the local model, each data owner\nensures their own privacy. Although it removes the need to trust the analyzer,\nlocal privacy comes at a price: a locally private protocol is less accurate\nthan a centrally private counterpart when solving many learning and estimation\nproblems. Protocols in the shuffle model are designed to attain the best of\nboth worlds: recent work has shown high accuracy is possible with only a mild\ntrust assumption. This survey paper gives an overview of novel shuffle\nprotocols, along with lower bounds that establish the limits of the new model.\nWe also summarize work that show the promise of interactivity in the shuffle\nmodel.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 16:40:21 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Cheu", "Albert", ""]]}, {"id": "2107.11870", "submitter": "Random Gwinn", "authors": "Random Gwinn, Mark A. Matties, Aviel D. Rubin", "title": "Wavelet Selection and Employment for Side-Channel Disassembly", "comments": "9 pages, 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Side-channel analysis, originally used in cryptanalysis is growing in use\ncases, both offensive and defensive. Wavelet analysis is a commonly employed\ntime-frequency analysis technique used across disciplines, with a variety of\npurposes, and has shown increasing prevalence within side-channel literature.\nThis paper explores wavelet selection and analysis parameters for use in\nside-channel analysis, particularly power side-channel-based instruction\ndisassembly and classification. Experiments are conducted on an ATmega328P\nmicrocontroller and a subset of the AVR instruction set. Classification\nperformance is evaluated with a time-series convolutional neural network (CNN)\nat clock-cycle fidelity. This work demonstrates that wavelet selection and\nemployment parameters have meaningful impact on analysis outcomes.\nPractitioners should make informed decisions and consider optimizing these\nfactors similarly to machine learning architecture and hyperparameters. We\nconclude that the gaus1 wavelet with scales 1-21 and grayscale colormap\nprovided the best balance of classification performance, time, and memory\nefficiency in our application.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 18:59:41 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Gwinn", "Random", ""], ["Matties", "Mark A.", ""], ["Rubin", "Aviel D.", ""]]}, {"id": "2107.11903", "submitter": "Damjan Vukcevic", "authors": "Michelle Blom, Jurlind Budurushi, Ronald L. Rivest, Philip B. Stark,\n  Peter J. Stuckey, Vanessa Teague, Damjan Vukcevic", "title": "Assertion-based Approaches to Auditing Complex Elections, with\n  application to party-list proportional elections", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Risk-limiting audits (RLAs), an ingredient in evidence-based elections, are\nincreasingly common. They are a rigorous statistical means of ensuring that\nelectoral results are correct, usually without having to perform an expensive\nfull recount -- at the cost of some controlled probability of error. A recently\ndeveloped approach for conducting RLAs, SHANGRLA, provides a flexible framework\nthat can encompass a wide variety of social choice functions and audit\nstrategies. Its flexibility comes from reducing sufficient conditions for\noutcomes to be correct to canonical `assertions' that have a simple\nmathematical form.\n  Assertions have been developed for auditing various social choice functions\nincluding plurality, multi-winner plurality, super-majority, Hamiltonian\nmethods, and instant runoff voting. However, there is no systematic approach to\nbuilding assertions. Here, we show that assertions with linear dependence on\ntransformations of the votes can easily be transformed to canonical form for\nSHANGRLA. We illustrate the approach by constructing assertions for party-list\nelections such as Hamiltonian free list elections and elections using the\nD'Hondt method, expanding the set of social choice functions to which SHANGRLA\napplies directly.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 22:52:49 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Blom", "Michelle", ""], ["Budurushi", "Jurlind", ""], ["Rivest", "Ronald L.", ""], ["Stark", "Philip B.", ""], ["Stuckey", "Peter J.", ""], ["Teague", "Vanessa", ""], ["Vukcevic", "Damjan", ""]]}, {"id": "2107.11905", "submitter": "Gonzalo Munilla Garrido", "authors": "Gonzalo Munilla Garrido and Johannes Sedlmeir and \\\"Omer Uluda\\u{g}\n  and Ilias Soto Alaoui and Andre Luckow and Florian Matthes", "title": "Revealing the Landscape of Privacy-Enhancing Technologies in the Context\n  of Data Markets for the IoT: A Systematic Literature Review", "comments": "44 pages, 17 figures, 12 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IoT data markets in public and private institutions have become increasingly\nrelevant in recent years because of their potential to improve data\navailability and unlock new business models. However, exchanging data in\nmarkets bears considerable challenges related to the disclosure of sensitive\ninformation. Despite considerable research that has focused on different\naspects of privacy-enhancing data markets for the IoT, none of the solutions\nproposed so far seems to find considerable practical adoption. Thus, this study\naims to organize the state-of-the-art solutions, analyze and scope the\ntechnologies that have been suggested in this context, and structure the\nremaining challenges to determine areas where future research is required. To\naccomplish this goal, we conducted a systematic literature review on privacy\nenhancement in data markets for the IoT, covering $50$ publications dated up to\nJuly 2020. Our results indicate that most research in this area has emerged\nonly recently, and no IoT data market architecture has established itself as\ncanonical. Existing solutions frequently lack the required combination of\nanonymization and secure computation technologies. Furthermore, there is no\nconsensus on the appropriate use of blockchain technology for IoT data markets\nand a low degree of leveraging existing libraries or reusing generic data\nmarket architectures. We also identified significant remaining challenges such\nas the copy problem and the recursive enforcement problem that -- while\nsolutions have been suggested to some extent -- are often not sufficiently\naddressed in proposed designs.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 23:03:28 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Garrido", "Gonzalo Munilla", ""], ["Sedlmeir", "Johannes", ""], ["Uluda\u011f", "\u00d6mer", ""], ["Alaoui", "Ilias Soto", ""], ["Luckow", "Andre", ""], ["Matthes", "Florian", ""]]}, {"id": "2107.12069", "submitter": "Dimitris Karakostas", "authors": "Dimitris Karakostas and Aggelos Kiayias", "title": "Filling the Tax Gap via Programmable Money", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We discuss the problem of facilitating tax auditing assuming \"programmable\nmoney\", i.e., digital monetary instruments that are managed by an underlying\ndistributed ledger. We explore how a taxation authority can verify the declared\nreturns of its citizens and create a counter-incentive to tax evasion by two\ndistinct mechanisms. First, we describe a design which enables auditing it as a\nbuilt-in feature with minimal changes on the underlying ledger's consensus\nprotocol. Second, we offer an application-layer extension, which requires no\nmodification in the underlying ledger's design. Both solutions provide a high\nlevel of privacy, ensuring that, apart from specific limited data given to the\ntaxation authority, no additional information - beyond the information already\npublished on the underlying ledger - is leaked.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 09:49:06 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Karakostas", "Dimitris", ""], ["Kiayias", "Aggelos", ""]]}, {"id": "2107.12172", "submitter": "Ania Piotrowska", "authors": "Ania M. Piotrowska", "title": "Studying the anonymity trilemma with a discrete-event mix network\n  simulator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a discrete event mix network simulator, which allows\nanalysing how anonymity, latency, and bandwidth overhead are affected by\nvarious scenarios of deployment and design choices. These design choices\ninclude network topology, mixing technique, volume of traffic, latency\nrequirements, packet size or use of cover traffic. To the best of our\nknowledge, this is the first such simulator as work on it began in 2017 to\nanalyze the Loopix mix network, and the code of our simulator is available\nunder an open-source license. To demonstrate the capabilities of our simulator,\nwe perform an empirical analysis of the impact of core design choices on\nanonymity, scalability and latency in Elixxir, HOPR and Nym, currently deployed\nmix network infrastructures that make a variety of different choices in their\ndesign.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 12:39:49 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 09:35:54 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Piotrowska", "Ania M.", ""]]}, {"id": "2107.12173", "submitter": "Yi Shi", "authors": "Yi Shi and Yalin E. Sagduyu", "title": "Membership Inference Attack and Defense for Wireless Signal Classifiers\n  with Deep Learning", "comments": "arXiv admin note: substantial text overlap with arXiv:2006.14576", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An over-the-air membership inference attack (MIA) is presented to leak\nprivate information from a wireless signal classifier. Machine learning (ML)\nprovides powerful means to classify wireless signals, e.g., for PHY-layer\nauthentication. As an adversarial machine learning attack, the MIA infers\nwhether a signal of interest has been used in the training data of a target\nclassifier. This private information incorporates waveform, channel, and device\ncharacteristics, and if leaked, can be exploited by an adversary to identify\nvulnerabilities of the underlying ML model (e.g., to infiltrate the PHY-layer\nauthentication). One challenge for the over-the-air MIA is that the received\nsignals and consequently the RF fingerprints at the adversary and the intended\nreceiver differ due to the discrepancy in channel conditions. Therefore, the\nadversary first builds a surrogate classifier by observing the spectrum and\nthen launches the black-box MIA on this classifier. The MIA results show that\nthe adversary can reliably infer signals (and potentially the radio and channel\ninformation) used to build the target classifier. Therefore, a proactive\ndefense is developed against the MIA by building a shadow MIA model and fooling\nthe adversary. This defense can successfully reduce the MIA accuracy and\nprevent information leakage from the wireless signal classifier.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 17:05:47 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Shi", "Yi", ""], ["Sagduyu", "Yalin E.", ""]]}, {"id": "2107.12299", "submitter": "Mouhammd Alkasassbeh Dr.", "authors": "Mohammad Almseidin, Jamil Al-Sawwa, Mouhammd Alkasassbeh", "title": "Anomaly-based Intrusion Detection System Using Fuzzy Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, the Distributed Denial of Service (DDOS) attacks has been used for\ndifferent aspects to denial the number of services for the end-users.\nTherefore, there is an urgent need to design an effective detection method\nagainst this type of attack. A fuzzy inference system offers the results in a\nmore readable and understandable form. This paper introduces an anomaly-based\nIntrusion Detection (IDS) system using fuzzy logic. The fuzzy logic inference\nsystem implemented as a detection method for Distributed Denial of Service\n(DDOS) attacks. The suggested method was applied to an open-source DDOS\ndataset. Experimental results show that the anomaly-based Intrusion Detection\nsystem using fuzzy logic obtained the best result by utilizing the InfoGain\nfeatures selection method besides the fuzzy inference system, the results were\n91.1% for the true-positive rate and 0.006% for the false-positive rate.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 11:05:35 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Almseidin", "Mohammad", ""], ["Al-Sawwa", "Jamil", ""], ["Alkasassbeh", "Mouhammd", ""]]}, {"id": "2107.12328", "submitter": "Shih-Yuan Yu", "authors": "Shih-Yuan Yu, Rozhin Yasaei, Qingrong Zhou, Tommy Nguyen, Mohammad\n  Abdullah Al Faruque", "title": "HW2VEC: A Graph Learning Tool for Automating Hardware Security", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The time-to-market pressure and continuous growing complexity of hardware\ndesigns have promoted the globalization of the Integrated Circuit (IC) supply\nchain. However, such globalization also poses various security threats in each\nphase of the IC supply chain. Although the advancements of Machine Learning\n(ML) have pushed the frontier of hardware security, most conventional ML-based\nmethods can only achieve the desired performance by manually finding a robust\nfeature representation for circuits that are non-Euclidean data. As a result,\nmodeling these circuits using graph learning to improve design flows has\nattracted research attention in the Electronic Design Automation (EDA) field.\nHowever, due to the lack of supporting tools, only a few existing works apply\ngraph learning to resolve hardware security issues. To attract more attention,\nwe propose HW2VEC, an open-source graph learning tool that lowers the threshold\nfor newcomers to research hardware security applications with graphs. HW2VEC\nprovides an automated pipeline for extracting a graph representation from a\nhardware design in various abstraction levels (register transfer level or\ngate-level netlist). Besides, HW2VEC users can automatically transform the\nnon-Euclidean hardware designs into Euclidean graph embeddings for solving\ntheir problems. In this paper, we demonstrate that HW2VEC can achieve\nstate-of-the-art performance on two hardware security-related tasks: Hardware\nTrojan Detection and Intellectual Property Piracy Detection. We provide the\ntime profiling results for the graph extraction and the learning pipelines in\nHW2VEC.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 17:03:51 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Yu", "Shih-Yuan", ""], ["Yasaei", "Rozhin", ""], ["Zhou", "Qingrong", ""], ["Nguyen", "Tommy", ""], ["Faruque", "Mohammad Abdullah Al", ""]]}, {"id": "2107.12342", "submitter": "Nandan Kumar Jha", "authors": "Karthik Garimella, Nandan Kumar Jha and Brandon Reagen", "title": "Sisyphus: A Cautionary Tale of Using Low-Degree Polynomial Activations\n  in Privacy-Preserving Deep Learning", "comments": "2 figures and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy concerns in client-server machine learning have given rise to private\ninference (PI), where neural inference occurs directly on encrypted inputs. PI\nprotects clients' personal data and the server's intellectual property. A\ncommon practice in PI is to use garbled circuits to compute nonlinear functions\nprivately, namely ReLUs. However, garbled circuits suffer from high storage,\nbandwidth, and latency costs. To mitigate these issues, PI-friendly polynomial\nactivation functions have been employed to replace ReLU. In this work, we ask:\nIs it feasible to substitute all ReLUs with low-degree polynomial activation\nfunctions for building deep, privacy-friendly neural networks? We explore this\nquestion by analyzing the challenges of substituting ReLUs with polynomials,\nstarting with simple drop-and-replace solutions to novel, more involved\nreplace-and-retrain strategies. We examine the limitations of each method and\nprovide commentary on the use of polynomial activation functions for PI. We\nfind all evaluated solutions suffer from the escaping activation problem:\nforward activation values inevitably begin to expand at an exponential rate\naway from stable regions of the polynomials, which leads to exploding values\n(NaNs) or poor approximations.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 17:33:56 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Garimella", "Karthik", ""], ["Jha", "Nandan Kumar", ""], ["Reagen", "Brandon", ""]]}, {"id": "2107.12407", "submitter": "Thomas Humphries", "authors": "Thomas Humphries, Rasoul Akhavan Mahdavi, Shannon Veitch, Florian\n  Kerschbaum", "title": "Selective MPC: Distributed Computation of Differentially Private Key\n  Value Statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasingly popular method for computing aggregate statistics while\npreserving users' privacy is local differential privacy (LDP). Under this\nmodel, users perturb their data before sending it to an untrusted central party\nto be processed. Key value data is a naturally occurring data type that has not\nbeen thoroughly investigated in the local trust model. Existing LDP solutions\nfor computing statistics over key value data suffer from the inherent accuracy\nlimitations of each user adding their own noise. Multi-party computation (MPC)\nis a common alternative to LDP that removes the requirement for a trusted\ncentral party while maintaining accuracy; however, naively applying MPC to key\nvalue data results in prohibitively expensive computation costs. In this work,\nwe present selective multi-party computation, a novel approach to distributed\ncomputation that leverages DP leakage to efficiently and accurately compute\nstatistics over key value data. We show that our protocol satisfies pure DP and\nis provably secure in the combined DP/MPC model. Our empirical evaluation\ndemonstrates that we can compute statistics over 10,000 keys in 20 seconds and\ncan scale up to 30 servers while obtaining results for a single key in under a\nsecond.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 18:01:19 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Humphries", "Thomas", ""], ["Mahdavi", "Rasoul Akhavan", ""], ["Veitch", "Shannon", ""], ["Kerschbaum", "Florian", ""]]}, {"id": "2107.12423", "submitter": "Jiayu Li", "authors": "Chathura Widanage, Weijie Liu, Jiayu Li, Hongbo Chen, XiaoFeng Wang,\n  Haixu Tang, Judy Fox", "title": "HySec-Flow: Privacy-Preserving Genomic Computing with SGX-based Big-Data\n  Analytics Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Trusted execution environments (TEE) such as Intel's Software Guard Extension\n(SGX) have been widely studied to boost security and privacy protection for the\ncomputation of sensitive data such as human genomics. However, a performance\nhurdle is often generated by SGX, especially from the small enclave memory. In\nthis paper, we propose a new Hybrid Secured Flow framework (called\n\"HySec-Flow\") for large-scale genomic data analysis using SGX platforms. Here,\nthe data-intensive computing tasks can be partitioned into independent subtasks\nto be deployed into distinct secured and non-secured containers, therefore\nallowing for parallel execution while alleviating the limited size of Page\nCache (EPC) memory in each enclave. We illustrate our contributions using a\nworkflow supporting indexing, alignment, dispatching, and merging the execution\nof SGX- enabled containers. We provide details regarding the architecture of\nthe trusted and untrusted components and the underlying Scorn and Graphene\nsupport as generic shielding execution frameworks to port legacy code. We\nthoroughly evaluate the performance of our privacy-preserving reads mapping\nalgorithm using real human genome sequencing data. The results demonstrate that\nthe performance is enhanced by partitioning the time-consuming genomic\ncomputation into subtasks compared to the conventional execution of the\ndata-intensive reads mapping algorithm in an enclave. The proposed HySec-Flow\nframework is made available as an open-source and adapted to the data-parallel\ncomputation of other large-scale genomic tasks requiring security and scalable\ncomputational resources.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 18:31:59 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Widanage", "Chathura", ""], ["Liu", "Weijie", ""], ["Li", "Jiayu", ""], ["Chen", "Hongbo", ""], ["Wang", "XiaoFeng", ""], ["Tang", "Haixu", ""], ["Fox", "Judy", ""]]}, {"id": "2107.12473", "submitter": "Aritra Chowdhury", "authors": "Alberto Santamaria-Pang, Jianwei Qiu, Aritra Chowdhury, James\n  Kubricht, Peter Tu, Iyer Naresh, Nurali Virani", "title": "Adversarial Attacks with Time-Scale Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel framework for real-time black-box universal attacks which\ndisrupts activations of early convolutional layers in deep learning models. Our\nhypothesis is that perturbations produced in the wavelet space disrupt early\nconvolutional layers more effectively than perturbations performed in the time\ndomain. The main challenge in adversarial attacks is to preserve low frequency\nimage content while minimally changing the most meaningful high frequency\ncontent. To address this, we formulate an optimization problem using time-scale\n(wavelet) representations as a dual space in three steps. First, we project\noriginal images into orthonormal sub-spaces for low and high scales via wavelet\ncoefficients. Second, we perturb wavelet coefficients for high scale projection\nusing a generator network. Third, we generate new adversarial images by\nprojecting back the original coefficients from the low scale and the perturbed\ncoefficients from the high scale sub-space. We provide a theoretical framework\nthat guarantees a dual mapping from time and time-scale domain representations.\nWe compare our results with state-of-the-art black-box attacks from\ngenerative-based and gradient-based models. We also verify efficacy against\nmultiple defense methods such as JPEG compression, Guided Denoiser and\nComdefend. Our results show that wavelet-based perturbations consistently\noutperform time-based attacks thus providing new insights into vulnerabilities\nof deep learning models and could potentially lead to robust architectures or\nnew defense and attack mechanisms by leveraging time-scale representations.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 20:58:57 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Santamaria-Pang", "Alberto", ""], ["Qiu", "Jianwei", ""], ["Chowdhury", "Aritra", ""], ["Kubricht", "James", ""], ["Tu", "Peter", ""], ["Naresh", "Iyer", ""], ["Virani", "Nurali", ""]]}, {"id": "2107.12490", "submitter": "Yi Zhou", "authors": "Kamala Varma, Yi Zhou, Nathalie Baracaldo, Ali Anwar", "title": "LEGATO: A LayerwisE Gradient AggregaTiOn Algorithm for Mitigating\n  Byzantine Attacks in Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning has arisen as a mechanism to allow multiple participants\nto collaboratively train a model without sharing their data. In these settings,\nparticipants (workers) may not trust each other fully; for instance, a set of\ncompetitors may collaboratively train a machine learning model to detect fraud.\nThe workers provide local gradients that a central server uses to update a\nglobal model. This global model can be corrupted when Byzantine workers send\nmalicious gradients, which necessitates robust methods for aggregating\ngradients that mitigate the adverse effects of Byzantine inputs. Existing\nrobust aggregation algorithms are often computationally expensive and only\neffective under strict assumptions. In this paper, we introduce LayerwisE\nGradient AggregatTiOn (LEGATO), an aggregation algorithm that is, by contrast,\nscalable and generalizable. Informed by a study of layer-specific responses of\ngradients to Byzantine attacks, LEGATO employs a dynamic gradient reweighing\nscheme that is novel in its treatment of gradients based on layer-specific\nrobustness. We show that LEGATO is more computationally efficient than multiple\nstate-of-the-art techniques and more generally robust across a variety of\nattack settings in practice. We also demonstrate LEGATO's benefits for gradient\ndescent convergence in the absence of an attack.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 21:34:45 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Varma", "Kamala", ""], ["Zhou", "Yi", ""], ["Baracaldo", "Nathalie", ""], ["Anwar", "Ali", ""]]}, {"id": "2107.12566", "submitter": "Nicholas Springer", "authors": "Nicholas Springer (1), Wu-chang Feng (1) ((1) Portland State\n  University)", "title": "Thunder CTF: Learning Cloud Security on a Dime", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Organizations have rapidly shifted infrastructure and applications over to\npublic cloud computing services such as AWS (Amazon Web Services), Google Cloud\nPlatform, and Azure. Unfortunately, such services have security models that are\nsubstantially different and more complex than traditional enterprise security\nmodels. As a result, misconfiguration errors in cloud deployments have led to\ndozens of well-publicized breaches. This paper describes Thunder CTF, a\nscaffolded, scenario-based CTF (Capture-the-Flag) for helping students learn\nabout and practice cloud security skills. Thunder CTF is easily deployed at\nminimal cost and is highly extensible to allow for crowd-sourced development of\nnew levels as security issues evolve in the cloud.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 03:01:47 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Springer", "Nicholas", ""], ["Feng", "Wu-chang", ""]]}, {"id": "2107.12592", "submitter": "Insha Ullah Dr", "authors": "Insha Ullah, Kerrie Mengersen, Rob J Hyndman and James McGree", "title": "Detection of cybersecurity attacks through analysis of web browsing\n  activities using principal component analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Organizations such as government departments and financial institutions\nprovide online service facilities accessible via an increasing number of\ninternet connected devices which make their operational environment vulnerable\nto cyber attacks. Consequently, there is a need to have mechanisms in place to\ndetect cyber security attacks in a timely manner. A variety of Network\nIntrusion Detection Systems (NIDS) have been proposed and can be categorized\ninto signature-based NIDS and anomaly-based NIDS. The signature-based NIDS,\nwhich identify the misuse through scanning the activity signature against the\nlist of known attack activities, are criticized for their inability to identify\nnew attacks (never-before-seen attacks). Among anomaly-based NIDS, which\ndeclare a connection anomalous if it expresses deviation from a trained model,\nthe unsupervised learning algorithms circumvent this issue since they have the\nability to identify new attacks. In this study, we use an unsupervised learning\nalgorithm based on principal component analysis to detect cyber attacks. In the\ntraining phase, our approach has the advantage of also identifying outliers in\nthe training dataset. In the monitoring phase, our approach first identifies\nthe affected dimensions and then calculates an anomaly score by aggregating\nacross only those components that are affected by the anomalies. We explore the\nperformance of the algorithm via simulations and through two applications,\nnamely to the UNSW-NB15 dataset recently released by the Australian Centre for\nCyber Security and to the well-known KDD'99 dataset. The algorithm is scalable\nto large datasets in both training and monitoring phases, and the results from\nboth the simulated and real datasets show that the method has promise in\ndetecting suspicious network activities.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 04:38:46 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Ullah", "Insha", ""], ["Mengersen", "Kerrie", ""], ["Hyndman", "Rob J", ""], ["McGree", "James", ""]]}, {"id": "2107.12612", "submitter": "Wesley Joon-Wie Tann", "authors": "Wesley Joon-Wie Tann and Ee-Chien Chang", "title": "Poisoning of Online Learning Filters: DDoS Attacks and Countermeasures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The recent advancements in machine learning have led to a wave of interest in\nadopting online learning-based approaches for long-standing attack mitigation\nissues. In particular, DDoS attacks remain a significant threat to network\nservice availability even after more than two decades. These attacks have been\nwell studied under the assumption that malicious traffic originates from a\nsingle attack profile. Based on this premise, malicious traffic characteristics\nare assumed to be considerably different from legitimate traffic. Consequently,\nonline filtering methods are designed to learn network traffic distributions\nadaptively and rank requests according to their attack likelihood. During an\nattack, requests rated as malicious are precipitously dropped by the filters.\nIn this paper, we conduct the first systematic study on the effects of data\npoisoning attacks on online DDoS filtering; introduce one such attack method,\nand propose practical protective countermeasures for these attacks. We\ninvestigate an adverse scenario where the attacker is \"crafty\", switching\nprofiles during attacks and generating erratic attack traffic that is\never-shifting. This elusive attacker generates malicious requests by\nmanipulating and shifting traffic distribution to poison the training data and\ncorrupt the filters. To this end, we present a generative model MimicShift,\ncapable of controlling traffic generation while retaining the originating\nregular traffic's intrinsic properties. Comprehensive experiments show that\nonline learning filters are highly susceptible to poisoning attacks, sometimes\nperforming much worse than a random filtering strategy in this attack scenario.\nAt the same time, our proposed protective countermeasure effectively minimizes\nthe attack impact.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 05:55:33 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Tann", "Wesley Joon-Wie", ""], ["Chang", "Ee-Chien", ""]]}, {"id": "2107.12621", "submitter": "Theodosios Mourouzis", "authors": "Theodosis Mourouzis, Andreas Avgousti", "title": "Intrusion Detection with Machine Learning Using Open-Sourced Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  No significant research has been conducted so far on Intrusion detection due\nto data availability since, network traffic within companies is private\ninformation and no available logs can be found on the Internet for independent\nresearch. This paper aims to answer the question whether open-sourced data,\nthat is usually simulated network traffic can assist in developing a robust\nmodel that will effectively recognize and deter possible denial of service or\ninfiltration attacks.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 06:29:18 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Mourouzis", "Theodosis", ""], ["Avgousti", "Andreas", ""]]}, {"id": "2107.12699", "submitter": "Jukka Ruohonen", "authors": "Jukka Ruohonen and Kalle Hjerppe and Kalle Rindell", "title": "A Large-Scale Security-Oriented Static Analysis of Python Packages in\n  PyPI", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different security issues are a common problem for open source packages\narchived to and delivered through software ecosystems. These often manifest\nthemselves as software weaknesses that may lead to concrete software\nvulnerabilities. This paper examines various security issues in Python packages\nwith static analysis. The dataset is based on a snapshot of all packages stored\nto the Python Package Index (PyPI). In total, over 197 thousand packages and\nover 749 thousand security issues are covered. Even under the constraints\nimposed by static analysis, (a) the results indicate prevalence of security\nissues; at least one issue is present for about 46% of the Python packages. In\nterms of the issue types, (b) exception handling and different code injections\nhave been the most common issues. The subprocess module stands out in this\nregard. Reflecting the generally small size of the packages, (c) software size\nmetrics do not predict well the amount of issues revealed through static\nanalysis. With these results and the accompanying discussion, the paper\ncontributes to the field of large-scale empirical studies for better\nunderstanding security problems in software ecosystems.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 09:57:25 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Ruohonen", "Jukka", ""], ["Hjerppe", "Kalle", ""], ["Rindell", "Kalle", ""]]}, {"id": "2107.12724", "submitter": "Yinsong Xu", "authors": "Yinsong Xu and Zhen Yuan", "title": "Quantum Meet-in-the-Middle Attack on 7-round Feistel Construction", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum attacks on Feistel constructions have attracted much more attention\nfrom worldwide cryptologists. To reduce the time complexity of quantum attacks\non 7-round Feistel construction, we propose a quantum meet-in-the-middle attack\nbased on quantum claw finding algorithm and 5-round distinguisher in Q1 model\nfirstly. Compared with quantum attacks in Q2 model, our attack reduce the time\ncomplexity from $O({2^n})$ to $O({2^{7n/8}})$. Moreover, our attack belongs to\nQ1 model, which is more practical than Q2 model. When compared with best\nclassical attacks, our attack not only reduces the time complexity, but also\nreduces the data and memory complexity by ${2^{n/2}}$ and ${2^{n/4}}$\nrespectively.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 10:55:06 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Xu", "Yinsong", ""], ["Yuan", "Zhen", ""]]}, {"id": "2107.12806", "submitter": "Sunder Ali Khowaja", "authors": "Sunder Ali Khowaja, Kapal Dev, Nawab Muhammad Faseeh Qureshi, Parus\n  Khuwaja, Luca Foschini", "title": "Towards Industrial Private AI: A two-tier framework for data and model\n  security", "comments": "9 pages, 4 figures, 1 table, Magazine article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  With the advances in 5G and IoT devices, the industries are vastly adopting\nartificial intelligence (AI) techniques for improving classification and\nprediction-based services. However, the use of AI also raises concerns\nregarding data privacy and security that can be misused or leaked. Private AI\nwas recently coined to address the data security issue by combining AI with\nencryption techniques but existing studies have shown that model inversion\nattacks can be used to reverse engineer the images from model parameters. In\nthis regard, we propose a federated learning and encryption-based private\n(FLEP) AI framework that provides two-tier security for data and model\nparameters in an IIoT environment. We proposed a three-layer encryption method\nfor data security and provided a hypothetical method to secure the model\nparameters. Experimental results show that the proposed method achieves better\nencryption quality at the expense of slightly increased execution time. We also\nhighlighted several open issues and challenges regarding the FLEP AI\nframework's realization.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 13:28:07 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Khowaja", "Sunder Ali", ""], ["Dev", "Kapal", ""], ["Qureshi", "Nawab Muhammad Faseeh", ""], ["Khuwaja", "Parus", ""], ["Foschini", "Luca", ""]]}, {"id": "2107.12867", "submitter": "Wenqiang Li", "authors": "Wenqiang Li, Le Guan, Jingqiang Lin, Jiameng Shi, Fengjun Li", "title": "From Library Portability to Para-rehosting: Natively Executing\n  Microcontroller Software on Commodity Hardware", "comments": "18 pages, 4 figures, Network and Distributed Systems Security (NDSS)\n  Symposium 2021", "journal-ref": null, "doi": "10.14722/ndss.2021.24308", "report-no": null, "categories": "cs.PL cs.CR cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding bugs in microcontroller (MCU) firmware is challenging, even for\ndevice manufacturers who own the source code. The MCU runs different\ninstruction sets than x86 and exposes a very different development environment.\nThis invalidates many existing sophisticated software testing tools on x86. To\nmaintain a unified developing and testing environment, a straightforward way is\nto re-compile the source code into the native executable for a commodity\nmachine (called rehosting). However, ad-hoc re-hosting is a daunting and\ntedious task and subject to many issues (library-dependence, kernel-dependence\nand hardware-dependence). In this work, we systematically explore the\nportability problem of MCU software and propose pararehosting to ease the\nporting process. Specifically, we abstract and implement a portable MCU (PMCU)\nusing the POSIX interface. It models common functions of the MCU cores. For\nperipheral specific logic, we propose HAL-based peripheral function\nreplacement, in which high-level hardware functions are replaced with an\nequivalent backend driver on the host. These backend drivers are invoked by\nwell-designed para-APIs and can be reused across many MCU OSs. We categorize\ncommon HAL functions into four types and implement templates for quick backend\ndevelopment. Using the proposed approach, we have successfully rehosted nine\nMCU OSs including the widely deployed Amazon FreeRTOS, ARM Mbed OS, Zephyr and\nLiteOS. To demonstrate the superiority of our approach in terms of security\ntesting, we used off-the-shelf dynamic analysis tools (AFL and ASAN) against\nthe rehosted programs and discovered 28 previously-unknown bugs, among which 5\nwere confirmed by CVE and the other 19 were confirmed by vendors at the time of\nwriting.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 16:54:46 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Li", "Wenqiang", ""], ["Guan", "Le", ""], ["Lin", "Jingqiang", ""], ["Shi", "Jiameng", ""], ["Li", "Fengjun", ""]]}, {"id": "2107.12873", "submitter": "Ihsen Alouani", "authors": "Nicolas Fleury, Theo Dubrunquez and Ihsen Alouani", "title": "PDF-Malware: An Overview on Threats, Detection and Evasion Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent years, Portable Document Format, commonly known as PDF, has\nbecome a democratized standard for document exchange and dissemination. This\ntrend has been due to its characteristics such as its flexibility and\nportability across platforms. The widespread use of PDF has installed a false\nimpression of inherent safety among benign users. However, the characteristics\nof PDF motivated hackers to exploit various types of vulnerabilities, overcome\nsecurity safeguards, thereby making the PDF format one of the most efficient\nmalicious code attack vectors. Therefore, efficiently detecting malicious PDF\nfiles is crucial for information security. Several analysis techniques has been\nproposed in the literature, be it static or dynamic, to extract the main\nfeatures that allow the discrimination of malware files from benign ones. Since\nclassical analysis techniques may be limited in case of zero-days,\nmachine-learning based techniques have emerged recently as an automatic\nPDF-malware detection method that is able to generalize from a set of training\nsamples. These techniques are themselves facing the challenge of evasion\nattacks where a malicious PDF is transformed to look benign. In this work, we\ngive an overview on the PDF-malware detection problem. We give a perspective on\nthe new challenges and emerging solutions.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 15:15:20 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Fleury", "Nicolas", ""], ["Dubrunquez", "Theo", ""], ["Alouani", "Ihsen", ""]]}, {"id": "2107.12912", "submitter": "Federico Franzoni", "authors": "Federico Franzoni, Xavier Salleras, Vanesa Daza", "title": "AToM: Active Topology Monitoring for the Bitcoin Peer-to-Peer Network", "comments": "27 pages, 4 figures, Accepted to Peer to Peer Network and\n  Applications journal (special issue on Blockchain)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over the past decade, the Bitcoin P2P network protocol has become a reference\nmodel for all modern cryptocurrencies. While nodes in this network are known,\nthe connections among them are kept hidden, as it is commonly believed that\nthis helps protect from deanonymization and low-level attacks. However,\nadversaries can bypass this limitation by inferring connections through side\nchannels. At the same time, the lack of topology information hinders the\nanalysis of the network, which is essential to improve efficiency and security.\nIn this paper, we thoroughly review network-level attacks and empirically show\nthat topology obfuscation is not an effective countermeasure. We then argue\nthat the benefits of an open topology potentially outweigh its risks, and\npropose a protocol to reliably infer and monitor connections among reachable\nnodes of the Bitcoin network. We formally analyze our protocol and\nexperimentally evaluate its accuracy in both trusted and untrusted settings.\nResults show our system has a low impact on the network, and has precision and\nrecall are over 90% with up to 20% of malicious nodes in the network.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 16:11:36 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Franzoni", "Federico", ""], ["Salleras", "Xavier", ""], ["Daza", "Vanesa", ""]]}, {"id": "2107.12957", "submitter": "David Sommer", "authors": "David M. Sommer, Lukas Abfalterer, Sheila Zingg and Esfandiar\n  Mohammadi", "title": "Learning Numeric Optimal Differentially Private Truncated Additive\n  Mechanisms", "comments": "Code is available at\n  https://github.com/teuron/optimal_truncated_noise", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentially private (DP) mechanisms face the challenge of providing\naccurate results while protecting their inputs: the privacy-utility trade-off.\nA simple but powerful technique for DP adds noise to sensitivity-bounded query\noutputs to blur the exact query output: additive mechanisms. While a vast body\nof work considers infinitely wide noise distributions, some applications (e.g.,\nreal-time operating systems) require hard bounds on the deviations from the\nreal query, and only limited work on such mechanisms exist. An additive\nmechanism with truncated noise (i.e., with bounded range) can offer such hard\nbounds. We introduce a gradient-descent-based tool to learn truncated noise for\nadditive mechanisms with strong utility bounds while simultaneously optimizing\nfor differential privacy under sequential composition, i.e., scenarios where\nmultiple noisy queries on the same data are revealed. Our method can learn\ndiscrete noise patterns and not only hyper-parameters of a predefined\nprobability distribution. For sensitivity bounded mechanisms, we show that it\nis sufficient to consider symmetric and that\\new{, for from the mean\nmonotonically falling noise,} ensuring privacy for a pair of representative\nquery outputs guarantees privacy for all pairs of inputs (that differ in one\nelement). We find that the utility-privacy trade-off curves of our generated\nnoise are remarkably close to truncated Gaussians and even replicate their\nshape for $l_2$ utility-loss. For a low number of compositions, we also\nimproved DP-SGD (sub-sampling). Moreover, we extend Moments Accountant to\ntruncated distributions, allowing to incorporate mechanism output events with\nvarying input-dependent zero occurrence probability.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 17:22:57 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Sommer", "David M.", ""], ["Abfalterer", "Lukas", ""], ["Zingg", "Sheila", ""], ["Mohammadi", "Esfandiar", ""]]}, {"id": "2107.12958", "submitter": "Tingting Tang", "authors": "Tingting Tang, Ramy E. Ali, Hanieh Hashemi, Tynan Gangwani, Salman\n  Avestimehr and Murali Annavaram", "title": "Verifiable Coded Computing: Towards Fast, Secure and Private Distributed\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stragglers, Byzantine workers, and data privacy are the main bottlenecks in\ndistributed cloud computing. Several prior works proposed coded computing\nstrategies to jointly address all three challenges. They require either a large\nnumber of workers, a significant communication cost or a significant\ncomputational complexity to tolerate malicious workers. Much of the overhead in\nprior schemes comes from the fact that they tightly couple coding for all three\nproblems into a single framework. In this work, we propose Verifiable Coded\nComputing (VCC) framework that decouples Byzantine node detection challenge\nfrom the straggler tolerance. VCC leverages coded computing just for handling\nstragglers and privacy, and then uses an orthogonal approach of verifiable\ncomputing to tackle Byzantine nodes. Furthermore, VCC dynamically adapts its\ncoding scheme to tradeoff straggler tolerance with Byzantine protection and\nvice-versa. We evaluate VCC on compute intensive distributed logistic\nregression application. Our experiments show that VCC speeds up the\nconventional uncoded implementation of distributed logistic regression by\n$3.2\\times-6.9\\times$, and also improves the test accuracy by up to $12.6\\%$.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 17:23:09 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Tang", "Tingting", ""], ["Ali", "Ramy E.", ""], ["Hashemi", "Hanieh", ""], ["Gangwani", "Tynan", ""], ["Avestimehr", "Salman", ""], ["Annavaram", "Murali", ""]]}, {"id": "2107.12974", "submitter": "Aleksey Fedorov", "authors": "E.O. Kiktenko, A.S. Zelenetsky, A.K. Fedorov", "title": "Practical quantum multiparty signatures using quantum key distribution\n  networks", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital signatures are widely used for providing security of communications.\nAt the same time, the security of currently deployed digital signature\nprotocols is based on unproven computational assumptions. An efficient way to\nensure an unconditional (information-theoretic) security of communication is to\nuse quantum key distribution (QKD), whose security is based on laws of quantum\nmechanics. In this work, we develop an unconditionally secure signatures (USS)\nscheme that guarantees authenticity and transferability of arbitrary length\nmessages in a QKD network. In the proposed setup, the QKD network consists of\ntwo subnetworks: (i) the internal network that includes the signer and with\nlimitation on the number of malicious nodes, and (ii) the external one that has\nno assumptions on the number of malicious nodes. A price of the absence of the\ntrust assumption in the external subnetwork is a necessity of the assistance\nfrom internal subnetwork recipients for the verification of message-signature\npairs by external subnetwork recipients. We provide a comprehensive security\nanalysis of the developed scheme, perform an optimization of the scheme\nparameters with respect to the secret key consumption, and demonstrate that the\ndeveloped scheme is compatible with the capabilities of currently available QKD\ndevices.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 17:41:40 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Kiktenko", "E. O.", ""], ["Zelenetsky", "A. S.", ""], ["Fedorov", "A. K.", ""]]}, {"id": "2107.12981", "submitter": "Akihiro Fujihara Dr.", "authors": "Takaaki Yanagihara and Akihiro Fujihara", "title": "Cross-Referencing Method for Scalable Public Blockchain", "comments": "(29 pages, 18 figures, Internet of Things 15 (2021) 100419)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We previously proposed a cross-referencing method for enabling multiple\npeer-to-peer network domains to manage their own public blockchains and\nperiodically exchanging the state of the latest fixed block in the blockchain\nwith hysteresis signatures among all the domains via an upper network layer. In\nthis study, we evaluated the effectiveness of our method from three theoretical\nviewpoints: decentralization, scalability, and tamper resistance. We show that\nthe performance of the entire system can be improved because transactions and\nblocks are distributed only inside the domain. We argue that the transaction\nprocessing capacity will increase to 56,000 transactions per second, which is\nas much as that of a VISA credit card system. The capacity is also evaluated by\nmultiplying the number of domains by the average reduction in\ntransaction-processing time due to the increase in block size and reduction in\nthe block-generation-time interval by domain partition. For tamper resistance,\neach domain has evidence of the hysteresis signatures of the other domains in\nthe blockchain. We introduce two types of tamper-resistance-improvement ratios\nas evaluation measures of tamper resistance for a blockchain and theoretically\nexplain how tamper resistance is improved using our cross-referencing method.\nWith our method, tamper resistance improves as the number of domains increases.\nThe proposed system of 1,000 domains are 3-10 times more tamper-resistant than\nthat of 100 domains, and the capacity is 10 times higher. We conclude that our\nmethod enables a more scalable and tamper-resistant public blockchain balanced\nwith decentralization.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 17:50:37 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Yanagihara", "Takaaki", ""], ["Fujihara", "Akihiro", ""]]}, {"id": "2107.12997", "submitter": "Georgios Leontidis", "authors": "George Onoufriou, Paul Mayfield and Georgios Leontidis", "title": "Fully Homomorphically Encrypted Deep Learning as a Service", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully Homomorphic Encryption (FHE) is a relatively recent advancement in the\nfield of privacy-preserving technologies. FHE allows for the arbitrary depth\ncomputation of both addition and multiplication, and thus the application of\nabelian/polynomial equations, like those found in deep learning algorithms.\nThis project investigates, derives, and proves how FHE with deep learning can\nbe used at scale, with relatively low time complexity, the problems that such a\nsystem incurs, and mitigations/solutions for such problems. In addition, we\ndiscuss how this could have an impact on the future of data privacy and how it\ncan enable data sharing across various actors in the agri-food supply chain,\nhence allowing the development of machine learning-based systems. Finally, we\nfind that although FHE incurs a high spatial complexity cost, the time\ncomplexity is within expected reasonable bounds, while allowing for absolutely\nprivate predictions to be made, in our case for milk yield prediction.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 20:17:48 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Onoufriou", "George", ""], ["Mayfield", "Paul", ""], ["Leontidis", "Georgios", ""]]}, {"id": "2107.13047", "submitter": "Suyash Gupta", "authors": "Sajjad Rahnama, Suyash Gupta, Rohan Sogani, Dhruv Krishnan, Mohammad\n  Sadoghi", "title": "RingBFT: Resilient Consensus over Sharded Ring Topology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The recent surge in federated data-management applications has brought forth\nconcerns about the security of underlying data and the consistency of replicas\nin the presence of malicious attacks. A prominent solution in this direction is\nto employ a permissioned blockchain framework that is modeled around\ntraditional Byzantine Fault-Tolerant (BFT) consensus protocols. Any federated\napplication expects its data to be globally scattered to achieve faster access.\nBut, prior works have shown that traditional BFT protocols are slow and this\nled to the rise of sharded-replicated blockchains. Existing BFT protocols for\nthese sharded blockchains are efficient if client transactions require access\nto a single-shard, but face performance degradation if there is a cross-shard\ntransaction that requires access to multiple shards. However, cross-shard\ntransactions are common, and to resolve this dilemma, we present RingBFT, a\nnovel meta-BFT protocol for sharded blockchains. RingBFT requires shards to\nadhere to the ring order, and follow the principle of process, forward, and\nre-transmit while ensuring the communication between shards is linear. Our\nevaluation of RingBFT against state-of-the-art sharding BFT protocols\nillustrates that RingBFT achieves up to 25x higher throughput, easily scales to\nnearly 500 globally distributed nodes, and achieves a peak throughput of 1.2\nmillion txns/s.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 19:15:23 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Rahnama", "Sajjad", ""], ["Gupta", "Suyash", ""], ["Sogani", "Rohan", ""], ["Krishnan", "Dhruv", ""], ["Sadoghi", "Mohammad", ""]]}, {"id": "2107.13190", "submitter": "Aoting Hu", "authors": "Aoting Hu, Renjie Xie, Zhigang Lu, Aiqun Hu, Minhui Xue", "title": "TableGAN-MCA: Evaluating Membership Collisions of GAN-Synthesized\n  Tabular Data Releasing", "comments": "Accepted to ACM CCS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GAN)-synthesized table publishing lets\npeople privately learn insights without access to the private table. However,\nexisting studies on Membership Inference (MI) Attacks show promising results on\ndisclosing membership of training datasets of GAN-synthesized tables. Different\nfrom those works focusing on discovering membership of a given data point, in\nthis paper, we propose a novel Membership Collision Attack against GANs\n(TableGAN-MCA), which allows an adversary given only synthetic entries randomly\nsampled from a black-box generator to recover partial GAN training data.\nNamely, a GAN-synthesized table immune to state-of-the-art MI attacks is\nvulnerable to the TableGAN-MCA. The success of TableGAN-MCA is boosted by an\nobservation that GAN-synthesized tables potentially collide with the training\ndata of the generator.\n  Our experimental evaluations on TableGAN-MCA have five main findings. First,\nTableGAN-MCA has a satisfying training data recovery rate on three commonly\nused real-world datasets against four generative models. Second, factors,\nincluding the size of GAN training data, GAN training epochs and the number of\nsynthetic samples available to the adversary, are positively correlated to the\nsuccess of TableGAN-MCA. Third, highly frequent data points have high risks of\nbeing recovered by TableGAN-MCA. Fourth, some unique data are exposed to\nunexpected high recovery risks in TableGAN-MCA, which may attribute to GAN's\ngeneralization. Fifth, as expected, differential privacy, without the\nconsideration of the correlations between features, does not show commendable\nmitigation effect against the TableGAN-MCA. Finally, we propose two mitigation\nmethods and show promising privacy and utility trade-offs when protecting\nagainst TableGAN-MCA.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 06:43:36 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Hu", "Aoting", ""], ["Xie", "Renjie", ""], ["Lu", "Zhigang", ""], ["Hu", "Aiqun", ""], ["Xue", "Minhui", ""]]}, {"id": "2107.13324", "submitter": "Eric Culf", "authors": "Eric Culf and Thomas Vidick", "title": "A monogamy-of-entanglement game for subspace coset states", "comments": "13 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR quant-ph", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We establish a strong monogamy-of-entanglement property for subspace coset\nstates, which are uniform superpositions of vectors in a linear subspace of\n$\\mathbb{F}_2^n$ to which has been applied a quantum one-time pad. This\nproperty was conjectured recently by [Coladangelo, Liu, Liu, and Zhandry,\nCrypto'21] and shown to have applications to unclonable decryption and\ncopy-protection of pseudorandom functions. We present two proofs, one which\ndirectly follows the method of the original paper and the other which uses an\nobservation from [Vidick and Zhang, Eurocrypt'20] to reduce the analysis to a\nsimpler monogamy game based on BB'84 states. Both proofs ultimately rely on the\nsame proof technique, introduced in [Tomamichel, Fehr, Kaniewski and Wehner,\nNew Journal of Physics '13].\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 12:41:39 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Culf", "Eric", ""], ["Vidick", "Thomas", ""]]}, {"id": "2107.13360", "submitter": "Vicente Martin", "authors": "Vicente Martin, Juan Pedro Brito, Carmen Escribano, Marco Menchetti,\n  Catherine White, Andrew Lord, Felix Wissel, Matthias Gunkel, Paulette\n  Gavignet, Naveena Genay, Olivier Le Moult, Carlos Abell\\'an, Antonio\n  Manzalini, Antonio Pastor-Perales, Victor L\\'opez, Diego L\\'opez", "title": "Quantum Technologies in the Telecommunications Industry", "comments": null, "journal-ref": "EPJ Quantum Technology 8:19 (2021)", "doi": "10.1140/epjqt/s40507-021-00108-9", "report-no": null, "categories": "quant-ph cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum based technologies have been fundamental in our world. After\nproducing the laser and the transistor, the devices that have shaped our modern\ninformation society, the possibilities enabled by the ability to create and\nmanipulate individual quantum states opens the door to a second quantum\nrevolution. In this paper we explore the possibilities that these new\ntechnologies bring to the Telecommu-nications industry\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 13:46:32 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Martin", "Vicente", ""], ["Brito", "Juan Pedro", ""], ["Escribano", "Carmen", ""], ["Menchetti", "Marco", ""], ["White", "Catherine", ""], ["Lord", "Andrew", ""], ["Wissel", "Felix", ""], ["Gunkel", "Matthias", ""], ["Gavignet", "Paulette", ""], ["Genay", "Naveena", ""], ["Moult", "Olivier Le", ""], ["Abell\u00e1n", "Carlos", ""], ["Manzalini", "Antonio", ""], ["Pastor-Perales", "Antonio", ""], ["L\u00f3pez", "Victor", ""], ["L\u00f3pez", "Diego", ""]]}, {"id": "2107.13404", "submitter": "James Patrick-Evans", "authors": "James Patrick-Evans, Moritz Dannehl, Johannes Kinder", "title": "XFL: eXtreme Function Labeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reverse engineers would benefit from identifiers like function names, but\nthese are usually unavailable in binaries. Training a machine learning model to\npredict function names automatically is promising but fundamentally hard due to\nthe enormous number of classes. In this paper, we introduce eXtreme Function\nLabeling (XFL), an extreme multi-label learning approach to selecting\nappropriate labels for binary functions. XFL splits function names into tokens,\ntreating each as an informative label akin to the problem of tagging texts in\nnatural language. To capture the semantics of binary code, we introduce DEXTER,\na novel function embedding that combines static analysis-based features with\nlocal context from the call graph and global context from the entire binary. We\ndemonstrate that XFL outperforms state-of-the-art approaches to function\nlabeling on a dataset of over 10,000 binaries from the Debian project,\nachieving a precision of 82.5%. We also study combinations of XFL with\ndifferent published embeddings for binary functions and show that DEXTER\nconsistently improves over the state of the art in information gain. As a\nresult, we are able to show that binary function labeling is best phrased in\nterms of multi-label learning, and that binary function embeddings benefit from\nmoving beyond just learning from syntax.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 14:49:30 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Patrick-Evans", "James", ""], ["Dannehl", "Moritz", ""], ["Kinder", "Johannes", ""]]}, {"id": "2107.13639", "submitter": "Wentao Wang", "authors": "Wentao Wang, Han Xu, Xiaorui Liu, Yaxin Li, Bhavani Thuraisingham,\n  Jiliang Tang", "title": "Imbalanced Adversarial Training with Reweighting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training has been empirically proven to be one of the most\neffective and reliable defense methods against adversarial attacks. However,\nalmost all existing studies about adversarial training are focused on balanced\ndatasets, where each class has an equal amount of training examples. Research\non adversarial training with imbalanced training datasets is rather limited. As\nthe initial effort to investigate this problem, we reveal the facts that\nadversarially trained models present two distinguished behaviors from naturally\ntrained models in imbalanced datasets: (1) Compared to natural training,\nadversarially trained models can suffer much worse performance on\nunder-represented classes, when the training dataset is extremely imbalanced.\n(2) Traditional reweighting strategies may lose efficacy to deal with the\nimbalance issue for adversarial training. For example, upweighting the\nunder-represented classes will drastically hurt the model's performance on\nwell-represented classes, and as a result, finding an optimal reweighting value\ncan be tremendously challenging. In this paper, to further understand our\nobservations, we theoretically show that the poor data separability is one key\nreason causing this strong tension between under-represented and\nwell-represented classes. Motivated by this finding, we propose Separable\nReweighted Adversarial Training (SRAT) to facilitate adversarial training under\nimbalanced scenarios, by learning more separable features for different\nclasses. Extensive experiments on various datasets verify the effectiveness of\nthe proposed framework.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 20:51:36 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Wang", "Wentao", ""], ["Xu", "Han", ""], ["Liu", "Xiaorui", ""], ["Li", "Yaxin", ""], ["Thuraisingham", "Bhavani", ""], ["Tang", "Jiliang", ""]]}, {"id": "2107.13640", "submitter": "Amit Chaulwar", "authors": "Amit Chaulwar and Michael Huth", "title": "Secure Bayesian Federated Analytics for Privacy-Preserving Trend\n  Detection", "comments": "10 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated analytics has many applications in edge computing, its use can lead\nto better decision making for service provision, product development, and user\nexperience. We propose a Bayesian approach to trend detection in which the\nprobability of a keyword being trendy, given a dataset, is computed via Bayes'\nTheorem; the probability of a dataset, given that a keyword is trendy, is\ncomputed through secure aggregation of such conditional probabilities over\nlocal datasets of users. We propose a protocol, named SAFE, for Bayesian\nfederated analytics that offers sufficient privacy for production grade use\ncases and reduces the computational burden of users and an aggregator. We\nillustrate this approach with a trend detection experiment and discuss how this\napproach could be extended further to make it production-ready.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 20:52:28 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Chaulwar", "Amit", ""], ["Huth", "Michael", ""]]}, {"id": "2107.13723", "submitter": "Roland Croft", "authors": "Roland Croft, Yongzheng Xie, Mansooreh Zahedi, M. Ali Babar, Christoph\n  Treude", "title": "An Empirical Study of Developers' Discussions about Security Challenges\n  of Different Programming Languages", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given programming languages can provide different types and levels of\nsecurity support, it is critically important to consider security aspects while\nselecting programming languages for developing software systems. Inadequate\nconsideration of security in the choice of a programming language may lead to\npotential ramifications for secure development. Whilst theoretical analysis of\nthe supposed security properties of different programming languages has been\nconducted, there has been relatively little effort to empirically explore the\nactual security challenges experienced by developers. We have performed a\nlarge-scale study of the security challenges of 15 programming languages by\nquantitatively and qualitatively analysing the developers' discussions from\nStack Overflow and GitHub. By leveraging topic modelling, we have derived a\ntaxonomy of 18 major security challenges for 6 topic categories. We have also\nconducted comparative analysis to understand how the identified challenges vary\nregarding the different programming languages and data sources. Our findings\nsuggest that the challenges and their characteristics differ substantially for\ndifferent programming languages and data sources, i.e., Stack Overflow and\nGitHub. The findings provide evidence-based insights and understanding of\nsecurity challenges related to different programming languages to software\nprofessionals (i.e., practitioners or researchers). The reported taxonomy of\nsecurity challenges can assist both practitioners and researchers in better\nunderstanding and traversing the secure development landscape. This study\nhighlights the importance of the choice of technology, e.g., programming\nlanguage, in secure software engineering. Hence, the findings are expected to\nmotivate practitioners to consider the potential impact of the choice of\nprogramming languages on software security.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 03:19:52 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Croft", "Roland", ""], ["Xie", "Yongzheng", ""], ["Zahedi", "Mansooreh", ""], ["Babar", "M. Ali", ""], ["Treude", "Christoph", ""]]}, {"id": "2107.13743", "submitter": "Hikmat Farhat", "authors": "Hikmat Farhat and Veronica Rammouz", "title": "Malware Classification Using Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of the number of devices on the Internet, malware poses\na threat not only to the affected devices but also their ability to use said\ndevices to launch attacks on the Internet ecosystem. Rapid malware\nclassification is an important tools to combat that threat. One of the\nsuccessful approaches to classification is based on malware images and deep\nlearning. While many deep learning architectures are very accurate they usually\ntake a long time to train. In this work we perform experiments on multiple well\nknown, pre-trained, deep network architectures in the context of transfer\nlearning. We show that almost all them classify malware accurately with a very\nshort training period.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 04:34:52 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Farhat", "Hikmat", ""], ["Rammouz", "Veronica", ""]]}, {"id": "2107.13754", "submitter": "I Wayan Budi  Sentana", "authors": "I Wayan Budi Sentana, Muhammad Ikram, Mohamed Ali Kaafar, Shlomo\n  Berkovsky", "title": "Empirical Security and Privacy Analysis of Mobile Symptom Checking\n  Applications on Google Play", "comments": "Published in SECRYPT 2021", "journal-ref": null, "doi": "10.5220/0010520106650673", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Smartphone technology has drastically improved over the past decade. These\nimprovements have seen the creation of specialized health applications, which\noffer consumers a range of health-related activities such as tracking and\nchecking symptoms of health conditions or diseases through their smartphones.\nWe term these applications as Symptom Checking apps or simply SymptomCheckers.\nDue to the sensitive nature of the private data they collect, store and manage,\nleakage of user information could result in significant consequences. In this\npaper, we use a combination of techniques from both static and dynamic analysis\nto detect, trace and categorize security and privacy issues in 36 popular\nSymptomCheckers on Google Play. Our analyses reveal that SymptomCheckers\nrequest a significantly higher number of sensitive permissions and embed a\nhigher number of third-party tracking libraries for targeted advertisements and\nanalytics exploiting the privileged access of the SymptomCheckers in which they\nexist, as a mean of collecting and sharing critically sensitive data about the\nuser and their device. We find that these are sharing the data that they\ncollect through unencrypted plain text to the third-party advertisers and, in\nsome cases, to malicious domains. The results reveal that the exploitation of\nSymptomCheckers is present in popular apps, still readily available on Google\nPlay.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 05:44:44 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Sentana", "I Wayan Budi", ""], ["Ikram", "Muhammad", ""], ["Kaafar", "Mohamed Ali", ""], ["Berkovsky", "Shlomo", ""]]}, {"id": "2107.13759", "submitter": "Nickson Karie", "authors": "Nickson M. Karie and Craig Valli", "title": "Digital Forensic Readiness Implementation in SDN: Issues and Challenges", "comments": "20th European Conference on Cyber Warfare and Security (ECCWS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The continued evolution in computer network technologies has seen the\nintroduction of new paradigms like Software Defined Networking (SDN) which has\naltered many traditional networking principles in todays business environments.\nSDN has brought about unprecedented change to the way organisations plan,\ndevelop, and enact their networking technology and infrastructure strategies.\nHowever, SDN does not only offer new opportunities and abilities for\norganisations to redesign their entire network infrastructure but also presents\na different set of issues and challenges that need to be resolved. One such\nchallenge is the implementation of Digital Forensic Readiness (DFR) in SDN\nenvironments. This paper, therefore, examines existing literature and\nhighlights the different issues and challenges impacting the implementation of\nDFR in SDN. However, the paper also goes further to offer insights on the\ndifferent countermeasures that organisations can embrace to enhance their\nability to respond to cybersecurity incidents as well as help them in\nimplementing DFR in SDN environments\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 06:00:02 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Karie", "Nickson M.", ""], ["Valli", "Craig", ""]]}, {"id": "2107.13862", "submitter": "Daniel Lerch Hostalot PhD", "authors": "David Meg\\'ias, Daniel Lerch-Hostalot", "title": "Subsequent embedding in image steganalysis: Theoretical framework and\n  practical applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Steganalysis is a collection of techniques used to detect whether secret\ninformation is embedded in a carrier using steganography. Most of the existing\nsteganalytic methods are based on machine learning, which typically requires\ntraining a classifier with \"laboratory\" data. However, applying\nmachine-learning classification to a new source of data is challenging, since\nthere is typically a mismatch between the training and the testing sets. In\naddition, other sources of uncertainty affect the steganlytic process,\nincluding the mismatch between the targeted and the true steganographic\nalgorithms, unknown parameters -- such as the message length -- and even having\na mixture of several algorithms and parameters, which would constitute a\nrealistic scenario. This paper presents subsequent embedding as a valuable\nstrategy that can be incorporated into modern steganalysis. Although this\nsolution has been applied in previous works, a theoretical basis for this\nstrategy was missing. Here, we cover this research gap by introducing the\n\"directionality\" property of features with respect to data embedding. Once this\nstrategy is sustained by a consistent theoretical framework, new practical\napplications are also described and tested against standard steganography,\nmoving steganalysis closer to real-world conditions.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 09:49:01 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Meg\u00edas", "David", ""], ["Lerch-Hostalot", "Daniel", ""]]}, {"id": "2107.13876", "submitter": "Felice Antonio Merra", "authors": "Vito Walter Anelli, Yashar Deldjoo, Tommaso Di Noia, Felice Antonio\n  Merra", "title": "Understanding the Effects of Adversarial Personalized Ranking\n  Optimization Method on Recommendation Quality", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recommender systems (RSs) employ user-item feedback, e.g., ratings, to match\ncustomers to personalized lists of products. Approaches to top-k recommendation\nmainly rely on Learning-To-Rank algorithms and, among them, the most widely\nadopted is Bayesian Personalized Ranking (BPR), which bases on a pair-wise\noptimization approach. Recently, BPR has been found vulnerable against\nadversarial perturbations of its model parameters. Adversarial Personalized\nRanking (APR) mitigates this issue by robustifying BPR via an adversarial\ntraining procedure. The empirical improvements of APR's accuracy performance on\nBPR have led to its wide use in several recommender models. However, a key\noverlooked aspect has been the beyond-accuracy performance of APR, i.e.,\nnovelty, coverage, and amplification of popularity bias, considering that\nrecent results suggest that BPR, the building block of APR, is sensitive to the\nintensification of biases and reduction of recommendation novelty. In this\nwork, we model the learning characteristics of the BPR and APR optimization\nframeworks to give mathematical evidence that, when the feedback data have a\ntailed distribution, APR amplifies the popularity bias more than BPR due to an\nunbalanced number of received positive updates from short-head items. Using\nmatrix factorization (MF), we empirically validate the theoretical results by\nperforming preliminary experiments on two public datasets to compare BPR-MF and\nAPR-MF performance on accuracy and beyond-accuracy metrics. The experimental\nresults consistently show the degradation of novelty and coverage measures and\na worrying amplification of bias.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 10:22:20 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Anelli", "Vito Walter", ""], ["Deldjoo", "Yashar", ""], ["Di Noia", "Tommaso", ""], ["Merra", "Felice Antonio", ""]]}, {"id": "2107.14065", "submitter": "Gregory Falco", "authors": "Gregory Falco, Paul Cornish, Sadie Creese, Madeline Carr, Myriam Dunn\n  Cavelty, Claudia Eckert, Herbert Lin, Gen Goto, Jamie Saunders, Andrew\n  Grotto, Howard Shrobe, Sean Kanuck, Lawrence Susskind, Arvind Parthasarathi", "title": "Cyber Crossroads: A Global Research Collaborative on Cyber Risk\n  Governance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spending on cybersecurity products and services is expected to top 123\nbillion U.S. dollars for 2020, more than double the 55 billion U.S. dollars\nspent in 2011.1 In that same period, cyber breaches quadrupled. Organizations\nglobally face increasing liabilities, while boards of directors grapple with a\nseemingly Sisyphean challenge. Cyber Crossroads was born out of these alarming\ntrends and a realization that the world cannot go on funneling finite resources\ninto an indefinite, intractable problem. Cyber Crossroads brings together\nexpertise from across the world, spanning aspects of the cyber problem\n(including technology, legal, risk, and economic) with the goal of creating a\nCyber Standard of Care built through a global, not-for-profit research\ncollaborative with no commercial interests. A Cyber Standard of Care should be\napplicable across industries and regardless of the organization size. It should\nbe practical and implementable, with no requirement to purchase any\nproduct/service. Cyber Standard of Care should be woven into the existing\ngovernance fabric of the organization and it should not be yet another\ntechnical checklist, but a process/governance framework that can stand over\ntime. To achieve this, we engaged with cyber risk experts and practitioners\nwith a variety of relevant expertise, secured the advice/guidance of regulators\nand legal experts across jurisdictions, and interviewed leaders from 56\norganizations globally to understand their challenges and identify best\npractices.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 11:58:27 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Falco", "Gregory", ""], ["Cornish", "Paul", ""], ["Creese", "Sadie", ""], ["Carr", "Madeline", ""], ["Cavelty", "Myriam Dunn", ""], ["Eckert", "Claudia", ""], ["Lin", "Herbert", ""], ["Goto", "Gen", ""], ["Saunders", "Jamie", ""], ["Grotto", "Andrew", ""], ["Shrobe", "Howard", ""], ["Kanuck", "Sean", ""], ["Susskind", "Lawrence", ""], ["Parthasarathi", "Arvind", ""]]}, {"id": "2107.14082", "submitter": "Adib Syed Adib", "authors": "Adib Mohammed Syed", "title": "Social engineering: Concepts, Techniques and Security Countermeasures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The purpose of this report is to research the topic called Social Engineering\nin Cyber Security and present the explanation of the meaning, concepts,\ntechniques, and security countermeasures of Social Engineering based on factual\nacademic research.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 14:05:05 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Syed", "Adib Mohammed", ""]]}, {"id": "2107.14093", "submitter": "Elena Baninemeh", "authors": "Elena Baninemeh (1), Siamak Farshidi (2), Slinger Jansen (1) ((1)\n  Department of Information and Computer Science at Utrecht University,\n  Utrecht, the Netherlands, (2) Informatics Institute at University of\n  Amsterdam, Amsterdam, the Netherlands)", "title": "A Decision Model for Decentralized Autonomous Organization Platform\n  Selection: Three Industry Case Studies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized autonomous organizations as a new form of online governance\narecollections of smart contracts deployed on a blockchain platform that\nintercede groupsof people. A growing number of Decentralized Autonomous\nOrganization Platforms,such as Aragon and Colony, have been introduced in the\nmarket to facilitate thedevelopment process of such organizations. Selecting\nthe best fitting platform ischallenging for the organizations, as a significant\nnumber of decision criteria, such aspopularity, developer availability,\ngovernance issues, and consistent documentation ofsuch platforms, should be\nconsidered. Additionally, decision-makers at theorganizations are not experts\nin every domain, so they must continuously acquirevolatile knowledge regarding\nsuch platforms and keep themselves updated.Accordingly, a decision model is\nrequired to analyze the decision criteria usingsystematic identification and\nevaluation of potential alternative solutions for adevelopment project. We have\ndeveloped a theoretical framework to assist softwareengineers with a set of\nMulti-Criteria Decision-Making problems in software production.This study\npresents a decision model as a Multi-Criteria Decision-Making problem forthe\ndecentralized autonomous organization platform selection problem. Weconducted\nthree industry case studies in the context of three decentralizedautonomous\norganizations to evaluate the effectiveness and efficiency of the decisionmodel\nin assisting decision-makers.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 10:05:56 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Baninemeh", "Elena", ""], ["Farshidi", "Siamak", ""], ["Jansen", "Slinger", ""]]}, {"id": "2107.14110", "submitter": "Juan C. P\\'erez", "authors": "Juan C. P\\'erez, Motasem Alfarra, Guillaume Jeanneret, Laura Rueda,\n  Ali Thabet, Bernard Ghanem, Pablo Arbel\\'aez", "title": "Enhancing Adversarial Robustness via Test-time Transformation Ensembling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning models are prone to being fooled by imperceptible perturbations\nknown as adversarial attacks. In this work, we study how equipping models with\nTest-time Transformation Ensembling (TTE) can work as a reliable defense\nagainst such attacks. While transforming the input data, both at train and test\ntimes, is known to enhance model performance, its effects on adversarial\nrobustness have not been studied. Here, we present a comprehensive empirical\nstudy of the impact of TTE, in the form of widely-used image transforms, on\nadversarial robustness. We show that TTE consistently improves model robustness\nagainst a variety of powerful attacks without any need for re-training, and\nthat this improvement comes at virtually no trade-off with accuracy on clean\nsamples. Finally, we show that the benefits of TTE transfer even to the\ncertified robustness domain, in which TTE provides sizable and consistent\nimprovements.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 15:32:35 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["P\u00e9rez", "Juan C.", ""], ["Alfarra", "Motasem", ""], ["Jeanneret", "Guillaume", ""], ["Rueda", "Laura", ""], ["Thabet", "Ali", ""], ["Ghanem", "Bernard", ""], ["Arbel\u00e1ez", "Pablo", ""]]}, {"id": "2107.14136", "submitter": "Nur Imtiazul Haque", "authors": "Nur Imtiazul Haque, Mohammad Ashiqur Rahman, Dong Chen, and Hisham\n  Kholidy", "title": "BIoTA Control-Aware Attack Analytics for Building Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern building control systems adopt demand control heating, ventilation,\nand cooling (HVAC) for increased energy efficiency. The integration of the\nInternet of Things (IoT) in the building control system can determine real-time\ndemand, which has made the buildings smarter, reliable, and efficient. As\noccupants in a building are the main source of continuous heat and $CO_2$\ngeneration, estimating the accurate number of people in real-time using\nbuilding IoT (BIoT) system facilities is essential for optimal energy\nconsumption and occupants' comfort. However, the incorporation of less secured\nIoT sensor nodes and open communication network in the building control system\neventually increases the number of vulnerable points to be compromised.\nExploiting these vulnerabilities, attackers can manipulate the controller with\nfalse sensor measurements and disrupt the system's consistency. The attackers\nwith the knowledge of overall system topology and control logics can launch\nattacks without alarming the system. This paper proposes a building internet of\nthings analyzer (BIoTA)\nframework\\footnote{https://github.com/imtiazulhaque/research-implementations/tree/main/biota}\nthat assesses the smart building HVAC control system's security using formal\nattack modeling. We evaluate the proposed attack analyzer's effectiveness on\nthe commercial occupancy dataset (COD) and the KTH live-in lab dataset. To the\nbest of our knowledge, this is the first research attempt to formally model a\nBIoT-based HVAC control system and perform an attack analysis.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 00:15:56 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Haque", "Nur Imtiazul", ""], ["Rahman", "Mohammad Ashiqur", ""], ["Chen", "Dong", ""], ["Kholidy", "Hisham", ""]]}, {"id": "2107.14140", "submitter": "Md Amiruzzaman", "authors": "Asif Bhat, Rizal Mohd Nor, Md Amiruzzaman and Md. Rajibul Islam", "title": "Methodology and Analysis of Smart Contracts in Blockchain-Based\n  International Trade Application", "comments": "10 pages, 2 figures, and 1 table. To appear in Proceedings of ICCTSAI\n  2021", "journal-ref": "International Conference on Computing and Technological Solutions\n  with Artificial Intelligence (ICCTSAI 2021)", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blokchain is used in a variety of applications where trustworthy computing is\nre-quired. Trade finance is one of these areas that would benefit immensely\nfrom a decentralized way of doing transactions. This paper presents the\npreliminary as-sessment of Accepire-BT, a software platform developed for the\npractice of col-laborative Trade Finance. The proposed solution is enforced by\nsmart contracts using Solidity, the underlying programming language for the\nEthereum block-chain. We evaluated the performance in the Rinkeby test network\nby using Remix and MetaMask. The results of the preliminary trial show that\nsmart contracts take less than one minute per cycle. Also, we present a\ndiscussion about costs for us-ing the public Ethereum Rinkeby network.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 02:14:30 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Bhat", "Asif", ""], ["Nor", "Rizal Mohd", ""], ["Amiruzzaman", "Md", ""], ["Islam", "Md. Rajibul", ""]]}, {"id": "2107.14142", "submitter": "Yuqi Bai", "authors": "Yuqi Bai and Lei Luo", "title": "Zero-knowledge Based Proof-chain -- A methodology for blockchain-partial\n  system", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Intuitively there is a drastic distinction between the pure decentralized\nblock-chain systems like Defis and those that only utilize block-chain as an\nenhancing technology but remain centralized with real-world business model and\nconventional technologies like database, application server, etc. Our study\nexplores extensively this distinction from a methodological point of view,\nclassifies them into blockchain-complete and blockchain-partial, analyzes key\nfeatures of the two types, and reveals the root cause of this distinction. We\nanalyze the function or, in more strong words, the \"ultimate purpose\" of\nblockchain in the blockchain-partial systems, and present a conceptual model we\nnamed proof-chain that quite satisfactorily represented the general paradigm of\nblockchain in blockchain-partial systems. A universal tension between strength\nof proof-chain and privacy is then revealed and the zero-knowledge based\nproof-chain takes shape. Several case studies demonstrate the explaining power\nof our proof-chain methodology. We then apply proof-chain methodology to the\nanalysis of the ecosystem of a collaborating group of blockchain-partial\nsystems, representing the paradigm of public and private data domain whose\nborder the proof-chain crosses. Finally, some derived guidelines from this\nmethodology speak usefulness of our methodology.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 21:59:21 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Bai", "Yuqi", ""], ["Luo", "Lei", ""]]}, {"id": "2107.14201", "submitter": "Phani Vadrevu", "authors": "Shekhar Chalise and Phani Vadrevu (University of New Orleans)", "title": "A Study of Feasibility and Diversity of Web Audio Fingerprints", "comments": "15 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior measurement studies on browser fingerprinting have unfortunately\nlargely excluded Web Audio API-based fingerprinting in their analysis. We\naddress this issue by conducting the first systematic study of effectiveness of\nweb audio fingerprinting mechanisms. We focus on studying the feasibility and\ndiversity properties of web audio fingerprinting. Along with 3 known audio\nfingerprinting vectors, we designed and implemented 4 new audio fingerprint\nvectors that work by obtaining FFTs of waveforms generated via different\nmethods. Our study analyzed audio fingerprints from 2093 web users and presents\nnew insights into the nature of Web Audio fingerprints. First, we show that\naudio fingeprinting vectors, unlike other prior vectors, reveal an apparent\nfickleness with some users' browsers giving away differing fingerprints in\nrepeated attempts. However, we show that it is possible to devise a graph-based\nanalysis mechanism to collectively consider all the different fingerprints of\nusers and thus craft a stable fingerprinting mechanism. Our analysis also shows\nthat it is possible to do this in a timely fashion.\n  Next, we investigate the diversity of audio fingerprints and compare this\nwith prior techniques. Our results show that audio fingerprints are much less\ndiverse than other vectors with only 95 distinct fingerprints among 2093 users.\nAt the same time, further analysis shows that web audio fingerprinting can\npotentially bring considerable additive value (in terms of entropy) to existing\nfingerprinting mechanisms. We also show that our results contradict the current\nsecurity and privacy recommendations provided by W3C regarding audio\nfingerprinting. Overall, our systematic study allows browser developers to\ngauge the degree of privacy invasion presented by audio fingerprinting thus\nhelping them take a more informed stance when designing privacy protection\nfeatures in the future.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 17:40:59 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Chalise", "Shekhar", "", "University of New Orleans"], ["Vadrevu", "Phani", "", "University of New Orleans"]]}]