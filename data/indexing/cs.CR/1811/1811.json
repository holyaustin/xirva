[{"id": "1811.00121", "submitter": "George Kesidis", "authors": "David J. Miller, Xinyi Hu, Zhen Xiang, and George Kesidis", "title": "A Mixture Model Based Defense for Data Poisoning Attacks Against Naive\n  Bayes Spam Filters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Naive Bayes spam filters are highly susceptible to data poisoning attacks.\nHere, known spam sources/blacklisted IPs exploit the fact that their received\nemails will be treated as (ground truth) labeled spam examples, and used for\nclassifier training (or re-training). The attacking source thus generates\nemails that will skew the spam model, potentially resulting in great\ndegradation in classifier accuracy. Such attacks are successful mainly because\nof the poor representation power of the naive Bayes (NB) model, with only a\nsingle (component) density to represent spam (plus a possible attack). We\npropose a defense based on the use of a mixture of NB models. We demonstrate\nthat the learned mixture almost completely isolates the attack in a second NB\ncomponent, with the original spam component essentially unchanged by the\nattack. Our approach addresses both the scenario where the classifier is being\nre-trained in light of new data and, significantly, the more challenging\nscenario where the attack is embedded in the original spam training set. Even\nfor weak attack strengths, BIC-based model order selection chooses a\ntwo-component solution, which invokes the mixture-based defense. Promising\nresults are presented on the TREC 2005 spam corpus.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 21:04:43 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Miller", "David J.", ""], ["Hu", "Xinyi", ""], ["Xiang", "Zhen", ""], ["Kesidis", "George", ""]]}, {"id": "1811.00125", "submitter": "Karl Kreder Iii", "authors": "Karl J. Kreder III", "title": "BlockReduce: Scaling Blockchain to Human Commerce", "comments": "9 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchains have shown great promise as peer-to-peer digital currency systems\nover the past 10 years. However, with increased popularity, the demand for\nprocessing transactions has also grown leading to increased costs, confirmation\ntimes, and limited blockchain utility. There have been a number of proposals on\nhow to scale blockchains, such as Plasma, Polkadot, Elastico, RapidChain,\nBitcoin-NG, and OmniLedger. These solutions all propose the segmentation of\nevery function of a blockchain, namely consensus, permanent data storage,\ntransaction processing, and consistency, which significantly increases the\ncomplexity and difficulty of implementation. BlockReduce is a new blockchain\nstructure which only segments consistency, allowing it to scale to handle tens\nof thousands of transactions per second without impacting fault tolerance or\ndecentralization. Moreover, BlockReduce will significantly decrease node\nbandwidth requirements and network latency through incentives while\nsimultaneously minimizing other resource demands in order to prevent\ncentralization of nodes.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 21:18:55 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Kreder", "Karl J.", "III"]]}, {"id": "1811.00142", "submitter": "Tingting Li", "authors": "Tingting Li and Cheng Feng and Chris Hankin", "title": "Improving ICS Cyber Resilience through Optimal Diversification of\n  Network Resources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network diversity has been widely recognized as an effective defense strategy\nto mitigate the spread of malware. Optimally diversifying network resources can\nimprove the resilience of a network against malware propagation. This work\nproposes an efficient method to compute such an optimal deployment, in the\ncontext of upgrading a legacy Industrial Control System with modern IT\ninfrastructure. Our approach can tolerate various constraints when searching\nfor an optimal diversification, such as outdated products and strict\nconfiguration policies. We explicitly measure the vulnerability similarity of\nproducts based on the CVE/NVD, to estimate the infection rate of malware\nbetween products. A Stuxnet-inspired case demonstrates our optimal\ndiversification in practice, particularly when constrained by various\nrequirements. We then measure the improved resilience of the diversified\nnetwork in terms of a well-defined diversity metric and Mean-time-to-compromise\n(MTTC), to verify the effectiveness of our approach. We further evaluate three\nfactors affecting the performance of the optimization, such as the network\nstructure, the variety of products and constraints. Finally, we show the\ncompetitive scalability of our approach in finding optimal solutions within a\ncouple of seconds to minutes for networks of large scales (up to 10,000 hosts)\nand high densities (up to 240,000 edges).\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 22:35:27 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 14:14:41 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Li", "Tingting", ""], ["Feng", "Cheng", ""], ["Hankin", "Chris", ""]]}, {"id": "1811.00175", "submitter": "Ivan De Oliveira Nunes", "authors": "Ivan De Oliveira Nunes, Karim Eldefrawy, Norrathep Rattanavipanon,\n  Michael Steiner, Gene Tsudik", "title": "Formally Verified Hardware/Software Co-Design for Remote Attestation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we take the first step towards formal verification of Remote\nAttestation (RA) by designing and verifying an architecture called VRASED:\nVerifiable Remote Attestation for Simple Embedded Devices. VRASED instantiates\na hybrid (HW/SW) RA co-design aimed at low-end embedded systems, e.g., simple\nIoT devices. VRASED provides a level of security comparable to HW-based\napproaches, while relying on SW to minimize additional HW costs. Since security\nproperties must be jointly guaranteed by HW and SW, verification is a\nchallenging task, which has never been attempted before in the context of RA.\nWe believe that VRASED is the first formally verified RA scheme. To the best of\nour knowledge, it is also the first formal verification of a HW/SW\nimplementation of any security service. To demonstrate VRASED's practicality\nand low overhead, we instantiate and evaluate it on a commodity platform (TI\nMSP430). VRASED's publicly available implementation was deployed on the Basys3\nFPGA.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 01:09:18 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 19:26:03 GMT"}, {"version": "v3", "created": "Fri, 17 May 2019 17:55:25 GMT"}, {"version": "v4", "created": "Fri, 24 May 2019 22:02:42 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Nunes", "Ivan De Oliveira", ""], ["Eldefrawy", "Karim", ""], ["Rattanavipanon", "Norrathep", ""], ["Steiner", "Michael", ""], ["Tsudik", "Gene", ""]]}, {"id": "1811.00236", "submitter": "Warit Sirichotedumrong", "authors": "Tatsuya Chuman, Warit Sirichotedumrong, Hitoshi Kiya", "title": "Encryption-then-Compression Systems using Grayscale-based Image\n  Encryption for JPEG Images", "comments": "Accepted in IEEE Transactions on Information Forensics & Security", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A block scrambling-based encryption scheme is presented to enhance the\nsecurity of Encryption-then-Compression (EtC) systems with JPEG compression,\nwhich allow us to securely transmit images through an untrusted channel\nprovider, such as social network service providers. The proposed scheme enables\nthe use of a smaller block size and a larger number of blocks than the\nconventional scheme. Images encrypted using the proposed scheme include less\ncolor information due to the use of grayscale images even when the original\nimage has three color channels. These features enhance security against various\nattacks such as jigsaw puzzle solver and brute-force attacks. In an experiment,\nthe security against jigsaw puzzle solver attacks is evaluated. Encrypted\nimages were uploaded to and then downloaded from Facebook and Twitter, and the\nresults demonstrated that the proposed scheme is effective for EtC systems.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 05:17:27 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Chuman", "Tatsuya", ""], ["Sirichotedumrong", "Warit", ""], ["Kiya", "Hitoshi", ""]]}, {"id": "1811.00262", "submitter": "Masahito Hayashi", "authors": "Masahito Hayashi", "title": "Semi-Finite Length Analysis for Information Theoretic Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the optimal value for various information-theoretical tasks.\nThere are several studies for the asymptotic expansion for these optimal values\nup to the order $\\sqrt{n}$ or $\\log n$. However, these expansions have errors\nof the order $o(\\sqrt{n})$ or $o(\\log n)$, which does not goes to zero\nasymptotically. To resolve this problem, we derive the asymptotic expansion up\nto the constant order for upper and lower bounds of these optimal values. While\nthe expansions of upper and lower bonds do not match, they clarify the ranges\nof these optimal values, whose errors go to zero asymptotically.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 07:07:01 GMT"}, {"version": "v2", "created": "Sat, 10 Nov 2018 07:24:52 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Hayashi", "Masahito", ""]]}, {"id": "1811.00513", "submitter": "Congzheng Song", "authors": "Congzheng Song, Vitaly Shmatikov", "title": "Auditing Data Provenance in Text-Generation Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To help enforce data-protection regulations such as GDPR and detect\nunauthorized uses of personal data, we develop a new \\emph{model auditing}\ntechnique that helps users check if their data was used to train a machine\nlearning model. We focus on auditing deep-learning models that generate\nnatural-language text, including word prediction and dialog generation. These\nmodels are at the core of popular online services and are often trained on\npersonal data such as users' messages, searches, chats, and comments.\n  We design and evaluate a black-box auditing method that can detect, with very\nfew queries to a model, if a particular user's texts were used to train it\n(among thousands of other users). We empirically show that our method can\nsuccessfully audit well-generalized models that are not overfitted to the\ntraining data. We also analyze how text-generation models memorize word\nsequences and explain why this memorization makes them amenable to auditing.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 17:32:44 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 18:47:05 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Song", "Congzheng", ""], ["Shmatikov", "Vitaly", ""]]}, {"id": "1811.00591", "submitter": "Miki Verma", "authors": "Miki E. Verma, Robert A. Bridges", "title": "Defining a Metric Space of Host Logs and Operational Use Cases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Host logs, in particular, Windows Event Logs, are a valuable source of\ninformation often collected by security operation centers (SOCs). The\nsemi-structured nature of host logs inhibits automated analytics, and while\nmanual analysis is common, the sheer volume makes manual inspection of all logs\nimpossible. Although many powerful algorithms for analyzing time-series and\nsequential data exist, utilization of such algorithms for most cyber security\napplications is either infeasible or requires tailored, research-intensive\npreparations. In particular, basic mathematic and algorithmic developments for\nproviding a generalized, meaningful similarity metric on system logs is needed\nto bridge the gap between many existing sequential data mining methods and this\ncurrently available but under-utilized data source. In this paper, we provide a\nrigorous definition of a metric product space on Windows Event Logs, providing\nan embedding that allows for the application of established machine learning\nand time-series analysis methods. We then demonstrate the utility and\nflexibility of this embedding with multiple use-cases on real data: (1)\ncomparing known infected to new host log streams for attack detection and\nforensics, (2) collapsing similar streams of logs into semantically-meaningful\ngroups (by user, by role), thereby reducing the quantity of data but not the\ncontent, (3) clustering logs as well as short sequences of logs to identify and\nvisualize user behaviors and background processes over time. Overall, we\nprovide a metric space framework for general host logs and log sequences that\nrespects semantic similarity and facilitates a wide variety of data science\nanalytics to these logs without data-specific preparations for each.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 19:00:29 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Verma", "Miki E.", ""], ["Bridges", "Robert A.", ""]]}, {"id": "1811.00621", "submitter": "Chirag Agarwal", "authors": "Chirag Agarwal, Anh Nguyen, Dan Schonfeld", "title": "Improving Adversarial Robustness by Encouraging Discriminative Features", "comments": "This article corresponds to the accepted version at IEEE ICIP 2019.\n  We will link the DOI as soon as it is available", "journal-ref": "2019 26th IEEE International Conference on Image Processing (ICIP)", "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have achieved state-of-the-art results in various\npattern recognition tasks. However, they perform poorly on out-of-distribution\nadversarial examples i.e. inputs that are specifically crafted by an adversary\nto cause DNNs to misbehave, questioning the security and reliability of\napplications. In this paper, we encourage DNN classifiers to learn more\ndiscriminative features by imposing a center loss in addition to the regular\nsoftmax cross-entropy loss. Intuitively, the center loss encourages DNNs to\nsimultaneously learns a center for the deep features of each class, and\nminimize the distances between the intra-class deep features and their\ncorresponding class centers. We hypothesize that minimizing distances between\nintra-class features and maximizing the distances between inter-class features\nat the same time would improve a classifier's robustness to adversarial\nexamples. Our results on state-of-the-art architectures on MNIST, CIFAR-10, and\nCIFAR-100 confirmed that intuition and highlight the importance of\ndiscriminative features.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 20:15:56 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 16:15:04 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Agarwal", "Chirag", ""], ["Nguyen", "Anh", ""], ["Schonfeld", "Dan", ""]]}, {"id": "1811.00634", "submitter": "Ankur Chowdhary", "authors": "Ankur Chowdhary, Dijiang Huang, Adel Alshamrani, Abdulhakim Sabur,\n  Myong Kang, Anya Kim and Alexander Velazquez", "title": "SDFW: SDN-based Stateful Distributed Firewall", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SDN provides a programmable command and control networking system in a\nmulti-tenant cloud network using control and data plane separation. However,\nseparating the control and data planes make it difficult for incorporating some\nsecurity services (e.g., firewalls) into SDN framework. Most of the existing\nsolutions use SDN switches as packet filters and rely on SDN controllers to\nimplement firewall policy management functions, which is impractical for\nimplementing stateful firewalls since SDN switches only send session's initial\npackets and statistical data of flows to their controllers. For a data center\nnetworking environment, applying a Distributed FireWall (DFW) system to prevent\nattacker's lateral movements is highly desired, in which designing and\nimplementing an SDN-based Stateful DFW (SDFW) demand a scalable distributed\nstates management solution at the data plane to track packets and flow states.\nOur performance results show that SDFW achieves scalable security against data\nplane attacks with a marginal performance hit ~ 1.6% reduction in network\nbandwidth.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 21:05:18 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Chowdhary", "Ankur", ""], ["Huang", "Dijiang", ""], ["Alshamrani", "Adel", ""], ["Sabur", "Abdulhakim", ""], ["Kang", "Myong", ""], ["Kim", "Anya", ""], ["Velazquez", "Alexander", ""]]}, {"id": "1811.00635", "submitter": "Ankur Chowdhary", "authors": "Ankur Chowdhary, Adel Alshamrani, Dijiang Huang, Myong Kang, Anya Kim\n  and Alexander Velazquez", "title": "TRUFL: Distributed Trust Management framework in SDN", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software Defined Networking (SDN) has emerged as a revolutionary paradigm to\nmanage cloud infrastructure. SDN lacks scalable trust setup and verification\nmechanism between Data Plane-Control Plane elements, Control Plane elements,\nand Control Plane-Application Plane. Trust management schemes like Public Key\nInfrastructure (PKI) used currently in SDN are slow for trust establishment in\na larger cloud environment. We propose a distributed trust mechanism - TRUFL to\nestablish and verify trust in SDN. The distributed framework utilizes\nparallelism in trust management, in effect faster transfer rates and reduced\nlatency compared to centralized trust management. The TRUFL framework scales\nwell with the number of OpenFlow rules when compared to existing research\nworks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 21:10:38 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 15:13:53 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Chowdhary", "Ankur", ""], ["Alshamrani", "Adel", ""], ["Huang", "Dijiang", ""], ["Kang", "Myong", ""], ["Kim", "Anya", ""], ["Velazquez", "Alexander", ""]]}, {"id": "1811.00636", "submitter": "Jerry Li", "authors": "Brandon Tran, Jerry Li, Aleksander Madry", "title": "Spectral Signatures in Backdoor Attacks", "comments": "16 pages, accepted to NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent line of work has uncovered a new form of data poisoning: so-called\n\\emph{backdoor} attacks. These attacks are particularly dangerous because they\ndo not affect a network's behavior on typical, benign data. Rather, the network\nonly deviates from its expected output when triggered by a perturbation planted\nby an adversary.\n  In this paper, we identify a new property of all known backdoor attacks,\nwhich we call \\emph{spectral signatures}. This property allows us to utilize\ntools from robust statistics to thwart the attacks. We demonstrate the efficacy\nof these signatures in detecting and removing poisoned examples on real image\nsets and state of the art neural network architectures. We believe that\nunderstanding spectral signatures is a crucial first step towards designing ML\nsystems secure against such backdoor attacks\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 21:12:01 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Tran", "Brandon", ""], ["Li", "Jerry", ""], ["Madry", "Aleksander", ""]]}, {"id": "1811.00651", "submitter": "Ankur Chowdhary", "authors": "Ankur Chowdhary, Sailik Sengupta, Adel Alshamrani, Dijiang Huang, and\n  Abdulhakim Sabur", "title": "Adaptive MTD Security using Markov Game Modeling", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large scale cloud networks consist of distributed networking and computing\nelements that process critical information and thus security is a key\nrequirement for any environment. Unfortunately, assessing the security state of\nsuch networks is a challenging task and the tools used in the past by security\nexperts such as packet filtering, firewall, Intrusion Detection Systems (IDS)\netc., provide a reactive security mechanism. In this paper, we introduce a\nMoving Target Defense (MTD) based proactive security framework for monitoring\nattacks which lets us identify and reason about multi-stage attacks that target\nsoftware vulnerabilities present in a cloud network. We formulate the\nmulti-stage attack scenario as a two-player zero-sum Markov Game (between the\nattacker and the network administrator) on attack graphs. The rewards and\ntransition probabilities are obtained by leveraging the expert knowledge\npresent in the Common Vulnerability Scoring System (CVSS). Our framework\nidentifies an attacker's optimal policy and places countermeasures to ensure\nthat this attack policy is always detected, thus forcing the attacker to use a\nsub-optimal policy with higher cost.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 22:06:02 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Chowdhary", "Ankur", ""], ["Sengupta", "Sailik", ""], ["Alshamrani", "Adel", ""], ["Huang", "Dijiang", ""], ["Sabur", "Abdulhakim", ""]]}, {"id": "1811.00653", "submitter": "Ankur Chowdhary", "authors": "Ankur Chowdhary, Dijiang Huang", "title": "SDN based Network Function Parallelism in Cloud", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network function virtualization (NFV) based service function chaining (SFC)\nallows the provisioning of various security and traffic engineering\napplications in a cloud network. Inefficient deployment of network functions\ncan lead to security violations and performance overhead. In an OpenFlow\nenabled cloud, the key problem with current mechanisms is that several packet\nfield match and flow rule action sets associated with the network functions are\nnon-overlapping and can be parallelized for performance enhancement. We\nintroduce Network Function Parallelism (NFP) SFC-NFP for OpenFlow network. Our\nsolution utilizes network function parallelism over the OpenFlow rules to\nimprove SFC performance in the cloud network. We have utilized the DPDK\nplatform with an OpenFlow switch (OVS) for experimental analysis. Our solution\nachieves a 1.40-1.90x reduction in latency for SFC in an OpenStack cloud\nnetwork managed by the SDN framework.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 22:11:47 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Chowdhary", "Ankur", ""], ["Huang", "Dijiang", ""]]}, {"id": "1811.00657", "submitter": "Ankur Chowdhary", "authors": "Ankur Chowdhary, Adel Alshamrani, and Dijiang Huang", "title": "SUPC: SDN enabled Universal Policy Checking in Cloud Network", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-tenant cloud networks have various security and monitoring service\nfunctions (SFs) that constitute a service function chain (SFC) between two\nendpoints. SF rule ordering overlaps and policy conflicts can cause increased\nlatency, service disruption and security breaches in cloud networks. Software\nDefined Network (SDN) based Network Function Virtualization (NFV) has emerged\nas a solution that allows dynamic SFC composition and traffic steering in a\ncloud network. We propose an SDN enabled Universal Policy Checking (SUPC)\nframework, to provide 1) Flow Composition and Ordering by translating various\nSF rules into the OpenFlow format. This ensures elimination of redundant rules\nand policy compliance in SFC. 2) Flow conflict analysis to identify conflicts\nin header space and actions between various SF rules. Our results show a\nsignificant reduction in SF rules on composition. Additionally, our conflict\nchecking mechanism was able to identify several rule conflicts that pose\nsecurity, efficiency, and service availability issues in the cloud network.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 22:17:02 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Chowdhary", "Ankur", ""], ["Alshamrani", "Adel", ""], ["Huang", "Dijiang", ""]]}, {"id": "1811.00701", "submitter": "Nickolaos Koroniotis", "authors": "Nickolaos Koroniotis, Nour Moustafa, Elena Sitnikova, Benjamin\n  Turnbull", "title": "Towards the Development of Realistic Botnet Dataset in the Internet of\n  Things for Network Forensic Analytics: Bot-IoT Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of IoT systems, has seen them targeted by malicious third\nparties. To address this, realistic protection and investigation\ncountermeasures need to be developed. Such countermeasures include network\nintrusion detection and network forensic systems. For that purpose, a\nwell-structured and representative dataset is paramount for training and\nvalidating the credibility of the systems. Although there are several network,\nin most cases, not much information is given about the Botnet scenarios that\nwere used. This paper, proposes a new dataset, Bot-IoT, which incorporates\nlegitimate and simulated IoT network traffic, along with various types of\nattacks. We also present a realistic testbed environment for addressing the\nexisting dataset drawbacks of capturing complete network information, accurate\nlabeling, as well as recent and complex attack diversity. Finally, we evaluate\nthe reliability of the BoT-IoT dataset using different statistical and machine\nlearning methods for forensics purposes compared with the existing datasets.\nThis work provides the baseline for allowing botnet identificaiton across\nIoT-specifc networks. The Bot-IoT dataset can be accessed at [1].\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 01:31:18 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Koroniotis", "Nickolaos", ""], ["Moustafa", "Nour", ""], ["Sitnikova", "Elena", ""], ["Turnbull", "Benjamin", ""]]}, {"id": "1811.00741", "submitter": "Pang Wei Koh", "authors": "Pang Wei Koh, Jacob Steinhardt, Percy Liang", "title": "Stronger Data Poisoning Attacks Break Data Sanitization Defenses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models trained on data from the outside world can be\ncorrupted by data poisoning attacks that inject malicious points into the\nmodels' training sets. A common defense against these attacks is data\nsanitization: first filter out anomalous training points before training the\nmodel. Can data poisoning attacks break data sanitization defenses? In this\npaper, we develop three new attacks that can all bypass a broad range of data\nsanitization defenses, including commonly-used anomaly detectors based on\nnearest neighbors, training loss, and singular-value decomposition. For\nexample, our attacks successfully increase the test error on the Enron spam\ndetection dataset from 3% to 24% and on the IMDB sentiment classification\ndataset from 12% to 29% by adding just 3% poisoned data. In contrast, many\nexisting attacks from the literature do not explicitly consider defenses, and\nwe show that those attacks are ineffective in the presence of the defenses we\nconsider. Our attacks are based on two ideas: (i) we coordinate our attacks to\nplace poisoned points near one another, which fools some anomaly detectors, and\n(ii) we formulate each attack as a constrained optimization problem, with\nconstraints designed to ensure that the poisoned points evade detection. While\nthis optimization involves solving an expensive bilevel problem, we explore and\ndevelop three efficient approximations to this problem based on influence\nfunctions; minimax duality; and the Karush-Kuhn-Tucker (KKT) conditions. Our\nresults underscore the urgent need to develop more sophisticated and robust\ndefenses against data poisoning attacks.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 05:19:07 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Koh", "Pang Wei", ""], ["Steinhardt", "Jacob", ""], ["Liang", "Percy", ""]]}, {"id": "1811.00778", "submitter": "Jun Jie Sim", "authors": "Ahmad Al Badawi, Jin Chao, Jie Lin, Chan Fook Mun, Jun Jie Sim,\n  Benjamin Hong Meng Tan, Xiao Nan, Khin Mi Mi Aung, Vijay Ramaseshan\n  Chandrasekhar", "title": "Towards the AlexNet Moment for Homomorphic Encryption: HCNN, theFirst\n  Homomorphic CNN on Encrypted Data with GPUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning as a Service (DLaaS) stands as a promising solution for\ncloud-based inference applications. In this setting, the cloud has a\npre-learned model whereas the user has samples on which she wants to run the\nmodel. The biggest concern with DLaaS is user privacy if the input samples are\nsensitive data. We provide here an efficient privacy-preserving system by\nemploying high-end technologies such as Fully Homomorphic Encryption (FHE),\nConvolutional Neural Networks (CNNs) and Graphics Processing Units (GPUs). FHE,\nwith its widely-known feature of computing on encrypted data, empowers a wide\nrange of privacy-concerned applications. This comes at high cost as it requires\nenormous computing power. In this paper, we show how to accelerate the\nperformance of running CNNs on encrypted data with GPUs. We evaluated two CNNs\nto classify homomorphically the MNIST and CIFAR-10 datasets. Our solution\nachieved a sufficient security level (> 80 bit) and reasonable classification\naccuracy (99%) and (77.55%) for MNIST and CIFAR-10, respectively. In terms of\nlatency, we could classify an image in 5.16 seconds and 304.43 seconds for\nMNIST and CIFAR-10, respectively. Our system can also classify a batch of\nimages (> 8,000) without extra overhead.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 08:44:21 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 04:23:59 GMT"}, {"version": "v3", "created": "Tue, 18 Aug 2020 18:21:38 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Badawi", "Ahmad Al", ""], ["Chao", "Jin", ""], ["Lin", "Jie", ""], ["Mun", "Chan Fook", ""], ["Sim", "Jun Jie", ""], ["Tan", "Benjamin Hong Meng", ""], ["Nan", "Xiao", ""], ["Aung", "Khin Mi Mi", ""], ["Chandrasekhar", "Vijay Ramaseshan", ""]]}, {"id": "1811.00830", "submitter": "Davide Maiorca", "authors": "Davide Maiorca, Battista Biggio and Giorgio Giacinto", "title": "Towards Adversarial Malware Detection: Lessons Learned from PDF-based\n  Attacks", "comments": null, "journal-ref": "ACM Computing Surveys, Vol. 52, No. 4, Article 78, 2019", "doi": "10.1145/3332184", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware still constitutes a major threat in the cybersecurity landscape, also\ndue to the widespread use of infection vectors such as documents. These\ninfection vectors hide embedded malicious code to the victim users,\nfacilitating the use of social engineering techniques to infect their machines.\nResearch showed that machine-learning algorithms provide effective detection\nmechanisms against such threats, but the existence of an arms race in\nadversarial settings has recently challenged such systems. In this work, we\nfocus on malware embedded in PDF files as a representative case of such an arms\nrace. We start by providing a comprehensive taxonomy of the different\napproaches used to generate PDF malware, and of the corresponding\nlearning-based detection systems. We then categorize threats specifically\ntargeted against learning-based PDF malware detectors, using a well-established\nframework in the field of adversarial machine learning. This framework allows\nus to categorize known vulnerabilities of learning-based PDF malware detectors\nand to identify novel attacks that may threaten such systems, along with the\npotential defense mechanisms that can mitigate the impact of such threats. We\nconclude the paper by discussing how such findings highlight promising research\ndirections towards tackling the more general challenge of designing robust\nmalware detectors in adversarial settings.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 12:06:37 GMT"}, {"version": "v2", "created": "Wed, 24 Apr 2019 16:20:15 GMT"}, {"version": "v3", "created": "Tue, 14 Apr 2020 07:46:41 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Maiorca", "Davide", ""], ["Biggio", "Battista", ""], ["Giacinto", "Giorgio", ""]]}, {"id": "1811.00866", "submitter": "Tsui-Wei Weng", "authors": "Huan Zhang, Tsui-Wei Weng, Pin-Yu Chen, Cho-Jui Hsieh, and Luca Daniel", "title": "Efficient Neural Network Robustness Certification with General\n  Activation Functions", "comments": "Accepted by NIPS 2018. Huan Zhang and Tsui-Wei Weng contributed\n  equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding minimum distortion of adversarial examples and thus certifying\nrobustness in neural network classifiers for given data points is known to be a\nchallenging problem. Nevertheless, recently it has been shown to be possible to\ngive a non-trivial certified lower bound of minimum adversarial distortion, and\nsome recent progress has been made towards this direction by exploiting the\npiece-wise linear nature of ReLU activations. However, a generic robustness\ncertification for general activation functions still remains largely\nunexplored. To address this issue, in this paper we introduce CROWN, a general\nframework to certify robustness of neural networks with general activation\nfunctions for given input data points. The novelty in our algorithm consists of\nbounding a given activation function with linear and quadratic functions, hence\nallowing it to tackle general activation functions including but not limited to\nfour popular choices: ReLU, tanh, sigmoid and arctan. In addition, we\nfacilitate the search for a tighter certified lower bound by adaptively\nselecting appropriate surrogates for each neuron activation. Experimental\nresults show that CROWN on ReLU networks can notably improve the certified\nlower bounds compared to the current state-of-the-art algorithm Fast-Lin, while\nhaving comparable computational efficiency. Furthermore, CROWN also\ndemonstrates its effectiveness and flexibility on networks with general\nactivation functions, including tanh, sigmoid and arctan.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 14:03:25 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Zhang", "Huan", ""], ["Weng", "Tsui-Wei", ""], ["Chen", "Pin-Yu", ""], ["Hsieh", "Cho-Jui", ""], ["Daniel", "Luca", ""]]}, {"id": "1811.00917", "submitter": "Sajjad Arshad", "authors": "Sajjad Arshad, Seyed Ali Mirheidari, Tobias Lauinger, Bruno Crispo,\n  Engin Kirda, William Robertson", "title": "Large-Scale Analysis of Style Injection by Relative Path Overwrite", "comments": "The Web Conference (WWW), Lyon, France, April 2018", "journal-ref": null, "doi": "10.1145/3178876.3186090", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relative Path Overwrite (RPO) is a recent technique to inject style\ndirectives into sites even when no style sink or markup injection vulnerability\nis present. It exploits differences in how browsers and web servers interpret\nrelative paths (i.e., path confusion) to make a HTML page reference itself as a\nstylesheet; a simple text injection vulnerability along with browsers' leniency\nin parsing CSS resources results in an attacker's ability to inject style\ndirectives that will be interpreted by the browser. Even though style injection\nmay appear less serious a threat than script injection, it has been shown that\nit enables a range of attacks, including secret exfiltration.\n  In this paper, we present the first large-scale study of the Web to measure\nthe prevalence and significance of style injection using RPO. Our work shows\nthat around 9% of the sites in the Alexa Top 10,000 contain at least one\nvulnerable page, out of which more than one third can be exploited. We analyze\nin detail various impediments to successful exploitation, and make\nrecommendations for remediation. In contrast to script injection, relatively\nsimple countermeasures exist to mitigate style injection. However, there\nappears to be little awareness of this attack vector as evidenced by a range of\npopular Content Management Systems (CMSes) that we found to be exploitable.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 15:09:58 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 00:07:22 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Arshad", "Sajjad", ""], ["Mirheidari", "Seyed Ali", ""], ["Lauinger", "Tobias", ""], ["Crispo", "Bruno", ""], ["Kirda", "Engin", ""], ["Robertson", "William", ""]]}, {"id": "1811.00918", "submitter": "Sajjad Arshad", "authors": "Tobias Lauinger, Abdelberi Chaabane, Sajjad Arshad, William Robertson,\n  Christo Wilson, Engin Kirda", "title": "Thou Shalt Not Depend on Me: Analysing the Use of Outdated JavaScript\n  Libraries on the Web", "comments": "Network and Distributed System Security Symposium (NDSS), San Diego,\n  CA, USA, February 2017", "journal-ref": null, "doi": "10.14722/ndss.2017.23414", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web developers routinely rely on third-party Java-Script libraries such as\njQuery to enhance the functionality of their sites. However, if not properly\nmaintained, such dependencies can create attack vectors allowing a site to be\ncompromised.\n  In this paper, we conduct the first comprehensive study of client-side\nJavaScript library usage and the resulting security implications across the\nWeb. Using data from over 133 k websites, we show that 37% of them include at\nleast one library with a known vulnerability; the time lag behind the newest\nrelease of a library is measured in the order of years. In order to better\nunderstand why websites use so many vulnerable or outdated libraries, we track\ncausal inclusion relationships and quantify different scenarios. We observe\nsites including libraries in ad hoc and often transitive ways, which can lead\nto different versions of the same library being loaded into the same document\nat the same time. Furthermore, we find that libraries included transitively, or\nvia ad and tracking code, are more likely to be vulnerable. This demonstrates\nthat not only website administrators, but also the dynamic architecture and\ndevelopers of third-party services are to blame for the Web's poor state of\nlibrary management.\n  The results of our work underline the need for more thorough approaches to\ndependency management, code maintenance and third-party code inclusion on the\nWeb.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 15:10:12 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 23:37:00 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Lauinger", "Tobias", ""], ["Chaabane", "Abdelberi", ""], ["Arshad", "Sajjad", ""], ["Robertson", "William", ""], ["Wilson", "Christo", ""], ["Kirda", "Engin", ""]]}, {"id": "1811.00919", "submitter": "Sajjad Arshad", "authors": "Sajjad Arshad, Amin Kharraz, William Robertson", "title": "Identifying Extension-based Ad Injection via Fine-grained Web Content\n  Provenance", "comments": "International Symposium on Research in Attacks, Intrusions and\n  Defenses (RAID), Paris, France, September 2016", "journal-ref": null, "doi": "10.1007/978-3-319-45719-2_19", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extensions provide useful additional functionality for web browsers, but are\nalso an increasingly popular vector for attacks. Due to the high degree of\nprivilege extensions can hold, extensions have been abused to inject\nadvertisements into web pages that divert revenue from content publishers and\npotentially expose users to malware. Users are often unaware of such practices,\nbelieving the modifications to the page originate from publishers.\nAdditionally, automated identification of unwanted third-party modifications is\nfundamentally difficult, as users are the ultimate arbiters of whether content\nis undesired in the absence of outright malice.\n  To resolve this dilemma, we present a fine-grained approach to tracking the\nprovenance of web content at the level of individual DOM elements. In\nconjunction with visual indicators, provenance information can be used to\nreliably determine the source of content modifications, distinguishing\npublisher content from content that originates from third parties such as\nextensions. We describe a prototype implementation of the approach called\nOriginTracer for Chromium, and evaluate its effectiveness, usability, and\nperformance overhead through a user study and automated experiments. The\nresults demonstrate a statistically significant improvement in the ability of\nusers to identify unwanted third-party content such as injected ads with modest\nperformance overhead.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 15:10:25 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 00:20:59 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Arshad", "Sajjad", ""], ["Kharraz", "Amin", ""], ["Robertson", "William", ""]]}, {"id": "1811.00920", "submitter": "Sajjad Arshad", "authors": "Muhammad Ahmad Bashir, Sajjad Arshad, William Robertson, Christo\n  Wilson", "title": "Tracing Information Flows Between Ad Exchanges Using Retargeted Ads", "comments": "USENIX Security Symposium, Austin, TX, USA, August 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous surveys have shown that Web users are concerned about the loss of\nprivacy associated with online tracking. Alarmingly, these surveys also reveal\nthat people are also unaware of the amount of data sharing that occurs between\nad exchanges, and thus underestimate the privacy risks associated with online\ntracking.\n  In reality, the modern ad ecosystem is fueled by a flow of user data between\ntrackers and ad exchanges. Although recent work has shown that ad exchanges\nroutinely perform cookie matching with other exchanges, these studies are based\non brittle heuristics that cannot detect all forms of information sharing,\nespecially under adversarial conditions.\n  In this study, we develop a methodology that is able to detect client- and\nserver-side flows of information between arbitrary ad exchanges. Our key\ninsight is to leverage retargeted ads as a tool for identifying information\nflows. Intuitively, our methodology works because it relies on the semantics of\nhow exchanges serve ads, rather than focusing on specific cookie matching\nmechanisms. Using crawled data on 35,448 ad impressions, we show that our\nmethodology can successfully categorize four different kinds of information\nsharing behavior between ad exchanges, including cases where existing heuristic\nmethods fail.\n  We conclude with a discussion of how our findings and methodologies can be\nleveraged to give users more control over what kind of ads they see and how\ntheir information is shared between ad exchanges.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 15:11:58 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 23:51:23 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Bashir", "Muhammad Ahmad", ""], ["Arshad", "Sajjad", ""], ["Robertson", "William", ""], ["Wilson", "Christo", ""]]}, {"id": "1811.00921", "submitter": "Sajjad Arshad", "authors": "Seyed Ali Mirheidari, Sajjad Arshad, Rasool Jalili", "title": "Alert Correlation Algorithms: A Survey and Taxonomy", "comments": "Symposium on Cyberspace Safety and Security (CSS), Lecture Notes in\n  Computer Science, Springer International Publishing, vol 8300, pp 183-197,\n  Zhangjiajie, China, November 2013", "journal-ref": null, "doi": "10.1007/978-3-319-03584-0_14", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alert correlation is a system which receives alerts from heterogeneous\nIntrusion Detection Systems and reduces false alerts, detects high level\npatterns of attacks, increases the meaning of occurred incidents, predicts the\nfuture states of attacks, and detects root cause of attacks. To reach these\ngoals, many algorithms have been introduced in the world with many advantages\nand disadvantages. In this paper, we are trying to present a comprehensive\nsurvey on already proposed alert correlation algorithms. The approach of this\nsurvey is mainly focused on algorithms in correlation engines which can work in\nenterprise and practical networks. Having this aim in mind, many features\nrelated to accuracy, functionality, and computation power are introduced and\nall algorithm categories are assessed with these features. The result of this\nsurvey shows that each category of algorithms has its own strengths and an\nideal correlation frameworks should be carried the strength feature of each\ncategory.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 15:12:05 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Mirheidari", "Seyed Ali", ""], ["Arshad", "Sajjad", ""], ["Jalili", "Rasool", ""]]}, {"id": "1811.00922", "submitter": "Sajjad Arshad", "authors": "Seyed Ali Mirheidari, Sajjad Arshad, Saeidreza Khoshkdahan, Rasool\n  Jalili", "title": "A Comprehensive Approach to Abusing Locality in Shared Web Hosting\n  Servers", "comments": "IEEE Conference on Trust, Security and Privacy in Computing and\n  Communications (TrustCom), Melbourne, Australia, July 2013", "journal-ref": null, "doi": "10.1109/TrustCom.2013.200", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing of network technology along with the need of human for\nsocial interaction, using websites nowadays becomes critically important which\nleads in the increasing number of websites and servers. One popular solution\nfor managing these large numbers of websites is using shared web hosting\nservers in order to decrease the overall cost of server maintenance. Despite\naffordability, this solution is insecure and risky according to high amount of\nreported defaces and attacks during recent years. In this paper, we introduce\ntop ten most common attacks in shared web hosting servers which can occur\nbecause of the nature and bad configuration in these servers. Moreover, we\npresent several simple scenarios that are capable of penetrating these kinds of\nservers even with the existence of several securing mechanisms. Finally, we\nprovide a comprehensive secure configuration for confronting these attacks.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 15:12:13 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Mirheidari", "Seyed Ali", ""], ["Arshad", "Sajjad", ""], ["Khoshkdahan", "Saeidreza", ""], ["Jalili", "Rasool", ""]]}, {"id": "1811.00923", "submitter": "Sajjad Arshad", "authors": "Seyed Ali Mirheidari, Sajjad Arshad, Saeidreza Khoshkdahan, Rasool\n  Jalili", "title": "Two Novel Server-Side Attacks against Log File in Shared Web Hosting\n  Servers", "comments": "IEEE Conference for Internet Technology and Secured Transactions\n  (ICITST), London, UK, December 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shared Web Hosting service enables hosting multitude of websites on a single\npowerful server. It is a well-known solution as many people share the overall\ncost of server maintenance and also, website owners do not need to deal with\nadministration issues is not necessary for website owners. In this paper, we\nillustrate how shared web hosting service works and demonstrate the security\nweaknesses rise due to the lack of proper isolation between different websites,\nhosted on the same server. We exhibit two new server-side attacks against the\nlog file whose objectives are revealing information of other hosted websites\nwhich are considered to be private and arranging other complex attacks. In the\nabsence of isolated log files among websites, an attacker controlling a website\ncan inspect and manipulate contents of the log file. These attacks enable an\nattacker to disclose file and directory structure of other websites and launch\nother sorts of attacks. Finally, we propose several countermeasures to secure\nshared web hosting servers against the two attacks subsequent to the separation\nof log files for each website.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 15:12:23 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Mirheidari", "Seyed Ali", ""], ["Arshad", "Sajjad", ""], ["Khoshkdahan", "Saeidreza", ""], ["Jalili", "Rasool", ""]]}, {"id": "1811.00924", "submitter": "Sajjad Arshad", "authors": "Seyed Ali Mirheidari, Sajjad Arshad, Saeidreza Khoshkdahan", "title": "Performance Evaluation of Shared Hosting Security Methods", "comments": "IEEE Conference on Trust, Security and Privacy in Computing and\n  Communications (TrustCom), Liverpool, UK, June 2012", "journal-ref": null, "doi": "10.1109/TrustCom.2012.219", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shared hosting is a kind of web hosting in which multiple websites reside on\none webserver. It is cost-effective and makes the administration easier for\nwebsites' owners. However, shared hosting has some performance and security\nissues. In default shared hosting configuration, all websites' scripts are\nexecuted under the webserver's user account regardless of their owners.\nTherefore, a website is able to access other websites' resources. This security\nproblem arises from lack of proper isolation between different websites hosted\non the same webserver. In this survey, we have examined different methods for\nhandling mentioned security issue. Also we evaluated the performance of\nmentioned methods. Finally, we evaluated performance of these methods with\nvarious configurations.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 15:12:34 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Mirheidari", "Seyed Ali", ""], ["Arshad", "Sajjad", ""], ["Khoshkdahan", "Saeidreza", ""]]}, {"id": "1811.00925", "submitter": "Sajjad Arshad", "authors": "Sajjad Arshad, Maghsoud Abbaspour, Mehdi Kharrazi, Hooman Sanatkar", "title": "An Anomaly-based Botnet Detection Approach for Identifying Stealthy\n  Botnets", "comments": "IEEE Conference on Computer Applications and Industrial Electronics\n  (ICCAIE), Penang, Malaysia, December 2011", "journal-ref": null, "doi": "10.1109/ICCAIE.2011.6162198", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Botnets (networks of compromised computers) are often used for malicious\nactivities such as spam, click fraud, identity theft, phishing, and distributed\ndenial of service (DDoS) attacks. Most of previous researches have introduced\nfully or partially signature-based botnet detection approaches. In this paper,\nwe propose a fully anomaly-based approach that requires no a priori knowledge\nof bot signatures, botnet C&C protocols, and C&C server addresses. We start\nfrom inherent characteristics of botnets. Bots connect to the C&C channel and\nexecute the received commands. Bots belonging to the same botnet receive the\nsame commands that causes them having similar netflows characteristics and\nperforming same attacks. Our method clusters bots with similar netflows and\nattacks in different time windows and perform correlation to identify bot\ninfected hosts. We have developed a prototype system and evaluated it with\nreal-world traces including normal traffic and several real-world botnet\ntraces. The results show that our approach has high detection accuracy and low\nfalse positive.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 15:12:45 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Arshad", "Sajjad", ""], ["Abbaspour", "Maghsoud", ""], ["Kharrazi", "Mehdi", ""], ["Sanatkar", "Hooman", ""]]}, {"id": "1811.00926", "submitter": "Sajjad Arshad", "authors": "Sajjad Arshad, Amin Kharraz, William Robertson", "title": "Include Me Out: In-Browser Detection of Malicious Third-Party Content\n  Inclusions", "comments": "International Conference on Financial Cryptography and Data Security\n  (FC), Barbados, February 2016", "journal-ref": null, "doi": "10.1007/978-3-662-54970-4_26", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern websites include various types of third-party content such as\nJavaScript, images, stylesheets, and Flash objects in order to create\ninteractive user interfaces. In addition to explicit inclusion of third-party\ncontent by website publishers, ISPs and browser extensions are hijacking web\nbrowsing sessions with increasing frequency to inject third-party content\n(e.g., ads). However, third-party content can also introduce security risks to\nusers of these websites, unbeknownst to both website operators and users.\nBecause of the often highly dynamic nature of these inclusions as well as the\nuse of advanced cloaking techniques in contemporary malware, it is exceedingly\ndifficult to preemptively recognize and block inclusions of malicious\nthird-party content before it has the chance to attack the user's system. In\nthis paper, we propose a novel approach to achieving the goal of preemptive\nblocking of malicious third-party content inclusion through an analysis of\ninclusion sequences on the Web. We implemented our approach, called Excision,\nas a set of modifications to the Chromium browser that protects users from\nmalicious inclusions while web pages load. Our analysis suggests that by\nadopting our in-browser approach, users can avoid a significant portion of\nmalicious third-party content on the Web. Our evaluation shows that Excision\neffectively identifies malicious content while introducing a low false positive\nrate. Our experiments also demonstrate that our approach does not negatively\nimpact a user's browsing experience when browsing popular websites drawn from\nthe Alexa Top 500.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 15:15:00 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 00:27:18 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Arshad", "Sajjad", ""], ["Kharraz", "Amin", ""], ["Robertson", "William", ""]]}, {"id": "1811.01017", "submitter": "Emmanouil Theodosis", "authors": "Emmanouil Theodosis and Petros Maragos", "title": "An Adaptive Pruning Algorithm for Spoofing Localisation Based on\n  Tropical Geometry", "comments": "Under review for the International Conference on Acoustics, Speech,\n  and Signal Processing (ICASSP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of spoofing attacks is increasingly relevant as digital systems\nare becoming more ubiquitous. Thus the detection of such attacks and the\nlocalisation of attackers have been objects of recent study. After an attack\nhas been detected, various algorithms have been proposed in order to localise\nthe attacker. In this work we propose a new adaptive pruning algorithm inspired\nby the tropical and geometrical analysis of the traditional Viterbi pruning\nalgorithm to solve the localisation problem. In particular, the proposed\nalgorithm tries to localise the attacker by adapting the leniency parameter\nbased on estimates about the state of the solution space. These estimates stem\nfrom the enclosed volume and the entropy of the solution space, as they were\nintroduced in our previous works.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 18:19:42 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Theodosis", "Emmanouil", ""], ["Maragos", "Petros", ""]]}, {"id": "1811.01027", "submitter": "Lingwei Chen", "authors": "Yanfang Ye, Shifu Hou, Lingwei Chen, Jingwei Lei, Wenqiang Wan, Jiabin\n  Wang, Qi Xiong, Fudong Shao", "title": "AiDroid: When Heterogeneous Information Network Marries Deep Neural\n  Network for Real-time Android Malware Detection", "comments": "The revised version will be published in IJCAI'2019 entitled\n  \"Out-of-sample Node Representation Learning for Heterogeneous Graph in\n  Real-time Android Malware Detection\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The explosive growth and increasing sophistication of Android malware call\nfor new defensive techniques that are capable of protecting mobile users\nagainst novel threats. In this paper, we first extract the runtime Application\nProgramming Interface (API) call sequences from Android apps, and then analyze\nhigher-level semantic relations within the ecosystem to comprehensively\ncharacterize the apps. To model different types of entities (i.e., app, API,\nIMEI, signature, affiliation) and the rich semantic relations among them, we\nthen construct a structural heterogeneous information network (HIN) and present\nmeta-path based approach to depict the relatedness over apps. To efficiently\nclassify nodes (e.g., apps) in the constructed HIN, we propose the HinLearning\nmethod to first obtain in-sample node embeddings and then learn representations\nof out-of-sample nodes without rerunning/adjusting HIN embeddings at the first\nattempt. Afterwards, we design a deep neural network (DNN) classifier taking\nthe learned HIN representations as inputs for Android malware detection. A\ncomprehensive experimental study on the large-scale real sample collections\nfrom Tencent Security Lab is performed to compare various baselines. Promising\nexperimental results demonstrate that our developed system AiDroid which\nintegrates our proposed method outperforms others in real-time Android malware\ndetection. AiDroid has already been incorporated into Tencent Mobile Security\nproduct that serves millions of users worldwide.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 18:11:55 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 20:34:49 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Ye", "Yanfang", ""], ["Hou", "Shifu", ""], ["Chen", "Lingwei", ""], ["Lei", "Jingwei", ""], ["Wan", "Wenqiang", ""], ["Wang", "Jiabin", ""], ["Xiong", "Qi", ""], ["Shao", "Fudong", ""]]}, {"id": "1811.01031", "submitter": "Faiq Khalid", "authors": "Faiq Khalid, Muhammad Abdullah Hanif, Semeen Rehman, Rehan Ahmed,\n  Muhammad Shafique", "title": "TrISec: Training Data-Unaware Imperceptible Security Attacks on Deep\n  Neural Networks", "comments": null, "journal-ref": "2019 IEEE 25th International Symposium on On-Line Testing and\n  Robust System Design (IOLTS), Rhodes, Greece, 2019, pp. 188-193", "doi": "10.1109/IOLTS.2019.8854425", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the data manipulation attacks on deep neural networks (DNNs) during\nthe training stage introduce a perceptible noise that can be catered by\npreprocessing during inference or can be identified during the validation\nphase. Therefore, data poisoning attacks during inference (e.g., adversarial\nattacks) are becoming more popular. However, many of them do not consider the\nimperceptibility factor in their optimization algorithms, and can be detected\nby correlation and structural similarity analysis, or noticeable (e.g., by\nhumans) in a multi-level security system. Moreover, the majority of the\ninference attack relies on some knowledge about the training dataset. In this\npaper, we propose a novel methodology which automatically generates\nimperceptible attack images by using the back-propagation algorithm on\npre-trained DNNs, without requiring any information about the training dataset\n(i.e., completely training data-unaware). We present a case study on traffic\nsign detection using the VGGNet trained on the German Traffic Sign Recognition\nBenchmarks dataset in an autonomous driving use case. Our results demonstrate\nthat the generated attack images successfully perform misclassification while\nremaining imperceptible in both \"subjective\" and \"objective\" quality tests.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 18:21:17 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 22:51:49 GMT"}, {"version": "v3", "created": "Thu, 14 May 2020 10:20:06 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Khalid", "Faiq", ""], ["Hanif", "Muhammad Abdullah", ""], ["Rehman", "Semeen", ""], ["Ahmed", "Rehan", ""], ["Shafique", "Muhammad", ""]]}, {"id": "1811.01057", "submitter": "Aditi Raghunathan", "authors": "Aditi Raghunathan, Jacob Steinhardt, Percy Liang", "title": "Semidefinite relaxations for certifying robustness to adversarial\n  examples", "comments": "To appear at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their impressive performance on diverse tasks, neural networks fail\ncatastrophically in the presence of adversarial inputs---imperceptibly but\nadversarially perturbed versions of natural inputs. We have witnessed an arms\nrace between defenders who attempt to train robust networks and attackers who\ntry to construct adversarial examples. One promise of ending the arms race is\ndeveloping certified defenses, ones which are provably robust against all\nattackers in some family. These certified defenses are based on convex\nrelaxations which construct an upper bound on the worst case loss over all\nattackers in the family. Previous relaxations are loose on networks that are\nnot trained against the respective relaxation. In this paper, we propose a new\nsemidefinite relaxation for certifying robustness that applies to arbitrary\nReLU networks. We show that our proposed relaxation is tighter than previous\nrelaxations and produces meaningful robustness guarantees on three different\n\"foreign networks\" whose training objectives are agnostic to our proposed\nrelaxation.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 19:08:04 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Raghunathan", "Aditi", ""], ["Steinhardt", "Jacob", ""], ["Liang", "Percy", ""]]}, {"id": "1811.01134", "submitter": "Nicolas Papernot", "authors": "Nicolas Papernot", "title": "A Marauder's Map of Security and Privacy in Machine Learning", "comments": "This report summarizes the keynote presented by the author in October\n  2018 at AISec (colocated with ACM CCS) on security and privacy in machine\n  learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is growing recognition that machine learning (ML) exposes new security\nand privacy vulnerabilities in software systems, yet the technical community's\nunderstanding of the nature and extent of these vulnerabilities remains limited\nbut expanding. In this talk, we explore the threat model space of ML algorithms\nthrough the lens of Saltzer and Schroeder's principles for the design of secure\ncomputer systems. This characterization of the threat space prompts an\ninvestigation of current and future research directions. We structure our\ndiscussion around three of these directions, which we believe are likely to\nlead to significant progress. The first encompasses a spectrum of approaches to\nverification and admission control, which is a prerequisite to enable fail-safe\ndefaults in machine learning systems. The second seeks to design mechanisms for\nassembling reliable records of compromise that would help understand the degree\nto which vulnerabilities are exploited by adversaries, as well as favor\npsychological acceptability of machine learning applications. The third pursues\nformal frameworks for security and privacy in machine learning, which we argue\nshould strive to align machine learning goals such as generalization with\nsecurity and privacy desiderata like robustness or privacy. Key insights\nresulting from these three directions pursued both in the ML and security\ncommunities are identified and the effectiveness of approaches are related to\nstructural elements of ML algorithms and the data used to train them. We\nconclude by systematizing best practices in our community.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 00:25:50 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Papernot", "Nicolas", ""]]}, {"id": "1811.01190", "submitter": "Amir Afianian", "authors": "Amir Afianian, Salman Niksefat, Babak Sadeghiyan, David Baptiste", "title": "Malware Dynamic Analysis Evasion Techniques: A Survey", "comments": "33 pages, 1 figure, two tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Cyber world is plagued with ever-evolving malware that readily\ninfiltrates all defense mechanisms, operates viciously unbeknownst to the user\nand surreptitiously exfiltrate sensitive data. Understanding the inner workings\nof such malware provides a leverage to effectively combat them. This\nunderstanding, is pursued through dynamic analysis which is conducted manually\nor automatically. Malware authors accordingly, have devised and advanced\nevasion techniques to thwart or evade these analyses. In this paper, we present\na comprehensive survey on malware dynamic analysis evasion techniques. In\naddition, we propose a detailed classification of these techniques and further\ndemonstrate how their efficacy hold against different types of detection and\nanalysis approach. Our observations attest that evasive behavior is mostly\ninterested in detecting and evading sandboxes. The primary tactic of such\nmalware we argue is fingerprinting followed by new trends for reverse Turing\ntest tactic which aims at detecting human interaction. Furthermore, we will\nposit that the current defensive strategies beginning with reactive methods to\nendeavors for more transparent analysis systems are readily foiled by zero-day\nfingerprinting techniques or other evasion tactics such as stalling.\nAccordingly, we would recommend pursuit of more generic defensive strategies\nwith emphasis on path exploration techniques that have the potential to thwart\nall the evasive tactics.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 11:00:49 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Afianian", "Amir", ""], ["Niksefat", "Salman", ""], ["Sadeghiyan", "Babak", ""], ["Baptiste", "David", ""]]}, {"id": "1811.01213", "submitter": "Zhehui Chen", "authors": "Haoming Jiang, Zhehui Chen, Yuyang Shi, Bo Dai, and Tuo Zhao", "title": "Learning to Defend by Learning to Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training provides a principled approach for training robust\nneural networks. From an optimization perspective, adversarial training is\nessentially solving a bilevel optimization problem. The leader problem is\ntrying to learn a robust classifier, while the follower problem is trying to\ngenerate adversarial samples. Unfortunately, such a bilevel problem is\ndifficult to solve due to its highly complicated structure. This work proposes\na new adversarial training method based on a generic learning-to-learn (L2L)\nframework. Specifically, instead of applying existing hand-designed algorithms\nfor the inner problem, we learn an optimizer, which is parametrized as a\nconvolutional neural network. At the same time, a robust classifier is learned\nto defense the adversarial attack generated by the learned optimizer.\nExperiments over CIFAR-10 and CIFAR-100 datasets demonstrate that L2L\noutperforms existing adversarial training methods in both classification\naccuracy and computational efficiency. Moreover, our L2L framework can be\nextended to generative adversarial imitation learning and stabilize the\ntraining.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 13:33:23 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 15:13:28 GMT"}, {"version": "v3", "created": "Wed, 27 Nov 2019 23:48:28 GMT"}, {"version": "v4", "created": "Tue, 10 Mar 2020 22:42:13 GMT"}, {"version": "v5", "created": "Sun, 2 May 2021 14:28:02 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Jiang", "Haoming", ""], ["Chen", "Zhehui", ""], ["Shi", "Yuyang", ""], ["Dai", "Bo", ""], ["Zhao", "Tuo", ""]]}, {"id": "1811.01312", "submitter": "Rahul Aralikatte", "authors": "Shreya Khare, Rahul Aralikatte, Senthil Mani", "title": "Adversarial Black-Box Attacks on Automatic Speech Recognition Systems\n  using Multi-Objective Evolutionary Optimization", "comments": "Published in Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fooling deep neural networks with adversarial input have exposed a\nsignificant vulnerability in the current state-of-the-art systems in multiple\ndomains. Both black-box and white-box approaches have been used to either\nreplicate the model itself or to craft examples which cause the model to fail.\nIn this work, we propose a framework which uses multi-objective evolutionary\noptimization to perform both targeted and un-targeted black-box attacks on\nAutomatic Speech Recognition (ASR) systems. We apply this framework on two ASR\nsystems: Deepspeech and Kaldi-ASR, which increases the Word Error Rates (WER)\nof these systems by upto 980%, indicating the potency of our approach. During\nboth un-targeted and targeted attacks, the adversarial samples maintain a high\nacoustic similarity of 0.98 and 0.97 with the original audio.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 02:05:16 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 09:49:56 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Khare", "Shreya", ""], ["Aralikatte", "Rahul", ""], ["Mani", "Senthil", ""]]}, {"id": "1811.01348", "submitter": "Roman Brunner", "authors": "Georgia Avarikioti, Roman Brunner, Aggelos Kiayias, Roger Wattenhofer,\n  Dionysis Zindros", "title": "Structure and Content of the Visible Darknet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we analyze the topology and the content found on the\n\"darknet\", the set of websites accessible via Tor. We created a darknet spider\nand crawled the darknet starting from a bootstrap list by recursively following\nlinks. We explored the whole connected component of more than 34,000 hidden\nservices, of which we found 10,000 to be online. Contrary to folklore belief,\nthe visible part of the darknet is surprisingly well-connected through hub\nwebsites such as wikis and forums. We performed a comprehensive categorization\nof the content using supervised machine learning. We observe that about half of\nthe visible dark web content is related to apparently licit activities based on\nour classifier. A significant amount of content pertains to software\nrepositories, blogs, and activism-related websites. Among unlawful hidden\nservices, most pertain to fraudulent websites, services selling counterfeit\ngoods, and drug markets.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 11:36:59 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 12:07:40 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Avarikioti", "Georgia", ""], ["Brunner", "Roman", ""], ["Kiayias", "Aggelos", ""], ["Wattenhofer", "Roger", ""], ["Zindros", "Dionysis", ""]]}, {"id": "1811.01388", "submitter": "Daniel Omeiza A", "authors": "Daniel Omeiza, Jemima Owusu-Tweneboah", "title": "Web Security Investigation through Penetration Tests: A Case study of an\n  Educational Institution Portal", "comments": "4 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web security has become an important subject; many companies and\norganizations are becoming more security conscious as they build web\napplications to render online services and increase web presence.\nUnfortunately, many of these web applications are still susceptible to threats\nas they lack strong immunity to malicious attacks. This poses potential danger\nto the users of the sites and could also affect operations of the organizations\nor companies concerned. Educational institutions are not left out, their\nportals and websites hold vital information whose integrity is of utmost\nimportance. Taking Carnegie Mellon University Africa's internship portal as\ncase study, we carried out penetration tests to investigate web vulnerabilities\nand proffered possible remedies to the discovered vulnerabilities. Our result\nwill inform educational institutions on better website security practices,\nespecially in the African domain.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 15:34:32 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 09:26:34 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Omeiza", "Daniel", ""], ["Owusu-Tweneboah", "Jemima", ""]]}, {"id": "1811.01410", "submitter": "Subhra Mazumdar", "authors": "Subhra Mazumdar, Sushmita Ruj", "title": "Design of Anonymous Endorsement System in Hyperledger Fabric", "comments": "33 pages, 9 figures, Accepted in IEEE Transactions on Emerging Topics\n  in Computing, Manuscript Type: Technical Track (Regular Paper)", "journal-ref": null, "doi": "10.1109/TETC.2019.2920719", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Permissioned Blockchain has become quite popular with enterprises forming\nconsortium since it prioritizes trust over privacy. One of the popular\nplatforms for distributed ledger solution, Hyperledger Fabric, requires a\ntransaction to be endorsed or approved by a group of special members known as\nendorsers before undergoing validation. To endorse a transaction, an endorser\nmentions its identity along with the signature so that it can be verified\nlater. However, for certain transactions, difference in opinion may exist among\nendorsers. Disclosing the identity of an endorser may lead to conflict within\nthe consortium. In such cases, an endorsement policy which not only allows an\nendorser to support a transaction discreetly, but at the same time takes into\naccount the decision of the majority is preferred. Thus we propose an Anonymous\nEndorsement System which uses a threshold endorsement policy in order to\naddress the issue. All these factors motivated us to design a new ring\nsignature scheme, called Fabric' Constant-Sized Linkable Ring Signature\n(FCsLRS) with Transaction-Oriented linkability for hiding identity of the\nendorsers. We have implemented the signature scheme in Golang and analyzed its\nsecurity and performance by varying the RSA (Rivest-Shamir-Adleman) modulus\nsize. Feasibility of implementation is supported by experimental analysis.\nSignature and tag generation time is quite fast and remains constant\nirrespective of change in message length or endorsement set size for a given\nRSA modulus value, assuming all the endorsers generates their signature in\nparallel. Lastly, we also discuss the integration of the scheme on v1.2\nHyperledger Fabric.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 18:08:57 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 16:47:47 GMT"}, {"version": "v3", "created": "Wed, 24 Apr 2019 06:34:58 GMT"}, {"version": "v4", "created": "Thu, 25 Apr 2019 03:21:15 GMT"}, {"version": "v5", "created": "Wed, 5 Jun 2019 14:33:01 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Mazumdar", "Subhra", ""], ["Ruj", "Sushmita", ""]]}, {"id": "1811.01431", "submitter": "Dianbo Liu Dr", "authors": "Shifa Zhang, Anne Kim, Dianbo Liu, Sandeep C. Nuckchady, Lauren Huang,\n  Aditya Masurkar, Jingwei Zhang, Lawrence Tseng, Pratheek Karnati, Laura\n  Martinez, Thomas Hardjono, Manolis Kellis, Zhizhuo Zhang", "title": "Genie: A Secure, Transparent Sharing and Services Platform for Genetic\n  and Health Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) incorporating genetic and medical information\nhave been applied in disease risk prediction, unveiling disease mechanism, and\nadvancing therapeutics. However, AI training relies on highly sensitive and\nprivate data which significantly limit their applications and robustness\nevaluation. Moreover, the data access management after sharing across\norganization heavily relies on legal restriction, and there is no guarantee in\npreventing data leaking after sharing. Here, we present Genie, a secure AI\nplatform which allows AI models to be trained on medical data securely. The\nplatform combines the security of Intel Software Guarded eXtensions (SGX),\ntransparency of blockchain technology, and verifiability of open algorithms and\nsource codes. Genie shares insights of genetic and medical data without\nexposing anyone's raw data. All data is instantly encrypted upon upload and\ncontributed to the models that the user chooses. The usage of the model and the\nvalue generated from the genetic and health data will be tracked via a\nblockchain, giving the data transparent and immutable ownership.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 20:43:53 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 21:29:50 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Zhang", "Shifa", ""], ["Kim", "Anne", ""], ["Liu", "Dianbo", ""], ["Nuckchady", "Sandeep C.", ""], ["Huang", "Lauren", ""], ["Masurkar", "Aditya", ""], ["Zhang", "Jingwei", ""], ["Tseng", "Lawrence", ""], ["Karnati", "Pratheek", ""], ["Martinez", "Laura", ""], ["Hardjono", "Thomas", ""], ["Kellis", "Manolis", ""], ["Zhang", "Zhizhuo", ""]]}, {"id": "1811.01437", "submitter": "Faiq Khalid", "authors": "Faiq Khalid, Hassan Ali, Hammad Tariq, Muhammad Abdullah Hanif, Semeen\n  Rehman, Rehan Ahmed and Muhammad Shafique", "title": "QuSecNets: Quantization-based Defense Mechanism for Securing Deep Neural\n  Network against Adversarial Attacks", "comments": null, "journal-ref": "2019 IEEE 25th International Symposium on On-Line Testing and\n  Robust System Design (IOLTS), Rhodes, Greece, 2019, pp. 182-187", "doi": "10.1109/IOLTS.2019.8854377", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples have emerged as a significant threat to machine learning\nalgorithms, especially to the convolutional neural networks (CNNs). In this\npaper, we propose two quantization-based defense mechanisms, Constant\nQuantization (CQ) and Trainable Quantization (TQ), to increase the robustness\nof CNNs against adversarial examples. CQ quantizes input pixel intensities\nbased on a \"fixed\" number of quantization levels, while in TQ, the quantization\nlevels are \"iteratively learned during the training phase\", thereby providing a\nstronger defense mechanism. We apply the proposed techniques on undefended CNNs\nagainst different state-of-the-art adversarial attacks from the open-source\n\\textit{Cleverhans} library. The experimental results demonstrate 50%-96% and\n10%-50% increase in the classification accuracy of the perturbed images\ngenerated from the MNIST and the CIFAR-10 datasets, respectively, on commonly\nused CNN (Conv2D(64, 8x8) - Conv2D(128, 6x6) - Conv2D(128, 5x5) - Dense(10) -\nSoftmax()) available in \\textit{Cleverhans} library.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 21:25:38 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 09:30:01 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Khalid", "Faiq", ""], ["Ali", "Hassan", ""], ["Tariq", "Hammad", ""], ["Hanif", "Muhammad Abdullah", ""], ["Rehman", "Semeen", ""], ["Ahmed", "Rehan", ""], ["Shafique", "Muhammad", ""]]}, {"id": "1811.01443", "submitter": "Faiq Khalid", "authors": "Hassan Ali, Faiq Khalid, Hammad Tariq, Muhammad Abdullah Hanif, Semeen\n  Rehman, Rehan Ahmed and Muhammad Shafique", "title": "SSCNets: Robustifying DNNs using Secure Selective Convolutional Filters", "comments": null, "journal-ref": "IEEE Design & Test, vol. 37, no. 2, pp. 58-65, April 2020", "doi": "10.1109/MDAT.2019.2961325", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel technique based on the Secure Selective\nConvolutional (SSC) techniques in the training loop that increases the\nrobustness of a given DNN by allowing it to learn the data distribution based\non the important edges in the input image. We validate our technique on\nConvolutional DNNs against the state-of-the-art attacks from the open-source\nCleverhans library using the MNIST, the CIFAR-10, and the CIFAR-100 datasets.\nOur experimental results show that the attack success rate, as well as the\nimperceptibility of the adversarial images, can be significantly reduced by\nadding effective pre-processing functions, i.e., Sobel filtering.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 21:54:11 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 03:44:31 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Ali", "Hassan", ""], ["Khalid", "Faiq", ""], ["Tariq", "Hammad", ""], ["Hanif", "Muhammad Abdullah", ""], ["Rehman", "Semeen", ""], ["Ahmed", "Rehan", ""], ["Shafique", "Muhammad", ""]]}, {"id": "1811.01444", "submitter": "Faiq Khalid", "authors": "Faiq Khalid, Muhammmad Abdullah Hanif, Semeen Rehman, Junaid Qadir,\n  Muhammad Shafique", "title": "FAdeML: Understanding the Impact of Pre-Processing Noise Filtering on\n  Adversarial Machine Learning", "comments": "Accepted in Design, Automation and Test in Europe 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN)-based machine learning (ML) algorithms have\nrecently emerged as the leading ML paradigm particularly for the task of\nclassification due to their superior capability of learning efficiently from\nlarge datasets. The discovery of a number of well-known attacks such as dataset\npoisoning, adversarial examples, and network manipulation (through the addition\nof malicious nodes) has, however, put the spotlight squarely on the lack of\nsecurity in DNN-based ML systems. In particular, malicious actors can use these\nwell-known attacks to cause random/targeted misclassification, or cause a\nchange in the prediction confidence, by only slightly but systematically\nmanipulating the environmental parameters, inference data, or the data\nacquisition block. Most of the prior adversarial attacks have, however, not\naccounted for the pre-processing noise filters commonly integrated with the\nML-inference module. Our contribution in this work is to show that this is a\nmajor omission since these noise filters can render ineffective the majority of\nthe existing attacks, which rely essentially on introducing adversarial noise.\nApart from this, we also extend the state of the art by proposing a novel\npre-processing noise Filter-aware Adversarial ML attack called FAdeML. To\ndemonstrate the effectiveness of the proposed methodology, we generate an\nadversarial attack image by exploiting the \"VGGNet\" DNN trained for the \"German\nTraffic Sign Recognition Benchmarks (GTSRB\" dataset, which despite having no\nvisual noise, can cause a classifier to misclassify even in the presence of\npre-processing noise filters.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 21:56:33 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Khalid", "Faiq", ""], ["Hanif", "Muhammmad Abdullah", ""], ["Rehman", "Semeen", ""], ["Qadir", "Junaid", ""], ["Shafique", "Muhammad", ""]]}, {"id": "1811.01463", "submitter": "Faiq Khalid", "authors": "Faiq Khalid, Muhammad Abdullah Hanif, Semeen Rehman, Muhammad Shafique", "title": "Security for Machine Learning-based Systems: Attacks and Challenges\n  during Training and Inference", "comments": null, "journal-ref": "International Conference on Frontiers of Information Technology\n  (FIT) 2018", "doi": "10.1109/FIT.2018.00064", "report-no": "INSPEC Accession Number: 18398499", "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exponential increase in dependencies between the cyber and physical world\nleads to an enormous amount of data which must be efficiently processed and\nstored. Therefore, computing paradigms are evolving towards machine learning\n(ML)-based systems because of their ability to efficiently and accurately\nprocess the enormous amount of data. Although ML-based solutions address the\nefficient computing requirements of big data, they introduce (new) security\nvulnerabilities into the systems, which cannot be addressed by traditional\nmonitoring-based security measures. Therefore, this paper first presents a\nbrief overview of various security threats in machine learning, their\nrespective threat models and associated research challenges to develop robust\nsecurity measures. To illustrate the security vulnerabilities of ML during\ntraining, inferencing and hardware implementation, we demonstrate some key\nsecurity threats on ML using LeNet and VGGNet for MNIST and German Traffic Sign\nRecognition Benchmarks (GTSRB), respectively. Moreover, based on the security\nanalysis of ML-training, we also propose an attack that has a very less impact\non the inference accuracy. Towards the end, we highlight the associated\nresearch challenges in developing security measures and provide a brief\noverview of the techniques used to mitigate such security threats.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 00:30:21 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Khalid", "Faiq", ""], ["Hanif", "Muhammad Abdullah", ""], ["Rehman", "Semeen", ""], ["Shafique", "Muhammad", ""]]}, {"id": "1811.01629", "submitter": "Kassem Kallas", "authors": "Mauro Barni, Kassem Kallas, Ehsan Nowroozi, Benedetta Tondi", "title": "On the Transferability of Adversarial Examples Against CNN-Based Image\n  Forensics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that Convolutional Neural Networks (CNN) are\nrelatively easy to attack through the generation of so-called adversarial\nexamples. Such vulnerability also affects CNN-based image forensic tools.\nResearch in deep learning has shown that adversarial examples exhibit a certain\ndegree of transferability, i.e., they maintain part of their effectiveness even\nagainst CNN models other than the one targeted by the attack. This is a very\nstrong property undermining the usability of CNN's in security-oriented\napplications. In this paper, we investigate if attack transferability also\nholds in image forensics applications. With specific reference to the case of\nmanipulation detection, we analyse the results of several experiments\nconsidering different sources of mismatch between the CNN used to build the\nadversarial examples and the one adopted by the forensic analyst. The analysis\nranges from cases in which the mismatch involves only the training dataset, to\ncases in which the attacker and the forensic analyst adopt different\narchitectures. The results of our experiments show that, in the majority of the\ncases, the attacks are not transferable, thus easing the design of proper\ncountermeasures at least when the attacker does not have a perfect knowledge of\nthe target detector.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 11:52:47 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Barni", "Mauro", ""], ["Kallas", "Kassem", ""], ["Nowroozi", "Ehsan", ""], ["Tondi", "Benedetta", ""]]}, {"id": "1811.01766", "submitter": "Douglas Stinson", "authors": "Bailey Kacsmar and Douglas R. Stinson", "title": "A Network Reliability Approach to the Analysis of Combinatorial\n  Repairable Threshold Schemes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A repairable threshold scheme (which we abbreviate to RTS) is a\n$(\\tau,n)$-threshold scheme in which a subset of players can \"repair\" another\nplayer's share in the event that their share has been lost or corrupted. This\nwill take place without the participation of the dealer who set up the scheme.\nThe repairing protocol should not compromise the (unconditional) security of\nthe threshold scheme. Combinatorial repairable threshold schemes (or\ncombinatorial RTS) were recently introduced by Stinson and Wei. In these\nschemes, \"multiple shares\" are distributed to each player, as defined by a\nsuitable combinatorial design called the distribution design. In this paper, we\nstudy the reliability of these combinatorial repairable threshold schemes in a\nsetting where players may not be available to take part in a repair of a given\nplayer's share. Using techniques from network reliability theory, we consider\nthe probability of existence of an available repair set, as well as the\nexpected number of available repair sets, for various types of distribution\ndesigns.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 14:59:01 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Kacsmar", "Bailey", ""], ["Stinson", "Douglas R.", ""]]}, {"id": "1811.01811", "submitter": "Kemal Davaslioglu", "authors": "Yi Shi, Yalin E. Sagduyu, Kemal Davaslioglu, and Jason H. Li", "title": "Active Deep Learning Attacks under Strict Rate Limitations for Online\n  API Calls", "comments": "Presented at 2018 IEEE International Symposium on Technologies for\n  Homeland Security (HST) on October 23 2018. Received the Best Paper Award in\n  Cyber Security Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has been applied to a broad range of applications and some\nof them are available online as application programming interfaces (APIs) with\neither free (trial) or paid subscriptions. In this paper, we study adversarial\nmachine learning in the form of back-box attacks on online classifier APIs. We\nstart with a deep learning based exploratory (inference) attack, which aims to\nbuild a classifier that can provide similar classification results (labels) as\nthe target classifier. To minimize the difference between the labels returned\nby the inferred classifier and the target classifier, we show that the deep\nlearning based exploratory attack requires a large number of labeled training\ndata samples. These labels can be collected by calling the online API, but\nusually there is some strict rate limitation on the number of allowed API\ncalls. To mitigate the impact of limited training data, we develop an active\nlearning approach that first builds a classifier based on a small number of API\ncalls and uses this classifier to select samples to further collect their\nlabels. Then, a new classifier is built using more training data samples. This\nupdating process can be repeated multiple times. We show that this active\nlearning approach can build an adversarial classifier with a small statistical\ndifference from the target classifier using only a limited number of training\ndata samples. We further consider evasion and causative (poisoning) attacks\nbased on the inferred classifier that is built by the exploratory attack.\nEvasion attack determines samples that the target classifier is likely to\nmisclassify, whereas causative attack provides erroneous training data samples\nto reduce the reliability of the re-trained classifier. The success of these\nattacks show that adversarial machine learning emerges as a feasible threat in\nthe realistic case with limited training data.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 15:50:30 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Shi", "Yi", ""], ["Sagduyu", "Yalin E.", ""], ["Davaslioglu", "Kemal", ""], ["Li", "Jason H.", ""]]}, {"id": "1811.01892", "submitter": "Joachim Draeger", "authors": "Joachim Draeger, Stephanie \\\"Ottl", "title": "Malware Epidemics Effects in a Lanchester Conflict Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a risk assessment framework for examining the effects of\ninfections with self-replicating malware on military forces engaged in kinetic\ncombat. The framework uses models, in which kinetic combat is represented by a\nLanchester model coupled with an SIR-like model describing the malware\npropagation across the forces. Basic knowledge about the expected circumstances\nrestricts the set of scenarios to be analyzed. Remaining uncertainties are\ntaken into account as random variations given by information-theoretic\nprinciples. The risk assessment is realized by Monte-Carlo simulations.\n  An application of the proposed framework to a simple exemplary situation\ndemonstrates its practicability. The assumed uncertainties about the considered\nsituation lead to a risk value statistics, which changes corresponding to the\nimproving knowledge about the situation. Large uncertainties may lead to\nresults profoundly different from point estimates.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 18:19:18 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 18:37:52 GMT"}, {"version": "v3", "created": "Thu, 19 Nov 2020 08:08:07 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Draeger", "Joachim", ""], ["\u00d6ttl", "Stephanie", ""]]}, {"id": "1811.02001", "submitter": "Mahmoud Nabil", "authors": "Mohamed Baza, Mahmoud Nabil, Muhammad Ismail, Mohamed Mahmoud, Erchin\n  Serpedin, Mohammad Rahman", "title": "Blockchain-based Charging Coordination Mechanism for Smart Grid Energy\n  Storage Units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy storage units (ESUs) enable several attractive features of modern\nsmart grids such as enhanced grid resilience, effective demand response, and\nreduced bills. However, uncoordinated charging of ESUs stresses the power\nsystem and can lead to a blackout. On the other hand, existing charging\ncoordination mechanisms suffer from several limitations. First, the need for a\ncentral charging coordinator (CC) presents a single point of failure that\njeopardizes the effectiveness of the charging coordination. Second, a\ntransparent charging coordination mechanism does not exist where users are not\naware whether the CC is honest or not in coordination charging requests among\nthem in a fair way. Third, existing mechanisms overlook the privacy concerns of\nthe involved customers. To address these limitations, in this paper, we\nleverage the blockchain and smart contracts to build a decentralized charging\ncoordination mechanism without the need for a centralized charging coordinator.\nFirst ESUs should use tokens for anonymously authenticate themselves to the\nblockchain. Then each ESU sends a charging request that contains its\nState-of-Charge (SoC), Time-to-complete-charge (TCC) and amount of required\ncharging to the smart contract address on the blockchain. The smart contract\nwill then run the charging coordination mechanism in a self-executed manner\nsuch that ESUs with the highest priorities are charged in the present time slot\nwhile charging requests of lower priority ESUs are deferred to future time\nslots. In this way, each ESU can make sure that charging schedules are computed\ncorrectly. Finally, we have implemented the proposed mechanism on the Ethereum\ntest-bed blockchain, and our analysis shows that execution cost can be\nacceptable in terms of gas consumption while enabling decentralized charging\ncoordination with increased transparency, reliability, and privacy preserving.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 19:48:14 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 16:52:28 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Baza", "Mohamed", ""], ["Nabil", "Mahmoud", ""], ["Ismail", "Muhammad", ""], ["Mahmoud", "Mohamed", ""], ["Serpedin", "Erchin", ""], ["Rahman", "Mohammad", ""]]}, {"id": "1811.02054", "submitter": "Varun Chandrasekaran", "authors": "Varun Chandrasekaran, Kamalika Chaudhuri, Irene Giacomelli, Somesh Jha\n  and Songbai Yan", "title": "Exploring Connections Between Active Learning and Model Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is being increasingly used by individuals, research\ninstitutions, and corporations. This has resulted in the surge of Machine\nLearning-as-a-Service (MLaaS) - cloud services that provide (a) tools and\nresources to learn the model, and (b) a user-friendly query interface to access\nthe model. However, such MLaaS systems raise privacy concerns such as model\nextraction. In model extraction attacks, adversaries maliciously exploit the\nquery interface to steal the model. More precisely, in a model extraction\nattack, a good approximation of a sensitive or proprietary model held by the\nserver is extracted (i.e. learned) by a dishonest user who interacts with the\nserver only via the query interface. This attack was introduced by Tramer et\nal. at the 2016 USENIX Security Symposium, where practical attacks for various\nmodels were shown. We believe that better understanding the efficacy of model\nextraction attacks is paramount to designing secure MLaaS systems. To that end,\nwe take the first step by (a) formalizing model extraction and discussing\npossible defense strategies, and (b) drawing parallels between model extraction\nand established area of active learning. In particular, we show that recent\nadvancements in the active learning domain can be used to implement powerful\nmodel extraction attacks, and investigate possible defense strategies.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 22:06:12 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 16:25:32 GMT"}, {"version": "v3", "created": "Tue, 4 Dec 2018 09:32:36 GMT"}, {"version": "v4", "created": "Sat, 2 Mar 2019 06:30:45 GMT"}, {"version": "v5", "created": "Tue, 5 Mar 2019 14:58:47 GMT"}, {"version": "v6", "created": "Wed, 20 Nov 2019 04:20:13 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Chandrasekaran", "Varun", ""], ["Chaudhuri", "Kamalika", ""], ["Giacomelli", "Irene", ""], ["Jha", "Somesh", ""], ["Yan", "Songbai", ""]]}, {"id": "1811.02120", "submitter": "Leon Abdillah", "authors": "Robbi Rahim, Andri Pranolo, Ronal Hadi, Rasyidah, Heri Nurdiyanto,\n  Darmawan Napitupulu, Ansari Saleh Ahmar, Leon Andretti Abdillah, Dahlan\n  Abdullah", "title": "Digital Signature Security in Data Communication", "comments": "6 pages, Paper presented at the International Conference on Education\n  and Technology (ICEduTech2017), Novotel Hotel, Balikpapan, Indonesia", "journal-ref": null, "doi": "10.2991/icedutech-17.2018.34", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Authenticity of access in very information are very important in the current\nera of Internet-based technology, there are many ways to secure information\nfrom irresponsible parties with various security attacks, some of technique can\nuse for defend attack from irresponsible parties are using steganography,\ncryptography or also use digital signatures. Digital signatures could be one of\nsolution where the authenticity of the message will be verified to prove that\nthe received message is the original message without any change,\nOng-Schnorr-Shamir is the algorithm are used in this research and the\nexperiment are perform on the digital signature scheme and the hidden channel\nscheme.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 01:52:25 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Rahim", "Robbi", ""], ["Pranolo", "Andri", ""], ["Hadi", "Ronal", ""], ["Rasyidah", "", ""], ["Nurdiyanto", "Heri", ""], ["Napitupulu", "Darmawan", ""], ["Ahmar", "Ansari Saleh", ""], ["Abdillah", "Leon Andretti", ""], ["Abdullah", "Dahlan", ""]]}, {"id": "1811.02217", "submitter": "Dongsheng Li", "authors": "Yingying Zhao, Dongsheng Li, Qin Lv, Li Shang", "title": "A Scalable Algorithm for Privacy-Preserving Item-based Top-N\n  Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems have become an indispensable component in online services\nduring recent years. Effective recommendation is essential for improving the\nservices of various online business applications. However, serious privacy\nconcerns have been raised on recommender systems requiring the collection of\nusers' private information for recommendation. At the same time, the success of\ne-commerce has generated massive amounts of information, making scalability a\nkey challenge in the design of recommender systems. As such, it is desirable\nfor recommender systems to protect users' privacy while achieving high-quality\nrecommendations with low-complexity computations.\n  This paper proposes a scalable privacy-preserving item-based top-N\nrecommendation solution, which can achieve high-quality recommendations with\nreduced computation complexity while ensuring that users' private information\nis protected. Furthermore, the computation complexity of the proposed method\nincreases slowly as the number of users increases, thus providing high\nscalability for privacy-preserving recommender systems. More specifically, the\nproposed approach consists of two key components: (1) MinHash-based similarity\nestimation and (2) client-side privacy-preserving prediction generation. Our\ntheoretical and experimental analysis using real-world data demonstrates the\nefficiency and effectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 08:34:39 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Zhao", "Yingying", ""], ["Li", "Dongsheng", ""], ["Lv", "Qin", ""], ["Shang", "Li", ""]]}, {"id": "1811.02248", "submitter": "Apostolos Modas", "authors": "Apostolos Modas, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard", "title": "SparseFool: a few pixels make a big difference", "comments": "In Proceedings of IEEE Conference on Computer Vision and Pattern\n  Recognition (CVPR), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks have achieved extraordinary results on image\nclassification tasks, but have been shown to be vulnerable to attacks with\ncarefully crafted perturbations of the input data. Although most attacks\nusually change values of many image's pixels, it has been shown that deep\nnetworks are also vulnerable to sparse alterations of the input. However, no\ncomputationally efficient method has been proposed to compute sparse\nperturbations. In this paper, we exploit the low mean curvature of the decision\nboundary, and propose SparseFool, a geometry inspired sparse attack that\ncontrols the sparsity of the perturbations. Extensive evaluations show that our\napproach computes sparse perturbations very fast, and scales efficiently to\nhigh dimensional data. We further analyze the transferability and the visual\neffects of the perturbations, and show the existence of shared semantic\ninformation across the images and the networks. Finally, we show that\nadversarial training can only slightly improve the robustness against sparse\nadditive perturbations computed with SparseFool.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 09:30:34 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 11:56:58 GMT"}, {"version": "v3", "created": "Sun, 18 Nov 2018 19:41:22 GMT"}, {"version": "v4", "created": "Mon, 27 May 2019 16:33:41 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Modas", "Apostolos", ""], ["Moosavi-Dezfooli", "Seyed-Mohsen", ""], ["Frossard", "Pascal", ""]]}, {"id": "1811.02276", "submitter": "Madhusanka Liyanage", "authors": "Ahsan Manzoor, Madhsanka Liyanage, An Braeken, Salil S. Kanhere, Mika\n  Ylianttila", "title": "Blockchain based Proxy Re-Encryption Scheme for Secure IoT Data Sharing", "comments": "Accepted to publish in proceeding of 2019 IEEE International\n  Conference on Blockchain and Cryptocurrency (ICBC 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data is central to the Internet of Things (IoT) ecosystem. Most of the\ncurrent IoT systems are using centralized cloud-based data sharing systems,\nwhich will be difficult to scale up to meet the demands of future IoT systems.\nInvolvement of such third-party service provider requires also trust from both\nsensor owner and sensor data user. Moreover, the fees need to be paid for their\nservices. To tackle both the scalability and trust issues and to automatize the\npayments, this paper presents a blockchain based proxy re-encryption scheme.\nThe system stores the IoT data in a distributed cloud after encryption. To\nshare the collected IoT data, the system establishes runtime dynamic smart\ncontracts between the sensor and data user without the involvement of a trusted\nthird party. It also uses a very efficient proxy re-encryption scheme which\nallows that the data is only visible by the owner and the person present in the\nsmart contract. This novel combination of smart contracts with proxy\nre-encryption provides an efficient, fast and secure platform for storing,\ntrading and managing of sensor data. The proposed system is implemented in an\nEthereum based testbed to analyze the performance and the security properties.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 10:46:42 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 18:46:17 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Manzoor", "Ahsan", ""], ["Liyanage", "Madhsanka", ""], ["Braeken", "An", ""], ["Kanhere", "Salil S.", ""], ["Ylianttila", "Mika", ""]]}, {"id": "1811.02293", "submitter": "Mohsin Ali Khan Md. Mohsin Ali Khan", "authors": "Mohsin Khan, Philip Ginzboorg, Kimmo J\\\"arvinen, and Valtteri Niemi", "title": "Defeating the Downgrade Attack on Identity Privacy in 5G", "comments": null, "journal-ref": "SSR 2018: Security Standardisation Research", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3GPP Release 15, the first 5G standard, includes protection of user identity\nprivacy against IMSI catchers. These protection mechanisms are based on public\nkey encryption. Despite this protection, IMSI catching is still possible in LTE\nnetworks which opens the possibility of a downgrade attack on user identity\nprivacy, where a fake LTE base station obtains the identity of a 5G user\nequipment. We propose (i) to use an existing pseudonym-based solution to\nprotect user identity privacy of 5G user equipment against IMSI catchers in LTE\nand (ii) to include a mechanism for updating LTE pseudonyms in the public key\nencryption based 5G identity privacy procedure. The latter helps to recover\nfrom a loss of synchronization of LTE pseudonyms. Using this mechanism,\npseudonyms in the user equipment and home network are automatically\nsynchronized when the user equipment connects to 5G. Our mechanisms utilize\nexisting LTE and 3GPP Release 15 messages and require modifications only in the\nuser equipment and home network in order to provide identity privacy.\nAdditionally, lawful interception requires minor patching in the serving\nnetwork.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 11:26:35 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Khan", "Mohsin", ""], ["Ginzboorg", "Philip", ""], ["J\u00e4rvinen", "Kimmo", ""], ["Niemi", "Valtteri", ""]]}, {"id": "1811.02536", "submitter": "Ross Horne", "authors": "Ross Horne", "title": "A Bisimilarity Congruence for the Applied pi-Calculus Sufficiently\n  Coarse to Verify Privacy Properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper is the first thorough investigation into the coarsest notion of\nbisimilarity for the applied pi-calculus that is a congruence relation: open\nbarbed bisimilarity. An open variant of labelled bisimilarity (quasi-open\nbisimilarity), better suited to constructing bisimulations, is proven to\ncoincide with open barbed bisimilarity. These bisimilary congruences are shown\nto be characterised by an intuitionistic modal logic that can be used, for\nexample, to describe an attack on privacy whenever a privacy property is\nviolated. Open barbed bisimilarity provides a compositional approach to\nverifying cryptographic protocols, since properties proven can be reused in any\ncontext, including under input prefix. Furthermore, open barbed bisimilarity is\nsufficiently coarse for reasoning about security and privacy properties of\ncryptographic protocols; in constrast to the finer bisimilarity congruence,\nopen bisimilarity, which cannot verify certain privacy properties.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 18:12:02 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Horne", "Ross", ""]]}, {"id": "1811.02625", "submitter": "Shiqi Wang", "authors": "Shiqi Wang, Yizheng Chen, Ahmed Abdou, Suman Jana", "title": "MixTrain: Scalable Training of Verifiably Robust Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making neural networks robust against adversarial inputs has resulted in an\narms race between new defenses and attacks. The most promising defenses,\nadversarially robust training and verifiably robust training, have limitations\nthat restrict their practical applications. The adversarially robust training\nonly makes the networks robust against a subclass of attackers and we reveal\nsuch weaknesses by developing a new attack based on interval gradients. By\ncontrast, verifiably robust training provides protection against any L-p\nnorm-bounded attacker but incurs orders of magnitude more computational and\nmemory overhead than adversarially robust training.\n  We propose two novel techniques, stochastic robust approximation and dynamic\nmixed training, to drastically improve the efficiency of verifiably robust\ntraining without sacrificing verified robustness. We leverage two critical\ninsights: (1) instead of over the entire training set, sound\nover-approximations over randomly subsampled training data points are\nsufficient for efficiently guiding the robust training process; and (2) We\nobserve that the test accuracy and verifiable robustness often conflict after\ncertain training epochs. Therefore, we use a dynamic loss function to\nadaptively balance them for each epoch.\n  We designed and implemented our techniques as part of MixTrain and evaluated\nit on six networks trained on three popular datasets including MNIST, CIFAR,\nand ImageNet-200. Our evaluations show that MixTrain can achieve up to $95.2\\%$\nverified robust accuracy against $L_\\infty$ norm-bounded attackers while taking\n$15$ and $3$ times less training time than state-of-the-art verifiably robust\ntraining and adversarially robust training schemes, respectively. Furthermore,\nMixTrain easily scales to larger networks like the one trained on ImageNet-200,\nsignificantly outperforming the existing verifiably robust training methods.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 20:47:28 GMT"}, {"version": "v2", "created": "Sat, 1 Dec 2018 23:52:52 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Wang", "Shiqi", ""], ["Chen", "Yizheng", ""], ["Abdou", "Ahmed", ""], ["Jana", "Suman", ""]]}, {"id": "1811.02748", "submitter": "Atefeh Musavi", "authors": "Seyyedeh Atefeh Musavi, and Mahmoud Reza Hashemi", "title": "A Method for Ontology-based Architecture Reconstruction of Computing\n  Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's ubiquitous computing ecosystem involves various kinds of hardware and\nsoftware technologies for different computing environments. As the result,\ncomputing systems can be seen as integrated system of hardware and software\nsystems. Realizing such complex systems is crucial for providing safety,\nsecurity, and maintenance. This is while the characterization of computing\nsystems is not possible without a systematic procedure for enumerating\ndifferent components and their structural/behavioral relationships.\nArchitecture Reconstruction (AR) is a practice defined in the domain of\nsoftware engineering for the realization of a specific software component.\nHowever, it is not applicable to a whole system (including HW/SW). Inspired by\nSymphony AR framework, we have proposed a generalized method to reconstruct the\narchitecture of a computing platform at HW/SW boundary. In order to cover\ndiverge set of existing HW/SW technologies, our method uses an ontology-based\napproach to handle these complexities. Due to the lack of a comprehensive\naccurate ontology in the literature, we have developed our own ontology --\ncalled PLATOnt -- which is shown to be more effective by ONTOQA evaluation\nframework. We have used our AR method in two use case scenarios to reconstruct\nthe architecture of ARM-based Trusted execution environment and a Raspberry-pi\nplatform have extensive application in embedded systems and IoT devices.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 03:57:30 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Musavi", "Seyyedeh Atefeh", ""], ["Hashemi", "Mahmoud Reza", ""]]}, {"id": "1811.02887", "submitter": "Tam Nguyen", "authors": "Tam N. Nguyen", "title": "Certified Ethical Hacker v.10 Online Course - a Case Study", "comments": "8 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CEH v.10 Certification Self-study Course is an online course preparing\nlearners for one of the most prestige cyber security certifications in the\nworld - the Certified Ethical Hacker (CEH) v.10 Certification. Due to a pay\nwall and the practical rather than theoretical nature, most researchers have\nlimited exposure to this course. For the first time, this paper will analyze\nthe course's instructional design based on the highest national standards and\nrelated peer-reviewed published research works. The sole intention is to push\nthe course to a higher ground, making it the best online course for cyber\nsecurity. More importantly, the paper's instructional design evaluation\nstrategy can well be extended and applied to any other online course'\ninstructional design review and/or evaluation process.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 23:40:00 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Nguyen", "Tam N.", ""]]}, {"id": "1811.02984", "submitter": "Atul Singh Arora", "authors": "Atul Singh Arora, J\\'er\\'emie Roland, Stephan Weis", "title": "Quantum Weak Coin Flipping", "comments": "98 pages split into 3 parts, 10 figures; For updates and contact\n  information see https://atulsingharora.github.io/WCF. Version 2 has minor\n  improvements. arXiv admin note: text overlap with arXiv:1402.7166 by other\n  authors", "journal-ref": "STOC 2019 Proceedings of the 51st Annual ACM SIGACT Symposium on\n  Theory of Computing Pages 205-216", "doi": "10.1145/3313276.3316306", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We investigate weak coin flipping, a fundamental cryptographic primitive\nwhere two distrustful parties need to remotely establish a shared random bit. A\ncheating player can try to bias the output bit towards a preferred value. For\nweak coin flipping the players have known opposite preferred values. A weak\ncoin-flipping protocol has a bias $\\epsilon$ if neither player can force the\noutcome towards their preferred value with probability more than\n$\\frac{1}{2}+\\epsilon$. While it is known that all classical protocols have\n$\\epsilon=\\frac{1}{2}$, Mochon showed in 2007 [arXiv:0711.4114] that quantumly\nweak coin flipping can be achieved with arbitrarily small bias (near perfect)\nbut the best known explicit protocol has bias $1/6$ (also due to Mochon, 2005\n[Phys. Rev. A 72, 022341]). We propose a framework to construct new explicit\nprotocols achieving biases below $1/6$. In particular, we construct explicit\nunitaries for protocols with bias approaching $1/10$. To go below, we introduce\nwhat we call the Elliptic Monotone Align (EMA) algorithm which, together with\nthe framework, allows us to numerically construct protocols with arbitrarily\nsmall biases.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 15:25:56 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 17:06:05 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Arora", "Atul Singh", ""], ["Roland", "J\u00e9r\u00e9mie", ""], ["Weis", "Stephan", ""]]}, {"id": "1811.03019", "submitter": "Rajendra Kumar", "authors": "Shashank K Mehta, Mahesh Sreekumar Rajasree and Rajendra Kumar", "title": "Maximum Distance Sub-Lattice Problem", "comments": "17 pages, No figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we define a problem on lattices called the Maximum Distance\nSub-lattice Problem (MDSP). The decision version of this problem is shown to be\nin NP. We prove that MDSP is isomorphic to a well-known problem called closest\nvector problem (CVP). We give an exact and a heuristic algorithm for MDSP.\nUsing experimental results we show that the LLL algorithm can be accelerated\nwhen it is combined with the heuristic algorithm for MDSP.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 17:12:02 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Mehta", "Shashank K", ""], ["Rajasree", "Mahesh Sreekumar", ""], ["Kumar", "Rajendra", ""]]}, {"id": "1811.03165", "submitter": "Nathan Burow", "authors": "Nathan Burow, Xinping Zhang, Mathias Payer", "title": "Shining Light On Shadow Stacks", "comments": "To Appear in IEEE Security and Privacy 2019", "journal-ref": null, "doi": "10.1109/SP.2019.00076", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Control-Flow Hijacking attacks are the dominant attack vector against C/C++\nprograms. Control-Flow Integrity (CFI) solutions mitigate these attacks on the\nforward edge,i.e., indirect calls through function pointers and virtual calls.\nProtecting the backward edge is left to stack canaries, which are easily\nbypassed through information leaks. Shadow Stacks are a fully precise mechanism\nfor protecting backwards edges, and should be deployed with CFI mitigations. We\npresent a comprehensive analysis of all possible shadow stack mechanisms along\nthree axes: performance, compatibility, and security. For performance\ncomparisons we use SPEC CPU2006, while security and compatibility are\nqualitatively analyzed. Based on our study, we renew calls for a shadow stack\ndesign that leverages a dedicated register, resulting in low performance\noverhead, and minimal memory overhead, but sacrifices compatibility. We present\ncase studies of our implementation of such a design, Shadesmar, on Phoronix and\nApache to demonstrate the feasibility of dedicating a general purpose register\nto a security monitor on modern architectures, and the deployability of\nShadesmar. Our comprehensive analysis, including detailed case studies for our\nnovel design, allows compiler designers and practitioners to select the correct\nshadow stack design for different usage scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 22:08:12 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 15:02:07 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Burow", "Nathan", ""], ["Zhang", "Xinping", ""], ["Payer", "Mathias", ""]]}, {"id": "1811.03190", "submitter": "Ming-Ming Wang", "authors": "Ming-Ming Wang, Lin-Ming Gong, and Lian-He Shao", "title": "Efficient semiquantum key distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum cryptography has attracted much attention in recent years. In most\nexisting quantum cryptographic protocols, players usually need the full quantum\npower of generating, manipulating or measuring quantum states. Semiquantum\ncryptography was proposed to deal with the issue that some players require only\npartial quantum power, such as preparing or measuring quantum states in the\nclassical basis, which simplifies the implementations of quantum cryptography.\nHowever, the efficiency of the existing semiquantum cryptographic protocols was\nrelatively low from a practical point of view. In this paper, we devise some\nnew semiquantum key distribution (SQKD) protocols which highly improve the\nefficiency of the most well-known SQKD protocols [Phys. Rev. Lett. 99, 140501\n(2007) & Phys. Rev. A 79, 052312 (2009)]. By letting players select their\nactions asymmetrically, the efficiency of our new protocols can be made\nasymptotically close to 100%. Besides, one of our proposed protocols also\nutilizes the discarded X-SIFT bits in the original SQKD protocol, which further\nimproves the efficiency of SQKD. We prove that the proposed SQKD protocols are\ncompletely robust against the most general attack.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 23:48:49 GMT"}, {"version": "v2", "created": "Fri, 9 Nov 2018 04:16:43 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Wang", "Ming-Ming", ""], ["Gong", "Lin-Ming", ""], ["Shao", "Lian-He", ""]]}, {"id": "1811.03194", "submitter": "Florian Tram\\`er", "authors": "Florian Tram\\`er, Pascal Dupr\\'e, Gili Rusak, Giancarlo Pellegrino,\n  Dan Boneh", "title": "AdVersarial: Perceptual Ad Blocking meets Adversarial Machine Learning", "comments": "17 pages, 14 figures", "journal-ref": "In 2019 ACM SIGSAC Conference on Computer and Communications\n  Security (CCS '19)", "doi": "10.1145/3319535.3354222", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perceptual ad-blocking is a novel approach that detects online advertisements\nbased on their visual content. Compared to traditional filter lists, the use of\nperceptual signals is believed to be less prone to an arms race with web\npublishers and ad networks. We demonstrate that this may not be the case. We\ndescribe attacks on multiple perceptual ad-blocking techniques, and unveil a\nnew arms race that likely disfavors ad-blockers. Unexpectedly, perceptual\nad-blocking can also introduce new vulnerabilities that let an attacker bypass\nweb security boundaries and mount DDoS attacks.\n  We first analyze the design space of perceptual ad-blockers and present a\nunified architecture that incorporates prior academic and commercial work. We\nthen explore a variety of attacks on the ad-blocker's detection pipeline, that\nenable publishers or ad networks to evade or detect ad-blocking, and at times\neven abuse its high privilege level to bypass web security boundaries.\n  On one hand, we show that perceptual ad-blocking must visually classify\nrendered web content to escape an arms race centered on obfuscation of page\nmarkup. On the other, we present a concrete set of attacks on visual\nad-blockers by constructing adversarial examples in a real web page context.\nFor seven ad-detectors, we create perturbed ads, ad-disclosure logos, and\nnative web content that misleads perceptual ad-blocking with 100% success\nrates. In one of our attacks, we demonstrate how a malicious user can upload\nadversarial content, such as a perturbed image in a Facebook post, that fools\nthe ad-blocker into removing another users' non-ad content.\n  Moving beyond the Web and visual domain, we also build adversarial examples\nfor AdblockRadio, an open source radio client that uses machine learning to\ndetects ads in raw audio streams.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 00:20:12 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 09:02:47 GMT"}, {"version": "v3", "created": "Mon, 26 Aug 2019 10:27:39 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Tram\u00e8r", "Florian", ""], ["Dupr\u00e9", "Pascal", ""], ["Rusak", "Gili", ""], ["Pellegrino", "Giancarlo", ""], ["Boneh", "Dan", ""]]}, {"id": "1811.03197", "submitter": "Hassan Jameel Asghar", "authors": "Victor Perrier and Hassan Jameel Asghar and Dali Kaafar", "title": "Private Continual Release of Real-Valued Data Streams", "comments": "Accepted for publication at NDSS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a differentially private mechanism to display statistics (e.g.,\nthe moving average) of a stream of real valued observations where the bound on\neach observation is either too conservative or unknown in advance. This is\nparticularly relevant to scenarios of real-time data monitoring and reporting,\ne.g., energy data through smart meters. Our focus is on real-world data streams\nwhose distribution is light-tailed, meaning that the tail approaches zero at\nleast as fast as the exponential distribution. For such data streams,\nindividual observations are expected to be concentrated below an unknown\nthreshold. Estimating this threshold from the data can potentially violate\nprivacy as it would reveal particular events tied to individuals [1]. On the\nother hand an overly conservative threshold may impact accuracy by adding more\nnoise than necessary. We construct a utility optimizing differentially private\nmechanism to release this threshold based on the input stream. Our main\nadvantage over the state-of-the-art algorithms is that the resulting noise\nadded to each observation of the stream is scaled to the threshold instead of a\npossibly much larger bound; resulting in considerable gain in utility when the\ndifference is significant. Using two real-world datasets, we demonstrate that\nour mechanism, on average, improves the utility by a factor of 3.5 on the first\ndataset, and 9 on the other. While our main focus is on continual release of\nstatistics, our mechanism for releasing the threshold can be used in various\nother applications where a (privacy-preserving) measure of the scale of the\ninput distribution is required.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 00:26:33 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Perrier", "Victor", ""], ["Asghar", "Hassan Jameel", ""], ["Kaafar", "Dali", ""]]}, {"id": "1811.03223", "submitter": "Jingwei Liu", "authors": "Jingwei Liu, Xiaolu Li, Lin Ye, Hongli Zhang, Xiaojiang Du, Mohsen\n  Guizani", "title": "BPDS: A Blockchain based Privacy-Preserving Data Sharing for Electronic\n  Medical Records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic medical record (EMR) is a crucial form of healthcare data,\ncurrently drawing a lot of attention. Sharing health data is considered to be a\ncritical approach to improve the quality of healthcare service and reduce\nmedical costs. However, EMRs are fragmented across decentralized hospitals,\nwhich hinders data sharing and puts patients' privacy at risks. To address\nthese issues, we propose a blockchain based privacy-preserving data sharing for\nEMRs, called BPDS. In BPDS, the original EMRs are stored securely in the cloud\nand the indexes are reserved in a tamper-proof consortium blockchain. By this\nmeans, the risk of the medical data leakage could be greatly reduced, and at\nthe same time, the indexes in blockchain ensure that the EMRs can not be\nmodified arbitrarily. Secure data sharing can be accomplished automatically\naccording to the predefined access permissions of patients through the smart\ncontracts of blockchain. Besides, the joint-design of the CP-ABE-based access\ncontrol mechanism and the content extraction signature scheme provides strong\nprivacy preservation in data sharing. Security analysis shows that BPDS is a\nsecure and effective way to realize data sharing for EMRs.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 02:19:06 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Liu", "Jingwei", ""], ["Li", "Xiaolu", ""], ["Ye", "Lin", ""], ["Zhang", "Hongli", ""], ["Du", "Xiaojiang", ""], ["Guizani", "Mohsen", ""]]}, {"id": "1811.03238", "submitter": "Jingwei Liu", "authors": "Jingwei Liu, Xiaolu Li, Rong Sun, Xiaojiang Du, Paul Ratazzi", "title": "An Efficient Privacy-Preserving Incentive Scheme without TTP in\n  Participatory Sensing Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Along with the development of wireless communication technology, a mass of\nmobile devices are gaining stronger sensing capability, which brings a novel\nparadigm to light: participatory sensing networks (PSNs). PSNs can greatly\nreduce the cost of wireless sensor networks, and hence are becoming an\nefficient way to obtain abundant sensing data from surrounding environment.\nTherefore, PSNs would lead to significant improvement in various fields,\nincluding cognitive communication. However, the large-scale deployment of\nparticipatory sensing applications is hindered by the lack of incentive\nmechanism, security and privacy concerns. It is still an ongoing issue to\naddress all three aspects simultaneously in PSNs. In this paper, we construct\nan efficient privacy-preserving incentive scheme without trusted third party\n(TTP) for PSNs to motivate user-participation. This scheme allows each\nparticipant to earn credits by contributing data privately. Using blind and\npartially blind signatures, the proposed scheme is proved to be secure for\nprivacy and incentive. Additionally, the performance evaluation in terms of\ncomputation and storage indicates that the proposed scheme has higher\nefficiency.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 03:03:53 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Liu", "Jingwei", ""], ["Li", "Xiaolu", ""], ["Sun", "Rong", ""], ["Du", "Xiaojiang", ""], ["Ratazzi", "Paul", ""]]}, {"id": "1811.03239", "submitter": "Jingwei Liu", "authors": "Jingwei Liu, Qingqing Li, Rong Sun, Xiaojiang Du, Mohsen Guizani", "title": "An Efficient Anonymous Authentication Scheme for Internet of Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Vehicles (IoV) is an intelligent application of IoT in smart\ntransportation, which can make intelligent decisions for passengers. It has\ndrawn extensive attention to improve traffic safety and efficiency and create a\nmore comfortable driving and riding environment. Vehicular cloud computing is a\nvariant of mobile cloud computing, which can process local information quickly.\nThe cooperation of the Internet and vehicular cloud can make the communication\nmore efficient in IoV. In this paper, we mainly focus on the secure\ncommunication between vehicles and roadside units. We first propose a new\ncertificateless short signature scheme (CLSS) and prove the unforgeability of\nit in random oracle model. Then, by combining CLSS and a regional management\nstrategy we design an efficient anonymous mutual quick authentication scheme\nfor IoV. Additionally, the quantitative performance analysis shows that the\nproposed scheme achieves higher efficiency in terms of interaction between\nvehicles and roadside units compared with other existing schemes.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 03:04:20 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Liu", "Jingwei", ""], ["Li", "Qingqing", ""], ["Sun", "Rong", ""], ["Du", "Xiaojiang", ""], ["Guizani", "Mohsen", ""]]}, {"id": "1811.03241", "submitter": "Wei Zhou", "authors": "Wei Zhou, Yan Jia, Yao Yao, Lipeng Zhu, Le Guan, Yuhang Mao, Peng Liu,\n  Yuqing Zhang", "title": "Discovering and Understanding the Security Hazards in the Interactions\n  between IoT Devices, Mobile Apps, and Clouds on Smart Home Platforms", "comments": "This paper has been accepted by USENIX Security '19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A smart home connects tens of home devices to the Internet, where an IoT\ncloud runs various home automation applications. While bringing unprecedented\nconvenience and accessibility, it also introduces various security hazards to\nusers. Prior research studied smart home security from several aspects.\nHowever, we found that the complexity of the interactions among the\nparticipating entities (i.e., devices, IoT clouds, and mobile apps) has not yet\nbeen systematically investigated. In this work, we conducted an in-depth\nanalysis of five widely-used smart home platforms. Combining firmware analysis,\nnetwork traffic interception, and blackbox testing, we reverse-engineered the\ndetails of the interactions among the participating entities. Based on the\ndetails, we inferred three legitimate state transition diagrams for the three\nentities, respectively. Using these state machines as a reference model, we\nidentified a set of unexpected state transitions. To confirm and trigger the\nunexpected state transitions, we implemented a set of phantom devices to mimic\na real device. By instructing the phantom devices to intervene in the normal\nentity-entity interactions, we have discovered several new vulnerabilities and\na spectrum of attacks against real-world smart home platforms.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 03:06:47 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 15:14:24 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Zhou", "Wei", ""], ["Jia", "Yan", ""], ["Yao", "Yao", ""], ["Zhu", "Lipeng", ""], ["Guan", "Le", ""], ["Mao", "Yuhang", ""], ["Liu", "Peng", ""], ["Zhang", "Yuqing", ""]]}, {"id": "1811.03243", "submitter": "Jingwei Liu", "authors": "Jingwei Liu, Huifang Tang, Chaoya Li, Rong Sun, Xiaojiang Du, Mohsen\n  Guizani", "title": "vFAC: Fine-Grained Access Control with Versatility for Cloud Storage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, cloud storage technology has been widely used in many fields\nsuch as education, business, medical and more because of its convenience and\nlow cost. With the widespread applications of cloud storage technology, data\naccess control methods become more and more important in cloud-based network.\nThe ciphertext policy attribute-based encryption (CP-ABE) scheme is very\nsuitable for access control of data in cloud storage. However, in many\npractical scenarios, all attributes of a user cannot be managed by one\nauthority, so many multi-authority CP-ABE schemes have emerged. Moreover, cloud\nservers are usually semi-trusted, which may leak user information. Aiming at\nthe above problems, we propose a fine-grained access control scheme with\nversatility for cloud storage based on multi-authority CP-ABE, named vFAC. The\nproposed vFAC has the features of large universe, no key escrow problem,\nonline/offline mechanism, hidden policy, verifiability and user revocation.\nFinally, we demonstrate vFAC is static security under the random oracle model.\nThrough the comparison of several existing schemes in terms of features,\ncomputational overhead and storage cost, we can draw a conclusion that vFAC is\nmore comprehensive and scalable.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 03:11:41 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Liu", "Jingwei", ""], ["Tang", "Huifang", ""], ["Li", "Chaoya", ""], ["Sun", "Rong", ""], ["Du", "Xiaojiang", ""], ["Guizani", "Mohsen", ""]]}, {"id": "1811.03246", "submitter": "Jingwei Liu", "authors": "Jingwei Liu, Qin Hu, Chaoya Li, Rong Sun, Xiaojiang Du, Mohsen Guizani", "title": "A Traceable Concurrent Data Anonymous Transmission Scheme for\n  Heterogeneous VANETs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicular Ad Hoc Networks (VANETs) are attractive scenarios that can improve\nthe traffic situation and provide convenient services for drivers and\npassengers via vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I)\ncommunication. However, there are still many security challenges in the traffic\ninformation transmission, especially in the intense traffic case. For ensuring\nthe privacy of users and traceability of vehicles, we propose a traceable\nconcurrent data anonymous transmission scheme for heterogeneous VANETs. The\nscheme is based on certificateless aggregate signcryption, so it supports batch\nverification. Moreover, conditional anonymity is also achieved due to the\ninvolving of the pseudo-ID technique. Furthermore, it is a pairing-free scheme\nfor the merit of multi-trapdoor hash functions. As a result, the total\ncomputation overhead is greatly reduced.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 03:21:09 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Liu", "Jingwei", ""], ["Hu", "Qin", ""], ["Li", "Chaoya", ""], ["Sun", "Rong", ""], ["Du", "Xiaojiang", ""], ["Guizani", "Mohsen", ""]]}, {"id": "1811.03265", "submitter": "Vinay Ribeiro", "authors": "Sourav Das, Vinay Joseph Ribeiro, Abhijeet Anand", "title": "YODA: Enabling computationally intensive contracts on blockchains with\n  Byzantine and Selfish nodes", "comments": "To appear at Network and Distributed Systems Security (NDSS)\n  Symposium 2019 24-27 February 2019, San Diego, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One major shortcoming of permissionless blockchains such as Bitcoin and\nEthereum is that they are unsuitable for running Computationally Intensive\nsmart Contracts (CICs). This prevents such blockchains from running Machine\nLearning algorithms, Zero-Knowledge proofs, etc. which may need non-trivial\ncomputation. In this paper, we present YODA, which is to the best of our\nknowledge the first solution for efficient computation of CICs in\npermissionless blockchains with guarantees for a threat model with both\nByzantine and selfish nodes. YODA selects one or more execution sets (ES) via\nSortition to execute a particular CIC off-chain. One key innovation is the\nMultI-Round Adaptive Consensus using Likelihood Estimation (MIRACLE) algorithm\nbased on sequential hypothesis testing. M I RACLE allows the execution sets to\nbe small thus making YODA efficient while ensuring correct CIC execution with\nhigh probability. It adapts the number of ES sets automatically depending on\nthe concentration of Byzantine nodes in the system and is optimal in terms of\nthe expected number of ES sets used in certain scenarios. Through a suite of\neconomic incentives and technical mechanisms such as the novel Randomness\nInserted Contract Execution (RICE) algorithm, we force selfish nodes to behave\nhonestly. We also prove that the honest behavior of selfish nodes is an\napproximate Nash Equilibrium. We present the system design and details of YODA\nand prove the security properties of MIRACLE and RICE. Our prototype\nimplementation built on top of Ethereum demonstrates the ability of YODA to run\nCICs with orders of magnitude higher gas per unit time as well as total gas\nrequirements than Ethereum currently supports. It also demonstrates the low\noverheads of RICE.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 04:44:06 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2018 10:06:02 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Das", "Sourav", ""], ["Ribeiro", "Vinay Joseph", ""], ["Anand", "Abhijeet", ""]]}, {"id": "1811.03290", "submitter": "Jason R.C. Nurse Dr", "authors": "Jason R. C. Nurse and Sadie Creese and David De Roure", "title": "Security Risk Assessment in Internet of Things Systems", "comments": "9 pages, 1 figure", "journal-ref": "IT Professional (Volume: 19, Issue: 5, 2017 )", "doi": "10.1109/MITP.2017.3680959", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information security risk assessment methods have served us well over the\npast two decades. They have provided a tool for organizations and governments\nto use in protecting themselves against pertinent risks. As the complexity,\npervasiveness, and automation of technology systems increases and cyberspace\nmatures, particularly with the Internet of Things (IoT), there is a strong\nargument that we will need new approaches to assess risk and build trust. The\nchallenge with simply extending existing assessment methodologies to IoT\nsystems is that we could be blind to new risks arising in such ecosystems.\nThese risks could be related to the high degrees of connectivity present or the\ncoupling of digital, cyber-physical, and social systems. This article makes the\ncase for new methodologies to assess risk in this context that consider the\ndynamics and uniqueness of the IoT while maintaining the rigor of best practice\nin risk assessment.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 06:50:58 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Nurse", "Jason R. C.", ""], ["Creese", "Sadie", ""], ["De Roure", "David", ""]]}, {"id": "1811.03417", "submitter": "Gautam Srivastava", "authors": "Gautam Srivastava, Ashutosh Dhar Dwivedi, Rajani Singh", "title": "Automated Remote Patient Monitoring: Data Sharing and Privacy Using\n  Blockchain", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The revolution of Internet of Things (IoT) devices and wearable technology\nhas opened up great possibilities in remote patient monitoring. To streamline\nthe diagnosis and treatment process, healthcare professionals are now adopting\nthe wearable technology. However, these technologies also pose grave privacy\nrisks and security concerns about the transfer and the logging of data\ntransactions. One solution to protect privacy in healthcare is the use of\nblockchain technology. However, one of the primary problems with blockchain is\nits highly limited scalability. In this work here, we propose the utilization\nof a blockchain based protocol to provide secure management and analysis of\ndata. In this paper we use recently introduced PoW based protocol GHOSTDAG,\nthat generalizes Satoshi's blockchain to a direct acyclic graph of blocks\n(blockDAG) and provides high throughput while also avoiding the\nsecurity-scalability problem. We use two blockchains based on the original\nGHOSTDAG protocol, one that is private and one that is public. Using a private\nblockchain, we create a system where we use smart contracts to analyze patient\nhealth data. If the smart contract for any reason issues an alert for an\nabnormal reading then the system makes the record of that event to the public\nblockchain. This would resolve the privacy and security vulnerabilities\nassociated with remote patient monitoring and also the limited scalability\nproblem of Satoshi's original blockchain.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 19:41:56 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Srivastava", "Gautam", ""], ["Dwivedi", "Ashutosh Dhar", ""], ["Singh", "Rajani", ""]]}, {"id": "1811.03456", "submitter": "Jiayang Liu", "authors": "Jiayang Liu, Weiming Zhang, Nenghai Yu", "title": "CAAD 2018: Iterative Ensemble Adversarial Attack", "comments": "arXiv admin note: text overlap with arXiv:1811.00189", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have recently led to significant improvements in\nmany fields. However, DNNs are vulnerable to adversarial examples which are\nsamples with imperceptible perturbations while dramatically misleading the\nDNNs. Adversarial attacks can be used to evaluate the robustness of deep\nlearning models before they are deployed. Unfortunately, most of existing\nadversarial attacks can only fool a black-box model with a low success rate. To\nimprove the success rates for black-box adversarial attacks, we proposed an\niterated adversarial attack against an ensemble of image classifiers. With this\nmethod, we won the 5th place in CAAD 2018 Targeted Adversarial Attack\ncompetition.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 07:36:55 GMT"}], "update_date": "2018-11-11", "authors_parsed": [["Liu", "Jiayang", ""], ["Zhang", "Weiming", ""], ["Yu", "Nenghai", ""]]}, {"id": "1811.03457", "submitter": "Lukas Burkhalter", "authors": "Lukas Burkhalter, Anwar Hithnawi, Alexander Viand, Hossein Shafagh,\n  Sylvia Ratnasamy", "title": "TimeCrypt: Encrypted Data Stream Processing at Scale with Cryptographic\n  Access Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A growing number of devices and services collect detailed time series data\nthat is stored in the cloud. Protecting the confidentiality of this vast and\ncontinuously generated data is an acute need for many applications in this\nspace. At the same time, we must preserve the utility of this data by enabling\nauthorized services to securely and selectively access and run analytics. This\npaper presents TimeCrypt, a system that provides scalable and real-time\nanalytics over large volumes of encrypted time series data. TimeCrypt allows\nusers to define expressive data access and privacy policies and enforces it\ncryptographically via encryption. In TimeCrypt, data is encrypted end-to-end,\nand authorized parties can only decrypt and verify queries within their\nauthorized access scope. Our evaluation of TimeCrypt shows that its memory\noverhead and performance are competitive and close to operating on data in the\nclear.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 14:41:28 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 17:11:41 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Burkhalter", "Lukas", ""], ["Hithnawi", "Anwar", ""], ["Viand", "Alexander", ""], ["Shafagh", "Hossein", ""], ["Ratnasamy", "Sylvia", ""]]}, {"id": "1811.03538", "submitter": "Vuk Lesi", "authors": "Vuk Lesi, Ilija Jovanov, Miroslav Pajic", "title": "Integrating Security in Resource-Constrained Cyber-Physical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Defense mechanisms against network-level attacks are commonly based on the\nuse of cryptographic techniques, such as message authentication codes that\nprovide data integrity guarantees. However, such mechanisms require significant\nresources, which prevents their continuous use in resource-constrained\ncyber-physical systems. Recently, it was shown how physical properties of\nplants can be exploited to relax these requirements for systems where sensor\nmeasurements and actuator commands are transmitted over a compromised network;\nspecifically, intermittent use of data authentication, can still provide\nQuality-of-Control (QoC) guarantees even in the presence of false-data\ninjection attacks. Consequently, in this work we focus on integrating security\ninto existing systems, in order to protect against these attacks. We introduce\na design-time methodology that incorporates requirements for QoC in the\npresence of attacks into end-to-end timing constraints for real-time control\ntransactions, which include data acquisition and authentication, communication,\nand control. This allows us to formulate a mixed integer linear\nprogramming-based method for synthesis of schedulable task and message\nparameters (i.e., deadlines and offsets) that maintain timing requirements of\ndeployed controllers, while adding a sufficient level of protection against\nattacks; specifically, this method provides suitable intermittent\nauthentication policies that ensure the desired QoC levels under attack. To\nadditionally reduce the security-related bandwidth overhead, we propose the use\nof cumulative message authentication. Furthermore, we introduce a method for\nopportunistic use of remaining resources to further improve the overall QoC\nguarantees while ensuring system schedulability. Finally, we demonstrate\napplicability of our methodology on synthetic automotive systems as well as an\nautomotive case-study.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 16:34:32 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Lesi", "Vuk", ""], ["Jovanov", "Ilija", ""], ["Pajic", "Miroslav", ""]]}, {"id": "1811.03661", "submitter": "Peter Snyder", "authors": "Mohammad Ghasemisharif and Peter Snyder and Andrius Aucinas and\n  Benjamin Livshits", "title": "SpeedReader: Reader Mode Made Fast and Private", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most popular web browsers include \"reader modes\" that improve the user\nexperience by removing un-useful page elements. Reader modes reformat the page\nto hide elements that are not related to the page's main content. Such page\nelements include site navigation, advertising related videos and images, and\nmost JavaScript. The intended end result is that users can enjoy the content\nthey are interested in, without distraction.\n  In this work, we consider whether the \"reader mode\" can be widened to also\nprovide performance and privacy improvements. Instead of its use as a\npost-render feature to clean up the clutter on a page we propose SpeedReader as\nan alternative multistep pipeline that is part of the rendering pipeline. Once\nthe tool decides during the initial phase of a page load that a page is\nsuitable for reader mode use, it directly applies document tree translation\nbefore the page is rendered.\n  Based on our measurements, we believe that SpeedReader can be continuously\nenabled in order to drastically improve end-user experience, especially on\nslower mobile connections. Combined with our approach to predicting which pages\nshould be rendered in reader mode with 91% accuracy, it achieves drastic\nspeedups and bandwidth reductions of up to 27x and 84x respectively on average.\nWe further find that our novel \"reader mode\" approach brings with it\nsignificant privacy improvements to users. Our approach effectively removes all\ncommonly recognized trackers, issuing 115 fewer requests to third parties, and\ninteracts with 64 fewer trackers on average, on transformed pages.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 20:01:50 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Ghasemisharif", "Mohammad", ""], ["Snyder", "Peter", ""], ["Aucinas", "Andrius", ""], ["Livshits", "Benjamin", ""]]}, {"id": "1811.03685", "submitter": "Ian Goodfellow", "authors": "Ian Goodfellow", "title": "New CleverHans Feature: Better Adversarial Robustness Evaluations with\n  Attack Bundling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This technical report describes a new feature of the CleverHans library\ncalled \"attack bundling\". Many papers about adversarial examples present lists\nof error rates corresponding to different attack algorithms. A common approach\nis to take the maximum across this list and compare defenses against that error\nrate. We argue that a better approach is to use attack bundling: the max should\nbe taken across many examples at the level of individual examples, then the\nerror rate should be calculated by averaging after this maximization operation.\nReporting the bundled attacker error rate provides a lower bound on the true\nworst-case error rate. The traditional approach of reporting the maximum error\nrate across attacks can underestimate the true worst-case error rate by an\namount approaching 100\\% as the number of attacks approaches infinity. Attack\nbundling can be used with different prioritization schemes to optimize\nquantities such as error rate on adversarial examples, perturbation size needed\nto cause misclassification, or failure rate when using a specific confidence\nthreshold.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 21:30:57 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Goodfellow", "Ian", ""]]}, {"id": "1811.03716", "submitter": "Jared Smith", "authors": "Jared M. Smith, Kyle Birkeland, Tyler McDaniel, and Max Schuchard", "title": "Withdrawing the BGP Re-Routing Curtain: Understanding the Security\n  Impact of BGP Poisoning via Real-World Measurements", "comments": "NDSS 2020", "journal-ref": null, "doi": "10.14722/ndss.2020.23240", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The security of the Internet's routing infrastructure has underpinned much of\nthe past two decades of distributed systems security research. However, the\nconverse is increasingly true. Routing and path decisions are now important for\nthe security properties of systems built on top of the Internet. In particular,\nBGP poisoning leverages the de facto routing protocol between Autonomous\nSystems (ASes) to maneuver the return paths of upstream networks onto\npreviously unusable, new paths. These new paths can be used to avoid\ncongestion, censors, geo-political boundaries, or any feature of the topology\nwhich can be expressed at an AS-level. Given the increase in BGP poisoning\nusage as a security primitive, we set out to evaluate poisoning feasibility in\npractice beyond simulation.\n  To that end, using an Internet-scale measurement infrastructure, we capture\nand analyze over 1,400 instances of BGP poisoning across thousands of ASes as a\nmechanism to maneuver return paths of traffic. We analyze in detail the\nperformance of steering paths, the graph-theoretic aspects of available paths,\nand re-evaluate simulated systems with this data. We find that the real-world\nevidence does not completely support the findings from simulated systems\npublished in the literature. We also analyze filtering of BGP poisoning across\ntypes of ASes and ISP working groups. We explore the connectivity concerns when\npoisoning by reproducing a decade old experiment to uncover the current state\nof an Internet triple the size. We build predictive models for understanding an\nASes' vulnerability to poisoning. Finally, an exhaustive measurement of an\nupper bound on the maximum path length of the Internet is presented, detailing\nhow security research should react to ASes leveraging poisoned long paths. In\ntotal, our results and analysis expose the real-world impact of BGP poisoning\non past and future security research.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 23:31:52 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 18:17:40 GMT"}, {"version": "v3", "created": "Mon, 15 Apr 2019 22:46:11 GMT"}, {"version": "v4", "created": "Sat, 18 May 2019 22:33:36 GMT"}, {"version": "v5", "created": "Tue, 21 May 2019 18:20:05 GMT"}, {"version": "v6", "created": "Fri, 24 Jan 2020 18:08:25 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Smith", "Jared M.", ""], ["Birkeland", "Kyle", ""], ["McDaniel", "Tyler", ""], ["Schuchard", "Max", ""]]}, {"id": "1811.03725", "submitter": "Jingwei Liu", "authors": "Jingwei Liu, Fanghui Cai, Longfei Wu, Rong Sun, Liehuang Zhu,\n  Xiaojiang Du", "title": "EPDA: Enhancing Privacy-Preserving Data Authentication for Mobile Crowd\n  Sensing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a popular application, mobile crowd sensing systems aim at providing more\nconvenient service via the swarm intelligence. With the popularity of\nsensor-embedded smart phones and intelligent wearable devices, mobile crowd\nsensing is becoming an efficient way to obtain various types of sensing data\nfrom individuals, which will make people's life more convenient. However,\nmobile crowd sensing systems today are facing a critical challenge, namely the\nprivacy leakage of the sensitive information and valuable data, which can raise\ngrave concerns among the participants. To address this issue, we propose an\nenhanced secure certificateless privacy-preserving verifiable data\nauthentication scheme for mobile crowd sensing, named EPDA. The proposed scheme\nprovides unconditional anonymous data authentication service for mobile crowd\nsensing, by deploying an improved certificateless ring signature as the\ncryptogram essential, in which the big sensing data should be signed by one of\nlegitimate members in a specific group and could be verified without exposing\nthe actual identity of the participant. The formal security proof demonstrates\nthat EPDA is secure against existential forgery under adaptive chosen message\nand identity attacks in random oracle model. Finally, extensive simulations are\nconducted. The results show that the proposed EPDA efficiently decreases\ncomputational cost and time consumption in the sensing data authentication\nprocess.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 00:57:11 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Liu", "Jingwei", ""], ["Cai", "Fanghui", ""], ["Wu", "Longfei", ""], ["Sun", "Rong", ""], ["Zhu", "Liehuang", ""], ["Du", "Xiaojiang", ""]]}, {"id": "1811.03727", "submitter": "Jingwei Liu", "authors": "Jingwei Liu, Jinping Han, Longfei Wu, Rong Sun, Xiaojiang Du", "title": "VDAS: Verifiable Data Aggregation Scheme for Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Along with the miniaturization of various types of sensors, a mass of\nintelligent terminals are gaining stronger sensing capability, which raises a\ndeeper perception and better prospect of Internet of Things (IoT). With big\nsensing data, IoT provides lots of convenient services for the monitoring and\nmanagement of smart cities and people's daily lives. However, there are still\nmany security challenges influencing the further development of IoT, one of\nwhich is how to quickly verify the big data obtained from IoT terminals.\nAggregate signature is an efficient approach to perform big data\nauthentication. It can effectively reduce the computation and communication\noverheads. In this paper, utilizing these features, we construct a verifiable\ndata aggregation scheme for Internet of Things, named VDAS, based on an\nimproved certificateless aggregate signature algorithm. In VDAS, the length of\nthe aggregated authentication message is independent of the number of IoT\nterminals. Then, we prove that VDAS is existentially unforgeable under adaptive\nchosen message attacks assuming that the computational Diffie-Hellman problem\nis hard. Additionally, the proposed VDAS achieves a better trade-off on the\ncomputation overheads between the resource-constrained IoT terminals and the\ndata center.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 01:06:58 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Liu", "Jingwei", ""], ["Han", "Jinping", ""], ["Wu", "Longfei", ""], ["Sun", "Rong", ""], ["Du", "Xiaojiang", ""]]}, {"id": "1811.03728", "submitter": "Bryant Chen", "authors": "Bryant Chen, Wilka Carvalho, Nathalie Baracaldo, Heiko Ludwig,\n  Benjamin Edwards, Taesung Lee, Ian Molloy, and Biplav Srivastava", "title": "Detecting Backdoor Attacks on Deep Neural Networks by Activation\n  Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While machine learning (ML) models are being increasingly trusted to make\ndecisions in different and varying areas, the safety of systems using such\nmodels has become an increasing concern. In particular, ML models are often\ntrained on data from potentially untrustworthy sources, providing adversaries\nwith the opportunity to manipulate them by inserting carefully crafted samples\ninto the training set. Recent work has shown that this type of attack, called a\npoisoning attack, allows adversaries to insert backdoors or trojans into the\nmodel, enabling malicious behavior with simple external backdoor triggers at\ninference time and only a blackbox perspective of the model itself. Detecting\nthis type of attack is challenging because the unexpected behavior occurs only\nwhen a backdoor trigger, which is known only to the adversary, is present.\nModel users, either direct users of training data or users of pre-trained model\nfrom a catalog, may not guarantee the safe operation of their ML-based system.\nIn this paper, we propose a novel approach to backdoor detection and removal\nfor neural networks. Through extensive experimental results, we demonstrate its\neffectiveness for neural networks classifying text and images. To the best of\nour knowledge, this is the first methodology capable of detecting poisonous\ndata crafted to insert backdoors and repairing the model that does not require\na verified and trusted dataset.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 01:08:00 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Chen", "Bryant", ""], ["Carvalho", "Wilka", ""], ["Baracaldo", "Nathalie", ""], ["Ludwig", "Heiko", ""], ["Edwards", "Benjamin", ""], ["Lee", "Taesung", ""], ["Molloy", "Ian", ""], ["Srivastava", "Biplav", ""]]}, {"id": "1811.03730", "submitter": "Jingwei Liu", "authors": "Jingwei Liu, Qingqing Li, Huijuan Cao, Rong Sun, Xiaojiang Du, Mohsen\n  Guizani", "title": "MDBV: Monitoring Data Batch Verification for Survivability of Internet\n  of Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Along with the development of vehicular sensors and wireless communication\ntechnology, Internet of Vehicles (IoV) is emerging that can improve traffic\nefficiency and provide a comfortable driving environment. However, there is\nstill a challenge how to ensure the survivability of IoV. Fortunately, this\ngoal can be achieved by quickly verifying real-time monitoring data to avoid\nnetwork failure. Aggregate signature is an efficient approach to realize quick\ndata verification quickly. In this paper, we propose a monitoring data batch\nverification scheme based on an improved certificateless aggregate signature\nfor IoV, named MDBV. The size of aggregated verification message is remain\nroughly constant even as the increasing number of vehicles in MDBV.\nAdditionally, MDBV is proved to be secure in the random oracle model assuming\nthe intractability of the computational Diffie-Hellman problem. In\nconsideration of the network survivability and performance, the proposed MDBV\ncan decrease the computation overhead and is more suitable for IoV.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 01:19:32 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Liu", "Jingwei", ""], ["Li", "Qingqing", ""], ["Cao", "Huijuan", ""], ["Sun", "Rong", ""], ["Du", "Xiaojiang", ""], ["Guizani", "Mohsen", ""]]}, {"id": "1811.03733", "submitter": "Bhavya Kailkhura", "authors": "Thomas A. Hogan and Bhavya Kailkhura", "title": "Universal Decision-Based Black-Box Perturbations: Breaking\n  Security-Through-Obscurity Defenses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of finding a universal (image-agnostic) perturbation to\nfool machine learning (ML) classifiers (e.g., neural nets, decision tress) in\nthe hard-label black-box setting. Recent work in adversarial ML in the\nwhite-box setting (model parameters are known) has shown that many\nstate-of-the-art image classifiers are vulnerable to universal adversarial\nperturbations: a fixed human-imperceptible perturbation that, when added to any\nimage, causes it to be misclassified with high probability Kurakin et al.\n[2016], Szegedy et al. [2013], Chen et al. [2017a], Carlini and Wagner [2017].\nThis paper considers a more practical and challenging problem of finding such\nuniversal perturbations in an obscure (or black-box) setting. More\nspecifically, we use zeroth order optimization algorithms to find such a\nuniversal adversarial perturbation when no model information is revealed-except\nthat the attacker can make queries to probe the classifier. We further relax\nthe assumption that the output of a query is continuous valued confidence\nscores for all the classes and consider the case where the output is a\nhard-label decision. Surprisingly, we found that even in these extremely\nobscure regimes, state-of-the-art ML classifiers can be fooled with a very high\nprobability just by adding a single human-imperceptible image perturbation to\nany natural image. The surprising existence of universal perturbations in a\nhard-label black-box setting raises serious security concerns with the\nexistence of a universal noise vector that adversaries can possibly exploit to\nbreak a classifier on most natural images.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 01:43:22 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 15:56:52 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Hogan", "Thomas A.", ""], ["Kailkhura", "Bhavya", ""]]}, {"id": "1811.03739", "submitter": "Sihong Xie", "authors": "Shuaijun Ge and Guixiang Ma and Sihong Xie and Philip S. Yu", "title": "Securing Behavior-based Opinion Spam Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reviews spams are prevalent in e-commerce to manipulate product ranking and\ncustomers decisions maliciously. While spams generated based on simple spamming\nstrategy can be detected effectively, hardened spammers can evade regular\ndetectors via more advanced spamming strategies. Previous work gave more\nattention to evasion against text and graph-based detectors, but evasions\nagainst behavior-based detectors are largely ignored, leading to\nvulnerabilities in spam detection systems. Since real evasion data are scarce,\nwe first propose EMERAL (Evasion via Maximum Entropy and Rating sAmpLing) to\ngenerate evasive spams to certain existing detectors. EMERAL can simulate\nspammers with different goals and levels of knowledge about the detectors,\ntargeting at different stages of the life cycle of target products. We show\nthat in the evasion-defense dynamic, only a few evasion types are meaningful to\nthe spammers, and any spammer will not be able to evade too many detection\nsignals at the same time. We reveal that some evasions are quite insidious and\ncan fail all detection signals. We then propose DETER (Defense via Evasion\ngeneraTion using EmeRal), based on model re-training on diverse evasive samples\ngenerated by EMERAL. Experiments confirm that DETER is more accurate in\ndetecting both suspicious time window and individual spamming reviews. In terms\nof security, DETER is versatile enough to be vaccinated against diverse and\nunexpected evasions, is agnostic about evasion strategy and can be released\nwithout privacy concern.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 02:09:31 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Ge", "Shuaijun", ""], ["Ma", "Guixiang", ""], ["Xie", "Sihong", ""], ["Yu", "Philip S.", ""]]}, {"id": "1811.03741", "submitter": "Jingwei Liu", "authors": "Jingwei Liu, Lihuan Zhang, Rong Sun, Xiaojiang Du, Mohsen Guizani", "title": "Mutual Heterogeneous Signcryption Schemes for 5G Network Slicings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the emerging of mobile communication technologies, we are entering the\nfifth generation mobile communication system (5G) era. Various application\nscenarios will arise in the 5G era to meet the different service requirements.\nDifferent 5G network slicings may deploy different public key cryptosystems.\nThe security issues among the heterogeneous systems should be considered. In\norder to ensure the secure communications between 5G network slicings, in\ndifferent public cryptosystems, we propose two heterogeneous signcryption\nschemes which can achieve mutual communications between the Public Key\nInfrastructure (PKI) and the CertificateLess public key Cryptography (CLC)\nenvironment. We prove that our schemes have the INDistinguishability against\nAdaptive Chosen Ciphertext Attack (IND-CCA2) under the Computational\nDiffie-Hellman Problem (CDHP) and the Existential UnForgeability against\nadaptive Chosen Message Attack (EUF-CMA) under the Discrete Logarithm Problem\n(DLP) in the random oracle model. We also set up two heterogeneous\ncryptosystems on Raspberry Pi to simulate the interprocess communication\nbetween different public key environments. Furthermore, we quantify and analyze\nthe performance of each scheme. Compared with the existing schemes, our schemes\nhave greater efficiency and security.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 02:18:59 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Liu", "Jingwei", ""], ["Zhang", "Lihuan", ""], ["Sun", "Rong", ""], ["Du", "Xiaojiang", ""], ["Guizani", "Mohsen", ""]]}, {"id": "1811.03761", "submitter": "Liping Li", "authors": "Liping Li, Wei Xu, Tianyi Chen, Georgios B. Giannakis, and Qing Ling", "title": "RSA: Byzantine-Robust Stochastic Aggregation Methods for Distributed\n  Learning from Heterogeneous Datasets", "comments": "To appear in AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a class of robust stochastic subgradient methods\nfor distributed learning from heterogeneous datasets at presence of an unknown\nnumber of Byzantine workers. The Byzantine workers, during the learning\nprocess, may send arbitrary incorrect messages to the master due to data\ncorruptions, communication failures or malicious attacks, and consequently bias\nthe learned model. The key to the proposed methods is a regularization term\nincorporated with the objective function so as to robustify the learning task\nand mitigate the negative effects of Byzantine attacks. The resultant\nsubgradient-based algorithms are termed Byzantine-Robust Stochastic Aggregation\nmethods, justifying our acronym RSA used henceforth. In contrast to most of the\nexisting algorithms, RSA does not rely on the assumption that the data are\nindependent and identically distributed (i.i.d.) on the workers, and hence fits\nfor a wider class of applications. Theoretically, we show that: i) RSA\nconverges to a near-optimal solution with the learning error dependent on the\nnumber of Byzantine workers; ii) the convergence rate of RSA under Byzantine\nattacks is the same as that of the stochastic gradient descent method, which is\nfree of Byzantine attacks. Numerically, experiments on real dataset corroborate\nthe competitive performance of RSA and a complexity reduction compared to the\nstate-of-the-art alternatives.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 03:46:46 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 08:01:36 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Li", "Liping", ""], ["Xu", "Wei", ""], ["Chen", "Tianyi", ""], ["Giannakis", "Georgios B.", ""], ["Ling", "Qing", ""]]}, {"id": "1811.03789", "submitter": "Minjia Shi", "authors": "Minjia Shi, Li Xu, Patrick Sole", "title": "Construction of isodual codes from polycirculant matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Double polycirculant codes are introduced here as a generalization of double\ncirculant codes. When the matrix of the polyshift is a companion matrix of a\ntrinomial, we show that such a code is isodual, hence formally self-dual.\nNumerical examples show that the codes constructed have optimal or\nquasi-optimal parameters amongst formally self-dual codes. Self-duality, the\ntrivial case of isoduality, can only occur over $ \\F_2$ in the double circulant\ncase. Building on an explicit infinite sequence of irreducible trinomials over\n$\\F_2,$ we show that binary double polycirculant codes are asymptotically good.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 06:12:35 GMT"}, {"version": "v2", "created": "Thu, 15 Nov 2018 07:45:38 GMT"}, {"version": "v3", "created": "Sun, 29 Mar 2020 09:18:01 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Shi", "Minjia", ""], ["Xu", "Li", ""], ["Sole", "Patrick", ""]]}, {"id": "1811.03934", "submitter": "Jonathan Roux", "authors": "Jonathan Roux (LAAS-TSF), Eric Alata (LAAS-TSF, INSA Toulouse),\n  Guillaume Auriol (LAAS-TSF, INSA Toulouse), Mohamed Ka\\^aniche (LAAS-TSF),\n  Vincent Nicomette (LAAS-TSF, INSA Toulouse), Romain Cayre (LAAS-TSF)", "title": "RadIoT: Radio Communications Intrusion Detection for IoT - A Protocol\n  Independent Approach", "comments": null, "journal-ref": "International Symposium on Network Computing and Applications -\n  IEEE-NCA 2018, Nov 2018, Cambridge, Massachusetts, United States. 2018", "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet-of-Things (IoT) devices are nowadays massively integrated in daily\nlife: homes, factories, or public places. This technology offers attractive\nservices to improve the quality of life as well as new economic markets through\nthe exploitation of the collected data. However, these connected objects have\nalso become attractive targets for attackers because their current security\ndesign is often weak or flawed, as illustrated by several vulnerabilities such\nas Mirai, Blueborne, etc. This paper presents a novel approach for detecting\nintrusions in smart spaces such as smarthomes, or smartfactories, that is based\non the monitoring and profiling of radio communications at the physical layer\nusing machine learning techniques. The approach is designed to be independent\nof the large and heterogeneous set of wireless communication protocols\ntypically implemented by connected objects such as WiFi, Bluetooth, Zigbee,\nBluetooth-Low-Energy (BLE) or proprietary communication protocols. The main\nconcepts of the proposed approach are presented together with an experimental\ncase study illustrating its feasibility based on data collected during the\ndeployment of the intrusion detection approach in a smart home under real-life\nconditions.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 14:46:40 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Roux", "Jonathan", "", "LAAS-TSF"], ["Alata", "Eric", "", "LAAS-TSF, INSA Toulouse"], ["Auriol", "Guillaume", "", "LAAS-TSF, INSA Toulouse"], ["Ka\u00e2niche", "Mohamed", "", "LAAS-TSF"], ["Nicomette", "Vincent", "", "LAAS-TSF, INSA Toulouse"], ["Cayre", "Romain", "", "LAAS-TSF"]]}, {"id": "1811.03974", "submitter": "Simon Foley", "authors": "Simon N. Foley, Fabien Autrel, Edwin Bourget, Thomas Cledel, Stephane\n  Grunenwald, Jose Rubio Hernan, Alexandre Kabil, Raphael Larsen, Vivien M.\n  Rooney, and Kirsten Vanhulst", "title": "Science Hackathons for Cyberphysical System Security Research: Putting\n  CPS testbed platforms to good use", "comments": null, "journal-ref": "Proceedings of the 2018 ACM Workshop on Cyber-Physical Systems\n  Security and PrivaCy (CPS-SPC@CCS 2018)", "doi": "10.1145/3264888.3264897", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A challenge is to develop cyber-physical system scenarios that reflect the\ndiversity and complexity of real-life cyber-physical systems in the research\nquestions that they address. Time-bounded collaborative events, such as\nhackathons, jams and sprints, are increasingly used as a means of bringing\ngroups of individuals together, in order to explore challenges and develop\nsolutions. This paper describes our experiences, using a science hackathon to\nbring individual researchers together, in order to develop a common use-case\nimplemented on a shared CPS testbed platform that embodies the diversity in\ntheir own security research questions. A qualitative study of the event was\nconducted, in order to evaluate the success of the process, with a view to\nimproving future similar events.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 15:37:11 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Foley", "Simon N.", ""], ["Autrel", "Fabien", ""], ["Bourget", "Edwin", ""], ["Cledel", "Thomas", ""], ["Grunenwald", "Stephane", ""], ["Hernan", "Jose Rubio", ""], ["Kabil", "Alexandre", ""], ["Larsen", "Raphael", ""], ["Rooney", "Vivien M.", ""], ["Vanhulst", "Kirsten", ""]]}, {"id": "1811.04017", "submitter": "Th\\'eo Ryffel", "authors": "Theo Ryffel, Andrew Trask, Morten Dahl, Bobby Wagner, Jason Mancuso,\n  Daniel Rueckert and Jonathan Passerat-Palmbach", "title": "A generic framework for privacy preserving deep learning", "comments": "PPML 2018, 5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We detail a new framework for privacy preserving deep learning and discuss\nits assets. The framework puts a premium on ownership and secure processing of\ndata and introduces a valuable representation based on chains of commands and\ntensors. This abstraction allows one to implement complex privacy preserving\nconstructs such as Federated Learning, Secure Multiparty Computation, and\nDifferential Privacy while still exposing a familiar deep learning API to the\nend-user. We report early results on the Boston Housing and Pima Indian\nDiabetes datasets. While the privacy features apart from Differential Privacy\ndo not impact the prediction accuracy, the current implementation of the\nframework introduces a significant overhead in performance, which will be\naddressed at a later stage of the development. We believe this work is an\nimportant milestone introducing the first reliable, general framework for\nprivacy preserving deep learning.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 17:10:47 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 18:11:15 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Ryffel", "Theo", ""], ["Trask", "Andrew", ""], ["Dahl", "Morten", ""], ["Wagner", "Bobby", ""], ["Mancuso", "Jason", ""], ["Rueckert", "Daniel", ""], ["Passerat-Palmbach", "Jonathan", ""]]}, {"id": "1811.04035", "submitter": "Sukanta Das Dr.", "authors": "Kamalika Bhattacharjee, Krishnendu Maity, Sukanta Das", "title": "A Search for Good Pseudo-random Number Generators : Survey and Empirical\n  Studies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In today's world, several applications demand numbers which appear random but\nare generated by a background algorithm; that is, pseudo-random numbers. Since\nlate $19^{th}$ century, researchers have been working on pseudo-random number\ngenerators (PRNGs). Several PRNGs continue to develop, each one demanding to be\nbetter than the previous ones. In this scenario, this paper targets to verify\nthe claim of so-called good generators and rank the existing generators based\non strong empirical tests in same platforms. To do this, the genre of PRNGs\ndeveloped so far has been explored and classified into three groups -- linear\ncongruential generator based, linear feedback shift register based and cellular\nautomata based. From each group, well-known generators have been chosen for\nempirical testing. Two types of empirical testing has been done on each PRNG --\nblind statistical tests with Diehard battery of tests, TestU01 library and NIST\nstatistical test-suite and graphical tests (lattice test and space-time diagram\ntest). Finally, the selected $29$ PRNGs are divided into $24$ groups and are\nranked according to their overall performance in all empirical tests.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 07:32:23 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Bhattacharjee", "Kamalika", ""], ["Maity", "Krishnendu", ""], ["Das", "Sukanta", ""]]}, {"id": "1811.04078", "submitter": "Aniruddh Rao Kabbinale", "authors": "Aniruddh Rao Kabbinale, Emmanouil Dimogerontakis, Mennan Selimi,\n  Anwaar Ali, Leandro Navarro, Arjuna Sathiaseelan and Jon Crowcroft", "title": "Blockchain for Economically Sustainable Wireless Mesh Networks", "comments": "arXiv admin note: substantial text overlap with arXiv:1804.00561", "journal-ref": null, "doi": null, "report-no": "ARK54-1", "categories": "cs.NI cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralization, in the form of mesh networking and blockchain, two\npromising technologies, is coming to the telecommunications industry. Mesh\nnetworking allows wider low cost Internet access with infrastructures built\nfrom routers contributed by diverse owners, while blockchain enables\ntransparency and accountability for investments, revenue or other forms of\neconomic compensations from sharing of network traffic, content and services.\nCrowdsourcing network coverage, combined with crowdfunding costs, can create\neconomically sustainable yet decentralized Internet access. This means every\nparticipant can invest in resources, and pay or be paid for usage to recover\nthe costs of network devices and maintenance. While mesh networks and mesh\nrouting protocols enable self-organized networks that expand organically,\ncryptocurrencies and smart contracts enable the economic coordination among\nnetwork providers and consumers. We explore and evaluate two existing\nblockchain software stacks, Hyperledger Fabric (HLF) and Ethereum geth with\nProof of Authority (PoA) intended as a local lightweight distributed ledger,\ndeployed in a real city-wide production mesh network and also in laboratory\nnetwork. We quantify the performance, bottlenecks and identify the current\nlimitations and opportunities for improvement to serve locally the needs of\nwireless mesh networks, without the privacy and economic cost of relying on\npublic blockchains.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 15:59:26 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 10:18:36 GMT"}, {"version": "v3", "created": "Tue, 4 Dec 2018 16:31:57 GMT"}, {"version": "v4", "created": "Tue, 2 Apr 2019 08:27:07 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Kabbinale", "Aniruddh Rao", ""], ["Dimogerontakis", "Emmanouil", ""], ["Selimi", "Mennan", ""], ["Ali", "Anwaar", ""], ["Navarro", "Leandro", ""], ["Sathiaseelan", "Arjuna", ""], ["Crowcroft", "Jon", ""]]}, {"id": "1811.04195", "submitter": "Yifan Tian", "authors": "Yifan Tian, Yantian Hou, Jiawei Yuan", "title": "CPAR: Cloud-Assisted Privacy-preserving Image Annotation with Randomized\n  KD-Forest", "comments": "13 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the explosive growth in the number of pictures taken by smartphones,\norganizing and searching pictures has become important tasks. To efficiently\nfulfill these tasks, the key enabler is annotating images with proper keywords,\nwith which keyword-based searching and organizing become available for images.\nCurrently, smartphones usually synchronize photo albums with cloud storage\nplatforms, and have their images annotated with the help of cloud computing.\nHowever, the \"offloading-to-cloud\" solution may cause privacy breach, since\nphotos from smart photos contain various sensitive information. For privacy\nprotection, existing research made effort to support cloud-based image\nannotation on encrypted images by utilizing cryptographic primitives.\nNevertheless, for each annotation, it requires the cloud to perform linear\nchecking on the large-scale encrypted dataset with high computational cost.\nThis paper proposes a cloud-assisted privacy-preserving image annotation with\nrandomized kd-forest, namely CPAR. With CPAR, users are able to automatically\nassign keywords to their images by leveraging the power of cloud with privacy\nprotected. CPAR proposes a novel privacy-preserving randomized kd-forest\nstructure, which significantly improves the annotation performance compared\nwith existing research. Thorough analysis is carried out to demonstrate the\nsecurity of CPAR. Experimental evaluation on the well-known IAPR TC-12 dataset\nvalidates the efficiency and effectiveness of CPAR.\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2018 04:50:10 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 18:52:10 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Tian", "Yifan", ""], ["Hou", "Yantian", ""], ["Yuan", "Jiawei", ""]]}, {"id": "1811.04304", "submitter": "Reza Mirzazade Farkhani", "authors": "Reza Mirzazadeh, Mohammad Hossein Moattar, Majid Vafaei Jahan", "title": "Metamorphic Malware Detection Using Linear Discriminant Analysis and\n  Graph Similarity", "comments": "5th International Conference on Computer and Knowledge Engineering\n  (lCCKE)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most common malware detection approaches which are based on signature\nmatching and are not sufficient for metamorphic malware detection, since virus\nkits and metamorphic engines can produce variants with no resemblance to one\nanother. Metamorphism provides an efficient way for eluding malware detection\nsoftware kits. Code obfuscation methods like dead-code insertion are also\nwidely used in metamorphic malware. In order to address the problem of\ndetecting mutated generations, we propose a method based on Opcode Graph\nSimilarity (OGS). OGS tries to detect metamorphic malware using the similarity\nof opcode graphs. In this method, all nodes and edges have a respective effect\non classification, but in the proposed method, edges of graphs are pruned using\nLinear Discriminant Analysis (LDA). LDA is based on the concept of searching\nfor a linear combination of predictors that best separates two or more classes.\nMost distinctive edges are identified with LDA and the rest of edges are\nremoved. The metamorphic malware families considered here are NGVCK and\nmetamorphic worms that we denote these worms as MWOR. The results show that our\napproach is capable of classifying metamorphosed instances with no or minimum\nfalse alarms. Also, our proposed method can detect NGVCK and MWOR with high\naccuracy rate.\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2018 20:15:49 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Mirzazadeh", "Reza", ""], ["Moattar", "Mohammad Hossein", ""], ["Jahan", "Majid Vafaei", ""]]}, {"id": "1811.04349", "submitter": "Zijian Bao", "authors": "Zijian Bao, Bin Wang, Yongxin Zhang, Qinghao Wang, Wenbo Shi", "title": "Lockcoin: a secure and privacy-preserving mix service for bitcoin\n  anonymity", "comments": "10 pages, 4 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Lockcoin, a secure and privacy-preserving mix service for bitcoin\nanonymity. We introduce mix servers to provide mix service for user to prevent\nattackers linking the input address with output address by using blind\nsignature shceme, multisignature scheme. Lockcoin provides anonymity,\nscalability, bitcoin compatibillity, theft impossibility and accountability. We\nhave proposed a prototype of Lockcoin based on bitcoin test network,\nexperimental results show that our solution is efficient. Lockcoin's source\ncodes are released on github.com/Northeastern-University-Blockchain/Lockcoin.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 04:46:54 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Bao", "Zijian", ""], ["Wang", "Bin", ""], ["Zhang", "Yongxin", ""], ["Wang", "Qinghao", ""], ["Shi", "Wenbo", ""]]}, {"id": "1811.04366", "submitter": "Anrin Chakraborti", "authors": "Anrin Chakraborti and Radu Sion", "title": "ConcurORAM: High-Throughput Stateless Parallel Multi-Client ORAM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ConcurORAM is a parallel, multi-client oblivious RAM (ORAM) that eliminates\nwaiting for concurrent stateless clients and allows overall throughput to scale\ngracefully, without requiring trusted third party components (proxies) or\ndirect inter-client coordination. A key insight behind ConcurORAM is the fact\nthat, during multi-client data access, only a subset of the\nconcurrently-accessed server-hosted data structures require access privacy\nguarantees. Everything else can be safely implemented as oblivious data\nstructures that are later synced securely and efficiently during an ORAM\n\"eviction\". Further, since a major contributor to latency is the eviction - in\nwhich client-resident data is reshuffled and reinserted back encrypted into the\nmain server database - ConcurORAM also enables multiple concurrent clients to\nevict asynchronously, in parallel (without compromising consistency), and in\nthe background without having to block ongoing queries. As a result, throughput\nscales well with increasing number of concurrent clients and is not\nsignificantly impacted by evictions. For example, about 65 queries per second\ncan be executed in parallel by 30 concurrent clients, a 2x speedup over the\nstate-of-the-art. The query access time for individual clients increases by\nonly 2x when compared to a single-client deployment.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 07:38:57 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 21:11:23 GMT"}, {"version": "v3", "created": "Wed, 12 Dec 2018 02:28:50 GMT"}, {"version": "v4", "created": "Thu, 13 Dec 2018 07:23:50 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Chakraborti", "Anrin", ""], ["Sion", "Radu", ""]]}, {"id": "1811.04582", "submitter": "Nazim Uddin Sheikh", "authors": "Nazim Uddin Sheikh, Hasina Rahman, Shashwat Vikram, and Hamed\n  AlQahtani", "title": "A Lightweight Signature-Based IDS for IoT Environment", "comments": "4 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of large-scale heterogeneous networks comes the problem of\nunified network control resulting in security lapses that could have otherwise\navoided. A mechanism is needed to detect and deflect intruders to safeguard\nresource constraint edge devices and networks as well. In this paper we\ndemonstrate the use of an optimized pattern recognition algorithm to detect\nsuch attacks. Furthermore, we propose an Intrusion Detection System (IDS)\nmethodology and design architecture for Internet of Things that makes the use\nof this search algorithm to thwart various security breaches. Numerical results\nare presented from tests conducted with the aid of NSL KDD cup dataset showing\nthe efficacy the IDS\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 06:44:22 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Sheikh", "Nazim Uddin", ""], ["Rahman", "Hasina", ""], ["Vikram", "Shashwat", ""], ["AlQahtani", "Hamed", ""]]}, {"id": "1811.04583", "submitter": "Denis Kolegov", "authors": "Sergey Gordeychik, Denis Kolegov", "title": "SD-WAN Threat Landscape", "comments": "24 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software Defined Wide Area Network (SD-WAN or SDWAN) is a modern conception\nand an attractive trend in network technologies. SD-WAN is defined as a\nspecific application of software-defined networking (SDN) to WAN connections.\nThere is growing recognition that SDN and SD-WAN technologies not only expand\nfeatures, but also expose new vulnerabilities. Unfortunately, at the present\ntime, most vendors say that SD-WAN are perfectly safe, hardened, and fully\nprotected. The goal of this paper is to understand SD-WAN threats using\npractical approach. We describe basic SD-WAN features and components,\ninvestigate an attack surface, explore various vendor features and their\nsecurity, explain threats and vulnerabilities found in SD-WAN products. We also\nextend existing SDN threat models by describing new potential threats and\nattack vectors, provide examples, and consider high-level approaches for their\nmitigations. The provided results may be used by SD-WAN developers as a part of\nSecure Software Development Life Cycle (SSDLC), security researchers for\npenetration testing and vulnerability assessment, system integrators for secure\ndesign of SD-WAN solutions, and finally customers for secure deployment\noperations and configurations of SD-WAN enabled network. The main idea of this\nwork is that SD-WAN threat model involves all traditional network and SDN\nthreats, as well as new product-specific threats, appended by vendors which\nreinvent or introduce proprietary technologies immature from a security\nperspective.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 06:45:15 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Gordeychik", "Sergey", ""], ["Kolegov", "Denis", ""]]}, {"id": "1811.04720", "submitter": "Zhongliang Yang", "authors": "Zhongliang Yang, Shuyu Jin, Yongfeng Huang, Yujin Zhang and Hui Li", "title": "Automatically Generate Steganographic Text Based on Markov Model and\n  Huffman Coding", "comments": "Submitted to IETE Technical Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Steganography, as one of the three basic information security systems, has\nlong played an important role in safeguarding the privacy and confidentiality\nof data in cyberspace. The text is the most widely used information carrier in\npeople's daily life, using text as a carrier for information hiding has broad\nresearch prospects. However, due to the high coding degree and less information\nredundancy in the text, it has been an extremely challenging problem to hide\ninformation in it for a long time. In this paper, we propose a steganography\nmethod which can automatically generate steganographic text based on the Markov\nchain model and Huffman coding. It can automatically generate fluent text\ncarrier in terms of secret information which need to be embedded. The proposed\nmodel can learn from a large number of samples written by people and obtain a\ngood estimate of the statistical language model. We evaluated the proposed\nmodel from several perspectives. Experimental results show that the performance\nof the proposed model is superior to all the previous related methods in terms\nof information imperceptibility and information hidden capacity.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 13:40:17 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Yang", "Zhongliang", ""], ["Jin", "Shuyu", ""], ["Huang", "Yongfeng", ""], ["Zhang", "Yujin", ""], ["Li", "Hui", ""]]}, {"id": "1811.04794", "submitter": "Alan Sherman", "authors": "Alan Sherman, Enis Golaszewski, Edward LaFemina, Ethan Goldschen,\n  Mohammed Khan, Lauren Mundy, Mykah Rather, Bryan Solis, Wubnyonga Tete, Edwin\n  Valdez, Brian Weber, Damian Doyle, Casey O'Brien, Linda Oliva, Joseph Roundy,\n  Jack Suess", "title": "The SFS Summer Research Study at UMBC: Project-Based Learning Inspires\n  Cybersecurity Students", "comments": "Full-length report with 18 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  May 30-June 2, 2017, Scholarship for Service (SFS) scholars at the University\nof Maryland, Baltimore County (UMBC) analyzed the security of a targeted aspect\nof the UMBC computer systems. During this hands-on study, with complete access\nto source code, students identified vulnerabilities, devised and implemented\nexploits, and suggested mitigations. As part of a pioneering program at UMBC to\nextend SFS scholarships to community colleges, the study helped initiate six\nstudents from two nearby community colleges, who transferred to UMBC in fall\n2017 to complete their four-year degrees in computer science and information\nsystems.\n  The study examined the security of a set of \"NetAdmin\" custom scripts that\nenable UMBC faculty and staff to open the UMBC firewall to allow external\naccess to machines they control for research purposes. Students discovered\nvulnerabilities stemming from weak architectural design, record overflow, and\nfailure to sanitize inputs properly. For example, they implemented a\nrecord-overflow and code-injection exploit that exfiltrated the vital API key\nof the UMBC firewall.\n  This report summarizes student activities and findings, and reflects on\nlessons learned for students, educators, and system administrators. Our\nstudents found the collaborative experience inspirational, students and\neducators appreciated the authentic case study, and IT administrators gained\naccess to future employees and received free recommendations for improving the\nsecurity of their systems. We hope that other universities can benefit from our\nmotivational and educational strategy of teaming educators and system\nadministrators to engage students in active project-based learning centering on\nfocused questions about their university computer systems.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 15:34:09 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Sherman", "Alan", ""], ["Golaszewski", "Enis", ""], ["LaFemina", "Edward", ""], ["Goldschen", "Ethan", ""], ["Khan", "Mohammed", ""], ["Mundy", "Lauren", ""], ["Rather", "Mykah", ""], ["Solis", "Bryan", ""], ["Tete", "Wubnyonga", ""], ["Valdez", "Edwin", ""], ["Weber", "Brian", ""], ["Doyle", "Damian", ""], ["O'Brien", "Casey", ""], ["Oliva", "Linda", ""], ["Roundy", "Joseph", ""], ["Suess", "Jack", ""]]}, {"id": "1811.04900", "submitter": "Lei Xu", "authors": "Lei Xu and Lin Chen and Zhimin Gao and Shouhuai Xu and Weidong Shi", "title": "Efficient Public Blockchain Client for Lightweight Users", "comments": "A preliminary version of this paper was published in SERIAL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public blockchains provide a decentralized method for storing transaction\ndata and have many applications in different sectors. In order for users to\ntrack transactions, a simple method is to let them keep a local copy of the\nentire public ledger. Since the size of the ledger keeps growing, this method\nbecomes increasingly less practical, especially for lightweight users such as\nIoT devices and smartphones. In order to cope with the problem, several\nsolutions have been proposed to reduce the storage burden. However, existing\nsolutions either achieve a limited storage reduction (e.g., simple payment\nverification), or rely on some strong security assumption (e.g., the use of\ntrusted server). In this paper, we propose a new approach to solving the\nproblem. Specifically, we propose an \\underline{e}fficient verification\nprotocol for \\underline{p}ublic \\underline{b}lock\\underline{c}hains, or EPBC\nfor short. EPBC is particularly suitable for lightweight users, who only need\nto store a small amount of data that is {\\it independent of} the size of the\nblockchain. We analyze EPBC's performance and security, and discuss its\nintegration with existing public ledger systems. Experimental results confirm\nthat EPBC is practical for lightweight users.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 18:40:03 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Xu", "Lei", ""], ["Chen", "Lin", ""], ["Gao", "Zhimin", ""], ["Xu", "Shouhuai", ""], ["Shi", "Weidong", ""]]}, {"id": "1811.05187", "submitter": "Lei Ma", "authors": "Qianyu Guo, Xiaofei Xie, Lei Ma, Qiang Hu, Ruitao Feng, Li Li, Yang\n  Liu, Jianjun Zhao, Xiaohong Li", "title": "An Orchestrated Empirical Study on Deep Learning Frameworks and\n  Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) has recently achieved tremendous success in a variety of\ncutting-edge applications, e.g., image recognition, speech and natural language\nprocessing, and autonomous driving. Besides the available big data and hardware\nevolution, DL frameworks and platforms play a key role to catalyze the\nresearch, development, and deployment of DL intelligent solutions. However, the\ndifference in computation paradigm, architecture design and implementation of\nexisting DL frameworks and platforms brings challenges for DL software\ndevelopment, deployment, maintenance, and migration. Up to the present, it\nstill lacks a comprehensive study on how current diverse DL frameworks and\nplatforms influence the DL software development process.\n  In this paper, we initiate the first step towards the investigation on how\nexisting state-of-the-art DL frameworks (i.e., TensorFlow, Theano, and Torch)\nand platforms (i.e., server/desktop, web, and mobile) support the DL software\ndevelopment activities. We perform an in-depth and comparative evaluation on\nmetrics such as learning accuracy, DL model size, robustness, and performance,\non state-of-the-art DL frameworks across platforms using two popular datasets\nMNIST and CIFAR-10. Our study reveals that existing DL frameworks still suffer\nfrom compatibility issues, which becomes even more severe when it comes to\ndifferent platforms. We pinpoint the current challenges and opportunities\ntowards developing high quality and compatible DL systems. To ignite further\ninvestigation along this direction to address urgent industrial demands of\nintelligent solutions, we make all of our assembled feasible toolchain and\ndataset publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 09:51:57 GMT"}], "update_date": "2018-11-18", "authors_parsed": [["Guo", "Qianyu", ""], ["Xie", "Xiaofei", ""], ["Ma", "Lei", ""], ["Hu", "Qiang", ""], ["Feng", "Ruitao", ""], ["Li", "Li", ""], ["Liu", "Yang", ""], ["Zhao", "Jianjun", ""], ["Li", "Xiaohong", ""]]}, {"id": "1811.05217", "submitter": "Ryutaroh Matsumoto", "authors": "Ryutaroh Matsumoto", "title": "Classical Access Structures of Ramp Secret Sharing Based on Quantum\n  Stabilizer Codes", "comments": "Publisher's Open Access PDF with copyright held by the author", "journal-ref": "Quantum Information Processing, vol.19, no.1, article ID 9,\n  January 2020", "doi": "10.1007/s11128-019-2503-3", "report-no": null, "categories": "quant-ph cs.CR cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we consider to use the quantum stabilizer codes as secret\nsharing schemes for classical secrets. We give necessary and sufficient\nconditions for qualified and forbidden sets in terms of quantum stabilizers.\nThen we give a Gilbert-Varshamove-type sufficient condition for existence of\nsecret sharing schemes with given parameters, and by using that sufficient\ncondition, we show that roughly 19% of participants can be made forbidden\nindependently of the size of classical secret, in particular when an $n$-bit\nclassical secret is shared among $n$ participants having 1-qubit share each. We\nalso consider how much information is obtained by an intermediate set and\nexpress that amount of information in terms of quantum stabilizers. All the\nresults are stated in terms of linear spaces over finite fields associated with\nthe quantum stabilizers.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 11:16:17 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 01:31:25 GMT"}, {"version": "v3", "created": "Wed, 21 Nov 2018 08:40:47 GMT"}, {"version": "v4", "created": "Wed, 3 Apr 2019 14:32:45 GMT"}, {"version": "v5", "created": "Sat, 13 Apr 2019 15:01:12 GMT"}, {"version": "v6", "created": "Wed, 24 Apr 2019 13:31:46 GMT"}, {"version": "v7", "created": "Wed, 27 Nov 2019 01:54:24 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Matsumoto", "Ryutaroh", ""]]}, {"id": "1811.05284", "submitter": "Ernst-Georg Schmid", "authors": "Ernst-Georg Schmid", "title": "Right to Sign: Safeguarding data immutability in blockchain systems with\n  cryptographic signatures over a broad range of available consensus finding\n  scenarios", "comments": "5 pages, 8 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of the consensus method ultimately determines throughput,\nscalability, tamper resistance, and consistency of a blockchain system.\nHowever, across all the types of blockchain (private, semi-private, consortium,\nor public), there is no consensus method that uniformly addresses all these\ntraits. Verifiable lottery algorithms (Proof of ...) increase tamper resistance\nbut show weakness in throughput and scalability, while established methods like\nPAXOS and RAFT provide no additional protection against tampering. In this\npaper, we introduce Right to Sign which aims to provide additional tamper\nresistance by cryptographic signatures over a broad range of available\nconsensus finding methods.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 13:35:19 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Schmid", "Ernst-Georg", ""]]}, {"id": "1811.05296", "submitter": "Luca Massarelli", "authors": "Luca Massarelli, Giuseppe Antonio Di Luna, Fabio Petroni, Leonardo\n  Querzoni and Roberto Baldoni", "title": "SAFE: Self-Attentive Function Embeddings for Binary Similarity", "comments": "Published in International Conference on Detection of Intrusions and\n  Malware, and Vulnerability Assessment (DIMVA) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The binary similarity problem consists in determining if two functions are\nsimilar by only considering their compiled form. Advanced techniques for binary\nsimilarity recently gained momentum as they can be applied in several fields,\nsuch as copyright disputes, malware analysis, vulnerability detection, etc.,\nand thus have an immediate practical impact. Current solutions compare\nfunctions by first transforming their binary code in multi-dimensional vector\nrepresentations (embeddings), and then comparing vectors through simple and\nefficient geometric operations. However, embeddings are usually derived from\nbinary code using manual feature extraction, that may fail in considering\nimportant function characteristics, or may consider features that are not\nimportant for the binary similarity problem. In this paper we propose SAFE, a\nnovel architecture for the embedding of functions based on a self-attentive\nneural network. SAFE works directly on disassembled binary functions, does not\nrequire manual feature extraction, is computationally more efficient than\nexisting solutions (i.e., it does not incur in the computational overhead of\nbuilding or manipulating control flow graphs), and is more general as it works\non stripped binaries and on multiple architectures. We report the results from\na quantitative and qualitative analysis that show how SAFE provides a\nnoticeable performance improvement with respect to previous solutions.\nFurthermore, we show how clusters of our embedding vectors are closely related\nto the semantic of the implemented algorithms, paving the way for further\ninteresting applications (e.g. semantic-based binary function search).\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 14:01:16 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 20:59:31 GMT"}, {"version": "v3", "created": "Wed, 30 Jan 2019 17:26:46 GMT"}, {"version": "v4", "created": "Thu, 19 Dec 2019 10:06:09 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Massarelli", "Luca", ""], ["Di Luna", "Giuseppe Antonio", ""], ["Petroni", "Fabio", ""], ["Querzoni", "Leonardo", ""], ["Baldoni", "Roberto", ""]]}, {"id": "1811.05372", "submitter": "Abhishek Divekar", "authors": "Abhishek Divekar (1 and 5), Meet Parekh (2 and 5), Vaibhav Savla (3\n  and 5), Rudra Mishra (4 and 5), Mahesh Shirole (5) ((1) Amazon, (2) New York\n  University, (3) Infosys, (4) Samsung, (5) Veermata Jijabai Technological\n  Institute)", "title": "Benchmarking datasets for Anomaly-based Network Intrusion Detection: KDD\n  CUP 99 alternatives", "comments": "Paper accepted into Proceedings of IEEE International Conference on\n  Computing, Communication and Security 2018 (ICCCS-2018) Statistics: 8 pages,\n  7 tables, 3 figures, 34 references", "journal-ref": "2018 3rd IEEE International Conference on Computing, Communication\n  and Security (ICCCS)", "doi": "10.1109/CCCS.2018.8586840", "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning has been steadily gaining traction for its use in\nAnomaly-based Network Intrusion Detection Systems (A-NIDS). Research into this\ndomain is frequently performed using the KDD~CUP~99 dataset as a benchmark.\nSeveral studies question its usability while constructing a contemporary NIDS,\ndue to the skewed response distribution, non-stationarity, and failure to\nincorporate modern attacks. In this paper, we compare the performance for\nKDD-99 alternatives when trained using classification models commonly found in\nliterature: Neural Network, Support Vector Machine, Decision Tree, Random\nForest, Naive Bayes and K-Means. Applying the SMOTE oversampling technique and\nrandom undersampling, we create a balanced version of NSL-KDD and prove that\nskewed target classes in KDD-99 and NSL-KDD hamper the efficacy of classifiers\non minority classes (U2R and R2L), leading to possible security risks. We\nexplore UNSW-NB15, a modern substitute to KDD-99 with greater uniformity of\npattern distribution. We benchmark this dataset before and after SMOTE\noversampling to observe the effect on minority performance. Our results\nindicate that classifiers trained on UNSW-NB15 match or better the Weighted\nF1-Score of those trained on NSL-KDD and KDD-99 in the binary case, thus\nadvocating UNSW-NB15 as a modern substitute to these datasets.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 15:49:54 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Divekar", "Abhishek", "", "1 and 5"], ["Parekh", "Meet", "", "2 and 5"], ["Savla", "Vaibhav", "", "3\n  and 5"], ["Mishra", "Rudra", "", "4 and 5"], ["Shirole", "Mahesh", ""]]}, {"id": "1811.05378", "submitter": "Jinwen Wang", "authors": "Jinwen Wang, Yueqiang Cheng, Qi Li, Yong Jiang", "title": "Interface-Based Side Channel Attack Against Intel SGX", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intel has introduced a trusted computing technology, Intel Software Guard\nExtension (SGX), which provides an isolated and secure execution environment\ncalled enclave for a user program without trusting any privilege software\n(e.g., an operating system or a hypervisor) or firmware. Nevertheless, SGX is\nvulnerable to several side channel attacks (e.g. page-fault-based attack and\ncache-based attack). In this paper, we explore a new, yet critical side channel\nattack in SGX, interface-based side channel attack, which can infer the\ninformation of the enclave input data. The root cause of the interface-based\nside channel attack is the input dependent interface invocation information\n(e.g., interface information and invocation patterns) which can be observed by\nthe untrusted privilege software can reveal the control flow in the enclave. We\nstudy the methodology which can be used to conduct the interface-based side\nchannel attack. To illustrate the effectiveness of the interface-based\nside-channel attacks, we use our methodology to infer whether tracked web pages\nhave been processed by the SGX-assisted NFV platforms and achieve the accuracy\nof 87.6% and recall of 76.6%. We also identify the packets which belong to the\ntracked web pages, with the accuracy of 67.9%and recall of 71.1%. We finally\npropose some countermeasures to defense the interface-based side channel attack\nin SGX-assisted applications.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 01:37:39 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Wang", "Jinwen", ""], ["Cheng", "Yueqiang", ""], ["Li", "Qi", ""], ["Jiang", "Yong", ""]]}, {"id": "1811.05385", "submitter": "Qipeng Liu", "authors": "Qipeng Liu and Mark Zhandry", "title": "On Finding Quantum Multi-collisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A $k$-collision for a compressing hash function $H$ is a set of $k$ distinct\ninputs that all map to the same output. In this work, we show that for any\nconstant $k$, $\\Theta\\left(N^{\\frac{1}{2}(1-\\frac{1}{2^k-1})}\\right)$ quantum\nqueries are both necessary and sufficient to achieve a $k$-collision with\nconstant probability. This improves on both the best prior upper bound\n(Hosoyamada et al., ASIACRYPT 2017) and provides the first non-trivial lower\nbound, completely resolving the problem.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 16:22:52 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 01:11:58 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Liu", "Qipeng", ""], ["Zhandry", "Mark", ""]]}, {"id": "1811.05441", "submitter": "Claudio Canella", "authors": "Claudio Canella and Jo Van Bulck and Michael Schwarz and Moritz Lipp\n  and Benjamin von Berg and Philipp Ortner and Frank Piessens and Dmitry\n  Evtyushkin and Daniel Gruss", "title": "A Systematic Evaluation of Transient Execution Attacks and Defenses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on transient execution attacks including Spectre and Meltdown showed\nthat exception or branch misprediction events might leave secret-dependent\ntraces in the CPU's microarchitectural state. This observation led to a\nproliferation of new Spectre and Meltdown attack variants and even more ad-hoc\ndefenses (e.g., microcode and software patches). Both the industry and academia\nare now focusing on finding effective defenses for known issues. However, we\nonly have limited insight on residual attack surface and the completeness of\nthe proposed defenses.\n  In this paper, we present a systematization of transient execution attacks.\nOur systematization uncovers 6 (new) transient execution attacks that have been\noverlooked and not been investigated so far: 2 new exploitable Meltdown\neffects: Meltdown-PK (Protection Key Bypass) on Intel, and Meltdown-BND (Bounds\nCheck Bypass) on Intel and AMD; and 4 new Spectre mistraining strategies. We\nevaluate the attacks in our classification tree through proof-of-concept\nimplementations on 3 major CPU vendors (Intel, AMD, ARM). Our systematization\nyields a more complete picture of the attack surface and allows for a more\nsystematic evaluation of defenses. Through this systematic evaluation, we\ndiscover that most defenses, including deployed ones, cannot fully mitigate all\nattack variants.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 18:17:50 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 08:28:25 GMT"}, {"version": "v3", "created": "Wed, 15 May 2019 05:36:39 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Canella", "Claudio", ""], ["Van Bulck", "Jo", ""], ["Schwarz", "Michael", ""], ["Lipp", "Moritz", ""], ["von Berg", "Benjamin", ""], ["Ortner", "Philipp", ""], ["Piessens", "Frank", ""], ["Evtyushkin", "Dmitry", ""], ["Gruss", "Daniel", ""]]}, {"id": "1811.05465", "submitter": "Pascal Cotret", "authors": "Muhammad Abdul Wahab, Pascal Cotret, Mounir Nasr Allah, Guillaume\n  Hiet, Vianney Lapotre, Guy Gogniat", "title": "Towards a hardware-assisted information flow tracking ecosystem for ARM\n  processors", "comments": "2 pages, FPL 2016 - PhD forum", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work details a hardware-assisted approach for information flow tracking\nimplemented on reconfigurable chips. Current solutions are either\ntime-consuming or hardly portable (modifications of both sofware/hardware\nlayers). This work takes benefits from debug components included in ARMv7\nprocessors to retrieve details on instructions committed by the CPU. First\nresults in terms of silicon area and time overheads are also given.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 21:45:24 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Wahab", "Muhammad Abdul", ""], ["Cotret", "Pascal", ""], ["Allah", "Mounir Nasr", ""], ["Hiet", "Guillaume", ""], ["Lapotre", "Vianney", ""], ["Gogniat", "Guy", ""]]}, {"id": "1811.05905", "submitter": "Mohamed Baza", "authors": "Mohamed Baza, Mahmoud Nabil, Noureddine Lasla, Kemal Fidan, Mohamed\n  Mahmoud, Mohamed Abdallah", "title": "Blockchain-based Firmware Update Scheme Tailored for Autonomous Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, Autonomous Vehicles (AVs) have gained extensive attention from both\nacademia and industry. AVs are a complex system composed of many subsystems,\nmaking them a typical target for attackers. Therefore, the firmware of the\ndifferent subsystems needs to be updated to the latest version by the\nmanufacturer to fix bugs and introduce new features, e.g., using security\npatches. In this paper, we propose a distributed firmware update scheme for the\nAVs' subsystems, leveraging blockchain and smart contract technology. A\nconsortium blockchain made of different AVs manufacturers is used to ensure the\nauthenticity and integrity of firmware updates. Instead of depending on\ncentralized third parties to distribute the new updates, we enable AVs, namely\ndistributors, to participate in the distribution process and we take advantage\nof their mobility to guarantee high availability and fast delivery of the\nupdates. To incentivize AVs to distribute the updates, a reward system is\nestablished that maintains a credit reputation for each distributor account in\nthe blockchain. A zero-knowledge proof protocol is used to exchange the update\nin return for a proof of distribution in a trust-less environment. Moreover, we\nuse attribute-based encryption (ABE) scheme to ensure that only authorized AVs\nwill be able to download and use a new update. Our analysis indicates that the\nadditional cryptography primitives and exchanged transactions do not affect the\noperation of the AVs network. Also, our security analysis demonstrates that our\nscheme is efficient and secure against different attacks.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 16:58:25 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Baza", "Mohamed", ""], ["Nabil", "Mahmoud", ""], ["Lasla", "Noureddine", ""], ["Fidan", "Kemal", ""], ["Mahmoud", "Mohamed", ""], ["Abdallah", "Mohamed", ""]]}, {"id": "1811.05936", "submitter": "Riccardo Aragona", "authors": "Riccardo Aragona and Roberto Civino and Norberto Gavioli and Carlo\n  Maria Scoppola", "title": "Regular subgroups with large intersection", "comments": null, "journal-ref": "Annali di Matematica Pura ed Applicata (1923 -), Vol. 198 No. 6,\n  2019", "doi": "10.1007/s10231-019-00853-w", "report-no": null, "categories": "math.GR cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the relationships between the elementary abelian\nregular subgroups and the Sylow $2$-subgroups of their normalisers in the\nsymmetric group $\\mathrm{Sym}(\\mathbb{F}_2^n)$, in view of the interest that\nthey have recently raised for their applications in symmetric cryptography.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 18:07:13 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 08:52:00 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Aragona", "Riccardo", ""], ["Civino", "Roberto", ""], ["Gavioli", "Norberto", ""], ["Scoppola", "Carlo Maria", ""]]}, {"id": "1811.05945", "submitter": "Lynsay Shepherd", "authors": "Adam Rapley, Xavier Bellekens, Lynsay A. Shepherd, Colin McLean", "title": "Mayall: A Framework for Desktop JavaScript Auditing and\n  Post-Exploitation Analysis", "comments": "19 pages", "journal-ref": null, "doi": "10.3390/informatics5040046", "report-no": null, "categories": "cs.CR cs.SE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Writing desktop applications in JavaScript offers developers the opportunity\nto write cross-platform applications with cutting edge capabilities. However in\ndoing so, they are potentially submitting their code to a number of\nunsanctioned modifications from malicious actors. Electron is one such\nJavaScript application framework which facilitates this multi-platform\nout-the-box paradigm and is based upon the Node.js JavaScript runtime --- an\nincreasingly popular server-side technology. In bringing this technology to the\nclient-side environment, previously unrealized risks are exposed to users due\nto the powerful system programming interface that Node.js exposes. In a\nconcerted effort to highlight previously unexposed risks in these rapidly\nexpanding frameworks, this paper presents the Mayall Framework, an extensible\ntoolkit aimed at JavaScript security auditing and post-exploitation analysis.\nThe paper also exposes fifteen highly popular Electron applications and\ndemonstrates that two thirds of applications were found to be using known\nvulnerable elements with high CVSS scores. Moreover, this paper discloses a\nwide-reaching and overlooked vulnerability within the Electron Framework which\nis a direct byproduct of shipping the runtime unaltered with each application,\nallowing malicious actors to modify source code and inject covert malware\ninside verified and signed applications without restriction. Finally, a number\nof injection vectors are explored and appropriate remediations are proposed.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 18:27:06 GMT"}, {"version": "v2", "created": "Thu, 15 Nov 2018 14:25:54 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Rapley", "Adam", ""], ["Bellekens", "Xavier", ""], ["Shepherd", "Lynsay A.", ""], ["McLean", "Colin", ""]]}, {"id": "1811.06012", "submitter": "Johann Knechtel", "authors": "Nikhil Rangarajan, Satwik Patnaik, Johann Knechtel, Ramesh Karri,\n  Ozgur Sinanoglu, and Shaloo Rakheja", "title": "Opening the Doors to Dynamic Camouflaging: Harnessing the Power of\n  Polymorphic Devices", "comments": "Published TETC version; original arxiv preprint found in v1", "journal-ref": null, "doi": "10.1109/TETC.2020.2991134", "report-no": null, "categories": "cs.CR cond-mat.mes-hall cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The era of widespread globalization has led to the emergence of\nhardware-centric security threats throughout the IC supply chain. Prior\ndefenses like logic locking, layout camouflaging, and split manufacturing have\nbeen researched extensively to protect against intellectual property (IP)\npiracy at different stages. In this work, we present dynamic camouflaging as a\nnew technique to thwart IP reverse engineering at all stages in the supply\nchain, viz., the foundry, the test facility, and the end-user. Toward this end,\nwe exploit the multi-functionality, post-fabrication reconfigurability, and\nrun-time polymorphism of spin-based devices, specifically the magneto-electric\nspin-orbit (MESO) device. Leveraging these unique properties, dynamic\ncamouflaging is shown to be resilient against state-of-the-art analytical\nSAT-based attacks and test-data mining attacks. Such dynamic reconfigurability\nis not afforded in CMOS owing to fundamental differences in operation. For such\nMESO-based camouflaging, we also anticipate massive savings in power,\nperformance, and area over other spin-based camouflaging schemes, due to the\nenergy-efficient electric-field driven reversal of the MESO device. Based on\nthorough experimentation, we outline the promises of dynamic camouflaging in\nsecuring the supply chain end-to-end along with a case study, demonstrating the\nefficacy of dynamic camouflaging in securing error-tolerant image processing\nIP.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 19:11:31 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 09:14:57 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Rangarajan", "Nikhil", ""], ["Patnaik", "Satwik", ""], ["Knechtel", "Johann", ""], ["Karri", "Ramesh", ""], ["Sinanoglu", "Ozgur", ""], ["Rakheja", "Shaloo", ""]]}, {"id": "1811.06078", "submitter": "Alejandra Diaz", "authors": "Alejandra Diaz, Alan T. Sherman, and Anupam Joshi", "title": "Phishing in an Academic Community: A Study of User Susceptibility and\n  Behavior", "comments": "7 pages, 5 figures, 3 tables, submitted to Cryptologia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an observational study on the relationship between demographic\nfactors and phishing susceptibility at the University of Maryland, Baltimore\nCounty (UMBC). In spring 2018, we delivered phishing attacks to 450\nrandomly-selected students on three different days (1,350 students total) to\nexamine user click rates and demographics among UMBC's undergraduates.\nParticipants were initially unaware of the study. Experiment 1 claimed to bill\nstudents; Experiment 2 enticed users with monetary rewards; and Experiment 3\nthreatened users with account cancellation. We found correlations resulting in\nlowered susceptibility based on college affiliation, academic year progression,\ncyber training, involvement in cyber clubs or cyber scholarship programs, time\nspent on the computer, and age demographics. We found no significant\ncorrelation between gender and susceptibility. Contrary to our expectations, we\nobserved greater user susceptibility with greater phishing knowledge and\nawareness. Students who identified themselves as understanding the definition\nof phishing had a higher susceptibility than did their peers who were merely\naware of phishing attacks, with both groups having a higher susceptibility than\nthose with no knowledge of phishing. Approximately 59% of subjects who opened\nthe phishing email clicked on its phishing link, and approximately 70% of those\nsubjects who additionally answered a demographic survey clicked.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 21:40:52 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Diaz", "Alejandra", ""], ["Sherman", "Alan T.", ""], ["Joshi", "Anupam", ""]]}, {"id": "1811.06143", "submitter": "Sabah Suhail", "authors": "Sabah Suhail, Mohammad Abdellatif, Shashi Raj Pandey, Abid Khan, and\n  Choong Seon Hong", "title": "Provenance-enabled Packet Path Tracing in the RPL-based Internet of\n  Things", "comments": "14 pages, 18 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interconnection of resource-constrained and globally accessible things\nwith untrusted and unreliable Internet make them vulnerable to attacks\nincluding data forging, false data injection, and packet drop that affects\napplications with critical decision-making processes. For data trustworthiness,\nreliance on provenance is considered to be an effective mechanism that tracks\nboth data acquisition and data transmission. However, provenance management for\nsensor networks introduces several challenges, such as low energy, bandwidth\nconsumption, and efficient storage. This paper attempts to identify packet drop\n(either maliciously or due to network disruptions) and detect faulty or\nmisbehaving nodes in the Routing Protocol for Low-Power and Lossy Networks\n(RPL) by following a bi-fold provenance-enabled packed path tracing (PPPT)\napproach. Firstly, a system-level ordered-provenance information encapsulates\nthe data generating nodes and the forwarding nodes in the data packet.\nSecondly, to closely monitor the dropped packets, a node-level provenance in\nthe form of the packet sequence number is enclosed as a routing entry in the\nrouting table of each participating node. Lossless in nature, both approaches\nconserve the provenance size satisfying processing and storage requirements of\nIoT devices. Finally, we evaluate the efficacy of the proposed scheme with\nrespect to provenance size, provenance generation time, and energy consumption.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 02:23:19 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 07:29:45 GMT"}, {"version": "v3", "created": "Mon, 10 Dec 2018 09:30:57 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Suhail", "Sabah", ""], ["Abdellatif", "Mohammad", ""], ["Pandey", "Shashi Raj", ""], ["Khan", "Abid", ""], ["Hong", "Choong Seon", ""]]}, {"id": "1811.06162", "submitter": "Michael Pritchard Jr", "authors": "Yevgeniy Vorobeychik and Michael Pritchard", "title": "Plan Interdiction Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for cyber risk assessment and mitigation which models\nattackers as formal planners and defenders as interdicting such plans. We\nillustrate the value of plan interdiction problems by first modeling network\ncyber risk through the use of formal planning, and subsequently formalizing an\nimportant question of prioritizing vulnerabilities for patching in the plan\ninterdiction framework. In particular, we show that selectively patching\nrelatively few vulnerabilities allows a network administrator to significantly\nreduce exposure to cyber risk. More broadly, we have developed a number of\nscalable approaches for plan interdiction problems, making especially\nsignificant advances when attack plans involve uncertainty about system\ndynamics. However, important open problems remain, including how to effectively\ncapture information asymmetry between the attacker and defender, how to best\nmodel dynamics in the attacker-defender interaction, and how to develop\nscalable algorithms for solving associated plan interdiction games.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 04:15:34 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Vorobeychik", "Yevgeniy", ""], ["Pritchard", "Michael", ""]]}, {"id": "1811.06246", "submitter": "Amandeep Bhatia", "authors": "Amandeep Singh Bhatia and Ajay Kumar", "title": "McEliece Cryptosystem Based On Extended Golay Code", "comments": "7", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With increasing advancements in technology, it is expected that the emergence\nof a quantum computer will potentially break many of the public-key\ncryptosystems currently in use. It will negotiate the confidentiality and\nintegrity of communications. In this regard, we have privacy protectors (i.e.\nPost-Quantum Cryptography), which resists attacks by quantum computers, deals\nwith cryptosystems that run on conventional computers and are secure against\nattacks by quantum computers. The practice of code-based cryptography is a\ntrade-off between security and efficiency. In this chapter, we have explored\nThe most successful McEliece cryptosystem, based on extended Golay code [24,\n12, 8]. We have examined the implications of using an extended Golay code in\nplace of usual Goppa code in McEliece cryptosystem. Further, we have\nimplemented a McEliece cryptosystem based on extended Golay code using MATLAB.\nThe extended Golay code has lots of practical applications. The main advantage\nof using extended Golay code is that it has codeword of length 24, a minimum\nHamming distance of 8 allows us to detect 7-bit errors while correcting for 3\nor fewer errors simultaneously and can be transmitted at high data rate.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 09:22:23 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Bhatia", "Amandeep Singh", ""], ["Kumar", "Ajay", ""]]}, {"id": "1811.06343", "submitter": "Peeter Laud", "authors": "Peeter Laud, Alisa Pankova and Martin Pettai", "title": "Achieving Differential Privacy using Methods from Calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce derivative sensitivity, an analogue to local sensitivity for\ncontinuous functions. We use this notion in an analysis that determines the\namount of noise to be added to the result of a database query in order to\nobtain a certain level of differential privacy, and demonstrate that derivative\nsensitivity allows us to employ powerful mechanisms from calculus to perform\nthe analysis for a variety of queries. We have implemented the analyzer and\nevaluated its efficiency and precision.\n  We also show the flexibility of derivative sensitivity in specifying the\nquantitative privacy notion of the database, as desired by the data owner.\nInstead of only using the `number of changed rows' metric, our metrics can\ndepend on the locations and amounts of changes in a much more nuanced manner.\nThis will help to make sure that the distance is not larger than the data owner\ndesires (which would undermine privacy), thereby encouraging the adoption of\ndifferentially private data analysis mechanisms.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 13:57:51 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Laud", "Peeter", ""], ["Pankova", "Alisa", ""], ["Pettai", "Martin", ""]]}, {"id": "1811.06386", "submitter": "Vladimir Shpilrain", "authors": "Dima Grigoriev and Vladimir Shpilrain", "title": "Tropical cryptography II: extensions by homomorphisms", "comments": "7 pages. arXiv admin note: text overlap with arXiv:1301.1195", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use extensions of tropical algebras as platforms for very efficient public\nkey exchange protocols.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 16:31:58 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Grigoriev", "Dima", ""], ["Shpilrain", "Vladimir", ""]]}, {"id": "1811.06414", "submitter": "Kim Kaivanto", "authors": "Iain Embrey and Kim Kaivanto", "title": "Many Phish in the $\\mathcal{C}$: A Coexisting-Choice-Criteria Model of\n  Security Behavior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Normative decision theory proves inadequate for modeling human responses to\nthe social-engineering campaigns of Advanced Persistent Threat (APT) attacks.\nBehavioral decision theory fares better, but still falls short of capturing\nsocial-engineering attack vectors, which operate through emotions and\nperipheral-route persuasion. We introduce a generalized decision theory, under\nwhich any decision will be made according to one of multiple coexisting choice\ncriteria. We denote the set of possible choice criteria by $\\mathcal{C}$. Thus\nthe proposed model reduces to conventional Expected Utility theory when\n$|\\,\\mathcal{C}_{\\text{EU}}|=1$, whilst Dual-Process (thinking fast vs.\nthinking slow) decision making corresponds to a model with\n$|\\,\\mathcal{C}_{\\text{DP}}|=2$. We consider a more general case with\n$|\\,\\mathcal{C}|\\geq 2$, which necessitates careful consideration of _how_, for\na particular choice-task instance, one criterion comes to prevail over others.\nWe operationalize this with a probability distribution that is conditional upon\ntraits of the decision maker as well as upon the context and the framing of\nchoice options. Whereas existing Signal Detection Theory (SDT) models of\nphishing detection commingle the different peripheral-route persuasion\npathways, in the present descriptive generalization the different pathways are\nexplicitly identified and represented. A number of implications follow\nimmediately from this formulation, ranging from the conditional nature of\nsecurity-breach risk to delineation of the prerequisites for valid tests of\nsecurity training. Moreover, the model explains the `stepping-stone'\npenetration pattern of APT attacks, which has confounded modeling approaches\nbased on normative rationality.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 15:00:10 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Embrey", "Iain", ""], ["Kaivanto", "Kim", ""]]}, {"id": "1811.06418", "submitter": "Ilya Razenshteyn", "authors": "S\\'ebastien Bubeck, Yin Tat Lee, Eric Price, Ilya Razenshteyn", "title": "Adversarial Examples from Cryptographic Pseudo-Random Generators", "comments": "4 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our recent work (Bubeck, Price, Razenshteyn, arXiv:1805.10204) we argued\nthat adversarial examples in machine learning might be due to an inherent\ncomputational hardness of the problem. More precisely, we constructed a binary\nclassification task for which (i) a robust classifier exists; yet no\nnon-trivial accuracy can be obtained with an efficient algorithm in (ii) the\nstatistical query model. In the present paper we significantly strengthen both\n(i) and (ii): we now construct a task which admits (i') a maximally robust\nclassifier (that is it can tolerate perturbations of size comparable to the\nsize of the examples themselves); and moreover we prove computational hardness\nof learning this task under (ii') a standard cryptographic assumption.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 15:08:12 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Bubeck", "S\u00e9bastien", ""], ["Lee", "Yin Tat", ""], ["Price", "Eric", ""], ["Razenshteyn", "Ilya", ""]]}, {"id": "1811.06492", "submitter": "Zehao Dou", "authors": "Zehao Dou, Stanley J. Osher, and Bao Wang", "title": "Mathematical Analysis of Adversarial Attacks", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze efficacy of the fast gradient sign method (FGSM)\nand the Carlini-Wagner's L2 (CW-L2) attack. We prove that, within a certain\nregime, the untargeted FGSM can fool any convolutional neural nets (CNNs) with\nReLU activation; the targeted FGSM can mislead any CNNs with ReLU activation to\nclassify any given image into any prescribed class. For a special two-layer\nneural network: a linear layer followed by the softmax output activation, we\nshow that the CW-L2 attack increases the ratio of the classification\nprobability between the target and ground truth classes. Moreover, we provide\nnumerical results to verify all our theoretical results.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 17:38:59 GMT"}, {"version": "v2", "created": "Sun, 25 Nov 2018 15:56:12 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Dou", "Zehao", ""], ["Osher", "Stanley J.", ""], ["Wang", "Bao", ""]]}, {"id": "1811.06539", "submitter": "Jamie Hayes", "authors": "Jamie Hayes", "title": "A note on hyperparameters in black-box adversarial examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since Biggio et al. (2013) and Szegedy et al. (2013) first drew attention to\nadversarial examples, there has been a flood of research into defending and\nattacking machine learning models. However, almost all proposed attacks assume\nwhite-box access to a model. In other words, the attacker is assumed to have\nperfect knowledge of the models weights and architecture. With this insider\nknowledge, a white-box attack can leverage gradient information to craft\nadversarial examples. Black-box attacks assume no knowledge of the model\nweights or architecture. These attacks craft adversarial examples using\ninformation only contained in the logits or hard classification label. Here, we\nassume the attacker can use the logits in order to find an adversarial example.\nEmpirically, we show that 2-sided stochastic gradient estimation techniques are\nnot sensitive to scaling parameters, and can be used to mount powerful\nblack-box attacks requiring relatively few model queries.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 23:45:20 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Hayes", "Jamie", ""]]}, {"id": "1811.06584", "submitter": "Michael Tschantz", "authors": "Jaeyoung Choi, Istemi Ekin Akkus, Serge Egelman, Gerald Friedland,\n  Robin Sommer, Michael Carl Tschantz and Nicholas Weaver", "title": "Cybercasing 2.0: You Get What You Pay For", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under U.S. law, marketing databases exist under almost no legal restrictions\nconcerning accuracy, access, or confidentiality. We explore the possible\n(mis)use of these databases in a criminal context by conducting two\nexperiments. First, we show how this data can be used for \"cybercasing\" by\nusing this data to resolve the physical addresses of individuals who are likely\nto be on vacation. Second, we evaluate the utility of a \"bride to be\" mailing\nlist augmented with data obtained by searching both Facebook and a bridal\nregistry aggregator. We conclude that marketing data is not necessarily\nharmless and can represent a fruitful target for criminal misuse.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 20:28:56 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Choi", "Jaeyoung", ""], ["Akkus", "Istemi Ekin", ""], ["Egelman", "Serge", ""], ["Friedland", "Gerald", ""], ["Sommer", "Robin", ""], ["Tschantz", "Michael Carl", ""], ["Weaver", "Nicholas", ""]]}, {"id": "1811.06591", "submitter": "Willie Harrison", "authors": "Benjamin Jensen, Bradford Clark, Dakota Flanary, Kalin Norman, Michael\n  Rice, Willie K. Harrison", "title": "Physical-Layer Security: Does it Work in a Real Environment?", "comments": "7 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper applies channel sounding measurements to enable physical-layer\nsecurity coding. The channel measurements were acquired in an indoor\nenvironment and used to assess the secrecy capacity as a function of physical\nlocation. A variety of Reed-Muller wiretap codes were applied to the channel\nmeasurements to determine the most effective code for the environment. The\nresults suggest that deploying physical-layer security coding is a three-point\ndesign process, where channel sounding data guides 1) the physical placement of\nthe antennas, 2) the power settings of the transmitter, and 3) the selection of\nwiretap coding.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 21:04:02 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Jensen", "Benjamin", ""], ["Clark", "Bradford", ""], ["Flanary", "Dakota", ""], ["Norman", "Kalin", ""], ["Rice", "Michael", ""], ["Harrison", "Willie K.", ""]]}, {"id": "1811.06624", "submitter": "Jason R.C. Nurse Dr", "authors": "Jason R. C. Nurse", "title": "Cybercrime and You: How Criminals Attack and the Human Factors That They\n  Seek to Exploit", "comments": null, "journal-ref": "The Oxford Handbook of Cyberpsychology, 2018", "doi": "10.1093/oxfordhb/9780198812746.013.35", "report-no": null, "categories": "cs.CR cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cybercrime is a significant challenge to society, but it can be particularly\nharmful to the individuals who become victims. This chapter engages in a\ncomprehensive and topical analysis of the cybercrimes that target individuals.\nIt also examines the motivation of criminals that perpetrate such attacks and\nthe key human factors and psychological aspects that help to make\ncybercriminals successful. Key areas assessed include social engineering (e.g.,\nphishing, romance scams, catfishing), online harassment (e.g., cyberbullying,\ntrolling, revenge porn, hate crimes), identity-related crimes (e.g., identity\ntheft, doxing), hacking (e.g., malware, cryptojacking, account hacking), and\ndenial-of-service crimes. As a part of its contribution, the chapter introduces\na summary taxonomy of cybercrimes against individuals and a case for why they\nwill continue to occur if concerted interdisciplinary efforts are not pursued.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 23:16:37 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Nurse", "Jason R. C.", ""]]}, {"id": "1811.06632", "submitter": "Wesley Joon-Wie Tann", "authors": "Wesley Joon-Wie Tann, Xing Jie Han, Sourav Sen Gupta, Yew-Soon Ong", "title": "Towards Safer Smart Contracts: A Sequence Learning Approach to Detecting\n  Security Threats", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symbolic analysis of security exploits in smart contracts has demonstrated to\nbe valuable for analyzing predefined vulnerability properties. While some\nsymbolic tools perform complex analysis steps, they require a predetermined\ninvocation depth to search vulnerable execution paths, and the search time\nincreases with depth. The number of contracts on blockchains like Ethereum has\nincreased 176 fold since December 2015. If these symbolic tools fail to analyze\nthe increasingly large number of contracts in time, entire classes of exploits\ncould cause irrevocable damage. In this paper, we aim to have safer smart\ncontracts against emerging threats. We propose the approach of sequential\nlearning of smart contract weaknesses using machine learning---long-short term\nmemory (LSTM)---that allows us to be able to detect new attack trends\nrelatively quickly, leading to safer smart contracts. Our experimental studies\non 620,000 smart contracts prove that our model can easily scale to analyze a\nmassive amount of contracts; that is, the LSTM maintains near constant analysis\ntime as contracts increase in complexity. In addition, our approach achieves\n$99\\%$ test accuracy and correctly analyzes contracts that were false positive\n(FP) errors made by a symbolic tool.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 00:02:59 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 07:06:43 GMT"}, {"version": "v3", "created": "Fri, 7 Jun 2019 06:42:04 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Tann", "Wesley Joon-Wie", ""], ["Han", "Xing Jie", ""], ["Gupta", "Sourav Sen", ""], ["Ong", "Yew-Soon", ""]]}, {"id": "1811.06667", "submitter": "Wenbo Wang", "authors": "Zhengwei Ni and Wenbo Wang and Dong In Kim and Ping Wang and Dusit\n  Niyato", "title": "Evolutionary Game for Consensus Provision in Permissionless Blockchain\n  Networks with Shard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of decentralized consensus protocols, permissionless\nblockchains have been envisioned as a promising enabler for the general-purpose\ntransaction-driven, autonomous systems. However, most of the prevalent\nblockchain networks are built upon the consensus protocols under the\ncrypto-puzzle framework known as proof-of-work. Such protocols face the\ninherent problem of transaction-processing bottleneck, as the networks achieve\nthe decentralized consensus for transaction confirmation at the cost of very\nhigh latency. In this paper, we study the problem of consensus formation in a\nsystem of multiple throughput-scalable blockchains with sharded consensus.\nSpecifically, the protocol design of sharded consensus not only enables\nparallelizing the process of transaction validation with sub-groups of\nprocessors, but also introduces the Byzantine consensus protocols for\naccelerating the consensus processes. By allowing different blockchains to\nimpose different levels of processing fees and to have different\ntransaction-generating rate, we aim to simulate the multi-service provision\neco-systems based on blockchains in real world. We focus on the dynamics of\nblockchain-selection in the condition of a large population of consensus\nprocessors. Hence, we model the evolution of blockchain selection by the\nindividual processors as an evolutionary game. Both the theoretical and the\nnumerical analysis are provided regarding the evolutionary equilibria and the\nstability of the processors' strategies in a general case.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 03:25:08 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Ni", "Zhengwei", ""], ["Wang", "Wenbo", ""], ["Kim", "Dong In", ""], ["Wang", "Ping", ""], ["Niyato", "Dusit", ""]]}, {"id": "1811.06751", "submitter": "Zhiniang Peng", "authors": "Zhiniang Peng and Yuki Chen", "title": "All roads lead to Rome: Many ways to double spend your cryptocurrency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2008, Satoshi Nakamoto proposed an electronic cash system (bitcoin) that\nis completely realized by peer-to-peer technology. The core value of this\nscheme is that it proposes a solution based on Proof-of Work, so that the cash\nsystem can run in a peer-to-peer environment and be able to prevent\ndouble-spend attacks. Bitcoin has been developed for ten years, and since then\ncountless digital currencies have been created. But the discussion of\ndouble-spend attacks seems to still concentrate on 51% Attacks. In fact, our\nresearch has found that there are many other way to achieve double-spend\nattacks. In this paper, by introducing a number of double-spend attack\nvulnerabilities that we have found in EOS, NEO and other large blockchain\nplatforms, we summarized various reasons for causing double-spend attacks, and\npropose an efficient mitigation measure against them.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 11:02:56 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Peng", "Zhiniang", ""], ["Chen", "Yuki", ""]]}, {"id": "1811.06822", "submitter": "Johann Knechtel", "authors": "Satwik Patnaik and Mohammed Ashraf and Ozgur Sinanoglu and Johann\n  Knechtel", "title": "Best of Both Worlds: Integration of Split Manufacturing and Camouflaging\n  into a Security-Driven CAD Flow for 3D ICs", "comments": "Published in Proc. International Conference On Computer Aided Design\n  (ICCAD) 2018", "journal-ref": null, "doi": "10.1145/3240765.3240784", "report-no": null, "categories": "cs.CR cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the globalization of manufacturing and supply chains, ensuring the\nsecurity and trustworthiness of ICs has become an urgent challenge. Split\nmanufacturing (SM) and layout camouflaging (LC) are promising techniques to\nprotect the intellectual property (IP) of ICs from malicious entities during\nand after manufacturing (i.e., from untrusted foundries and reverse-engineering\nby end-users). In this paper, we strive for \"the best of both worlds,\" that is\nof SM and LC. To do so, we extend both techniques towards 3D integration, an\nup-and-coming design and manufacturing paradigm based on stacking and\ninterconnecting of multiple chips/dies/tiers. Initially, we review prior art\nand their limitations. We also put forward a novel, practical threat model of\nIP piracy which is in line with the business models of present-day design\nhouses. Next, we discuss how 3D integration is a naturally strong match to\ncombine SM and LC. We propose a security-driven CAD and manufacturing flow for\nface-to-face (F2F) 3D ICs, along with obfuscation of interconnects. Based on\nthis CAD flow, we conduct comprehensive experiments on DRC-clean layouts.\nStrengthened by an extensive security analysis (also based on a novel attack to\nrecover obfuscated F2F interconnects), we argue that entering the next, third\ndimension is eminent for effective and efficient IP protection.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 14:43:08 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Patnaik", "Satwik", ""], ["Ashraf", "Mohammed", ""], ["Sinanoglu", "Ozgur", ""], ["Knechtel", "Johann", ""]]}, {"id": "1811.06888", "submitter": "Juan Tapiador", "authors": "Alejandro Calleja, Juan Tapiador, Juan Caballero", "title": "The MalSource Dataset: Quantifying Complexity and Code Reuse in Malware\n  Development", "comments": "To appear in IEEE Transactions on Information Forensics and Security", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last decades, the problem of malicious and unwanted software\n(malware) has surged in numbers and sophistication. Malware plays a key role in\nmost of today's cyber attacks and has consolidated as a commodity in the\nunderground economy. In this work, we analyze the evolution of malware from\n1975 to date from a software engineering perspective. We analyze the source\ncode of 456 samples from 428 unique families and obtain measures of their size,\ncode quality, and estimates of the development costs (effort, time, and number\nof people). Our results suggest an exponential increment of nearly one order of\nmagnitude per decade in aspects such as size and estimated effort, with code\nquality metrics similar to those of benign software.We also study the extent to\nwhich code reuse is present in our dataset. We detect a significant number of\ncode clones across malware families and report which features and\nfunctionalities are more commonly shared. Overall, our results support claims\nabout the increasing complexity of malware and its production progressively\nbecoming an industry.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 16:09:40 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Calleja", "Alejandro", ""], ["Tapiador", "Juan", ""], ["Caballero", "Juan", ""]]}, {"id": "1811.06917", "submitter": "Zhitao Guan", "authors": "Xueyan Liu, Zhitao Guan, Xiaojiang Du, Liehuang Zhu, Zhengtao Yu,\n  Yinglong Ma", "title": "ESAS: An Efficient Semantic and Authorized Search Scheme over Encrypted\n  Outsourced Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, a large amount of user privacy-sensitive data is outsourced to the\ncloud server in ciphertext, which is provided by the data owners and can be\naccessed by authorized data users. When accessing data, the user should be\nassigned with the access permission according to his identities or attributes.\nIn addition, the search capabilities in encrypted outsourced data is expected\nto be enhanced, i.e., the search results can better pre-sent user's intentions.\nTo address the above issues, ESAS, an Efficient Semantic and Authorized Search\nscheme over encrypt-ed outsourced data, is proposed. In ESAS, by integrating\nPRSCG (the privacy-preserving ranked search based on con-ceptual graph) and\nCP-ABE (ciphertext policy attribute-based encryption), semantic search with\nfile-level fine-grained access authorization can be realized. In addition,\nsearch authorization can be done in an offline manner, which can improve search\nefficiency and reduce the response time. The security analysis indicate that\nthe proposed ESAS meets security requirement.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 07:48:10 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Liu", "Xueyan", ""], ["Guan", "Zhitao", ""], ["Du", "Xiaojiang", ""], ["Zhu", "Liehuang", ""], ["Yu", "Zhengtao", ""], ["Ma", "Yinglong", ""]]}, {"id": "1811.06918", "submitter": "Zhitao Guan", "authors": "Zhitao Guan, Guanlin Si, Xiaojiang Du, Peng Liu", "title": "Protecting User Privacy Based on Secret Sharing with Error Tolerance for\n  Big Data in Smart Grid", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In smart grid, large quantities of data is collected from various\napplications, such as smart metering substation state monitoring, electric\nenergy data acquisition, and smart home. Big data acquired in smart grid\napplications usually is sensitive. For instance, in order to dispatch\naccurately and support the dynamic price, lots of smart meters are installed at\nuser's house to collect the real-time data, but all these collected data are\nrelated to user privacy. In this paper, we propose a data aggregation scheme\nbased on secret sharing with error tolerance in smart grid, which ensures that\nthe control center gets the integrated data without revealing users' privacy.\nMeanwhile, we also consider the differential privacy and error tolerance during\nthe data aggregation. At last, we analyze the security of our scheme and carry\nout experiments to validate the results.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 07:47:32 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Guan", "Zhitao", ""], ["Si", "Guanlin", ""], ["Du", "Xiaojiang", ""], ["Liu", "Peng", ""]]}, {"id": "1811.06922", "submitter": "Adrien Koutsos", "authors": "Adrien Koutsos", "title": "The 5G-AKA Authentication Protocol Privacy", "comments": "Changes: - added details when describing some attacks. - added a\n  constant message in the AKA+ protocol", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the 5G-AKA authentication protocol described in the 5G mobile\ncommunication standards. This version of AKA tries to achieve a better privacy\nthan the 3G and 4G versions through the use of asymmetric randomized\nencryption. Nonetheless, we show that except for the IMSI-catcher attack, all\nknown attacks against 5G-AKA privacy still apply.\n  Next, we modify the 5G-AKA protocol to prevent these attacks, while\nsatisfying the cost and efficiency constraints of the 5G-AKA protocol. We then\nformally prove that our protocol is sigma-unlinkable. This is a new security\nnotion, which allows for a fine-grained quantification of a protocol privacy.\nOur security proof is carried out in the Bana-Comon indistinguishability logic.\nWe also prove mutual authentication as a secondary result.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 17:04:57 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 11:50:26 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Koutsos", "Adrien", ""]]}, {"id": "1811.06936", "submitter": "Adrien Koutsos", "authors": "Adrien Koutsos", "title": "Deciding Indistinguishability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational indistinguishability is a key property in cryptography and\nverification of security protocols. Current tools for proving it rely on\ncryptographic game transformations.\n  We follow Bana and Comon's approach, axiomatizing what an adversary cannot\ndistinguish. We prove the decidability of a set of first-order axioms that are\nboth computationally sound and expressive enough. This can be viewed as the\ndecidability of a family of cryptographic game transformations. Our proof\nrelies on term rewriting and automated deduction techniques.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 17:39:14 GMT"}, {"version": "v2", "created": "Fri, 10 May 2019 15:16:43 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Koutsos", "Adrien", ""]]}, {"id": "1811.06969", "submitter": "Nicholas Frosst", "authors": "Nicholas Frosst, Sara Sabour, Geoffrey Hinton", "title": "DARCCC: Detecting Adversaries by Reconstruction from Class Conditional\n  Capsules", "comments": "To be presented at NIPS 2018 Workshop on Security in Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple technique that allows capsule models to detect\nadversarial images. In addition to being trained to classify images, the\ncapsule model is trained to reconstruct the images from the pose parameters and\nidentity of the correct top-level capsule. Adversarial images do not look like\na typical member of the predicted class and they have much larger\nreconstruction errors when the reconstruction is produced from the top-level\ncapsule for that class. We show that setting a threshold on the $l2$ distance\nbetween the input image and its reconstruction from the winning capsule is very\neffective at detecting adversarial images for three different datasets. The\nsame technique works quite well for CNNs that have been trained to reconstruct\nthe image from all or part of the last hidden layer before the softmax. We then\nexplore a stronger, white-box attack that takes the reconstruction error into\naccount. This attack is able to fool our detection technique but in order to\nmake the model change its prediction to another class, the attack must\ntypically make the \"adversarial\" image resemble images of the other class.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 18:52:58 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Frosst", "Nicholas", ""], ["Sabour", "Sara", ""], ["Hinton", "Geoffrey", ""]]}, {"id": "1811.07005", "submitter": "Yannic Noller", "authors": "Shirin Nilizadeh, Yannic Noller, Corina S. Pasareanu", "title": "DifFuzz: Differential Fuzzing for Side-Channel Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Side-channel attacks allow an adversary to uncover secret program data by\nobserving the behavior of a program with respect to a resource, such as\nexecution time, consumed memory or response size. Side-channel vulnerabilities\nare difficult to reason about as they involve analyzing the correlations\nbetween resource usage over multiple program paths. We present DifFuzz, a\nfuzzing-based approach for detecting side-channel vulnerabilities related to\ntime and space. DifFuzz automatically detects these vulnerabilities by\nanalyzing two versions of the program and using resource-guided heuristics to\nfind inputs that maximize the difference in resource consumption between\nsecret-dependent paths. The methodology of DifFuzz is general and can be\napplied to programs written in any language. For this paper, we present an\nimplementation that targets analysis of Java programs, and uses and extends the\nKelinci and AFL fuzzers. We evaluate DifFuzz on a large number of Java programs\nand demonstrate that it can reveal unknown side-channel vulnerabilities in\npopular applications. We also show that DifFuzz compares favorably against\nBlazer and Themis, two state-of-the-art analysis tools for finding\nside-channels in Java programs.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 19:48:17 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 11:22:57 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Nilizadeh", "Shirin", ""], ["Noller", "Yannic", ""], ["Pasareanu", "Corina S.", ""]]}, {"id": "1811.07018", "submitter": "Yuan Gong", "authors": "Yuan Gong and Christian Poellabauer", "title": "Protecting Voice Controlled Systems Using Sound Source Identification\n  Based on Acoustic Cues", "comments": "Proceedings of the 27th International Conference on Computer\n  Communications and Networks (ICCCN), Hangzhou, China, July-August 2018. arXiv\n  admin note: text overlap with arXiv:1803.09156", "journal-ref": null, "doi": "10.1109/ICCCN.2018.8487334", "report-no": null, "categories": "cs.CR cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last few years, a rapidly increasing number of Internet-of-Things\n(IoT) systems that adopt voice as the primary user input have emerged. These\nsystems have been shown to be vulnerable to various types of voice spoofing\nattacks. Existing defense techniques can usually only protect from a specific\ntype of attack or require an additional authentication step that involves\nanother device. Such defense strategies are either not strong enough or lower\nthe usability of the system. Based on the fact that legitimate voice commands\nshould only come from humans rather than a playback device, we propose a novel\ndefense strategy that is able to detect the sound source of a voice command\nbased on its acoustic features. The proposed defense strategy does not require\nany information other than the voice command itself and can protect a system\nfrom multiple types of spoofing attacks. Our proof-of-concept experiments\nverify the feasibility and effectiveness of this defense strategy.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 20:13:25 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Gong", "Yuan", ""], ["Poellabauer", "Christian", ""]]}, {"id": "1811.07028", "submitter": "Behshid Shayesteh", "authors": "Behshid Shayesteh, Vesal Hakami, Ahmad Akbari", "title": "A Trust Management Scheme for IoT-Enabled Environmental\n  Health/Accessibility Monitoring Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One rapidly growing application of Internet of Things (IoT) is the protection\nof public health and well-being through enabling environmental monitoring\nservices. In particular, an IoT-enabled health/accessibility monitoring service\n(HAMS) can be consulted by its users to query about the status of different\nareas so as to optimize their trip throughout a geographic region. Given the\nhigh cost associated with a vast deployment of totally trusted information\nsources, the IoT-enabled monitoring services also subsist on citizen engagement\nand on (possibly untrusted) users' sensing apparatus for data collection.\nHowever, trust management becomes a key factor in the success of such services\nbecause they might be misled by malicious users through altered or fake sensor\ndata. In this paper, we consider a monitoring service, and propose a hybrid\nentity/data trust computation scheme which relies on Bayesian learning to score\nthe users (as data reporters), and on Dempster-Shafer theory (DST) for data\nfusion and for the computation of the trustworthiness of the data itself. In\norder to provide resiliency against behavioral changes, the probability masses\nused in DST are dynamically updated using the freshly estimated user scores as\nwell as the contextual properties associated with the reported data. We conduct\nsimulation experiments to evaluate the performance of our scheme. Compared to\nprior work, the results demonstrate superior performance in terms of accuracy\nand resilience against malicious behavior.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 20:40:09 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Shayesteh", "Behshid", ""], ["Hakami", "Vesal", ""], ["Akbari", "Ahmad", ""]]}, {"id": "1811.07060", "submitter": "Sudip Vhaduri", "authors": "Sudip Vhaduri, Christian Poellabauer", "title": "Biometric-Based Wearable User Authentication During Sedentary and\n  Non-sedentary Periods", "comments": "1st International Workshop on Security and Privacy for the\n  Internet-of-Things (IoTSec)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) is increasingly empowering people with an\ninterconnected world of physical objects ranging from smart buildings to\nportable smart devices such as wearables. With the recent advances in mobile\nsensing, wearables have become a rich collection of portable sensors and are\nable to provide various types of services including health and fitness\ntracking, financial transactions, and unlocking smart locks and vehicles.\nExisting explicit authentication approaches (i.e., PINs or pattern locks)\nsuffer from several limitations including limited display size, shoulder\nsurfing, and recall burden. Oftentimes, users completely disable security\nfeatures out of convenience. Therefore, there is a need for a burden-free\n(implicit) authentication mechanism for wearable device users based on easily\nobtainable biometric data. In this paper, we present an implicit wearable\ndevice user authentication mechanism using combinations of three types of\ncoarse-grained minute-level biometrics: behavioral (step counts), physiological\n(heart rate), and hybrid (calorie burn and metabolic equivalent of task). From\nour analysis of 421 Fitbit users from a two-year long health study, we are able\nto authenticate subjects with average accuracy values of around 92% and 88%\nduring sedentary and non-sedentary periods, respectively. Our findings also\nshow that (a) behavioral biometrics do not work well during sedentary periods\nand (b) hybrid biometrics typically perform better than other biometrics.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 23:05:29 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Vhaduri", "Sudip", ""], ["Poellabauer", "Christian", ""]]}, {"id": "1811.07108", "submitter": "Hengbiao Yu", "authors": "Chengdong Feng, Zhenbang Chen, Weijiang Hong, Hengbiao Yu, Wei Dong,\n  Ji Wang", "title": "Boosting the Robustness Verification of DNN by Identifying the\n  Achilles's Heel", "comments": "12", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Network (DNN) is a widely used deep learning technique. How to\nensure the safety of DNN-based system is a critical problem for the research\nand application of DNN. Robustness is an important safety property of DNN.\nHowever, existing work of verifying DNN's robustness is time-consuming and hard\nto scale to large-scale DNNs. In this paper, we propose a boosting method for\nDNN robustness verification, aiming to find counter-examples earlier. Our\nobservation is DNN's different inputs have different possibilities of existing\ncounter-examples around them, and the input with a small difference between the\nlargest output value and the second largest output value tends to be the\nachilles's heel of the DNN. We have implemented our method and applied it on\nReluplex, a state-of-the-art DNN verification tool, and four DNN attacking\nmethods. The results of the extensive experiments on two benchmarks indicate\nthe effectiveness of our boosting method.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 06:33:10 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Feng", "Chengdong", ""], ["Chen", "Zhenbang", ""], ["Hong", "Weijiang", ""], ["Yu", "Hengbiao", ""], ["Dong", "Wei", ""], ["Wang", "Ji", ""]]}, {"id": "1811.07153", "submitter": "Anatoly Shusterman", "authors": "Anatoly Shusterman, Lachlan Kang, Yarden Haskal, Yosef Meltser,\n  Prateek Mittal, Yossi Oren, Yuval Yarom", "title": "Robust Website Fingerprinting Through the Cache Occupancy Channel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Website fingerprinting attacks, which use statistical analysis on network\ntraffic to compromise user privacy, have been shown to be effective even if the\ntraffic is sent over anonymity-preserving networks such as Tor. The classical\nattack model used to evaluate website fingerprinting attacks assumes an on-path\nadversary, who can observe all traffic traveling between the user's computer\nand the Tor network. In this work we investigate these attacks under a\ndifferent attack model, in which the adversary is capable of running a small\namount of unprivileged code on the target user's computer. Under this model,\nthe attacker can mount cache side-channel attacks, which exploit the effects of\ncontention on the CPU's cache, to identify the website being browsed. In an\nimportant special case of this attack model, a JavaScript attack is launched\nwhen the target user visits a website controlled by the attacker. The\neffectiveness of this attack scenario has never been systematically analyzed,\nespecially in the open-world model which assumes that the user is visiting a\nmix of both sensitive and non-sensitive sites. In this work we show that cache\nwebsite fingerprinting attacks in JavaScript are highly feasible, even when\nthey are run from highly restrictive environments, such as the Tor Browser.\nSpecifically, we use machine learning techniques to classify traces of cache\nactivity. Unlike prior works, which try to identify cache conflicts, our work\nmeasures the overall occupancy of the last-level cache. We show that our\napproach achieves high classification accuracy in both the open-world and the\nclosed-world models. We further show that our techniques are resilient both to\nnetwork-based defenses and to side-channel countermeasures introduced to modern\nbrowsers as a response to the Spectre attack.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 12:25:00 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 08:57:41 GMT"}, {"version": "v3", "created": "Thu, 21 Feb 2019 14:48:25 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Shusterman", "Anatoly", ""], ["Kang", "Lachlan", ""], ["Haskal", "Yarden", ""], ["Meltser", "Yosef", ""], ["Mittal", "Prateek", ""], ["Oren", "Yossi", ""], ["Yarom", "Yuval", ""]]}, {"id": "1811.07211", "submitter": "Jacob Springer", "authors": "Jacob M. Springer, Charles S. Strauss, Austin M. Thresher, Edward Kim,\n  Garrett T. Kenyon", "title": "Classifiers Based on Deep Sparse Coding Architectures are Robust to Deep\n  Learning Transferable Examples", "comments": "8 pages, 8 figures, fixed typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep learning has shown great success in recent years, researchers\nhave discovered a critical flaw where small, imperceptible changes in the input\nto the system can drastically change the output classification. These attacks\nare exploitable in nearly all of the existing deep learning classification\nframeworks. However, the susceptibility of deep sparse coding models to\nadversarial examples has not been examined. Here, we show that classifiers\nbased on a deep sparse coding model whose classification accuracy is\ncompetitive with a variety of deep neural network models are robust to\nadversarial examples that effectively fool those same deep learning models. We\ndemonstrate both quantitatively and qualitatively that the robustness of deep\nsparse coding models to adversarial examples arises from two key properties.\nFirst, because deep sparse coding models learn general features corresponding\nto generators of the dataset as a whole, rather than highly discriminative\nfeatures for distinguishing specific classes, the resulting classifiers are\nless dependent on idiosyncratic features that might be more easily exploited.\nSecond, because deep sparse coding models utilize fixed point attractor\ndynamics with top-down feedback, it is more difficult to find small changes to\nthe input that drive the resulting representations out of the correct attractor\nbasin.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 19:39:54 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 18:55:55 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Springer", "Jacob M.", ""], ["Strauss", "Charles S.", ""], ["Thresher", "Austin M.", ""], ["Kim", "Edward", ""], ["Kenyon", "Garrett T.", ""]]}, {"id": "1811.07269", "submitter": "Kong Hyeok", "authors": "Un-Hyang Ho, Hye-Ok Kong", "title": "Prediction of Signal Sequences in Abiotic Stress Inducible Genes from\n  Main Crops by Association Rule Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is important to study on genes affecting to growing environment of main\ncrops. Especially the recognition problem of promoter region, which is the\nproblem to predict whether DNA sequences contain promoter regions or not, is\nprior to find abiotic stress-inducible genes. Studies on predicting promoter\nsequences in DNA sequences have been studied by traditional pattern matching\nmethods and machine learning methods in biology and computer science.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 04:21:18 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Ho", "Un-Hyang", ""], ["Kong", "Hye-Ok", ""]]}, {"id": "1811.07276", "submitter": "Soyeon Park", "authors": "Soyeon Park, Sangho Lee, Wen Xu, Hyungon Moon and Taesoo Kim", "title": "libmpk: Software Abstraction for Intel Memory Protection Keys", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intel memory protection keys (MPK) is a new hardware feature to support\nthread-local permission control on groups of pages without requiring\nmodification of page tables. Unfortunately, its current hardware implementation\nand software supports suffer from security, scalability, and semantic-gap\nproblems: (1) MPK is vulnerable to protection-key-use-after-free and\nprotection-key corruption; (2) MPK does not scale due to hardware limitations;\nand (3) MPK is not perfectly compatible with mprotect() because it does not\nsupport permission synchronization across threads.\n  In this paper, we propose libmpk, a software abstraction for MPK. libmpk\nvirtualizes protection keys to eliminate the protection-key-use-after-free and\nprotection-key corruption problems while supporting a tremendous number of\nmemory page groups. libmpk also prevents unauthorized writes to its metadata\nand supports inter-thread key synchronization. We apply libmpk to three\nreal-world applications: OpenSSL, JavaScript JIT compiler, and Memcached for\nmemory protection and isolation. An evaluation shows that libmpk introduces\nnegligible performance overhead (<1%) compared with insecure versions, and\nimproves their performance by 8.1x over secure equivalents using mprotect().\nThe source code of libmpk will be publicly available and maintained as an open\nsource project.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 05:19:54 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Park", "Soyeon", ""], ["Lee", "Sangho", ""], ["Xu", "Wen", ""], ["Moon", "Hyungon", ""], ["Kim", "Taesoo", ""]]}, {"id": "1811.07311", "submitter": "Yoel Shoshan", "authors": "Yoel Shoshan and Vadim Ratner", "title": "Regularized adversarial examples for model interpretability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As machine learning algorithms continue to improve, there is an increasing\nneed for explaining why a model produces a certain prediction for a certain\ninput. In recent years, several methods for model interpretability have been\ndeveloped, aiming to provide explanation of which subset regions of the model\ninput is the main reason for the model prediction. In parallel, a significant\nresearch community effort is occurring in recent years for developing\nadversarial example generation methods for fooling models, while not altering\nthe true label of the input,as it would have been classified by a human\nannotator. In this paper, we bridge the gap between adversarial example\ngeneration and model interpretability, and introduce a modification to the\nadversarial example generation process which encourages better\ninterpretability. We analyze the proposed method on a public medical imaging\ndataset, both quantitatively and qualitatively, and show that it significantly\noutperforms the leading known alternative method. Our suggested method is\nsimple to implement, and can be easily plugged into most common adversarial\nexample generation frameworks. Additionally, we propose an explanation quality\nmetric - $APE$ - \"Adversarial Perturbative Explanation\", which measures how\nwell an explanation describes model decisions.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 10:40:16 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 07:29:32 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Shoshan", "Yoel", ""], ["Ratner", "Vadim", ""]]}, {"id": "1811.07335", "submitter": "Liu Sen", "authors": "Sen Liu and Jianxin Lin and Zhibo Chen", "title": "Distribution Discrepancy Maximization for Image Privacy Preserving", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid increase in online photo sharing activities, image obfuscation\nalgorithms become particularly important for protecting the sensitive\ninformation in the shared photos. However, existing image obfuscation methods\nbased on hand-crafted principles are challenged by the dramatic development of\ndeep learning techniques. To address this problem, we propose to maximize the\ndistribution discrepancy between the original image domain and the encrypted\nimage domain. Accordingly, we introduce a collaborative training scheme: a\ndiscriminator $D$ is trained to discriminate the reconstructed image from the\nencrypted image, and an encryption model $G_e$ is required to generate these\ntwo kinds of images to maximize the recognition rate of $D$, leading to the\nsame training objective for both $D$ and $G_e$. We theoretically prove that\nsuch a training scheme maximizes two distributions' discrepancy. Compared with\ncommonly-used image obfuscation methods, our model can produce satisfactory\ndefense against the attack of deep recognition models indicated by significant\naccuracy decreases on FaceScrub, Casia-WebFace and LFW datasets.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 14:53:49 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Liu", "Sen", ""], ["Lin", "Jianxin", ""], ["Chen", "Zhibo", ""]]}, {"id": "1811.07366", "submitter": "Mahmoud Ammar", "authors": "Mahmoud Ammar, Mahdi Washha, Bruno Crispo", "title": "WISE: Lightweight Intelligent Swarm Attestation Scheme for IoT (The\n  Verifier's Perspective)", "comments": "This paper has been accepted and presented at the 14th IEEE\n  International Conference on Wireless and Mobile Computing, Networking and\n  Communications (WiMob)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing pervasiveness of Internet of Things (IoT) expands the attack\nsurface by connecting more and more attractive attack targets, i.e. embedded\ndevices, to the Internet. One key component in securing these devices is\nsoftware integrity checking, which typically attained with Remote Attestation\n(RA). RA is realized as an interactive protocol, whereby a trusted party,\nverifier, verifies the software integrity of a potentially compromised remote\ndevice, prover. In the vast majority of IoT applications, smart devices operate\nin swarms, thus triggering the need for efficient swarm attestation schemes. In\nthis paper, we present WISE, the first intelligent swarm attestation protocol\nthat aims to minimize the communication overhead while preserving an adequate\nlevel of security. WISE depends on a resource-efficient smart broadcast\nauthentication scheme where devices are organized in fine-grained\nmulti-clusters, and whenever needed, the most likely compromised devices are\nattested. The candidate devices are selected intelligently taking into account\nthe attestation history and the diverse characteristics (and constraints) of\neach device in the swarm. We show that WISE is very suitable for\nresource-constrained embedded devices, highly efficient and scalable in\nheterogenous IoT networks, and offers an adjustable level of security.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 17:57:06 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Ammar", "Mahmoud", ""], ["Washha", "Mahdi", ""], ["Crispo", "Bruno", ""]]}, {"id": "1811.07367", "submitter": "Mahmoud Ammar", "authors": "Mahmoud Ammar, Mahdi Washha, Gowri Sankar Ramachandran, Bruno Crispo", "title": "slimIoT: Scalable Lightweight Attestation Protocol For the Internet of\n  Things", "comments": "This paper has been accepted at the 2018 IEEE Conference on\n  Dependable and Secure Computing (DSC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) is increasingly intertwined with critical\nindustrial processes, yet contemporary IoT devices offer limited security\nfeatures, creating a large new attack surface. Remote attestation is a\nwell-known technique to detect cyber threats by remotely verifying the internal\nstate of a networked embedded device through a trusted entity. Multi-device\nattestation has received little attention although current single-device\napproaches show limited scalability in IoT applications. Though recent work has\nyielded some proposals for scalable attestation, several aspects remain\nunexplored, and thus more research is required. This paper presents slimIoT, a\nscalable lightweight attestation protocol that is suitable for all IoT devices.\nslimIoT depends on an efficient broadcast authentication scheme along with\nsymmetric key cryptography. It is resilient against a strong adversary with\nphysical access to the IoT device. Our protocol is informative in the sense\nthat it identifies the precise status of every device in the network. We\nimplement and evaluate slimIoT considering many factors. On the one hand, our\nevaluation results show a low overhead in terms of memory footprint and\nruntime. On the other hand, simulations demonstrate that slimIoT is scalable,\nrobust and highly efficient to be used in static and dynamic networks\nconsisting of thousands of heterogenous IoT devices.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 17:58:46 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Ammar", "Mahmoud", ""], ["Washha", "Mahdi", ""], ["Ramachandran", "Gowri Sankar", ""], ["Crispo", "Bruno", ""]]}, {"id": "1811.07375", "submitter": "Ilia Shumailov", "authors": "Ilia Shumailov, Yiren Zhao, Robert Mullins, Ross Anderson", "title": "The Taboo Trap: Behavioural Detection of Adversarial Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Deep Neural Networks (DNNs) have become a powerful toolfor a wide range of\nproblems. Yet recent work has found an increasing variety of adversarial\nsamplesthat can fool them. Most existing detection mechanisms against\nadversarial attacksimpose significant costs, either by using additional\nclassifiers to spot adversarial samples, or by requiring the DNN to be\nrestructured. In this paper, we introduce a novel defence. We train our DNN so\nthat, as long as it is workingas intended on the kind of inputs we expect, its\nbehavior is constrained, in that some set of behaviors are taboo. If it is\nexposed to adversarial samples, they will often cause a taboo behavior, which\nwe can detect. Taboos can be both subtle and diverse, so their choice can\nencode and hide information. It is a well-established design principle that the\nsecurity of a system should not depend on the obscurity of its design, but on\nsome variable (the key) which can differ between implementations and bechanged\nas necessary. We discuss how taboos can be used to equip a classifier with just\nsuch a key, and how to tune the keying mechanism to adversaries of various\ncapabilities. We evaluate the performance of a prototype against a wide range\nof attacks and show how our simple defense can defend against cheap attacks at\nscale with zero run-time computation overhead, making it a suitable defense\nmethod for IoT devices.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 18:43:43 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 16:29:55 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Shumailov", "Ilia", ""], ["Zhao", "Yiren", ""], ["Mullins", "Robert", ""], ["Anderson", "Ross", ""]]}, {"id": "1811.07521", "submitter": "Zongxiang Yi", "authors": "Zongxiang Yi, Yuyin Yu, Chunming Tang and Yanbin Zheng", "title": "A Note on Two Constructions of Zero-Difference Balanced Functions", "comments": "fix the math symbols in abstract", "journal-ref": null, "doi": "10.1587/transfun.E102.A.680", "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Notes on two constructions of zero-difference balanced (ZDB) functions are\nmade in this letter. Then ZDB functions over $\\mathbb{Z}_{e}\\times\n\\prod_{i=0}^{k}{\\mathbb{F}_{q_i}}$ are obtained. And it shows that all the\nknown ZDB functions using cyclotomic cosets over $\\mathbb{Z}_{n}$ are special\ncases of a generic construction. Moreover, applications of these ZDB functions\nare presented.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 06:28:51 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 09:38:19 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Yi", "Zongxiang", ""], ["Yu", "Yuyin", ""], ["Tang", "Chunming", ""], ["Zheng", "Yanbin", ""]]}, {"id": "1811.07525", "submitter": "Po-Chun Kuo", "authors": "Tai-Yuan Chen and Wei-Ning Huang and Po-Chun Kuo and Hao Chung and\n  Tzu-Wei Chao", "title": "DEXON: A Highly Scalable, Decentralized DAG-Based Consensus Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A blockchain system is a replicated state machine that must be fault\ntolerant. When designing a blockchain system, there is usually a trade-off\nbetween decentralization, scalability, and security. In this paper, we propose\na novel blockchain system, DEXON, which achieves high scalability while\nremaining decentralized and robust in the real-world environment. We have two\nmain contributions. First, we present a highly scalable sharding framework for\nblockchain. This framework takes an arbitrary number of single chains and\ntransforms them into the \\textit{blocklattice} data structure, enabling\n\\textit{high scalability} and \\textit{low transaction confirmation latency}\nwith asymptotically optimal communication overhead. Second, we propose a\nsingle-chain protocol based on our novel verifiable random function and a new\nByzantine agreement that achieves high decentralization and low latency.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 06:59:50 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Chen", "Tai-Yuan", ""], ["Huang", "Wei-Ning", ""], ["Kuo", "Po-Chun", ""], ["Chung", "Hao", ""], ["Chao", "Tzu-Wei", ""]]}, {"id": "1811.07642", "submitter": "Jinguang Han", "authors": "Jinguang Han, Liqun Chen, Steve Schneider, Helen Treharne, Stephan\n  Wesemeyer and Nick Wils", "title": "Anonymous Single Sign-on with Proxy Re-Verification", "comments": "20 pages, 8 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An anonymous Single Sign-On (ASSO) scheme allows users to access multiple\nservices anonymously using one credential. We propose a new ASSO scheme, where\nusers can access services anonymously through the use of anonymous credentials\nand unlinkably through the provision of designated verifiers. Notably,\nverifiers cannot link service requests of a user even if they collude. The\nnovelty is that when a designated verifier is unavailable, a central authority\ncan authorise new verifiers to authenticate the user on behalf of the original\nverifier. Furthermore, if required, a central verifier is authorised to\ndeanonymise users and trace their service requests. We formalise the scheme\nalong with a security proof and provide an empirical evaluation of its\nperformance. This scheme can be applied to smart ticketing where minimising the\ncollection of personal information of users is increasingly important to\ntransport organisations due to privacy regulations such as General Data\nProtection Regulations (GDPR).\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 12:26:19 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 09:24:10 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Han", "Jinguang", ""], ["Chen", "Liqun", ""], ["Schneider", "Steve", ""], ["Treharne", "Helen", ""], ["Wesemeyer", "Stephan", ""], ["Wils", "Nick", ""]]}, {"id": "1811.07765", "submitter": "Aaron Roth", "authors": "Seth Neel, Aaron Roth, Zhiwei Steven Wu", "title": "How to Use Heuristics for Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop theory for using heuristics to solve computationally hard problems\nin differential privacy. Heuristic approaches have enjoyed tremendous success\nin machine learning, for which performance can be empirically evaluated.\nHowever, privacy guarantees cannot be evaluated empirically, and must be proven\n--- without making heuristic assumptions. We show that learning problems over\nbroad classes of functions can be solved privately and efficiently, assuming\nthe existence of a non-private oracle for solving the same problem. Our first\nalgorithm yields a privacy guarantee that is contingent on the correctness of\nthe oracle. We then give a reduction which applies to a class of heuristics\nwhich we call certifiable, which allows us to convert oracle-dependent privacy\nguarantees to worst-case privacy guarantee that hold even when the heuristic\nstanding in for the oracle might fail in adversarial ways. Finally, we consider\na broad class of functions that includes most classes of simple boolean\nfunctions studied in the PAC learning literature, including conjunctions,\ndisjunctions, parities, and discrete halfspaces. We show that there is an\nefficient algorithm for privately constructing synthetic data for any such\nclass, given a non-private learning oracle. This in particular gives the first\noracle-efficient algorithm for privately generating synthetic data for\ncontingency tables. The most intriguing question left open by our work is\nwhether or not every problem that can be solved differentially privately can be\nprivately solved with an oracle-efficient algorithm. While we do not resolve\nthis, we give a barrier result that suggests that any generic oracle-efficient\nreduction must fall outside of a natural class of algorithms (which includes\nthe algorithms given in this paper).\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 15:57:08 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Neel", "Seth", ""], ["Roth", "Aaron", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "1811.07842", "submitter": "Bander Alsulami", "authors": "Bander Alsulami, Spiros Mancoridis", "title": "Behavioral Malware Classification using Convolutional Recurrent Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Behavioral malware detection aims to improve on the performance of static\nsignature-based techniques used by anti-virus systems, which are less effective\nagainst modern polymorphic and metamorphic malware. Behavioral malware\nclassification aims to go beyond the detection of malware by also identifying a\nmalware's family according to a naming scheme such as the ones used by\nanti-virus vendors. Behavioral malware classification techniques use run-time\nfeatures, such as file system or network activities, to capture the behavioral\ncharacteristic of running processes. The increasing volume of malware samples,\ndiversity of malware families, and the variety of naming schemes given to\nmalware samples by anti-virus vendors present challenges to behavioral malware\nclassifiers. We describe a behavioral classifier that uses a Convolutional\nRecurrent Neural Network and data from Microsoft Windows Prefetch files. We\ndemonstrate the model's improvement on the state-of-the-art using a large\ndataset of malware families and four major anti-virus vendor naming schemes.\nThe model is effective in classifying malware samples that belong to common and\nrare malware families and can incrementally accommodate the introduction of new\nmalware samples and families.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 18:02:10 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Alsulami", "Bander", ""], ["Mancoridis", "Spiros", ""]]}, {"id": "1811.07864", "submitter": "Zhitao Guan", "authors": "Zhitao Guan, Tingting Yang, Xiaojiang Du, Mohsen Guizani", "title": "Secure Data Access for Wireless Body Sensor Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, with the support of mobile cloud computing, a large number of\nhealth related data collected from various body sensor networks can be managed\nefficiently. However, to ensure data security and data privacy in\ncloud-integrated body sensor networks is an important and challenging issue. In\nthis paper, we present a novel secure access control mechanism Mask Certificate\nAttribute Based Encryption for cloud integrated body sensor networks. A\nspecific signature is designed to mask the plaintext, then the masked data can\nbe securely outsourced to cloud severs. An authorization certificate composing\nof the signature and related privilege items is constructed that is used to\ngrant privileges to data receivers. To ensure security, a unique value is\nchosen to mask the certificate for each data receiver. The analysis shows that\nthe proposed scheme has less computational cost and storage cost compared with\nother popular models.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 07:49:15 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Guan", "Zhitao", ""], ["Yang", "Tingting", ""], ["Du", "Xiaojiang", ""], ["Guizani", "Mohsen", ""]]}, {"id": "1811.07971", "submitter": "Jingcheng Liu", "authors": "Jingcheng Liu and Kunal Talwar", "title": "Private Selection from Private Candidates", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentially Private algorithms often need to select the best amongst many\ncandidate options. Classical works on this selection problem require that the\ncandidates' goodness, measured as a real-valued score function, does not change\nby much when one person's data changes. In many applications such as\nhyperparameter optimization, this stability assumption is much too strong. In\nthis work, we consider the selection problem under a much weaker stability\nassumption on the candidates, namely that the score functions are\ndifferentially private. Under this assumption, we present algorithms that are\nnear-optimal along the three relevant dimensions: privacy, utility and\ncomputational efficiency.\n  Our result can be seen as a generalization of the exponential mechanism and\nits existing generalizations. We also develop an online version of our\nalgorithm, that can be seen as a generalization of the sparse vector technique\nto this weaker stability assumption. We show how our results imply better\nalgorithms for hyperparameter selection in differentially private machine\nlearning, as well as for adaptive data analysis.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 20:48:42 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Liu", "Jingcheng", ""], ["Talwar", "Kunal", ""]]}, {"id": "1811.08080", "submitter": "Kazuya Kakizaki", "authors": "Hajime Ono, Tsubasa Takahashi, Kazuya Kakizaki", "title": "Lightweight Lipschitz Margin Training for Certified Defense against\n  Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we make machine learning provably robust against adversarial examples\nin a scalable way? Since certified defense methods, which ensure\n$\\epsilon$-robust, consume huge resources, they can only achieve small degree\nof robustness in practice. Lipschitz margin training (LMT) is a scalable\ncertified defense, but it can also only achieve small robustness due to\nover-regularization. How can we make certified defense more efficiently? We\npresent LC-LMT, a light weight Lipschitz margin training which solves the above\nproblem. Our method has the following properties; (a) efficient: it can achieve\n$\\epsilon$-robustness at early epoch, and (b) robust: it has a potential to get\nhigher robustness than LMT. In the evaluation, we demonstrate the benefits of\nthe proposed method. LC-LMT can achieve required robustness more than 30 epoch\nearlier than LMT in MNIST, and shows more than 90 $\\%$ accuracy against both\nlegitimate and adversarial inputs.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 05:22:55 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Ono", "Hajime", ""], ["Takahashi", "Tsubasa", ""], ["Kakizaki", "Kazuya", ""]]}, {"id": "1811.08097", "submitter": "Akinori Hosoyamada", "authors": "Akinori Hosoyamada, Yu Sasaki, Seiichiro Tani, Keita Xagawa", "title": "Improved Quantum Multicollision-Finding Algorithm", "comments": "To appear at PQCrypto 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC cs.DS quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current paper improves the number of queries of the previous quantum\nmulti-collision finding algorithms presented by Hosoyamada et al. at Asiacrypt\n2017. Let an $l$-collision be a tuple of $l$ distinct inputs that result in the\nsame output of a target function. In cryptology, it is important to study how\nmany queries are required to find $l$-collisions for random functions of which\ndomains are larger than ranges. The previous algorithm finds an $l$-collision\nfor a random function by recursively calling the algorithm for finding\n$(l-1)$-collisions, and it achieves the average quantum query complexity of\n$O(N^{(3^{l-1}-1) / (2 \\cdot 3^{l-1})})$, where $N$ is the range size of target\nfunctions. The new algorithm removes the redundancy of the previous recursive\nalgorithm so that different recursive calls can share a part of computations.\nThe new algorithm finds an $l$-collision for random functions with the average\nquantum query complexity of $O(N^{(2^{l-1}-1) / (2^{l}-1)})$, which improves\nthe previous bound for all $l\\ge 3$ (the new and previous algorithms achieve\nthe optimal bound for $l=2$). More generally, the new algorithm achieves the\naverage quantum query complexity of $O\\left(c^{3/2}_N N^{\\frac{2^{l-1}-1}{\n2^{l}-1}}\\right)$ for a random function $f\\colon X\\to Y$ such that $|X| \\geq l\n\\cdot |Y| / c_N$ for any $1\\le c_N \\in o(N^{\\frac{1}{2^l - 1}})$. With the same\nquery complexity, it also finds a multiclaw for random functions, which is\nharder to find than a multicollision.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 07:10:45 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 11:56:56 GMT"}, {"version": "v3", "created": "Mon, 28 Jan 2019 09:37:23 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Hosoyamada", "Akinori", ""], ["Sasaki", "Yu", ""], ["Tani", "Seiichiro", ""], ["Xagawa", "Keita", ""]]}, {"id": "1811.08132", "submitter": "Zongxiang Yi", "authors": "Zongxiang Yi, Dingyi Pei and ChunmingTang", "title": "The Zero-Difference Properties of Functions and Their Applications", "comments": "rewrite again; add more results; add more examples", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A function $f$ from an Abelian group $(A,+)$ to an Abelian group $(B,+)$ is\n$(n, m, S)$ zero-difference (ZD), if $S=\\{\\lambda_\\alpha \\mid \\alpha \\in\nA\\setminus\\{0\\}\\}$ where $n=|A|$, $m=|f(A)|$ and $\\lambda_\\alpha=|\\{x \\in A\n\\mid f(x+\\alpha)=f(x)\\}|$. A function is called zero-difference balanced (ZDB)\nif $S=\\{\\lambda\\}$ where $\\lambda$ is a constant number. ZDB functions have\nmany good applications. However it is point out that many known zero-difference\nbalanced functions are already given in the language of partitioned difference\nfamily (PDF). The problem that whether zero-difference \"not balanced\" functions\nstill have good applications as ZDB functions, is investigated in this paper.\nBy using the change point technic, zero-difference functions with good\napplications are constructed from known ZDB function. Then optimal difference\nsystems of sets (DSS) and optimal frequency-hopping sequences (FHS) are\nobtained with new parameters. Furthermore the sufficient and necessary\nconditions of these being optimal, are given.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 09:07:44 GMT"}, {"version": "v2", "created": "Thu, 6 Dec 2018 06:18:21 GMT"}, {"version": "v3", "created": "Fri, 14 Dec 2018 04:45:38 GMT"}, {"version": "v4", "created": "Mon, 7 Jan 2019 02:36:56 GMT"}, {"version": "v5", "created": "Tue, 26 Mar 2019 10:45:33 GMT"}, {"version": "v6", "created": "Fri, 28 Jun 2019 16:00:44 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Yi", "Zongxiang", ""], ["Pei", "Dingyi", ""], ["ChunmingTang", "", ""]]}, {"id": "1811.08180", "submitter": "Ning Yu", "authors": "Ning Yu, Larry Davis, Mario Fritz", "title": "Attributing Fake Images to GANs: Learning and Analyzing GAN Fingerprints", "comments": "Accepted to ICCV'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.CY cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in Generative Adversarial Networks (GANs) have shown\nincreasing success in generating photorealistic images. But they also raise\nchallenges to visual forensics and model attribution. We present the first\nstudy of learning GAN fingerprints towards image attribution and using them to\nclassify an image as real or GAN-generated. For GAN-generated images, we\nfurther identify their sources. Our experiments show that (1) GANs carry\ndistinct model fingerprints and leave stable fingerprints in their generated\nimages, which support image attribution; (2) even minor differences in GAN\ntraining can result in different fingerprints, which enables fine-grained model\nauthentication; (3) fingerprints persist across different image frequencies and\npatches and are not biased by GAN artifacts; (4) fingerprint finetuning is\neffective in immunizing against five types of adversarial image perturbations;\nand (5) comparisons also show our learned fingerprints consistently outperform\nseveral baselines in a variety of setups.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 11:11:21 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2019 13:19:40 GMT"}, {"version": "v3", "created": "Fri, 16 Aug 2019 17:11:32 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Yu", "Ning", ""], ["Davis", "Larry", ""], ["Fritz", "Mario", ""]]}, {"id": "1811.08234", "submitter": "Abhishek Bichhawat", "authors": "Abhishek Bichhawat and Matt Fredrikson and Jean Yang and Akash Trehan", "title": "Contextual and Granular Policy Enforcement in Database-backed\n  Applications", "comments": null, "journal-ref": null, "doi": "10.1145/3320269.3384759", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Database-backed applications rely on inlined policy checks to process users'\nprivate and confidential data in a policy-compliant manner as traditional\ndatabase access control mechanisms cannot enforce complex policies. However,\napplication bugs due to missed checks are common in such applications, which\nresult in data breaches. While separating policy from code is a natural\nsolution, many data protection policies specify restrictions based on the\ncontext in which data is accessed and how the data is used. Enforcing these\nrestrictions automatically presents significant challenges, as the information\nneeded to determine context requires a tight coupling between policy\nenforcement and an application's implementation. We present Estrela, a\nframework for enforcing contextual and granular data access policies. Working\nfrom the observation that API endpoints can be associated with salient\ncontextual information in most database-backed applications, Estrela allows\ndevelopers to specify API-specific restrictions on data access and use. Estrela\nprovides a clean separation between policy specification and the application's\nimplementation, which facilitates easier auditing and maintenance of policies.\nPolicies in Estrela consist of pre-evaluation and post-evaluation conditions,\nwhich provide the means to modulate database access before a query is issued,\nand to impose finer-grained constraints on information release after the\nevaluation of query, respectively. We build a prototype of Estrela and apply it\nto retrofit several real world applications (from 1000-80k LOC) to enforce\ndifferent contextual policies. Our evaluation shows that Estrela can enforce\npolicies with minimal overheads.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 13:18:47 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 15:23:31 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 15:18:41 GMT"}, {"version": "v4", "created": "Fri, 13 Mar 2020 19:09:27 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Bichhawat", "Abhishek", ""], ["Fredrikson", "Matt", ""], ["Yang", "Jean", ""], ["Trehan", "Akash", ""]]}, {"id": "1811.08257", "submitter": "Shaohua Li", "authors": "Shaohua Li, Kaiping Xue, Chenkai Ding, Xindi Gao, David S L Wei, Tao\n  Wan, Feng Wu", "title": "FALCON: A Fourier Transform Based Approach for Fast and Secure\n  Convolutional Neural Network Predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning as a service has been widely deployed to utilize deep neural\nnetwork models to provide prediction services. However, this raises privacy\nconcerns since clients need to send sensitive information to servers. In this\npaper, we focus on the scenario where clients want to classify private images\nwith a convolutional neural network model hosted in the server, while both\nparties keep their data private. We present FALCON, a fast and secure approach\nfor CNN predictions based on Fourier Transform. Our solution enables linear\nlayers of a CNN model to be evaluated simply and efficiently with fully\nhomomorphic encryption. We also introduce the first efficient and\nprivacy-preserving protocol for softmax function, which is an indispensable\ncomponent in CNNs and has not yet been evaluated in previous works due to its\nhigh complexity. We implemented the FALCON and evaluated the performance on\nreal-world CNN models. The experimental results show that FALCON outperforms\nthe best known works in both computation and communication cost.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 14:13:33 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Li", "Shaohua", ""], ["Xue", "Kaiping", ""], ["Ding", "Chenkai", ""], ["Gao", "Xindi", ""], ["Wei", "David S L", ""], ["Wan", "Tao", ""], ["Wu", "Feng", ""]]}, {"id": "1811.08263", "submitter": "Qianlan Bai", "authors": "Qianlan Bai and Xinyan Zhou and Xing Wang and Yuedong Xu and Xin Wang\n  and Qingsheng Kong", "title": "A Deep Dive into Blockchain Selfish Mining", "comments": "6 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a fundamental problem regarding the security of blockchain\non how the existence of multiple misbehaving pools influences the profitability\nof selfish mining. Each selfish miner maintains a private chain and makes it\npublic opportunistically for the purpose of acquiring more rewards\nincommensurate to his Hashrate. We establish a novel Markov chain model to\ncharacterize all the state transitions of public and private chains. The\nminimum requirement of Hashrate together with the minimum delay of being\nprofitable is derived in close-form. The former reduces to 21.48% with the\nsymmetric selfish miners, while their competition with asymmetric Hashrates\nputs forward a higher requirement of the profitable threshold. The profitable\ndelay increases with the decrease of the Hashrate of selfish miners, making the\nmining pools more cautious on performing selfish mining.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 07:02:02 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Bai", "Qianlan", ""], ["Zhou", "Xinyan", ""], ["Wang", "Xing", ""], ["Xu", "Yuedong", ""], ["Wang", "Xin", ""], ["Kong", "Qingsheng", ""]]}, {"id": "1811.08271", "submitter": "Zhitao Guan", "authors": "Jing Li, Zhitao Guan, Xiaojiang Du, Zijian Zhang, Zhenyu Zhou", "title": "A Low-latency Secure Data Outsourcing Scheme for Cloud-WSN", "comments": "arXiv admin note: text overlap with arXiv:1810.10746", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the support of cloud computing, large quantities of data collected from\nvarious WSN applications can be managed efficiently. However, maintaining data\nsecurity and efficiency of data processing in cloud-WSN (C-WSN) are important\nand challenging issues. In this paper, we present an efficient data outsourcing\nscheme based on CP-ABE, which can not only guarantee secure data access, but\nalso reduce overall data processing time. In our proposed scheme, a large file\nis divided into several data blocks by data owner (DO) firstly. Then, the data\nblocks are encrypted and transferred to the cloud server in parallel. For data\nreceiver (DR), data decryption and data transmission is also processed in\nparallel. In addition, data integrity can be checked by DR without any master\nkey components. The security analysis shows that the proposed scheme can meet\nthe security requirement of C-WSN. By performance evaluation, it shows that our\nscheme can dramatically improve data processing efficiency compared to the\ntraditional CP-ABE method.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 07:49:13 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Li", "Jing", ""], ["Guan", "Zhitao", ""], ["Du", "Xiaojiang", ""], ["Zhang", "Zijian", ""], ["Zhou", "Zhenyu", ""]]}, {"id": "1811.08360", "submitter": "Kostantinos Papadamou Mr", "authors": "Kostantinos Papadamou and Savvas Zannettou and Bogdan Chifor and Sorin\n  Teican and George Gugulea and Annamaria Recupero and Alberto Caponi and\n  Claudio Pisa and Giuseppe Bianchi and Steven Gevers and Christos Xenakis and\n  Michael Sirivianos", "title": "Killing the Password and Preserving Privacy with Device-Centric and\n  Attribute-based Authentication", "comments": "This paper has been accepted for publication in IEEE Transactions on\n  Information Forensics and Security. Content is final as presented here, with\n  the exception of pagination. IEEE Copyright Notice: Copyright (c) 2019 IEEE.\n  Personal use is permitted. For any other purposes, permission must be\n  obtained from the IEEE by emailing pubs-permissions@ieee.org", "journal-ref": null, "doi": "10.1109/TIFS.2019.2958763", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current authentication methods on the Web have serious weaknesses. First,\nservices heavily rely on the traditional password paradigm, which diminishes\nthe end-users' security and usability. Second, the lack of attribute-based\nauthentication does not allow anonymity-preserving access to services. Third,\nusers have multiple online accounts that often reflect distinct identity\naspects. This makes proving combinations of identity attributes hard on the\nusers.\n  In this paper, we address these weaknesses by proposing a privacy-preserving\narchitecture for device-centric and attribute-based authentication based on: 1)\nthe seamless integration between usable/strong device-centric authentication\nmethods and federated login solutions; 2) the separation of the concerns for\nAuthorization, Authentication, Behavioral Authentication and Identification to\nfacilitate incremental deployability, wide adoption and compliance with NIST\nassurance levels; and 3) a novel centralized component that allows end-users to\nperform identity profile and consent management, to prove combinations of\nfragmented identity aspects, and to perform account recovery in case of device\nloss. To the best of our knowledge, this is the first effort towards fusing the\naforementioned techniques under an integrated architecture. This architecture\neffectively deems the password paradigm obsolete with minimal modification on\nthe service provider's software stack.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 16:46:59 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 23:19:35 GMT"}, {"version": "v3", "created": "Thu, 16 Jan 2020 13:34:17 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Papadamou", "Kostantinos", ""], ["Zannettou", "Savvas", ""], ["Chifor", "Bogdan", ""], ["Teican", "Sorin", ""], ["Gugulea", "George", ""], ["Recupero", "Annamaria", ""], ["Caponi", "Alberto", ""], ["Pisa", "Claudio", ""], ["Bianchi", "Giuseppe", ""], ["Gevers", "Steven", ""], ["Xenakis", "Christos", ""], ["Sirivianos", "Michael", ""]]}, {"id": "1811.08507", "submitter": "Sachin Taneja", "authors": "Sachin Taneja, Massimo Alioto", "title": "Ultra-Low Power Crypto-Engine Based on Simon 32/64 for Energy- and\n  Area-Constrained Integrated Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an ultra-low power crypto-engine achieving sub-pJ/bit\nenergy and sub-1K$\\mu$$m^2$ in 40nm CMOS, based on the Simon cryptographic\nalgorithm. Energy and area efficiency are pursued via microarchitectural\nexploration, ultra-low voltage operation with high resiliency via latch-based\npipelines, and power reduction techniques via multi-bit sequential elements.\nOverall, the comparison with the state of the art shows best-in-class energy\nefficiency and area. This makes it well suited for ubiquitous security in\ntightly-constrained platforms, e.g. RFIDs, low-end sensor nodes.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 17:00:06 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Taneja", "Sachin", ""], ["Alioto", "Massimo", ""]]}, {"id": "1811.08531", "submitter": "Kamer Vishi", "authors": "Nils Gruschka, Vasileios Mavroeidis, Kamer Vishi, Meiko Jensen", "title": "Privacy Issues and Data Protection in Big Data: A Case Study Analysis\n  under GDPR", "comments": "7 pages, 1 figure, GDPR, Privacy, Cyber Threat Intelligence,\n  Biometrics. To be appeared in the Proceedings of the 2018 IEEE International\n  Conference on Big Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Big data has become a great asset for many organizations, promising improved\noperations and new business opportunities. However, big data has increased\naccess to sensitive information that when processed can directly jeopardize the\nprivacy of individuals and violate data protection laws. As a consequence, data\ncontrollers and data processors may be imposed tough penalties for\nnon-compliance that can result even to bankruptcy. In this paper, we discuss\nthe current state of the legal regulations and analyze different data\nprotection and privacy-preserving techniques in the context of big data\nanalysis. In addition, we present and analyze two real-life research projects\nas case studies dealing with sensitive data and actions for complying with the\ndata regulation laws. We show which types of information might become a privacy\nrisk, the employed privacy-preserving techniques in accordance with the legal\nrequirements, and the influence of these techniques on the data processing\nphase and the research results.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 23:42:12 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Gruschka", "Nils", ""], ["Mavroeidis", "Vasileios", ""], ["Vishi", "Kamer", ""], ["Jensen", "Meiko", ""]]}, {"id": "1811.08569", "submitter": "Robert Annessi", "authors": "Robert Annessi, Joachim Fabini, Felix Iglesias, and Tanja Zseby", "title": "Encryption is Futile: Delay Attacks on High-Precision Clock\n  Synchronization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clock synchronization has become essential to modern societies since many\ncritical infrastructures depend on a precise notion of time. This paper\nanalyzes security aspects of high-precision clock synchronization protocols,\nparticularly their alleged protection against delay attacks when clock\nsynchronization traffic is encrypted using standard network security protocols\nsuch as IPsec, MACsec, or TLS. We use the Precision Time Protocol (PTP), the\nmost widely used protocol for high-precision clock synchronization, to\ndemonstrate that statistical traffic analysis can identify properties that\nsupport selective message delay attacks even for encrypted traffic. We\nfurthermore identify a fundamental conflict in secure clock synchronization\nbetween the need of deterministic traffic to improve precision and the need to\nobfuscate traffic in order to mitigate delay attacks.\n  A theoretical analysis of clock synchronization protocols isolates the\ncharacteristics that make these protocols vulnerable to delay attacks and\nargues that such attacks cannot be prevented entirely but only be mitigated.\nKnowledge of the underlying communication network in terms of one-way delays\nand knowledge on physical constraints of these networks can help to compute\nguaranteed maximum bounds for slave clock offsets. These bounds are essential\nfor detecting delay attacks and minimizing their impact. In the general case,\nhowever, the precision that can be guaranteed in adversarial settings is orders\nof magnitude lower than required for high-precision clock synchronization in\ncritical infrastructures, which, therefore, must not rely on a precise notion\nof time when using untrusted networks.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 02:29:02 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Annessi", "Robert", ""], ["Fabini", "Joachim", ""], ["Iglesias", "Felix", ""], ["Zseby", "Tanja", ""]]}, {"id": "1811.08572", "submitter": "Matt Weinberg", "authors": "Nick Arnosti, S. Matthew Weinberg", "title": "Bitcoin: A Natural Oligopoly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although Bitcoin was intended to be a decentralized digital currency, in\npractice, mining power is quite concentrated. This fact is a persistent source\nof concern for the Bitcoin community.\n  We provide an explanation using a simple model to capture miners' incentives\nto invest in equipment. In our model, $n$ miners compete for a prize of fixed\nsize. Each miner chooses an investment $q_i$, incurring cost $c_i q_i$, and\nthen receives reward $\\frac{q_i^\\alpha}{\\sum_j q_j^\\alpha}$, for some $\\alpha\n\\geq 1$. When $c_i = c_j$ for all $i,j$, and $\\alpha = 1$, there is a unique\nequilibrium where all miners invest equally. However, we prove that under\nseemingly mild deviations from this model, equilibrium outcomes become\ndrastically more centralized. In particular, (a) When costs are asymmetric, if\nminer $i$ chooses to invest, then miner $j$ has market share at least\n$1-\\frac{c_j}{c_i}$. That is, if miner $j$ has costs that are (e.g.) $20\\%$\nlower than those of miner $i$, then miner $j$ must control at least $20\\%$ of\nthe \\emph{total} mining power. (b) In the presence of economies of scale\n($\\alpha > 1$), every market participant has a market share of at least\n$1-\\frac{1}{\\alpha}$, implying that the market features at most\n$\\frac{\\alpha}{\\alpha - 1}$ miners in total.\n  We discuss the implications of our results for the future design of\ncryptocurrencies. In particular, our work further motivates the study of\nprotocols that minimize \"orphaned\" blocks, proof-of-stake protocols, and\nincentive compatible protocols.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 02:41:52 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Arnosti", "Nick", ""], ["Weinberg", "S. Matthew", ""]]}, {"id": "1811.08641", "submitter": "Wei Rong", "authors": "Wei Rong, Bowen Zhang, Xixiang Lv", "title": "Malicious Web Request Detection Using Character-level CNN", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Web parameter injection attacks are common and powerful. In this kind of\nattacks, malicious attackers can employ HTTP requests to implement attacks\nagainst servers by injecting some malicious codes into the parameters of the\nHTTP requests. Against the web parameter injection attacks, most of the\nexisting Web Intrusion Detection Systems (WIDS) cannot find unknown new attacks\nand have a high false positive rate (FPR), since they lack the ability of\nre-learning and rarely pay attention to the intrinsic relationship between the\ncharacters. In this paper, we propose a malicious requests detection system\nwith re-learning ability based on an improved convolution neural network (CNN)\nmodel. We add a character-level embedding layer before the convolution layer,\nwhich makes our model able to learn the intrinsic relationship between the\ncharacters of the query string. Further, we modify the filters of CNN and the\nmodified filters can extract the fine-grained features of the query string. The\ntest results demonstrate that our model has lower FPR compared with support\nvector machine (SVM) and random forest (RF).\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 09:07:52 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Rong", "Wei", ""], ["Zhang", "Bowen", ""], ["Lv", "Xixiang", ""]]}, {"id": "1811.08660", "submitter": "Tobias Urban", "authors": "Tobias Urban, Dennis Tatang, Martin Degeling, Thorsten Holz, Norbert\n  Pohlmann", "title": "The Unwanted Sharing Economy: An Analysis of Cookie Syncing and User\n  Transparency under GDPR", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The European General Data Protection Regulation (GDPR), which went into\neffect in May 2018, leads to important changes in this area: companies are now\nrequired to ask for users' consent before collecting and sharing personal data\nand by law users now have the right to gain access to the personal information\ncollected about them.\n  In this paper, we study and evaluate the effect of the GDPR on the online\nadvertising ecosystem. In a first step, we measure the impact of the\nlegislation on the connections (regarding cookie syncing) between third-parties\nand show that the general structure how the entities are arranged is not\naffected by the GDPR. However, we find that the new regulation has a\nstatistically significant impact on the number of connections, which shrinks by\naround 40%. Furthermore, we analyze the right to data portability by evaluating\nthe subject access right process of popular companies in this ecosystem and\nobserve differences between the processes implemented by the companies and how\nthey interpret the new legislation. We exercised our right of access under GDPR\nwith 36 companies that had tracked us online. Although 32 companies (89%) we\ninquired replied within the period defined by law, only 21 (58%) finished the\nprocess by the deadline set in the GDPR. Our work has implications regarding\nthe implementation of privacy law as well as what online tracking companies\nshould do to be more compliant with the new regulation.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 10:09:54 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Urban", "Tobias", ""], ["Tatang", "Dennis", ""], ["Degeling", "Martin", ""], ["Holz", "Thorsten", ""], ["Pohlmann", "Norbert", ""]]}, {"id": "1811.08705", "submitter": "Joewie Koh", "authors": "Joewie J. Koh and Barton Rhodes", "title": "Inline Detection of Domain Generation Algorithms with Context-Sensitive\n  Word Embeddings", "comments": "6 pages, 5 figures, 2 tables", "journal-ref": "Proceedings of the 2018 IEEE International Conference on Big Data,\n  2018, pp. 2966-2971", "doi": "10.1109/BigData.2018.8622066", "report-no": null, "categories": "cs.CR cs.CL cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain generation algorithms (DGAs) are frequently employed by malware to\ngenerate domains used for connecting to command-and-control (C2) servers.\nRecent work in DGA detection leveraged deep learning architectures like\nconvolutional neural networks (CNNs) and character-level long short-term memory\nnetworks (LSTMs) to classify domains. However, these classifiers perform poorly\nwith wordlist-based DGA families, which generate domains by pseudorandomly\nconcatenating dictionary words. We propose a novel approach that combines\ncontext-sensitive word embeddings with a simple fully-connected classifier to\nperform classification of domains based on word-level information. The word\nembeddings were pre-trained on a large unrelated corpus and left frozen during\nthe training on domain data. The resulting small number of trainable parameters\nenabled extremely short training durations, while the transfer of language\nknowledge stored in the representations allowed for high-performing models with\nsmall training datasets. We show that this architecture reliably outperformed\nexisting techniques on wordlist-based DGA families with just 30 DGA training\nexamples and achieved state-of-the-art performance with around 100 DGA training\nexamples, all while requiring an order of magnitude less time to train compared\nto current techniques. Of special note is the technique's performance on the\nmatsnu DGA: the classifier attained a 89.5% detection rate with a 1:1,000 false\npositive rate (FPR) after training on only 30 examples of the DGA domains, and\na 91.2% detection rate with a 1:10,000 FPR after 90 examples. Considering that\nsome of these DGAs have wordlists of several hundred words, our results\ndemonstrate that this technique does not rely on the classifier learning the\nDGA wordlists. Instead, the classifier is able to learn the semantic signatures\nof the wordlist-based DGA families.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 12:14:12 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Koh", "Joewie J.", ""], ["Rhodes", "Barton", ""]]}, {"id": "1811.08951", "submitter": "Xiaopeng Li", "authors": "Xiaopeng Li, Xianshan Qu, Wenyuan Xu, Song Wang, Yan Tong and Lannan\n  Luo", "title": "Validating the Contextual Information of Outdoor Images for Photo Misuse\n  Detection", "comments": "An extension of our conference paper 'Are You Lying: Validating the\n  Time-Location of Outdoor Images'", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The contextual information (i.e., the time and location) in which a photo is\ntaken can be easily tampered with or falsely claimed by forgers to achieve\nmalicious purposes, e.g., creating fear among the general public. A rich body\nof work has focused on detecting photo tampering and manipulation by verifying\nthe integrity of image content. Instead, we aim to detect photo misuse by\nverifying the capture time and location of photos. This paper is motivated by\nthe law of nature that sun position varies with the time and location, which\ncan be used to determine whether the claimed contextual information corresponds\nwith the sun position that the image content actually indicates. Prior\napproaches to inferring sun position from images mainly rely on vanishing\npoints associated with at least two shadows, while we propose novel algorithms\nwhich utilize only one shadow in the image to infer the sun position.\nMeanwhile, we compute the sun position by applying astronomical algorithms\nwhich take as input the claimed capture time and location. Only when the two\nestimated sun positions are consistent can the claimed contextual information\nbe genuine. We have developed a prototype called IMAGEGUARD. The experimental\nresults show that our method can successfully estimate sun position and detect\nthe time-location inconsistency with high accuracy. By setting the thresholds\nto be 9.4 degrees and 5 degrees for the sun position distance and the altitude\nangle distance, respectively, our system can correctly identify 91.5% of\nfalsified photos with fake contextual information.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 21:08:07 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Li", "Xiaopeng", ""], ["Qu", "Xianshan", ""], ["Xu", "Wenyuan", ""], ["Wang", "Song", ""], ["Tong", "Yan", ""], ["Luo", "Lannan", ""]]}, {"id": "1811.08954", "submitter": "Mouhammd Alkasassbeh", "authors": "Mohammad Almseidin, Mouhammd Alkasassbeh, Szilveszter Kovacs", "title": "Fuzzy Rule Interpolation and SNMP-MIB for Emerging Network Abnormality", "comments": "10", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is difficult to implement an efficient detection approach for Intrusion\nDetection Systems (IDS) and many factors contribute to this challenge. One such\nchallenge concerns establishing adequate boundaries and finding a proper data\nsource. Typical IDS detection approaches deal with raw traffics. These traffics\nneed to be studied in depth and thoroughly investigated in order to extract the\nrequired knowledge base. Another challenge involves implementing the binary\ndecision. This is because there are no reasonable limits between normal and\nattack traffics patterns. In this paper, we introduce a novel idea capable of\nsupporting the proper data source while avoiding the issues associated with the\nbinary decision. This paper aims to introduce a detection approach for defining\nabnormality by using the Fuzzy Rule Interpolation (FRI) with Simple Network\nManagement Protocol (SNMP) Management Information Base (MIB) parameters. The\nstrength of the proposed detection approach is based on adapting the SNMP-MIB\nparameters with the FRI. This proposed method eliminates the raw traffic\nprocessing component which is time consuming and requires extensive\ncomputational measures. It also eliminates the need for a complete fuzzy rule\nbased intrusion definition. The proposed approach was tested and evaluated\nusing an open source SNMP-MIB dataset and obtained a 93% detection rate.\nAdditionally, when compared to other literature in which the same test-bed\nenvironment was employed along with the same number of parameters, the proposed\ndetection approach outperformed the support vector machine and neural network.\nTherefore, combining the SNMP-MIB parameters with the FRI based reasoning could\nbe beneficial for detecting intrusions, even in the case if the fuzzy rule\nbased intrusion definition is incomplete (not fully defined).\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 21:17:58 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Almseidin", "Mohammad", ""], ["Alkasassbeh", "Mouhammd", ""], ["Kovacs", "Szilveszter", ""]]}, {"id": "1811.09024", "submitter": "Nalin Asanka Gamagedara Arachchilage", "authors": "Gitanjali Baral and Nalin Asanka Gamagedara Arachchilage", "title": "Building Confidence not to be Phished through a Gamified Approach:\n  Conceptualising User's Self-Efficacy in Phishing Threat Avoidance Behaviour", "comments": "15", "journal-ref": "International Conferences on Cyber Security and Communication\n  Systems (ICCSCS2018), 2018", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phishing attacks are prevalent and humans are central to this online identity\ntheft attack, which aims to steal victims' sensitive and personal information\nsuch as username, password, and online banking details. There are many\nanti-phishing tools developed to thwart against phishing attacks. Since humans\nare the weakest link in phishing, it is important to educate them to detect and\navoid phishing attacks. One can argue self-efficacy is one of the most\nimportant determinants of individual's motivation in phishing threat avoidance\nbehavior, which has co-relation with knowledge. The proposed research endeavors\non the user's self-efficacy in order to enhance the individual's phishing\nthreat avoidance behavior through their motivation. Using social cognitive\ntheory, we explored that various knowledge attributes such as observational\n(vicarious) knowledge, heuristic knowledge and structural knowledge contributes\nimmensely towards the individual's self-efficacy to enhance phishing threat\nprevention behavior. A theoretical framework is then developed depicting the\nmechanism that links knowledge attributes, self-efficacy, threat avoidance\nmotivation that leads to users' threat avoidance behavior. Finally, a gaming\nprototype is designed incooperating the knowledge elements identified in this\nresearch that aimed to enhance individual's self-efficacy in phishing threat\navoidance behavior.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 05:17:00 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Baral", "Gitanjali", ""], ["Arachchilage", "Nalin Asanka Gamagedara", ""]]}, {"id": "1811.09144", "submitter": "Gerard Memmi P", "authors": "Katarzyna Kapusta and Gerard Memmi", "title": "PE-AONT: Partial Encryption combined with an All-or-Nothing Transform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report, we introduce PE-AONT: a novel algorithm for fast and secure\ndata fragmentation. Initial data are fragmented and only a selected subset of\nthe fragments is encrypted. Further, fragments are transformed using a\nvariation of an all-or-nothing transform that blends encrypted and\nnon-encrypted fragments. By encrypting data only partially, we achieve better\nperformance than relevant techniques including data encryption and\nstraightforward fragmentation. Moreover, when the ratio between the number of\nencrypted and non-encrypted fragments is wisely chosen, data inside fragments\nare protected against exposure of the encryption key unless all fragments are\ngathered by an attacker.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 12:50:03 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Kapusta", "Katarzyna", ""], ["Memmi", "Gerard", ""]]}, {"id": "1811.09189", "submitter": "Thomas Nyman", "authors": "Hans Liljestrand, Thomas Nyman, Kui Wang, Carlos Chinea Perez,\n  Jan-Erik Ekberg, N. Asokan", "title": "PAC it up: Towards Pointer Integrity using ARM Pointer Authentication", "comments": "Author's version of article to appear in USENIX Security 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Run-time attacks against programs written in memory-unsafe programming\nlanguages (e.g., C and C++) remain a prominent threat against computer systems.\nThe prevalence of techniques like return-oriented programming (ROP) in\nattacking real-world systems has prompted major processor manufacturers to\ndesign hardware-based countermeasures against specific classes of run-time\nattacks. An example is the recently added support for pointer authentication\n(PA) in the ARMv8-A processor architecture, commonly used in devices like\nsmartphones. PA is a low-cost technique to authenticate pointers so as to\nresist memory vulnerabilities. It has been shown to enable practical protection\nagainst memory vulnerabilities that corrupt return addresses or function\npointers. However, so far, PA has received very little attention as a general\npurpose protection mechanism to harden software against various classes of\nmemory attacks. In this paper, we use PA to build novel defenses against\nvarious classes of run-time attacks, including the first PA-based mechanism for\ndata pointer integrity. We present PARTS, an instrumentation framework that\nintegrates our PA-based defenses into the LLVM compiler and the GNU/Linux\noperating system and show, via systematic evaluation, that PARTS provides\nbetter protection than current solutions at a reasonable performance overhead\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 14:26:22 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 12:42:34 GMT"}, {"version": "v3", "created": "Mon, 18 Feb 2019 11:48:18 GMT"}, {"version": "v4", "created": "Fri, 24 May 2019 13:39:20 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Liljestrand", "Hans", ""], ["Nyman", "Thomas", ""], ["Wang", "Kui", ""], ["Perez", "Carlos Chinea", ""], ["Ekberg", "Jan-Erik", ""], ["Asokan", "N.", ""]]}, {"id": "1811.09239", "submitter": "Purdue University", "authors": "Umit Karabiyik, Kemal Akkaya", "title": "Digital Forensics for IoT and WSNs", "comments": "41 pages, 25 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, wireless sensor networks (WSNs) and Internet-of-Things\n(IoT) devices are proliferated in many domains including critical\ninfrastructures such as energy, transportation and manufacturing. Consequently,\nmost of the daily operations now rely on the data coming from wireless sensors\nor IoT devices and their actions. In addition, personal IoT devices are heavily\nused for social media applications, which connect people as well as all\ncritical infrastructures to each other under the cyber domain. However, this\nconnectedness also comes with the risk of increasing number of cyber attacks\nthrough WSNs and/or IoT. While a significant research has been dedicated to\nsecure WSN/IoT, this still indicates that there needs to be forensics\nmechanisms to be able to conduct investigations and analysis. In particular,\nunderstanding what has happened after a failure is crucial to many businesses,\nwhich rely on WSN/IoT applications. Therefore, there is a great interest and\nneed for understanding digital forensics applications in WSN and IoT realms.\nThis chapter fills this gap by providing an overview and classification of\ndigital forensics research and applications in these emerging domains in a\ncomprehensive manner. In addition to analyzing the technical challenges, the\nchapter provides a survey of the existing efforts from the device level to\nnetwork level while also pointing out future research opportunities.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 17:12:24 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Karabiyik", "Umit", ""], ["Akkaya", "Kemal", ""]]}, {"id": "1811.09300", "submitter": "Edward Grefenstette", "authors": "Edward Grefenstette, Robert Stanforth, Brendan O'Donoghue, Jonathan\n  Uesato, Grzegorz Swirszcz, Pushmeet Kohli", "title": "Strength in Numbers: Trading-off Robustness and Computation via\n  Adversarially-Trained Ensembles", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning has led to remarkable results on a number of challenging\nproblems, researchers have discovered a vulnerability of neural networks in\nadversarial settings, where small but carefully chosen perturbations to the\ninput can make the models produce extremely inaccurate outputs. This makes\nthese models particularly unsuitable for safety-critical application domains\n(e.g. self-driving cars) where robustness is extremely important. Recent work\nhas shown that augmenting training with adversarially generated data provides\nsome degree of robustness against test-time attacks. In this paper we\ninvestigate how this approach scales as we increase the computational budget\ngiven to the defender. We show that increasing the number of parameters in\nadversarially-trained models increases their robustness, and in particular that\nensembling smaller models while adversarially training the entire ensemble as a\nsingle model is a more efficient way of spending said budget than simply using\na larger single model. Crucially, we show that it is the adversarial training\nof the ensemble, rather than the ensembling of adversarially trained models,\nwhich provides robustness.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 20:32:58 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Grefenstette", "Edward", ""], ["Stanforth", "Robert", ""], ["O'Donoghue", "Brendan", ""], ["Uesato", "Jonathan", ""], ["Swirszcz", "Grzegorz", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1811.09310", "submitter": "Adnan Siraj Rakin", "authors": "Adnan Siraj Rakin and Zhezhi He, Deliang Fan", "title": "Parametric Noise Injection: Trainable Randomness to Improve Deep Neural\n  Network Robustness against Adversarial Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent development in the field of Deep Learning have exposed the underlying\nvulnerability of Deep Neural Network (DNN) against adversarial examples. In\nimage classification, an adversarial example is a carefully modified image that\nis visually imperceptible to the original image but can cause DNN model to\nmisclassify it. Training the network with Gaussian noise is an effective\ntechnique to perform model regularization, thus improving model robustness\nagainst input variation. Inspired by this classical method, we explore to\nutilize the regularization characteristic of noise injection to improve DNN's\nrobustness against adversarial attack. In this work, we propose\nParametric-Noise-Injection (PNI) which involves trainable Gaussian noise\ninjection at each layer on either activation or weights through solving the\nmin-max optimization problem, embedded with adversarial training. These\nparameters are trained explicitly to achieve improved robustness. To the best\nof our knowledge, this is the first work that uses trainable noise injection to\nimprove network robustness against adversarial attacks, rather than manually\nconfiguring the injected noise level through cross-validation. The extensive\nresults show that our proposed PNI technique effectively improves the\nrobustness against a variety of powerful white-box and black-box attacks such\nas PGD, C & W, FGSM, transferable attack and ZOO attack. Last but not the\nleast, PNI method improves both clean- and perturbed-data accuracy in\ncomparison to the state-of-the-art defense methods, which outperforms current\nunbroken PGD defense by 1.1 % and 6.8 % on clean test data and perturbed test\ndata respectively using Resnet-20 architecture.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 21:10:52 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Rakin", "Adnan Siraj", ""], ["He", "Zhezhi", ""], ["Fan", "Deliang", ""]]}, {"id": "1811.09322", "submitter": "Ricardo P\\'erez-Marco", "authors": "Cyril Grunspan, Ricardo P\\'erez-Marco", "title": "On Profitability of Trailing Mining", "comments": "19 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compute the revenue ratio of the Trail Stubborn mining strategy in the\nBitcoin network and compare its profitability to other block-withholding\nstrategies. We use for this martingale techniques and a classical analysis of\nthe hiker problem. In this strategy the attacker could find himself mining in a\nshorter fork, but we prove that for some parameter values it is still\nprofitable to not give up. This confirms previous numerical studies.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 23:06:26 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Grunspan", "Cyril", ""], ["P\u00e9rez-Marco", "Ricardo", ""]]}, {"id": "1811.09340", "submitter": "Ghazaleh Beigi", "authors": "Ghazaleh Beigi, Ruocheng Guo, Alexander Nou, Yanchao Zhang, Huan Liu", "title": "Protecting User Privacy: An Approach for Untraceable Web Browsing\n  History and Unambiguous User Profiles", "comments": "This paper is accepted in the 12th ACM International Conference on\n  Web Search and Data Mining (WSDM-2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The overturning of the Internet Privacy Rules by the Federal Communications\nCommissions (FCC) in late March 2017 allows Internet Service Providers (ISPs)\nto collect, share and sell their customers' Web browsing data without their\nconsent. With third-party trackers embedded on Web pages, this new rule has put\nuser privacy under more risk. The need arises for users on their own to protect\ntheir Web browsing history from any potential adversaries. Although some\navailable solutions such as Tor, VPN, and HTTPS can help users conceal their\nonline activities, their use can also significantly hamper personalized online\nservices, i.e., degraded utility. In this paper, we design an effective Web\nbrowsing history anonymization scheme, PBooster, aiming to protect users'\nprivacy while retaining the utility of their Web browsing history. The proposed\nmodel pollutes users' Web browsing history by automatically inferring how many\nand what links should be added to the history while addressing the\nutility-privacy trade-off challenge. We conduct experiments to validate the\nquality of the manipulated Web browsing history and examine the robustness of\nthe proposed approach for user privacy protection.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 01:43:01 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Beigi", "Ghazaleh", ""], ["Guo", "Ruocheng", ""], ["Nou", "Alexander", ""], ["Zhang", "Yanchao", ""], ["Liu", "Huan", ""]]}, {"id": "1811.09447", "submitter": "Marcel B\\\"ohme", "authors": "Van-Thuan Pham, Marcel B\\\"ohme, Andrew E. Santosa, Alexandru\n  R\\u{a}zvan C\\u{a}ciulescu, Abhik Roychoudhury", "title": "Smart Greybox Fuzzing", "comments": "Accepted IEEE Transactions on Software Engineering, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coverage-based greybox fuzzing (CGF) is one of the most successful methods\nfor automated vulnerability detection. Given a seed file (as a sequence of\nbits), CGF randomly flips, deletes or bits to generate new files. CGF\niteratively constructs (and fuzzes) a seed corpus by retaining those generated\nfiles which enhance coverage. However, random bitflips are unlikely to produce\nvalid files (or valid chunks in files), for applications processing complex\nfile formats.\n  In this work, we introduce smart greybox fuzzing (SGF) which leverages a\nhigh-level structural representation of the seed file to generate new files. We\ndefine innovative mutation operators that work on the virtual file structure\nrather than on the bit level which allows SGF to explore completely new input\ndomains while maintaining file validity. We introduce a novel validity-based\npower schedule that enables SGF to spend more time generating files that are\nmore likely to pass the parsing stage of the program, which can expose\nvulnerabilities much deeper in the processing logic.\n  Our evaluation demonstrates the effectiveness of SGF. On several libraries\nthat parse structurally complex files, our tool AFLSmart explores substantially\nmore paths (up to 200%) and exposes more vulnerabilities than baseline AFL. Our\ntool AFLSmart has discovered 42 zero-day vulnerabilities in widely-used,\nwell-tested tools and libraries; so far 17 CVEs were assigned.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 12:14:34 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Pham", "Van-Thuan", ""], ["B\u00f6hme", "Marcel", ""], ["Santosa", "Andrew E.", ""], ["C\u0103ciulescu", "Alexandru R\u0103zvan", ""], ["Roychoudhury", "Abhik", ""]]}, {"id": "1811.09570", "submitter": "Aditya Sundararajan", "authors": "Aditya Sundararajan and Tanwir Khan and Amir Moghadasi and Arif I.\n  Sarwat", "title": "A Survey on Synchrophasor Data Quality and Cybersecurity Challenges, and\n  Evaluation of their Interdependencies", "comments": "18 pages", "journal-ref": null, "doi": "10.1007/s40565-018-0473-6", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Synchrophasor devices guarantee situation awareness for real-time monitoring\nand operational visibility of the smart grid. With their widespread\nimplementation, significant challenges have emerged, especially in\ncommunication, data quality and cybersecurity. The existing literature treats\nthese challenges as separate problems, when in reality, they have a complex\ninterplay. This paper conducts a comprehensive review of quality and\ncybersecurity challenges for synchrophasors, and identifies the\ninterdependencies between them. It also summarizes different methods used to\nevaluate the dependency and surveys how quality checking methods can be used to\ndetect potential cyber-attacks. In doing so, this paper serves as a starting\npoint for researchers entering the fields of synchrophasor data analytics and\nsecurity.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 17:25:54 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Sundararajan", "Aditya", ""], ["Khan", "Tanwir", ""], ["Moghadasi", "Amir", ""], ["Sarwat", "Arif I.", ""]]}, {"id": "1811.09581", "submitter": "Vladimir Edemskiy", "authors": "Vladimir Edemskiy", "title": "About the k-Error Linear Complexity over $\\mathbb{F}_p$ of sequences of\n  length 2$p$ with optimal three-level autocorrelation", "comments": null, "journal-ref": null, "doi": "10.1088/1742-6596/1352/1/012011", "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the $k$-error linear complexity over $\\mathbb{F}_p$ of binary\nsequences of length $2p$ with optimal three-level autocorrelation. These\nbalanced sequences are constructed by cyclotomic classes of order four using a\nmethod presented by Ding et al.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 17:55:44 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Edemskiy", "Vladimir", ""]]}, {"id": "1811.09600", "submitter": "Luiz Gustavo Hafemann", "authors": "J\\'er\\^ome Rony, Luiz G. Hafemann, Luiz S. Oliveira, Ismail Ben Ayed,\n  Robert Sabourin, Eric Granger", "title": "Decoupling Direction and Norm for Efficient Gradient-Based L2\n  Adversarial Attacks and Defenses", "comments": "Accepted as a conference paper to the 2019 IEEE/CVF Conference on\n  Computer Vision and Pattern Recognition (CVPR oral presentation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on adversarial examples in computer vision tasks has shown that\nsmall, often imperceptible changes to an image can induce misclassification,\nwhich has security implications for a wide range of image processing systems.\nConsidering $L_2$ norm distortions, the Carlini and Wagner attack is presently\nthe most effective white-box attack in the literature. However, this method is\nslow since it performs a line-search for one of the optimization terms, and\noften requires thousands of iterations. In this paper, an efficient approach is\nproposed to generate gradient-based attacks that induce misclassifications with\nlow $L_2$ norm, by decoupling the direction and the norm of the adversarial\nperturbation that is added to the image. Experiments conducted on the MNIST,\nCIFAR-10 and ImageNet datasets indicate that our attack achieves comparable\nresults to the state-of-the-art (in terms of $L_2$ norm) with considerably\nfewer iterations (as few as 100 iterations), which opens the possibility of\nusing these attacks for adversarial training. Models trained with our attack\nachieve state-of-the-art robustness against white-box gradient-based $L_2$\nattacks on the MNIST and CIFAR-10 datasets, outperforming the Madry defense\nwhen the attacks are limited to a maximum norm.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 18:54:47 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2018 21:11:22 GMT"}, {"version": "v3", "created": "Wed, 3 Apr 2019 21:11:11 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Rony", "J\u00e9r\u00f4me", ""], ["Hafemann", "Luiz G.", ""], ["Oliveira", "Luiz S.", ""], ["Ayed", "Ismail Ben", ""], ["Sabourin", "Robert", ""], ["Granger", "Eric", ""]]}, {"id": "1811.09680", "submitter": "Bhaskar Krishnamachari", "authors": "Yi Lucy Wang and Bhaskar Krishnamachari", "title": "Enhancing Engagement in Token-Curated Registries via an Inflationary\n  Mechanism", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Token Curated Registries (TCR) are decentralized recommendation systems that\ncan be implemented using Blockchain smart contracts. They allow participants to\nvote for or against adding items to a list through a process that involves\nstaking tokens intrinsic to the registry, with winners receiving the staked\ntokens for each vote. A TCR aims to provide incentives to create a well-curated\nlist. In this work, we consider a challenge for these systems - incentivizing\ntoken-holders to actually engage and participate in the voting process. We\npropose a novel token-inflation mechanism for enhancing engagement, whereby\nonly voting participants see their token supply increased by a pre-defined\nmultiple after each round of voting. To evaluate this proposal, we propose a\nsimple 4-class model of voters that captures all possible combinations of two\nkey dimensions: whether they are engaged (likely to vote at all for a given\nitem) or disengaged, and whether they are informed (likely to vote in a way\nthat increases the quality of the list) or uninformed, and a simple metric to\nevaluate the quality of the list as a function of the vote outcomes. We conduct\nsimulations using this model of voters and show that implementing\ntoken-inflation results in greater wealth accumulation for engaged voters. In\nparticular, when the number of informed voters is sufficiently high, our\nsimulations show that voters that are both informed and engaged see the\ngreatest benefits from participating in the registry when our proposed\ntoken-inflation mechanism is employed. We further validate this finding using a\nsimplified mathematical analysis.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 20:51:13 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Wang", "Yi Lucy", ""], ["Krishnamachari", "Bhaskar", ""]]}, {"id": "1811.09712", "submitter": "Clement Fung", "authors": "Clement Fung, Jamie Koerner, Stewart Grant, Ivan Beschastnikh", "title": "Dancing in the Dark: Private Multi-Party Machine Learning in an\n  Untrusted Setting", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed machine learning (ML) systems today use an unsophisticated threat\nmodel: data sources must trust a central ML process. We propose a brokered\nlearning abstraction that allows data sources to contribute towards a\nglobally-shared model with provable privacy guarantees in an untrusted setting.\nWe realize this abstraction by building on federated learning, the state of the\nart in multi-party ML, to construct TorMentor: an anonymous hidden service that\nsupports private multi-party ML.\n  We define a new threat model by characterizing, developing and evaluating new\nattacks in the brokered learning setting, along with new defenses for these\nattacks. We show that TorMentor effectively protects data providers against\nknown ML attacks while providing them with a tunable trade-off between model\naccuracy and privacy. We evaluate TorMentor with local and geo-distributed\ndeployments on Azure/Tor. In an experiment with 200 clients and 14 MB of data\nper client, our prototype trained a logistic regression model using stochastic\ngradient descent in 65s.\n  Code is available at: https://github.com/DistributedML/TorML\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 22:00:39 GMT"}, {"version": "v2", "created": "Sun, 24 Feb 2019 00:40:45 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Fung", "Clement", ""], ["Koerner", "Jamie", ""], ["Grant", "Stewart", ""], ["Beschastnikh", "Ivan", ""]]}, {"id": "1811.09767", "submitter": "Mohsen Amini Salehi", "authors": "Hoang Pham, Jason Woodworth, Mohsen Amini Salehi", "title": "Survey on Secure Search Over Encrypted Data on the Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing has become a potential resource for businesses and\nindividuals to outsource their data to remote but highly accessible servers.\nHowever, potentials of the cloud services have not been fully unleashed due to\nusers' concerns about security and privacy of their data in the cloud.\nUser-side encryption techniques can be employed to mitigate the security\nconcerns. Nonetheless, once the data in encrypted, no processing (e.g.,\nsearching) can be performed on the outsourced data. Searchable Encryption (SE)\ntechniques have been widely studied to enable searching on the data while they\nare encrypted. These techniques enable various types of search on the encrypted\ndata and offer different levels of security. In addition, although these\ntechniques enable different search types and vary in details, they share\nsimilarities in their components and architectures. In this paper, we provide a\ncomprehensive survey on different secure search techniques; a high-level\narchitecture for these systems, and an analysis of their performance and\nsecurity level.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 05:25:21 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Pham", "Hoang", ""], ["Woodworth", "Jason", ""], ["Salehi", "Mohsen Amini", ""]]}, {"id": "1811.09876", "submitter": "Vitaly Roman'kov", "authors": "Vitali\\u{i} Roman'kov", "title": "Cryptographic analysis of the Modified Matrix Modular Cryptosystem", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the Modified Matrix Modular Cryptosystem proposed by S.K.\nRososhek is not secure against the attack based on the linear decomposition\nmethod. The security of the encryption scheme in the Rososhek's system is based\non the mix of the conjugacy search problem and random \"salt\". We do not solve\nthe conjugacy search problem and we are not looking for the exact meaning of\nthe \"salt\". The transported secret message in the system is recovered without\ncomputation the secret parameters, that have been used for its encryption.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 14:13:37 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Roman'kov", "Vitali\u012d", ""]]}, {"id": "1811.09878", "submitter": "Karanbir Chahal", "authors": "Vaibhav Mathur and Karanbir Chahal", "title": "Hydra: A Peer to Peer Distributed Training & Data Collection Framework", "comments": "10 pages. arXiv admin note: text overlap with arXiv:1611.01578 by\n  other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The world needs diverse and unbiased data to train deep learning models.\nCurrently data comes from a variety of sources that are unmoderated to a large\nextent. The outcomes of training neural networks with unverified data yields\nbiased models with various strains of homophobia, sexism and racism. Another\ntrend observed in the world of deep learning is the rise of distributed\ntraining. Although cloud companies provide high performance compute for\ntraining models in the form of GPU's connected with a low latency network,\nusing these services comes at a high cost. We propose Hydra, a system that\nseeks to solve both of these problems in a novel manner by proposing a\ndecentralized distributed framework which utilizes the substantial amount of\nidle compute of everyday electronic devices like smartphones and desktop\ncomputers for training and data collection purposes. Hydra couples a\nspecialized distributed training framework on a network of these low powered\ndevices with a reward scheme that incentivizes users to provide high quality\ndata to unleash the compute capability on this training framework. Such a\nsystem has the ability to capture data from a wide variety of diverse sources\nwhich has been an issue in the current scenario of deep learning. Hydra brings\nin several new innovations in training on low powered devices including a fault\ntolerant version of the All Reduce algorithm. Furthermore we introduce a\nreinforcement learning policy to decide the size of training jobs on different\nmachines on a heterogeneous cluster of devices with varying network latencies\nfor Synchronous SGD. The novel thing about such a network is the ability of\neach machine to shut down and resume training capabilities at any point of time\nwithout restarting the overall training. To enable such an asynchronous\nbehaviour we propose a communication framework inspired by the Bittorrent\nprotocol and the Kademlia DHT.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 19:11:41 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Mathur", "Vaibhav", ""], ["Chahal", "Karanbir", ""]]}, {"id": "1811.09904", "submitter": "Muhammad Shayan", "authors": "Muhammad Shayan, Clement Fung, Chris J.M. Yoon, Ivan Beschastnikh", "title": "Biscotti: A Ledger for Private and Secure Peer-to-Peer Machine Learning", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning is the current state of the art in supporting secure\nmulti-party machine learning (ML): data is maintained on the owner's device and\nthe updates to the model are aggregated through a secure protocol. However,\nthis process assumes a trusted centralized infrastructure for coordination, and\nclients must trust that the central service does not use the byproducts of\nclient data. In addition to this, a group of malicious clients could also harm\nthe performance of the model by carrying out a poisoning attack.\n  As a response, we propose Biscotti: a fully decentralized peer to peer (P2P)\napproach to multi-party ML, which uses blockchain and cryptographic primitives\nto coordinate a privacy-preserving ML process between peering clients. Our\nevaluation demonstrates that Biscotti is scalable, fault tolerant, and defends\nagainst known attacks. For example, Biscotti is able to protect the privacy of\nan individual client's update and the performance of the global model at scale\nwhen 30% of adversaries are trying to poison the model.\n  The implementation can be found at: https://github.com/DistributedML/Biscotti\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 22:24:38 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 21:39:04 GMT"}, {"version": "v3", "created": "Sat, 23 Feb 2019 01:40:22 GMT"}, {"version": "v4", "created": "Thu, 12 Dec 2019 04:29:53 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Shayan", "Muhammad", ""], ["Fung", "Clement", ""], ["Yoon", "Chris J. M.", ""], ["Beschastnikh", "Ivan", ""]]}, {"id": "1811.09931", "submitter": "Songfeng Lu", "authors": "Qing Zhou, Songfeng Lu, Zhigang Zhang, Jie Sun", "title": "Quantum Differential Cryptanalysis", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a quantum version of the differential cryptanalysis\nwhich offers a quadratic speedup over the existing classical one and show the\nquantum circuit implementing it. The quantum differential cryptanalysis is\nbased on the quantum minimum/maximum-finding algorithm, where the values to be\ncompared and filtered are obtained by calling the quantum counting algorithm.\nAny cipher which is vulnerable to the classical differential cryptanalysis\nbased on counting procedures can be cracked more quickly under this quantum\ndifferential attack.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 02:23:34 GMT"}, {"version": "v2", "created": "Thu, 3 Jan 2019 02:39:02 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Zhou", "Qing", ""], ["Lu", "Songfeng", ""], ["Zhang", "Zhigang", ""], ["Sun", "Jie", ""]]}, {"id": "1811.09943", "submitter": "Muhammad Saad", "authors": "Muhammad Saad, Laurent Njilla, Charles Kamhoua, and Aziz Mohaisen", "title": "Countering Selfish Mining in Blockchains", "comments": "International Workshop on Computing, Networking and Communications\n  (CNC 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selfish mining is a well known vulnerability in blockchains exploited by\nminers to steal block rewards. In this paper, we explore a new form of selfish\nmining attack that guarantees high rewards with low cost. We show the\nfeasibility of this attack facilitated by recent developments in blockchain\ntechnology opening new attack avenues. By outlining the limitations of existing\ncountermeasures, we highlight a need for new defense strategies to counter this\nattack, and leverage key system parameters in blockchain applications to\npropose an algorithm that enforces fair mining. We use the expected transaction\nconfirmation height and block publishing height to detect selfish mining\nbehavior and develop a network-wide defense mechanism to disincentivize selfish\nminers. Our design involves a simple modifications to transactions' data\nstructure in order to obtain a \"truth state\" used to catch the selfish miners\nand prevent honest miners from losing block rewards.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 04:42:22 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2018 08:15:00 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Saad", "Muhammad", ""], ["Njilla", "Laurent", ""], ["Kamhoua", "Charles", ""], ["Mohaisen", "Aziz", ""]]}, {"id": "1811.09944", "submitter": "Muhammad Saad", "authors": "Ashar Ahmad, Muhammad Saad, Mostafa Bassiouni, and Aziz Mohaisen", "title": "Towards Blockchain-Driven, Secure and Transparent Audit Logs", "comments": "The 1st Workshop on Distributed Ledger of Things (DLOT 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audit logs serve as a critical component in the enterprise business systems\nthat are used for auditing, storing, and tracking changes made to the data.\nHowever, audit logs are vulnerable to a series of attacks, which enable\nadversaries to tamper data and corresponding audit logs. In this paper, we\npresent BlockAudit: a scalable and tamper-proof system that leverages the\ndesign properties of audit logs and security guarantees of blockchains to\nenable secure and trustworthy audit logs. Towards that, we construct the design\nschema of BlockAudit, and outline its operational procedures. We implement our\ndesign on Hyperledger and evaluate its performance in terms of latency, network\nsize, and payload size. Our results show that conventional audit logs can\nseamlessly transition into BlockAudit to achieve higher security, integrity,\nand fault tolerance.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 04:55:31 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Ahmad", "Ashar", ""], ["Saad", "Muhammad", ""], ["Bassiouni", "Mostafa", ""], ["Mohaisen", "Aziz", ""]]}, {"id": "1811.09951", "submitter": "Edward Chou Mr.", "authors": "Edward Chou, Thao Nguyen, Josh Beal, Albert Haque, Li Fei-Fei", "title": "A Fully Private Pipeline for Deep Learning on Electronic Health Records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an end-to-end private deep learning framework, applied to the\ntask of predicting 30-day readmission from electronic health records. By using\ndifferential privacy during training and homomorphic encryption during\ninference, we demonstrate that our proposed pipeline could maintain high\nperformance while providing robust privacy guarantees against information leak\nfrom data transmission or attacks against the model. We also explore several\ntechniques to address the privacy-utility trade-off in deploying neural\nnetworks with privacy mechanisms, improving the accuracy of\ndifferentially-private training and the computation cost of encrypted\noperations using ideas from both machine learning and cryptography.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 05:55:50 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Chou", "Edward", ""], ["Nguyen", "Thao", ""], ["Beal", "Josh", ""], ["Haque", "Albert", ""], ["Fei-Fei", "Li", ""]]}, {"id": "1811.09953", "submitter": "Edward Chou Mr.", "authors": "Edward Chou, Josh Beal, Daniel Levy, Serena Yeung, Albert Haque, Li\n  Fei-Fei", "title": "Faster CryptoNets: Leveraging Sparsity for Real-World Encrypted\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Homomorphic encryption enables arbitrary computation over data while it\nremains encrypted. This privacy-preserving feature is attractive for machine\nlearning, but requires significant computational time due to the large overhead\nof the encryption scheme. We present Faster CryptoNets, a method for efficient\nencrypted inference using neural networks. We develop a pruning and\nquantization approach that leverages sparse representations in the underlying\ncryptosystem to accelerate inference. We derive an optimal approximation for\npopular activation functions that achieves maximally-sparse encodings and\nminimizes approximation error. We also show how privacy-safe training\ntechniques can be used to reduce the overhead of encrypted inference for\nreal-world datasets by leveraging transfer learning and differential privacy.\nOur experiments show that our method maintains competitive accuracy and\nachieves a significant speedup over previous methods. This work increases the\nviability of deep learning systems that use homomorphic encryption to protect\nuser privacy.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 05:56:18 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Chou", "Edward", ""], ["Beal", "Josh", ""], ["Levy", "Daniel", ""], ["Yeung", "Serena", ""], ["Haque", "Albert", ""], ["Fei-Fei", "Li", ""]]}, {"id": "1811.09982", "submitter": "Battista Biggio", "authors": "Battista Biggio, Ignazio Pillai, Samuel Rota Bul\\`o, Davide Ariu,\n  Marcello Pelillo, Fabio Roli", "title": "Is Data Clustering in Adversarial Settings Secure?", "comments": null, "journal-ref": "Proceedings of the 2013 ACM Workshop on Artificial Intelligence\n  and Security, AISec '13, pages 87-98, New York, NY, USA, 2013. ACM", "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering algorithms have been increasingly adopted in security applications\nto spot dangerous or illicit activities. However, they have not been originally\ndevised to deal with deliberate attack attempts that may aim to subvert the\nclustering process itself. Whether clustering can be safely adopted in such\nsettings remains thus questionable. In this work we propose a general framework\nthat allows one to identify potential attacks against clustering algorithms,\nand to evaluate their impact, by making specific assumptions on the adversary's\ngoal, knowledge of the attacked system, and capabilities of manipulating the\ninput data. We show that an attacker may significantly poison the whole\nclustering process by adding a relatively small percentage of attack samples to\nthe input data, and that some attack samples may be obfuscated to be hidden\nwithin some existing clusters. We present a case study on single-linkage\nhierarchical clustering, and report experiments on clustering of malware\nsamples and handwritten digits.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 10:21:59 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Biggio", "Battista", ""], ["Pillai", "Ignazio", ""], ["Bul\u00f2", "Samuel Rota", ""], ["Ariu", "Davide", ""], ["Pelillo", "Marcello", ""], ["Roli", "Fabio", ""]]}, {"id": "1811.09985", "submitter": "Battista Biggio", "authors": "Battista Biggio, Konrad Rieck, Davide Ariu, Christian Wressnegger,\n  Igino Corona, Giorgio Giacinto, Fabio Roli", "title": "Poisoning Behavioral Malware Clustering", "comments": null, "journal-ref": "2014 ACM CCS Workshop on Artificial Intelligent and Security,\n  AISec '14, pages 27-36, New York, NY, USA, 2014. ACM", "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering algorithms have become a popular tool in computer security to\nanalyze the behavior of malware variants, identify novel malware families, and\ngenerate signatures for antivirus systems. However, the suitability of\nclustering algorithms for security-sensitive settings has been recently\nquestioned by showing that they can be significantly compromised if an attacker\ncan exercise some control over the input data. In this paper, we revisit this\nproblem by focusing on behavioral malware clustering approaches, and\ninvestigate whether and to what extent an attacker may be able to subvert these\napproaches through a careful injection of samples with poisoning behavior. To\nthis end, we present a case study on Malheur, an open-source tool for\nbehavioral malware clustering. Our experiments not only demonstrate that this\ntool is vulnerable to poisoning attacks, but also that it can be significantly\ncompromised even if the attacker can only inject a very small percentage of\nattacks into the input data. As a remedy, we discuss possible countermeasures\nand highlight the need for more secure clustering algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 10:31:53 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Biggio", "Battista", ""], ["Rieck", "Konrad", ""], ["Ariu", "Davide", ""], ["Wressnegger", "Christian", ""], ["Corona", "Igino", ""], ["Giacinto", "Giorgio", ""], ["Roli", "Fabio", ""]]}, {"id": "1811.10050", "submitter": "Daegeon Kim", "authors": "Daegeon Kim and Huy Kang Kim", "title": "Automated Dataset Generation System for Collaborative Research of Cyber\n  Threat Analysis", "comments": "preprint version of paper published in Security and Communication\n  Networks special issue on Data-Driven Cybersecurity", "journal-ref": null, "doi": "10.1155/2019/6268476", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objectives of cyberattacks are becoming sophisticated, and attackers are\nconcealing their identity by masquerading as other attackers. Cyber threat\nintelligence (CTI) is gaining attention as a way to collect meaningful\nknowledge to better understand the intention of an attacker and eventually\npredict future attacks. A systemic threat analysis based on data acquired from\nactual cyber incidents is a useful approach to generating intelligence for such\nan objective. Developing an analysis technique requires a high volume and fine\nquality data. However, researchers can become discouraged by an inaccessibility\nto data because organizations rarely release their data to the research\ncommunity. Owing to a data inaccessibility issue, academic research tends to be\nbiased toward techniques that develope steps of the CTI process other than\nanalysis and production. In this paper, we propose an automated dataset\ngeneration system called CTIMiner. The system collects threat data from\npublicly available security reports and malware repositories. The data are\nstored in a structured format. We released the source codes and dataset to the\npublic, including approximately 640,000 records from 612 security reports\npublished from January 2008 to June 2019. In addition, we present a statistical\nfeature of the dataset and techniques that can be developed using it. Moreover,\nwe demonstrate an application example of the dataset that analyzes the\ncorrelation and characteristics of an incident. We believe our dataset will\npromote collaborative research on threat analysis for the generation of CTI.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 16:36:30 GMT"}, {"version": "v2", "created": "Sat, 7 Sep 2019 13:29:26 GMT"}, {"version": "v3", "created": "Sun, 6 Oct 2019 08:15:17 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Kim", "Daegeon", ""], ["Kim", "Huy Kang", ""]]}, {"id": "1811.10168", "submitter": "Xiaopeng Li", "authors": "Wenyuan Xu, Xiaopeng Li, Jing Tian, Yujun Xiao, Xianshan Qu, Song Wang\n  and Xiaoyu Ji", "title": "Which One to Go: Security and Usability Evaluation of Mid-Air Gestures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the emerging of touch-less human-computer interaction techniques and\ngadgets, mid-air hand gestures have been widely used for authentication. Much\nliterature examined either the usability or security of a handful of gestures.\nThis paper aims at quantifying usability and security of gestures as well as\nunderstanding their relationship across multiple gestures. To study\ngesture-based authentication, we design an authentication method that combines\nDynamic Time Warping (DTW) and Support Vector Machine (SVM), and conducted a\nuser study with 42 participants over a period of 6 weeks. We objectively\nquantify the usability of a gesture by the number of corners and the frame\nlength of all gesture samples, quantify the security using the equal error rate\n(EER), and the consistency by EER over a period of time. Meanwhile, we obtain\nsubjective evaluation of usability and security by conducting a survey. By\nexamining the responses, we found that the subjective evaluation confirms with\nthe objective ones, and usability is in inverse relationship with security. We\nstudied the consistency of gestures and found that most participants forgot\ngestures to some degree and reinforcing the memorization of gestures is\nnecessary to improve the authentication performance. Finally, we performed a\nstudy with another 17 participants on shoulder surfing attacks, where attackers\ncan observe the victims multiple times. The results show that shoulder surfing\ndoes not help to boost the attacks.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 04:00:00 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Xu", "Wenyuan", ""], ["Li", "Xiaopeng", ""], ["Tian", "Jing", ""], ["Xiao", "Yujun", ""], ["Qu", "Xianshan", ""], ["Wang", "Song", ""], ["Ji", "Xiaoyu", ""]]}, {"id": "1811.10254", "submitter": "Hitoshi Kiya", "authors": "Hitoshi Kiya", "title": "Compressible and Learnable Encryption for Untrusted Cloud Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the wide/rapid spread of distributed systems for information processing,\nsuch as cloud computing and social networking, not only transmission but also\nprocessing is done on the internet. Therefore, a lot of studies on secure,\nefficient and flexible communications have been reported. Moreover, huge\ntraining data sets are required for machine learning and deep learning\nalgorithms to obtain high performance. However, it requires large cost to\ncollect enough training data while maintaining people's privacy. Nobody wants\nto include their personal data into datasets because providers can directly\ncheck the data. Full encryption with a state-of-the-art cipher (like RSA, or\nAES) is the most secure option for securing multimedia data. However, in cloud\nenvironments, data have to be computed/manipulated somewhere on the internet.\nThus, many multimedia applications have been seeking a trade-off in security to\nenable other requirements, e.g., low processing demands, and processing and\nlearning in the encrypted domain, Accordingly, we first focus on compressible\nimage encryption schemes, which have been proposed for\nencryption-then-compression (EtC) systems, although the traditional way for\nsecure image transmission is to use a compression-then encryption (CtE) system.\nEtC systems allow us to close unencrypted images to network providers, because\nencrypted images can be directly compressed even when the images are multiply\nrecompressed by providers. Next, we address the issue of learnable encryption.\nCloud computing and machine learning are widely used in many fields. However,\nthey have some serious issues for end users, such as unauthorized access, data\nleaks, and privacy compromise, due to unreliability of providers and some\naccidents.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 09:52:54 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Kiya", "Hitoshi", ""]]}, {"id": "1811.10256", "submitter": "Natasha Fernandes", "authors": "Natasha Fernandes, Mark Dras, Annabelle McIver", "title": "Generalised Differential Privacy for Text Document Processing", "comments": "Typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of how to \"obfuscate\" texts by removing stylistic\nclues which can identify authorship, whilst preserving (as much as possible)\nthe content of the text. In this paper we combine ideas from \"generalised\ndifferential privacy\" and machine learning techniques for text processing to\nmodel privacy for text documents. We define a privacy mechanism that operates\nat the level of text documents represented as \"bags-of-words\" - these\nrepresentations are typical in machine learning and contain sufficient\ninformation to carry out many kinds of classification tasks including topic\nidentification and authorship attribution (of the original documents). We show\nthat our mechanism satisfies privacy with respect to a metric for semantic\nsimilarity, thereby providing a balance between utility, defined by the\nsemantic content of texts, with the obfuscation of stylistic clues. We\ndemonstrate our implementation on a \"fan fiction\" dataset, confirming that it\nis indeed possible to disguise writing style effectively whilst preserving\nenough information and variation for accurate content classification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 09:54:13 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 15:49:36 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Fernandes", "Natasha", ""], ["Dras", "Mark", ""], ["McIver", "Annabelle", ""]]}, {"id": "1811.10296", "submitter": "Tanmay Gangwani", "authors": "Yunhui Long, Tanmay Gangwani, Haris Mughees and Carl Gunter", "title": "Distributed and Secure ML with Self-tallying Multi-party Aggregation", "comments": "NeurIPS 2018 Workshop on PPML", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy preserving multi-party computation has many applications in areas\nsuch as medicine and online advertisements. In this work, we propose a\nframework for distributed, secure machine learning among untrusted individuals.\nThe framework consists of two parts: a two-step training protocol based on\nhomomorphic addition and a zero knowledge proof for data validity. By combining\nthese two techniques, our framework provides privacy of per-user data, prevents\nagainst a malicious user contributing corrupted data to the shared pool,\nenables each user to self-compute the results of the algorithm without relying\non external trusted third parties, and requires no private channels between\ngroups of users. We show how different ML algorithms such as Latent Dirichlet\nAllocation, Naive Bayes, Decision Trees etc. fit our framework for distributed,\nsecure computing.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 11:24:38 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Long", "Yunhui", ""], ["Gangwani", "Tanmay", ""], ["Mughees", "Haris", ""], ["Gunter", "Carl", ""]]}, {"id": "1811.10448", "submitter": "Ehsan Edalat", "authors": "Ehsan Edalat, Babak Sadeghiyan, Fatemeh Ghassemi", "title": "ConsiDroid: A Concolic-based Tool for Detecting SQL Injection\n  Vulnerability in Android Apps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a concolic execution technique for detecting SQL\ninjection vulnerabilities in Android apps, with a new tool we called\nConsiDroid. We extend the source code of apps with mocking technique, such that\nthe execution of original source code is not affected. The extended source code\ncan be treated as Java applications and may be executed by SPF with concolic\nexecution. We automatically produce a DummyMain class out of static analysis\nsuch that the essential functions are called sequentially and, the events\nleading to vulnerable functions are triggered. We extend SPF with taint\nanalysis in ConsiDroid. For making taint analysis possible, we introduce a new\ntechnique of symbolic mock classes in order to ease the propagation of tainted\nvalues in the code. An SQL injection vulnerability is detected through\nreceiving a tainted value by a vulnerable function. Besides, ConsiDroid takes\nadvantage of static analysis to adjust SPF in order to inspect only suspicious\npaths. To illustrate the applicability of ConsiDroid, we have inspected\nrandomly selected 140 apps from F-Droid repository. From these apps, we found\nthree apps vulnerable to SQL injection. To verify their vulnerability, we\nanalyzed the apps manually based on ConsiDroid's reports by using Robolectric.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 15:28:10 GMT"}, {"version": "v2", "created": "Sun, 20 Jan 2019 14:44:07 GMT"}, {"version": "v3", "created": "Thu, 8 Aug 2019 06:33:32 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Edalat", "Ehsan", ""], ["Sadeghiyan", "Babak", ""], ["Ghassemi", "Fatemeh", ""]]}, {"id": "1811.10509", "submitter": "Virgile Robles", "authors": "Virgile Robles, Nikolai Kosmatov, Virgile Prevosto, Louis Rilling,\n  Pascale Le Gall", "title": "MetAcsl: Specification and Verification of High-Level Properties", "comments": "7 pages, slightly extended camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modular deductive verification is a powerful technique capable to show that\neach function in a program satisfies its contract. However, function contracts\ndo not provide a global view of which high-level (e.g. security-related\nproperties of a whole software module are actually established, making it very\ndifficult to assess them. To address this issue, this paper proposes a new\nspecification mechanism, called meta-properties. A meta-property can be seen as\nan enhanced global invariant specified for a set of functions, and capable to\nexpress predicates on values of variables, as well as memory related conditions\n(such as separation) and read or write access constraints. We also propose an\nautomatic transformation technique translating meta-properties into usual\ncontracts and assertions, that can be proved by traditional deductive\nverification tools. This technique has been implemented as a Frama-C plugin\ncalled MetAcsl and successfully applied to specify and prove safety- and\nsecurity-related meta-properties in two illustrative case studies.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 17:02:00 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 13:50:58 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Robles", "Virgile", ""], ["Kosmatov", "Nikolai", ""], ["Prevosto", "Virgile", ""], ["Rilling", "Louis", ""], ["Gall", "Pascale Le", ""]]}, {"id": "1811.10548", "submitter": "Adam Aviv", "authors": "Adam J. Aviv and Markus Duermuth", "title": "A Survey of Collection Methods and Cross-Data Set Comparison of Android\n  Unlock Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Android's graphical password unlock remains one of the most widely used\nschemes for phone unlock authentication, and it is has been studied extensively\nin the last decade since its launch. We have learned that users' choice of\npatterns mimics the poor password choices in other systems, such as PIN or\ntext-based passwords. A wide variety of analysis and data collections methods\nwas used to reach these conclusions, but what is missing from the literature is\na systemized comparison of the related work in this space that compares both\nthe methodology and the results. In this paper, we take a detailed accounting\nof the different methods applied to data collection and analysis for Android\nunlock patterns. We do so in two dimensions. First we systemize prior work into\na detailed taxonomy of collection methods, and in the second dimension, we\nperform a detailed analysis of 9 different data sets collected using different\nmethods. While this study focuses singularly on the collection methods and\ncomparisons of the Android pattern unlock scheme, we believe that many of the\nfindings generalize to other graphical password schemes, unlock authentication\ntechnology, and other knowledge-based authentication schemes.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 17:51:34 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Aviv", "Adam J.", ""], ["Duermuth", "Markus", ""]]}, {"id": "1811.10649", "submitter": "Minghai Qin", "authors": "Minghai Qin, Dejan Vucinic", "title": "Noisy Computations during Inference: Harmful or Helpful?", "comments": "20 pages, 11 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study two aspects of noisy computations during inference. The first aspect\nis how to mitigate their side effects for naturally trained deep learning\nsystems. One of the motivations for looking into this problem is to reduce the\nhigh power cost of conventional computing of neural networks through the use of\nanalog neuromorphic circuits. Traditional GPU/CPU-centered deep learning\narchitectures exhibit bottlenecks in power-restricted applications (e.g.,\nembedded systems). The use of specialized neuromorphic circuits, where analog\nsignals passed through memory-cell arrays are sensed to accomplish\nmatrix-vector multiplications, promises large power savings and speed gains but\nbrings with it the problems of limited precision of computations and\nunavoidable analog noise. We manage to improve inference accuracy from 21.1% to\n99.5% for MNIST images, from 29.9% to 89.1% for CIFAR10, and from 15.5% to\n89.6% for MNIST stroke sequences with the presence of strong noise (with\nsignal-to-noise power ratio being 0 dB) by noise-injected training and a voting\nmethod. This observation promises neural networks that are insensitive to\ninference noise, which reduces the quality requirements on neuromorphic\ncircuits and is crucial for their practical usage. The second aspect is how to\nutilize the noisy inference as a defensive architecture against black-box\nadversarial attacks. During inference, by injecting proper noise to signals in\nthe neural networks, the robustness of adversarially-trained neural networks\nagainst black-box attacks has been further enhanced by 0.5% and 1.13% for two\nadversarially trained models for MNIST and CIFAR10, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 19:18:18 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Qin", "Minghai", ""], ["Vucinic", "Dejan", ""]]}, {"id": "1811.10745", "submitter": "Bao Wang", "authors": "Bao Wang and Binjie Yuan and Zuoqiang Shi and Stanley J. Osher", "title": "ResNets Ensemble via the Feynman-Kac Formalism to Improve Natural and\n  Robust Accuracies", "comments": "18 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empirical adversarial risk minimization (EARM) is a widely used mathematical\nframework to robustly train deep neural nets (DNNs) that are resistant to\nadversarial attacks. However, both natural and robust accuracies, in\nclassifying clean and adversarial images, respectively, of the trained robust\nmodels are far from satisfactory. In this work, we unify the theory of optimal\ncontrol of transport equations with the practice of training and testing of\nResNets. Based on this unified viewpoint, we propose a simple yet effective\nResNets ensemble algorithm to boost the accuracy of the robustly trained model\non both clean and adversarial images. The proposed algorithm consists of two\ncomponents: First, we modify the base ResNets by injecting a variance specified\nGaussian noise to the output of each residual mapping. Second, we average over\nthe production of multiple jointly trained modified ResNets to get the final\nprediction. These two steps give an approximation to the Feynman-Kac formula\nfor representing the solution of a transport equation with viscosity, or a\nconvection-diffusion equation. For the CIFAR10 benchmark, this simple algorithm\nleads to a robust model with a natural accuracy of {\\bf 85.62}\\% on clean\nimages and a robust accuracy of ${\\bf 57.94 \\%}$ under the 20 iterations of the\nIFGSM attack, which outperforms the current state-of-the-art in defending\nagainst IFGSM attack on the CIFAR10. Both natural and robust accuracies of the\nproposed ResNets ensemble can be improved dynamically as the building block\nResNet advances. The code is available at:\n\\url{https://github.com/BaoWangMath/EnResNet}.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 23:46:09 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 05:07:37 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Wang", "Bao", ""], ["Yuan", "Binjie", ""], ["Shi", "Zuoqiang", ""], ["Osher", "Stanley J.", ""]]}, {"id": "1811.10783", "submitter": "Masahiro Kaminaga", "authors": "Toshinori Suzuki, Masahiro Kaminaga", "title": "A True Random Number Generator Method Embedded in Wireless Communication\n  Systems", "comments": "We decided to withdraw this paper in order to significantly rewrite\n  this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To increase the number of wireless devices, e.g., mobile or IoT terminals,\ncryptosystems are essential for secure communications. In this regard, random\nnumber generation is crucial because the appropriate function of cryptosystems\nrelies on it to work properly. This paper proposes a true random number\ngenerator (TRNG) method capable of working in wireless communication systems.\nBy embedding a TRNG in such systems, no additional analog circuits are required\nand working conditions can be limited as long as wireless communication systems\nare functioning properly, making TRNG method cost-effective. We also present\nsome theoretical background and considerations. We next conduct experimental\nverification, which strongly supports the viability of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 02:52:03 GMT"}, {"version": "v2", "created": "Sun, 17 Mar 2019 07:09:06 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Suzuki", "Toshinori", ""], ["Kaminaga", "Masahiro", ""]]}, {"id": "1811.10828", "submitter": "Quanquan Gu", "authors": "Jinghui Chen, Dongruo Zhou, Jinfeng Yi, Quanquan Gu", "title": "A Frank-Wolfe Framework for Efficient and Effective Adversarial Attacks", "comments": "25 pages, 1 figure, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depending on how much information an adversary can access to, adversarial\nattacks can be classified as white-box attack and black-box attack. For\nwhite-box attack, optimization-based attack algorithms such as projected\ngradient descent (PGD) can achieve relatively high attack success rates within\nmoderate iterates. However, they tend to generate adversarial examples near or\nupon the boundary of the perturbation set, resulting in large distortion.\nFurthermore, their corresponding black-box attack algorithms also suffer from\nhigh query complexities, thereby limiting their practical usefulness. In this\npaper, we focus on the problem of developing efficient and effective\noptimization-based adversarial attack algorithms. In particular, we propose a\nnovel adversarial attack framework for both white-box and black-box settings\nbased on a variant of Frank-Wolfe algorithm. We show in theory that the\nproposed attack algorithms are efficient with an $O(1/\\sqrt{T})$ convergence\nrate. The empirical results of attacking the ImageNet and MNIST datasets also\nverify the efficiency and effectiveness of the proposed algorithms. More\nspecifically, our proposed algorithms attain the best attack performances in\nboth white-box and black-box attacks among all baselines, and are more time and\nquery efficient than the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 06:11:31 GMT"}, {"version": "v2", "created": "Sun, 15 Sep 2019 06:42:48 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Chen", "Jinghui", ""], ["Zhou", "Dongruo", ""], ["Yi", "Jinfeng", ""], ["Gu", "Quanquan", ""]]}, {"id": "1811.10851", "submitter": "Baptiste David", "authors": "Baptiste David", "title": "How a simple bug in ML compiler could be exploited for backdoors?", "comments": "8 pages, 15 figures, 5 sections. White paper of the talk presented at\n  ZeroNight 2018 in Saint-Petersburg", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Whenever a bug occurs in a program, software developers assume that the code\nis flawed, not the compiler. In fact, if compilers should be correct, they are\njust normal software with their own bugs. Hard to find, errors in them have\nsignificant impact, since it could result to vulnerabilities, especially when\nthey silently miscompile a critical application. Using assembly language to\nwrite such software is quite common, especially when time constraint is\ninvolved in such program.\n  This paper exposes a bug found in Microsoft Macro Assembler (ml for short)\ncompiler, developed by Microsoft since 1981. This assembly has the\ncharacteristics to get high level-like constructs and high level-like records\nwhich help the developer to write assembly code. It is in the management of one\nof this level-like construct the bug has been found.\n  This study aims to show how a compiler-bug can be audited and possibly\ncorrected. For application developers, it shows that even old and mature\ncompilers can present bugs. For security researcher, it shows possibilities to\nhide some unexpected behavior in software with a clear and officially non-bogus\ncode. It highlights opportunities for including stealth backdoors even in\nopen-source software.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 07:43:47 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["David", "Baptiste", ""]]}, {"id": "1811.10868", "submitter": "Yu Han", "authors": "Yu Han, Zhongru Wang, Qiang Ruan and Binxing Fang", "title": "Sapiens Chain: A Blockchain-based Cybersecurity Framework", "comments": null, "journal-ref": null, "doi": "10.5121/csit.2018.81509", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, cybersecurity becomes more and more important due to the rapid\ndevelopment of Internet. However, existing methods are in reality highly\nsensitive to attacks and are far more vulnerable than expected, as they are\nlack of trustable measures. In this paper, to address the aforementioned\nproblems, we propose a blockchain-based cybersecurity framework, termed as\nSapiens Chain, which can protect the privacy of the anonymous users and ensure\nthat the transactions are immutable by providing decentralized and trustable\nservices. Integrating semantic analysis, symbolic execution, and routing\nlearning methods into intelligent auditing, this framework can achieve good\naccuracy for detecting hidden vulnerabilities. In addition, a revenue incentive\nmechanism, which aims to donate participants, is built. The practical results\ndemonstrate the effectiveness of the proposed framework.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 08:27:49 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Han", "Yu", ""], ["Wang", "Zhongru", ""], ["Ruan", "Qiang", ""], ["Fang", "Binxing", ""]]}, {"id": "1811.10945", "submitter": "Valentin Zieglmeier", "authors": "Valentin Zieglmeier and Severin Kacianka and Thomas Hutzelmann and\n  Alexander Pretschner", "title": "A Real-Time Remote IDS Testbed for Connected Vehicles", "comments": "Peer-reviewed version accepted for publication in the proceedings of\n  the 34th ACM/SIGAPP Symposium On Applied Computing (SAC'19)", "journal-ref": null, "doi": "10.1145/3297280.3297465", "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connected vehicles are becoming commonplace. A constant connection between\nvehicles and a central server enables new features and services. This added\nconnectivity raises the likelihood of exposure to attackers and risks\nunauthorized access. A possible countermeasure to this issue are intrusion\ndetection systems (IDS), which aim at detecting these intrusions during or\nafter their occurrence. The problem with IDS is the large variety of possible\napproaches with no sensible option for comparing them. Our contribution to this\nproblem comprises the conceptualization and implementation of a testbed for an\nautomotive real-world scenario. That amounts to a server-side IDS detecting\nintrusions into vehicles remotely. To verify the validity of our approach, we\nevaluate the testbed from multiple perspectives, including its fitness for\npurpose and the quality of the data it generates. Our evaluation shows that the\ntestbed makes the effective assessment of various IDS possible. It solves\nmultiple problems of existing approaches, including class imbalance.\nAdditionally, it enables reproducibility and generating data of varying\ndetection difficulties. This allows for comprehensive evaluation of real-time,\nremote IDS.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 12:53:28 GMT"}, {"version": "v2", "created": "Wed, 16 Jan 2019 09:45:03 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Zieglmeier", "Valentin", ""], ["Kacianka", "Severin", ""], ["Hutzelmann", "Thomas", ""], ["Pretschner", "Alexander", ""]]}, {"id": "1811.11039", "submitter": "Pol Mac Aonghusa", "authors": "Pol Mac Aonghusa and Douglas Leith", "title": "3PS - Online Privacy through Group Identities", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Limiting online data collection to the minimum required for specific purposes\nis mandated by modern privacy legislation such as the General Data Protection\nRegulation (GDPR) and the California Consumer Protection Act. This is\nparticularly true in online services where broad collection of personal\ninformation represents an obvious concern for privacy. We challenge the view\nthat broad personal data collection is required to provide personalised\nservices. By first developing formal models of privacy and utility, we show how\nusers can obtain personalised content, while retaining an ability to plausibly\ndeny their interests in topics they regard as sensitive using a system of\nproxy, group identities we call 3PS. Through extensive experiment on a\nprototype implementation, using openly accessible data sources, we show that\n3PS provides personalised content to individual users over 98% of the time in\nour tests, while protecting plausible deniability effectively in the face of\nworst-case threats from a variety of attack types.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 15:02:34 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Mac Aonghusa", "Pol", ""], ["Leith", "Douglas", ""]]}, {"id": "1811.11079", "submitter": "Suproteem Sarkar", "authors": "Suproteem K. Sarkar, Kojin Oshiba, Daniel Giebisch, Yaron Singer", "title": "Robust Classification of Financial Risk", "comments": "NIPS 2018 Workshop on Challenges and Opportunities for AI in\n  Financial Services", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms are increasingly common components of high-impact decision-making,\nand a growing body of literature on adversarial examples in laboratory settings\nindicates that standard machine learning models are not robust. This suggests\nthat real-world systems are also susceptible to manipulation or\nmisclassification, which especially poses a challenge to machine learning\nmodels used in financial services. We use the loan grade classification problem\nto explore how machine learning models are sensitive to small changes in\nuser-reported data, using adversarial attacks documented in the literature and\nan original, domain-specific attack. Our work shows that a robust optimization\nalgorithm can build models for financial services that are resistant to\nmisclassification on perturbations. To the best of our knowledge, this is the\nfirst study of adversarial attacks and defenses for deep learning in financial\nservices.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 16:28:32 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Sarkar", "Suproteem K.", ""], ["Oshiba", "Kojin", ""], ["Giebisch", "Daniel", ""], ["Singer", "Yaron", ""]]}, {"id": "1811.11148", "submitter": "Gautam Kamath", "authors": "Cl\\'ement L. Canonne, Gautam Kamath, Audra McMillan, Adam Smith,\n  Jonathan Ullman", "title": "The Structure of Optimal Private Tests for Simple Hypotheses", "comments": "To appear in STOC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypothesis testing plays a central role in statistical inference, and is used\nin many settings where privacy concerns are paramount. This work answers a\nbasic question about privately testing simple hypotheses: given two\ndistributions $P$ and $Q$, and a privacy level $\\varepsilon$, how many i.i.d.\nsamples are needed to distinguish $P$ from $Q$ subject to\n$\\varepsilon$-differential privacy, and what sort of tests have optimal sample\ncomplexity? Specifically, we characterize this sample complexity up to constant\nfactors in terms of the structure of $P$ and $Q$ and the privacy level\n$\\varepsilon$, and show that this sample complexity is achieved by a certain\nrandomized and clamped variant of the log-likelihood ratio test. Our result is\nan analogue of the classical Neyman-Pearson lemma in the setting of private\nhypothesis testing. We also give an application of our result to the private\nchange-point detection. Our characterization applies more generally to\nhypothesis tests satisfying essentially any notion of algorithmic stability,\nwhich is known to imply strong generalization bounds in adaptive data analysis,\nand thus our results have applications even when privacy is not a primary\nconcern.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 18:21:33 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 21:46:45 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Canonne", "Cl\u00e9ment L.", ""], ["Kamath", "Gautam", ""], ["McMillan", "Audra", ""], ["Smith", "Adam", ""], ["Ullman", "Jonathan", ""]]}, {"id": "1811.11160", "submitter": "Yi-Peng Wei", "authors": "Yi-Peng Wei and Batuhan Arasli and Karim Banawan and Sennur Ulukus", "title": "The Capacity of Private Information Retrieval from Decentralized Uncoded\n  Caching Databases", "comments": "Submitted for publication, November 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.DB math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the private information retrieval (PIR) problem from\ndecentralized uncoded caching databases. There are two phases in our problem\nsetting, a caching phase, and a retrieval phase. In the caching phase, a data\ncenter containing all the $K$ files, where each file is of size $L$ bits, and\nseveral databases with storage size constraint $\\mu K L$ bits exist in the\nsystem. Each database independently chooses $\\mu K L$ bits out of the total\n$KL$ bits from the data center to cache through the same probability\ndistribution in a decentralized manner. In the retrieval phase, a user\n(retriever) accesses $N$ databases in addition to the data center, and wishes\nto retrieve a desired file privately. We characterize the optimal normalized\ndownload cost to be $\\frac{D}{L} = \\sum_{n=1}^{N+1} \\binom{N}{n-1} \\mu^{n-1}\n(1-\\mu)^{N+1-n} \\left( 1+ \\frac{1}{n} + \\dots+ \\frac{1}{n^{K-1}} \\right)$. We\nshow that uniform and random caching scheme which is originally proposed for\ndecentralized coded caching by Maddah-Ali and Niesen, along with Sun and Jafar\nretrieval scheme which is originally proposed for PIR from replicated databases\nsurprisingly result in the lowest normalized download cost. This is the\ndecentralized counterpart of the recent result of Attia, Kumar and Tandon for\nthe centralized case. The converse proof contains several ingredients such as\ninterference lower bound, induction lemma, replacing queries and answering\nstring random variables with the content of distributed databases, the nature\nof decentralized uncoded caching databases, and bit marginalization of joint\ncaching distributions.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 18:51:12 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Wei", "Yi-Peng", ""], ["Arasli", "Batuhan", ""], ["Banawan", "Karim", ""], ["Ulukus", "Sennur", ""]]}, {"id": "1811.11197", "submitter": "Richard Garcia-Lebron", "authors": "Richard Garcia-Lebron, David J. Myers, Shouhuai Xu and Jie Sun", "title": "Node Diversification in Complex Networks by Decentralized Coloring", "comments": null, "journal-ref": "Journal of Complex Networks (2018)", "doi": "10.1093/comnet/cny031", "report-no": null, "categories": "cs.SI cs.CR cs.DS cs.MA physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a decentralized coloring approach to diversify the nodes in a\ncomplex network. The key is the introduction of a local conflict index that\nmeasures the color conflicts arising at each node which can be efficiently\ncomputed using only local information. We demonstrate via both synthetic and\nreal-world networks that the proposed approach significantly outperforms random\ncoloring as measured by the size of the largest color-induced connected\ncomponent. Interestingly, for scale-free networks further improvement of\ndiversity can be achieved by tuning a degree-biasing weighting parameter in the\nlocal conflict index.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 19:02:36 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Garcia-Lebron", "Richard", ""], ["Myers", "David J.", ""], ["Xu", "Shouhuai", ""], ["Sun", "Jie", ""]]}, {"id": "1811.11218", "submitter": "Berk Gulmezoglu", "authors": "Berk Gulmezoglu, Andreas Zankl, M. Caner Tol, Saad Islam, Thomas\n  Eisenbarth and Berk Sunar", "title": "Undermining User Privacy on Mobile Devices Using AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past years, literature has shown that attacks exploiting the\nmicroarchitecture of modern processors pose a serious threat to the privacy of\nmobile phone users. This is because applications leave distinct footprints in\nthe processor, which can be used by malware to infer user activities. In this\nwork, we show that these inference attacks are considerably more practical when\ncombined with advanced AI techniques. In particular, we focus on profiling the\nactivity in the last-level cache (LLC) of ARM processors. We employ a simple\nPrime+Probe based monitoring technique to obtain cache traces, which we\nclassify with Deep Learning methods including Convolutional Neural Networks. We\ndemonstrate our approach on an off-the-shelf Android phone by launching a\nsuccessful attack from an unprivileged, zeropermission App in well under a\nminute. The App thereby detects running applications with an accuracy of 98%\nand reveals opened websites and streaming videos by monitoring the LLC for at\nmost 6 seconds. This is possible, since Deep Learning compensates measurement\ndisturbances stemming from the inherently noisy LLC monitoring and unfavorable\ncache characteristics such as random line replacement policies. In summary, our\nresults show that thanks to advanced AI techniques, inference attacks are\nbecoming alarmingly easy to implement and execute in practice. This once more\ncalls for countermeasures that confine microarchitectural leakage and protect\nmobile phone applications, especially those valuing the privacy of their users.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 19:44:12 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 20:53:54 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Gulmezoglu", "Berk", ""], ["Zankl", "Andreas", ""], ["Tol", "M. Caner", ""], ["Islam", "Saad", ""], ["Eisenbarth", "Thomas", ""], ["Sunar", "Berk", ""]]}, {"id": "1811.11274", "submitter": "Tian Xie", "authors": "Tian Xie, Guan-Hua Tu, Bangjie Yin, Chi-Yu Li, Chunyi Peng, Mi Zhang,\n  Hui Liu, Xiaoming Liu", "title": "The Untold Secrets of Operational Wi-Fi Calling Services:\n  Vulnerabilities, Attacks, and Countermeasures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since 2016, all of four major U.S. operators have rolled out nationwide Wi-Fi\ncalling services. They are projected to surpass VoLTE (Voice over LTE) and\nother VoIP services in terms of mobile IP voice usage minutes in 2018. They\nenable mobile users to place cellular calls over Wi-Fi networks based on the\n3GPP IMS (IP Multimedia Subsystem) technology. Compared with conventional\ncellular voice solutions, the major difference lies in that their traffic\ntraverses untrustful Wi-Fi networks and the Internet. This exposure to insecure\nnetworks may cause the Wi-Fi calling users to suffer from security threats. Its\nsecurity mechanisms are similar to the VoLTE, because both of them are\nsupported by the IMS. They include SIM-based security, 3GPP AKA (Authentication\nand Key Agreement), IPSec (Internet Protocol Security), etc. However, are they\nsufficient to secure Wi-Fi calling services? Unfortunately, our study yields a\nnegative answer. We conduct the first study of exploring security issues of the\noperational Wi-Fi calling services in three major U.S. operators' networks\nusing commodity devices. We disclose that current Wi-Fi calling security is not\nbullet-proof and uncover four vulnerabilities which stem from improper standard\ndesigns, device implementation issues and network operation slips. By\nexploiting the vulnerabilities, together with several state-of-the-art computer\nvisual recognition technologies, we devise two proof-of-concept attacks: user\nprivacy leakage and telephony harassment or denial of voice service (THDoS);\nboth of them can bypass the security defenses deployed on mobile devices and\nthe network infrastructure. We have confirmed their feasibility and simplicity\nusing real-world experiments, as well as assessed their potential damages and\nproposed recommended solutions.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 21:49:02 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 14:51:37 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Xie", "Tian", ""], ["Tu", "Guan-Hua", ""], ["Yin", "Bangjie", ""], ["Li", "Chi-Yu", ""], ["Peng", "Chunyi", ""], ["Zhang", "Mi", ""], ["Liu", "Hui", ""], ["Liu", "Xiaoming", ""]]}, {"id": "1811.11304", "submitter": "Mahyar Najibi", "authors": "Ali Shafahi, Mahyar Najibi, Zheng Xu, John Dickerson, Larry S. Davis,\n  Tom Goldstein", "title": "Universal Adversarial Training", "comments": "Accepted to AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard adversarial attacks change the predicted class label of a selected\nimage by adding specially tailored small perturbations to its pixels. In\ncontrast, a universal perturbation is an update that can be added to any image\nin a broad class of images, while still changing the predicted class label. We\nstudy the efficient generation of universal adversarial perturbations, and also\nefficient methods for hardening networks to these attacks. We propose a simple\noptimization-based universal attack that reduces the top-1 accuracy of various\nnetwork architectures on ImageNet to less than 20%, while learning the\nuniversal perturbation 13X faster than the standard method.\n  To defend against these perturbations, we propose universal adversarial\ntraining, which models the problem of robust classifier generation as a\ntwo-player min-max game, and produces robust models with only 2X the cost of\nnatural training. We also propose a simultaneous stochastic gradient method\nthat is almost free of extra computation, which allows us to do universal\nadversarial training on ImageNet.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 23:09:27 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 20:57:36 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Shafahi", "Ali", ""], ["Najibi", "Mahyar", ""], ["Xu", "Zheng", ""], ["Dickerson", "John", ""], ["Davis", "Larry S.", ""], ["Goldstein", "Tom", ""]]}, {"id": "1811.11402", "submitter": "Siddique Latif", "authors": "Siddique Latif, Rajib Rana, and Junaid Qadir", "title": "Adversarial Machine Learning And Speech Emotion Recognition: Utilizing\n  Generative Adversarial Networks For Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has undoubtedly offered tremendous improvements in the\nperformance of state-of-the-art speech emotion recognition (SER) systems.\nHowever, recent research on adversarial examples poses enormous challenges on\nthe robustness of SER systems by showing the susceptibility of deep neural\nnetworks to adversarial examples as they rely only on small and imperceptible\nperturbations. In this study, we evaluate how adversarial examples can be used\nto attack SER systems and propose the first black-box adversarial attack on SER\nsystems. We also explore potential defenses including adversarial training and\ngenerative adversarial network (GAN) to enhance robustness. Experimental\nevaluations suggest various interesting aspects of the effective utilization of\nadversarial examples useful for achieving robustness for SER systems opening up\nopportunities for researchers to further innovate in this space.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 06:26:03 GMT"}, {"version": "v2", "created": "Sun, 30 Dec 2018 10:44:21 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Latif", "Siddique", ""], ["Rana", "Rajib", ""], ["Qadir", "Junaid", ""]]}, {"id": "1811.11462", "submitter": "Prabal Banerjee", "authors": "Prabal Banerjee, Sushmita Ruj", "title": "Blockchain Enabled Data Marketplace -- Design and Challenges", "comments": "A version with minor differences has been submitted to IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data is of unprecedented importance today. The most valuable companies of\ntoday treat data as a commodity, which they trade and earn revenues. To\nfacilitate such trading, data marketplaces have emerged. Present data\nmarketplaces are inadequate as they fail to satisfy all the desirable\nproperties - fairness, efficiency, security, privacy and adherence to\nregulations. In this article, we propose a blockchain enabled data marketplace\nsolution that fulfills all required properties. We outline the design, show how\nto design such a system and discuss the challenges in building a complete data\nmarketplace.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 09:40:39 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 11:28:31 GMT"}, {"version": "v3", "created": "Wed, 17 Apr 2019 06:55:02 GMT"}, {"version": "v4", "created": "Fri, 27 Sep 2019 10:08:40 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Banerjee", "Prabal", ""], ["Ruj", "Sushmita", ""]]}, {"id": "1811.11493", "submitter": "Francesco Croce", "authors": "Francesco Croce, Matthias Hein", "title": "A randomized gradient-free attack on ReLU networks", "comments": "In GCPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has recently been shown that neural networks but also other classifiers\nare vulnerable to so called adversarial attacks e.g. in object recognition an\nalmost non-perceivable change of the image changes the decision of the\nclassifier. Relatively fast heuristics have been proposed to produce these\nadversarial inputs but the problem of finding the optimal adversarial input,\nthat is with the minimal change of the input, is NP-hard. While methods based\non mixed-integer optimization which find the optimal adversarial input have\nbeen developed, they do not scale to large networks. Currently, the attack\nscheme proposed by Carlini and Wagner is considered to produce the best\nadversarial inputs. In this paper we propose a new attack scheme for the class\nof ReLU networks based on a direct optimization on the resulting linear\nregions. In our experimental validation we improve in all except one experiment\nout of 18 over the Carlini-Wagner attack with a relative improvement of up to\n9\\%. As our approach is based on the geometrical structure of ReLU networks, it\nis less susceptible to defences targeting their functional properties.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 11:03:26 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Croce", "Francesco", ""], ["Hein", "Matthias", ""]]}, {"id": "1811.11629", "submitter": "Paul D. Beale", "authors": "Jetanat Datephanyawat and Paul D. Beale", "title": "Class of scalable parallel and vectorizable pseudorandom number\n  generators based on non-cryptographic RSA exponentiation ciphers", "comments": "10 pages, 1 figure. arXiv admin note: text overlap with\n  arXiv:1411.2484", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallel supercomputer-based Monte Carlo and stochastic simulations require\npseudorandom number generators that can produce distinct pseudorandom streams\nacross many independent processes. We propose a scalable class of parallel and\nvectorizable pseudorandom number generators based on a non-cryptographic\nversion of the RSA public-key exponentiation cipher. Our method generates\nuniformly distributed IEEE double-precision floating point pseudorandom\nsequences on $[0,1)$ by encrypting pseudorandom sequences of 64-bit integer\nmessages by modular exponentiation. The advantages of the method are: the\nmethod is parallelizable by parameterization with each pseudorandom number\ngenerator instance derived from an independent 64-bit composite modulus, the\nmethod is fully scalable on massively parallel computing clusters because of\nthe millions of available 32-bit prime numbers, the seeding and initialization\nof the independent streams is simple, the periods of the independent instances\nare all different and greater than $8.5\\times 10^{37}$, and the method passes a\nbattery of intrastream and interstream correlation tests. The calculations in\neach instance can be vectorized using steam splitting and can produce more than\n$10^8$ pseudorandom numbers per second on each multicore CPU.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 17:10:20 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 20:14:05 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Datephanyawat", "Jetanat", ""], ["Beale", "Paul D.", ""]]}, {"id": "1811.11645", "submitter": "Michael Fr\\\"owis", "authors": "Michael Fr\\\"owis, Andreas Fuchs, Rainer B\\\"ohme", "title": "Detecting Token Systems on Ethereum", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and compare two approaches to identify smart contracts as token\nsystems by analyzing their public bytecode. The first approach symbolically\nexecutes the code in order to detect token systems by their characteristic\nbehavior of updating internal accounts. The second approach serves as a\ncomparison base and exploits the common interface of ERC-20, the most popular\ntoken standard. We present quantitative results for the Ethereum blockchain,\nand validate the effectiveness of both approaches using a set of curated token\nsystems as ground truth. We observe 100% recall for the second approach. Recall\nrates of 89% (with well explainable missed detections) indicate that the first\napproach may also be able to identify \"hidden\" or undocumented token systems\nthat intentionally do not implement the standard. One possible application of\nthe proposed methods is to facilitate regulator' tasks of monitoring and\npolicing the use of token systems and their underlying platforms.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 16:04:48 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Fr\u00f6wis", "Michael", ""], ["Fuchs", "Andreas", ""], ["B\u00f6hme", "Rainer", ""]]}, {"id": "1811.11705", "submitter": "Daniel L. Marino", "authors": "Daniel L. Marino, Chathurika S. Wickramasinghe, Milos Manic", "title": "An Adversarial Approach for Explainable AI in Intrusion Detection\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the growing popularity of modern machine learning techniques (e.g.\nDeep Neural Networks) in cyber-security applications, most of these models are\nperceived as a black-box for the user. Adversarial machine learning offers an\napproach to increase our understanding of these models. In this paper we\npresent an approach to generate explanations for incorrect classifications made\nby data-driven Intrusion Detection Systems (IDSs). An adversarial approach is\nused to find the minimum modifications (of the input features) required to\ncorrectly classify a given set of misclassified samples. The magnitude of such\nmodifications is used to visualize the most relevant features that explain the\nreason for the misclassification. The presented methodology generated\nsatisfactory explanations that describe the reasoning behind the\nmis-classifications, with descriptions that match expert knowledge. The\nadvantages of the presented methodology are: 1) applicable to any classifier\nwith defined gradients. 2) does not require any modification of the classifier\nmodel. 3) can be extended to perform further diagnosis (e.g. vulnerability\nassessment) and gain further understanding of the system. Experimental\nevaluation was conducted on the NSL-KDD99 benchmark dataset using Linear and\nMultilayer perceptron classifiers. The results are shown using intuitive\nvisualizations in order to improve the interpretability of the results.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 17:48:11 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Marino", "Daniel L.", ""], ["Wickramasinghe", "Chathurika S.", ""], ["Manic", "Milos", ""]]}, {"id": "1811.11858", "submitter": "Christian Majenz", "authors": "Gorjan Alagic, Tommaso Gagliardoni and Christian Majenz", "title": "Can you sign a quantum state?", "comments": "19+19 pages, v2: improved presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptography with quantum states exhibits a number of surprising and\ncounterintuitive features. In a 2002 work, Barnum et al. argue that these\nfeatures imply that digital signatures for quantum states are impossible\n(Barnum et al., FOCS 2002). In this work, we ask: can all forms of signing\nquantum data, even in a possibly weak sense, be completely ruled out? We give\ntwo results which shed significant light on this basic question.\n  First, we prove an impossibility result for digital signatures for quantum\ndata, which extends the result of Barnum et al. Specifically, we show that no\nnontrivial combination of correctness and security requirements can be\nfulfilled, beyond what is achievable simply by measuring the quantum message\nand then signing the outcome. In other words, only classical signature schemes\nexist.\n  We then show a positive result: a quantum state can be signed with the same\nsecurity guarantees as classically, provided that it is also encrypted with the\npublic key of the intended recipient. Following classical nomenclature, we call\nthis notion quantum signcryption. Classically, signcryption is only interesting\nif it provides superior performance to encypt-then-sign. Quantumly, it is far\nmore interesting: it is the only signing method available. We develop\n\"as-strong-as-classical\" security definitions for quantum signcryption and give\nsecure constructions based on post-quantum public-key primitives. Along the\nway, we show that a natural hybrid method of combining classical and quantum\nschemes can be used to \"upgrade\" a secure classical scheme to the fully-quantum\nsetting, in a wide range of cryptographic settings including signcryption,\nauthenticated encryption, and CCA security.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 22:11:24 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 16:10:26 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Alagic", "Gorjan", ""], ["Gagliardoni", "Tommaso", ""], ["Majenz", "Christian", ""]]}, {"id": "1811.11929", "submitter": "Joseph Fitzsimons", "authors": "Monireh Houshmand, Mahboobeh Houshmand, Si-Hui Tan and Joseph\n  Fitzsimons", "title": "Composable secure multi-client delegated quantum computation", "comments": "24 pages, 7 figures. Comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The engineering challenges involved in building large scale quantum\ncomputers, and the associated infrastructure requirements, mean that when such\ndevices become available it is likely that this will be in limited numbers and\nin limited geographic locations. It is likely that many users will need to rely\non remote access to delegate their computation to the available hardware. In\nsuch a scenario, the privacy and reliability of the delegated computations are\nimportant concerns. On the other hand, the distributed nature of modern\ncomputations has led to a widespread class of applications in which a group of\nparties attempt to perform a joint task over their inputs, e.g., in cloud\ncomputing. In this paper, we study the multi-client delegated quantum\ncomputation problem where we consider the global computation be made up of\nlocal computations that are individually decided by the clients. Each client\npart is kept secret from the server and the other clients. We construct a\ncomposable secure multi-client delegated quantum computation scheme from any\ncomposable secure single-client delegated quantum computation protocol and\nquantum authentication codes.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 02:22:09 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Houshmand", "Monireh", ""], ["Houshmand", "Mahboobeh", ""], ["Tan", "Si-Hui", ""], ["Fitzsimons", "Joseph", ""]]}, {"id": "1811.12028", "submitter": "Naoto Yanai", "authors": "Hiromasa Kitai, Jason Paul Cruz, Naoto Yanai, Naohisa Nishida, Tatsumi\n  Oba, Yuji Unagami, Tadanori Teruya, Nuttapong Attrapadung, Takahiro Matsuda,\n  Goichiro Hanaoka", "title": "MOBIUS: Model-Oblivious Binarized Neural Networks", "comments": null, "journal-ref": "IEEE Access (Volume: 7, Issue:1. 04 September 2019)", "doi": "10.1109/ACCESS.2019.2939410", "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A privacy-preserving framework in which a computational resource provider\nreceives encrypted data from a client and returns prediction results without\ndecrypting the data, i.e., oblivious neural network or encrypted prediction,\nhas been studied in machine learning that provides prediction services. In this\nwork, we present MOBIUS (Model-Oblivious BInary neUral networkS), a new system\nthat combines Binarized Neural Networks (BNNs) and secure computation based on\nsecret sharing as tools for scalable and fast privacy-preserving machine\nlearning. BNNs improve computational performance by binarizing values in\ntraining to $-1$ and $+1$, while secure computation based on secret sharing\nprovides fast and various computations under encrypted forms via modulo\noperations with a short bit length. However, combining these tools is not\ntrivial because their operations have different algebraic structures and the\nuse of BNNs downgrades prediction accuracy in general. MOBIUS uses improved\nprocedures of BNNs and secure computation that have compatible algebraic\nstructures without downgrading prediction accuracy. We created an\nimplementation of MOBIUS in C++ using the ABY library (NDSS 2015). We then\nconducted experiments using the MNIST dataset, and the results show that MOBIUS\ncan return a prediction within 0.76 seconds, which is six times faster than\nSecureML (IEEE S\\&P 2017). MOBIUS allows a client to request for encrypted\nprediction and allows a trainer to obliviously publish an encrypted model to a\ncloud provided by a computational resource provider, i.e., without revealing\nthe original model itself to the provider.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 09:18:38 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Kitai", "Hiromasa", ""], ["Cruz", "Jason Paul", ""], ["Yanai", "Naoto", ""], ["Nishida", "Naohisa", ""], ["Oba", "Tatsumi", ""], ["Unagami", "Yuji", ""], ["Teruya", "Tadanori", ""], ["Attrapadung", "Nuttapong", ""], ["Matsuda", "Takahiro", ""], ["Hanaoka", "Goichiro", ""]]}, {"id": "1811.12040", "submitter": "Brendan Avent", "authors": "Brendan Avent, Yatharth Dubey, Aleksandra Korolova", "title": "The Power of The Hybrid Model for Mean Estimation", "comments": "Proceedings on Privacy Enhancing Technologies 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the power of the hybrid model of differential privacy (DP), in\nwhich some users desire the guarantees of the local model of DP and others are\ncontent with receiving the trusted-curator model guarantees. In particular, we\nstudy the utility of hybrid model estimators that compute the mean of arbitrary\nreal-valued distributions with bounded support. When the curator knows the\ndistribution's variance, we design a hybrid estimator that, for realistic\ndatasets and parameter settings, achieves a constant factor improvement over\nnatural baselines. We then analytically characterize how the estimator's\nutility is parameterized by the problem setting and parameter choices. When the\ndistribution's variance is unknown, we design a heuristic hybrid estimator and\nanalyze how it compares to the baselines. We find that it often performs better\nthan the baselines, and sometimes almost as well as the known-variance\nestimator. We then answer the question of how our estimator's utility is\naffected when users' data are not drawn from the same distribution, but rather\nfrom distributions dependent on their trust model preference. Concretely, we\nexamine the implications of the two groups' distributions diverging and show\nthat in some cases, our estimators maintain fairly high utility. We then\ndemonstrate how our hybrid estimator can be incorporated as a sub-component in\nmore complex, higher-dimensional applications. Finally, we propose a new\nprivacy amplification notion for the hybrid model that emerges due to\ninteraction between the groups, and derive corresponding amplification results\nfor our hybrid estimators.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 09:52:17 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 21:14:29 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Avent", "Brendan", ""], ["Dubey", "Yatharth", ""], ["Korolova", "Aleksandra", ""]]}, {"id": "1811.12082", "submitter": "Shaohan Feng Mr", "authors": "Shaohan Feng, Dusit Niyato, Ping Wang, Dong In Kim, and Ying-Chang\n  Liang", "title": "Joint Service Pricing and Cooperative Relay Communication for Federated\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the sake of protecting data privacy and due to the rapid development of\nmobile devices, e.g., powerful central processing unit (CPU) and nascent neural\nprocessing unit (NPU), collaborative machine learning on mobile devices, e.g.,\nfederated learning, has been envisioned as a new AI approach with broad\napplication prospects. However, the learning process of the existing federated\nlearning platforms rely on the direct communication between the model owner,\ne.g., central cloud or edge server, and the mobile devices for transferring the\nmodel update. Such a direct communication may be energy inefficient or even\nunavailable in mobile environments. In this paper, we consider adopting the\nrelay network to construct a cooperative communication platform for supporting\nmodel update transfer and trading. In the system, the mobile devices generate\nmodel updates based on their training data. The model updates are then\nforwarded to the model owner through the cooperative relay network. The model\nowner enjoys the learning service provided by the mobile devices. In return,\nthe mobile devices charge the model owner certain prices. Due to the coupled\ninterference of wireless transmission among the mobile devices that use the\nsame relay node, the rational mobile devices have to choose their relay nodes\nas well as deciding on their transmission powers. Thus, we formulate a\nStackelberg game model to investigate the interaction among the mobile devices\nand that between the mobile devices and the model owner. The Stackelberg\nequilibrium is investigated by capitalizing on the exterior point method.\nMoreover, we provide a series of insightful analytical and numerical results on\nthe equilibrium of the Stackelberg game.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 11:51:05 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Feng", "Shaohan", ""], ["Niyato", "Dusit", ""], ["Wang", "Ping", ""], ["Kim", "Dong In", ""], ["Liang", "Ying-Chang", ""]]}, {"id": "1811.12088", "submitter": "Pramod Subramanyan", "authors": "Deepak Sirone and Pramod Subramanyan", "title": "Functional Analysis Attacks on Logic Locking", "comments": null, "journal-ref": null, "doi": "10.1109/TIFS.2020.2968183", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logic locking refers to a set of techniques that can protect integrated\ncircuits (ICs) from counterfeiting, piracy and malicious functionality changes\nby an untrusted foundry. It achieves these goals by introducing new inputs,\ncalled key inputs, and additional logic to an IC such that the circuit produces\nthe correct output only when the key inputs are set to specific values. The\ncorrect values of the key inputs are kept secret from the untrusted foundry and\nprogrammed after manufacturing and before distribution, rendering piracy,\ncounterfeiting and malicious design changes infeasible. The security of logic\nlocking relies on the assumption that the untrusted foundry cannot infer the\ncorrect values of the key inputs by analysis of the circuit.\n  This paper proposes Functional Analysis attacks on Logic Locking algorithms\n(abbreviated as FALL attacks). FALL attacks have two stages. Their first stage\nis dependent on the locking algorithm and involves analyzing structural and\nfunctional properties of locked circuits to identify a list of potential\nlocking keys. The second stage is algorithm agnostic and introduces a powerful\naddition to SAT-based attacks called key confirmation. Key confirmation can\nidentify the correct key from a list of alternatives and works even on circuits\nthat are resilient to the SAT attack. In comparison to past work, the FALL\nattack is more practical as it can often succeed (90% of successful attempts in\nour experiments) by only analyzing the locked netlist, without requiring oracle\naccess to an unlocked circuit. Our experimental evaluation shows that FALL\nattacks are able to defeat 65 out of 80 (81%) circuits locked using\nStripped-Functionality Logic Locking (SFLL-HD).\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 12:07:45 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 13:04:15 GMT"}, {"version": "v3", "created": "Fri, 10 Jan 2020 18:15:10 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Sirone", "Deepak", ""], ["Subramanyan", "Pramod", ""]]}, {"id": "1811.12365", "submitter": "Peter Breuer", "authors": "Peter T. Breuer and Jonathan P. Bowen", "title": "(Un)Encrypted Computing and Indistinguishability Obfuscation", "comments": "2 pages, extended abstract for Principles of Secure Compilation\n  (PriSC'19) at Principles of Programming Languages (POPL'19), Lisbon 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper first describes an `obfuscating' compiler technology developed for\nencrypted computing, then examines if the trivial case without encryption\nproduces much-sought indistinguishability obfuscation.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 18:22:13 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Breuer", "Peter T.", ""], ["Bowen", "Jonathan P.", ""]]}, {"id": "1811.12395", "submitter": "Tsui-Wei Weng", "authors": "Akhilan Boopathy, Tsui-Wei Weng, Pin-Yu Chen, Sijia Liu and Luca\n  Daniel", "title": "CNN-Cert: An Efficient Framework for Certifying Robustness of\n  Convolutional Neural Networks", "comments": "Accepted by AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verifying robustness of neural network classifiers has attracted great\ninterests and attention due to the success of deep neural networks and their\nunexpected vulnerability to adversarial perturbations. Although finding minimum\nadversarial distortion of neural networks (with ReLU activations) has been\nshown to be an NP-complete problem, obtaining a non-trivial lower bound of\nminimum distortion as a provable robustness guarantee is possible. However,\nmost previous works only focused on simple fully-connected layers (multilayer\nperceptrons) and were limited to ReLU activations. This motivates us to propose\na general and efficient framework, CNN-Cert, that is capable of certifying\nrobustness on general convolutional neural networks. Our framework is general\n-- we can handle various architectures including convolutional layers,\nmax-pooling layers, batch normalization layer, residual blocks, as well as\ngeneral activation functions; our approach is efficient -- by exploiting the\nspecial structure of convolutional layers, we achieve up to 17 and 11 times of\nspeed-up compared to the state-of-the-art certification algorithms (e.g.\nFast-Lin, CROWN) and 366 times of speed-up compared to the dual-LP approach\nwhile our algorithm obtains similar or even better verification bounds. In\naddition, CNN-Cert generalizes state-of-the-art algorithms e.g. Fast-Lin and\nCROWN. We demonstrate by extensive experiments that our method outperforms\nstate-of-the-art lower-bound-based certification algorithms in terms of both\nbound quality and speed.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 18:57:43 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Boopathy", "Akhilan", ""], ["Weng", "Tsui-Wei", ""], ["Chen", "Pin-Yu", ""], ["Liu", "Sijia", ""], ["Daniel", "Luca", ""]]}, {"id": "1811.12469", "submitter": "Vitaly Feldman", "authors": "\\'Ulfar Erlingsson, Vitaly Feldman, Ilya Mironov, Ananth Raghunathan,\n  Kunal Talwar, Abhradeep Thakurta", "title": "Amplification by Shuffling: From Local to Central Differential Privacy\n  via Anonymity", "comments": "Stated amplification bounds for epsilon > 1 explicitly and also\n  stated the bounds for for Renyi DP. Fixed an incorrect statement in one of\n  the proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensitive statistics are often collected across sets of users, with repeated\ncollection of reports done over time. For example, trends in users' private\npreferences or software usage may be monitored via such reports. We study the\ncollection of such statistics in the local differential privacy (LDP) model,\nand describe an algorithm whose privacy cost is polylogarithmic in the number\nof changes to a user's value.\n  More fundamentally---by building on anonymity of the users' reports---we also\ndemonstrate how the privacy cost of our LDP algorithm can actually be much\nlower when viewed in the central model of differential privacy. We show, via a\nnew and general privacy amplification technique, that any permutation-invariant\nalgorithm satisfying $\\varepsilon$-local differential privacy will satisfy\n$(O(\\varepsilon \\sqrt{\\log(1/\\delta)/n}), \\delta)$-central differential\nprivacy. By this, we explain how the high noise and $\\sqrt{n}$ overhead of LDP\nprotocols is a consequence of them being significantly more private in the\ncentral model. As a practical corollary, our results imply that several\nLDP-based industrial deployments may have much lower privacy cost than their\nadvertised $\\varepsilon$ would indicate---at least if reports are anonymized.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 20:24:45 GMT"}, {"version": "v2", "created": "Sun, 26 Jul 2020 01:37:51 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Erlingsson", "\u00dalfar", ""], ["Feldman", "Vitaly", ""], ["Mironov", "Ilya", ""], ["Raghunathan", "Ananth", ""], ["Talwar", "Kunal", ""], ["Thakurta", "Abhradeep", ""]]}, {"id": "1811.12470", "submitter": "Arjun Nitin Bhagoji", "authors": "Arjun Nitin Bhagoji, Supriyo Chakraborty, Prateek Mittal, Seraphin\n  Calo", "title": "Analyzing Federated Learning through an Adversarial Lens", "comments": "Extended version of paper accepted to ICML 2019, code available at\n  https://github.com/inspire-group/ModelPoisoning; 19 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning distributes model training among a multitude of agents,\nwho, guided by privacy concerns, perform training using their local data but\nshare only model parameter updates, for iterative aggregation at the server. In\nthis work, we explore the threat of model poisoning attacks on federated\nlearning initiated by a single, non-colluding malicious agent where the\nadversarial objective is to cause the model to misclassify a set of chosen\ninputs with high confidence. We explore a number of strategies to carry out\nthis attack, starting with simple boosting of the malicious agent's update to\novercome the effects of other agents' updates. To increase attack stealth, we\npropose an alternating minimization strategy, which alternately optimizes for\nthe training loss and the adversarial objective. We follow up by using\nparameter estimation for the benign agents' updates to improve on attack\nsuccess. Finally, we use a suite of interpretability techniques to generate\nvisual explanations of model decisions for both benign and malicious models and\nshow that the explanations are nearly visually indistinguishable. Our results\nindicate that even a highly constrained adversary can carry out model poisoning\nattacks while simultaneously maintaining stealth, thus highlighting the\nvulnerability of the federated learning setting and the need to develop\neffective defense strategies.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 20:27:14 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 17:14:03 GMT"}, {"version": "v3", "created": "Sat, 2 Mar 2019 22:04:18 GMT"}, {"version": "v4", "created": "Mon, 25 Nov 2019 00:34:14 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Bhagoji", "Arjun Nitin", ""], ["Chakraborty", "Supriyo", ""], ["Mittal", "Prateek", ""], ["Calo", "Seraphin", ""]]}, {"id": "1811.12476", "submitter": "Khaza Anuarul Hoque", "authors": "Aniket Gulhane, Akhil Vyas, Reshmi Mitra, Roland Oruche, Gabriela\n  Hoefer, Samaikya Valluripally, Prasad Calyam, Khaza Anuarul Hoque", "title": "Security, Privacy and Safety Risk Assessment for Virtual Reality\n  Learning Environment Applications", "comments": "Tp appear in the CCNC 2019 Conference", "journal-ref": null, "doi": "10.1109/CCNC.2019.8651847", "report-no": null, "categories": "cs.HC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social Virtual Reality based Learning Environments (VRLEs) such as vSocial\nrender instructional content in a three-dimensional immersive computer\nexperience for training youth with learning impediments. There are limited\nprior works that explored attack vulnerability in VR technology, and hence\nthere is a need for systematic frameworks to quantify risks corresponding to\nsecurity, privacy, and safety (SPS) threats. The SPS threats can adversely\nimpact the educational user experience and hinder delivery of VRLE content. In\nthis paper, we propose a novel risk assessment framework that utilizes attack\ntrees to calculate a risk score for varied VRLE threats with rate and duration\nof threats as inputs. We compare the impact of a well-constructed attack tree\nwith an adhoc attack tree to study the trade-offs between overheads in managing\nattack trees, and the cost of risk mitigation when vulnerabilities are\nidentified. We use a vSocial VRLE testbed in a case study to showcase the\neffectiveness of our framework and demonstrate how a suitable attack tree\nformalism can result in a more safer, privacy-preserving and secure VRLE\nsystem.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 20:46:35 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Gulhane", "Aniket", ""], ["Vyas", "Akhil", ""], ["Mitra", "Reshmi", ""], ["Oruche", "Roland", ""], ["Hoefer", "Gabriela", ""], ["Valluripally", "Samaikya", ""], ["Calyam", "Prasad", ""], ["Hoque", "Khaza Anuarul", ""]]}, {"id": "1811.12601", "submitter": "Angus Galloway", "authors": "Angus Galloway and Anna Golubeva and Graham W. Taylor", "title": "Adversarial Examples as an Input-Fault Tolerance Problem", "comments": "NIPS 2018 Workshop on Security and Machine Learning. Source available\n  at https://github.com/uoguelph-mlrg/nips18-secml-advex-input-fault", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the adversarial examples problem in terms of a model's fault\ntolerance with respect to its input. Whereas previous work focuses on\narbitrarily strict threat models, i.e., $\\epsilon$-perturbations, we consider\narbitrary valid inputs and propose an information-based characteristic for\nevaluating tolerance to diverse input faults.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 03:32:44 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Galloway", "Angus", ""], ["Golubeva", "Anna", ""], ["Taylor", "Graham W.", ""]]}, {"id": "1811.12620", "submitter": "Gurcan Comert", "authors": "Gurcan Comert, Mizanur Rahman, Mhafuzul Islam, Mashrur Chowdhury", "title": "Change Point Models for Real-time V2I Cyber Attack Detection in a\n  Connected Vehicle Environment", "comments": "7 pages, 1 figure, 2 tables, the 98th Annual Meeting of the\n  Transportation Research Board, January 13-17, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connected vehicle (CV) systems are cognizant of potential cyber attacks\nbecause of increasing connectivity between its different components such as\nvehicles, roadside infrastructure and traffic management centers. However, it\nis a challenge to detect security threats in real-time and develop\nappropriate/effective countermeasures for a CV system because of the dynamic\nbehavior of such attacks, high computational power requirement and a historical\ndata requirement for training detection models. To address these challenges,\nstatistical models, especially change point models, have potentials for\nreal-time anomaly detections. Thus, the objective of this study is to\ninvestigate the efficacy of two change point models, Expectation Maximization\n(EM) and Cumulative Sum (CUSUM), for real-time V2I cyber attack detection in a\nCV Environment. To prove the efficacy of these models, we evaluated these two\nmodels for three different type of cyber attack, denial of service (DOS),\nimpersonation, and false information, using basic safety messages (BSMs)\ngenerated from CVs through simulation. Results from numerical analysis revealed\nthat EM and CUSUM could detect these cyber attacks, DOS, impersonation, and\nfalse information, with an accuracy of 99\\%, 100\\%, and 98\\%, and 100\\%, 100\\%\nand 98\\%, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 05:25:45 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Comert", "Gurcan", ""], ["Rahman", "Mizanur", ""], ["Islam", "Mhafuzul", ""], ["Chowdhury", "Mashrur", ""]]}, {"id": "1811.12713", "submitter": "Mohammad Ghafari", "authors": "Pascal Gadient, Mohammad Ghafari, Patrick Frischknecht, Oscar\n  Nierstrasz", "title": "Security Code Smells in Android ICC", "comments": "Accepted on 28 Nov 2018, Empirical Software Engineering Journal\n  (EMSE), 2018", "journal-ref": null, "doi": "10.1007/s10664-018-9673-y", "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Android Inter-Component Communication (ICC) is complex, largely\nunconstrained, and hard for developers to understand. As a consequence, ICC is\na common source of security vulnerability in Android apps. To promote secure\nprogramming practices, we have reviewed related research, and identified\navoidable ICC vulnerabilities in Android-run devices and the security code\nsmells that indicate their presence. We explain the vulnerabilities and their\ncorresponding smells, and we discuss how they can be eliminated or mitigated\nduring development. We present a lightweight static analysis tool on top of\nAndroid Lint that analyzes the code under development and provides just-in-time\nfeedback within the IDE about the presence of such smells in the code.\nMoreover, with the help of this tool we study the prevalence of security code\nsmells in more than 700 open-source apps, and manually inspect around 15% of\nthe apps to assess the extent to which identifying such smells uncovers ICC\nsecurity vulnerabilities.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 10:44:36 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 10:38:30 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Gadient", "Pascal", ""], ["Ghafari", "Mohammad", ""], ["Frischknecht", "Patrick", ""], ["Nierstrasz", "Oscar", ""]]}, {"id": "1811.12715", "submitter": "Abbas Rasoolzadegan", "authors": "Abbas Javan Jafari and Abbas Rasoolzadegan", "title": "Security Patterns: A Systematic Mapping Study", "comments": "Keywords: Security Patterns, Systematic Review, Mapping Study, Secure\n  Software Development", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security patterns are a means to encapsulate and communicate proven security\nsolutions. They are well-established approaches for introducing security into\nthe software development process. Our objective is to explore the research\nefforts on security patterns and discuss the current state of the art. This\nstudy will serve as a guideline for researchers, practitioners, and teachers\ninterested in this field. We have conducted a systematic mapping study of\nrelevant literature from 1997 until the end of 2017 and identified 403 relevant\npapers, 274 of which were selected for analysis based on quality criteria. This\nstudy derives a customized research strategy from established systematic\napproaches in the literature. We have utilized an exhaustive 3-tier search\nstrategy to ensure a high degree of completeness during the study collection\nand used a test set to evaluate our search. The first 3 research questions\naddress the demographics of security pattern research such as topic\nclassification, trends, and distribution between academia and industry, along\nwith prominent researchers and venues. The next 9 research questions focus on\nmore in-depth analyses such as pattern presentation notations and\nclassification criteria, pattern evaluation techniques, and pattern usage\nenvironments. The results and discussions of this study have significant\nimplications for researchers, practitioners, and teachers in software\nengineering and information security.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 10:50:36 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Jafari", "Abbas Javan", ""], ["Rasoolzadegan", "Abbas", ""]]}, {"id": "1811.12740", "submitter": "Georgia Avarikioti", "authors": "Georgia Avarikioti, Felix Laufenberg, Jakub Sliwinski, Yuyi Wang,\n  Roger Wattenhofer", "title": "Towards Secure and Efficient Payment Channels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Micropayment channels are the most prominent solution to the limitation on\ntransaction throughput in current blockchain systems. However, in practice\nchannels are risky because participants have to be online constantly to avoid\nfraud, and inefficient because participants have to open multiple channels and\nlock funds in them. To address the security issue, we propose a novel mechanism\nthat involves watchtowers incentivized to watch the channels and reveal a\nfraud. Our protocol does not require participants to be online constantly\nwatching the blockchain. The protocol is secure, incentive compatible and\nlightweight in communication. Furthermore, we present an adaptation of our\nprotocol implementable on the Lightning protocol. Towards efficiency, we\nexamine specific topological structures in the blockchain transaction graph and\ngeneralize the construction of channels to enable topologies better suited to\nspecific real-world needs. In these cases, our construction reduces the\nrequired amount of signatures for a transaction and the total amount of locked\nfunds in the system.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 11:45:16 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Avarikioti", "Georgia", ""], ["Laufenberg", "Felix", ""], ["Sliwinski", "Jakub", ""], ["Wang", "Yuyi", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "1811.12775", "submitter": "Max Maass", "authors": "Max Maass, Nicolas Walter, Dominik Herrmann, Matthias Hollick", "title": "On the Difficulties of Incentivizing Online Privacy through\n  Transparency: A Qualitative Survey of the German Health Insurance Market", "comments": "Accepted to Wirtschaftsinformatik 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, online privacy is the domain of regulatory measures and\nprivacy-enhancing technologies. Transparency in the form of external and public\nassessments has been proposed for improving privacy and security because it\nexposes otherwise hidden deficiencies. Previous work has studied privacy\nattitudes and behavior of consumers. However, little is known on how\norganizations react to measures that employ public \"naming and shaming\" as an\nincentive for improvement. We performed the first study on this aspect by\nconducting a qualitative survey with 152 German health insurers. We scanned\ntheir websites with PrivacyScore.org to generate a public ranking and\nconfronted the insurers with the results. We obtained a response rate of 27%.\nResponses ranged from positive feedback to legal threats. Only 12% of the sites\n- mostly non-responders - improved during our study. Our results show that\ninsurers struggle due to unawareness, reluctance, and incapability, and\ndemonstrate the general difficulties of transparency-based approaches.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 13:10:48 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 16:52:08 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Maass", "Max", ""], ["Walter", "Nicolas", ""], ["Herrmann", "Dominik", ""], ["Hollick", "Matthias", ""]]}]