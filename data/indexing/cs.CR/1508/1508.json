[{"id": "1508.00184", "submitter": "Ali Al Imem", "authors": "Ali Al Imem", "title": "Comparison and evaluation of digital signature schemes employed in ndn\n  network", "comments": "International Journal of Software Engineering & Applications Volume:\n  7 - Volume No: 3 - issue: June 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named Data networking ensure data integrity so that every important data has\nto be signed by its owner in order to send it safely inside the network.\nSimilarly, in NDN we have to assure that none could open the data except\nauthorized users. Since only the endpoints have the right to sign the data or\ncheck its validity during the verification process, we have considered that the\ndata could be requested from various types of devices used by different people,\nthese devices could be anything like a smartphone, PC, sensor node with a\ndifferent CPU descriptions, parameters, and memory sizes, however their ability\nto check the high traffic of a data during the key generation and verification\nperiod is definitely a hard task and it could exhaust the systems with low\ncomputational resources. RSA and ECDSA as digital signature algorithms have\nproven their efficiency against cyber attacks, they are characterized by their\nspeed to encrypt and decrypt data, in addition to their competence at checking\nthe data integrity. The main purpose of our research was to find the optimal\nalgorithm that avoids the systems overhead and offers the best time during the\nsignature scheme\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2015 02:56:16 GMT"}], "update_date": "2015-08-04", "authors_parsed": [["Imem", "Ali Al", ""]]}, {"id": "1508.00545", "submitter": "Jun Zhao", "authors": "Jun Zhao, Osman Ya\\u{g}an, Virgil Gligor", "title": "Connectivity in Secure Wireless Sensor Networks under Transmission\n  Constraints", "comments": "Full version of a paper published in Annual Allerton Conference on\n  Communication, Control, and Computing (Allerton) 2014", "journal-ref": null, "doi": "10.1109/ALLERTON.2014.7028605", "report-no": null, "categories": "cs.CR cs.DM cs.IT math.IT math.PR physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In wireless sensor networks (WSNs), the Eschenauer-Gligor (EG) key\npre-distribution scheme is a widely recognized way to secure communications.\nAlthough connectivity properties of secure WSNs with the EG scheme have been\nextensively investigated, few results address physical transmission\nconstraints. These constraints reflect real-world implementations of WSNs in\nwhich two sensors have to be within a certain distance from each other to\ncommunicate. In this paper, we present zero-one laws for connectivity in WSNs\nemploying the EG scheme under transmission constraints. These laws help specify\nthe critical transmission ranges for connectivity. Our analytical findings are\nconfirmed via numerical experiments. In addition to secure WSNs, our\ntheoretical results are also applied to frequency hopping in wireless networks.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2015 19:33:34 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2015 01:38:11 GMT"}], "update_date": "2015-08-05", "authors_parsed": [["Zhao", "Jun", ""], ["Ya\u011fan", "Osman", ""], ["Gligor", "Virgil", ""]]}, {"id": "1508.00837", "submitter": "Gang Wang", "authors": "Gang Wang, Bolun Wang, Tianyi Wang, Ana Nika, Haitao Zheng, Ben Y.\n  Zhao", "title": "Defending against Sybil Devices in Crowdsourced Mapping Services", "comments": "Measure and integration", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time crowdsourced maps such as Waze provide timely updates on traffic,\ncongestion, accidents and points of interest. In this paper, we demonstrate how\nlack of strong location authentication allows creation of software-based {\\em\nSybil devices} that expose crowdsourced map systems to a variety of security\nand privacy attacks. Our experiments show that a single Sybil device with\nlimited resources can cause havoc on Waze, reporting false congestion and\naccidents and automatically rerouting user traffic. More importantly, we\ndescribe techniques to generate Sybil devices at scale, creating armies of\nvirtual vehicles capable of remotely tracking precise movements for large user\npopulations while avoiding detection. We propose a new approach to defend\nagainst Sybil devices based on {\\em co-location edges}, authenticated records\nthat attest to the one-time physical co-location of a pair of devices. Over\ntime, co-location edges combine to form large {\\em proximity graphs} that\nattest to physical interactions between devices, allowing scalable detection of\nvirtual vehicles. We demonstrate the efficacy of this approach using\nlarge-scale simulations, and discuss how they can be used to dramatically\nreduce the impact of attacks against crowdsourced mapping services.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2015 17:11:01 GMT"}, {"version": "v2", "created": "Wed, 27 Apr 2016 17:57:36 GMT"}], "update_date": "2016-04-28", "authors_parsed": [["Wang", "Gang", ""], ["Wang", "Bolun", ""], ["Wang", "Tianyi", ""], ["Nika", "Ana", ""], ["Zheng", "Haitao", ""], ["Zhao", "Ben Y.", ""]]}, {"id": "1508.01053", "submitter": "Manuel Rivas", "authors": "Manuel Jes\\'us Rivas S\\'andez", "title": "A Review of Technical Problems when Conducting an Investigation in Cloud\n  Based Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing is a relatively new technology which is quickly becoming one\nof the most important technological advances for computer science. This\ntechnology has had a significant growth in recent years. It is now more\naffordable and cloud platforms are becoming more stable. Businesses are\nsuccessfully migrating their systems to a cloud infrastructure, obtaining\ntechnological and economic benefits. However, others still remain reluctant to\ndo it due to both security concerns and the loss of control over their\ninfrastructures and data that the migration entails. At the same time that new\ntechnologies progress, its benefits appeal to criminals too. They can not only\nsteal data from clouds, but they can also hide data in clouds, which has\nprovoked an increased in the number of cybercrimes and their economic impacts.\nTheir victims range from children and adults to companies and even countries.\nOn the other hand, digital forensics have negatively suffered the impact of the\nboom of cloud computing due to its dynamic nature. The tools and procedures\nthat were successfully proved and used in digital investigations are now\nbecoming irrelevant, making it an urging necessity to develop new forensics\ncapabilities for conducting an investigation in this new environment. As a\nconsequence of these needs a new area has emerged, Cloud Forensics, which is\nthe result of the intersection between cloud computing and digital forensics.\n  Keywords: Cloud forensics, cloud computing, forensics investigation, forensic\nchallenges.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2015 12:34:24 GMT"}], "update_date": "2015-08-06", "authors_parsed": [["S\u00e1ndez", "Manuel Jes\u00fas Rivas", ""]]}, {"id": "1508.01295", "submitter": "Kittipong Kittichokechai", "authors": "Kittipong Kittichokechai and Giuseppe Caire", "title": "Secret key-based Identification and Authentication with a Privacy\n  Constraint", "comments": "33 pages, 3 figures, submitted to IEEE Transactions on Information\n  Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of identification and authentication based on secret\nkey generation from some user-generated source data (e.g., a biometric source).\nThe goal is to reliably identify users pre-enrolled in a database as well as\nauthenticate them based on the estimated secret key while preserving the\nprivacy of the enrolled data and of the generated keys. We characterize the\noptimal tradeoff between the identification rate, the compression rate of the\nusers' source data, information leakage rate, and secret key rate. In\nparticular, we provide a coding strategy based on layered random binning which\nis shown to be optimal. In addition, we study a related secure\nidentification/authentication problem where an adversary tries to deceive the\nsystem using its own data. Here the optimal tradeoff between the identification\nrate, compression rate, leakage rate, and exponent of the maximum false\nacceptance probability is provided. The results reveal a close connection\nbetween the optimal secret key rate and the false acceptance exponent of the\nidentification/authentication system.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2015 07:16:45 GMT"}], "update_date": "2015-08-07", "authors_parsed": [["Kittichokechai", "Kittipong", ""], ["Caire", "Giuseppe", ""]]}, {"id": "1508.01324", "submitter": "Nisha Panwar", "authors": "Shlomi Dolev, Lukasz Krzywiecki, Nisha Panwar, Michael Segal", "title": "Vehicle to Vehicle Authentication", "comments": "This is a version that appeared as a brief announcement in 17th\n  International Symposium on Stabilization, Safety, and Security of Distributed\n  Systems (SSS, 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent future, vehicles will establish a spontaneous connection over a\nwireless radio channel, coordinating actions and information. Vehicles will\nexchange warning messages over the wireless radio channel through Dedicated\nShort Range Communication (IEEE 1609) over the Wireless Access in Vehicular\nEnvironment (802.11p). Unfortunately, the wireless communication among vehicles\nis vulnerable to security threats that may lead to very serious safety hazards.\nTherefore, the warning messages being exchanged must incorporate an authentic\nfactor such that recipient is willing to verify and accept the message in a\ntimely manner\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2015 08:49:28 GMT"}], "update_date": "2015-08-07", "authors_parsed": [["Dolev", "Shlomi", ""], ["Krzywiecki", "Lukasz", ""], ["Panwar", "Nisha", ""], ["Segal", "Michael", ""]]}, {"id": "1508.01375", "submitter": "Yara Elias", "authors": "Yara Elias, Kristin E. Lauter, Ekin Ozman, Katherine E. Stange", "title": "Ring-LWE Cryptography for the Number Theorist", "comments": "20 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we survey the status of attacks on the ring and polynomial\nlearning with errors problems (RLWE and PLWE). Recent work on the security of\nthese problems [Eisentr\\\"ager-Hallgren-Lauter, Elias-Lauter-Ozman-Stange] gives\nrise to interesting questions about number fields. We extend these attacks and\nsurvey related open problems in number theory, including spectral distortion of\nan algebraic number and its relationship to Mahler measure, the monogenic\nproperty for the ring of integers of a number field, and the size of elements\nof small order modulo q.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2015 12:35:59 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2015 06:14:28 GMT"}], "update_date": "2015-09-24", "authors_parsed": [["Elias", "Yara", ""], ["Lauter", "Kristin E.", ""], ["Ozman", "Ekin", ""], ["Stange", "Katherine E.", ""]]}, {"id": "1508.01420", "submitter": "Luis Marujo", "authors": "Lu\\'is Marujo, Jos\\'e Port\\^elo, Wang Ling, David Martins de Matos,\n  Jo\\~ao P. Neto, Anatole Gershman, Jaime Carbonell, Isabel Trancoso, Bhiksha\n  Raj", "title": "Privacy-Preserving Multi-Document Summarization", "comments": "4 pages, In Proceedings of 2nd ACM SIGIR Workshop on\n  Privacy-Preserving Information Retrieval, August 2015. arXiv admin note: text\n  overlap with arXiv:1407.5416", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art extractive multi-document summarization systems are usually\ndesigned without any concern about privacy issues, meaning that all documents\nare open to third parties. In this paper we propose a privacy-preserving\napproach to multi-document summarization. Our approach enables other parties to\nobtain summaries without learning anything else about the original documents'\ncontent. We use a hashing scheme known as Secure Binary Embeddings to convert\ndocuments representation containing key phrases and bag-of-words into bit\nstrings, allowing the computation of approximate distances, instead of exact\nones. Our experiments indicate that our system yields similar results to its\nnon-private counterpart on standard multi-document evaluation datasets.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2015 14:30:47 GMT"}], "update_date": "2015-08-07", "authors_parsed": [["Marujo", "Lu\u00eds", ""], ["Port\u00ealo", "Jos\u00e9", ""], ["Ling", "Wang", ""], ["de Matos", "David Martins", ""], ["Neto", "Jo\u00e3o P.", ""], ["Gershman", "Anatole", ""], ["Carbonell", "Jaime", ""], ["Trancoso", "Isabel", ""], ["Raj", "Bhiksha", ""]]}, {"id": "1508.01430", "submitter": "Mohammad Salam", "authors": "Mohammad Abdus Salam, Alfred Sarkodee-Adoo", "title": "Referencing Tool for Reputation and Trust in Wireless Sensor Networks", "comments": "13 pages", "journal-ref": "International Journal of Computer Networks & Communications\n  (IJCNC) Vol.7, No.4, pp. 139-151, July 2015", "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Presently, there are not many literatures on the characterization of\nreputation and trust in wireless sensor networks (WSNs) which can be referenced\nby scientists, researchers and students. Although some research documents\ninclude information on reputation and trust, characterization of these features\nare not adequately covered. In this paper, reputation and trust are divided\ninto various classes or categories and a method of referencing the information\nis provided. This method used results in providing researchers with a tool that\nmakes it easier to reference these features on reputation and trust in a much\neasier way than if referencing has to be directed to several uncoordinated\nresources. Although the outcome of this work proves beneficial to research in\nthe characterization of reputation and trust in WSNs, more work needs to be\ndone in extending the benefits to other network systems.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2015 15:16:14 GMT"}], "update_date": "2015-08-07", "authors_parsed": [["Salam", "Mohammad Abdus", ""], ["Sarkodee-Adoo", "Alfred", ""]]}, {"id": "1508.01575", "submitter": "Lei Zhang", "authors": "Lei Zhang, Chuanyan Hu, Qianhong Wu, Josep Domingo-Ferrer, Bo Qin", "title": "On the Security of Privacy-Preserving Vehicular Communication\n  Authentication with Hierarchical Aggregation and Fast Response", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In [3], the authors proposed a highly efficient secure and privacy-preserving\nscheme for secure vehicular communications. The proposed scheme consists of\nfour protocols: system setup, protocol for STP and STK distribution, protocol\nfor common string synchronization, and protocol for vehicular communications.\nHere we define the security models for the protocol for STP and STK\ndistribution, and the protocol for vehicular communications,respectively. We\nthen prove that these two protocols are secure in our models.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2015 00:30:17 GMT"}], "update_date": "2015-08-10", "authors_parsed": [["Zhang", "Lei", ""], ["Hu", "Chuanyan", ""], ["Wu", "Qianhong", ""], ["Domingo-Ferrer", "Josep", ""], ["Qin", "Bo", ""]]}, {"id": "1508.01651", "submitter": "David Barrera", "authors": "David Barrera, Raphael M. Reischuk, Pawel Szalachowski, Adrian Perrig", "title": "SCION Five Years Later: Revisiting Scalability, Control, and Isolation\n  on Next-Generation Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The SCION (Scalability, Control, and Isolation on Next-generation Networks)\ninter-domain network architecture was proposed to address the availability,\nscalability, and security shortcomings of the current Internet. This paper\npresents a retrospective of the SCION goals and design decisions, its attacker\nmodel and limitations, and research highlights of work conducted in the 5 years\nfollowing SCION's initial publication.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2015 10:20:19 GMT"}], "update_date": "2015-08-10", "authors_parsed": [["Barrera", "David", ""], ["Reischuk", "Raphael M.", ""], ["Szalachowski", "Pawel", ""], ["Perrig", "Adrian", ""]]}, {"id": "1508.01703", "submitter": "Kasra Madadipouya", "authors": "Mohammad Ahmadi, Mostafa Vali, Farez Moghaddam, Aida Hakemi, Kasra\n  Madadipouya", "title": "A Reliable User Authentication and Data Protection Model in Cloud\n  Computing Environments", "comments": "4 pages in International Conference on Information, System and\n  Convergence Applications June 24-27, 2015 in Kuala Lumpur, Malaysia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security issues are the most challenging problems in cloud computing\nenvironments as an emerging technology. Regarding to this importance, an\nefficient and reliable user authentication and data protection model has been\npresented in this paper to increase the rate of reliability cloud-based\nenvironments. Accordingly, two encryption procedures have been established in\nan independent middleware (Agent) to perform the process of user\nauthentication, access control, and data protection in cloud servers. AES has\nbeen used as a symmetric cryptography algorithm in cloud servers and RSA has\nbeen used as an asymmetric cryptography algorithm in Agent servers. The\ntheoretical evaluation of the proposed model shows that the ability of\nresistance in face with possible attacks and unpredictable events has been\nenhanced considerably in comparison with similar models because of using dual\nencryption and an independent middleware during user authentication and data\nprotection procedures.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2015 14:24:14 GMT"}], "update_date": "2015-08-10", "authors_parsed": [["Ahmadi", "Mohammad", ""], ["Vali", "Mostafa", ""], ["Moghaddam", "Farez", ""], ["Hakemi", "Aida", ""], ["Madadipouya", "Kasra", ""]]}, {"id": "1508.01706", "submitter": "Kasra Madadipouya", "authors": "Jaderian Morteza, Moradzadeh Hossein, Madadipouya Kasra, Firoozinia\n  Mohammad and Shamshirband Shahaboddin", "title": "A Method in Security of Wireless Sensor Network based on Optimized\n  Artificial immune system in Multi-Agent Environments", "comments": "8 pages", "journal-ref": "Research Journal of Recent Sciences, Vol. 2(10), 99-106, October\n  (2013)", "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security in computer networks is one of the most interesting aspects of\ncomputer systems. It is typically represented by the initials CIA:\nconfidentiality, integrity, and authentication or availability. Although, many\naccess levels for data protection have been identified in computer networks,\nthe intruders would still find lots of ways to harm sites and systems. The\naccommodation proceedings and the security supervision in the network systems,\nespecially wireless sensor networks have been changed into a challenging point.\nOne of the newest security algorithms for wireless sensor networks is\nArtificial Immune System (AIS) algorithm. Human lymphocytes play the main role\nin recognizing and destroying the unknown elements. In this article, we focus\non the inspiration of these defective systems to guarantee the complications\nsecurity using two algorithms; the first algorithms proposed to distinguish\nself-nodes from non-self ones by the related factors and the second one is to\neliminate the enemy node danger.The results showed a high rate success and good\nrate of detecting for unknown object; it could present the best nodes with high\naffinity and fitness to be selected to confront the unknown agents.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2015 14:32:10 GMT"}], "update_date": "2015-11-02", "authors_parsed": [["Morteza", "Jaderian", ""], ["Hossein", "Moradzadeh", ""], ["Kasra", "Madadipouya", ""], ["Mohammad", "Firoozinia", ""], ["Shahaboddin", "Shamshirband", ""]]}, {"id": "1508.01707", "submitter": "Wanpeng Li", "authors": "Wanpeng Li and Chris J Mitchell", "title": "Analysing the Security of Google's implementation of OpenID Connect", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many millions of users routinely use their Google accounts to log in to\nrelying party (RP) websites supporting the Google OpenID Connect service.\nOpenID Connect, a newly standardised single-sign-on protocol, builds an\nidentity layer on top of the OAuth 2.0 protocol, which has itself been widely\nadopted to support identity management services. It adds identity management\nfunctionality to the OAuth 2.0 system and allows an RP to obtain assurances\nregarding the authenticity of an end user. A number of authors have analysed\nthe security of the OAuth 2.0 protocol, but whether OpenID Connect is secure in\npractice remains an open question. We report on a large-scale practical study\nof Google's implementation of OpenID Connect, involving forensic examination of\n103 RP websites which support its use for sign-in. Our study reveals serious\nvulnerabilities of a number of types, all of which allow an attacker to log in\nto an RP website as a victim user. Further examination suggests that these\nvulnerabilities are caused by a combination of Google's design of its OpenID\nConnect service and RP developers making design decisions which sacrifice\nsecurity for simplicity of implementation. We also give practical\nrecommendations for both RPs and OPs to help improve the security of real world\nOpenID Connect systems.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2015 14:33:03 GMT"}], "update_date": "2015-08-10", "authors_parsed": [["Li", "Wanpeng", ""], ["Mitchell", "Chris J", ""]]}, {"id": "1508.01719", "submitter": "Daniel Fett", "authors": "Daniel Fett and Ralf Kuesters and Guido Schmitz", "title": "SPRESSO: A Secure, Privacy-Respecting Single Sign-On System for the Web", "comments": "Parts of this work extend the web model presented in arXiv:1411.7210\n  and arXiv:1403.1866", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single sign-on (SSO) systems, such as OpenID and OAuth, allow web sites,\nso-called relying parties (RPs), to delegate user authentication to identity\nproviders (IdPs), such as Facebook or Google. These systems are very popular,\nas they provide a convenient means for users to log in at RPs and move much of\nthe burden of user authentication from RPs to IdPs.\n  There is, however, a downside to current systems, as they do not respect\nusers' privacy: IdPs learn at which RP a user logs in. With one exception,\nnamely Mozilla's BrowserID system (a.k.a. Mozilla Persona), current SSO systems\nwere not even designed with user privacy in mind. Unfortunately, recently\ndiscovered attacks, which exploit design flaws of BrowserID, show that\nBrowserID does not provide user privacy either.\n  In this paper, we therefore propose the first privacy-respecting SSO system\nfor the web, called SPRESSO (for Secure Privacy-REspecting Single Sign-On). The\nsystem is easy to use, decentralized, and platform independent. It is based\nsolely on standard HTML5 and web features and uses no browser extensions,\nplug-ins, or other executables.\n  Existing SSO systems and the numerous attacks on such systems illustrate that\nthe design of secure SSO systems is highly non-trivial. We therefore also carry\nout a formal analysis of SPRESSO based on an expressive model of the web in\norder to formally prove that SPRESSO enjoys strong authentication and privacy\nproperties.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2015 15:12:53 GMT"}], "update_date": "2015-08-10", "authors_parsed": [["Fett", "Daniel", ""], ["Kuesters", "Ralf", ""], ["Schmitz", "Guido", ""]]}, {"id": "1508.01746", "submitter": "Alan Godoy", "authors": "Alan Godoy, Fl\\'avio Sim\\~oes, Jos\\'e Augusto Stuchi, Marcus de Assis\n  Angeloni, M\\'ario Uliani, Ricardo Violato", "title": "Using Deep Learning for Detecting Spoofing Attacks on Speech Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that speaker verification systems are subject to spoofing\nattacks. The Automatic Speaker Verification Spoofing and Countermeasures\nChallenge -- ASVSpoof2015 -- provides a standard spoofing database, containing\nattacks based on synthetic speech, along with a protocol for experiments. This\npaper describes CPqD's systems submitted to the ASVSpoof2015 Challenge, based\non deep neural networks, working both as a classifier and as a feature\nextraction module for a GMM and a SVM classifier. Results show the validity of\nthis approach, achieving less than 0.5\\% EER for known attacks.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2015 16:20:52 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2016 16:27:49 GMT"}], "update_date": "2016-01-20", "authors_parsed": [["Godoy", "Alan", ""], ["Sim\u00f5es", "Fl\u00e1vio", ""], ["Stuchi", "Jos\u00e9 Augusto", ""], ["Angeloni", "Marcus de Assis", ""], ["Uliani", "M\u00e1rio", ""], ["Violato", "Ricardo", ""]]}, {"id": "1508.01818", "submitter": "Chong Huang", "authors": "Chong Huang, Lalitha Sankar and Anand D. Sarwate", "title": "Designing Incentive Schemes For Privacy-Sensitive Users", "comments": "25 pages, 10 figures, submitted to journal of privacy and\n  confidentiality", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Businesses (retailers) often wish to offer personalized advertisements\n(coupons) to individuals (consumers), but run the risk of strong reactions from\nconsumers who want a customized shopping experience but feel their privacy has\nbeen violated. Existing models for privacy such as differential privacy or\ninformation theory try to quantify privacy risk but do not capture the\nsubjective experience and heterogeneous expression of privacy-sensitivity. We\npropose a Markov decision process (MDP) model to capture (i) different consumer\nprivacy sensitivities via a time-varying state; (ii) different coupon types\n(action set) for the retailer; and (iii) the action-and-state-dependent cost\nfor perceived privacy violations. For the simple case with two states (\"Normal\"\nand \"Alerted\"), two coupons (targeted and untargeted) model, and consumer\nbehavior statistics known to the retailer, we show that a stationary\nthreshold-based policy is the optimal coupon-offering strategy for a retailer\nthat wishes to minimize its expected discounted cost. The threshold is a\nfunction of all model parameters; the retailer offers a targeted coupon if\ntheir belief that the consumer is in the \"Alerted\" state is below the\nthreshold. We extend this two-state model to consumers with multiple\nprivacy-sensitivity states as well as coupon-dependent state transition\nprobabilities. Furthermore, we study the case with imperfect (noisy) cost\nfeedback from consumers and uncertain initial belief state.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2015 21:11:21 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2015 17:29:05 GMT"}], "update_date": "2015-09-24", "authors_parsed": [["Huang", "Chong", ""], ["Sankar", "Lalitha", ""], ["Sarwate", "Anand D.", ""]]}, {"id": "1508.01890", "submitter": "Tala Tafazzoli", "authors": "Tala Tafazzoli, Elham Salahi, Hossein Gharaee", "title": "A proposed architecture for network forensic system in large-scale\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cybercrime is increasing at a faster pace and sometimes causes billions of\ndollars of business- losses so investigating attackers after commitment is of\nutmost importance and become one of the main concerns of network managers.\nNetwork forensics as the process of Collecting, identifying, extracting and\nanalyzing data and systematically monitoring traffic of network is one of the\nmain requirements in detection and tracking of criminals. In this paper, we\npropose an architecture for network forensic system. Our proposed architecture\nconsists of five main components: collection and indexing, database management,\nanalysis component, SOC communication component and the database. The main\ndifference between our proposed architecture and other systems is in analysis\ncomponent. This component is composed of four parts: Analysis and investigation\nsubsystem, Reporting subsystem, Alert and visualization subsystem and the\nmalware analysis subsystem. The most important differentiating factors of the\nproposed system with existing systems are: clustering and ranking of malware,\ndynamic analysis of malware, collecting and analysis of network flows and\nanomalous behaviour analysis.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2015 11:56:53 GMT"}], "update_date": "2015-08-11", "authors_parsed": [["Tafazzoli", "Tala", ""], ["Salahi", "Elham", ""], ["Gharaee", "Hossein", ""]]}, {"id": "1508.01893", "submitter": "Erika Andersson", "authors": "Ryan Amiri and Erika Andersson", "title": "Unconditionally Secure Quantum Signatures", "comments": "16 pages; an accessible short review paper in a special issue on\n  Quantum Cryptography", "journal-ref": "Entropy 2015, 17(8), 5635-5659", "doi": "10.3390/e17085635", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signature schemes, proposed in 1976 by Diffie and Hellman, have become\nubiquitous across modern communications. They allow for the exchange of\nmessages from one sender to multiple recipients, with the guarantees that\nmessages cannot be forged or tampered with and that messages also can be\nforwarded from one recipient to another without compromising their validity.\nSignatures are different from, but no less important than encryption, which\nensures the privacy of a message. Commonly used signature protocols -\nsignatures based on the Rivest-Adleman-Shamir (RSA) algorithm, the digital\nsignature algorithm (DSA), and the elliptic curve digital signature algorithm\n(ECDSA) - are only computationally secure, similar to public key encryption\nmethods. In fact, since these rely on the difficulty of finding discrete\nlogarithms or factoring large primes, it is known that they will become\ncompletely insecure with the emergence of quantum computers. We may therefore\nsee a shift towards signature protocols that will remain secure even in a\npost-quantum world. Ideally, such schemes would provide unconditional or\ninformation-theoretic security. In this paper, we aim to provide an accessible\nand comprehensive review of existing unconditionally secure signature schemes\nfor signing classical messages, with a focus on unconditionally secure quantum\nsignature schemes.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2015 12:25:24 GMT"}], "update_date": "2015-08-11", "authors_parsed": [["Amiri", "Ryan", ""], ["Andersson", "Erika", ""]]}, {"id": "1508.02035", "submitter": "Hossein Khani", "authors": "Hossein Khani and Mohsen Afsharchi", "title": "Security Games with Ambiguous Beliefs of Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently the Dempster-Shafer based algorithm and Uniform Random Probability\nbased algorithm are the preferred method of resolving security games, in which\ndefenders are able to identify attackers and only strategy remained ambiguous.\nHowever this model is inefficient in situations where resources are limited and\nboth the identity of the attackers and their strategies are ambiguous. The\nintent of this study is to find a more effective algorithm to guide the\ndefenders in choosing which outside agents with which to cooperate given both\nambiguities. We designed an experiment where defenders were compelled to engage\nwith outside agents in order to maximize protection of their targets. We\nintroduced two important notions: the behavior of each agent in target\nprotection and the tolerance threshold in the target protection process. From\nthese, we proposed an algorithm that was applied by each defender to determine\nthe best potential assistant(s) with which to cooperate. Our results showed\nthat our proposed algorithm is safer than the Dempster-Shafer based algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2015 14:54:57 GMT"}], "update_date": "2015-08-11", "authors_parsed": [["Khani", "Hossein", ""], ["Afsharchi", "Mohsen", ""]]}, {"id": "1508.02082", "submitter": "Binjie Benjamin Lim", "authors": "Benjamin Lim", "title": "Vulnerability Analysis of GWireless", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless networking has become very popular in recent years due to the\nincrease in adoption of mobile devices. As more and more employees demand for\nWi-Fi access for their devices, more companies have been jumping onto the\n\"Bring Your Own Device\" (BYOD) bandwagon[1] to appease their employees. One\nsuch example of an enterprise wireless infrastructure is the George Washington\nUniversity's GWireless.\n  For this project, I will attempt to capture hashes of authentication\ncredentials from users who are connecting to the GWireless network using what\nis commonly known as the \"evil twin\" attack. I will document the hardware,\nsoftware used and steps taken to configure the devices. I will then evaluate\nthe feasibility of such an attack, explore variations of the attack and\ndocument measures that can be taken to prevent such an attack.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2015 20:45:50 GMT"}], "update_date": "2015-08-11", "authors_parsed": [["Lim", "Benjamin", ""]]}, {"id": "1508.02448", "submitter": "Omar Chowdhury", "authors": "Omar Chowdhury, Deepak Garg, Limin Jia, and Anupam Datta", "title": "Equivalence-based Security for Querying Encrypted Databases: Theory and\n  Application to Privacy Policy Audits", "comments": "CCS 2015 paper technical report, in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the problem of simultaneously preserving confidentiality and\nusability of data outsourced to third-party clouds, we present two different\ndatabase encryption schemes that largely hide data but reveal enough\ninformation to support a wide-range of relational queries. We provide a\nsecurity definition for database encryption that captures confidentiality based\non a notion of equivalence of databases from the adversary's perspective. As a\nspecific application, we adapt an existing algorithm for finding violations of\nprivacy policies to run on logs encrypted under our schemes and observe low to\nmoderate overheads.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2015 22:37:54 GMT"}], "update_date": "2015-08-12", "authors_parsed": [["Chowdhury", "Omar", ""], ["Garg", "Deepak", ""], ["Jia", "Limin", ""], ["Datta", "Anupam", ""]]}, {"id": "1508.02526", "submitter": "George Grispos", "authors": "George Grispos, William Bradley Glisson, Tim Storer", "title": "Security Incident Response Criteria: A Practitioner's Perspective", "comments": "The 21st Americas Conference on Information Systems (AMCIS 2015),\n  Puerto Rico, USA.\n  http://aisel.aisnet.org/amcis2015/ISSecurity/GeneralPresentations/35/. August\n  13-15, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industrial reports indicate that security incidents continue to inflict large\nfinancial losses on organizations. Researchers and industrial analysts contend\nthat there are fundamental problems with existing security incident response\nprocess solutions. This paper presents the Security Incident Response Criteria\n(SIRC) which can be applied to a variety of security incident response\napproaches. The criteria are derived from empirical data based on in-depth\ninterviews conducted within a Global Fortune 500 organization and supporting\nliterature. The research contribution of this paper is twofold. First, the\ncriteria presented in this paper can be used to evaluate existing security\nincident response solutions and second, as a guide, to support future security\nincident response improvement initiatives.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2015 09:10:17 GMT"}], "update_date": "2015-08-12", "authors_parsed": [["Grispos", "George", ""], ["Glisson", "William Bradley", ""], ["Storer", "Tim", ""]]}, {"id": "1508.02984", "submitter": "Hsien-Pu Chen", "authors": "Hsien-Pu Chen, Elias Gonzalez, Yessica Saez, and Laszlo B. Kish", "title": "Cable Capacitance Attack against the KLJN Secure Key Exchange", "comments": "Accepted for publication in the journal: Information", "journal-ref": "Information 2015, 6(4), 719-732", "doi": "10.3390/info6040719", "report-no": null, "categories": "cs.ET cs.CR physics.class-ph", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The security of the Kirchhoff-law-Johnson-(like)-noise (KLJN) key exchange\nsystem is based on the Fluctuation-Dissipation-Theorem of classical statistical\nphysics. Similarly to quantum key distribution, in practical situations, due to\nthe non-idealities of the building elements, there is a small information leak,\nwhich can be mitigated by privacy amplification or other techniques so that the\nunconditional (information theoretic) security is preserved. In this paper, the\nindustrial cable and circuit simulator LTSPICE is used to validate the\ninformation leak due to one of the non-idealities in KLJN, the parasitic\n(cable) capacitance. Simulation results show that privacy amplification and/or\ncapacitor killer (capacitance compensation) arrangements can effectively\neliminate the leak.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2015 05:41:03 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2015 15:38:45 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2015 21:58:35 GMT"}, {"version": "v4", "created": "Mon, 26 Oct 2015 19:48:53 GMT"}], "update_date": "2015-11-23", "authors_parsed": [["Chen", "Hsien-Pu", ""], ["Gonzalez", "Elias", ""], ["Saez", "Yessica", ""], ["Kish", "Laszlo B.", ""]]}, {"id": "1508.03096", "submitter": "Konstantin Berlin", "authors": "Joshua Saxe, Konstantin Berlin", "title": "Deep Neural Network Based Malware Detection Using Two Dimensional Binary\n  Program Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware remains a serious problem for corporations, government agencies, and\nindividuals, as attackers continue to use it as a tool to effect frequent and\ncostly network intrusions. Machine learning holds the promise of automating the\nwork required to detect newly discovered malware families, and could\npotentially learn generalizations about malware and benign software that\nsupport the detection of entirely new, unknown malware families. Unfortunately,\nfew proposed machine learning based malware detection methods have achieved the\nlow false positive rates required to deliver deployable detectors.\n  In this paper we a deep neural network malware classifier that achieves a\nusable detection rate at an extremely low false positive rate and scales to\nreal world training example volumes on commodity hardware. Specifically, we\nshow that our system achieves a 95% detection rate at 0.1% false positive rate\n(FPR), based on more than 400,000 software binaries sourced directly from our\ncustomers and internal malware databases. We achieve these results by directly\nlearning on all binaries, without any filtering, unpacking, or manually\nseparating binary files into categories. Further, we confirm our false positive\nrates directly on a live stream of files coming in from Invincea's deployed\nendpoint solution, provide an estimate of how many new binary files we expected\nto see a day on an enterprise network, and describe how that relates to the\nfalse positive rate and translates into an intuitive threat score.\n  Our results demonstrate that it is now feasible to quickly train and deploy a\nlow resource, highly accurate machine learning classification model, with false\npositive rates that approach traditional labor intensive signature based\nmethods, while also detecting previously unseen malware.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2015 01:22:13 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2015 13:22:28 GMT"}], "update_date": "2015-09-04", "authors_parsed": [["Saxe", "Joshua", ""], ["Berlin", "Konstantin", ""]]}, {"id": "1508.03410", "submitter": "Damon McCoy", "authors": "Mohammad Karami, Youngsam Park, Damon McCoy", "title": "Stress Testing the Booters: Understanding and Undermining the Business\n  of DDoS Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DDoS-for-hire services, also known as booters, have commoditized DDoS attacks\nand enabled abusive subscribers of these services to cheaply extort, harass and\nintimidate businesses and people by knocking them offline. However, due to the\nunderground nature of these booters, little is known about their underlying\ntechnical and business structure. In this paper we empirically measure many\nfacets of their technical and payment infrastructure. We also perform an\nanalysis of leaked and scraped data from three major booters---Asylum Stresser,\nLizard Stresser and VDO---which provides us with an in-depth view of their\ncustomers and victims. Finally, we conduct a large-scale payment intervention\nin collaboration with PayPal and evaluate its effectiveness. Based on our\nanalysis we show that these services are responsible for hundreds of thousands\nof DDoS attacks and identify potentially promising methods of increasing\nbooters' costs and undermining these services.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2015 03:25:57 GMT"}], "update_date": "2015-08-17", "authors_parsed": [["Karami", "Mohammad", ""], ["Park", "Youngsam", ""], ["McCoy", "Damon", ""]]}, {"id": "1508.03629", "submitter": "Laurent Fournier", "authors": "Laurent Fournier", "title": "RFC 7800 - Money Over IP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This Request For Comment (RFC) is a proposal for a new protocol to use money\nover the Internet. Features like a distributed architecture, a published\ncryptographic algorithm, a minimal authority responsibility, the absence of\nfees will make this protocol a perfect tool for citizens in today's digital\nWorld. An implementation has validated the main principles and we entering now\na testing phase (v0.1). Depending of the results, a released date for the 1.0\nrevision will to decided to allow anybody to send or to receive money to/from\nanyone, in any currency, with a regular and personal smart-phone. A distributed\nhash table (DHT) is used to store all transactions, public keys and\ncertificates redundantly on several nodes. The all system may replace coins,\nbanknotes and classical checks in the future. We also argue that the Bitcoin\ntechnology does not satisfy the requirements for a digital mean of payment.\nThis proposal is expected to be reviewed and commented by the Internet\nEngineering Task Force.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2015 09:38:33 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2015 13:34:48 GMT"}, {"version": "v3", "created": "Fri, 28 Aug 2015 13:25:22 GMT"}], "update_date": "2015-08-31", "authors_parsed": [["Fournier", "Laurent", ""]]}, {"id": "1508.03657", "submitter": "Geir Agnarsson", "authors": "Geir Agnarsson, Raymond Greenlaw, Sanpawat Kantabutra", "title": "The complexity of cyber attacks in a new layered-security model and the\n  maximum-weight, rooted-subtree problem", "comments": "18 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our cyber security model we define the concept of {\\em penetration cost},\nwhich is the cost that must be paid in order to break into the next layer of\nsecurity. Given a tree $T$ rooted at a vertex $r$, a {\\em penetrating cost}\nedge function $c$ on $T$, a {\\em target-acquisition} vertex function $p$ on\n$T$, the attacker's {\\em budget} and the {\\em game-over threshold} $B,G \\in\n{\\mathbb{Q}}^{+}$ respectively, we consider the problem of determining the\nexistence of a rooted subtree $T'$ of $T$ within the attacker's budget (that\nis, the sum of the costs of the edges in $T'$ is less than or equal to $B$)\nwith total acquisition value more than the game-over threshold (that is, the\nsum of the target values of the nodes in $T'$ is greater than or equal to $G$).\nWe prove that the general version of this problem is intractable, but does\nadmit a polynomial time approximation scheme. We also analyze the complexity of\nthree restricted versions of the problems, where the penetration cost is the\nconstant function, integer-valued, and rational-valued among a given fixed\nnumber of distinct values.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2015 16:00:30 GMT"}], "update_date": "2015-08-18", "authors_parsed": [["Agnarsson", "Geir", ""], ["Greenlaw", "Raymond", ""], ["Kantabutra", "Sanpawat", ""]]}, {"id": "1508.03664", "submitter": "Ioannis Chatzigeorgiou", "authors": "Amjad Saeed Khan and Andrea Tassi and Ioannis Chatzigeorgiou", "title": "Rethinking the Intercept Probability of Random Linear Network Coding", "comments": "IEEE Communications Letters, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT cs.NI cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This letter considers a network comprising a transmitter, which employs\nrandom linear network coding to encode a message, a legitimate receiver, which\ncan recover the message if it gathers a sufficient number of linearly\nindependent coded packets, and an eavesdropper. Closed-form expressions for the\nprobability of the eavesdropper intercepting enough coded packets to recover\nthe message are derived. Transmission with and without feedback is studied.\nFurthermore, an optimization model that minimizes the intercept probability\nunder delay and reliability constraints is presented. Results validate the\nproposed analysis and quantify the secrecy gain offered by a feedback link from\nthe legitimate receiver.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2015 21:08:32 GMT"}], "update_date": "2015-08-18", "authors_parsed": [["Khan", "Amjad Saeed", ""], ["Tassi", "Andrea", ""], ["Chatzigeorgiou", "Ioannis", ""]]}, {"id": "1508.03687", "submitter": "Shachar Siboni", "authors": "Shachar Siboni and Asaf Cohen", "title": "Universal Anomaly Detection: Algorithms and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern computer threats are far more complicated than those seen in the past.\nThey are constantly evolving, altering their appearance, perpetually changing\ndisguise. Under such circumstances, detecting known threats, a fortiori\nzero-day attacks, requires new tools, which are able to capture the essence of\ntheir behavior, rather than some fixed signatures. In this work, we propose\nnovel universal anomaly detection algorithms, which are able to learn the\nnormal behavior of systems and alert for abnormalities, without any prior\nknowledge on the system model, nor any knowledge on the characteristics of the\nattack. The suggested method utilizes the Lempel-Ziv universal compression\nalgorithm in order to optimally give probability assignments for normal\nbehavior (during learning), then estimate the likelihood of new data (during\noperation) and classify it accordingly. The suggested technique is generic, and\ncan be applied to different scenarios. Indeed, we apply it to key problems in\ncomputer security. The first is detecting Botnets Command and Control (C&C)\nchannels. A Botnet is a logical network of compromised machines which are\nremotely controlled by an attacker using a C&C infrastructure, in order to\nperform malicious activities. We derive a detection algorithm based on timing\ndata, which can be collected without deep inspection, from open as well as\nencrypted flows. We evaluate the algorithm on real-world network traces,\nshowing how a universal, low complexity C&C identification system can be built,\nwith high detection rates and low false-alarm probabilities. Further\napplications include malicious tools detection via system calls monitoring and\ndata leakage identification.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2015 02:25:41 GMT"}], "update_date": "2015-08-18", "authors_parsed": [["Siboni", "Shachar", ""], ["Cohen", "Asaf", ""]]}, {"id": "1508.03787", "submitter": "K. V. Rashmi", "authors": "Nihar B. Shah, K. V. Rashmi, Kannan Ramchandran, and P. Vijay Kumar", "title": "Information-theoretically Secure Erasure Codes for Distributed Storage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Repair operations in distributed storage systems potentially expose the data\nto malicious acts of passive eavesdroppers or active adversaries, which can be\ndetrimental to the security of the system. This paper presents erasure codes\nand repair algorithms that ensure security of the data in the presence of\npassive eavesdroppers and active adversaries, while maintaining high\navailability, reliability and efficiency in the system. Our codes are optimal\nin that they meet previously proposed lower bounds on the storage,\nnetwork-bandwidth, and reliability requirements for a wide range of system\nparameters. Our results thus establish the capacity of such systems. Our codes\nfor security from active adversaries provide an additional appealing feature of\n`on-demand security' where the desired level of security can be chosen\nseparately for each instance of repair, and our algorithms remain optimal\nsimultaneously for all possible levels. The paper also provides necessary and\nsufficient conditions governing the transformation of any (non-secure) code\ninto one providing on-demand security.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2015 03:40:48 GMT"}], "update_date": "2015-08-18", "authors_parsed": [["Shah", "Nihar B.", ""], ["Rashmi", "K. V.", ""], ["Ramchandran", "Kannan", ""], ["Kumar", "P. Vijay", ""]]}, {"id": "1508.03903", "submitter": "EPTCS", "authors": "Andrea Margheri (Universit\\`a degli Studi di Firenze, Universit\\`a di\n  Pisa), Rosario Pugliese (Universit\\`a degli Studi di Firenze), Francesco\n  Tiezzi (Universit\\`a di Camerino)", "title": "On Properties of Policy-Based Specifications", "comments": "In Proceedings WWV 2015, arXiv:1508.03389", "journal-ref": "EPTCS 188, 2015, pp. 33-50", "doi": "10.4204/EPTCS.188.5", "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of large-scale, complex computing systems has dramatically\nincreased the difficulties of securing accesses to systems' resources. To\nensure confidentiality and integrity, the exploitation of access control\nmechanisms has thus become a crucial issue in the design of modern computing\nsystems. Among the different access control approaches proposed in the last\ndecades, the policy-based one permits to capture, by resorting to the concept\nof attribute, all systems' security-relevant information and to be, at the same\ntime, sufficiently flexible and expressive to represent the other approaches.\nIn this paper, we move a step further to understand the effectiveness of\npolicy-based specifications by studying how they permit to enforce traditional\nsecurity properties. To support system designers in developing and maintaining\npolicy-based specifications, we formalise also some relevant properties\nregarding the structure of policies. By means of a case study from the banking\ndomain, we present real instances of such properties and outline an approach\ntowards their automatised verification.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2015 01:51:12 GMT"}], "update_date": "2015-08-18", "authors_parsed": [["Margheri", "Andrea", "", "Universit\u00e0 degli Studi di Firenze, Universit\u00e0 di\n  Pisa"], ["Pugliese", "Rosario", "", "Universit\u00e0 degli Studi di Firenze"], ["Tiezzi", "Francesco", "", "Universit\u00e0 di Camerino"]]}, {"id": "1508.04324", "submitter": "Christian Mainka", "authors": "Vladislav Mladenov and Christian Mainka and J\\\"org Schwenk", "title": "On the security of modern Single Sign-On Protocols: Second-Order\n  Vulnerabilities in OpenID Connect", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OAuth is the new de facto standard for delegating authorization in the web.\nAn important limitation of OAuth is the fact that it was designed for\nauthorization and not for authentication. The usage of OAuth for authentication\nthus leads to serious vulnerabilities as shown by Zhou et. al. in [44] and Chen\net. al. in [9]. OpenID Connect was created on top of OAuth to fill this gap by\nproviding federated identity management and user authentication. OpenID Connect\nwas standardized in February 2014, but leading companies like Google,\nMicrosoft, AOL and PayPal are already using it in their web applications [1],\n[2], [3], [30].\n  In this paper we describe the OpenID Connect protocol and provide the first\nin-depth analysis of one of the key features of OpenID Connect: the Discovery\nand the Dynamic Registration extensions.We present a new class of attacks on\nOpenID Connect that belong to the category of second-order vulnerabilities.\nThese attacks consist of two phases: First, the injection payload is stored by\nthe legitimate application. Later on, this payload is used in a\nsecurity-critical operation. Our new class of attacks - called Malicious\nEndpoints attacks - exploits the OpenID Connect extensions Discovery and\nDynamic Registration. These attacks break user authentication, compromise user\nprivacy, and enable Server Side Request Forgery (SSRF), client-side code\ninjection, and Denial-of-Service (DoS). As a result, the security of the OpenID\nConnect protocol cannot be guaranteed when these extensions are enabled in\ntheir present form.\n  We contacted the authors of the OpenID Connect and OAuth specifications. They\nacknowledged our Malicious Endpoint attacks and recognized the need to improve\nthe specification [29]. We are currently involved in the discussion regarding\nthe mitigation of the existing issues and an extension to the OAuth\nspecification.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2015 14:08:18 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2016 18:24:40 GMT"}], "update_date": "2016-01-08", "authors_parsed": [["Mladenov", "Vladislav", ""], ["Mainka", "Christian", ""], ["Schwenk", "J\u00f6rg", ""]]}, {"id": "1508.04364", "submitter": "Efstathios Panayi", "authors": "Gareth W. Peters, Efstathios Panayi, Ariane Chapelle", "title": "Trends in crypto-currencies and blockchain technologies: A monetary\n  theory and regulation perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The internet era has generated a requirement for low cost, anonymous and\nrapidly verifiable transactions to be used for online barter, and fast settling\nmoney have emerged as a consequence. For the most part, e-money has fulfilled\nthis role, but the last few years have seen two new types of money emerge.\nCentralised virtual currencies, usually for the purpose of transacting in\nsocial and gaming economies, and crypto-currencies, which aim to eliminate the\nneed for financial intermediaries by offering direct peer-to-peer online\npayments.\n  We describe the historical context which led to the development of these\ncurrencies and some modern and recent trends in their uptake, in terms of both\nusage in the real economy and as investment products. As these currencies are\npurely digital constructs, with no government or local authority backing, we\nthen discuss them in the context of monetary theory, in order to determine how\nthey may be have value under each. Finally, we provide an overview of the state\nof regulatory readiness in terms of dealing with transactions in these\ncurrencies in various regions of the world.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2015 15:55:31 GMT"}], "update_date": "2015-08-19", "authors_parsed": [["Peters", "Gareth W.", ""], ["Panayi", "Efstathios", ""], ["Chapelle", "Ariane", ""]]}, {"id": "1508.04627", "submitter": "Bhargava Shastry", "authors": "Bhargava Shastry, Fabian Yamaguchi, Konrad Rieck, and Jean-Pierre\n  Seifert", "title": "Towards Vulnerability Discovery Using Staged Program Analysis", "comments": "A revised version to appear in the proceedings of the 13th conference\n  on Detection of Intrusions and Malware & Vulnerability Assessment (DIMVA),\n  July 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eliminating vulnerabilities from low-level code is vital for securing\nsoftware. Static analysis is a promising approach for discovering\nvulnerabilities since it can provide developers early feedback on the code they\nwrite. But, it presents multiple challenges not the least of which is\nunderstanding what makes a bug exploitable and conveying this information to\nthe developer. In this paper, we present the design and implementation of a\npractical vulnerability assessment framework, called Melange. Melange performs\ndata and control flow analysis to diagnose potential security bugs, and outputs\nwell-formatted bug reports that help developers understand and fix security\nbugs. Based on the intuition that real-world vulnerabilities manifest\nthemselves across multiple parts of a program, Melange performs both local and\nglobal analyses. To scale up to large programs, global analysis is\ndemand-driven. Our prototype detects multiple vulnerability classes in C and\nC++ code including type confusion, and garbage memory reads. We have evaluated\nMelange extensively. Our case studies show that Melange scales up to large\ncodebases such as Chromium, is easy-to-use, and most importantly, capable of\ndiscovering vulnerabilities in real-world code. Our findings indicate that\nstatic analysis is a viable reinforcement to the software testing tool set.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2015 13:00:56 GMT"}, {"version": "v2", "created": "Wed, 6 Apr 2016 18:38:03 GMT"}], "update_date": "2016-04-07", "authors_parsed": [["Shastry", "Bhargava", ""], ["Yamaguchi", "Fabian", ""], ["Rieck", "Konrad", ""], ["Seifert", "Jean-Pierre", ""]]}, {"id": "1508.04868", "submitter": "Duane Wilson", "authors": "Duane Wilson, Giuseppe Ateniese", "title": "From Pretty Good To Great: Enhancing PGP using Bitcoin and the\n  Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PGP is built upon a Distributed Web of Trust in which the trustworthiness of\na user is established by others who can vouch through a digital signature for\nthat particular identity. Preventing its wholesale adoption are a number of\ninherent weaknesses to include (but not limited to) the following: 1) Trust\nRelationships are built on a subjective honor system, 2) Only first degree\nrelationships can be fully trusted, 3) Levels of trust are difficult to\nquantify with actual values, and 4) Issues with the Web of Trust itself\n(Certification and Endorsement). Although the security that PGP provides is\nproven to be reliable, it has largely failed to garner large scale adoption. In\nthis paper, we propose several novel contributions to address the\naforementioned issues with PGP and associated Web of Trust. To address the\nsubjectivity of the Web of Trust, we provide a new certificate format based on\nBitcoin which allows a user to verify a PGP certificate using Bitcoin\nidentity-verification transactions - forming first degree trust relationships\nthat are tied to actual values (i.e., number of Bitcoins transferred during\ntransaction). Secondly, we present the design of a novel Distributed PGP key\nserver that leverages the Bitcoin transaction blockchain to store and retrieve\nBitcoin-Based PGP certificates. Lastly, we provide a web prototype application\nthat demonstrates several of these capabilities in an actual environment.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2015 03:45:05 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2015 01:10:23 GMT"}], "update_date": "2015-08-24", "authors_parsed": [["Wilson", "Duane", ""], ["Ateniese", "Giuseppe", ""]]}, {"id": "1508.04978", "submitter": "Krzysztof Szczypiorski", "authors": "Krzysztof Szczypiorski, Artur Janicki, and Steffen Wendzel", "title": "\"The Good, The Bad And The Ugly\": Evaluation of Wi-Fi Steganography", "comments": "6 pages, 6 figures, to appear in Proc. of: ICNIT 2015 - 6th\n  International Conference on Networking and Information Technology, Tokyo,\n  Japan, November 5-6, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new method for the evaluation of network\nsteganography algorithms based on the new concept of \"the moving observer\". We\nconsidered three levels of undetectability named: \"good\", \"bad\", and \"ugly\". To\nillustrate this method we chose Wi-Fi steganography as a solid family of\ninformation hiding protocols. We present the state of the art in this area\ncovering well-known hiding techniques for 802.11 networks. \"The moving\nobserver\" approach could help not only in the evaluation of steganographic\nalgorithms, but also might be a starting point for a new detection system of\nnetwork steganography. The concept of a new detection system, called MoveSteg,\nis explained in detail.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2015 13:35:43 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2015 22:22:09 GMT"}], "update_date": "2015-09-11", "authors_parsed": [["Szczypiorski", "Krzysztof", ""], ["Janicki", "Artur", ""], ["Wendzel", "Steffen", ""]]}, {"id": "1508.05002", "submitter": "Hrishikesh Deshpande", "authors": "Hrishikesh Arun Deshpande", "title": "HoneyMesh: Preventing Distributed Denial of Service Attacks using\n  Virtualized Honeypots", "comments": "5 Pages with 4 figures and 1 table", "journal-ref": "IJERT ISSN: 2278-0181 Vol. 4 Issue 08, August-2015 pp. 263-267", "doi": "10.17577/IJERTV4IS080325", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Today, internet and web services have become an inseparable part of our\nlives. Hence, ensuring continuous availability of service has become imperative\nto the success of any organization. But these services are often hampered by\nconstant threats from myriad types of attacks. One such attack is called\ndistributed denial of service attack that results in issues ranging from\ntemporary slowdown of servers to complete non-availability of service.\nHoneypot, which is a sort of a trap, can be used to interact with potential\nattackers to deflect, detect or prevent such attacks and ensure continuous\navailability of service. This paper gives insights into the problems posed by\ndistributed denial of service attacks, existing solutions that use honeypots\nand how a mesh of virtualized honeypots can be used to prevent distributed\ndenial of service attacks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2015 15:07:52 GMT"}], "update_date": "2015-08-21", "authors_parsed": [["Deshpande", "Hrishikesh Arun", ""]]}, {"id": "1508.05052", "submitter": "Tanya Khovanova", "authors": "Nicholas Diaco and Tanya Khovanova", "title": "Weighing Coins and Keeping Secrets", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.HO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this expository paper we discuss a relatively new counterfeit coin problem\nwith an unusual goal: maintaining the privacy of, rather than revealing,\ncounterfeit coins in a set of both fake and real coins. We introduce two\nclasses of solutions to this problem --- one that respects the privacy of all\nthe coins and one that respects the privacy of only the fake coins --- and give\nseveral results regarding each. We describe and generalize 6 unique strategies\nthat fall into these two categories. Furthermore, we explain conditions for the\nexistence of a solution, as well as showing proof of a solution's optimality in\nselect cases. In order to quantify exactly how much information is revealed by\na given solution, we also define the revealing factor and revealing\ncoefficient; these two values additionally act as a means of comparing the\nrelative effectiveness of different solutions. Most importantly, by introducing\nan array of new concepts, we lay the foundation for future analysis of this\nvery interesting problem, as well as many other problems related to privacy and\nthe transfer of information.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2015 17:24:42 GMT"}], "update_date": "2015-08-21", "authors_parsed": [["Diaco", "Nicholas", ""], ["Khovanova", "Tanya", ""]]}, {"id": "1508.05228", "submitter": "Michael Hanspach", "authors": "Wolfgang Schmidt, Michael Hanspach, J\\\"org Keller", "title": "A Case Study on Covert Channel Establishment via Software Caches in\n  High-Assurance Computing Systems", "comments": "12 pages, based upon the master's thesis of Schmidt", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Covert channels can be utilized to secretly deliver information from high\nprivileged processes to low privileged processes in the context of a\nhigh-assurance computing system. In this case study, we investigate the\npossibility of covert channel establishment via software caches in the context\nof a framework for component-based operating systems. While component-based\noperating systems offer security through the encapsulation of system service\nprocesses, complete isolation of these processes is not reasonably feasible.\nThis limitation is practically demonstrated with our concept of a specific\ncovert timing channel based on file system caching. The stability of the covert\nchannel is evaluated and a methodology to disrupt the covert channel\ntransmission is presented. While these kinds of attacks are not limited to\nhigh-assurance computing systems, our study practically demonstrates that even\nsecurity-focused computing systems with a minimal trusted computing base are\nvulnerable for such kinds of attacks and careful design decisions are necessary\nfor secure operating system architectures.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2015 09:59:27 GMT"}], "update_date": "2015-08-24", "authors_parsed": [["Schmidt", "Wolfgang", ""], ["Hanspach", "Michael", ""], ["Keller", "J\u00f6rg", ""]]}, {"id": "1508.05411", "submitter": "Youssef Gahi Mr", "authors": "Youssef Gahi, Mouhcine Guennoun, Zouhair Guennoun, Khalil El-khatib", "title": "On the use of homomorphic encryption to secure cloud computing,\n  services, and routing protocols", "comments": "Youssef Gahi, PhD dissertation, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The trend towards delegating data processing to a remote party raises major\nconcerns related to privacy violations for both end-users and service\nproviders. These concerns have attracted the attention of the research\ncommunity, and several techniques have been proposed to protect against\nmalicious parties by providing secure communication protocols. Most of the\nproposed techniques, however, require the involvement of a third party, and\nthis by itself can be viewed as another security concern. These security\nbreaches can be avoided by following a new approach that depends on data\nsorted, managed, and stored in encrypted form at the remote servers. To realize\nsuch an approach, the encryption cryptosystem must support algebraic operations\nover encrypted data. This cryptosystem can be effective in protecting data and\nsupporting the construction of programs that can process encrypted input and\nproduce encrypted output. In fact, the latter programs do not decrypt the\ninput, and therefore, they can be run by an un-trusted party without revealing\ntheir data and internal states. Furthermore, such programs prove to be\npractical in situations where we need to outsource private computations,\nespecially in the context of cloud computing. Homomorphic cryptosystems are\nperfectly aligned with these objectives as they are a strong foundation for\nschemes that allow a blind processing of encrypted data without the need to\ndecrypt them. In this dissertation we rely on homomorphic encryption schemes to\nsecure cloud computing, services and routing protocols. We design several\ncircuits that allow for the blind processing and management of data such that\nmalicious parties are denied access to sensitive information. We select five\nareas to apply our models to. These models are easily customized for many other\nareas. We also provide prototypes that we use to study the performance and\nrobustness of our models.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2015 21:08:10 GMT"}], "update_date": "2015-12-15", "authors_parsed": [["Gahi", "Youssef", ""], ["Guennoun", "Mouhcine", ""], ["Guennoun", "Zouhair", ""], ["El-khatib", "Khalil", ""]]}, {"id": "1508.05457", "submitter": "Leon Abdillah", "authors": "Heru Pranata, Leon Andretti Abdillah, Usman Ependi", "title": "Analisis Keamanan Protokol Secure Socket Layer (SSL) Terhadap Proses\n  Sniffing di Jaringan", "comments": "6 pages, Student Colloquium Sistem Informasi & Teknik Informatika\n  (SC-SITI) 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Development of information technology, especially in the field of computer\nnetwork allows the exchange of information faster and more complex and the data\nthat is exchanged can vary. Security of data on communication in the network is\na major thing. Secure socket layer (SSL) is the solution to the problem, but\nfurther research on the security of the SSL protocol transactions should be\ndone to determine the extent of SSL can secure the data on the network. When\nthe computer sends data across the network, the data is transmitted in packets.\nSniffing is a technique of monitoring of every packet traversing the network.\nSecurity threat presented by sniffers is their ability to capture all incoming\nand outgoing packets through the network, which includes the passwords,\nusernames and other sensitive issues. Packet sniffer captures the data\naddressed to other devices, which will then be stored for later analysis later.\nSniffing can also be used by system administrators to monitor the network and\nsolve problems in the network.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2015 02:24:14 GMT"}], "update_date": "2015-08-25", "authors_parsed": [["Pranata", "Heru", ""], ["Abdillah", "Leon Andretti", ""], ["Ependi", "Usman", ""]]}, {"id": "1508.05626", "submitter": "Joseph Maguire", "authors": "Joseph Maguire and Karen Renaud", "title": "You Only Live Twice or \"The Years We Wasted Caring about\n  Shoulder-Surfing\"", "comments": "Proceedings of the BCS HCI 2012", "journal-ref": null, "doi": "10.1145/2377916.2377975", "report-no": null, "categories": "cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Passwords are a good idea, in theory. They have the potential to act as a\nfairly strong gateway. In practice though, passwords are plagued with problems.\nThey are (1) easily shared, (2) trivial to observe and (3) maddeningly elusive\nwhen forgotten. While alternatives to passwords have been proposed, none, as\nyet, have been adopted widely. There seems to be a reluctance to switch from\ntried and tested passwords to novel alternatives, even if the most glaring\nflaws of passwords can be mitigated. One argument is that there is not enough\ninvestigation into the feasibility of many password alternatives. Graphical\nauthentication mechanisms are a case in point. Therefore, in this paper, we\ndetail the design of two prototype applications that utilise graphical\nauthentication mechanisms. However, when forced to consider the design of such\nprototypes, we find that pertinent password problems eg. observation of entry,\nare just that: password problems. We conclude that effective, alternative\nauthentication mechanisms should target authentication scenarios rather than\nthe well-known problems of passwords. This is the only route to wide-spread\nadoption of alternatives.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2015 15:55:49 GMT"}], "update_date": "2015-08-25", "authors_parsed": [["Maguire", "Joseph", ""], ["Renaud", "Karen", ""]]}, {"id": "1508.06069", "submitter": "Leon Abdillah", "authors": "Muhammad Ilham Daniel, Leon Andretti Abdillah, Kiky Rizky Nova Wardani", "title": "Evaluasi Celah Keamanan Web Server pada LPSE Kota Palembang", "comments": "6 pages, presented at the Student Colloquium Sistem Informasi &\n  Teknik Informatika (SC-SITI) 2015, Palembang, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Along the development of information technology systems among the public at\nlarge, also develops information systems to facilitate the public to access and\nsearch for information in the form of a website. Electronic Procurement Service\n(LPSE) Palembang is a business unit set up to organize the service system of\ngovernment procurement of goods or services electronically. And to allow\ncompanies or providers that want to follow the procurement of goods or\nservices, LPSE providing a website that can be accessed from anywhere so the\ncompany or provider to follow the procurement of goods or services without\nhaving to come to the office LPSE. In the management of its website, LPSE\nPalembang has its own web server so that the need to consider the existing\nsecurity system on the web server. Web servers often become the target of\nattacks by an attacker. This study is set to test the security system of the\nweb server to find out if a web server is secure or not of the crime committed\nby an attacker. This research involves penetration testing with multiple\napplications. The results show some holes and suggestions.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2015 08:50:59 GMT"}], "update_date": "2015-08-26", "authors_parsed": [["Daniel", "Muhammad Ilham", ""], ["Abdillah", "Leon Andretti", ""], ["Wardani", "Kiky Rizky Nova", ""]]}, {"id": "1508.06110", "submitter": "Emiliano De Cristofaro", "authors": "Luca Melis and George Danezis and Emiliano De Cristofaro", "title": "Efficient Private Statistics with Succinct Sketches", "comments": "To appear in NDSS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale collection of contextual information is often essential in order\nto gather statistics, train machine learning models, and extract knowledge from\ndata. The ability to do so in a {\\em privacy-preserving} way -- i.e., without\ncollecting fine-grained user data -- enables a number of additional\ncomputational scenarios that would be hard, or outright impossible, to realize\nwithout strong privacy guarantees. In this paper, we present the design and\nimplementation of practical techniques for privately gathering statistics from\nlarge data streams. We build on efficient cryptographic protocols for private\naggregation and on data structures for succinct data representation, namely,\nCount-Min Sketch and Count Sketch. These allow us to reduce the communication\nand computation complexity incurred by each data source (e.g., end-users) from\nlinear to logarithmic in the size of their input, while introducing a\nparametrized upper-bounded error that does not compromise the quality of the\nstatistics. We then show how to use our techniques, efficiently, to instantiate\nreal-world privacy-friendly systems, supporting recommendations for media\nstreaming services, prediction of user locations, and computation of median\nstatistics for Tor hidden services.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2015 11:24:11 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2015 08:42:46 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2016 10:35:43 GMT"}], "update_date": "2016-01-07", "authors_parsed": [["Melis", "Luca", ""], ["Danezis", "George", ""], ["De Cristofaro", "Emiliano", ""]]}, {"id": "1508.06370", "submitter": "Akash Nag", "authors": "Akash Nag, Sunil Karforma", "title": "DSA Security Enhancement through Efficient Nonce Generation", "comments": null, "journal-ref": "Journal of Global Research in Computer Science (JGRCS). Vol.5(10).\n  pp:14-19. 2014", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Digital Signature Algorithm (DSA) has become the de facto standard for\nauthentication of transacting entities since its inception as a standard by\nNIST. An integral part of the signing process in DSA is the generation of a\nrandom number called a nonce or an ephemeral key. If sufficient caution is not\ntaken while generating the nonce, it can lead to the discovery of the\nprivate-key paving the way for critical security violations further on. The\nstandard algorithms for generation of the nonce as specified by NIST, as well\nas the widely implemented random number generators, fail to serve as true\nrandom sources, thus leaving the DSA algorithm open to attack, resulting in\npossible signature forgery in electronic transactions, by potential attackers.\nFurthermore, the user can select the nonce arbitrarily, which leads to a\nsubliminal channel being present to exchange messages through each signature,\nwhich may be intolerable for security reasons. In this paper, we have improved\nthe security of the DSA algorithm by proposing an efficient nonce-generation\nprocess, which ensures that the generated nonce is sufficiently random as well\nas unique for each generated signature, thereby securing the signing process.\nFurthermore, our algorithm also ensures that there are no subliminal channels\npresent in DSA.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2015 05:36:14 GMT"}], "update_date": "2015-08-27", "authors_parsed": [["Nag", "Akash", ""], ["Karforma", "Sunil", ""]]}, {"id": "1508.06525", "submitter": "Raphael Khoury", "authors": "Rapha\\\"el Khoury and Sylvain Hall\\'e", "title": "Runtime Enforcement With Partial Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study carries forward the line of enquiry that seeks to characterize\nprecisely which security policies are enforceable by runtime monitors. In this\nregard, Basin et al.\\ recently refined the structure that helps distinguish\nbetween those actions that the monitor can potentially suppress or insert in\nthe execution, from those that the monitor can only observe. In this paper, we\ngeneralize this model by organizing the universe of possible actions in a\nlattice that naturally corresponds to the levels of monitor control. We then\ndelineate the set of properties that are enforceable under this paradigm and\nrelate our results to previous work in the field. Finally, we explore the set\nof security policies that are enforceable if the monitor is given greater\nlatitude to alter the execution of its target, which allows us to reflect on\nthe capabilities of different types of monitors.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2015 15:08:23 GMT"}], "update_date": "2015-08-27", "authors_parsed": [["Khoury", "Rapha\u00ebl", ""], ["Hall\u00e9", "Sylvain", ""]]}, {"id": "1508.06574", "submitter": "Louis Aslett", "authors": "Louis J. M. Aslett, Pedro M. Esperan\\c{c}a, Chris C. Holmes", "title": "A review of homomorphic encryption and software tools for encrypted\n  statistical machine learning", "comments": "21 pages, technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in cryptography promise to enable secure statistical\ncomputation on encrypted data, whereby a limited set of operations can be\ncarried out without the need to first decrypt. We review these homomorphic\nencryption schemes in a manner accessible to statisticians and machine\nlearners, focusing on pertinent limitations inherent in the current state of\nthe art. These limitations restrict the kind of statistics and machine learning\nalgorithms which can be implemented and we review those which have been\nsuccessfully applied in the literature. Finally, we document a high performance\nR package implementing a recent homomorphic scheme in a general framework.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2015 17:11:12 GMT"}], "update_date": "2015-08-27", "authors_parsed": [["Aslett", "Louis J. M.", ""], ["Esperan\u00e7a", "Pedro M.", ""], ["Holmes", "Chris C.", ""]]}, {"id": "1508.06614", "submitter": "Yaman Sharaf-Dabbagh", "authors": "Yaman Sharaf-Dabbagh and Walid Saad", "title": "Transfer Learning for Device Fingerprinting with Application to\n  Cognitive Radio Networks", "comments": "6 pages, 3 figures, in Proceedings of IEEE 26th International\n  Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC), Hong\n  Kong, P.R. China, Aug. 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Primary user emulation (PUE) attacks are an emerging threat to cognitive\nradio (CR) networks in which malicious users imitate the primary users (PUs)\nsignals to limit the access of secondary users (SUs). Ascertaining the identity\nof the devices is a key technical challenge that must be overcome to thwart the\nthreat of PUE attacks. Typically, detection of PUE attacks is done by\ninspecting the signals coming from all the devices in the system, and then\nusing these signals to form unique fingerprints for each device. Current\ndetection and fingerprinting approaches require certain conditions to hold in\norder to effectively detect attackers. Such conditions include the need for a\nsufficient amount of fingerprint data for users or the existence of both the\nattacker and the victim PU within the same time frame. These conditions are\nnecessary because current methods lack the ability to learn the behavior of\nboth SUs and PUs with time. In this paper, a novel transfer learning (TL)\napproach is proposed, in which abstract knowledge about PUs and SUs is\ntransferred from past time frames to improve the detection process at future\ntime frames. The proposed approach extracts a high level representation for the\nenvironment at every time frame. This high level information is accumulated to\nform an abstract knowledge database. The CR system then utilizes this database\nto accurately detect PUE attacks even if an insufficient amount of fingerprint\ndata is available at the current time frame. The dynamic structure of the\nproposed approach uses the final detection decisions to update the abstract\nknowledge database for future runs. Simulation results show that the proposed\nmethod can improve the performance with an average of 3.5% for only 10%\nrelevant information between the past knowledge and the current environment\nsignals.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2015 19:24:14 GMT"}], "update_date": "2015-08-27", "authors_parsed": [["Sharaf-Dabbagh", "Yaman", ""], ["Saad", "Walid", ""]]}, {"id": "1508.06829", "submitter": "Gregory Gutin", "authors": "Gregory Gutin and Magnus Wahlstrom", "title": "Tight Lower Bounds for the Workflow Satisfiability Problem Based on the\n  Strong Exponential Time Hypothesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Workflow Satisfiability Problem (WSP) asks whether there exists an\nassignment of authorized users to the steps in a workflow specification,\nsubject to certain constraints on the assignment. The problem is NP-hard even\nwhen restricted to just not equals constraints. Since the number of steps $k$\nis relatively small in practice, Wang and Li (2010) introduced a\nparametrisation of WSP by $k$. Wang and Li (2010) showed that, in general, the\nWSP is W[1]-hard, i.e., it is unlikely that there exists a fixed-parameter\ntractable (FPT) algorithm for solving the WSP. Crampton et al. (2013) and Cohen\net al. (2014) designed FPT algorithms of running time $O^*(2^{k})$ and\n$O^*(2^{k\\log_2 k})$ for the WSP with so-called regular and user-independent\nconstraints, respectively. In this note, we show that there are no algorithms\nof running time $O^*(2^{ck})$ and $O^*(2^{ck\\log_2 k})$ for the two\nrestrictions of WSP, respectively, with any $c<1$, unless the Strong\nExponential Time Hypothesis fails.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2015 12:32:42 GMT"}], "update_date": "2015-08-28", "authors_parsed": [["Gutin", "Gregory", ""], ["Wahlstrom", "Magnus", ""]]}, {"id": "1508.06845", "submitter": "Louis Aslett", "authors": "Louis J. M. Aslett, Pedro M. Esperan\\c{c}a, Chris C. Holmes", "title": "Encrypted statistical machine learning: new privacy preserving methods", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two new statistical machine learning methods designed to learn on\nfully homomorphic encrypted (FHE) data. The introduction of FHE schemes\nfollowing Gentry (2009) opens up the prospect of privacy preserving statistical\nmachine learning analysis and modelling of encrypted data without compromising\nsecurity constraints. We propose tailored algorithms for applying extremely\nrandom forests, involving a new cryptographic stochastic fraction estimator,\nand na\\\"{i}ve Bayes, involving a semi-parametric model for the class decision\nboundary, and show how they can be used to learn and predict from encrypted\ndata. We demonstrate that these techniques perform competitively on a variety\nof classification data sets and provide detailed information about the\ncomputational practicalities of these and other FHE methods.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2015 13:06:55 GMT"}], "update_date": "2015-08-28", "authors_parsed": [["Aslett", "Louis J. M.", ""], ["Esperan\u00e7a", "Pedro M.", ""], ["Holmes", "Chris C.", ""]]}, {"id": "1508.07246", "submitter": "Ahmad Taha", "authors": "Ahmad F. Taha, Junjian Qi, Jianhui Wang, and Jitesh H. Panchal", "title": "Risk Mitigation for Dynamic State Estimation Against Cyber Attacks and\n  Unknown Inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.CR math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phasor measurement units (PMUs) can be effectively utilized for the\nmonitoring and control of the power grid. As the cyber-world becomes\nincreasingly embedded into power grids, the risks of this inevitable evolution\nbecome serious. In this paper, we present a risk mitigation strategy, based on\ndynamic state estimation, to eliminate threat levels from the grid's unknown\ninputs and potential cyber-attacks. The strategy requires (a) the potentially\nincomplete knowledge of power system models and parameters and (b) real-time\nPMU measurements.\n  First, we utilize a dynamic state estimator for higher order depictions of\npower system dynamics for simultaneous state and unknown inputs estimation.\nSecond, estimates of cyber-attacks are obtained through an attack detection\nalgorithm. Third, the estimation and detection components are seamlessly\nutilized in an optimization framework to determine the most impacted PMU\nmeasurements. Finally, a risk mitigation strategy is proposed to guarantee the\nelimination of threats from attacks, ensuring the observability of the power\nsystem through available, safe measurements. Case studies are included to\nvalidate the proposed approach. Insightful suggestions, extensions, and open\nproblems are also posed.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2015 15:45:30 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2016 18:02:27 GMT"}, {"version": "v3", "created": "Thu, 19 May 2016 21:34:17 GMT"}], "update_date": "2016-05-23", "authors_parsed": [["Taha", "Ahmad F.", ""], ["Qi", "Junjian", ""], ["Wang", "Jianhui", ""], ["Panchal", "Jitesh H.", ""]]}, {"id": "1508.07306", "submitter": "Ashwin Machanavajjhala", "authors": "Yan Chen and Ashwin Machanavajjhala", "title": "On the Privacy Properties of Variants on the Sparse Vector Technique", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sparse vector technique is a powerful differentially private primitive\nthat allows an analyst to check whether queries in a stream are greater or\nlesser than a threshold. This technique has a unique property -- the algorithm\nworks by adding noise with a finite variance to the queries and the threshold,\nand guarantees privacy that only degrades with (a) the maximum sensitivity of\nany one query in stream, and (b) the number of positive answers output by the\nalgorithm. Recent work has developed variants of this algorithm, which we call\n{\\em generalized private threshold testing}, and are claimed to have privacy\nguarantees that do not depend on the number of positive or negative answers\noutput by the algorithm. These algorithms result in a significant improvement\nin utility over the sparse vector technique for a given privacy budget, and\nhave found applications in frequent itemset mining, feature selection in\nmachine learning and generating synthetic data.\n  In this paper we critically analyze the privacy properties of generalized\nprivate threshold testing. We show that generalized private threshold testing\ndoes not satisfy \\epsilon-differential privacy for any finite \\epsilon. We\nidentify a subtle error in the privacy analysis of this technique in prior\nwork. Moreover, we show an adversary can use generalized private threshold\ntesting to recover counts from the datasets (especially small counts) exactly\nwith high accuracy, and thus can result in individuals being reidentified. We\ndemonstrate our attacks empirically on real datasets.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2015 18:42:56 GMT"}], "update_date": "2015-08-31", "authors_parsed": [["Chen", "Yan", ""], ["Machanavajjhala", "Ashwin", ""]]}, {"id": "1508.07482", "submitter": "Alberto Garcia-Serrano", "authors": "Alberto Garcia-Serrano", "title": "Anomaly Detection for malware identification using Hardware Performance\n  Counters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computers are widely used today by most people. Internet based applications,\nlike ecommerce or ebanking attracts criminals, who using sophisticated\ntechniques, tries to introduce malware on the victim computer. But not only\ncomputer users are in risk, also smartphones or smartwatch users, smart cities,\nInternet of Things devices, etc. Different techniques has been tested against\nmalware. Currently, pattern matching is the default approach in antivirus\nsoftware. Also, Machine Learning is successfully being used. Continuing this\ntrend, in this article we propose an anomaly based method using the hardware\nperformance counters (HPC) available in almost any modern computer\narchitecture. Because anomaly detection is an unsupervised process, new malware\nand APTs can be detected even if they are unknown.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2015 17:28:40 GMT"}], "update_date": "2015-09-01", "authors_parsed": [["Garcia-Serrano", "Alberto", ""]]}, {"id": "1508.07690", "submitter": "Johannes Schneider", "authors": "Johannes Schneider", "title": "Secure Multi-Party Computation with a Helper", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A client wishes to outsource computation on confidential data to a network of\nparties. He does not trust a single party but believes that multiple parties do\nnot collude. To solve this problem, we use the idea of treating one of the\nparties as a helper. A helper assists computation only. Often using more\nparties ensures confidentiality despite more corrupted parties. This does not\nhold for adding a helper. But a helper can in some cases lower the amount of\ncommunication asymptotically to the theoretical minimum of one bit per AND\ngate, improving significantly on schemes without a helper. It can also allow\nfor very efficient computations of certain functions, as we show for the\nexponential function with public base.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2015 05:36:56 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2015 09:40:02 GMT"}, {"version": "v3", "created": "Sun, 31 Jan 2016 00:13:39 GMT"}, {"version": "v4", "created": "Fri, 10 Feb 2017 19:55:52 GMT"}, {"version": "v5", "created": "Wed, 19 Jul 2017 21:42:45 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Schneider", "Johannes", ""]]}, {"id": "1508.07756", "submitter": "Samir Bouftass", "authors": "Samir Bouftass", "title": "On a new fast public key cryptosystem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a new fast public key cryptosystem namel : a key exchange\nalgorithm, a public key encryption algorithm and a digital signature algorithm,\nbased on the difficulty to invert the following function: $$F(x) =(a\\times\nx)Mod(2^p)Div(2^q).$$ Mod is modulo operation , Div is integer division\noperation , a , p and q are integers where $( p > q )$. We define p and q\nvalues for which ModDiv2Inv can be the hardest. We then present ModDiv2Kex, a\nnew fast key exchange algorithm based on ModDiv2Inv. In this paper we also\nevaluate the hardness of this problem by reducing it to SAT .\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2015 10:27:34 GMT"}, {"version": "v2", "created": "Sat, 24 Apr 2021 09:12:49 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Bouftass", "Samir", ""]]}, {"id": "1508.07885", "submitter": "Michael Kotson", "authors": "Michael C. Kotson and Alexia Schulz", "title": "Characterizing Phishing Threats with Natural Language Processing", "comments": "This paper has been accepted for publication by the IEEE Conference\n  on Communications and Network Security in September 2015 at Florence, Italy.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spear phishing is a widespread concern in the modern network security\nlandscape, but there are few metrics that measure the extent to which\nreconnaissance is performed on phishing targets. Spear phishing emails closely\nmatch the expectations of the recipient, based on details of their experiences\nand interests, making them a popular propagation vector for harmful malware. In\nthis work we use Natural Language Processing techniques to investigate a\nspecific real-world phishing campaign and quantify attributes that indicate a\ntargeted spear phishing attack. Our phishing campaign data sample comprises 596\nemails - all containing a web bug and a Curriculum Vitae (CV) PDF attachment -\nsent to our institution by a foreign IP space. The campaign was found to\nexclusively target specific demographics within our institution. Performing a\nsemantic similarity analysis between the senders' CV attachments and the\nrecipients' LinkedIn profiles, we conclude with high statistical certainty (p\n$< 10^{-4}$) that the attachments contain targeted rather than randomly\nselected material. Latent Semantic Analysis further demonstrates that\nindividuals who were a primary focus of the campaign received CVs that are\nhighly topically clustered. These findings differentiate this campaign from one\nthat leverages random spam.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2015 16:03:14 GMT"}], "update_date": "2015-09-01", "authors_parsed": [["Kotson", "Michael C.", ""], ["Schulz", "Alexia", ""]]}]