[{"id": "2002.00050", "submitter": "Sihem Mesnager", "authors": "Claude Carlet and Kwang Ho Kim and Sihem Mesnager", "title": "A direct proof of APN-ness of the Kasami functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using recent results on solving the equation $X^{2^k+1}+X+a=0$ over a finite\nfield $\\mathbb{F}_{2^n}$, we address an open question raised by the first\nauthor in WAIFI 2014 concerning the APN-ness of the Kasami functions $x\\mapsto\nx^{2^{2k}-2^k+1}$ with $gcd(k,n)=1$, $x\\in\\mathbb{F}_{2^n}$.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 20:27:08 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Carlet", "Claude", ""], ["Kim", "Kwang Ho", ""], ["Mesnager", "Sihem", ""]]}, {"id": "2002.00069", "submitter": "Philokypros Ioulianou", "authors": "Ryan Smith, Daniel Palin, Philokypros P. Ioulianou, Vassilios G.\n  Vassilakis, Siamak F. Shahandashti", "title": "Battery draining attacks against edge computing nodes in IoT networks", "comments": "19 pages,", "journal-ref": "Cyber-Physical Systems (2020), pp.1-21", "doi": "10.1080/23335777.2020.1716268", "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many IoT devices, especially those deployed at the network edge have limited\npower resources. A number of attacks aim to exhaust these resources and drain\nthe batteries of such edge nodes. In this work, we study the effects of a\nvariety of battery draining attacks against edge nodes. Through simulation, we\nclarify the extent to which such attacks are able to increase the usage and\nhence waste the power resources of edge nodes. Specifically, we implement hello\nflooding, packet flooding, selective forwarding, rank attack, and versioning\nattack in ContikiOS and simulate them in the Cooja simulator, and measure and\nreport a number of time and power resource usage metrics including CPU time,\nlow power mode time, TX/RX time, and battery consumption. Besides, we test the\nstretch attack with three different batteries as an extreme scenario. Our\nextensive measurements enable us to compare the effectiveness of these attacks.\nOur results show that Versioning attack is the most severe attack in terms of\ndraining the power resources of the network, followed by Packet Flooding and\nHello Flood attacks. Furthermore, we confirm that Selective Forwarding and Rank\nattacks are not able to considerably increase the power resource usage in our\nscenarios. By quantifying the effects of these attacks, we demonstrate that\nunder specific scenarios, Versioning attack can be three to four times as\neffective as Packet Flooding and Hello Flood attacks in wasting network\nresources, while Packet Flooding is generally comparable to Hello Flood in CPU\nand TX time usage increase but twice as powerful in draining device batteries.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 21:44:21 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 17:03:48 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Smith", "Ryan", ""], ["Palin", "Daniel", ""], ["Ioulianou", "Philokypros P.", ""], ["Vassilakis", "Vassilios G.", ""], ["Shahandashti", "Siamak F.", ""]]}, {"id": "2002.00087", "submitter": "Li Xiao", "authors": "Li Xiao, Xiang-Gen Xia, and Yu-Ping Wang", "title": "Exact and Robust Reconstructions of Integer Vectors Based on\n  Multidimensional Chinese Remainder Theorem (MD-CRT)", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2020.3023584", "report-no": null, "categories": "cs.IT cs.CR math.IT math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The robust Chinese remainder theorem (CRT) has been recently proposed for\nrobustly reconstructing a large nonnegative integer from erroneous remainders.\nIt has found many applications in signal processing, including phase unwrapping\nand frequency estimation under sub-Nyquist sampling. Motivated by the\napplications in multidimensional (MD) signal processing, in this paper we\npropose the MD-CRT and robust MD-CRT for integer vectors. Specifically, by\nrephrasing the abstract CRT for rings in number-theoretic terms, we first\nderive the MD-CRT for integer vectors with respect to a general set of integer\nmatrix moduli, which provides an algorithm to uniquely reconstruct an integer\nvector from its remainders, if it is in the fundamental parallelepiped of the\nlattice generated by a least common right multiple of all the moduli. For some\nspecial forms of moduli, we present explicit reconstruction formulae. Moreover,\nwe derive the robust MD-CRT for integer vectors when the remaining integer\nmatrices of all the moduli left divided by their greatest common left divisor\n(gcld) are pairwise commutative and coprime. Two different reconstruction\nalgorithms are proposed, and accordingly, two different conditions on the\nremainder error bound for the reconstruction robustness are obtained, which are\nrelated to a quarter of the minimum distance of the lattice generated by the\ngcld of all the moduli or the Smith normal form of the gcld.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 22:52:35 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 21:02:16 GMT"}, {"version": "v3", "created": "Tue, 25 Aug 2020 03:15:36 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Xiao", "Li", ""], ["Xia", "Xiang-Gen", ""], ["Wang", "Yu-Ping", ""]]}, {"id": "2002.00123", "submitter": "Naoto Yanai", "authors": "Tatsuya Takemura and Naoto Yanai and Toru Fujiwara", "title": "Model Extraction Attacks against Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model extraction attacks are a kind of attacks in which an adversary obtains\na new model, whose performance is equivalent to that of a target model, via\nquery access to the target model efficiently, i.e., fewer datasets and\ncomputational resources than those of the target model. Existing works have\ndealt with only simple deep neural networks (DNNs), e.g., only three layers, as\ntargets of model extraction attacks, and hence are not aware of the\neffectiveness of recurrent neural networks (RNNs) in dealing with time-series\ndata. In this work, we shed light on the threats of model extraction attacks\nagainst RNNs. We discuss whether a model with a higher accuracy can be\nextracted with a simple RNN from a long short-term memory (LSTM), which is a\nmore complicated and powerful RNN. Specifically, we tackle the following\nproblems. First, in a case of a classification problem, such as image\nrecognition, extraction of an RNN model without final outputs from an LSTM\nmodel is presented by utilizing outputs halfway through the sequence. Next, in\na case of a regression problem. such as in weather forecasting, a new attack by\nnewly configuring a loss function is presented. We conduct experiments on our\nmodel extraction attacks against an RNN and an LSTM trained with publicly\navailable academic datasets. We then show that a model with a higher accuracy\ncan be extracted efficiently, especially through configuring a loss function\nand a more complex architecture different from the target model.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 01:47:50 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Takemura", "Tatsuya", ""], ["Yanai", "Naoto", ""], ["Fujiwara", "Toru", ""]]}, {"id": "2002.00179", "submitter": "Zifei Zhang", "authors": "Zifei Zhang, Kai Qiao, Lingyun Jiang, Linyuan Wang, and Bin Yan", "title": "AdvJND: Generating Adversarial Examples with Just Noticeable Difference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared with traditional machine learning models, deep neural networks\nperform better, especially in image classification tasks. However, they are\nvulnerable to adversarial examples. Adding small perturbations on examples\ncauses a good-performance model to misclassify the crafted examples, without\ncategory differences in the human eyes, and fools deep models successfully.\nThere are two requirements for generating adversarial examples: the attack\nsuccess rate and image fidelity metrics. Generally, perturbations are increased\nto ensure the adversarial examples' high attack success rate; however, the\nadversarial examples obtained have poor concealment. To alleviate the tradeoff\nbetween the attack success rate and image fidelity, we propose a method named\nAdvJND, adding visual model coefficients, just noticeable difference\ncoefficients, in the constraint of a distortion function when generating\nadversarial examples. In fact, the visual subjective feeling of the human eyes\nis added as a priori information, which decides the distribution of\nperturbations, to improve the image quality of adversarial examples. We tested\nour method on the FashionMNIST, CIFAR10, and MiniImageNet datasets. Adversarial\nexamples generated by our AdvJND algorithm yield gradient distributions that\nare similar to those of the original inputs. Hence, the crafted noise can be\nhidden in the original inputs, thus improving the attack concealment\nsignificantly.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 09:55:27 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 09:34:17 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Zhang", "Zifei", ""], ["Qiao", "Kai", ""], ["Jiang", "Lingyun", ""], ["Wang", "Linyuan", ""], ["Yan", "Bin", ""]]}, {"id": "2002.00192", "submitter": "Wen-jie Liu", "authors": "Wenjie Liu, Peipei Gao, Zhihao Liu, Hanwu Chen, Maojun Zhang", "title": "A Quantum-based Database Query Scheme for Privacy Preservation in Cloud\n  Environment", "comments": "14 pages, 8 figures", "journal-ref": "Security and Communication Networks, 2019", "doi": "10.1155/2019/4923590", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing is a powerful and popular information technology paradigm\nthat enables data service outsourcing and provides higher-level services with\nminimal management effort. However, it is still a key challenge to protect data\nprivacy when a user accesses the sensitive cloud data. Privacy-preserving\ndatabase query allows the user to retrieve a data item from the cloud database\nwithout revealing the information of the queried data item, meanwhile limiting\nuser's ability to access other ones. In this study, in order to achieve the\nprivacy preservation and reduce the communication complexity, a quantum-based\ndatabase query scheme for privacy preservation in cloud environment is\ndeveloped. Specifically, all the data items of the database are firstly\nencrypted by different keys for protecting server's privacy, and in order to\nguarantee the clients' privacy, the server is required to transmit all these\nencrypted data items to the client with the oblivious transfer strategy.\nBesides, two oracle operations, a modified Grover iteration, and a special\noffset encryption mechanism are combined together to ensure that the client can\ncorrectly query the desirable data item. Finally, performance evaluation is\nconducted to validate the correctness, privacy, and efficiency of our proposed\nscheme.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 11:14:38 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Liu", "Wenjie", ""], ["Gao", "Peipei", ""], ["Liu", "Zhihao", ""], ["Chen", "Hanwu", ""], ["Zhang", "Maojun", ""]]}, {"id": "2002.00211", "submitter": "Suyi Li", "authors": "Suyi Li, Yong Cheng, Wei Wang, Yang Liu, Tianjian Chen", "title": "Learning to Detect Malicious Clients for Robust Federated Learning", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning systems are vulnerable to attacks from malicious clients.\nAs the central server in the system cannot govern the behaviors of the clients,\na rogue client may initiate an attack by sending malicious model updates to the\nserver, so as to degrade the learning performance or enforce targeted model\npoisoning attacks (a.k.a. backdoor attacks). Therefore, timely detecting these\nmalicious model updates and the underlying attackers becomes critically\nimportant. In this work, we propose a new framework for robust federated\nlearning where the central server learns to detect and remove the malicious\nmodel updates using a powerful detection model, leading to targeted defense. We\nevaluate our solution in both image classification and sentiment analysis tasks\nwith a variety of machine learning models. Experimental results show that our\nsolution ensures robust federated learning that is resilient to both the\nByzantine attacks and the targeted model poisoning attacks.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 14:09:48 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Li", "Suyi", ""], ["Cheng", "Yong", ""], ["Wang", "Wei", ""], ["Liu", "Yang", ""], ["Chen", "Tianjian", ""]]}, {"id": "2002.00456", "submitter": "Sarwan Ali", "authors": "Safi Faizullah, Muhammad Asad Khan, Ali Alzahrani, Imdadullah Khan", "title": "Permissioned Blockchain-Based Security for SDN in IoT Cloud Networks", "comments": "Accepted to International Conference on Advances in the Emerging\n  Computing Technologies (AECT) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advancement in cloud networks has enabled connectivity of both\ntraditional networked elements and new devices from all walks of life, thereby\nforming the Internet of Things (IoT). In an IoT setting, improving and scaling\nnetwork components as well as reducing cost is essential to sustain exponential\ngrowth. In this domain, software-defined networking (SDN) is revolutionizing\nthe network infrastructure with a new paradigm. SDN splits the control/routing\nlogic from the data transfer/forwarding. This splitting causes many issues in\nSDN, such as vulnerabilities of DDoS attacks. Many solutions (including\nblockchain based) have been proposed to overcome these problems. In this work,\nwe offer a blockchain-based solution that is provided in redundant SDN\n(load-balanced) to service millions of IoT devices. Blockchain is considered as\ntamper-proof and impossible to corrupt due to the replication of the ledger and\nconsensus for verification and addition to the ledger. Therefore, it is a\nperfect fit for SDN in IoT Networks. Blockchain technology provides everyone\nwith a working proof of decentralized trust. The experimental results show gain\nand efficiency with respect to the accuracy, update process, and bandwidth\nutilization.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 18:48:31 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Faizullah", "Safi", ""], ["Khan", "Muhammad Asad", ""], ["Alzahrani", "Ali", ""], ["Khan", "Imdadullah", ""]]}, {"id": "2002.00464", "submitter": "Wen-jie Liu", "authors": "Wen-Jie Liu, Zhen-Yu Chen, Jin-Suo Liu, Zhao-Feng Su, and Lian-Hua Chi", "title": "Full-Blind Delegating Private Quantum Computation", "comments": "9 figures, 13 pages", "journal-ref": "Cmc-Computers Materials & Continua, 2018, vol. 56, no. 2, pp.\n  211-223", "doi": "10.3970/cmc.2018.02288", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The delegating private quantum computation (DQC) protocol with the universal\nquantum gate set $\\left\\{ {X,Z,H,P,R,CNOT} \\right\\}$ was firstly proposed by\nBroadbent \\emph{et al.}, and then Tan \\emph{et al.} tried to put forward an\nhalf-blind DQC protocol (HDQC) with another universal set $\\left\\{ {H,P,CNOT,T}\n\\right\\}$. However, the decryption circuit of \\emph{Toffoli} gate (i.e.,\n\\emph{T}) is a little redundant, and Tan \\emph{et al}.'s protocol exists the\ninformation leak. In addition, both of these two protocols just focus on the\nblindness of data (i.e., the client's input and output), but do not consider\nthe blindness of computation (i.e., the delegated quantum operation). For\nsolving these problems, we propose a full-blind DQC protocol (FDQC) with\nquantum gate set $\\left\\{ {H,P,CNOT,T} \\right\\}$ , where the desirable\ndelegated quantum operation, one of $\\left\\{ {H,P,CNOT,T} \\right\\}$ , is\nreplaced by a fixed sequence $\\left \\{ {H,P,T,CZ,CNOT} \\right\\}$ to make the\ncomputation blind, and the decryption circuit of \\emph{Toffoli} gate is also\noptimized. Analysis shows that our protocol can not only correctly perform any\ndelegated quantum computation, but also holds the characteristics of data\nblindness and computation blindness.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 19:09:25 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Liu", "Wen-Jie", ""], ["Chen", "Zhen-Yu", ""], ["Liu", "Jin-Suo", ""], ["Su", "Zhao-Feng", ""], ["Chi", "Lian-Hua", ""]]}, {"id": "2002.00506", "submitter": "Jihoon Suh", "authors": "Jihoon Suh, Takashi Tanaka", "title": "SARSA(0) Reinforcement Learning over Fully Homomorphic Encryption", "comments": "7 pages, 2 figures, submitted to SICE ISCS 2021; replaced with\n  supplementary paragraphs added and format change for the correct publishing\n  medium", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CR cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a cloud-based control architecture in which the local plants\noutsource the control synthesis task to the cloud. In particular, we consider a\ncloud-based reinforcement learning (RL), where updating the value function is\noutsourced to the cloud. To achieve confidentiality, we implement computations\nover Fully Homomorphic Encryption (FHE). We use a CKKS encryption scheme and a\nmodified SARSA(0) reinforcement learning to incorporate the encryption-induced\ndelays. We then give a convergence result for the delayed updated rule of\nSARSA(0) with a blocking mechanism. We finally present a numerical\ndemonstration via implementing on a classical pole-balancing problem.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 23:12:42 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 05:18:05 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Suh", "Jihoon", ""], ["Tanaka", "Takashi", ""]]}, {"id": "2002.00524", "submitter": "Zhi Zhang", "authors": "Zhi Zhang, Yueqiang Cheng, Yinqian Zhang and Surya Nepal", "title": "GhostKnight: Breaching Data Integrity via Speculative Execution", "comments": "The paper is subject to change", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing speculative execution attacks are limited to breaching\nconfidentiality of data beyond privilege boundary, the so-called spectre-type\nattacks. All of them utilize the changes in microarchitectural buffers made by\nthe speculative execution to leak data. We show that the speculative execution\ncan be abused to break data integrity. We observe that the speculative\nexecution not only leaves traces in the microarchitectural buffers but also\ninduces side effects within DRAM, that is, the speculative execution can\ntrigger an access to an illegitimate address in DRAM. If the access to DRAM is\nfrequent enough, then architectural changes (i.e., permanent bit flips in DRAM)\nwill occur, which we term GhostKnight. With the power of of GhostKnight, an\nattacker is essentially able to cross different privilege boundaries and write\nexploitable bits to other privilege domains. In our future work, we will\ndevelop a GhostKnight-based exploit to cross a trusted execution environment,\ndefeat a 1024-bit RSA exponentiation implementation and obtain a controllable\nsignature.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 01:11:57 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Zhang", "Zhi", ""], ["Cheng", "Yueqiang", ""], ["Zhang", "Yinqian", ""], ["Nepal", "Surya", ""]]}, {"id": "2002.00559", "submitter": "Saeid Sahraei", "authors": "Saeid Sahraei and Salman Avestimehr", "title": "InfoCommit: Information-Theoretic Polynomial Commitment and Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce InfoCommit, a protocol for polynomial commitment and\nverification. InfoCommit consists of two phases. An initial commitment phase\nand an evaluation phase. During the commitment phase, the verifier and the\nprover engage in a private two-party computation algorithm so that the verifier\nextracts a private verification key. In the evaluation phase, the verifier is\ninterested in learning the evaluations of the polynomial at several input\npoints. InfoCommit has four main features. Firstly, the verifier is able to\ndetect, with high probability, if the prover has responded with evaluations of\nthe same polynomial that he has initially committed to. Secondly, InfoCommit\nprovides rigorous privacy guarantees for the prover: upon observing the initial\ncommitment and the response provided by the prover to $m$ evaluation requests,\nthe verifier only learns $O(m^2)$ symbols about the coefficients of the\npolynomial. Thirdly, the verifiability guarantee is unconditional and without\nthe need for a trusted party, while \"bounded storage\" is the only assumption\nunderlying the privacy of the algorithm. In particular, both properties hold\nregardless of the computation power of the two parties. Lastly, InfoCommit is\ndoubly-efficient in the sense that in the evaluation phase, the verifier runs\nin $O(\\sqrt{d})$ and the prover runs in $O(d)$, where $d-1$ is the degree of\nthe polynomial.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 05:00:46 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Sahraei", "Saeid", ""], ["Avestimehr", "Salman", ""]]}, {"id": "2002.00760", "submitter": "Dou Yan Liu Goodman", "authors": "Dou Goodman and Lv Zhonghou and Wang minghua", "title": "FastWordBug: A Fast Method To Generate Adversarial Text Against NLP\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel algorithm, FastWordBug, to efficiently\ngenerate small text perturbations in a black-box setting that forces a\nsentiment analysis or text classification mode to make an incorrect prediction.\nBy combining the part of speech attributes of words, we propose a scoring\nmethod that can quickly identify important words that affect text\nclassification. We evaluate FastWordBug on three real-world text datasets and\ntwo state-of-the-art machine learning models under black-box setting. The\nresults show that our method can significantly reduce the accuracy of the\nmodel, and at the same time, we can call the model as little as possible, with\nthe highest attack efficiency. We also attack two popular real-world cloud\nservices of NLP, and the results show that our method works as well.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 07:39:45 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Goodman", "Dou", ""], ["Zhonghou", "Lv", ""], ["minghua", "Wang", ""]]}, {"id": "2002.00801", "submitter": "Amos Treiber", "authors": "Amos Treiber and Alejandro Molina and Christian Weinert and Thomas\n  Schneider and Kristian Kersting", "title": "CryptoSPN: Privacy-preserving Sum-Product Network Inference", "comments": "Accepted for publication at ECAI'20. Please cite the conference\n  version of this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI algorithms, and machine learning (ML) techniques in particular, are\nincreasingly important to individuals' lives, but have caused a range of\nprivacy concerns addressed by, e.g., the European GDPR. Using cryptographic\ntechniques, it is possible to perform inference tasks remotely on sensitive\nclient data in a privacy-preserving way: the server learns nothing about the\ninput data and the model predictions, while the client learns nothing about the\nML model (which is often considered intellectual property and might contain\ntraces of sensitive data). While such privacy-preserving solutions are\nrelatively efficient, they are mostly targeted at neural networks, can degrade\nthe predictive accuracy, and usually reveal the network's topology.\nFurthermore, existing solutions are not readily accessible to ML experts, as\nprototype implementations are not well-integrated into ML frameworks and\nrequire extensive cryptographic knowledge.\n  In this paper, we present CryptoSPN, a framework for privacy-preserving\ninference of sum-product networks (SPNs). SPNs are a tractable probabilistic\ngraphical model that allows a range of exact inference queries in linear time.\nSpecifically, we show how to efficiently perform SPN inference via secure\nmulti-party computation (SMPC) without accuracy degradation while hiding\nsensitive client and training information with provable security guarantees.\nNext to foundations, CryptoSPN encompasses tools to easily transform existing\nSPNs into privacy-preserving executables. Our empirical results demonstrate\nthat CryptoSPN achieves highly efficient and accurate inference in the order of\nseconds for medium-sized SPNs.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 14:49:18 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Treiber", "Amos", ""], ["Molina", "Alejandro", ""], ["Weinert", "Christian", ""], ["Schneider", "Thomas", ""], ["Kersting", "Kristian", ""]]}, {"id": "2002.00817", "submitter": "Borja Balle", "authors": "Borja Balle, James Bell, Adria Gascon, Kobbi Nissim", "title": "Private Summation in the Multi-Message Shuffle Model", "comments": "Published at CCS'20", "journal-ref": null, "doi": "10.1145/3372297.3417242", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The shuffle model of differential privacy (Erlingsson et al. SODA 2019; Cheu\net al. EUROCRYPT 2019) and its close relative encode-shuffle-analyze (Bittau et\nal. SOSP 2017) provide a fertile middle ground between the well-known local and\ncentral models. Similarly to the local model, the shuffle model assumes an\nuntrusted data collector who receives privatized messages from users, but in\nthis case a secure shuffler is used to transmit messages from users to the\ncollector in a way that hides which messages came from which user. An\ninteresting feature of the shuffle model is that increasing the amount of\nmessages sent by each user can lead to protocols with accuracies comparable to\nthe ones achievable in the central model. In particular, for the problem of\nprivately computing the sum of $n$ bounded real values held by $n$ different\nusers, Cheu et al. showed that $O(\\sqrt{n})$ messages per user suffice to\nachieve $O(1)$ error (the optimal rate in the central model), while Balle et\nal. (CRYPTO 2019) recently showed that a single message per user leads to\n$\\Theta(n^{1/3})$ MSE (mean squared error), a rate strictly in-between what is\nachievable in the local and central models.\n  This paper introduces two new protocols for summation in the shuffle model\nwith improved accuracy and communication trade-offs. Our first contribution is\na recursive construction based on the protocol from Balle et al. mentioned\nabove, providing $\\mathrm{poly}(\\log \\log n)$ error with $O(\\log \\log n)$\nmessages per user. The second contribution is a protocol with $O(1)$ error and\n$O(1)$ messages per user based on a novel analysis of the reduction from secure\nsummation to shuffling introduced by Ishai et al. (FOCS 2006) (the original\nreduction required $O(\\log n)$ messages per user).\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 15:17:26 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 09:52:54 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Balle", "Borja", ""], ["Bell", "James", ""], ["Gascon", "Adria", ""], ["Nissim", "Kobbi", ""]]}, {"id": "2002.00918", "submitter": "Aythami Morales", "authors": "Alejandro Acien and Aythami Morales and Julian Fierrez and Ruben\n  Vera-Rodriguez and Ivan Bartolome", "title": "BeCAPTCHA: Detecting Human Behavior in Smartphone Interaction using\n  Multiple Inbuilt Sensors", "comments": "AAAI-20 Workshop on Artificial Intelligence for Ciber Security\n  (AICS), New York, NY, USA, February 2020. AICS-2020 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel multimodal mobile database called HuMIdb (Human Mobile\nInteraction database) that comprises 14 mobile sensors acquired from 600 users.\nThe heterogeneous flow of data generated during the interaction with the\nsmartphones can be used to model human behavior when interacting with the\ntechnology. Based on this new dataset, we explore the capacity of smartphone\nsensors to improve bot detection. We propose a CAPTCHA method based on the\nanalysis of the information obtained during a single drag and drop task. We\nevaluate the method generating fake samples synthesized with Generative\nAdversarial Neural Networks and handcrafted methods. Our results suggest the\npotential of mobile sensors to characterize the human behavior and develop a\nnew generation of CAPTCHAs.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 17:56:56 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 17:12:20 GMT"}, {"version": "v3", "created": "Fri, 29 May 2020 09:22:10 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Acien", "Alejandro", ""], ["Morales", "Aythami", ""], ["Fierrez", "Julian", ""], ["Vera-Rodriguez", "Ruben", ""], ["Bartolome", "Ivan", ""]]}, {"id": "2002.00934", "submitter": "Pushkal Agarwal", "authors": "Pushkal Agarwal, Sagar Joglekar, Panagiotis Papadopoulos, Nishanth\n  Sastry, Nicolas Kourtellis", "title": "Stop Tracking Me Bro! Differential Tracking Of User Demographics On\n  Hyper-partisan Websites", "comments": "Published at The Web Conference 2020 (WWW 2020). Please cite the WWW\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Websites with hyper-partisan, left or right-leaning focus offer content that\nis typically biased towards the expectations of their target audience. Such\ncontent often polarizes users, who are repeatedly primed to specific (extreme)\ncontent, usually reflecting hard party lines on political and socio-economic\ntopics. Though this polarization has been extensively studied with respect to\ncontent, it is still unknown how it associates with the online tracking\nexperienced by browsing users, especially when they exhibit certain demographic\ncharacteristics. For example, it is unclear how such websites enable the\nad-ecosystem to track users based on their gender or age. In this paper, we\ntake a first step to shed light and measure such potential differences in\ntracking imposed on users when visiting specific party-line's websites. For\nthis, we design and deploy a methodology to systematically probe such websites\nand measure differences in user tracking. This methodology allows us to create\nuser personas with specific attributes like gender and age and automate their\nbrowsing behavior in a consistent and repeatable manner. Thus, we\nsystematically study how personas are being tracked by these websites and their\nthird parties, especially if they exhibit particular demographic properties.\nOverall, we test 9 personas on 556 hyper-partisan websites and find that\nright-leaning websites tend to track users more intensely than left-leaning,\ndepending on user demographics, using both cookies and cookie synchronization\nmethods and leading to more costly delivered ads.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 18:35:57 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 19:07:44 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Agarwal", "Pushkal", ""], ["Joglekar", "Sagar", ""], ["Papadopoulos", "Panagiotis", ""], ["Sastry", "Nishanth", ""], ["Kourtellis", "Nicolas", ""]]}, {"id": "2002.00937", "submitter": "Alexandre Sablayrolles", "authors": "Alexandre Sablayrolles, Matthijs Douze, Cordelia Schmid, Herv\\'e\n  J\\'egou", "title": "Radioactive data: tracing through training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We want to detect whether a particular image dataset has been used to train a\nmodel. We propose a new technique, \\emph{radioactive data}, that makes\nimperceptible changes to this dataset such that any model trained on it will\nbear an identifiable mark. The mark is robust to strong variations such as\ndifferent architectures or optimization methods. Given a trained model, our\ntechnique detects the use of radioactive data and provides a level of\nconfidence (p-value). Our experiments on large-scale benchmarks (Imagenet),\nusing standard architectures (Resnet-18, VGG-16, Densenet-121) and training\nprocedures, show that we can detect usage of radioactive data with high\nconfidence (p<10^-4) even when only 1% of the data used to trained our model is\nradioactive. Our method is robust to data augmentation and the stochasticity of\ndeep network optimization. As a result, it offers a much higher signal-to-noise\nratio than data poisoning and backdoor methods.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 18:41:08 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Sablayrolles", "Alexandre", ""], ["Douze", "Matthijs", ""], ["Schmid", "Cordelia", ""], ["J\u00e9gou", "Herv\u00e9", ""]]}, {"id": "2002.00944", "submitter": "Ferdinando Fioretto", "authors": "Ferdinando Fioretto, Lesia Mitridati, Pascal Van Hentenryck", "title": "Differential Privacy for Stackelberg Games", "comments": "arXiv admin note: substantial text overlap with arXiv:1911.10178", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a differentially private (DP) mechanism to protect the\ninformation exchanged during the coordination of sequential and interdependent\nmarkets. This coordination represents a classic Stackelberg game and relies on\nthe exchange of sensitive information between the system agents. The paper is\nmotivated by the observation that the perturbation introduced by traditional DP\nmechanisms fundamentally changes the underlying optimization problem and even\nleads to unsatisfiable instances. To remedy such limitation, the paper\nintroduces the Privacy-Preserving Stackelberg Mechanism (PPSM), a framework\nthat enforces the notions of feasibility and fidelity of the privacy-preserving\ninformation to the original problem objective. PPSM complies with the notion of\ndifferential privacy and ensures that the outcomes of the privacy-preserving\ncoordination mechanism are close-to-optimality for each agent. Experimental\nresults on several gas and electricity market benchmarks based on a real case\nstudy demonstrate the effectiveness of the approach.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 13:33:33 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Fioretto", "Ferdinando", ""], ["Mitridati", "Lesia", ""], ["Van Hentenryck", "Pascal", ""]]}, {"id": "2002.01043", "submitter": "Zhigang Lu", "authors": "Zhigang Lu, Hong Shen", "title": "Differentially Private k-Means Clustering with Guaranteed Convergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Iterative clustering algorithms help us to learn the insights behind the\ndata. Unfortunately, this may allow adversaries to infer the privacy of\nindividuals with some background knowledge. In the worst case, the adversaries\nknow the centroids of an arbitrary iteration and the information of n-1 out of\nn items. To protect individual privacy against such an inference attack,\npreserving differential privacy (DP) for the iterative clustering algorithms\nhas been extensively studied in the interactive settings. However, existing\ninteractive differentially private clustering algorithms suffer from a\nnon-convergence problem, i.e., these algorithms may not terminate without a\npredefined number of iterations. This problem severely impacts the clustering\nquality and the efficiency of a differentially private algorithm. To resolve\nthis problem, in this paper, we propose a novel differentially private\nclustering framework in the interactive settings which controls the orientation\nof the movement of the centroids over the iterations to ensure the convergence\nby injecting DP noise in a selected area. We prove that, in the expected case,\nalgorithm under our framework converges in at most twice the iterations of\nLloyd's algorithm. We perform experimental evaluations on real-world datasets\nto show that our algorithm outperforms the state-of-the-art of the interactive\ndifferentially private clustering algorithms with guaranteed convergence and\nbetter clustering quality to meet the same DP requirement.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 22:53:47 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Lu", "Zhigang", ""], ["Shen", "Hong", ""]]}, {"id": "2002.01078", "submitter": "Mordechai Guri", "authors": "Mordechai Guri, Dima Bykhovsky, Yuval Elovici", "title": "BRIGHTNESS: Leaking Sensitive Data from Air-Gapped Workstations via\n  Screen Brightness", "comments": "2019 12th CMI Conference on Cybersecurity and Privacy (CMI)", "journal-ref": null, "doi": "10.1109/CMI48017.2019.8962137", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Air-gapped computers are systems that are kept isolated from the Internet\nsince they store or process sensitive information.\n  In this paper, we introduce an optical covert channel in which an attacker\ncan leak (or, exfiltlrate) sensitive information from air-gapped computers\nthrough manipulations on the screen brightness. This covert channel is\ninvisible and it works even while the user is working on the computer. Malware\non a compromised computer can obtain sensitive data (e.g., files, images,\nencryption keys and passwords), and modulate it within the screen brightness,\ninvisible to users. The small changes in the brightness are invisible to humans\nbut can be recovered from video streams taken by cameras such as a local\nsecurity camera, smartphone camera or a webcam. We present related work and\ndiscuss the technical and scientific background of this covert channel. We\nexamined the channel's boundaries under various parameters, with different\ntypes of computer and TV screens, and at several distances. We also tested\ndifferent types of camera receivers to demonstrate the covert channel. Lastly,\nwe present relevant countermeasures to this type of attack. Lastly, we present\nrelevant countermeasures to this type of attack.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 01:25:44 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Guri", "Mordechai", ""], ["Bykhovsky", "Dima", ""], ["Elovici", "Yuval", ""]]}, {"id": "2002.01139", "submitter": "Ruian Duan", "authors": "Ruian Duan, Omar Alrawi, Ranjita Pai Kasturi, Ryan Elder, Brendan\n  Saltaformaggio, Wenke Lee", "title": "Towards Measuring Supply Chain Attacks on Package Managers for\n  Interpreted Languages", "comments": "To appear in NDSS SYMPOSIUM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Package managers have become a vital part of the modern software development\nprocess. They allow developers to reuse third-party code, share their own code,\nminimize their codebase, and simplify the build process. However, recent\nreports showed that package managers have been abused by attackers to\ndistribute malware, posing significant security risks to developers and\nend-users. For example, eslint-scope, a package with millions of weekly\ndownloads in Npm, was compromised to steal credentials from developers. To\nunderstand the security gaps and the misplaced trust that make recent supply\nchain attacks possible, we propose a comparative framework to qualitatively\nassess the functional and security features of package managers for interpreted\nlanguages. Based on qualitative assessment, we apply well-known program\nanalysis techniques such as metadata, static, and dynamic analysis to study\nregistry abuse. Our initial efforts found 339 new malicious packages that we\nreported to the registries for removal. The package manager maintainers\nconfirmed 278 (82%) from the 339 reported packages where three of them had more\nthan 100,000 downloads. For these packages we were issued official CVE numbers\nto help expedite the removal of these packages from infected victims. We\noutline the challenges of tailoring program analysis tools to interpreted\nlanguages and release our pipeline as a reference point for the community to\nbuild on and help in securing the software supply chain.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 06:10:18 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 17:40:57 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Duan", "Ruian", ""], ["Alrawi", "Omar", ""], ["Kasturi", "Ranjita Pai", ""], ["Elder", "Ryan", ""], ["Saltaformaggio", "Brendan", ""], ["Lee", "Wenke", ""]]}, {"id": "2002.01143", "submitter": "Suthee Ruangwises", "authors": "Suthee Ruangwises, Toshiya Itoh", "title": "Physical Zero-Knowledge Proof for Numberlink Puzzle and $k$\n  Vertex-Disjoint Paths Problem", "comments": "A preliminary version of this paper has appeared in the proceedings\n  of FUN 2021", "journal-ref": "New Generation Computing, 39(1): 3-17 (2021)", "doi": "10.1007/s00354-020-00114-y", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numberlink is a logic puzzle with an objective to connect all pairs of cells\nwith the same number by non-crossing paths in a rectangular grid. In this\npaper, we propose a physical protocol of zero-knowledge proof for Numberlink\nusing a deck of cards, which allows a prover to convince a verifier that he/she\nknows a solution without revealing it. In particular, the protocol shows how to\nphysically count the number of elements in a list that are equal to a given\nsecret value without revealing that value, the positions of elements in the\nlist that are equal to it, or the value of any other element in the list.\nFinally, we show that our protocol can be modified to verify a solution of the\nwell-known $k$ vertex-disjoint paths problem, both the undirected and directed\nsettings.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 06:18:47 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 19:33:07 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Ruangwises", "Suthee", ""], ["Itoh", "Toshiya", ""]]}, {"id": "2002.01243", "submitter": "Noureddine Lasla", "authors": "Lina Alsahan, Noureddine Lasla, Mohamed Abdallah", "title": "Local Bitcoin Network Simulator for Performance Evaluation using\n  Lightweight Virtualization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new blockchain network simulator that uses bitcoin's\noriginal reference implementation as its main application. The proposed\nsimulator leverages the use of lightweight virtualization technology to build a\nfine tuned local testing network. To enable fast simulation of a large scale\nnetwork without disabling mining service, the simulator can adjust the bitcoin\nmining difficulty level to below the default minimum value. In order to assess\nthe performance of blockchain under different network conditions, the simulator\nallows to define different network topologies, and integrates Linux kernel\ntraffic control (tc) tool to apply distinct delay or packet loss on the network\nnodes. Moreover, to validate the efficiency of our simulator we conduct a set\nof experiments and study the impact of the computation power and network delay\non the network's consistency in terms of number of forks and mining revenues.\nThe impact of applying different mining difficulty levels is also studied and\nthe block time as well as fork occurrences are evaluated. Furthermore, a\ncomprehensive survey and taxonomy of existing blockchain simulators are\nprovided along with a discussion justifying the need of new simulator. As part\nof our contribution, we have made the simulator available on Github\n(https://github.com/noureddinel/core-bitcoin-net-simulator) for the community\nto use and improve it.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 12:05:24 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 18:52:03 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Alsahan", "Lina", ""], ["Lasla", "Noureddine", ""], ["Abdallah", "Mohamed", ""]]}, {"id": "2002.01277", "submitter": "Haji Akhundov", "authors": "Haji Akhundov, Erik van der Sluis, Said Hamdioui and Mottaqiallah\n  Taouil", "title": "Public-Key Based Authentication Architecture for IoT Devices Using PUF", "comments": null, "journal-ref": "6th International Conference on Computer Science, Engineering and\n  Information Technology (CSEIT-2019)", "doi": "10.5121/csit.2019.91328", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nowadays, Internet of Things (IoT) is a trending topic in the computing\nworld. Notably, IoT devices have strict design requirements and are often\nreferred to as constrained devices. Therefore, security techniques and\nprimitives that are lightweight are more suitable for such devices, e.g.,\nStatic Random-Access Memory (SRAM) Physical Unclonable Functions (PUFs) and\nElliptic Curve Cryptography (ECC). SRAM PUF is an intrinsic security primitive\nthat is seeing widespread adoption in the IoT segment. ECC is a public-key\nalgorithm technique that has been gaining popularity among constrained IoT\ndevices. The popularity is due to using significantly smaller operands when\ncompared to other public-key techniques such as RSA (Rivest Shamir Adleman).\nThis paper shows the design, development, and evaluation of an\napplication-specific secure communication architecture based on SRAM PUF\ntechnology and ECC for constrained IoT devices. More specifically, it\nintroduces an Elliptic Curve Diffie-Hellman (ECDH) public-key based\ncryptographic protocol that utilizes PUF-derived keys as the root-of-trust for\nsilicon authentication. Also, it proposes a design of a modular hardware\narchitecture that supports the protocol. Finally, to analyze the practicality\nas well as the feasibility of the proposed protocol, we demonstrate the\nsolution by prototyping and verifying a protocol variant on the commercial\nXilinx Zynq-7000 APSoC device.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 13:26:43 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Akhundov", "Haji", ""], ["van der Sluis", "Erik", ""], ["Hamdioui", "Said", ""], ["Taouil", "Mottaqiallah", ""]]}, {"id": "2002.01336", "submitter": "Feng Wei", "authors": "Feng Wei and Uyen Trang Nguyen", "title": "Twitter Bot Detection Using Bidirectional Long Short-term Memory Neural\n  Networks and Word Embeddings", "comments": "IEEE TPS 2019. arXiv admin note: text overlap with arXiv:1703.04482\n  by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twitter is a web application playing dual roles of online social networking\nand micro-blogging. The popularity and open structure of Twitter have attracted\na large number of automated programs, known as bots. Legitimate bots generate a\nlarge amount of benign contextual content, i.e., tweets delivering news and\nupdating feeds, while malicious bots spread spam or malicious contents. To\nassist human users in identifying who they are interacting with, this paper\nfocuses on the classification of human and spambot accounts on Twitter, by\nemploying recurrent neural networks, specifically bidirectional Long Short-term\nMemory (BiLSTM), to efficiently capture features across tweets. To the best of\nour knowledge, our work is the first that develops a recurrent neural model\nwith word embeddings to distinguish Twitter bots from human accounts, that\nrequires no prior knowledge or assumption about users' profiles, friendship\nnetworks, or historical behavior on the target account. Moreover, our model\ndoes not require any handcrafted features. The preliminary simulation results\nare very encouraging. Experiments on the cresci-2017 dataset show that our\napproach can achieve competitive performance compared with existing\nstate-of-the-art bot detection systems.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 17:07:03 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Wei", "Feng", ""], ["Nguyen", "Uyen Trang", ""]]}, {"id": "2002.01374", "submitter": "Ricardo P\\'erez-Marco", "authors": "Cyril Grunspan, Gabriel Leh\\'ericy, Ricardo P\\'erez-Marco", "title": "Ant Routing scalability for the Lightning Network", "comments": "26 pagew, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ambition of the Lightning Network is to provide a second layer to the\nBitcoin network to enable transactions confirmed instantly, securely and\nanonymously with a world scale capacity using a decentralized protocol. Some of\nthe current propositions and implementations present some difficulties in\nanonymity, scaling and decentalization. The Ant Routing algorithm for the\nLightning Network was proposed in \\cite{GrunspanPerez} for maximal\ndecentralization, anonymity and potential scaling. It solves several problems\nof current implementation, such as channel information update and\ncentralization by beacon nodes. Ant Routing nodes play all the same role and\ndon't require any extra information on the network topology beside for their\nimmediate neighbors. The goal of LN transactions are completed instantaneously\nand anonymously. We study the scaling of the Ant Routing protocol. We propose a\nprecise implementation, with efficient memory management using AVL trees. We\nevaluate the efficiency of the algorithm and we estimate the memory usage of\nnodes by local node workload simulations. We prove that the number of\ntransactions per second that Ant Routing can sustain is of the order of several\nthousands which is enough for a global payment network.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 15:49:29 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Grunspan", "Cyril", ""], ["Leh\u00e9ricy", "Gabriel", ""], ["P\u00e9rez-Marco", "Ricardo", ""]]}, {"id": "2002.01391", "submitter": "Minghan Chen", "authors": "Minghan Chen, Fangyan Dai, Bingjie Yan, Jieren Cheng and Longjuan Wang", "title": "Encryption Algorithm for TCP Session Hijacking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed network of the computer and the design defects of the TCP\nprotocol are given to the network attack to be multiplicative. Based on the\nsimple and open assumptions of the TCP protocol in academic and collaborative\ncommunication environments, the protocol lacks secure authentication. In this\npaper, by adding RSA-based cryptography technology, RSA-based signature\ntechnology, DH key exchange algorithm, and HAMC-SHA1 integrity verification\ntechnology to the TCP protocol, and propose a security strategy which can\neffectively defend against TCP session hijacking.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 16:17:47 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Chen", "Minghan", ""], ["Dai", "Fangyan", ""], ["Yan", "Bingjie", ""], ["Cheng", "Jieren", ""], ["Wang", "Longjuan", ""]]}, {"id": "2002.01469", "submitter": "Sohrab Ferdowsi", "authors": "Sohrab Ferdowsi, Behrooz Razeghi, Taras Holotyak, Flavio P. Calmon,\n  Slava Voloshynovskiy", "title": "Privacy-Preserving Image Sharing via Sparsifying Layers on Convolutional\n  Groups", "comments": "Accepted as an oral presentation for ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a practical framework to address the problem of privacy-aware\nimage sharing in large-scale setups. We argue that, while compactness is always\ndesired at scale, this need is more severe when trying to furthermore protect\nthe privacy-sensitive content. We therefore encode images, such that, from one\nhand, representations are stored in the public domain without paying the huge\ncost of privacy protection, but ambiguated and hence leaking no discernible\ncontent from the images, unless a combinatorially-expensive guessing mechanism\nis available for the attacker. From the other hand, authorized users are\nprovided with very compact keys that can easily be kept secure. This can be\nused to disambiguate and reconstruct faithfully the corresponding\naccess-granted images. We achieve this with a convolutional autoencoder of our\ndesign, where feature maps are passed independently through sparsifying\ntransformations, providing multiple compact codes, each responsible for\nreconstructing different attributes of the image. The framework is tested on a\nlarge-scale database of images with public implementation available.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 18:54:52 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Ferdowsi", "Sohrab", ""], ["Razeghi", "Behrooz", ""], ["Holotyak", "Taras", ""], ["Calmon", "Flavio P.", ""], ["Voloshynovskiy", "Slava", ""]]}, {"id": "2002.01501", "submitter": "Milan Lopuha\\\"a-Zwakenberg", "authors": "Milan Lopuha\\\"a-Zwakenberg", "title": "The Privacy Funnel from the viewpoint of Local Differential Privacy", "comments": "To appear at: ICDS 2020, PPODS track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a database $\\vec{X} = (X_1,\\cdots,X_n)$ containing the data of\n$n$ users. The data aggregator wants to publicise the database, but wishes to\nsanitise the dataset to hide sensitive data $S_i$ correlated to $X_i$. This\nsetting is considered in the Privacy Funnel, which uses mutual information as a\nleakage metric. The downsides to this approach are that mutual information does\nnot give worst-case guarantees, and that finding optimal sanitisation protocols\ncan be computationally prohibitive. We tackle these problems by using\ndifferential privacy metrics, and by considering local protocols which operate\non one entry at a time. We show that under both the Local Differential Privacy\nand Local Information Privacy leakage metrics, one can efficiently obtain\noptimal protocols; however, Local Information Privacy is both more closely\naligned to the privacy requirements of the Privacy Funnel scenario, and more\nefficiently computable. We also consider the scenario where each user has\nmultiple attributes (i.e. $X_i = (X^1_i,\\cdots,X^m_i)$), for which we define\n\\emph{Side-channel Resistant Local Information Privacy}, and we give efficient\nmethods to find protocols satisfying this criterion while still offering good\nutility. Exploratory experiments confirm the validity of these methods.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 19:16:00 GMT"}, {"version": "v2", "created": "Sat, 7 Mar 2020 21:03:10 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Lopuha\u00e4-Zwakenberg", "Milan", ""]]}, {"id": "2002.01513", "submitter": "Benjamin Harsha", "authors": "Benjamin Harsha, Robert Morton, Jeremiah Blocki, John Springer,\n  Melissa Dark", "title": "Bicycle Attacks Considered Harmful: Quantifying the Damage of Widespread\n  Password Length Leakage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the issue of password length leakage via encrypted traffic i.e.,\nbicycle attacks. We aim to quantify both the prevalence of password length\nleakage bugs as well as the potential harm to users. In an observational study,\nwe find that {\\em most} of the Alexa top 100 rates sites are vulnerable to\nbicycle attacks meaning that an eavesdropping attacker can infer the exact\nlength of a password based on the length the encrypted packet containing the\npassword. We discuss several ways in which an eavesdropping attacker could link\nthis password length with a particular user account e.g., a targeted campaign\nagainst a smaller group of users or via DNS hijacking for larger scale\ncampaigns. We next use a decision-theoretic model to quantify the extent to\nwhich password length leakage might help an attacker to crack user passwords.\nIn our analysis, we consider three different levels of password attackers:\nhacker, criminal and nation-state. In all cases, we find that such an attacker\nwho knows the length of each user password gains a significant advantage over\none without knowing the password length. As part of this analysis, we also\nrelease a new differentially private password frequency dataset from the 2016\nLinkedIn breach using a differentially private algorithm of Blocki et al. (NDSS\n2016) to protect user accounts. The LinkedIn frequency corpus is based on over\n170 million passwords making it the largest frequency corpus publicly available\nto password researchers. While the defense against bicycle attacks is\nstraightforward (i.e., ensure that passwords are always padded before\nencryption), we discuss several practical challenges organizations may face\nwhen attempting to patch this vulnerability. We advocate for a new W3C standard\non how password fields are handled which would effectively eliminate most\ninstances of password length leakage.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 19:34:34 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Harsha", "Benjamin", ""], ["Morton", "Robert", ""], ["Blocki", "Jeremiah", ""], ["Springer", "John", ""], ["Dark", "Melissa", ""]]}, {"id": "2002.01582", "submitter": "Ryan McKenna", "authors": "Ryan McKenna, Raj Kumar Maity, Arya Mazumdar, Gerome Miklau", "title": "A workload-adaptive mechanism for linear queries under local\n  differential privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new mechanism to accurately answer a user-provided set of linear\ncounting queries under local differential privacy (LDP). Given a set of linear\ncounting queries (the workload) our mechanism automatically adapts to provide\naccuracy on the workload queries. We define a parametric class of mechanisms\nthat produce unbiased estimates of the workload, and formulate a constrained\noptimization problem to select a mechanism from this class that minimizes\nexpected total squared error. We solve this optimization problem numerically\nusing projected gradient descent and provide an efficient implementation that\nscales to large workloads. We demonstrate the effectiveness of our\noptimization-based approach in a wide variety of settings, showing that it\noutperforms many competitors, even outperforming existing mechanisms on the\nworkloads for which they were intended.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 00:10:54 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 16:32:57 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["McKenna", "Ryan", ""], ["Maity", "Raj Kumar", ""], ["Mazumdar", "Arya", ""], ["Miklau", "Gerome", ""]]}, {"id": "2002.01647", "submitter": "Hongyu Li", "authors": "Hongyu Li, Dan Meng, Hong Wang and Xiaolin Li", "title": "Knowledge Federation: A Unified and Hierarchical Privacy-Preserving AI\n  Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With strict protections and regulations of data privacy and security,\nconventional machine learning based on centralized datasets is confronted with\nsignificant challenges, making artificial intelligence (AI) impractical in many\nmission-critical and data-sensitive scenarios, such as finance, government, and\nhealth. In the meantime, tremendous datasets are scattered in isolated silos in\nvarious industries, organizations, different units of an organization, or\ndifferent branches of an international organization. These valuable data\nresources are well underused. To advance AI theories and applications, we\npropose a comprehensive framework (called Knowledge Federation - KF) to address\nthese challenges by enabling AI while preserving data privacy and ownership.\nBeyond the concepts of federated learning and secure multi-party computation,\nKF consists of four levels of federation: (1) information level, low-level\nstatistics and computation of data, meeting the requirements of simple queries,\nsearching and simplistic operators; (2) model level, supporting training,\nlearning, and inference; (3) cognition level, enabling abstract feature\nrepresentation at various levels of abstractions and contexts; (4) knowledge\nlevel, fusing knowledge discovery, representation, and reasoning. We further\nclarify the relationship and differentiation between knowledge federation and\nother related research areas. We have developed a reference implementation of\nKF, called iBond Platform, to offer a production-quality KF platform to enable\nindustrial applications in finance, insurance et al. The iBond platform will\nalso help establish the KF community and a comprehensive ecosystem and usher in\na novel paradigm shift towards secure, privacy-preserving and responsible AI.\nAs far as we know, knowledge federation is the first hierarchical and unified\nframework for secure multi-party computing and learning.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 05:23:35 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 01:54:28 GMT"}, {"version": "v3", "created": "Fri, 22 May 2020 07:34:14 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Li", "Hongyu", ""], ["Meng", "Dan", ""], ["Wang", "Hong", ""], ["Li", "Xiaolin", ""]]}, {"id": "2002.01656", "submitter": "Tianming Liu", "authors": "Tianming Liu, Haoyu Wang, Li Li, Xiapu Luo, Feng Dong, Yao Guo, Liu\n  Wang, Tegawend\\'e F. Bissyand\\'e and Jacques Klein", "title": "MadDroid: Characterising and Detecting Devious Ad Content for Android\n  Apps", "comments": "To be published in The Web Conference 2020 (WWW'20)", "journal-ref": null, "doi": "10.1145/3366423.3380242", "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advertisement drives the economy of the mobile app ecosystem. As a key\ncomponent in the mobile ad business model, mobile ad content has been\noverlooked by the research community, which poses a number of threats, e.g.,\npropagating malware and undesirable contents. To understand the practice of\nthese devious ad behaviors, we perform a large-scale study on the app contents\nharvested through automated app testing. In this work, we first provide a\ncomprehensive categorization of devious ad contents, including five kinds of\nbehaviors belonging to two categories: \\emph{ad loading content} and \\emph{ad\nclicking content}. Then, we propose MadDroid, a framework for automated\ndetection of devious ad contents. MadDroid leverages an automated app testing\nframework with a sophisticated ad view exploration strategy for effectively\ncollecting ad-related network traffic and subsequently extracting ad contents.\nWe then integrate dedicated approaches into the framework to identify devious\nad contents. We have applied MadDroid to 40,000 Android apps and found that\nroughly 6\\% of apps deliver devious ad contents, e.g., distributing malicious\napps that cannot be downloaded via traditional app markets. Experiment results\nindicate that devious ad contents are prevalent, suggesting that our community\nshould invest more effort into the detection and mitigation of devious ads\ntowards building a trustworthy mobile advertising ecosystem.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 06:08:00 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Liu", "Tianming", ""], ["Wang", "Haoyu", ""], ["Li", "Li", ""], ["Luo", "Xiapu", ""], ["Dong", "Feng", ""], ["Guo", "Yao", ""], ["Wang", "Liu", ""], ["Bissyand\u00e9", "Tegawend\u00e9 F.", ""], ["Klein", "Jacques", ""]]}, {"id": "2002.01810", "submitter": "Felix Assion", "authors": "David Mickisch, Felix Assion, Florens Gre{\\ss}ner, Wiebke G\\\"unther,\n  Mariele Motta", "title": "Understanding the Decision Boundary of Deep Neural Networks: An\n  Empirical Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite achieving remarkable performance on many image classification tasks,\nstate-of-the-art machine learning (ML) classifiers remain vulnerable to small\ninput perturbations. Especially, the existence of adversarial examples raises\nconcerns about the deployment of ML models in safety- and security-critical\nenvironments, like autonomous driving and disease detection. Over the last few\nyears, numerous defense methods have been published with the goal of improving\nadversarial as well as corruption robustness. However, the proposed measures\nsucceeded only to a very limited extent. This limited progress is partly due to\nthe lack of understanding of the decision boundary and decision regions of deep\nneural networks. Therefore, we study the minimum distance of data points to the\ndecision boundary and how this margin evolves over the training of a deep\nneural network. By conducting experiments on MNIST, FASHION-MNIST, and\nCIFAR-10, we observe that the decision boundary moves closer to natural images\nover training. This phenomenon even remains intact in the late epochs of\ntraining, where the classifier already obtains low training and test error\nrates. On the other hand, adversarial training appears to have the potential to\nprevent this undesired convergence of the decision boundary.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 14:34:22 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Mickisch", "David", ""], ["Assion", "Felix", ""], ["Gre\u00dfner", "Florens", ""], ["G\u00fcnther", "Wiebke", ""], ["Motta", "Mariele", ""]]}, {"id": "2002.01847", "submitter": "Alberto Garoffolo", "authors": "Alberto Garoffolo, Dmytro Kaidalov, Roman Oliynykov", "title": "Zendoo: a zk-SNARK Verifiable Cross-Chain Transfer Protocol Enabling\n  Decoupled and Decentralized Sidechains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sidechains are an appealing innovation devised to enable blockchain\nscalability and extensibility. The basic idea is simple yet powerful: construct\na parallel chain -- sidechain -- with desired features, and provide a way to\ntransfer coins between the mainchain and the sidechain.\n  In this paper, we introduce Zendoo, a construction for Bitcoin-like\nblockchain systems that allows the creation and communication with sidechains\nof different types without knowing their internal structure. We consider a\nparent-child relationship between the mainchain and sidechains, where sidechain\nnodes directly observe the mainchain while mainchain nodes only observe\ncryptographically authenticated certificates from sidechain maintainers. We use\nzk-SNARKs to construct a universal verifiable transfer mechanism that is used\nby sidechains.\n  Moreover, we propose a specific sidechain construction, named Latus, that can\nbe built on top of this infrastructure, and realizes a decentralized verifiable\nblockchain system for payments. We leverage the use of recursive composition of\nzk-SNARKs to generate succinct proofs of sidechain state progression that are\nused to generate certificates' validity proofs. This allows the mainchain to\nefficiently verify all operations performed in the sidechain without knowing\nany details about those operations.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 16:17:24 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Garoffolo", "Alberto", ""], ["Kaidalov", "Dmytro", ""], ["Oliynykov", "Roman", ""]]}, {"id": "2002.01919", "submitter": "Badih Ghazi", "authors": "Badih Ghazi, Noah Golowich, Ravi Kumar, Pasin Manurangsi, Rasmus Pagh,\n  Ameya Velingker", "title": "Pure Differentially Private Summation from Anonymous Messages", "comments": "40 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The shuffled (aka anonymous) model has recently generated significant\ninterest as a candidate distributed privacy framework with trust assumptions\nbetter than the central model but with achievable errors smaller than the local\nmodel. We study pure differentially private (DP) protocols in the shuffled\nmodel for summation, a basic and widely used primitive:\n  - For binary summation where each of n users holds a bit as an input, we give\na pure $\\epsilon$-DP protocol for estimating the number of ones held by the\nusers up to an error of $O_\\epsilon(1)$, and each user sends $O_\\epsilon(\\log\nn)$ messages each of 1 bit. This is the first pure protocol in the shuffled\nmodel with error $o(\\sqrt{n})$ for constant $\\epsilon$.\n  Using this protocol, we give a pure $\\epsilon$-DP protocol that performs\nsummation of real numbers in $[0, 1]$ up to an error of $O_{\\epsilon}(1)$, and\nwhere each user sends $O_{\\epsilon}(\\log^3 n)$ messages each of $O(\\log\\log n)$\nbits.\n  - In contrast, we show that for any pure $\\epsilon$-DP protocol for binary\nsummation in the shuffled model having absolute error $n^{0.5-\\Omega(1)}$, the\nper user communication has to be at least $\\Omega_{\\epsilon}(\\sqrt{\\log n})$\nbits. This implies the first separation between the (bounded-communication)\nmulti-message shuffled model and the central model, and the first separation\nbetween pure and approximate DP protocols in the shuffled model.\n  To prove our lower bound, we consider (a generalization of) the following\nquestion: given $\\gamma$ in $(0, 1)$, what is the smallest m for which there\nare two random variables $X^0, X^1$ supported on $\\{0, \\dots ,m\\}$ such that\n(i) the total variation distance between $X^0$ and $X^1$ is at least\n$1-\\gamma$, and (ii) the moment generating functions of $X^0$ and $X^1$ are\nwithin a constant factor of each other everywhere? We show that the answer is\n$m = \\Theta(\\sqrt{\\log(1/\\gamma)})$.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 18:53:21 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Ghazi", "Badih", ""], ["Golowich", "Noah", ""], ["Kumar", "Ravi", ""], ["Manurangsi", "Pasin", ""], ["Pagh", "Rasmus", ""], ["Velingker", "Ameya", ""]]}, {"id": "2002.01969", "submitter": "Mohamadreza Ahmadi", "authors": "Mohamadreza Ahmadi, Arun A. Viswanathan, Michel D. Ingham, Kymie Tan,\n  and Aaron D. Ames", "title": "Partially Observable Games for Secure Autonomy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.CR cs.FL cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technology development efforts in autonomy and cyber-defense have been\nevolving independently of each other, over the past decade. In this paper, we\nreport our ongoing effort to integrate these two presently distinct areas into\na single framework. To this end, we propose the two-player partially observable\nstochastic game formalism to capture both high-level autonomous mission\nplanning under uncertainty and adversarial decision making subject to imperfect\ninformation. We show that synthesizing sub-optimal strategies for such games is\npossible under finite-memory assumptions for both the autonomous decision maker\nand the cyber-adversary. We then describe an experimental testbed to evaluate\nthe efficacy of the proposed framework.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 19:31:56 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Ahmadi", "Mohamadreza", ""], ["Viswanathan", "Arun A.", ""], ["Ingham", "Michel D.", ""], ["Tan", "Kymie", ""], ["Ames", "Aaron D.", ""]]}, {"id": "2002.02007", "submitter": "Shuo Wang", "authors": "Shuo Wang, Tianle Chen, Surya Nepal, Carsten Rudolph, Marthie Grobler,\n  Shangyu Chen", "title": "Defending Adversarial Attacks via Semantic Feature Manipulation", "comments": "arXiv admin note: text overlap with arXiv:2001.06640 and text overlap\n  with arXiv:1705.09064 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models have demonstrated vulnerability to adversarial\nattacks, more specifically misclassification of adversarial examples. In this\npaper, we propose a one-off and attack-agnostic Feature Manipulation\n(FM)-Defense to detect and purify adversarial examples in an interpretable and\nefficient manner. The intuition is that the classification result of a normal\nimage is generally resistant to non-significant intrinsic feature changes,\ne.g., varying thickness of handwritten digits. In contrast, adversarial\nexamples are sensitive to such changes since the perturbation lacks\ntransferability. To enable manipulation of features, a combo-variational\nautoencoder is applied to learn disentangled latent codes that reveal semantic\nfeatures. The resistance to classification change over the morphs, derived by\nvarying and reconstructing latent codes, is used to detect suspicious inputs.\nFurther, combo-VAE is enhanced to purify the adversarial examples with good\nquality by considering both class-shared and class-unique features. We\nempirically demonstrate the effectiveness of detection and the quality of\npurified instance. Our experiments on three datasets show that FM-Defense can\ndetect nearly $100\\%$ of adversarial examples produced by different\nstate-of-the-art adversarial attacks. It achieves more than $99\\%$ overall\npurification accuracy on the suspicious instances that close the manifold of\nnormal examples.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 23:24:32 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 13:14:48 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Wang", "Shuo", ""], ["Chen", "Tianle", ""], ["Nepal", "Surya", ""], ["Rudolph", "Carsten", ""], ["Grobler", "Marthie", ""], ["Chen", "Shangyu", ""]]}, {"id": "2002.02061", "submitter": "Xiaoguang Li", "authors": "Xiaoguang Li, Hui Li, Haonan Yan, Zelei Cheng, Wenhai Sun, Hui Zhu", "title": "Mitigating Query-Flooding Parameter Duplication Attack on Regression\n  Models with High-Dimensional Gaussian Mechanism", "comments": "it has some mistakes. Since I submitted the paper for the first time,\n  there were many mistakes in the paper. At the same time, I found a serious\n  mistake in the content of the paper, so I thought it was inappropriate to\n  publish it now after careful consideration.", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public intelligent services enabled by machine learning algorithms are\nvulnerable to model extraction attacks that can steal confidential information\nof the learning models through public queries. Differential privacy (DP) has\nbeen considered a promising technique to mitigate this attack. However, we find\nthat the vulnerability persists when regression models are being protected by\ncurrent DP solutions. We show that the adversary can launch a query-flooding\nparameter duplication (QPD) attack to infer the model information by repeated\nqueries.\n  To defend against the QPD attack on logistic and linear regression models, we\npropose a novel High-Dimensional Gaussian (HDG) mechanism to prevent\nunauthorized information disclosure without interrupting the intended services.\nIn contrast to prior work, the proposed HDG mechanism will dynamically generate\nthe privacy budget and random noise for different queries and their results to\nenhance the obfuscation. Besides, for the first time, HDG enables an optimal\nprivacy budget allocation that automatically determines the minimum amount of\nnoise to be added per user-desired privacy level on each dimension. We\ncomprehensively evaluate the performance of HDG using real-world datasets and\nshows that HDG effectively mitigates the QPD attack while satisfying the\nprivacy requirements. We also prepare to open-source the relevant codes to the\ncommunity for further research.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 01:47:08 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 14:20:42 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2020 01:40:09 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Li", "Xiaoguang", ""], ["Li", "Hui", ""], ["Yan", "Haonan", ""], ["Cheng", "Zelei", ""], ["Sun", "Wenhai", ""], ["Zhu", "Hui", ""]]}, {"id": "2002.02074", "submitter": "Pooja Gupta", "authors": "Pooja Gupta, Volkan Dedeoglu, Kamran Najeebullah, Salil S. Kanhere and\n  Raja Jurdak", "title": "Energy-aware Demand Selection and Allocation for Real-time IoT Data\n  Trading", "comments": "Accepted in SmartComp 2020", "journal-ref": null, "doi": "10.1109/SMARTCOMP50058.2020.00038", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personal IoT data is a new economic asset that individuals can trade to\ngenerate revenue on the emerging data marketplaces. Typically, marketplaces are\ncentralized systems that raise concerns of privacy, single point of failure,\nlittle transparency and involve trusted intermediaries to be fair. Furthermore,\nthe battery-operated IoT devices limit the amount of IoT data to be traded in\nreal-time that affects buyer/seller satisfaction and hence, impacting the\nsustainability and usability of such a marketplace. This work proposes to\nutilize blockchain technology to realize a trusted and transparent\ndecentralized marketplace for contract compliance for trading IoT data streams\ngenerated by battery-operated IoT devices in real-time. The contribution of\nthis paper is two-fold: (1) we propose an autonomous blockchain-based\nmarketplace equipped with essential functionalities such as agreement\nframework, pricing model and rating mechanism to create an effective\nmarketplace framework without involving a mediator, (2) we propose a mechanism\nfor selection and allocation of buyers' demands on seller's devices under\nquality and battery constraints. We present a proof-of-concept implementation\nin Ethereum to demonstrate the feasibility of the framework. We investigated\nthe impact of buyer's demand on the battery drainage of the IoT devices under\ndifferent scenarios through extensive simulations. Our results show that this\napproach is viable and benefits the seller and buyer for creating a sustainable\nmarketplace model for trading IoT data in real-time from battery-powered IoT\ndevices.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 02:35:05 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 05:41:52 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Gupta", "Pooja", ""], ["Dedeoglu", "Volkan", ""], ["Najeebullah", "Kamran", ""], ["Kanhere", "Salil S.", ""], ["Jurdak", "Raja", ""]]}, {"id": "2002.02082", "submitter": "Chao Li", "authors": "Chao Li and Balaji Palanisamy", "title": "Comparison of Decentralization in DPoS and PoW Blockchains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralization is a key indicator for the evaluation of public blockchains.\nIn the past, there have been very few studies on measuring and comparing the\nactual level of decentralization between Proof-of-Work (PoW) blockchains and\nblockchains with other consensus protocols. This paper presents a new\ncomparison study of the level of decentralization in Bitcoin and Steem, a\nprominent Delegated-Proof-of-Stake (DPoS) blockchain. Our study particularly\nfocuses on analysing the power that decides the creators of blocks in the\nblockchain. In Bitcoin, miners with higher computational power generate more\nblocks. In contrast, blocks in Steem are equally generated by witnesses while\nwitnesses are periodically elected by stakeholders with different voting power\nweighted by invested stake. We analyze the process of stake-weighted election\nof witnesses in DPoS and measure the actual stake invested by each stakeholder\nin Steem. We then compute the Shannon entropy of the distribution of\ncomputational power among miners in Bitcoin and the distribution of invested\nstake among stakeholders in Steem. Our analyses reveal that neither Bitcoin nor\nSteem is dominantly better than the other with respect to decentralization.\nCompared with Steem, Bitcoin tends to be more decentralized among top miners\nbut less decentralized in general. Our study is designed to provide insights\ninto the current state of the degree of decentralization in DPoS and PoW\nblockchains. We believe that the methodologies and findings in this paper can\nfacilitate future studies of decentralization in other blockchain systems\nemploying different consensus protocols.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 03:20:15 GMT"}, {"version": "v2", "created": "Sun, 31 May 2020 09:34:36 GMT"}, {"version": "v3", "created": "Tue, 2 Feb 2021 03:52:24 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Li", "Chao", ""], ["Palanisamy", "Balaji", ""]]}, {"id": "2002.02088", "submitter": "Chaochao Chen", "authors": "Chaochao Chen, Liang Li, Bingzhe Wu, Cheng Hong, Li Wang, Jun Zhou", "title": "Secure Social Recommendation based on Secret Sharing", "comments": "Accepted by ECAI'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, privacy preserving machine learning has been drawing much attention\nin both industry and academy. Meanwhile, recommender systems have been\nextensively adopted by many commercial platforms (e.g. Amazon) and they are\nmainly built based on user-item interactions. Besides, social platforms (e.g.\nFacebook) have rich resources of user social information. It is well known that\nsocial information, which is rich on social platforms such as Facebook, are\nuseful to recommender systems. It is anticipated to combine the social\ninformation with the user-item ratings to improve the overall recommendation\nperformance. Most existing recommendation models are built based on the\nassumptions that the social information are available. However, different\nplatforms are usually reluctant to (or cannot) share their data due to certain\nconcerns. In this paper, we first propose a SEcure SOcial RECommendation\n(SeSoRec) framework which can (1) collaboratively mine knowledge from social\nplatform to improve the recommendation performance of the rating platform, and\n(2) securely keep the raw data of both platforms. We then propose a Secret\nSharing based Matrix Multiplication (SSMM) protocol to optimize SeSoRec and\nprove its correctness and security theoretically. By applying minibatch\ngradient descent, SeSoRec has linear time complexities in terms of both\ncomputation and communication. The comprehensive experimental results on three\nreal-world datasets demonstrate the effectiveness of our proposed SeSoRec and\nSSMM.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 03:49:51 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 06:43:35 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Chen", "Chaochao", ""], ["Li", "Liang", ""], ["Wu", "Bingzhe", ""], ["Hong", "Cheng", ""], ["Wang", "Li", ""], ["Zhou", "Jun", ""]]}, {"id": "2002.02091", "submitter": "Yingting Liu", "authors": "Yingting Liu, Chaochao Chen, Longfei Zheng, Li Wang, Jun Zhou, Guiquan\n  Liu, Shuang Yang", "title": "Privacy Preserving PCA for Multiparty Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a general multiparty modeling paradigm with Privacy\nPreserving Principal Component Analysis (PPPCA) for horizontally partitioned\ndata. PPPCA can accomplish multiparty cooperative execution of PCA under the\npremise of keeping plaintext data locally. We also propose implementations\nusing two techniques, i.e., homomorphic encryption and secret sharing. The\noutput of PPPCA can be sent directly to data consumer to build any machine\nlearning models. We conduct experiments on three UCI benchmark datasets and a\nreal-world fraud detection dataset. Results show that the accuracy of the model\nbuilt upon PPPCA is the same as the model with PCA that is built based on\ncentralized plaintext data.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 04:16:59 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 13:29:21 GMT"}, {"version": "v3", "created": "Thu, 12 Mar 2020 12:38:39 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Liu", "Yingting", ""], ["Chen", "Chaochao", ""], ["Zheng", "Longfei", ""], ["Wang", "Li", ""], ["Zhou", "Jun", ""], ["Liu", "Guiquan", ""], ["Yang", "Shuang", ""]]}, {"id": "2002.02096", "submitter": "Sen Wang", "authors": "Sen Wang, J.Morris Chang", "title": "Privacy-Preserving Boosting in the Local Setting", "comments": "12 pages, 11 figures, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning, boosting is one of the most popular methods that\ndesigned to combine multiple base learners to a superior one. The well-known\nBoosted Decision Tree classifier, has been widely adopted in many areas. In the\nbig data era, the data held by individual and entities, like personal images,\nbrowsing history and census information, are more likely to contain sensitive\ninformation. The privacy concern raises when such data leaves the hand of the\nowners and be further explored or mined. Such privacy issue demands that the\nmachine learning algorithm should be privacy aware. Recently, Local\nDifferential Privacy is proposed as an effective privacy protection approach,\nwhich offers a strong guarantee to the data owners, as the data is perturbed\nbefore any further usage, and the true values never leave the hands of the\nowners. Thus the machine learning algorithm with the private data instances is\nof great value and importance. In this paper, we are interested in developing\nthe privacy-preserving boosting algorithm that a data user is allowed to build\na classifier without knowing or deriving the exact value of each data samples.\nOur experiments demonstrate the effectiveness of the proposed boosting\nalgorithm and the high utility of the learned classifiers.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 04:48:51 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Wang", "Sen", ""], ["Chang", "J. Morris", ""]]}, {"id": "2002.02175", "submitter": "Guannan Lou", "authors": "Yao Deng, Xi Zheng, Tianyi Zhang, Chen Chen, Guannan Lou, Miryung Kim", "title": "An Analysis of Adversarial Attacks and Defenses on Autonomous Driving\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, autonomous driving has attracted much attention from both industry\nand academia. Convolutional neural network (CNN) is a key component in\nautonomous driving, which is also increasingly adopted in pervasive computing\nsuch as smartphones, wearable devices, and IoT networks. Prior work shows\nCNN-based classification models are vulnerable to adversarial attacks. However,\nit is uncertain to what extent regression models such as driving models are\nvulnerable to adversarial attacks, the effectiveness of existing defense\ntechniques, and the defense implications for system and middleware builders.\nThis paper presents an in-depth analysis of five adversarial attacks and four\ndefense methods on three driving models. Experiments show that, similar to\nclassification models, these models are still highly vulnerable to adversarial\nattacks. This poses a big security threat to autonomous driving and thus should\nbe taken into account in practice. While these defense methods can effectively\ndefend against different attacks, none of them are able to provide adequate\nprotection against all five attacks. We derive several implications for system\nand middleware builders: (1) when adding a defense component against\nadversarial attacks, it is important to deploy multiple defense methods in\ntandem to achieve a good coverage of various attacks, (2) a blackbox attack is\nmuch less effective compared with a white-box attack, implying that it is\nimportant to keep model details (e.g., model architecture, hyperparameters)\nconfidential via model obfuscation, and (3) driving models with a complex\narchitecture are preferred if computing resources permit as they are more\nresilient to adversarial attacks than simple models.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 09:49:16 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Deng", "Yao", ""], ["Zheng", "Xi", ""], ["Zhang", "Tianyi", ""], ["Chen", "Chen", ""], ["Lou", "Guannan", ""], ["Kim", "Miryung", ""]]}, {"id": "2002.02196", "submitter": "Tao Bai", "authors": "Tao Bai, Jun Zhao, Jinlin Zhu, Shoudong Han, Jiefeng Chen, Bo Li, Alex\n  Kot", "title": "AI-GAN: Attack-Inspired Generation of Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are vulnerable to adversarial examples, which are\ncrafted by adding imperceptible perturbations to inputs. Recently different\nattacks and strategies have been proposed, but how to generate adversarial\nexamples perceptually realistic and more efficiently remains unsolved. This\npaper proposes a novel framework called Attack-Inspired GAN (AI-GAN), where a\ngenerator, a discriminator, and an attacker are trained jointly. Once trained,\nit can generate adversarial perturbations efficiently given input images and\ntarget classes. Through extensive experiments on several popular datasets \\eg\nMNIST and CIFAR-10, AI-GAN achieves high attack success rates and reduces\ngeneration time significantly in various settings. Moreover, for the first\ntime, AI-GAN successfully scales to complicated datasets \\eg CIFAR-100 with\naround $90\\%$ success rates among all classes.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 10:57:41 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 06:22:17 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Bai", "Tao", ""], ["Zhao", "Jun", ""], ["Zhu", "Jinlin", ""], ["Han", "Shoudong", ""], ["Chen", "Jiefeng", ""], ["Li", "Bo", ""], ["Kot", "Alex", ""]]}, {"id": "2002.02316", "submitter": "Carlos Sarraute PhD", "authors": "Hartwig Mayer, Ismael Bejarano, Daniel Fernandez, Gustavo Ajzenman,\n  Nicolas Ayala, Nahuel Santoalla, Carlos Sarraute, Ariel Futoransky", "title": "BatPay: a gas efficient protocol for the recurrent micropayment of ERC20\n  tokens", "comments": "14 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  BatPay is a proxy scaling solution for the transfer of ERC20 tokens. It is\nsuitable for micropayments in one-to-many and few-to-many scenarios, including\ndigital markets and the distribution of rewards and dividends. In BatPay, many\nsimilar operations are bundled together into a single transaction in order to\noptimize gas consumption on the Ethereum blockchain. In addition, some costly\nverifications are replaced by a challenge game, pushing most of the computing\ncost off-chain. This results in a gas reduction of the transfer costs of three\norders of magnitude, achieving around 1700 transactions per second on the\nEthereum blockchain. Furthermore, it includes many relevant features, like\nmeta-transactions for end-user operation without ether, and key-locked payments\nfor atomic exchange of digital goods.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 15:43:52 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Mayer", "Hartwig", ""], ["Bejarano", "Ismael", ""], ["Fernandez", "Daniel", ""], ["Ajzenman", "Gustavo", ""], ["Ayala", "Nicolas", ""], ["Santoalla", "Nahuel", ""], ["Sarraute", "Carlos", ""], ["Futoransky", "Ariel", ""]]}, {"id": "2002.02368", "submitter": "Abdalrahman Hwoij Mr", "authors": "Abdalrahman Hwoij, Mouhammd Al-kasassbeh, Mustafa Al-Fayoumi", "title": "Detecting Network Anomalies using Rule-based machine learning within\n  SNMP-MIB dataset", "comments": "17 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most effective threats that targeting cybercriminals to limit\nnetwork performance is Denial of Service (DOS) attack. Thus, data security,\ncompleteness and efficiency could be greatly damaged by this type of attacks.\nThis paper developed a network traffic system that relies on adopted dataset to\ndifferentiate the DOS attacks from normal traffic. The detection model is built\nwith five Rule-based machine learning classifiers (DecisionTable, JRip, OneR,\nPART and ZeroR). The findings have shown that the ICMP variables are\nimplemented in the identification of ICMP attack, HTTP flood attack, and\nSlowloris at a high accuracy of approximately 99.7% using PART classifier. In\naddition, PART classifier has succeeded in classifying normal traffic from\ndifferent DOS attacks at 100%.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 13:05:41 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Hwoij", "Abdalrahman", ""], ["Al-kasassbeh", "Mouhammd", ""], ["Al-Fayoumi", "Mustafa", ""]]}, {"id": "2002.02372", "submitter": "Zhuanghua Liu", "authors": "Zhuanghua Liu and Ivor W. Tsang", "title": "Towards Sharper First-Order Adversary with Quantized Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Despite the huge success of Deep Neural Networks (DNNs) in a wide spectrum of\nmachine learning and data mining tasks, recent research shows that this\npowerful tool is susceptible to maliciously crafted adversarial examples. Up\nuntil now, adversarial training has been the most successful defense against\nadversarial attacks. To increase adversarial robustness, a DNN can be trained\nwith a combination of benign and adversarial examples generated by first-order\nmethods. However, in state-of-the-art first-order attacks, adversarial examples\nwith sign gradients retain the sign information of each gradient component but\ndiscard the relative magnitude between components. In this work, we replace\nsign gradients with quantized gradients. Gradient quantization not only\npreserves the sign information, but also keeps the relative magnitude between\ncomponents. Experiments show white-box first-order attacks with quantized\ngradients outperform their variants with sign gradients on multiple datasets.\nNotably, our BLOB\\_QG attack achieves an accuracy of $88.32\\%$ on the secret\nMNIST model from the MNIST Challenge and it outperforms all other methods on\nthe leaderboard of white-box attacks.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 14:33:51 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Liu", "Zhuanghua", ""], ["Tsang", "Ivor W.", ""]]}, {"id": "2002.02379", "submitter": "Bo Chen", "authors": "Bo Chen", "title": "Towards Designing A Secure Plausibly Deniable System for Mobile Devices\n  against Multi-snapshot Adversaries -- A Preliminary Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile computing devices have been used broadly to store, manage and process\nsensitive or even mission critical data. To protect confidentiality of data\nstored in mobile devices, major mobile operating systems use full disk\nencryption, which relies on traditional encryption mechanisms and requires that\ndecryption keys will not be disclosed. This however, is not necessarily true,\nsince an active attacker may coerce victims for decryption keys. Plausibly\ndeniable encryption (PDE) can defend against such a coercive attacker by\ndisguising the true secret key with a decoy key. Leveraging concept of PDE,\nvarious deniable storage systems have been built for both PC and mobile\nplatforms. However, a secure PDE system for mobile devices is still missing\nwhich can be compatible with mainstream mobile devices and, meanwhile, remains\nsecure when facing a strong multi-snapshot adversary. In this work, we propose\na preliminary PDE system design for mobile computing devices using flash memory\nas underlying storage medium. Ours is the first secure PDE system for mobile\ndevices which has the following new design features: 1) it is compatible with\nmainstream mobile devices due to its integration of PDE into flash translation\nlayer (FTL), the most popular form of flash memory being used by modern mobile\ndevices; and 2) it can defend against the multi-snapshot adversary by denying\nhidden writes (over the flash memory) caused by hidden sensitive data using\nrandom dummy writes.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 00:06:09 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Chen", "Bo", ""]]}, {"id": "2002.02413", "submitter": "Shreyank N Gowda", "authors": "Shreyank N Gowda, Chun Yuan", "title": "StegColNet: Steganalysis based on an ensemble colorspace approach", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-73973-7_30", "report-no": null, "categories": "eess.IV cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image steganography refers to the process of hiding information inside\nimages. Steganalysis is the process of detecting a steganographic image. We\nintroduce a steganalysis approach that uses an ensemble color space model to\nobtain a weighted concatenated feature activation map. The concatenated map\nhelps to obtain certain features explicit to each color space. We use a\nlevy-flight grey wolf optimization strategy to reduce the number of features\nselected in the map. We then use these features to classify the image into one\nof two classes: whether the given image has secret information stored or not.\nExtensive experiments have been done on a large scale dataset extracted from\nthe Bossbase dataset. Also, we show that the model can be transferred to\ndifferent datasets and perform extensive experiments on a mixture of datasets.\nOur results show that the proposed approach outperforms the recent state of the\nart deep learning steganalytical approaches by 2.32 percent on average for 0.2\nbits per channel (bpc) and 1.87 percent on average for 0.4 bpc.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 17:44:25 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 16:30:15 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Gowda", "Shreyank N", ""], ["Yuan", "Chun", ""]]}, {"id": "2002.02516", "submitter": "Ran Cohen", "authors": "Elette Boyle and Ran Cohen and Aarushi Goel", "title": "Breaking the $O(\\sqrt n)$-Bit Barrier: Byzantine Agreement with Polylog\n  Bits Per Party", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Byzantine agreement (BA), the task of $n$ parties to agree on one of their\ninput bits in the face of malicious agents, is a powerful primitive that lies\nat the core of a vast range of distributed protocols. Interestingly, in\nprotocols with the best overall communication, the demands of the parties are\nhighly unbalanced: the amortized cost is $\\tilde O(1)$ bits per party, but some\nparties must send $\\Omega(n)$ bits. In best known balanced protocols, the\noverall communication is sub-optimal, with each party communicating $\\tilde\nO(\\sqrt{n})$. In this work, we ask whether asymmetry is inherent for optimizing\ntotal communication. Our contributions in this line are as follows:\n  1) We define a cryptographic primitive, succinctly reconstructed distributed\nsignatures (SRDS), that suffices for constructing $\\tilde O(1)$ balanced BA. We\nprovide two constructions of SRDS from different cryptographic and Public-Key\nInfrastructure (PKI) assumptions.\n  2) The SRDS-based BA follows a paradigm of boosting from \"almost-everywhere\"\nagreement to full agreement, and does so in a single round. We prove that PKI\nsetup and cryptographic assumptions are necessary for such protocols in which\nevery party sends $o(n)$ messages.\n  3) We further explore connections between a natural approach toward attaining\nSRDS and average-case succinct non-interactive argument systems (SNARGs) for a\nparticular type of NP-Complete problems (generalizing Subset-Sum and\nSubset-Product).\n  Our results provide new approaches forward, as well as limitations and\nbarriers, towards minimizing per-party communication of BA. In particular, we\nconstruct the first two BA protocols with $\\tilde O(1)$ balanced communication,\noffering a tradeoff between setup and cryptographic assumptions, and answering\nan open question presented by King and Saia (DISC'09).\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 21:19:32 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 15:28:28 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 20:34:36 GMT"}, {"version": "v4", "created": "Mon, 26 Jul 2021 18:51:58 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Boyle", "Elette", ""], ["Cohen", "Ran", ""], ["Goel", "Aarushi", ""]]}, {"id": "2002.02519", "submitter": "Subhash Lakshminarayana", "authors": "Subhash Lakshminarayana, Abla Kammoun, Merouane Debbah and H. Vincent\n  Poor", "title": "Data-Driven False Data Injection Attacks Against Power Grids: A Random\n  Matrix Approach", "comments": null, "journal-ref": "IEEE Trans. Smart Grid, 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.IT cs.SY eess.SP eess.SY math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of constructing false data injection (FDI) attacks\nthat can bypass the bad data detector (BDD) of a power grid. The attacker is\nassumed to have access to only power flow measurement data traces (collected\nover a limited period of time) and no other prior knowledge about the grid.\nExisting related algorithms are formulated under the assumption that the\nattacker has access to measurements collected over a long (asymptotically\ninfinite) time period, which may not be realistic. We show that these\napproaches do not perform well when the attacker has a limited number of data\nsamples only. We design an enhanced algorithm to construct FDI attack vectors\nin the face of limited measurements that can nevertheless bypass the BDD with\nhigh probability. The algorithm design is guided by results from random matrix\ntheory. Furthermore, we characterize an important trade-off between the\nattack's BDD-bypass probability and its sparsity, which affects the spatial\nextent of the attack that must be achieved. Extensive simulations using data\ntraces collected from the MATPOWER simulator and benchmark IEEE bus systems\nvalidate our findings.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 21:45:42 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 08:51:21 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Lakshminarayana", "Subhash", ""], ["Kammoun", "Abla", ""], ["Debbah", "Merouane", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2002.02696", "submitter": "Hannes Bartz", "authors": "Hannes Bartz, Emna Ben Yacoub, Lorenza Bertarelli, Gianluigi Liva", "title": "Protograph-Based Decoding of LDPC Codes with Hamming Weight Amplifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new protograph-based framework for message passing (MP) decoding of low\ndensity parity-check (LDPC) codes with Hamming weight amplifiers (HWAs), which\nare used e.g. in the NIST post-quantum crypto candidate LEDAcrypt, is proposed.\nThe scheme exploits the correlations in the error patterns introduced by the\nHWA using a turbo-like decoding approach where messages between the decoders\nfor the outer code given by the HWA and the inner LDPC code are exchanged.\nDecoding thresholds for the proposed scheme are computed using density\nevolution (DE) analysis for belief propagation (BP) and ternary message passing\n(TMP) decoding and compared to existing decoding approaches. The proposed\nscheme improves upon the basic approach of decoding LDPC code from the\namplified error and has a similar performance as decoding the corresponding\nmoderate-density parity-check (MDPC) code but with a significantly lower\ncomputational complexity.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 10:06:44 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Bartz", "Hannes", ""], ["Yacoub", "Emna Ben", ""], ["Bertarelli", "Lorenza", ""], ["Liva", "Gianluigi", ""]]}, {"id": "2002.02710", "submitter": "Pedro Antonino", "authors": "Pedro Antonino and A. W. Roscoe", "title": "Formalising and verifying smart contracts with Solidifier: a bounded\n  model checker for Solidity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exploitation of smart-contract vulnerabilities can have catastrophic\nconsequences such as the loss of millions of pounds worth of crypto assets.\nFormal verification can be a useful tool in identifying vulnerabilities and\nproving that they have been fixed. In this paper, we present a formalisation of\nSolidity and the Ethereum blockchain using the Solid language and its\nblockchain; a Solid program is obtained by explicating/desugaring a Solidity\nprogram. We make some abstractions that over-approximate the way in which\nSolidity/Ethereum behave. Based on this formalisation, we create Solidifier: a\nbounded model checker for Solidity. It translates Solid into Boogie, an\nintermediate verification language, that is later verified using Corral, a\nbounded model checker for Boogie. Unlike much of the work in this area, we do\nnot try to find specific behavioural/code patterns that might lead to\nvulnerabilities. Instead, we provide a tool to find errors/bad states, i.e.\nprogram states that do not conform with the intent of the developer. Such a bad\nstate, be it a vulnerability or not, might be reached through the execution of\nspecific known code patterns or through behaviours that have not been\nanticipated.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 10:54:57 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Antonino", "Pedro", ""], ["Roscoe", "A. W.", ""]]}, {"id": "2002.02741", "submitter": "Moshe Kravchik", "authors": "Moshe Kravchik, Asaf Shabtai", "title": "Can't Boil This Frog: Robustness of Online-Trained Autoencoder-Based\n  Anomaly Detectors to Adversarial Poisoning Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, a variety of effective neural network-based methods for\nanomaly and cyber attack detection in industrial control systems (ICSs) have\nbeen demonstrated in the literature. Given their successful implementation and\nwidespread use, there is a need to study adversarial attacks on such detection\nmethods to better protect the systems that depend upon them. The extensive\nresearch performed on adversarial attacks on image and malware classification\nhas little relevance to the physical system state prediction domain, which most\nof the ICS attack detection systems belong to. Moreover, such detection systems\nare typically retrained using new data collected from the monitored system,\nthus the threat of adversarial data poisoning is significant, however this\nthreat has not yet been addressed by the research community. In this paper, we\npresent the first study focused on poisoning attacks on online-trained\nautoencoder-based attack detectors. We propose two algorithms for generating\npoison samples, an interpolation-based algorithm and a back-gradient\noptimization-based algorithm, which we evaluate on both synthetic and\nreal-world ICS data. We demonstrate that the proposed algorithms can generate\npoison samples that cause the target attack to go undetected by the autoencoder\ndetector, however the ability to poison the detector is limited to a small set\nof attack types and magnitudes. When the poison-generating algorithms are\napplied to the popular SWaT dataset, we show that the autoencoder detector\ntrained on the physical system state data is resilient to poisoning in the face\nof all ten of the relevant attacks in the dataset. This finding suggests that\nneural network-based attack detectors used in the cyber-physical domain are\nmore robust to poisoning than in other problem domains, such as malware\ndetection and image processing.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 12:41:28 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Kravchik", "Moshe", ""], ["Shabtai", "Asaf", ""]]}, {"id": "2002.02776", "submitter": "Hasan Ferit Eniser", "authors": "Hasan Ferit Eniser, Maria Christakis, Valentin W\\\"ustholz", "title": "RAID: Randomized Adversarial-Input Detection for Neural Networks", "comments": "10 pages of content plus 2 pages of bibliography. Submitted to ISSTA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, neural networks have become the default choice for image\nclassification and many other learning tasks, even though they are vulnerable\nto so-called adversarial attacks. To increase their robustness against these\nattacks, there have emerged numerous detection mechanisms that aim to\nautomatically determine if an input is adversarial. However, state-of-the-art\ndetection mechanisms either rely on being tuned for each type of attack, or\nthey do not generalize across different attack types. To alleviate these\nissues, we propose a novel technique for adversarial-image detection, RAID,\nthat trains a secondary classifier to identify differences in neuron activation\nvalues between benign and adversarial inputs. Our technique is both more\nreliable and more effective than the state of the art when evaluated against\nsix popular attacks. Moreover, a straightforward extension of RAID increases\nits robustness against detection-aware adversaries without affecting its\neffectiveness.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 13:27:29 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Eniser", "Hasan Ferit", ""], ["Christakis", "Maria", ""], ["W\u00fcstholz", "Valentin", ""]]}, {"id": "2002.02780", "submitter": "Joshua Siegel", "authors": "Gregory Falco, Joshua E. Siegel", "title": "A Distributed `Black Box' Audit Trail Design Specification for Connected\n  and Automated Vehicle Data and Software Assurance", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automotive software is increasingly complex and critical to safe vehicle\noperation, and related embedded systems must remain up-to-date to ensure\nlong-term system performance. Update mechanisms and data modification tools\nintroduce opportunities for malicious actors to compromise these cyber-physical\nsystems, and for trusted actors to mistakenly install incompatible software\nversions. A distributed and stratified \"black box\" audit trail for automotive\nsoftware and data provenance is proposed to assure users, service providers,\nand original equipment manufacturers (OEMs) of vehicular software integrity and\nreliability. The proposed black box architecture is both layered and diffuse,\nemploying distributed hash tables (DHT), a parity system and a public\nblockchain to provide high resilience, assurance, scalability, and efficiency\nfor automotive and other high-assurance systems.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 13:38:30 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 12:47:37 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Falco", "Gregory", ""], ["Siegel", "Joshua E.", ""]]}, {"id": "2002.02831", "submitter": "Dongwei Chen", "authors": "Dongwei Chen, Daliang Xu, Dong Tong, Kang Sun, Xuetao Guan, Chun Yang,\n  Xu Cheng", "title": "Saturation Memory Access: Mitigating Memory Spatial Errors without\n  Terminating Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory spatial errors, i.e., buffer overflow vulnerabilities, have been a\nwell-known issue in computer security for a long time and remain one of the\nroot causes of exploitable vulnerabilities. Most of the existing mitigation\ntools adopt a fail-stop strategy to protect programs from intrusions, which\nmeans the victim program will be terminated upon detecting a memory safety\nviolation. Unfortunately, the fail-stop strategy harms the availability of\nsoftware.\n  In this paper, we propose Saturation Memory Access (SMA), a memory spatial\nerror mitigation mechanism that prevents out-of-bounds access without\nterminating a program. SMA is based on a key observation that developers\ngenerally do not rely on out-of-bounds accesses to implement program logic. SMA\nmodifies dynamic memory allocators and adds paddings to objects to form an\nenlarged object boundary. By dynamically correcting all the out-of-bounds\naccesses to operate on the enlarged protecting boundaries, SMA can tolerate\nout-of-bounds accesses. For the sake of compatibility, we chose tagged pointers\nto record the boundary metadata of a memory object in the pointer itself, and\ncorrect the address upon detecting out-of-bounds access.\n  We have implemented the prototype of SMA on LLVM 10.0. Our results show that\nour compiler enables the programs to execute successfully through buffer\noverflow attacks. Experiments on MiBench show that our prototype incurs an\noverhead of 78\\%. Further optimizations would require ISA supports.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 15:07:00 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 07:43:00 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Chen", "Dongwei", ""], ["Xu", "Daliang", ""], ["Tong", "Dong", ""], ["Sun", "Kang", ""], ["Guan", "Xuetao", ""], ["Yang", "Chun", ""], ["Cheng", "Xu", ""]]}, {"id": "2002.02855", "submitter": "Sazzadur Rahaman", "authors": "Sazzadur Rahaman and Gang Wang and Danfeng (Daphne) Yao", "title": "Security Certification in Payment Card Industry: Testbeds, Measurements,\n  and Recommendations", "comments": "In Proceedings of the 2019 ACM Conference on Computer and\n  Communications Security (CCS)", "journal-ref": null, "doi": "10.1145/3319535.3363195", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The massive payment card industry (PCI) involves various entities such as\nmerchants, issuer banks, acquirer banks, and card brands. Ensuring security for\nall entities that process payment card information is a challenging task. The\nPCI Security Standards Council requires all entities to be compliant with the\nPCI Data Security Standard (DSS), which specifies a series of security\nrequirements. However, little is known regarding how well PCI DSS is enforced\nin practice. In this paper, we take a measurement approach to systematically\nevaluate the PCI DSS certification process for e-commerce websites. We develop\nan e-commerce web application testbed, BuggyCart, which can flexibly add or\nremove 35 PCI DSS related vulnerabilities. Then we use the testbed to examine\nthe capability and limitations of PCI scanners and the rigor of the\ncertification process. We find that there is an alarming gap between the\nsecurity standard and its real-world enforcement. None of the 6 PCI scanners we\ntested are fully compliant with the PCI scanning guidelines, issuing\ncertificates to merchants that still have major vulnerabilities. To further\nexamine the compliance status of real-world e-commerce websites, we build a new\nlightweight scanning tool named PciCheckerLite and scan 1,203 e-commerce\nwebsites across various business sectors. The results confirm that 86% of the\nwebsites have at least one PCI DSS violation that should have disqualified them\nas non-compliant. Our in-depth accuracy analysis also shows that\nPciCheckerLite's output is more precise than w3af. We reached out to the PCI\nSecurity Council to share our research results to improve the enforcement in\npractice.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 15:47:50 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Rahaman", "Sazzadur", "", "Daphne"], ["Wang", "Gang", "", "Daphne"], ["Danfeng", "", "", "Daphne"], ["Yao", "", ""]]}, {"id": "2002.02998", "submitter": "Ting-Wu Chin", "authors": "Ting-Wu Chin, Cha Zhang, Diana Marculescu", "title": "Renofeation: A Simple Transfer Learning Method for Improved Adversarial\n  Robustness", "comments": "2021 IEEE CVPR Workshop on Fair, Data Efficient and Trusted Computer\n  Vision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuning through knowledge transfer from a pre-trained model on a\nlarge-scale dataset is a widely spread approach to effectively build models on\nsmall-scale datasets. In this work, we show that a recent adversarial attack\ndesigned for transfer learning via re-training the last linear layer can\nsuccessfully deceive models trained with transfer learning via end-to-end\nfine-tuning. This raises security concerns for many industrial applications. In\ncontrast, models trained with random initialization without transfer are much\nmore robust to such attacks, although these models often exhibit much lower\naccuracy. To this end, we propose noisy feature distillation, a new transfer\nlearning method that trains a network from random initialization while\nachieving clean-data performance competitive with fine-tuning. Code available\nat https://github.com/cmu-enyac/Renofeation.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 20:07:22 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 14:46:56 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Chin", "Ting-Wu", ""], ["Zhang", "Cha", ""], ["Marculescu", "Diana", ""]]}, {"id": "2002.03018", "submitter": "Elan Rosenfeld", "authors": "Elan Rosenfeld, Ezra Winston, Pradeep Ravikumar, J. Zico Kolter", "title": "Certified Robustness to Label-Flipping Attacks via Randomized Smoothing", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms are known to be susceptible to data poisoning\nattacks, where an adversary manipulates the training data to degrade\nperformance of the resulting classifier. In this work, we present a unifying\nview of randomized smoothing over arbitrary functions, and we leverage this\nnovel characterization to propose a new strategy for building classifiers that\nare pointwise-certifiably robust to general data poisoning attacks. As a\nspecific instantiation, we utilize our framework to build linear classifiers\nthat are robust to a strong variant of label flipping, where each test example\nis targeted independently. In other words, for each test point, our classifier\nincludes a certification that its prediction would be the same had some number\nof training labels been changed adversarially. Randomized smoothing has\npreviously been used to guarantee---with high probability---test-time\nrobustness to adversarial manipulation of the input to a classifier; we derive\na variant which provides a deterministic, analytical bound, sidestepping the\nprobabilistic certificates that traditionally result from the sampling\nsubprocedure. Further, we obtain these certified bounds with minimal additional\nruntime complexity over standard classification and no assumptions on the train\nor test distributions. We generalize our results to the multi-class case,\nproviding the first multi-class classification algorithm that is certifiably\nrobust to label-flipping attacks.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 21:28:30 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 01:16:35 GMT"}, {"version": "v3", "created": "Thu, 6 Aug 2020 03:27:14 GMT"}, {"version": "v4", "created": "Tue, 11 Aug 2020 13:17:30 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Rosenfeld", "Elan", ""], ["Winston", "Ezra", ""], ["Ravikumar", "Pradeep", ""], ["Kolter", "J. Zico", ""]]}, {"id": "2002.03057", "submitter": "Lum Ramabaja", "authors": "Lum Ramabaja, Arber Avdullahu", "title": "The Bloom Tree", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a data structure that allows for efficient (probabilistic)\npresence proofs and non-probabilistic absence proofs in a bandwidth efficient\nand secure way. The Bloom tree combines the idea of Bloom filters with that of\nMerkle trees. Bloom filters are used to verify the presence, or absence of\nelements in a set. In the case of the Bloom tree, we are interested to verify\nand transmit the presence, or absence of an element in a secure and bandwidth\nefficient way to another party. Instead of sending the whole Bloom filter to\ncheck for the presence, or absence of an element, the Bloom tree achieves\nefficient verification by using a compact Merkle multiproof.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 00:54:19 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 12:58:19 GMT"}, {"version": "v3", "created": "Wed, 19 Feb 2020 11:50:25 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Ramabaja", "Lum", ""], ["Avdullahu", "Arber", ""]]}, {"id": "2002.03058", "submitter": "Ronak Tanna", "authors": "Ronak Tanna, Shivam Dhar, Ashwin Sudhir, Shreyash Devan, Shubham Verma", "title": "Lessons Learned Developing and Extending a Visual Analytics Solution for\n  Investigative Analysis of Scamming Activities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cybersecurity analysts work on large communication data sets to perform\ninvestigative analysis by painstakingly going over thousands of email\nconversations to find potential scamming activities and the network of cyber\nscammers. Traditionally,experts used email clients, database systems and text\neditors to perform this investigation. With the advent of technology,elaborate\ntools that summarize data more efficiently by using cutting edge data\nvisualization techniques have come out. Beagle[1] is one such tool which\nvisualizes the large communication data using different panels such that the\ninspector has better chances of finding the scam network. This paper is a\nreport on our work to implement and improve the work done by Jay Koven et al.\n[1]. We have proposed and demonstrated via implementation, a few more\nvisualizations that we feel would help in grouping and analyzing the e-mail\ndata more efficiently. Lastly, we have also presented a case study that shows\nthe potential use of our tool in a real-world scenario.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 00:59:41 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Tanna", "Ronak", ""], ["Dhar", "Shivam", ""], ["Sudhir", "Ashwin", ""], ["Devan", "Shreyash", ""], ["Verma", "Shubham", ""]]}, {"id": "2002.03080", "submitter": "Adam Dziedzic", "authors": "Adam Dziedzic, Sanjay Krishnan", "title": "Analysis of Random Perturbations for Robust Convolutional Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has extensively shown that randomized perturbations of neural\nnetworks can improve robustness to adversarial attacks. The literature is,\nhowever, lacking a detailed compare-and-contrast of the latest proposals to\nunderstand what classes of perturbations work, when they work, and why they\nwork. We contribute a detailed evaluation that elucidates these questions and\nbenchmarks perturbation based defenses consistently. In particular, we show\nfive main results: (1) all input perturbation defenses, whether random or\ndeterministic, are equivalent in their efficacy, (2) attacks transfer between\nperturbation defenses so the attackers need not know the specific type of\ndefense -- only that it involves perturbations, (3) a tuned sequence of noise\nlayers across a network provides the best empirical robustness, (4)\nperturbation based defenses offer almost no robustness to adaptive attacks\nunless these perturbations are observed during training, and (5) adversarial\nexamples in a close neighborhood of original inputs show an elevated\nsensitivity to perturbations in first and second-order analyses.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 03:46:07 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 00:22:31 GMT"}, {"version": "v3", "created": "Mon, 6 Apr 2020 19:56:06 GMT"}, {"version": "v4", "created": "Sun, 7 Jun 2020 19:25:31 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Dziedzic", "Adam", ""], ["Krishnan", "Sanjay", ""]]}, {"id": "2002.03095", "submitter": "Lu Chen", "authors": "Lu Chen and Wei Xu", "title": "Attacking Optical Character Recognition (OCR) Systems with Adversarial\n  Watermarks", "comments": "9 pages, this http url http://aics.site/AICS2020/AICS20_paper_18.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical character recognition (OCR) is widely applied in real applications\nserving as a key preprocessing tool. The adoption of deep neural network (DNN)\nin OCR results in the vulnerability against adversarial examples which are\ncrafted to mislead the output of the threat model. Different from vanilla\ncolorful images, images of printed text have clear backgrounds usually.\nHowever, adversarial examples generated by most of the existing adversarial\nattacks are unnatural and pollute the background severely. To address this\nissue, we propose a watermark attack method to produce natural distortion that\nis in the disguise of watermarks and evade human eyes' detection. Experimental\nresults show that watermark attacks can yield a set of natural adversarial\nexamples attached with watermarks and attain similar attack performance to the\nstate-of-the-art methods in different attack scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 05:53:21 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Chen", "Lu", ""], ["Xu", "Wei", ""]]}, {"id": "2002.03144", "submitter": "Andrei Bytes", "authors": "Andrei Bytes and Jay Prakash and Jianying Zhou and Tony Q.S. Quek", "title": "Why is My Secret Leaked? Discovering Vulnerabilities in Device-to-Device\n  File Sharing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of active users of Wi-Fi Direct Device-to-Device file sharing\napplications on Android has exceeded 1.8 billion. Wi-Fi Direct, also known as\nWi-Fi P2P, is commonly used for peer-to-peer, high-speed file transfer between\nmobile devices, as well as a close proximity connection mode for wireless\ncameras, network printers, TVs and other IoT and mobile devices. For its end\nusers, such type of direct file transfer does not incur cellular data charges.\nHowever, despite the popularity of such applications, we observe that the\nsoftware vendors tend to prioritize the ease of user flow over the security in\ntheir implementations, which leads to serious security flaws. We perform a\ncomprehensive security analysis in the context of security and usability and\nreport our findings in the form of 17 Common Vulnerabilities and Exposures\n(CVE) which have been disclosed to the corresponding vendors. To address the\nsimilar flaws at the early stage of the application design, we propose a joint\nconsideration of security and usability for such applications and their\nprotocols that can be visualized in form of a customised User Journey Map\n(UJM).\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 11:21:21 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 15:23:23 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Bytes", "Andrei", ""], ["Prakash", "Jay", ""], ["Zhou", "Jianying", ""], ["Quek", "Tony Q. S.", ""]]}, {"id": "2002.03212", "submitter": "Nicolas Courtois T", "authors": "Nicolas T. Courtois", "title": "Invariant Hopping Attacks on Block Ciphers", "comments": "27 pages, 8 figures, extended version with new more complex examples\n  of attacks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.AC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Block ciphers are in widespread use since the 1970s. Their iterated structure\nis prone to numerous round invariant attacks for example in Linear\nCryptanalysis (LC). The next step is to look at non-linear polynomial\ninvariants cf. Eurocrypt'95. Until recently, researchers have found extremely\nfew such attacks, with some impossibility results. Eventually recent papers\nshow how to construct polynomial invariant attacks for block ciphers, however\nmany such results were of degree 2. In this paper we propose a new incremental\nmethodology for constructing high degree polynomial invariant attacks on block\nciphers. A trivial attack on one cipher setup will be transposed to show the\nexistence of a more advanced attack on a stronger cipher in several steps. The\nkey tool is the manipulation of the roots of the so called Fundamental\nEquation. Examples are constructed with an old historical block cipher T-310.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 18:05:54 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Courtois", "Nicolas T.", ""]]}, {"id": "2002.03261", "submitter": "Sen Wang", "authors": "Sen Wang, J.Morris Chang", "title": "Privacy-Preserving Image Classification in the Local Setting", "comments": "10 pages, 4 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image data has been greatly produced by individuals and commercial vendors in\nthe daily life, and it has been used across various domains, like advertising,\nmedical and traffic analysis. Recently, image data also appears to be greatly\nimportant in social utility, like emergency response. However, the privacy\nconcern becomes the biggest obstacle that prevents further exploration of image\ndata, due to that the image could reveal sensitive information, like the\npersonal identity and locations. The recent developed Local Differential\nPrivacy (LDP) brings us a promising solution, which allows the data owners to\nrandomly perturb their input to provide the plausible deniability of the data\nbefore releasing. In this paper, we consider a two-party image classification\nproblem, in which data owners hold the image and the untrustworthy data user\nwould like to fit a machine learning model with these images as input. To\nprotect the image privacy, we propose to locally perturb the image\nrepresentation before revealing to the data user. Subsequently, we analyze how\nthe perturbation satisfies {\\epsilon}-LDP and affect the data utility regarding\ncount-based and distance-based machine learning algorithm, and propose a\nsupervised image feature extractor, DCAConv, which produces an image\nrepresentation with scalable domain size. Our experiments show that DCAConv\ncould maintain a high data utility while preserving the privacy regarding\nmultiple image benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 01:25:52 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Wang", "Sen", ""], ["Chang", "J. Morris", ""]]}, {"id": "2002.03284", "submitter": "Zhongyuan Jiang", "authors": "Zhongyuan Jiang, Lichao Sun, Philip S. Yu, Hui Li, Jianfeng Ma, Yulong\n  Shen", "title": "Target Privacy Preserving for Social Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we incorporate the realistic scenario of key protection into\nlink privacy preserving and propose the target-link privacy preserving (TPP)\nmodel: target links referred to as targets are the most important and sensitive\nobjectives that would be intentionally attacked by adversaries, in order that\nneed privacy protections, while other links of less privacy concerns are\nproperly released to maintain the graph utility. The goal of TPP is to limit\nthe target disclosure by deleting a budget limited set of alternative\nnon-target links referred to as protectors to defend the adversarial link\npredictions for all targets. Traditional link privacy preserving treated all\nlinks as targets and concentrated on structural level protections in which\nserious link disclosure and high graph utility loss is still the bottleneck of\ngraph releasing today, while TPP focuses on the target level protections in\nwhich key protection is implemented on a tiny fraction of critical targets to\nachieve better privacy protection and lower graph utility loss. Currently there\nis a lack of clear TPP problem definition, provable optimal or near optimal\nprotector selection algorithms and scalable implementations on large-scale\nsocial graphs. Firstly, we introduce the TPP model and propose a dissimilarity\nfunction used for measuring the defense ability against privacy analyzing for\nthe targets. We consider two different problems by budget assignment settings:\n1) we protect all targets and to optimize the dissimilarity of all targets with\na single budget; 2) besides the protections of all targets, we also care about\nthe protection of each target by assigning a local budget to every target,\nconsidering two local protector selections. We also implement scalable\nimplementations and experiments to demonstrate the effectiveness and efficiency\nof the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 05:03:29 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Jiang", "Zhongyuan", ""], ["Sun", "Lichao", ""], ["Yu", "Philip S.", ""], ["Li", "Hui", ""], ["Ma", "Jianfeng", ""], ["Shen", "Yulong", ""]]}, {"id": "2002.03331", "submitter": "Xiruo Wang", "authors": "Xiruo Wang and Risto Miikkulainen", "title": "MDEA: Malware Detection with Evolutionary Adversarial Learning", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware detection have used machine learning to detect malware in programs.\nThese applications take in raw or processed binary data to neural network\nmodels to classify as benign or malicious files. Even though this approach has\nproven effective against dynamic changes, such as encrypting, obfuscating and\npacking techniques, it is vulnerable to specific evasion attacks where that\nsmall changes in the input data cause misclassification at test time. This\npaper proposes a new approach: MDEA, an Adversarial Malware Detection model\nuses evolutionary optimization to create attack samples to make the network\nrobust against evasion attacks. By retraining the model with the evolved\nmalware samples, its performance improves a significant margin.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 09:59:56 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 02:26:30 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Wang", "Xiruo", ""], ["Miikkulainen", "Risto", ""]]}, {"id": "2002.03388", "submitter": "Shushan Arakelyan", "authors": "Shushan Arakelyan, Sima Arasteh, Christophe Hauser, Erik Kline and\n  Aram Galstyan", "title": "Bin2vec: Learning Representations of Binary Executable Programs for\n  Security Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tackling binary program analysis problems has traditionally implied manually\ndefining rules and heuristics, a tedious and time-consuming task for human\nanalysts. In order to improve automation and scalability, we propose an\nalternative direction based on distributed representations of binary programs\nwith applicability to a number of downstream tasks. We introduce Bin2vec, a new\napproach leveraging Graph Convolutional Networks (GCN) along with computational\nprogram graphs in order to learn a high dimensional representation of binary\nexecutable programs. We demonstrate the versatility of this approach by using\nour representations to solve two semantically different binary analysis tasks -\nfunctional algorithm classification and vulnerability discovery. We compare the\nproposed approach to our own strong baseline as well as published results and\ndemonstrate improvement over state-of-the-art methods for both tasks. We\nevaluated Bin2vec on 49191 binaries for the functional algorithm classification\ntask, and on 30 different CWE-IDs including at least 100 CVE entries each for\nthe vulnerability discovery task. We set a new state-of-the-art result by\nreducing the classification error by 40% compared to the source-code-based\ninst2vec approach, while working on binary code. For almost every vulnerability\nclass in our dataset, our prediction accuracy is over 80% (and over 90% in\nmultiple classes).\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 15:46:43 GMT"}, {"version": "v2", "created": "Sat, 22 May 2021 17:27:57 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Arakelyan", "Shushan", ""], ["Arasteh", "Sima", ""], ["Hauser", "Christophe", ""], ["Kline", "Erik", ""], ["Galstyan", "Aram", ""]]}, {"id": "2002.03391", "submitter": "Stephan Kleber", "authors": "Stephan Kleber, Rens Wouter van der Heijden, Frank Kargl", "title": "Message Type Identification of Binary Network Protocols using Continuous\n  Segment Similarity", "comments": "11 pages, 4 figures, to be published in IEEE International Conference\n  on Computer Communications. INFOCOM. Beijing, China, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protocol reverse engineering based on traffic traces infers the behavior of\nunknown network protocols by analyzing observable network messages. To perform\ncorrect deduction of message semantics or behavior analysis, accurate message\ntype identification is an essential first step. However, identifying message\ntypes is particularly difficult for binary protocols, whose structural features\nare hidden in their densely packed data representation. We leverage the\nintrinsic structural features of binary protocols and propose an accurate\nmethod for discriminating message types.\n  Our approach uses a similarity measure with continuous value range by\ncomparing feature vectors where vector elements correspond to the fields in a\nmessage, rather than discrete byte values. This enables a better recognition of\nstructural patterns, which remain hidden when only exact value matches are\nconsidered. We combine Hirschberg alignment with DBSCAN as cluster algorithm to\nyield a novel inference mechanism. By applying novel autoconfiguration schemes,\nwe do not require manually configured parameters for the analysis of an unknown\nprotocol, as required by earlier approaches.\n  Results of our evaluations show that our approach has considerable advantages\nin message type identification result quality and also execution performance\nover previous approaches.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 16:00:05 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Kleber", "Stephan", ""], ["van der Heijden", "Rens Wouter", ""], ["Kargl", "Frank", ""]]}, {"id": "2002.03416", "submitter": "Sajjad Arshad", "authors": "William Blair, Andrea Mambretti, Sajjad Arshad, Michael Weissbacher,\n  William Robertson, Engin Kirda, Manuel Egele", "title": "HotFuzz: Discovering Algorithmic Denial-of-Service Vulnerabilities\n  Through Guided Micro-Fuzzing", "comments": "Network and Distributed Systems Security (NDSS) Symposium, San Diego,\n  CA, USA, February 2020", "journal-ref": null, "doi": "10.14722/ndss.2020.24415", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contemporary fuzz testing techniques focus on identifying memory corruption\nvulnerabilities that allow adversaries to achieve either remote code execution\nor information disclosure. Meanwhile, Algorithmic Complexity\n(AC)vulnerabilities, which are a common attack vector for denial-of-service\nattacks, remain an understudied threat. In this paper, we present HotFuzz, a\nframework for automatically discovering AC vulnerabilities in Java libraries.\nHotFuzz uses micro-fuzzing, a genetic algorithm that evolves arbitrary Java\nobjects in order to trigger the worst-case performance for a method under test.\nWe define Small Recursive Instantiation (SRI) as a technique to derive seed\ninputs represented as Java objects to micro-fuzzing. After micro-fuzzing,\nHotFuzz synthesizes test cases that triggered AC vulnerabilities into Java\nprograms and monitors their execution in order to reproduce vulnerabilities\noutside the fuzzing framework. HotFuzz outputs those programs that exhibit high\nCPU utilization as witnesses for AC vulnerabilities in a Java library. We\nevaluate HotFuzz over the Java Runtime Environment (JRE), the 100 most popular\nJava libraries on Maven, and challenges contained in the DARPA Space and Time\nAnalysis for Cybersecurity (STAC) program. We evaluate SRI's effectiveness by\ncomparing the performance of micro-fuzzing with SRI, measured by the number of\nAC vulnerabilities detected, to simply using empty values as seed inputs. In\nthis evaluation, we verified known AC vulnerabilities, discovered previously\nunknown AC vulnerabilities that we responsibly reported to vendors, and\nreceived confirmation from both IBM and Oracle. Our results demonstrate that\nmicro-fuzzing finds AC vulnerabilities in real-world software, and that\nmicro-fuzzing with SRI-derived seed inputs outperforms using empty values.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 18:24:34 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 20:16:22 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Blair", "William", ""], ["Mambretti", "Andrea", ""], ["Arshad", "Sajjad", ""], ["Weissbacher", "Michael", ""], ["Robertson", "William", ""], ["Kirda", "Engin", ""], ["Egele", "Manuel", ""]]}, {"id": "2002.03421", "submitter": "Jinyuan Jia", "authors": "Jinyuan Jia, Binghui Wang, Xiaoyu Cao, Neil Zhenqiang Gong", "title": "Certified Robustness of Community Detection against Adversarial\n  Structural Perturbation via Randomized Smoothing", "comments": "Accepted by WWW'20; This is technical report version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community detection plays a key role in understanding graph structure.\nHowever, several recent studies showed that community detection is vulnerable\nto adversarial structural perturbation. In particular, via adding or removing a\nsmall number of carefully selected edges in a graph, an attacker can manipulate\nthe detected communities. However, to the best of our knowledge, there are no\nstudies on certifying robustness of community detection against such\nadversarial structural perturbation. In this work, we aim to bridge this gap.\nSpecifically, we develop the first certified robustness guarantee of community\ndetection against adversarial structural perturbation. Given an arbitrary\ncommunity detection method, we build a new smoothed community detection method\nvia randomly perturbing the graph structure. We theoretically show that the\nsmoothed community detection method provably groups a given arbitrary set of\nnodes into the same community (or different communities) when the number of\nedges added/removed by an attacker is bounded. Moreover, we show that our\ncertified robustness is tight. We also empirically evaluate our method on\nmultiple real-world graphs with ground truth communities.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 18:39:39 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 01:58:17 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Jia", "Jinyuan", ""], ["Wang", "Binghui", ""], ["Cao", "Xiaoyu", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "2002.03437", "submitter": "Jonathan Katz", "authors": "Erica Blum, Jonathan Katz, Julian Loss", "title": "Network-Agnostic State Machine Replication", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of state machine replication (SMR)---the underlying\nproblem addressed by blockchain protocols---in the presence of a malicious\nadversary who can corrupt some fraction of the parties running the protocol.\nExisting protocols for this task assume either a synchronous network (where all\nmessages are delivered within some known time $\\Delta$) or an asynchronous\nnetwork (where messages can be delayed arbitrarily). Although protocols for the\nlatter case give seemingly stronger guarantees, this is not the case since they\n(inherently) tolerate a lower fraction of corrupted parties.\n  We design an SMR protocol that is network-agnostic in the following sense: if\nit is run in a synchronous network, it tolerates $t_s$ corrupted parties; if\nthe network happens to be asynchronous it is resilient to $t_a \\leq t_s$\nfaults. Our protocol achieves optimal tradeoffs between $t_s$ and $t_a$.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 19:42:57 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 16:53:05 GMT"}, {"version": "v3", "created": "Fri, 27 Mar 2020 19:18:25 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Blum", "Erica", ""], ["Katz", "Jonathan", ""], ["Loss", "Julian", ""]]}, {"id": "2002.03466", "submitter": "Filipo Sharevski", "authors": "Filipo Sharevski, Paige Treebridge, Peter Jachim, Audrey Li, Adam\n  Babin, Jessica Westbrook", "title": "Meet Malexa, Alexa's Malicious Twin: Malware-Induced Misperception\n  Through Intelligent Voice Assistants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports the findings of a study where users (N=220) interacted\nwith Malexa, Alexa's malicious twin. Malexa is an intelligent voice assistant\nwith a simple and seemingly harmless third-party skill that delivers news\nbriefings to users. The twist, however, is that Malexa covertly rewords these\nbriefings to intentionally introduce misperception about the reported events.\nThis covert rewording is referred to as a Malware-Induced Misperception (MIM)\nattack. It differs from squatting or invocation hijacking attacks in that it is\nfocused on manipulating the \"content\" delivered through a third-party skill\ninstead of the skill's \"invocation logic.\" Malexa, in the study, reworded\nregulatory briefings to make a government response sound more accidental or\nlenient than the original news delivered by Alexa. The results show that users\nwho interacted with Malexa perceived that the government was less friendly to\nworking people and more in favor of big businesses. The results also show that\nMalexa is capable of inducing misperceptions regardless of the user's gender,\npolitical ideology or frequency of interaction with intelligent voice\nassistants. We discuss the implications in the context of using Malexa as a\ncovert \"influencer\" in people's living or working environments.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 22:44:06 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Sharevski", "Filipo", ""], ["Treebridge", "Paige", ""], ["Jachim", "Peter", ""], ["Li", "Audrey", ""], ["Babin", "Adam", ""], ["Westbrook", "Jessica", ""]]}, {"id": "2002.03488", "submitter": "Nazar Waheed", "authors": "Nazar Waheed, Xiangjian He, Muhammad Ikram, Muhammad Usman, Saad Sajid\n  Hashmi, Muhammad Usman", "title": "Security and Privacy in IoT Using Machine Learning and Blockchain:\n  Threats & Countermeasures", "comments": "35 pages, ACM CSUR Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security and privacy of the users have become significant concerns due to the\ninvolvement of the Internet of things (IoT) devices in numerous applications.\nCyber threats are growing at an explosive pace making the existing security and\nprivacy measures inadequate. Hence, everyone on the Internet is a product for\nhackers. Consequently, Machine Learning (ML) algorithms are used to produce\naccurate outputs from large complex databases, where the generated outputs can\nbe used to predict and detect vulnerabilities in IoT-based systems.\nFurthermore, Blockchain (BC) techniques are becoming popular in modern IoT\napplications to solve security and privacy issues. Several studies have been\nconducted on either ML algorithms or BC techniques. However, these studies\ntarget either security or privacy issues using ML algorithms or BC techniques,\nthus posing a need for a combined survey on efforts made in recent years\naddressing both security and privacy issues using ML algorithms and BC\ntechniques. In this paper, we provide a summary of research efforts made in the\npast few years, starting from 2008 to 2019, addressing security and privacy\nissues using ML algorithms and BCtechniques in the IoT domain. First, we\ndiscuss and categorize various security and privacy threats reported in the\npast twelve years in the IoT domain. Then, we classify the literature on\nsecurity and privacy efforts based on ML algorithms and BC techniques in the\nIoT domain. Finally, we identify and illuminate several challenges and future\nresearch directions in using ML algorithms and BC techniques to address\nsecurity and privacy issues in the IoT domain.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 01:11:38 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 06:14:27 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 00:06:40 GMT"}, {"version": "v4", "created": "Thu, 6 Aug 2020 03:53:52 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Waheed", "Nazar", ""], ["He", "Xiangjian", ""], ["Ikram", "Muhammad", ""], ["Usman", "Muhammad", ""], ["Hashmi", "Saad Sajid", ""], ["Usman", "Muhammad", ""]]}, {"id": "2002.03517", "submitter": "Hongyang Zhang", "authors": "Avrim Blum, Travis Dick, Naren Manoj, Hongyang Zhang", "title": "Random Smoothing Might be Unable to Certify $\\ell_\\infty$ Robustness for\n  High-Dimensional Images", "comments": "20 pages, 2 figures; Code is available at\n  https://github.com/hongyanz/TRADES-smoothing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show a hardness result for random smoothing to achieve certified\nadversarial robustness against attacks in the $\\ell_p$ ball of radius\n$\\epsilon$ when $p>2$. Although random smoothing has been well understood for\nthe $\\ell_2$ case using the Gaussian distribution, much remains unknown\nconcerning the existence of a noise distribution that works for the case of\n$p>2$. This has been posed as an open problem by Cohen et al. (2019) and\nincludes many significant paradigms such as the $\\ell_\\infty$ threat model. In\nthis work, we show that any noise distribution $\\mathcal{D}$ over\n$\\mathbb{R}^d$ that provides $\\ell_p$ robustness for all base classifiers with\n$p>2$ must satisfy\n$\\mathbb{E}\\eta_i^2=\\Omega(d^{1-2/p}\\epsilon^2(1-\\delta)/\\delta^2)$ for 99% of\nthe features (pixels) of vector $\\eta\\sim\\mathcal{D}$, where $\\epsilon$ is the\nrobust radius and $\\delta$ is the score gap between the highest-scored class\nand the runner-up. Therefore, for high-dimensional images with pixel values\nbounded in $[0,255]$, the required noise will eventually dominate the useful\ninformation in the images, leading to trivial smoothed classifiers.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 03:26:59 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 02:02:22 GMT"}, {"version": "v3", "created": "Thu, 5 Mar 2020 17:16:41 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Blum", "Avrim", ""], ["Dick", "Travis", ""], ["Manoj", "Naren", ""], ["Zhang", "Hongyang", ""]]}, {"id": "2002.03588", "submitter": "Hao Wang", "authors": "Hao Wang, Desheng Yang, Nian Duan, Yang Guo, Lu Zhang", "title": "Medusa: Blockchain Powered Log Storage System", "comments": null, "journal-ref": null, "doi": "10.1109/ICSESS.2018.8663935", "report-no": null, "categories": "cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain is one of the most heavily invested technologies in recent years.\nDue to its tamper-proof and decentralization properties, blockchain has become\nan ideal utility for data storage that is applicable in many real world\nindustrial scenarios. One important scenario is web log, which is treated as\nsources of technical significance and commercial revenues in major internet\ncompanies. In this paper, we illustrate our design of a web log storage system\nbased on HyperLedger. HyperLedger yields higher throughput and lower latency\ncompared with other blockchain systems. Alongside its efficiency advantages,\nHyperLeger is a permissioned blockchain, which is an ideal fit for enterprise\nsoftware design scenario.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 08:08:22 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Wang", "Hao", ""], ["Yang", "Desheng", ""], ["Duan", "Nian", ""], ["Guo", "Yang", ""], ["Zhang", "Lu", ""]]}, {"id": "2002.03594", "submitter": "Zhuo Ma", "authors": "Zhuo Ma, Haoran Ge, Zhuzhu Wang, Yang Liu, Ximeng Liu", "title": "Droidetec: Android Malware Detection and Malicious Code Localization\n  through Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Android malware detection is a critical step towards building a security\ncredible system. Especially, manual search for the potential malicious code has\nplagued program analysts for a long time. In this paper, we propose Droidetec,\na deep learning based method for android malware detection and malicious code\nlocalization, to model an application program as a natural language sequence.\nDroidetec adopts a novel feature extraction method to derive behavior sequences\nfrom Android applications. Based on that, the bi-directional Long Short Term\nMemory network is utilized for malware detection. Each unit in the extracted\nbehavior sequence is inventively represented as a vector, which allows\nDroidetec to automatically analyze the semantics of sequence segments and\neventually find out the malicious code. Experiments with 9616 malicious and\n11982 benign programs show that Droidetec reaches an accuracy of 97.22% and an\nF1-score of 98.21%. In all, Droidetec has a hit rate of 91% to properly find\nout malicious code segments.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 08:20:19 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Ma", "Zhuo", ""], ["Ge", "Haoran", ""], ["Wang", "Zhuzhu", ""], ["Liu", "Yang", ""], ["Liu", "Ximeng", ""]]}, {"id": "2002.03720", "submitter": "Shengxin Zhu", "authors": "Binrui Shen, Qiang Niu and Shengxin Zhu", "title": "Fabricated Pictures Detection with Graph Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fabricating experimental pictures in research work is a serious academic\nmisconduct, which should better be detected in the reviewing process. However,\ndue to large number of submissions, the detection whether a picture is\nfabricated or reused is laborious for reviewers, and sometimes is indistinct\nwith human eyes. A tool for detecting similarity between images may help to\nalleviate this problem. Some methods based on local feature points matching\nwork for most of the time, while these methods may result in mess of matchings\ndue to ignorance of global relationship between features. We present a\nframework to detect similar, or perhaps fabricated, pictures with the graph\nmatching techniques. A new iterative method is proposed, and experiments show\nthat such a graph matching technique is better than the methods based only on\nlocal features for some cases.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 12:29:16 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Shen", "Binrui", ""], ["Niu", "Qiang", ""], ["Zhu", "Shengxin", ""]]}, {"id": "2002.03810", "submitter": "Carlos Sarraute PhD", "authors": "Ariel Futoransky, Carlos Sarraute, Ariel Waissbein, Matias Travizano,\n  Daniel Fernandez", "title": "WibsonTree: Efficiently Preserving Seller's Privacy in a Decentralized\n  Data Marketplace", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a cryptographic primitive called WibsonTree designed to preserve\nusers' privacy by allowing them to demonstrate predicates on their personal\nattributes, without revealing the values of those attributes. We suppose that\nthere are three types of agents --buyers, sellers and notaries-- who interact\nin a decentralized privacy-preserving data marketplace (dPDM) such as the\nWibson marketplace. We introduce the WibsonTree protocol as an efficient\ncryptographic primitive that enables the exchange of private information while\npreserving the seller's privacy. Using our primitive, a data seller can\nefficiently prove that he/she belongs to the target audience of a buyer's data\nrequest, without revealing any additional information.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 14:39:16 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Futoransky", "Ariel", ""], ["Sarraute", "Carlos", ""], ["Waissbein", "Ariel", ""], ["Travizano", "Matias", ""], ["Fernandez", "Daniel", ""]]}, {"id": "2002.03811", "submitter": "Andrew Hone N.W.", "authors": "Andrew N. W. Hone", "title": "Efficient ECM factorization in parallel with the Lyness map", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.CR nlin.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Lyness map is a birational map in the plane which provides one of the\nsimplest discrete analogues of a Hamiltonian system with one degree of freedom,\nhaving a conserved quantity and an invariant symplectic form. As an example of\na symmetric Quispel-Roberts-Thompson (QRT) map, each generic orbit of the\nLyness map lies on a curve of genus one, and corresponds to a sequence of\npoints on an elliptic curve which is one of the fibres in a pencil of\nbiquadratic curves in the plane. Here we present a version of the elliptic\ncurve method (ECM) for integer factorization, which is based on iteration of\nthe Lyness map with a particular choice of initial data. More precisely, we\ngive an algorithm for scalar multiplication of a point on an elliptic curve,\nwhich is represented by one of the curves in the Lyness pencil. In order to\navoid field inversion, and require only field multiplication (${\\bf M}$),\nsquaring (${\\bf S}$) and addition, projective coordinates in $\\mathbb{P}^1\n\\times \\mathbb{P}^1$ are used. Neglecting multiplication by curve constants\n(assumed small), each addition of the chosen point uses $2{\\bf M}$, while each\ndoubling step requires $15{\\bf M}$. We further show that the doubling step can\nbe implemented efficiently in parallel with four processors, dropping the\neffective cost to $4{\\bf M}$. Our scalar multiplication algorithm should\nrequire, on average, roughly twice as many multiplications per bit as the\nfastest state of the art methods using twisted Edwards curves with small\nconstants, but it can be applied to any elliptic curve over $\\mathbb{Q}$,\nwhereas twisted Edwards curves (equivalent to Montgomery curves) correspond to\nonly a subset of all elliptic curves. Hence, if implemented in parallel, our\nmethod may have potential advantages for integer factorization or elliptic\ncurve cryptography.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 14:14:59 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Hone", "Andrew N. W.", ""]]}, {"id": "2002.03827", "submitter": "Yunhan Huang", "authors": "Yunhan Huang and Quanyan Zhu", "title": "Manipulating Reinforcement Learning: Poisoning Attacks on Cost Signals", "comments": "This chapter is written for the forthcoming book \"Game Theory and\n  Machine Learning for Cyber Security\" (Wiley-IEEE Press), edited by Charles\n  Kamhoua et. al. arXiv admin note: text overlap with arXiv:1906.10571", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter studies emerging cyber-attacks on reinforcement learning (RL)\nand introduces a quantitative approach to analyze the vulnerabilities of RL.\nFocusing on adversarial manipulation on the cost signals, we analyze the\nperformance degradation of TD($\\lambda$) and $Q$-learning algorithms under the\nmanipulation. For TD($\\lambda$), the approximation learned from the manipulated\ncosts has an approximation error bound proportional to the magnitude of the\nattack. The effect of the adversarial attacks on the bound does not depend on\nthe choice of $\\lambda$. In $Q$-learning, we show that $Q$-learning algorithms\nconverge under stealthy attacks and bounded falsifications on cost signals. We\ncharacterize the relation between the falsified cost and the $Q$-factors as\nwell as the policy learned by the learning agent which provides fundamental\nlimits for feasible offensive and defensive moves. We propose a robust region\nin terms of the cost within which the adversary can never achieve the targeted\npolicy. We provide conditions on the falsified cost which can mislead the agent\nto learn an adversary's favored policy. A case study of TD($\\lambda$) learning\nis provided to corroborate the results.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 15:42:02 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 22:55:26 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Huang", "Yunhan", ""], ["Zhu", "Quanyan", ""]]}, {"id": "2002.03872", "submitter": "Maximilian Bachl", "authors": "Maximilian Bachl, Fares Meghdouri, Joachim Fabini, Tanja Zseby", "title": "SparseIDS: Learning Packet Sampling with Reinforcement Learning", "comments": null, "journal-ref": "2020 IEEE Conference on Communications and Network Security (CNS),\n  Avignon, France", "doi": "10.1109/CNS48642.2020.9162253", "report-no": null, "categories": "cs.LG cs.CR cs.NI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recurrent Neural Networks (RNNs) have been shown to be valuable for\nconstructing Intrusion Detection Systems (IDSs) for network data. They allow\ndetermining if a flow is malicious or not already before it is over, making it\npossible to take action immediately. However, considering the large number of\npackets that has to be inspected, for example in cloud/fog and edge computing,\nthe question of computational efficiency arises. We show that by using a novel\nReinforcement Learning (RL)-based approach called SparseIDS, we can reduce the\nnumber of consumed packets by more than three fourths while keeping\nclassification accuracy high. To minimize the computational expenses of the\nRL-based sampling we show that a shared neural network can be used for both the\nclassifier and the RL logic. Thus, no additional resources are consumed by the\nsampling in deployment. Comparing to various other sampling techniques,\nSparseIDS consistently achieves higher classification accuracy by learning to\nsample only relevant packets. A major novelty of our RL-based approach is that\nit can not only skip up to a predefined maximum number of samples like other\napproaches proposed in the domain of Natural Language Processing but can even\nskip arbitrarily many packets in one step. This enables saving even more\ncomputational resources for long sequences. Inspecting SparseIDS's behavior of\nchoosing packets shows that it adopts different sampling strategies for\ndifferent attack types and network flows. Finally we build an automatic\nsteering mechanism that can guide SparseIDS in deployment to achieve a desired\nlevel of sparsity.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 15:38:38 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 12:18:44 GMT"}, {"version": "v3", "created": "Mon, 4 May 2020 15:22:43 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Bachl", "Maximilian", ""], ["Meghdouri", "Fares", ""], ["Fabini", "Joachim", ""], ["Zseby", "Tanja", ""]]}, {"id": "2002.03885", "submitter": "Filipo Sharevski", "authors": "Filipo Sharevski, Paige Treebridge, Peter Jachim, Audrey Li, Adam\n  Babin, Jessica Westbrook", "title": "Beyond Trolling: Malware-Induced Misperception Attacks on Polarized\n  Facebook Discourse", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media trolling is a powerful tactic to manipulate public opinion on\nissues with a high moral component. Troll farms, as evidenced in the past,\ncreated fabricated content to provoke or silence people to share their opinion\non social media during the US presidential election in 2016. In this paper, we\nintroduce an alternate way of provoking or silencing social media discourse by\nmanipulating how users perceive authentic content. This manipulation is\nperformed by man-in-the-middle malware that covertly rearranges the linguistic\ncontent of an authentic social media post and comments. We call this attack\nMalware-Induced Misperception (MIM) because the goal is to socially engineer\nspiral-of-silence conditions on social media by inducing perception. We\nconducted experimental tests in controlled settings (N = 311) where a malware\ncovertly altered selected words in a Facebook post about the freedom of\npolitical expression on college campuses. The empirical results (1) confirm the\nprevious findings about the presence of the spiral-of-silence effect on social\nmedia; and (2) demonstrate that inducing misperception is an effective tactic\nto silence or provoke targeted users on Facebook to express their opinion on a\npolarizing political issue.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 15:55:23 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Sharevski", "Filipo", ""], ["Treebridge", "Paige", ""], ["Jachim", "Peter", ""], ["Li", "Audrey", ""], ["Babin", "Adam", ""], ["Westbrook", "Jessica", ""]]}, {"id": "2002.03914", "submitter": "Guangyuan Hu", "authors": "Guangyuan Hu, Zecheng He, Ruby Lee", "title": "Smartphone Impostor Detection with Built-in Sensors and Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show that sensor-based impostor detection with deep\nlearning can achieve excellent impostor detection accuracy at lower hardware\ncost compared to past work on sensor-based user authentication (the inverse\nproblem) which used more conventional machine learning algorithms. While these\nmethods use other smartphone users' sensor data to build the (user, non-user)\nclassification models, we go further to show that using only the legitimate\nuser's sensor data can still achieve very good accuracy while preserving the\nprivacy of the user's sensor data (behavioral biometrics). For this use case, a\nkey contribution is showing that the detection accuracy of a Recurrent Neural\nNetwork (RNN) deep learning model can be significantly improved by comparing\nprediction error distributions. This requires generating and comparing\nempirical probability distributions, which we show in an efficient hardware\ndesign. Another novel contribution is in the design of SID (Smartphone impostor\nDetection), a minimalist hardware accelerator that can be integrated into\nfuture smartphones for efficient impostor detection for different scenarios.\nOur SID module can implement many common Machine Learning and Deep Learning\nalgorithms. SID is also scalable in parallelism and performance and easy to\nprogram. We show an FPGA prototype of SID, which can provide more than enough\nperformance for real-time impostor detection, with very low hardware complexity\nand power consumption (one to two orders of magnitude less than related\nperformance-oriented FPGA accelerators). We also show that the FPGA\nimplementation of SID consumes 64.41X less energy than an implementation using\nthe CPU with a GPU.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 16:21:47 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Hu", "Guangyuan", ""], ["He", "Zecheng", ""], ["Lee", "Ruby", ""]]}, {"id": "2002.04049", "submitter": "Aaron Roth", "authors": "Daniel Kifer, Solomon Messing, Aaron Roth, Abhradeep Thakurta, and\n  Danfeng Zhang", "title": "Guidelines for Implementing and Auditing Differentially Private Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy is an information theoretic constraint on algorithms and\ncode. It provides quantification of privacy leakage and formal privacy\nguarantees that are currently considered the gold standard in privacy\nprotections. In this paper we provide an initial set of \"best practices\" for\ndeveloping differentially private platforms, techniques for unit testing that\nare specific to differential privacy, guidelines for checking if differential\nprivacy is being applied correctly in an application, and recommendations for\nparameter settings. The genesis of this paper was an initiative by Facebook and\nSocial Science One to provide social science researchers with programmatic\naccess to a URL-shares dataset. In order to maximize the utility of the data\nfor research while protecting privacy, researchers should access the data\nthrough an interactive platform that supports differential privacy.\n  The intention of this paper is to provide guidelines and recommendations that\ncan generally be re-used in a wide variety of systems. For this reason, no\nspecific platforms will be named, except for systems whose details and theory\nappear in academic papers.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 19:04:46 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 18:45:12 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Kifer", "Daniel", ""], ["Messing", "Solomon", ""], ["Roth", "Aaron", ""], ["Thakurta", "Abhradeep", ""], ["Zhang", "Danfeng", ""]]}, {"id": "2002.04059", "submitter": "Tomas Pevny", "authors": "Tomas Pevny and Marek Dedic", "title": "Nested Multiple Instance Learning in Modelling of HTTP network traffic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many interesting cases, the application of machine learning is hindered by\ndata having a complicated structure stimulated by a structured file-formats\nlike JSONs, XMLs, or ProtoBuffers, which is non-trivial to convert to a vector\n/ matrix. Moreover, since the structure frequently carries a semantic meaning,\nreflecting it in the machine learning model should improve the accuracy but\nmore importantly it facilitates the explanation of decisions and the model.\nThis paper demonstrates on the identification of infected computers in the\ncomputer network from their HTTP traffic, how to achieve this reflection using\nrecent progress in multiple-instance learning. The proposed model is compared\nto complementary approaches from the prior art, the first relying on\nhuman-designed features and the second on automatically learned features\nthrough convolution neural networks. In a challenging scenario measuring\naccuracy only on unseen domains/malware families, the proposed model is\nsuperior to the prior art while providing a valuable feedback to the security\nresearchers. We believe that the proposed framework will found applications\nelsewhere even beyond the field of security.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 19:48:14 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Pevny", "Tomas", ""], ["Dedic", "Marek", ""]]}, {"id": "2002.04124", "submitter": "Maede Zolanvari", "authors": "Deval Bhamare, Maede Zolanvari, Aiman Erbad, Raj Jain, Khaled Khan,\n  Nader Meskin", "title": "Cybersecurity for Industrial Control Systems: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industrial Control System (ICS) is a general term that includes supervisory\ncontrol & data acquisition (SCADA) systems, distributed control systems (DCS),\nand other control system configurations such as programmable logic controllers\n(PLC). ICSs are often found in the industrial sectors and critical\ninfrastructures, such as nuclear and thermal plants, water treatment\nfacilities, power generation, heavy industries, and distribution systems.\nThough ICSs were kept isolated from the Internet for so long, significant\nachievable business benefits are driving a convergence between ICSs and the\nInternet as well as information technology (IT) environments, such as cloud\ncomputing. As a result, ICSs have been exposed to the attack vectors used in\nthe majority of cyber-attacks. However, ICS devices are inherently much less\nsecure against such advanced attack scenarios. A compromise to ICS can lead to\nenormous physical damage and danger to human lives. In this work, we have a\nclose look at the shift of the ICS from stand-alone systems to cloud-based\nenvironments. Then we discuss the major works, from industry and academia\ntowards the development of the secure ICSs, especially applicability of the\nmachine learning techniques for the ICS cyber-security. The work may help to\naddress the challenges of securing industrial processes, particularly while\nmigrating them to the cloud environments.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 22:52:14 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Bhamare", "Deval", ""], ["Zolanvari", "Maede", ""], ["Erbad", "Aiman", ""], ["Jain", "Raj", ""], ["Khan", "Khaled", ""], ["Meskin", "Nader", ""]]}, {"id": "2002.04156", "submitter": "Jinhyun So", "authors": "Jinhyun So, Basak Guler, and A. Salman Avestimehr", "title": "Turbo-Aggregate: Breaking the Quadratic Aggregation Barrier in Secure\n  Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a distributed framework for training machine learning\nmodels over the data residing at mobile devices, while protecting the privacy\nof individual users. A major bottleneck in scaling federated learning to a\nlarge number of users is the overhead of secure model aggregation across many\nusers. In particular, the overhead of the state-of-the-art protocols for secure\nmodel aggregation grows quadratically with the number of users. In this paper,\nwe propose the first secure aggregation framework, named Turbo-Aggregate, that\nin a network with $N$ users achieves a secure aggregation overhead of\n$O(N\\log{N})$, as opposed to $O(N^2)$, while tolerating up to a user dropout\nrate of $50\\%$. Turbo-Aggregate employs a multi-group circular strategy for\nefficient model aggregation, and leverages additive secret sharing and novel\ncoding techniques for injecting aggregation redundancy in order to handle user\ndropouts while guaranteeing user privacy. We experimentally demonstrate that\nTurbo-Aggregate achieves a total running time that grows almost linear in the\nnumber of users, and provides up to $40\\times$ speedup over the\nstate-of-the-art protocols with up to $N=200$ users. Our experiments also\ndemonstrate the impact of model size and bandwidth on the performance of\nTurbo-Aggregate.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 01:15:41 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 16:52:26 GMT"}, {"version": "v3", "created": "Sat, 20 Feb 2021 20:20:49 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["So", "Jinhyun", ""], ["Guler", "Basak", ""], ["Avestimehr", "A. Salman", ""]]}, {"id": "2002.04210", "submitter": "Fatemeh Ganji", "authors": "Ulbert J. Botero, Ronald Wilson, Hangwei Lu, Mir Tanjidur Rahman,\n  Mukhil A. Mallaiyan, Fatemeh Ganji, Navid Asadizanjani, Mark M. Tehranipoor,\n  Damon L. Woodard, and Domenic Forte", "title": "Hardware Trust and Assurance through Reverse Engineering: A Survey and\n  Outlook from Image Analysis and Machine Learning Perspectives", "comments": "It is essential not to reduce the size of the figures as high quality\n  ones are required to discuss the image processing algorithms and methods", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In the context of hardware trust and assurance, reverse engineering has been\noften considered as an illegal action. Generally speaking, reverse engineering\naims to retrieve information from a product, i.e., integrated circuits (ICs)\nand printed circuit boards (PCBs) in hardware security-related scenarios, in\nthe hope of understanding the functionality of the device and determining its\nconstituent components. Hence, it can raise serious issues concerning\nIntellectual Property (IP) infringement, the (in)effectiveness of\nsecurity-related measures, and even new opportunities for injecting hardware\nTrojans. Ironically, reverse engineering can enable IP owners to verify and\nvalidate the design. Nevertheless, this cannot be achieved without overcoming\nnumerous obstacles that limit successful outcomes of the reverse engineering\nprocess. This paper surveys these challenges from two complementary\nperspectives: image processing and machine learning. These two fields of study\nform a firm basis for the enhancement of efficiency and accuracy of reverse\nengineering processes for both PCBs and ICs. In summary, therefore, this paper\npresents a roadmap indicating clearly the actions to be taken to fulfill\nhardware trust and assurance objectives.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 05:23:16 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 23:00:31 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Botero", "Ulbert J.", ""], ["Wilson", "Ronald", ""], ["Lu", "Hangwei", ""], ["Rahman", "Mir Tanjidur", ""], ["Mallaiyan", "Mukhil A.", ""], ["Ganji", "Fatemeh", ""], ["Asadizanjani", "Navid", ""], ["Tehranipoor", "Mark M.", ""], ["Woodard", "Damon L.", ""], ["Forte", "Domenic", ""]]}, {"id": "2002.04344", "submitter": "Cheng Hong", "authors": "Cheng Hong, Zhicong Huang, Wen-jie Lu, Hunter Qu, Li Ma, Morten Dahl,\n  Jason Mancuso", "title": "Privacy-preserving collaborative machine learning on genomic data using\n  TensorFlow", "comments": "Description of the winning solution at Track IV of iDASH competition\n  2019, to be presented at the Trustworthy ML workshop co-located with ICLR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) methods have been widely used in genomic studies.\nHowever, genomic data are often held by different stakeholders (e.g. hospitals,\nuniversities, and healthcare companies) who consider the data as sensitive\ninformation, even though they desire to collaborate. To address this issue,\nrecent works have proposed solutions using Secure Multi-party Computation\n(MPC), which train on the decentralized data in a way that the participants\ncould learn nothing from each other beyond the final trained model.\n  We design and implement several MPC-friendly ML primitives, including class\nweight adjustment and parallelizable approximation of activation function. In\naddition, we develop the solution as an extension to TF\nEncrypted~\\citep{dahl2018private}, enabling us to quickly experiment with\nenhancements of both machine learning techniques and cryptographic protocols\nwhile leveraging the advantages of TensorFlow's optimizations. Our\nimplementation compares favorably with state-of-the-art methods, winning first\nplace in Track IV of the iDASH2019 secure genome analysis competition.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 12:21:01 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 10:59:39 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Hong", "Cheng", ""], ["Huang", "Zhicong", ""], ["Lu", "Wen-jie", ""], ["Qu", "Hunter", ""], ["Ma", "Li", ""], ["Dahl", "Morten", ""], ["Mancuso", "Jason", ""]]}, {"id": "2002.04427", "submitter": "Ehsan Meamari", "authors": "Ehsan Meamari and Hao Guo and Chien-Chung Shen and Rui Zhang", "title": "Data User-Based Attribute-Based Encryption", "comments": "5 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribute-Based Encryption (ABE) has emerged as an information-centric\npublic-key cryptographic system which allows a data owner to share data,\naccording to access policy, with multiple data users based on the attributes\nthey possess, without knowing their identities. In the original ABE schemes, a\ncentral authority administrates the system and issues secret keys to data users\nbased on their attributes and both the owner and users need to trust a specific\nCA. However, in certain real-world applications, the data users would not trust\nanyone but themselves. For such situations, we introduce a new decentralization\nmodel of ABE, termed Data User-based ABE (DU-ABE), which is managed jointly by\nthe data users. DU-ABE is the first decentralized ABE scheme that replaces the\nauthorities with the data users without employing any other extra entities.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 03:46:32 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Meamari", "Ehsan", ""], ["Guo", "Hao", ""], ["Shen", "Chien-Chung", ""], ["Zhang", "Rui", ""]]}, {"id": "2002.04533", "submitter": "Haoqian Zhang", "authors": "Haoqian Zhang, Yancheng Zhao, Abhishek Paryani, Ke Yi", "title": "Infnote: A Decentralized Information Sharing Platform Based on\n  Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet censorship has been implemented in several countries to prevent\ncitizens from accessing information and to suppress discussion of specific\ntopics. This paper presents Infnote, a platform that helps eliminate the\nproblem of sharing content in these censorship regimes. Infnote is a\ndecentralized information sharing system based on blockchain and peer-to-peer\nnetwork, aiming to provide an easy-to-use medium for users to share their\nthoughts, insights and views freely without worrying about data tampering and\ndata loss. Infnote provides a solution that is able to work on any level of\nInternet censorship. Infnote uses multi-chains architecture to support various\nindependent applications or different functions in an application.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 16:35:40 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Zhang", "Haoqian", ""], ["Zhao", "Yancheng", ""], ["Paryani", "Abhishek", ""], ["Yi", "Ke", ""]]}, {"id": "2002.04540", "submitter": "Leonid Glanz", "authors": "Leonid Glanz, Patrick M\\\"uller, Lars Baumg\\\"artner, Michael Reif, Sven\n  Amann, Pauline Anthonysamy, Mira Mezini", "title": "Hidden in Plain Sight: Obfuscated Strings Threatening Your Privacy", "comments": "to appear in ASIA CCS 20, Taipei, Taiwan", "journal-ref": null, "doi": "10.1145/3320269.3384745", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  String obfuscation is an established technique used by proprietary,\nclosed-source applications to protect intellectual property. Furthermore, it is\nalso frequently used to hide spyware or malware in applications. In both cases,\nthe techniques range from bit-manipulation over XOR operations to AES\nencryption. However, string obfuscation techniques/tools suffer from one shared\nweakness: They generally have to embed the necessary logic to deobfuscate\nstrings into the app code.\n  In this paper, we show that most of the string obfuscation techniques found\nin malicious and benign applications for Android can easily be broken in an\nautomated fashion. We developed StringHound, an open-source tool that uses\nnovel techniques that identify obfuscated strings and reconstruct the originals\nusing slicing.\n  We evaluated StringHound on both benign and malicious Android apps. In\nsummary, we deobfuscate almost 30 times more obfuscated strings than other\nstring deobfuscation tools. Additionally, we analyzed 100,000 Google Play Store\napps and found multiple obfuscated strings that hide vulnerable cryptographic\nusages, insecure internet accesses, API keys, hard-coded passwords, and\nexploitation of privileges without the awareness of the developer. Furthermore,\nour analysis reveals that not only malware uses string obfuscation but also\nbenign apps make extensive use of string obfuscation.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 16:47:03 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 13:48:28 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Glanz", "Leonid", ""], ["M\u00fcller", "Patrick", ""], ["Baumg\u00e4rtner", "Lars", ""], ["Reif", "Michael", ""], ["Amann", "Sven", ""], ["Anthonysamy", "Pauline", ""], ["Mezini", "Mira", ""]]}, {"id": "2002.04547", "submitter": "Steffen Haas", "authors": "Steffen Haas, Robin Sommer, Mathias Fischer", "title": "zeek-osquery: Host-Network Correlation for Advanced Monitoring and\n  Intrusion Detection", "comments": "Accepted for publication at ICT Systems Security and Privacy\n  Protection (IFIP) SEC 2020", "journal-ref": null, "doi": "10.1007/978-3-030-58201-2_17", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrusion Detection Systems (IDSs) can analyze network traffic for signs of\nattacks and intrusions. However, encrypted communication limits their\nvisibility and sophisticated attackers additionally try to evade their\ndetection. To overcome these limitations, we extend the scope of Network IDSs\n(NIDSs) with additional data from the hosts. For that, we propose the\nintegrated open-source zeek-osquery platform that combines the Zeek IDS with\nthe osquery host monitor. Our platform can collect, process, and correlate host\nand network data at large scale, e.g., to attribute network flows to processes\nand users. The platform can be flexibly extended with own detection scripts\nusing already correlated, but also additional and dynamically retrieved host\ndata. A distributed deployment enables it to scale with an arbitrary number of\nosquery hosts. Our evaluation results indicate that a single Zeek instance can\nmanage more than 870 osquery hosts and can attribute more than 96% of TCP\nconnections to host-side applications and users in real-time.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 17:06:36 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 14:15:05 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Haas", "Steffen", ""], ["Sommer", "Robin", ""], ["Fischer", "Mathias", ""]]}, {"id": "2002.04599", "submitter": "Florian Tram\\`er", "authors": "Florian Tram\\`er and Jens Behrmann and Nicholas Carlini and Nicolas\n  Papernot and J\\\"orn-Henrik Jacobsen", "title": "Fundamental Tradeoffs between Invariance and Sensitivity to Adversarial\n  Perturbations", "comments": "ICML 2020 (Supersedes the workshop paper \"Exploiting Excessive\n  Invariance caused by Norm-Bounded Adversarial Robustness\", arXiv:1903.10484)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are malicious inputs crafted to induce\nmisclassification. Commonly studied sensitivity-based adversarial examples\nintroduce semantically-small changes to an input that result in a different\nmodel prediction. This paper studies a complementary failure mode,\ninvariance-based adversarial examples, that introduce minimal semantic changes\nthat modify an input's true label yet preserve the model's prediction. We\ndemonstrate fundamental tradeoffs between these two types of adversarial\nexamples.\n  We show that defenses against sensitivity-based attacks actively harm a\nmodel's accuracy on invariance-based attacks, and that new approaches are\nneeded to resist both attack types. In particular, we break state-of-the-art\nadversarially-trained and certifiably-robust models by generating small\nperturbations that the models are (provably) robust to, yet that change an\ninput's class according to human labelers. Finally, we formally show that the\nexistence of excessively invariant classifiers arises from the presence of\noverly-robust predictive features in standard datasets.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 18:50:23 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 16:53:43 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Tram\u00e8r", "Florian", ""], ["Behrmann", "Jens", ""], ["Carlini", "Nicholas", ""], ["Papernot", "Nicolas", ""], ["Jacobsen", "J\u00f6rn-Henrik", ""]]}, {"id": "2002.04609", "submitter": "Kee Jefferys", "authors": "Kee Jefferys, Maxim Shishmarev, Simon Harman", "title": "Session: A Model for End-To-End Encrypted Conversations With Minimal\n  Metadata Leakage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Session is an open-source, public-key-based secure messaging application\nwhich uses a set of decentralised storage servers and an onion routing protocol\nto send end-to-end encrypted messages with minimal exposure of user metadata.\nIt does this while also providing common features of mainstream messaging\napplications.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 06:53:29 GMT"}, {"version": "v2", "created": "Sun, 29 Mar 2020 23:49:51 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Jefferys", "Kee", ""], ["Shishmarev", "Maxim", ""], ["Harman", "Simon", ""]]}, {"id": "2002.04631", "submitter": "Pardis Emami-Naeini", "authors": "Pardis Emami-Naeini, Yuvraj Agarwal, Lorrie Faith Cranor, Hanan Hibshi", "title": "Ask the Experts: What Should Be on an IoT Privacy and Security Label?", "comments": "To appear at the 41st IEEE Symposium on Security and Privacy (S&P'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information about the privacy and security of Internet of Things (IoT)\ndevices is not readily available to consumers who want to consider it before\nmaking purchase decisions. While legislators have proposed adding succinct,\nconsumer accessible, labels, they do not provide guidance on the content of\nthese labels. In this paper, we report on the results of a series of interviews\nand surveys with privacy and security experts, as well as consumers, where we\nexplore and test the design space of the content to include on an IoT privacy\nand security label. We conduct an expert elicitation study by following a\nthree-round Delphi process with 22 privacy and security experts to identify the\nfactors that experts believed are important for consumers when comparing the\nprivacy and security of IoT devices to inform their purchase decisions. Based\non how critical experts believed each factor is in conveying risk to consumers,\nwe distributed these factors across two layers---a primary layer to display on\nthe product package itself or prominently on a website, and a secondary layer\navailable online through a web link or a QR code. We report on the experts'\nrationale and arguments used to support their choice of factors. Moreover, to\nstudy how consumers would perceive the privacy and security information\nspecified by experts, we conducted a series of semi-structured interviews with\n15 participants, who had purchased at least one IoT device (smart home device\nor wearable). Based on the results of our expert elicitation and consumer\nstudies, we propose a prototype privacy and security label to help consumers\nmake more informed IoT-related purchase decisions.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 19:01:14 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Emami-Naeini", "Pardis", ""], ["Agarwal", "Yuvraj", ""], ["Cranor", "Lorrie Faith", ""], ["Hibshi", "Hanan", ""]]}, {"id": "2002.04784", "submitter": "Jie Chen", "authors": "Xiao Zang, Yi Xie, Jie Chen, Bo Yuan", "title": "Graph Universal Adversarial Attacks: A Few Bad Actors Ruin Graph\n  Learning Models", "comments": "IJCAI 2021. Code is available at\n  https://github.com/chisam0217/Graph-Universal-Attack", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks, while generalize well, are known to be sensitive to\nsmall adversarial perturbations. This phenomenon poses severe security threat\nand calls for in-depth investigation of the robustness of deep learning models.\nWith the emergence of neural networks for graph structured data, similar\ninvestigations are urged to understand their robustness. It has been found that\nadversarially perturbing the graph structure and/or node features may result in\na significant degradation of the model performance. In this work, we show from\na different angle that such fragility similarly occurs if the graph contains a\nfew bad-actor nodes, which compromise a trained graph neural network through\nflipping the connections to any targeted victim. Worse, the bad actors found\nfor one graph model severely compromise other models as well. We call the bad\nactors ``anchor nodes'' and propose an algorithm, named GUA, to identify them.\nThorough empirical investigations suggest an interesting finding that the\nanchor nodes often belong to the same class; and they also corroborate the\nintuitive trade-off between the number of anchor nodes and the attack success\nrate. For the dataset Cora which contains 2708 nodes, as few as six anchor\nnodes will result in an attack success rate higher than 80\\% for GCN and other\nthree models.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 03:52:11 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 03:41:22 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Zang", "Xiao", ""], ["Xie", "Yi", ""], ["Chen", "Jie", ""], ["Yuan", "Bo", ""]]}, {"id": "2002.04863", "submitter": "Christoph Sorge", "authors": "Santi Mart\\'inez and Francesc Seb\\'e and Christoph Sorge", "title": "Measuring privacy in smart metering anonymized data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, many proposals have arisen from research on privacy in smart\nmetering. In one of the considered approaches, referred to as anonymization,\nsmart meters transmit fine-grained electricity consumption values in such a way\nthat the energy supplier can not exactly determine procedence. This paper\nmeasures the real privacy provided by such approach by taking into account that\nat the end of a billing period the energy supplier collects the overall\nelectricity consumption of each meter for billing purposes. An entropy-based\nmeasure is proposed for quantifying privacy and determine the extent to which\nknowledge on the overall consumption of meters allows to re-identify anonymous\nfine-grained consumption values.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 09:24:11 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Mart\u00ednez", "Santi", ""], ["Seb\u00e9", "Francesc", ""], ["Sorge", "Christoph", ""]]}, {"id": "2002.04887", "submitter": "Nedra Benletaief", "authors": "Nedra Benletaief and Houria Rezig and Ammar Bouallegue", "title": "Toward Efficient Quantum Key Distribution Reconciliation", "comments": "12 pages, 9 figures, journal", "journal-ref": "Journal of Quantum Information Science, 2014, 4, 117-128", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose how to construct a reconciliation method for the\nBB84 Quantum Key Distribution (QKD) protocol. Theoretically, it is\nunconditionally secure because it is based on the quantum laws of physics,\nrather than the assumed computational complexity of mathematical problems. BB84\nprotocol performances can be reduced by various errors and information leakages\nsuch as limited intrinsic efficiency of the protocol, imperfect devices and\neavesdropping. The proposed reconciliation method allowed to weed out these\nerrors by using Turbo codes. Since their high error correction capability\nimplies getting low errors, this method has high performance especially when\ncompared to the last method presented in the literature based on Low- Density\nParity Check codes (LDPC). In particular, we demonstrate that our method leads\nto a significant improvement of the protocol security and of the Bit Error Rate\n(BER) even with great eavesdropping capability.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 09:59:46 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Benletaief", "Nedra", ""], ["Rezig", "Houria", ""], ["Bouallegue", "Ammar", ""]]}, {"id": "2002.04902", "submitter": "Roberto Doriguzzi Corin", "authors": "Roberto Doriguzzi-Corin, Stuart Millar, Sandra Scott-Hayward, Jesus\n  Martinez-del-Rincon, Domenico Siracusa", "title": "LUCID: A Practical, Lightweight Deep Learning Solution for DDoS Attack\n  Detection", "comments": "Accepted for publication in the IEEE Transactions on Network and\n  Service Management", "journal-ref": null, "doi": "10.1109/TNSM.2020.2971776", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Denial of Service (DDoS) attacks are one of the most harmful\nthreats in today's Internet, disrupting the availability of essential services.\nThe challenge of DDoS detection is the combination of attack approaches coupled\nwith the volume of live traffic to be analysed. In this paper, we present a\npractical, lightweight deep learning DDoS detection system called LUCID, which\nexploits the properties of Convolutional Neural Networks (CNNs) to classify\ntraffic flows as either malicious or benign. We make four main contributions;\n(1) an innovative application of a CNN to detect DDoS traffic with low\nprocessing overhead, (2) a dataset-agnostic preprocessing mechanism to produce\ntraffic observations for online attack detection, (3) an activation analysis to\nexplain LUCID's DDoS classification, and (4) an empirical validation of the\nsolution on a resource-constrained hardware platform. Using the latest\ndatasets, LUCID matches existing state-of-the-art detection accuracy whilst\npresenting a 40x reduction in processing time, as compared to the\nstate-of-the-art. With our evaluation results, we prove that the proposed\napproach is suitable for effective DDoS detection in resource-constrained\noperational environments.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 10:34:18 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 08:15:19 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Doriguzzi-Corin", "Roberto", ""], ["Millar", "Stuart", ""], ["Scott-Hayward", "Sandra", ""], ["Martinez-del-Rincon", "Jesus", ""], ["Siracusa", "Domenico", ""]]}, {"id": "2002.05051", "submitter": "Simone Raponi", "authors": "Simone Raponi, Savio Sciancalepore, Gabriele Oligeri, Roberto Di\n  Pietro", "title": "Road Traffic Poisoning of Navigation Apps: Threats and Countermeasures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assisted-navigation applications have a relevant impact on our daily life.\nHowever, technological progress in virtualization technologies and\nSoftware-Defined Radios recently enabled new attack vectors, namely, road\ntraffic poisoning. These attacks open up several dreadful scenarios, which are\naddressed in this contribution by identifying the associated challenges and\nproposing innovative countermeasures.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 15:37:58 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 13:49:41 GMT"}, {"version": "v3", "created": "Wed, 5 May 2021 16:33:52 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Raponi", "Simone", ""], ["Sciancalepore", "Savio", ""], ["Oligeri", "Gabriele", ""], ["Di Pietro", "Roberto", ""]]}, {"id": "2002.05071", "submitter": "Subhra Mazumdar", "authors": "Subhra Mazumdar and Sushmita Ruj and Ram Govind Singh and Arindam Pal", "title": "HushRelay: A Privacy-Preserving, Efficient, and Scalable Routing\n  Algorithm for Off-Chain Payments", "comments": "9 pages, 16 figures, 1 table, accepted to the Short Paper track of\n  the 2020 IEEE International Conference on Blockchain and Cryptocurrency (ICBC\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Payment channel networks (PCN) are used in cryptocurrencies to enhance the\nperformance and scalability of off-chain transactions. Except for opening and\nclosing of a payment channel, no other transaction requests accepted by a PCN\nare recorded in the Blockchain. Only the parties which have opened the channel\nwill know the exact amount of fund left at a given instant. In real scenarios,\nthere might not exist a single path which can enable transfer of high value\npayments. For such cases, splitting up the transaction value across multiple\npaths is a better approach. While there exists several approaches which route\ntransactions via several paths, such techniques are quite inefficient, as the\ndecision on the number of splits must be taken at the initial phase of the\nrouting algorithm (e.g., SpeedyMurmur [42]). Algorithms which do not consider\nthe residual capacity of each channel in the network are susceptible to\nfailure. Other approaches leak sensitive information, and are quite\ncomputationally expensive [28]. To the best of our knowledge, our proposed\nscheme HushRelay is an efficient privacy preserving routing algorithm, taking\ninto account the funds left in each channel, while splitting the transaction\nvalue across several paths. Comparing the performance of our algorithm with\nexisting routing schemes on real instances (e.g., Ripple Network), we observed\nthat HushRelay attains a success ratio of 1, with an execution time of 2.4 sec.\nHowever, SpeedyMurmur [42] attains a success ratio of 0.98 and takes 4.74 sec\nwhen the number of landmarks is 6. On testing our proposed routing algorithm on\nthe Lightning Network, a success ratio of 0.99 is observed, having an execution\ntime of 0.15 sec, which is 12 times smaller than the time taken by\nSpeedyMurmur.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 16:21:36 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Mazumdar", "Subhra", ""], ["Ruj", "Sushmita", ""], ["Singh", "Ram Govind", ""], ["Pal", "Arindam", ""]]}, {"id": "2002.05091", "submitter": "James Pavur", "authors": "James Pavur, Martin Strohmeier, Vincent Lenders, Ivan Martinovic", "title": "QPEP: A QUIC-Based Approach to Encrypted Performance Enhancing Proxies\n  for High-Latency Satellite Broadband", "comments": "A reference implementation of QPEP and a dockerized version of the\n  testbed and scripts used for its evaluation can be found at\n  https://www.github.com/pavja2/qpep", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI cs.PF", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Satellite broadband services are critical infrastructures enabling advanced\ntechnologies to function in the most remote regions of the globe. However,\nstatus-quo services are often unencrypted by default and vulnerable to\neavesdropping attacks. In this paper, we challenge the historical perception\nthat over-the-air security must trade off with TCP performance in high-latency\nsatellite networks due to the deep-packet inspection requirements of\nPerformance Enhancing Proxies (PEPs).\n  After considering why prior work in this area has failed to find wide\nadoption, we present an open-source encrypted-by-default PEP - QPEP - which\nseeks to address these issues. QPEP is built around the open QUIC standard and\ndesigned so individual customers may adopt it without ISP involvement. QPEP's\nperformance is assessed through simulations in a replicable docker-based\ntestbed. Across many benchmarks and network conditions, QPEP is found to avoid\nthe perceived security-encryption trade-off in PEP design. Compared to\nunencrypted PEP implementations, QPEP reduces average page load times by more\nthan 30% while also offering over-the-air privacy. Compared to the traditional\nVPN encryption available to customers today, QPEP more than halves average page\nload times. Together, these experiments lead to the conclusion that QPEP\nrepresents a promising new approach to protecting modern satellite broadband\nconnections.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 16:54:00 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Pavur", "James", ""], ["Strohmeier", "Martin", ""], ["Lenders", "Vincent", ""], ["Martinovic", "Ivan", ""]]}, {"id": "2002.05093", "submitter": "Waqas Aman", "authors": "Waqas Aman, Zeeshan Haider, S. Waqas H. Shah, M. Mahboob Ur Rahman,\n  Octavia A. Dobre", "title": "On the Effective Capacity of an Underwater Acoustic Channel under\n  Impersonation Attack", "comments": "This paper is accepted for presentation at IEEE International\n  Conference on Communications (ICC) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the impact of authentication on effective capacity\n(EC) of an underwater acoustic (UWA) channel. Specifically, the UWA channel is\nunder impersonation attack by a malicious node (Eve) present in the close\nvicinity of the legitimate node pair (Alice and Bob); Eve tries to inject its\nmalicious data into the system by making Bob believe that she is indeed Alice.\nTo thwart the impersonation attack by Eve, Bob utilizes the distance of the\ntransmit node as the feature/fingerprint to carry out feature-based\nauthentication at the physical layer. Due to authentication at Bob, due to lack\nof channel knowledge at the transmit node (Alice or Eve), and due to the\nthreshold-based decoding error model, the relevant dynamics of the considered\nsystem could be modelled by a Markov chain (MC). Thus, we compute the\nstate-transition probabilities of the MC, and the moment generating function\nfor the service process corresponding to each state. This enables us to derive\na closed-form expression of the EC in terms of authentication parameters.\nFurthermore, we compute the optimal transmission rate (at Alice) through\ngradient-descent (GD) technique and artificial neural network (ANN) method.\nSimulation results show that the EC decreases under severe authentication\nconstraints (i.e., more false alarms and more transmissions by Eve). Simulation\nresults also reveal that the (optimal transmission rate) performance of the ANN\ntechnique is quite close to that of the GD method.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 16:57:17 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Aman", "Waqas", ""], ["Haider", "Zeeshan", ""], ["Shah", "S. Waqas H.", ""], ["Rahman", "M. Mahboob Ur", ""], ["Dobre", "Octavia A.", ""]]}, {"id": "2002.05097", "submitter": "Benny Fuhry", "authors": "Benny Fuhry (1), Jayanth Jain H A (1), Florian Kerschbaum (2) ((1) SAP\n  Security Research, (2) University of Waterloo)", "title": "EncDBDB: Searchable Encrypted, Fast, Compressed, In-Memory Database\n  using Enclaves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data confidentiality is an important requirement for clients when outsourcing\ndatabases to the cloud. Trusted execution environments, such as Intel SGX,\noffer an efficient, hardware-based solution to this cryptographic problem.\nExisting solutions are not optimized for column-oriented, in-memory databases\nand pose impractical memory requirements on the enclave. We present EncDBDB, a\nnovel approach for client-controlled encryption of a column-oriented, in-memory\ndatabases allowing range searches using an enclave. EncDBDB offers nine\nencrypted dictionaries, which provide different security, performance and\nstorage efficiency tradeoffs for the data. It is especially suited for complex,\nread-oriented, analytic queries, e.g., as present in data warehouses. The\ncomputational overhead compared to plaintext processing is within a millisecond\neven for databases with millions of entries and the leakage is limited.\nCompressed encrypted data requires less space than a corresponding plaintext\ncolumn. Furthermore, the resulting code - and data - in the enclave is very\nsmall reducing the potential for security-relevant implementation errors and\nside-channel leakages.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 17:06:19 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Fuhry", "Benny", ""], ["A", "Jayanth Jain H", ""], ["Kerschbaum", "Florian", ""]]}, {"id": "2002.05123", "submitter": "Roi Pony", "authors": "Roi Pony, Itay Naeh, Shie Mannor", "title": "Over-the-Air Adversarial Flickering Attacks against Video Recognition\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks for video classification, just like image classification\nnetworks, may be subjected to adversarial manipulation. The main difference\nbetween image classifiers and video classifiers is that the latter usually use\ntemporal information contained within the video. In this work we present a\nmanipulation scheme for fooling video classifiers by introducing a flickering\ntemporal perturbation that in some cases may be unnoticeable by human observers\nand is implementable in the real world. After demonstrating the manipulation of\naction classification of single videos, we generalize the procedure to make\nuniversal adversarial perturbation, achieving high fooling ratio. In addition,\nwe generalize the universal perturbation and produce a temporal-invariant\nperturbation, which can be applied to the video without synchronizing the\nperturbation to the input. The attack was implemented on several target models\nand the transferability of the attack was demonstrated. These properties allow\nus to bridge the gap between simulated environment and real-world application,\nas will be demonstrated in this paper for the first time for an over-the-air\nflickering attack.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 17:58:12 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 10:17:19 GMT"}, {"version": "v3", "created": "Fri, 27 Nov 2020 14:39:25 GMT"}, {"version": "v4", "created": "Fri, 4 Jun 2021 22:11:54 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Pony", "Roi", ""], ["Naeh", "Itay", ""], ["Mannor", "Shie", ""]]}, {"id": "2002.05126", "submitter": "William Buchanan Prof", "authors": "Ian Lowe, William J Buchanan, Richard J Macfarlane, Owen Lo", "title": "Wi-Fi Channel Saturation as a Mechanism to Improve Passive Capture of\n  Bluetooth Through Channel Usage Restriction", "comments": null, "journal-ref": "Journal of Network Technology, 2019", "doi": "10.6025/jnt/2019/10/4/124-155", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bluetooth is a short-range wireless technology that provides audio and data\nlinks between personal smartphones and playback devices, such as speakers,\nheadsets and car entertainment systems. Since its introduction in 2001,\nsecurity researchers have suggested that the protocol is weak, and prone to a\nvariety of attacks against its authentication, link management and encryption\nschemes. Key researchers in the field have suggested that reliable passive\nsniffing of Bluetooth traffic would enable the practical application of a range\nof currently hypothesised attacks. Restricting Bluetooth's frequency hopping\nbehaviour by manipulation of the available channels, in order to make brute\nforce attacks more effective has been a frequently proposed avenue of future\nresearch from the literature. This paper has evaluated the proposed approach in\na series of experiments using the software defined radio tools and custom\nhardware developed by the Ubertooth project. The work concludes that the\nmechanism suggested by previous researchers may not deliver the proposed\nimprovements, but describes an as yet undocumented interaction between\nBluetooth and Wi-Fi technologies which may provide a Denial of Service attack\nmechanism.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 18:10:36 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Lowe", "Ian", ""], ["Buchanan", "William J", ""], ["Macfarlane", "Richard J", ""], ["Lo", "Owen", ""]]}, {"id": "2002.05146", "submitter": "Zhentian Qian", "authors": "Zhentian Qian, Jie Fu, Quanyan Zhu", "title": "A Receding-Horizon MDP Approach for Performance Evaluation of Moving\n  Target Defense in Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of assessing the effectiveness of a\nproactive defense-by-detection policy with a network-based moving target\ndefense. We model the network system using a probabilistic attack graph--a\ngraphical security model. Given a network system with a proactive defense\nstrategy, an intelligent attacker needs to perform reconnaissance repeatedly to\nlearn about the locations of intrusion detection systems and re-plan optimally\nto reach the target while avoiding detection. To compute the attacker's\nstrategy for security evaluation, we develop a receding-horizon planning\nalgorithm using a risk-sensitive Markov decision process with a time-varying\nreward function. Finally, we implement both defense and attack strategies in a\nsynthetic network and analyze how the frequency of network randomization and\nthe number of detection systems can influence the success rate of the attacker.\nThis study provides insights for designing proactive defense strategies against\nonline and multi-stage attacks by a resourceful attacker.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 20:56:04 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 05:45:27 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 03:42:57 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Qian", "Zhentian", ""], ["Fu", "Jie", ""], ["Zhu", "Quanyan", ""]]}, {"id": "2002.05151", "submitter": "Mohamed Mohamed", "authors": "Mohamed Seif, Ravi Tandon, Ming Li", "title": "Wireless Federated Learning with Local Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of federated learning (FL) over a\nwireless channel, modeled by a Gaussian multiple access channel (MAC), subject\nto local differential privacy (LDP) constraints. We show that the superposition\nnature of the wireless channel provides a dual benefit of bandwidth efficient\ngradient aggregation, in conjunction with strong LDP guarantees for the users.\nWe propose a private wireless gradient aggregation scheme, which shows that\nwhen aggregating gradients from $K$ users, the privacy leakage per user scales\nas $\\mathcal{O}\\big(\\frac{1}{\\sqrt{K}} \\big)$ compared to orthogonal\ntransmission in which the privacy leakage scales as a constant. We also present\nanalysis for the convergence rate of the proposed private FL aggregation\nalgorithm and study the tradeoffs between wireless resources, convergence, and\nprivacy.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 18:54:01 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Seif", "Mohamed", ""], ["Tandon", "Ravi", ""], ["Li", "Ming", ""]]}, {"id": "2002.05184", "submitter": "Anirban Pathak", "authors": "Mitali Sisodia, Kishore Thapliyal and Anirban Pathak", "title": "Optical designs for realization of a set of schemes for quantum\n  cryptography", "comments": "Explicit optical designs for the implementation of secure direct\n  quantum communication are provided", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several quantum cryptographic schemes have been proposed and realized\nexperimentally in the past. However, even with an advancement in quantum\ntechnology and escalated interest in the designing of direct secure quantum\ncommunication schemes there are not many experimental implementations of these\ncryptographic schemes. In this paper, we have provided a set of optical\ncircuits for such quantum cryptographic schemes, which have not yet been\nrealized experimentally by modifying some of our theoretically proposed secure\ncommunication schemes. Specifically, we have proposed optical designs for the\nimplementation of two single photon and one entangled state based controlled\nquantum dialogue schemes and subsequently reduced our optical designs to yield\nsimpler designs for realizing other secure quantum communication tasks, i.e.,\ncontrolled deterministic secure quantum communication, quantum dialogue,\nquantum secure direct communication, quantum key agreement, and quantum key\ndistribution. We have further proposed an optical design for an entanglement\nswapping based deterministic secure quantum communication and its controlled\ncounterpart.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 19:14:12 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Sisodia", "Mitali", ""], ["Thapliyal", "Kishore", ""], ["Pathak", "Anirban", ""]]}, {"id": "2002.05231", "submitter": "Kilian Becher", "authors": "Kilian Becher, Thorsten Strufe", "title": "Efficient Cloud-based Secret Shuffling via Homomorphic Encryption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When working with joint collections of confidential data from multiple\nsources, e.g., in cloud-based multi-party computation scenarios, the ownership\nrelation between data providers and their inputs itself is confidential\ninformation. Protecting data providers' privacy desires a function for secretly\nshuffling the data collection. We present the first efficient secure\nmulti-party computation protocol for secret shuffling in scenarios with a\ncentral server. Based on a novel approach to random index distribution, our\nsolution enables the randomization of the order of a sequence of encrypted data\nsuch that no observer can map between elements of the original sequence and the\nshuffled sequence with probability better than guessing. It allows for\nshuffling data encrypted under an additively homomorphic cryptosystem with\nconstant round complexity and linear computational complexity. Being a\ngeneral-purpose protocol, it is of relevance for a variety of practical use\ncases.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 20:49:12 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Becher", "Kilian", ""], ["Strufe", "Thorsten", ""]]}, {"id": "2002.05276", "submitter": "Yixin Shen", "authors": "Xavier Bonnetain, R\\'emi Bricout, Andr\\'e Schrottenloher, Yixin Shen", "title": "Improved Classical and Quantum Algorithms for Subset-Sum", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new classical and quantum algorithms for solving random subset-sum\ninstances. First, we improve over the Becker-Coron-Joux algorithm (EUROCRYPT\n2011) from $\\tilde{\\mathcal{O}}(2^{0.291 n})$ downto\n$\\tilde{\\mathcal{O}}(2^{0.283 n})$, using more general representations with\nvalues in $\\{-1,0,1,2\\}$.\n  Next, we improve the state of the art of quantum algorithms for this problem\nin several directions. By combining the Howgrave-Graham-Joux algorithm\n(EUROCRYPT 2010) and quantum search, we devise an algorithm with asymptotic\ncost $\\tilde{\\mathcal{O}}(2^{0.236 n})$, lower than the cost of the quantum\nwalk based on the same classical algorithm proposed by Bernstein, Jeffery,\nLange and Meurer (PQCRYPTO 2013). This algorithm has the advantage of using\n\\emph{classical} memory with quantum random access, while the previously known\nalgorithms used the quantum walk framework, and required \\emph{quantum} memory\nwith quantum random access.\n  We also propose new quantum walks for subset-sum, performing better than the\nprevious best time complexity of $\\tilde{\\mathcal{O}}(2^{0.226 n})$ given by\nHelm and May (TQC 2018). We combine our new techniques to reach a time\n$\\tilde{\\mathcal{O}}(2^{0.216 n})$. This time is dependent on a heuristic on\nquantum walk updates, formalized by Helm and May, that is also required by the\nprevious algorithms. We show how to partially overcome this heuristic, and we\nobtain an algorithm with quantum time $\\tilde{\\mathcal{O}}(2^{0.218 n})$\nrequiring only the standard classical subset-sum heuristics.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 23:23:04 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 22:20:38 GMT"}, {"version": "v3", "created": "Mon, 1 Jun 2020 15:50:55 GMT"}, {"version": "v4", "created": "Tue, 10 Nov 2020 15:32:16 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Bonnetain", "Xavier", ""], ["Bricout", "R\u00e9mi", ""], ["Schrottenloher", "Andr\u00e9", ""], ["Shen", "Yixin", ""]]}, {"id": "2002.05341", "submitter": "Ruoxi Sun", "authors": "Ruoxi Sun and Minhui Xue", "title": "Quality Assessment of Online Automated Privacy Policy Generators: An\n  Empirical Study", "comments": "The International Conference on Evaluation and Assessment in Software\n  Engineering (EASE) 2020", "journal-ref": null, "doi": "10.1145/3383219.3383247", "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online Automated Privacy Policy Generators (APPGs) are tools used by app\ndevelopers to quickly create app privacy policies which are required by privacy\nregulations to be incorporated to each mobile app. The creation of these tools\nbrings convenience to app developers; however, the quality of these tools puts\ndevelopers and stakeholders at legal risk. In this paper, we conduct an\nempirical study to assess the quality of online APPGs. We analyze the\ncompleteness of privacy policies, determine what categories and items should be\ncovered in a complete privacy policy, and conduct APPG assessment with\nboilerplate apps. The results of assessment show that due to the lack of static\nor dynamic analysis of app's behavior, developers may encounter two types of\nissues caused by APPGs. First, the generated policies could be incomplete\nbecause they do not cover all the essential items required by a privacy policy.\nSecond, some generated privacy policies contain unnecessary personal\ninformation collection or arbitrary commitments inconsistent with user input.\nUltimately, the defects of APPGs may potentially lead to serious legal issues.\nWe hope that the results and insights developed in this paper can motivate the\nhealthy and ethical development of APPGs towards generating a more complete,\naccurate, and robust privacy policy.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 04:34:57 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Sun", "Ruoxi", ""], ["Xue", "Minhui", ""]]}, {"id": "2002.05369", "submitter": "Haoyu Wang", "authors": "Yuheng Huang, Haoyu Wang, Lei Wu, Gareth Tyson, Xiapu Luo, Run Zhang,\n  Xuanzhe Liu, Gang Huang, Xuxian Jiang", "title": "Characterizing EOSIO Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  EOSIO has become one of the most popular blockchain platforms since its\nmainnet launch in June 2018. In contrast to the traditional PoW-based systems\n(e.g., Bitcoin and Ethereum), which are limited by low throughput, EOSIO is the\nfirst high throughput Delegated Proof of Stake system that has been widely\nadopted by many applications. Although EOSIO has millions of accounts and\nbillions of transactions, little is known about its ecosystem, especially\nrelated to security and fraud. In this paper, we perform a large-scale\nmeasurement study of the EOSIO blockchain and its associated DApps. We gather a\nlarge-scale dataset of EOSIO and characterize activities including money\ntransfers, account creation and contract invocation. Using our insights, we\nthen develop techniques to automatically detect bots and fraudulent activity.\nWe discover thousands of bot accounts (over 30\\% of the accounts in the\nplatform) and a number of real-world attacks (301 attack accounts). By the time\nof our study, 80 attack accounts we identified have been confirmed by DApp\nteams, causing 828,824 EOS tokens losses (roughly 2.6 million US\\$) in total.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 07:07:26 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Huang", "Yuheng", ""], ["Wang", "Haoyu", ""], ["Wu", "Lei", ""], ["Tyson", "Gareth", ""], ["Luo", "Xiapu", ""], ["Zhang", "Run", ""], ["Liu", "Xuanzhe", ""], ["Huang", "Gang", ""], ["Jiang", "Xuxian", ""]]}, {"id": "2002.05377", "submitter": "Rafael Dowsley", "authors": "Martine De Cock and Rafael Dowsley and Anderson C. A. Nascimento and\n  Davis Railsback and Jianwei Shen and Ariel Todoki", "title": "High Performance Logistic Regression for Privacy-Preserving Genome\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a secure logistic regression training protocol and\nits implementation, with a new subprotocol to securely compute the activation\nfunction. To the best of our knowledge, we present the fastest existing secure\nMulti-Party Computation implementation for training logistic regression models\non high dimensional genome data distributed across a local area network.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 07:37:08 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 11:00:01 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["De Cock", "Martine", ""], ["Dowsley", "Rafael", ""], ["Nascimento", "Anderson C. A.", ""], ["Railsback", "Davis", ""], ["Shen", "Jianwei", ""], ["Todoki", "Ariel", ""]]}, {"id": "2002.05463", "submitter": "Victor Akinwande", "authors": "Victor Akinwande, Celia Cintas, Skyler Speakman, Srihari Sridharan", "title": "Identifying Audio Adversarial Examples via Anomalous Pattern Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audio processing models based on deep neural networks are susceptible to\nadversarial attacks even when the adversarial audio waveform is 99.9% similar\nto a benign sample. Given the wide application of DNN-based audio recognition\nsystems, detecting the presence of adversarial examples is of high practical\nrelevance. By applying anomalous pattern detection techniques in the activation\nspace of these models, we show that 2 of the recent and current\nstate-of-the-art adversarial attacks on audio processing systems systematically\nlead to higher-than-expected activation at some subset of nodes and we can\ndetect these with up to an AUC of 0.98 with no degradation in performance on\nbenign samples.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 12:08:34 GMT"}, {"version": "v2", "created": "Sat, 25 Jul 2020 06:25:22 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Akinwande", "Victor", ""], ["Cintas", "Celia", ""], ["Speakman", "Skyler", ""], ["Sridharan", "Srihari", ""]]}, {"id": "2002.05517", "submitter": "Keith Dillon", "authors": "Keith Dillon", "title": "Feature-level Malware Obfuscation in Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of detecting malware with deep learning models, where\nthe malware may be combined with significant amounts of benign code. Examples\nof this include piggybacking and trojan horse attacks on a system, where\nmalicious behavior is hidden within a useful application. Such added\nflexibility in augmenting the malware enables significantly more code\nobfuscation. Hence we focus on the use of static features, particularly\nIntents, Permissions, and API calls, which we presume cannot be ultimately\nhidden from the Android system, but only augmented with yet more such features.\nWe first train a deep neural network classifier for malware classification\nusing features of benign and malware samples. Then we demonstrate a steep\nincrease in false negative rate (i.e., attacks succeed), simply by randomly\nadding features of a benign app to malware. Finally we test the use of data\naugmentation to harden the classifier against such attacks. We find that for\nAPI calls, it is possible to reject the vast majority of attacks, where using\nIntents or Permissions is less successful.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 00:47:23 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Dillon", "Keith", ""]]}, {"id": "2002.05547", "submitter": "Arnab Chatterjee", "authors": "Arnab Chatterjee and Yash Pitroda and Manojkumar Parmar", "title": "Dynamic Role-Based Access Control for Decentralized Applications", "comments": "6 pages, 3 figures, 1 table", "journal-ref": "Blockchain -- ICBC 2020. Lecture Notes in Computer Science, vol\n  12404. Springer, Cham", "doi": "10.1007/978-3-030-59638-5_13", "report-no": null, "categories": "cs.CR cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Access control management is an integral part of maintaining the security of\nan application. Although there has been significant work in the field of cloud\naccess control mechanisms, however, with the advent of Distributed Ledger\nTechnology (DLT), on-chain access control management frameworks hardly exist.\nExisting access control management mechanisms are tightly coupled with the\nbusiness logic, resulting in governance issues, non-coherent with existing\nIdentity Management Solutions, low security, and compromised usability. We\npropose a novel framework to implement dynamic role-based access control for\ndecentralized applications (dApps). The framework allows for managing access\ncontrol on a dApp, which is completely decoupled from the business application\nand integrates seamlessly with any dApps. The smart contract architecture\nallows for the independent management of business logic and execution of access\ncontrol policies. It also facilitates secure, low cost, and a high degree of\nflexibility of access control management. The proposed framework promotes\ndecentralized governance of access control policies and efficient smart\ncontract upgrades. We also provide quantitative and qualitative metrics for the\nefficacy and efficiency of the framework. Any Turing complete smart contract\nprogramming language is an excellent fit to implement the framework. We expect\nthis framework to benefit enterprise and non-enterprise dApps and provide\ngreater access control flexibility and effective integration with traditional\nand state of the art identity management solutions.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 14:57:43 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 06:03:02 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Chatterjee", "Arnab", ""], ["Pitroda", "Yash", ""], ["Parmar", "Manojkumar", ""]]}, {"id": "2002.05624", "submitter": "Jun Zhao", "authors": "Lin Sun, Xiaojun Ye, Jun Zhao, Chenhui Lu, Mengmeng Yang", "title": "BiSample: Bidirectional Sampling for Handling Missing Data with Local\n  Differential Privacy", "comments": "This paper appears as a full paper in the Proceedings of 25th\n  International Conference on Database Systems for Advanced Applications\n  (DASFAA 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local differential privacy (LDP) has received much interest recently. In\nexisting protocols with LDP guarantees, a user encodes and perturbs his data\nlocally before sharing it to the aggregator. In common practice, however, users\nwould prefer not to answer all the questions due to different\nprivacy-preserving preferences for different questions, which leads to data\nmissing or the loss of data quality. In this paper, we demonstrate a new\napproach for addressing the challenges of data perturbation with consideration\nof users' privacy preferences. Specifically, we first propose BiSample: a\nbidirectional sampling technique value perturbation in the framework of LDP.\nThen we combine the BiSample mechanism with users' privacy preferences for\nmissing data perturbation. Theoretical analysis and experiments on a set of\ndatasets confirm the effectiveness of the proposed mechanisms.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 16:49:50 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Sun", "Lin", ""], ["Ye", "Xiaojun", ""], ["Zhao", "Jun", ""], ["Lu", "Chenhui", ""], ["Yang", "Mengmeng", ""]]}, {"id": "2002.05646", "submitter": "Ram Shankar Siva Kumar", "authors": "Ram Shankar Siva Kumar, Magnus Nystr\\\"om, John Lambert, Andrew\n  Marshall, Mario Goertzel, Andi Comissoneru, Matt Swann, Sharon Xia", "title": "Adversarial Machine Learning -- Industry Perspectives", "comments": "Minor Typos corrected 7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on interviews with 28 organizations, we found that industry\npractitioners are not equipped with tactical and strategic tools to protect,\ndetect and respond to attacks on their Machine Learning (ML) systems. We\nleverage the insights from the interviews and we enumerate the gaps in\nperspective in securing machine learning systems when viewed in the context of\ntraditional software security development. We write this paper from the\nperspective of two personas: developers/ML engineers and security incident\nresponders who are tasked with securing ML systems as they are designed,\ndeveloped and deployed ML systems. The goal of this paper is to engage\nresearchers to revise and amend the Security Development Lifecycle for\nindustrial-grade software in the adversarial ML era.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 02:28:34 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 17:33:37 GMT"}, {"version": "v3", "created": "Fri, 19 Mar 2021 16:02:28 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Kumar", "Ram Shankar Siva", ""], ["Nystr\u00f6m", "Magnus", ""], ["Lambert", "John", ""], ["Marshall", "Andrew", ""], ["Goertzel", "Mario", ""], ["Comissoneru", "Andi", ""], ["Swann", "Matt", ""], ["Xia", "Sharon", ""]]}, {"id": "2002.05648", "submitter": "Ram Shankar Siva Kumar", "authors": "Kendra Albert, Jonathon Penney, Bruce Schneier, Ram Shankar Siva Kumar", "title": "Politics of Adversarial Machine Learning", "comments": "Authors ordered alphabetically; 4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In addition to their security properties, adversarial machine-learning\nattacks and defenses have political dimensions. They enable or foreclose\ncertain options for both the subjects of the machine learning systems and for\nthose who deploy them, creating risks for civil liberties and human rights. In\nthis paper, we draw on insights from science and technology studies,\nanthropology, and human rights literature, to inform how defenses against\nadversarial attacks can be used to suppress dissent and limit attempts to\ninvestigate machine learning systems. To make this concrete, we use real-world\nexamples of how attacks such as perturbation, model inversion, or membership\ninference can be used for socially desirable ends. Although the predictions of\nthis analysis may seem dire, there is hope. Efforts to address human rights\nconcerns in the commercial spyware industry provide guidance for similar\nmeasures to ensure ML systems serve democratic, not authoritarian ends\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 01:15:39 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 20:34:56 GMT"}, {"version": "v3", "created": "Sun, 26 Apr 2020 04:59:52 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Albert", "Kendra", ""], ["Penney", "Jonathon", ""], ["Schneier", "Bruce", ""], ["Kumar", "Ram Shankar Siva", ""]]}, {"id": "2002.05659", "submitter": "Mahdi Miraz", "authors": "Mahdi H. Miraz and Marie Haikel-Elsabeh", "title": "Analysis of Users' Behaviour and Adoption Trends of Social Media Payment\n  Platforms", "comments": null, "journal-ref": "2019 International Conference on Computing, Electronics &\n  Communications Engineering (iCCECE), London, United Kingdom, 2019, pp.\n  197-202", "doi": "10.1109/iCCECE46942.2019.8941991", "report-no": null, "categories": "cs.CY cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent proliferation of Electronic Commerce (E-commerce) has been further\nescalated by multifaceted emerging payment solutions such as cryptocurrencies,\nmobile, peer-to-peer (P2P) and social media payment platforms. While these\ntechnological advancements are gaining tremendous popularity, mostly for their\nease of use, various impediments such as security and privacy concerns,\nsocietal and cultural norms etc. forbear the users' adoption trends to some\nextents. This article examines the current status of the social media payment\nplatforms as well as the projection of future adoption trends. Our research\nunderlines the motivations and obstacles to the adoption of social media\nplatforms.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 12:08:43 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Miraz", "Mahdi H.", ""], ["Haikel-Elsabeh", "Marie", ""]]}, {"id": "2002.05691", "submitter": "Hua Sun", "authors": "Zhou Li, Hua Sun", "title": "Conditional Disclosure of Secrets: A Noise and Signal Alignment Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the conditional disclosure of secrets (CDS) problem, Alice and Bob (each\nholds an input and a common secret) wish to disclose, as efficiently as\npossible, the secret to Carol if and only if their inputs satisfy some\nfunction. The capacity of CDS is the maximum number of bits of the secret that\ncan be securely disclosed per bit of total communication. We characterize the\nnecessary and sufficient condition for the extreme case where the capacity of\nCDS is the highest and is equal to 1/2. For the simplest instance where the\ncapacity is smaller than 1/2, we show that the linear capacity is 2/5.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 18:18:31 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Li", "Zhou", ""], ["Sun", "Hua", ""]]}, {"id": "2002.05798", "submitter": "Mohammad Sayad Haghighi", "authors": "Soheila Barchinezhad, Mohammad Sayad Haghighi", "title": "Compensation of Linear Attacks to Cyber Physical Systems through ARX\n  System Identification", "comments": "9 figures, conference", "journal-ref": "IKT 2019 proceedings", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-Physical Systems (CPSs) are vastly used in today's cities critical\ninfrastructure. The cyber part of these systems usually has a network component\nthrough which cyber attacks can be launched. In this paper, we first design an\nintrusion detection system (IDS) by identifying the plant. We assume the\ninitial operation period of the CPS is attack-free and learn the plant model.\nThen, we compare the expected output found via the identifier with the real one\ncoming through the feedback link. Any difference greater than a threshold is\ndeemed to be an anomaly. To compensate, once the IDS flags a change in the\nloop, we restart the system identification to find the new transfer function.\nWith the estimation of the new transfer function at hand, a new controller is\ndesigned to keep the system stable. To test the idea, we took a DC motor as the\nplant and employed ARX identifier. MATLAB Simulink environment was used to test\nthe proposed intrusion detection and compensation framework. We applied a set\nof deception attacks to the forward channel in our experiments. The obtained\nresults prove that our detection strategy works well and timely reacts to\nanomalies. Moreover, they show that the compensation strategy is also effective\nand keeps the system stable under such attacks.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 22:22:19 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Barchinezhad", "Soheila", ""], ["Haghighi", "Mohammad Sayad", ""]]}, {"id": "2002.05839", "submitter": "Ryan Rogers", "authors": "Ryan Rogers, Subbu Subramaniam, Sean Peng, David Durfee, Seunghyun\n  Lee, Santosh Kumar Kancha, Shraddha Sahay, Parvez Ahammad", "title": "LinkedIn's Audience Engagements API: A Privacy Preserving Data Analytics\n  System at Scale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a privacy system that leverages differential privacy to protect\nLinkedIn members' data while also providing audience engagement insights to\nenable marketing analytics related applications. We detail the differentially\nprivate algorithms and other privacy safeguards used to provide results that\ncan be used with existing real-time data analytics platforms, specifically with\nthe open sourced Pinot system. Our privacy system provides user-level privacy\nguarantees. As part of our privacy system, we include a budget management\nservice that enforces a strict differential privacy budget on the returned\nresults to the analyst. This budget management service brings together the\nlatest research in differential privacy into a product to maintain utility\ngiven a fixed differential privacy budget.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 01:41:30 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 05:44:56 GMT"}, {"version": "v3", "created": "Mon, 16 Nov 2020 18:08:01 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Rogers", "Ryan", ""], ["Subramaniam", "Subbu", ""], ["Peng", "Sean", ""], ["Durfee", "David", ""], ["Lee", "Seunghyun", ""], ["Kancha", "Santosh Kumar", ""], ["Sahay", "Shraddha", ""], ["Ahammad", "Parvez", ""]]}, {"id": "2002.05905", "submitter": "Omar Ibrahim Mr", "authors": "Omar Adel Ibrahim, Savio Sciancalepore, Gabriele Oligeri, Roberto Di\n  Pietro", "title": "MAGNETO: Fingerprinting USB Flash Drives via Unintentional Magnetic\n  Emissions", "comments": "Accepted for publication in ACM Transactions on Embedded Computing\n  Systems (TECS) in September 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Universal Serial Bus (USB) Flash Drives are nowadays one of the most\nconvenient and diffused means to transfer files, especially when no Internet\nconnection is available. However, USB flash drives are also one of the most\ncommon attack vectors used to gain unauthorized access to host devices. For\ninstance, it is possible to replace a USB drive so that when the USB key is\nconnected, it would install passwords stealing tools, root-kit software, and\nother disrupting malware. In such a way, an attacker can steal sensitive\ninformation via the USB-connected devices, as well as inject any kind of\nmalicious software into the host.\n  To thwart the above-cited raising threats, we propose MAGNETO, an efficient,\nnon-interactive, and privacy-preserving framework to verify the authenticity of\na USB flash drive, rooted in the analysis of its unintentional magnetic\nemissions. We show that the magnetic emissions radiated during boot operations\non a specific host are unique for each device, and sufficient to uniquely\nfingerprint both the brand and the model of the USB flash drive, or the\nspecific USB device, depending on the used equipment. Our investigation on 59\ndifferent USB flash drives---belonging to 17 brands, including the top brands\npurchased on Amazon in mid-2019---, reveals a minimum classification accuracy\nof 98.2% in the identification of both brand and model, accompanied by a\nnegligible time and computational overhead. MAGNETO can also identify the\nspecific USB Flash drive, with a minimum classification accuracy of 91.2%.\nOverall, MAGNETO proves that unintentional magnetic emissions can be considered\nas a viable and reliable means to fingerprint read-only USB flash drives.\nFinally, future research directions in this domain are also discussed.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 08:09:54 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 12:33:20 GMT"}, {"version": "v3", "created": "Sun, 13 Sep 2020 02:34:33 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Ibrahim", "Omar Adel", ""], ["Sciancalepore", "Savio", ""], ["Oligeri", "Gabriele", ""], ["Di Pietro", "Roberto", ""]]}, {"id": "2002.05988", "submitter": "Ana Sofia Gomes", "authors": "Bernardo Branco, Pedro Abreu, Ana Sofia Gomes, Mariana S. C. Almeida,\n  Jo\\~ao Tiago Ascens\\~ao, Pedro Bizarro", "title": "Interleaved Sequence RNNs for Fraud Detection", "comments": "9 pages, 4 figures, to appear in SIGKDD'20 Industry Track", "journal-ref": null, "doi": "10.1145/3394486.3403361", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Payment card fraud causes multibillion dollar losses for banks and merchants\nworldwide, often fueling complex criminal activities. To address this, many\nreal-time fraud detection systems use tree-based models, demanding complex\nfeature engineering systems to efficiently enrich transactions with historical\ndata while complying with millisecond-level latencies.\n  In this work, we do not require those expensive features by using recurrent\nneural networks and treating payments as an interleaved sequence, where the\nhistory of each card is an unbounded, irregular sub-sequence. We present a\ncomplete RNN framework to detect fraud in real-time, proposing an efficient ML\npipeline from preprocessing to deployment.\n  We show that these feature-free, multi-sequence RNNs outperform\nstate-of-the-art models saving millions of dollars in fraud detection and using\nfewer computational resources.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 12:04:11 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 16:59:41 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Branco", "Bernardo", ""], ["Abreu", "Pedro", ""], ["Gomes", "Ana Sofia", ""], ["Almeida", "Mariana S. C.", ""], ["Ascens\u00e3o", "Jo\u00e3o Tiago", ""], ["Bizarro", "Pedro", ""]]}, {"id": "2002.05990", "submitter": "Dongxian Wu", "authors": "Dongxian Wu, Yisen Wang, Shu-Tao Xia, James Bailey, Xingjun Ma", "title": "Skip Connections Matter: On the Transferability of Adversarial Examples\n  Generated with ResNets", "comments": "ICLR 2020 conference paper (spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Skip connections are an essential component of current state-of-the-art deep\nneural networks (DNNs) such as ResNet, WideResNet, DenseNet, and ResNeXt.\nDespite their huge success in building deeper and more powerful DNNs, we\nidentify a surprising security weakness of skip connections in this paper. Use\nof skip connections allows easier generation of highly transferable adversarial\nexamples. Specifically, in ResNet-like (with skip connections) neural networks,\ngradients can backpropagate through either skip connections or residual\nmodules. We find that using more gradients from the skip connections rather\nthan the residual modules according to a decay factor, allows one to craft\nadversarial examples with high transferability. Our method is termed Skip\nGradient Method(SGM). We conduct comprehensive transfer attacks against\nstate-of-the-art DNNs including ResNets, DenseNets, Inceptions,\nInception-ResNet, Squeeze-and-Excitation Network (SENet) and robustly trained\nDNNs. We show that employing SGM on the gradient flow can greatly improve the\ntransferability of crafted attacks in almost all cases. Furthermore, SGM can be\neasily combined with existing black-box attack techniques, and obtain high\nimprovements over state-of-the-art transferability methods. Our findings not\nonly motivate new research into the architectural vulnerability of DNNs, but\nalso open up further challenges for the design of secure DNN architectures.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 12:09:21 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Wu", "Dongxian", ""], ["Wang", "Yisen", ""], ["Xia", "Shu-Tao", ""], ["Bailey", "James", ""], ["Ma", "Xingjun", ""]]}, {"id": "2002.05999", "submitter": "Yinpeng Dong", "authors": "Yinpeng Dong, Zhijie Deng, Tianyu Pang, Hang Su, Jun Zhu", "title": "Adversarial Distributional Training for Robust Deep Learning", "comments": "NeurIPS 2020. The first two authors contribute equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training (AT) is among the most effective techniques to improve\nmodel robustness by augmenting training data with adversarial examples.\nHowever, most existing AT methods adopt a specific attack to craft adversarial\nexamples, leading to the unreliable robustness against other unseen attacks.\nBesides, a single attack algorithm could be insufficient to explore the space\nof perturbations. In this paper, we introduce adversarial distributional\ntraining (ADT), a novel framework for learning robust models. ADT is formulated\nas a minimax optimization problem, where the inner maximization aims to learn\nan adversarial distribution to characterize the potential adversarial examples\naround a natural one under an entropic regularizer, and the outer minimization\naims to train robust models by minimizing the expected loss over the worst-case\nadversarial distributions. Through a theoretical analysis, we develop a general\nalgorithm for solving ADT, and present three approaches for parameterizing the\nadversarial distributions, ranging from the typical Gaussian distributions to\nthe flexible implicit ones. Empirical results on several benchmarks validate\nthe effectiveness of ADT compared with the state-of-the-art AT methods.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 12:36:59 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 05:47:50 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Dong", "Yinpeng", ""], ["Deng", "Zhijie", ""], ["Pang", "Tianyu", ""], ["Su", "Hang", ""], ["Zhu", "Jun", ""]]}, {"id": "2002.06259", "submitter": "Hui Yang", "authors": "Hui Yang, Kaixuan Zhan, Michel Kadoch, Yongshen Liang, Mohamed Cheriet", "title": "BLCS: Brain-Like based Distributed Control Security in Cyber Physical\n  Systems", "comments": "accepted by IEEE Network", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-physical system (CPS) has operated, controlled and coordinated the\nphysical systems integrated by a computing and communication core applied in\nindustry 4.0. To accommodate CPS services, fog radio and optical networks\n(F-RON) has become an important supporting physical cyber infrastructure taking\nadvantage of both the inherent ubiquity of wireless technology and the large\ncapacity of optical networks. However, cyber security is the biggest issue in\nCPS scenario as there is a tradeoff between security control and privacy\nexposure in F-RON. To deal with this issue, we propose a brain-like based\ndistributed control security (BLCS) architecture for F-RON in CPS, by\nintroducing a brain-like security (BLS) scheme. BLCS can accomplish the secure\ncross-domain control among tripartite controllers verification in the scenario\nof decentralized F-RON for distributed computing and communications, which has\nno need to disclose the private information of each domain against\ncyber-attacks. BLS utilizes parts of information to perform control\nidentification through relation network and deep learning of behavior library.\nThe functional modules of BLCS architecture are illustrated including various\ncontrollers and brain-like knowledge base. The interworking procedures in\ndistributed control security modes based on BLS are described. The overall\nfeasibility and efficiency of architecture are experimentally verified on the\nsoftware defined network testbed in terms of average mistrust rate, path\nprovisioning latency, packet loss probability and blocking probability. The\nemulation results are obtained and dissected based on the testbed.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 09:14:10 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Yang", "Hui", ""], ["Zhan", "Kaixuan", ""], ["Kadoch", "Michel", ""], ["Liang", "Yongshen", ""], ["Cheriet", "Mohamed", ""]]}, {"id": "2002.06383", "submitter": "Andrew McDole", "authors": "Andrew McDole and Mahmoud Abdelsalam and Maanak Gupta and Sudip Mittal", "title": "Analyzing CNN Based Behavioural Malware Detection Techniques on Cloud\n  IaaS", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-59635-4_5", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud Infrastructure as a Service (IaaS) is vulnerable to malware due to its\nexposure to external adversaries, making it a lucrative attack vector for\nmalicious actors. A datacenter infected with malware can cause data loss and/or\nmajor disruptions to service for its users. This paper analyzes and compares\nvarious Convolutional Neural Networks (CNNs) for online detection of malware in\ncloud IaaS. The detection is performed based on behavioural data using process\nlevel performance metrics including cpu usage, memory usage, disk usage etc. We\nhave used the state of the art DenseNets and ResNets in effectively detecting\nmalware in online cloud system. CNN are designed to extract features from data\ngathered from a live malware running on a real cloud environment. Experiments\nare performed on OpenStack (a cloud IaaS software) testbed designed to\nreplicate a typical 3-tier web architecture. Comparative analysis is performed\nfor different metrics for different CNN models used in this research.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 14:04:33 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["McDole", "Andrew", ""], ["Abdelsalam", "Mahmoud", ""], ["Gupta", "Maanak", ""], ["Mittal", "Sudip", ""]]}, {"id": "2002.06403", "submitter": "Ashutosh Bhatia Dr.", "authors": "Aman Sharma, Ashutosh Bhatia", "title": "Bitcoin's Blockchain Data Analytics: A Graph Theoretic Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin is the most popular cryptocurrency used worldwide. It provides\npseudonymity to its users by establishing identity using public keys as\ntransaction end-points. These transactions are recorded on an immutable public\nledger called Blockchain which is an append-only data structure. The popularity\nof Bitcoin has increased unreasonably. The general trend shows a positive\nresponse from the common masses indicating an increase in trust and privacy\nconcerns which makes an interesting use case from the analysis point of view.\nMoreover, since the blockchain is publicly available and up-to-date, any\nanalysis would provide a live insight into the usage patterns which ultimately\nwould be useful for making a number of inferences by law-enforcement agencies,\neconomists, tech-enthusiasts, etc. In this paper, we study various applications\nand techniques of performing data analytics over Bitcoin blockchain from a\ngraph theoretic perspective. We also propose a framework for performing such\ndata analytics and explored a couple of use cases using the proposed framework.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 16:07:34 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Sharma", "Aman", ""], ["Bhatia", "Ashutosh", ""]]}, {"id": "2002.06448", "submitter": "Roberto Perdisci", "authors": "Karthika Subramani (1), Xingzi Yuan (1), Omid Setayeshfar (1), Phani\n  Vadrevu (2), Kyu Hyung Lee (1), Roberto Perdisci (1 and 3) ((1) University of\n  Georgia, (2) University of New Orleans, (3) Georgia Institute of Technology)", "title": "Measuring Abuse in Web Push Advertising", "comments": null, "journal-ref": "IMC '20: ACM Internet Measurement Conference October, 2020", "doi": "10.1145/3419394.3423631", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth of online advertising has fueled the growth of ad-blocking\nsoftware, such as new ad-blocking and privacy-oriented browsers or browser\nextensions. In response, both ad publishers and ad networks are constantly\ntrying to pursue new strategies to keep up their revenues. To this end, ad\nnetworks have started to leverage the Web Push technology enabled by modern web\nbrowsers.\n  As web push notifications (WPNs) are relatively new, their role in ad\ndelivery has not been yet studied in depth. Furthermore, it is unclear to what\nextent WPN ads are being abused for malvertising (i.e., to deliver malicious\nads). In this paper, we aim to fill this gap. Specifically, we propose a system\ncalled PushAdMiner that is dedicated to (1) automatically registering for and\ncollecting a large number of web-based push notifications from publisher\nwebsites, (2) finding WPN-based ads among these notifications, and (3)\ndiscovering malicious WPN-based ad campaigns.\n  Using PushAdMiner, we collected and analyzed 21,541 WPN messages by visiting\nthousands of different websites. Among these, our system identified 572 WPN ad\ncampaigns, for a total of 5,143 WPN-based ads that were pushed by a variety of\nad networks. Furthermore, we found that 51% of all WPN ads we collected are\nmalicious, and that traditional ad-blockers and malicious URL filters are\nremarkably ineffective against WPN-based malicious ads, leaving a significant\nabuse vector unchecked.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 20:46:10 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Subramani", "Karthika", "", "1 and 3"], ["Yuan", "Xingzi", "", "1 and 3"], ["Setayeshfar", "Omid", "", "1 and 3"], ["Vadrevu", "Phani", "", "1 and 3"], ["Lee", "Kyu Hyung", "", "1 and 3"], ["Perdisci", "Roberto", "", "1 and 3"]]}, {"id": "2002.06463", "submitter": "Pedro Reviriego", "authors": "Pedro Reviriego and Daniel Ting", "title": "Security of HyperLogLog (HLL) Cardinality Estimation: Vulnerabilities\n  and Protection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Count distinct or cardinality estimates are widely used in network monitoring\nfor security. They can be used, for example, to detect the malware spread,\nnetwork scans, or a denial of service attack. There are many algorithms to\nestimate cardinality. Among those, HyperLogLog (HLL) has been one of the most\nwidely adopted. HLL is simple, provides good cardinality estimates over a wide\nrange of values, requires a small amount of memory, and allows merging of\nestimates from different sources. However, as HLL is increasingly used to\ndetect attacks, it can itself become the target of attackers that want to avoid\nbeing detected. To the best of our knowledge, the security of HLL has not been\nstudied before. In this letter, we take an initial step in its study by first\nexposing a vulnerability of HLL that allows an attacker to manipulate its\nestimate. This shows the importance of designing secure HLL implementations. In\nthe second part of the letter, we propose an efficient protection technique to\ndetect and avoid the HLL manipulation. The results presented strongly suggest\nthat the security of HLL should be further studied given that it is widely\nadopted in many networking and computing applications.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 22:28:07 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Reviriego", "Pedro", ""], ["Ting", "Daniel", ""]]}, {"id": "2002.06495", "submitter": "Milad Nasr", "authors": "Milad Nasr, Alireza Bahramali, Amir Houmansadr", "title": "Blind Adversarial Network Perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are commonly used for various traffic analysis\nproblems, such as website fingerprinting and flow correlation, as they\noutperform traditional (e.g., statistical) techniques by large margins.\nHowever, deep neural networks are known to be vulnerable to adversarial\nexamples: adversarial inputs to the model that get labeled incorrectly by the\nmodel due to small adversarial perturbations. In this paper, for the first\ntime, we show that an adversary can defeat DNN-based traffic analysis\ntechniques by applying \\emph{adversarial perturbations} on the patterns of\n\\emph{live} network traffic.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 02:59:41 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Nasr", "Milad", ""], ["Bahramali", "Alireza", ""], ["Houmansadr", "Amir", ""]]}, {"id": "2002.06512", "submitter": "Vinod Ganapathy", "authors": "Rakesh Rajan Beck and Abhishek Vijeev and Vinod Ganapathy", "title": "Privaros: A Framework for Privacy-Compliant Delivery Drones", "comments": null, "journal-ref": null, "doi": "10.1145/3372297.3417858", "report-no": null, "categories": "cs.CR cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Privaros, a framework to enforce privacy policies on drones.\nPrivaros is designed for commercial delivery drones, such as the ones that will\nlikely be used by Amazon Prime Air. Such drones visit a number of host\nairspaces, each of which may have different privacy requirements. Privaros\nprovides an information flow control framework to enforce the policies of these\nhosts on the guest delivery drones. The mechanisms in Privaros are built on top\nof ROS, a middleware popular in many drone platforms. This paper presents the\ndesign and implementation of these mechanisms, describes how policies are\nspecified, and shows that Privaros's policy specification can be integrated\nwith India's Digital Sky portal. Our evaluation shows that a drone running\nPrivaros can robustly enforce various privacy policies specified by hosts, and\nthat its core mechanisms only marginally increase communication latency and\npower consumption.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 05:51:41 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 04:42:57 GMT"}, {"version": "v3", "created": "Thu, 13 Aug 2020 18:00:46 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Beck", "Rakesh Rajan", ""], ["Vijeev", "Abhishek", ""], ["Ganapathy", "Vinod", ""]]}, {"id": "2002.06531", "submitter": "Mohammad Hossein Manshaei", "authors": "Tayebeh Rajab, Mohammad Hossein Manshaei, Mohammad Dakhilalian,\n  Murtuza Jadliwala, Mohammad Ashiqur Rahman", "title": "On the Feasibility of Sybil Attacks in Shard-Based Permissionless\n  Blockchains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin's single leader consensus protocol (Nakamoto consensus) suffers from\nsignificant transaction throughput and network scalability issues due to the\ncomputational requirements of it Proof-of-Work (PoW) based leader selection\nstrategy. To overcome this, committee-based approaches (e.g., Elastico) that\npartition the outstanding transaction set into shards and (randomly) select\nmultiple committees to process these transactions in parallel have been\nproposed and have become very popular. However, by design these committee or\nshard-based blockchain solutions are easily vulnerable to the Sybil attacks,\nwhere an adversary can easily compromise/manipulate the consensus protocol if\nit has enough computational power to generate multiple Sybil committee members\n(by generating multiple valid node identifiers). Despite the straightforward\nnature of these attacks, they have not been systematically analyzed. In this\npaper, we fill this research gap by modelling and analyzing Sybil attacks in a\nrepresentative and popular shard-based protocol called Elastico. We show that\nthe PoW technique used for identifier or ID generation in the initial phase of\nthe protocol is vulnerable to Sybil attacks, and a node with high hash-power\ncan generate enough Sybil IDs to successfully compromise Elastico. We\nanalytically derive conditions for two different categories of Sybil attacks\nand perform numerical simulations to validate our theoretical results under\ndifferent network and protocol parameters.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 08:04:16 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Rajab", "Tayebeh", ""], ["Manshaei", "Mohammad Hossein", ""], ["Dakhilalian", "Mohammad", ""], ["Jadliwala", "Murtuza", ""], ["Rahman", "Mohammad Ashiqur", ""]]}, {"id": "2002.06538", "submitter": "Burak Bartan", "authors": "Burak Bartan, Mert Pilanci", "title": "Distributed Sketching Methods for Privacy Preserving Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study distributed sketching methods for large scale\nregression problems. We leverage multiple randomized sketches for reducing the\nproblem dimensions as well as preserving privacy and improving straggler\nresilience in asynchronous distributed systems. We derive novel approximation\nguarantees for classical sketching methods and analyze the accuracy of\nparameter averaging for distributed sketches. We consider random matrices\nincluding Gaussian, randomized Hadamard, uniform sampling and leverage score\nsampling in the distributed setting. Moreover, we propose a hybrid approach\ncombining sampling and fast random projections for better computational\nefficiency. We illustrate the performance of distributed sketches in a\nserverless computing platform with large scale experiments.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 08:35:48 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 00:36:01 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Bartan", "Burak", ""], ["Pilanci", "Mert", ""]]}, {"id": "2002.06564", "submitter": "Ayelet Mizrahi", "authors": "Ayelet Mizrahi and Aviv Zohar", "title": "Congestion Attacks in Payment Channel Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Payment channel networks provide a fast and scalable solution to relay funds,\nacting as a second layer to slower and less scalable blockchain protocols. In\nthis paper, we present an accessible, low-cost attack in which the attacker\nparalyzes multiple payment network channels for several days. The attack is\nbased on overloading channels with requests that are kept unresolved until\ntheir expiration time. Reaching the maximum allowed unresolved requests (HTLCs)\nlocks the channel for new payments. The attack is in fact inherent to the way\noff-chain networks are constructed, since limits on the number of unresolved\npayments are derived from limits on the blockchain. We consider three main\nversions of the attack: one in which the attacker attempts to block as many\nhigh liquidity channels as possible, one in which it disconnects as many pairs\nof nodes as it can, and one in which it tries to isolate individual nodes from\nthe network. We evaluate the costs of these attacks on Bitcoin's Lightning\nNetwork and compare how changes in the network have affected the cost of\nattack. Specifically, we consider how recent changes to default parameters in\neach of the main Lightning implementations contribute to the attacks. As we\nevaluate the attacks, we also look at statistics on parameters in the Lightning\nNetwork, which are of independent interest and compare the various\nimplementations of Lightning nodes. Finally, we suggest mitigation techniques\nthat make these attacks much harder to carry out.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 12:17:28 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 18:03:57 GMT"}, {"version": "v3", "created": "Wed, 25 Nov 2020 15:16:26 GMT"}, {"version": "v4", "created": "Sun, 31 Jan 2021 14:25:53 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Mizrahi", "Ayelet", ""], ["Zohar", "Aviv", ""]]}, {"id": "2002.06713", "submitter": "Khalid Malik", "authors": "Ahmad Mansour, Khalid M. Malik and Niko Kaso", "title": "AMOUN: Asymmetric lightweight cryptographic scheme for wireless group\n  communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-recipient cryptographic schemes provide secure communication, between\none sender and multiple recipients, in a multi-party group. Providing secure\nmulti-party communication is very challenging, especially in dynamic networks.\nExisting multi-recipient cryptographic schemes pose a variety of limitations.\nThese include high computational overhead for both encryption and decryption,\nadditional communication overhead and high setup cost due to change in\nmembership, and collusion among recipients. In order to overcome these\nlimitations, this paper introduces a novel asymmetric multi-recipient\ncryptographic scheme, AMOUN. In the proposed scheme, to better utilize network\nresources, the sender transmits a ciphertext containing different messages to\nmultiple recipients, where each recipient only allowed to retrieve its own\ndesignated message. Security analysis demonstrates that the proposed scheme is\nindistinguishable under adaptive chosen plaintext attack. Quantitative analysis\nreveals that lightweight AMOUN shows lower average computational cost than both\nRSA and Multi-RSA, for both encryption and decryption, even when the key sizes\nare four times larger. For a given prime size, in case of encryption, AMOUN\nshows 98% and 99% lower average computational cost than RSA and Multi-RSA,\nrespectively. For decryption, AMOUN shows a performance improvement of 99%\ncompared to RSA and Multi-RSA.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 23:52:37 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Mansour", "Ahmad", ""], ["Malik", "Khalid M.", ""], ["Kaso", "Niko", ""]]}, {"id": "2002.06776", "submitter": "Sanghyun Hong", "authors": "Sanghyun Hong, Michael Davinroy, Yi\\u{g}itcan Kaya, Dana\n  Dachman-Soled, Tudor Dumitra\\c{s}", "title": "How to 0wn NAS in Your Spare Time", "comments": "Accepted to ICLR 2020 [Poster]; Our code is available at\n  https://github.com/sanghyun-hong/How-to-0wn-NAS-in-Your-Spare-Time", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New data processing pipelines and novel network architectures increasingly\ndrive the success of deep learning. In consequence, the industry considers\ntop-performing architectures as intellectual property and devotes considerable\ncomputational resources to discovering such architectures through neural\narchitecture search (NAS). This provides an incentive for adversaries to steal\nthese novel architectures; when used in the cloud, to provide Machine Learning\nas a Service, the adversaries also have an opportunity to reconstruct the\narchitectures by exploiting a range of hardware side channels. However, it is\nchallenging to reconstruct novel architectures and pipelines without knowing\nthe computational graph (e.g., the layers, branches or skip connections), the\narchitectural parameters (e.g., the number of filters in a convolutional layer)\nor the specific pre-processing steps (e.g. embeddings). In this paper, we\ndesign an algorithm that reconstructs the key components of a novel deep\nlearning system by exploiting a small amount of information leakage from a\ncache side-channel attack, Flush+Reload. We use Flush+Reload to infer the trace\nof computations and the timing for each computation. Our algorithm then\ngenerates candidate computational graphs from the trace and eliminates\nincompatible candidates through a parameter estimation process. We implement\nour algorithm in PyTorch and Tensorflow. We demonstrate experimentally that we\ncan reconstruct MalConv, a novel data pre-processing pipeline for malware\ndetection, and ProxylessNAS- CPU, a novel network architecture for the ImageNet\nclassification optimized to run on CPUs, without knowing the architecture\nfamily. In both cases, we achieve 0% error. These results suggest hardware side\nchannels are a practical attack vector against MLaaS, and more efforts should\nbe devoted to understanding their impact on the security of deep learning\nsystems.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 05:40:55 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 23:04:04 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Hong", "Sanghyun", ""], ["Davinroy", "Michael", ""], ["Kaya", "Yi\u011fitcan", ""], ["Dachman-Soled", "Dana", ""], ["Dumitra\u015f", "Tudor", ""]]}, {"id": "2002.06794", "submitter": "Zichi Wang", "authors": "Zhenxing Qian, Zichi Wang, Xinpeng Zhang", "title": "Computing in Covert Domain Using Data Hiding", "comments": "5 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an idea of data computing in the covert domain (DCCD). We\nshow that with information hiding some data computing tasks can be executed\nbeneath the covers like images, audios, random data, etc. In the proposed\nframework, a sender hides his source data into two covers and uploads them onto\na server. The server executes computation within the stego and returns the\ncovert computing result to a receiver. With the covert result, the receiver can\nextract the computing result of the source data. During the process, it is\nimperceptible for the server and the adversaries to obtain the source data as\nthey are hidden in the cover. The transmission can be done over public\nchannels. Meanwhile, since the computation is realized in the covert domain,\nthe cloud cannot obtain the knowledge of the computing result. Therefore, the\nproposed idea is useful for cloud computing.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 06:30:17 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Qian", "Zhenxing", ""], ["Wang", "Zichi", ""], ["Zhang", "Xinpeng", ""]]}, {"id": "2002.06819", "submitter": "arXiv Admin", "authors": "Sajedul Talukder", "title": "Tools and Techniques for Malware Detection and Analysis", "comments": "arXiv admin note: submission has been withdrawn by arXiv\n  administrators due to inappropriate overlap with external sources", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major and serious threats that the Internet faces today is the\nvast amounts of data and files which need to be evaluated for potential\nmalicious intent. Malicious software, often referred to as a malware that are\ndesigned by attackers are polymorphic and metamorphic in nature which have the\ncapability to change their code as they spread. Moreover, the diversity and\nvolume of their variants severely undermine the effectiveness of traditional\ndefenses which typically use signature based techniques and are unable to\ndetect the previously unknown malicious executables. The variants of malware\nfamilies share typical behavioral patterns reflecting their origin and purpose.\nThe behavioral patterns obtained either statically or dynamically can be\nexploited to detect and classify unknown malware into their known families\nusing machine learning techniques. This survey paper provides an overview of\ntechniques and tools for detecting and analyzing the malware.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 07:52:47 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 20:32:22 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Talukder", "Sajedul", ""]]}, {"id": "2002.06852", "submitter": "Zhaohua Chen", "authors": "Hongyin Chen, Zhaohua Chen, Yukun Cheng, Xiaotie Deng, Wenhan Huang,\n  Jichen Li, Hongyi Ling, Mengqian Zhang", "title": "An Efficient Permissioned Blockchain with Provable Reputation Mechanism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of permissioned blockchains places an access control requirement\nfor members to read, access, and write information over the blockchains. In\nthis paper, we study a hierarchical scenario to include three types of\nparticipants: providers, collectors, and governors. To be specific, providers\nforward transactions, collected from terminals, to collectors; collectors\nupload received transactions to governors after verifying and labeling them;\nand governors validate a part of received labeled transactions, pack valid ones\ninto a block, and append a new block on the ledger. Collectors in the\nhierarchical model play a crucial role in the design: they have connections\nwith both providers and governors, and are responsible for collecting,\nverifying, and uploading transactions. However, collectors are rational and\nsome of them may behave maliciously (not necessarily for their own benefits).\nIn this paper, we introduce a reputation protocol as a measure of the\nreliability of collectors in the permissioned blockchain environment. Its\nobjective is to encourage collectors to behave truthfully and, in addition, to\nreduce the verification cost. The verification cost on provider $p$ is defined\nas the total number of invalid transactions provided by $p$ and checked by\ngovernors. Through theoretical analysis, our protocol with the reputation\nmechanism has a significant improvement in efficiency. Specifically, the\nverification loss that governors suffer is proved to be asymptotically\n$O(\\sqrt{T_{total}})$ ($T_{total}$, representing the number of transactions\nverified by governors and provided by $p$), as long as there exists at least\none collector who behaves well. At last, two typical cases where our model can\nbe well applied are also demonstrated.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 09:25:59 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 08:42:17 GMT"}, {"version": "v3", "created": "Mon, 25 Jan 2021 12:28:02 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Chen", "Hongyin", ""], ["Chen", "Zhaohua", ""], ["Cheng", "Yukun", ""], ["Deng", "Xiaotie", ""], ["Huang", "Wenhan", ""], ["Li", "Jichen", ""], ["Ling", "Hongyi", ""], ["Zhang", "Mengqian", ""]]}, {"id": "2002.06938", "submitter": "Tom Mahler", "authors": "Tom Mahler, Yuval Elovici, Yuval Shahar", "title": "A New Methodology for Information Security Risk Assessment for Medical\n  Devices and Its Evaluation", "comments": "24 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As technology advances towards more connected and digital environments,\nmedical devices are becoming increasingly connected to hospital networks and to\nthe Internet, which exposes them, and thus the patients using them, to new\ncybersecurity threats. Currently, there is a lack of a methodology dedicated to\ninformation security risk assessment for medical devices.\n  In this study, we present the Threat identification, ontology-based\nLikelihood, severity Decomposition, and Risk integration (TLDR) methodology for\ninformation security risk assessment for medical devices. The TLDR methodology\nuses the following steps: (1) identifying the potentially vulnerable components\nof medical devices, in this case, four different medical imaging devices\n(MIDs); (2) identifying the potential attacks, in this case, 23 potential\nattacks on MIDs; (3) mapping the discovered attacks into a known attack\nontology - in this case, the Common Attack Pattern Enumeration and\nClassifications (CAPECs); (4) estimating the likelihood of the mapped CAPECs in\nthe medical domain with the assistance of a panel of senior healthcare\nInformation Security Experts (ISEs); (5) computing the CAPEC-based likelihood\nestimates of each attack; (6) decomposing each attack into several severity\naspects and assigning them weights; (7) assessing the magnitude of the impact\nof each of the severity aspects for each attack with the assistance of a panel\nof senior Medical Experts (MEs); (8) computing the composite severity\nassessments for each attack; and finally, (9) integrating the likelihood and\nseverity of each attack into its risk, and thus prioritizing it. The details of\nsteps six to eight are beyond the scope of the current study; in the current\nstudy, we had replaced them by a single step that included asking the panel of\nMEs [in this case, radiologists], to assess the overall severity for each\nattack and use it as its severity...\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 13:10:43 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Mahler", "Tom", ""], ["Elovici", "Yuval", ""], ["Shahar", "Yuval", ""]]}, {"id": "2002.06993", "submitter": "Alexander Spiegelman", "authors": "Alexander Spiegelman", "title": "In Search for a Linear Byzantine Agreement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The long-standing byzantine agreement problem gets more attention in recent\nyears due to the increasing demand for scalable geo-replicated Byzantine state\nmachine replication (SMR) systems (e.g., Blockchains). To date, the key\nbottleneck of such systems is the communication cost of the byzantine agreement\nthey employ as a building block, which motivates many researchers to search for\nlow-communication byzantine agreement protocols. The conventional approach is\nto design deterministic protocols in the eventually synchronous communication\nmodel that are optimized to reduce the communication cost after the global\nstabilization time (GST).\n  In this paper, we challenge the conventional approach and argue it is not the\nbest fit for scalable SMR systems since it might induce an unbounded\ncommunication cost during asynchronous periods before GST, which we prove to be\ninherent. Instead, we forgo eventual synchrony and propose a different approach\nthat hopes for the best (synchrony) but prepares for the worst (asynchrony).\nAccordingly, we design an optimistic protocol that first tries to reach an\nagreement via an efficient deterministic algorithm that relies on synchrony for\ntermination, and then, only if an agreement was not reached due to asynchrony,\nthe protocol uses a randomized asynchronous algorithm for fallback that\nguarantees termination with probability $1$. Although randomized asynchronous\nalgorithms are considered to be costly, we design our solution to pay this cost\nonly when an equivalent cost has already been paid while unsuccessfully trying\nthe synchronous protocol. Moreover, we formally prove that our protocol\nachieves optimal communication complexity under all network conditions and\nfailure scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 15:07:44 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Spiegelman", "Alexander", ""]]}, {"id": "2002.07041", "submitter": "Markku-Juhani Saarinen", "authors": "Markku-Juhani O. Saarinen", "title": "A Lightweight ISA Extension for AES and SM4", "comments": "4 Pages. First International Workshop on Secure RISC-V Architecture\n  Design Exploration (SECRISC-V'20). Held in conjunction with the IEEE\n  International Symposium on Performance Analysis of Systems and Software\n  (ISPASS) - August 23rd, 2020 in Boston, Massachusetts, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a lightweight RISC-V ISA extension for AES and SM4 block ciphers.\nSixteen instructions (and a subkey load) is required to implement an AES round\nwith the extension, instead of 80 without. An SM4 step (quarter-round) has 6.5\narithmetic instructions, a similar reduction. Perhaps even more importantly the\nISA extension helps to eliminate slow, secret-dependent table lookups and to\nprotect against cache timing side-channel attacks. Having only one S-box, the\nextension has a minimal hardware size and is well suited for ultra-low power\napplications. AES and SM4 implementations using the ISA extension also have a\nmuch-reduced software footprint. The AES and SM4 instances can share the same\ndata paths but are independent in the sense that a chip designer can implement\nSM4 without AES and vice versa. Full AES and SM4 assembler listings, HDL source\ncode for instruction's combinatorial logic, and C code for emulation is\nprovided to the community under a permissive open source license. The\nimplementation contains depth- and size-optimized joint AES and SM4 S-Box logic\nbased on the Boyar-Peralta construction with a shared non-linear middle layer,\ndemonstrating additional avenues for logic optimization. The instruction logic\nhas been experimentally integrated into the single-cycle execution path of the\n\"Pluto\" RV32 core and has been tested on an FPGA system.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 16:31:49 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 14:41:34 GMT"}, {"version": "v3", "created": "Fri, 20 Mar 2020 20:10:22 GMT"}, {"version": "v4", "created": "Tue, 11 Aug 2020 10:04:05 GMT"}, {"version": "v5", "created": "Sat, 15 Aug 2020 23:52:13 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Saarinen", "Markku-Juhani O.", ""]]}, {"id": "2002.07068", "submitter": "Ehsan Meamari", "authors": "Ehsan Meamari and Chien-Chung Shen", "title": "Profit from Two Bitcoin Mining Tactics: Towing and Shutdown", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since Bitcoin's inception in 2008, it has became attractive investments for\nboth trading and mining. To mine Bitcoins, a miner has to invest in computing\npower and pay for electricity to solve cryptographic puzzles for rewards, if it\nbecomes the first to solve a puzzle, paid in Bitcoin. Given that mining is such\na resource intensive effort, miners seek new strategies trying to make the\nmining process more profitable.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 01:08:47 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Meamari", "Ehsan", ""], ["Shen", "Chien-Chung", ""]]}, {"id": "2002.07088", "submitter": "Ryan Feng", "authors": "Ryan Feng, Jiefeng Chen, Earlence Fernandes, Somesh Jha, Atul Prakash", "title": "Robust Physical Hard-Label Attacks on Deep Learning Visual\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing physical adversarial examples for computer vision rely on white-box\naccess. In this work, we investigate physical examples in the black-box\nhard-label case -- where the attacker has only query access to the model and\nonly receives the top-1 class label without confidence information. This threat\nmodel is more realistic for cyber-physical systems -- the main target when\nconsidering physical attacks on computer vision. Key challenges in this setting\ninclude obtaining reliability against environmental variations and creating\narea-limited perturbations without access to model gradients. We base our work\non recent advances in gradient-free optimization and present GRAPHITE, the\nfirst algorithm for black-box hard-label physical attacks on computer vision\nmodels. We evaluate GRAPHITE on a traffic sign classifier and a\npublicly-available Automatic License Plate Recognition (ALPR) tool using only\nquery access. We successfully cause a Stop sign to be misclassified as a Speed\nLimit 30 in 92.9% of physical test images and cause errors in 95% of cases for\nthe ALPR tool.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 17:24:14 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 21:13:32 GMT"}, {"version": "v3", "created": "Thu, 17 Dec 2020 21:01:43 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Feng", "Ryan", ""], ["Chen", "Jiefeng", ""], ["Fernandes", "Earlence", ""], ["Jha", "Somesh", ""], ["Prakash", "Atul", ""]]}, {"id": "2002.07111", "submitter": "Muhammad Umer", "authors": "Muhammad Umer, Glenn Dawson, Robi Polikar", "title": "Targeted Forgetting and False Memory Formation in Continual Learners\n  through Adversarial Backdoor Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks are well-known to be susceptible to catastrophic\nforgetting when continually learning from sequences of tasks. Various continual\n(or \"incremental\") learning approaches have been proposed to avoid catastrophic\nforgetting, but they are typically adversary agnostic, i.e., they do not\nconsider the possibility of a malicious attack. In this effort, we explore the\nvulnerability of Elastic Weight Consolidation (EWC), a popular continual\nlearning algorithm for avoiding catastrophic forgetting. We show that an\nintelligent adversary can bypass the EWC's defenses, and instead cause gradual\nand deliberate forgetting by introducing small amounts of misinformation to the\nmodel during training. We demonstrate such an adversary's ability to assume\ncontrol of the model via injection of \"backdoor\" attack samples on both\npermuted and split benchmark variants of the MNIST dataset. Importantly, once\nthe model has learned the adversarial misinformation, the adversary can then\ncontrol the amount of forgetting of any task. Equivalently, the malicious actor\ncan create a \"false memory\" about any task by inserting carefully-designed\nbackdoor samples to any fraction of the test instances of that task. Perhaps\nmost damaging, we show this vulnerability to be very acute; neural network\nmemory can be easily compromised with the addition of backdoor samples into as\nlittle as 1% of the training data of even a single task.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 18:13:09 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Umer", "Muhammad", ""], ["Dawson", "Glenn", ""], ["Polikar", "Robi", ""]]}, {"id": "2002.07135", "submitter": "Mamdouh Alenezi", "authors": "Mamdouh Alenezi and Mohammad Zarour", "title": "On the Relationship between Software Complexity and Security", "comments": null, "journal-ref": "International Journal of Software Engineering & Applications\n  (IJSEA), Vol.11, No.1, January 2020", "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work aims at discussing the complexity aspect of software while\ndemonstrating its relationship with security. Complexity is an essential part\nof software; however, numerous studies indicate that they increase the\nvulnerability of the software systems and introduce bugs in the program. Many\ndevelopers face difficulty when trying to understand the complex components of\nsoftware. Complexity in software increases when objects in the software are\nused to design a more complex object while creating a hierarchical complexity\nin the system. However, it is necessary for the developers to strive for\nminimum complexity, as increased complexity introduces security risks in the\nsoftware, which can cause severe monetary and reputational damage to a\ngovernment or a private organization. It even causes bodily harm to human\nbeings with various examples found in previous years where security breaches\nled to severe consequences. Hence it is vital to maintain low complexity and\nsimple design of structure. Various developers tend to introduce deliberate\ncomplexities in the system so that they do not have to write the same program\ntwice; however, it is getting problematic for the software organizations as the\ndemands of security are continually increasing.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 04:15:31 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Alenezi", "Mamdouh", ""], ["Zarour", "Mohammad", ""]]}, {"id": "2002.07175", "submitter": "Umut Can Cabuk", "authors": "Umut Can Cabuk, Eylul Adiguzel, Enis Karaarslan", "title": "A Survey on Feasibility and Suitability of Blockchain Techniques for the\n  E-Voting Systems", "comments": null, "journal-ref": "International Journal of Advanced Research in Computer and\n  Communication Engineering (IJARCCE), Vol. 7, Issue 3, March 2018", "doi": "10.17148/IJARCCE.2018.7324", "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the second decade of the 21st century, blockchain definitely became one of\nthe most trending computational technologies. This research aims to question\nthe feasibility and suitability of using blockchain technology within e-voting\nsystems, regarding both technical and non-technical aspects. In today's world,\nalthough the course of this spreading is considerably slow, several countries\nalready use means of e-voting due to many social and economic reasons, which we\nfurther investigated. Nevertheless, the number of countries offering various\ne-government solutions, apart from e-voting, is significantly high. E-voting\nsystems, naturally, require much more attention and assurance regarding\npotential security and anonymity issues, since voting is one of the few\nextremely critical governmental processes. Nevertheless, e-voting is not purely\na governmental service, but many companies and nonprofit organizations would\nbenefit the cost-efficiency, scalability, remote accessibility, and ease of use\nthat it provides. Blockchain technology is claimed to be able to address some,\nobviously not all, important security concerns, including anonymity,\nconfidentiality, integrity, and non-repudiation. The analysis results presented\nin this article mostly confirm these claims.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 11:19:54 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Cabuk", "Umut Can", ""], ["Adiguzel", "Eylul", ""], ["Karaarslan", "Enis", ""]]}, {"id": "2002.07214", "submitter": "Ziwei Guan", "authors": "Ziwei Guan, Kaiyi Ji, Donald J Bucci Jr, Timothy Y Hu, Joseph Palombo,\n  Michael Liston, Yingbin Liang", "title": "Robust Stochastic Bandit Algorithms under Probabilistic Unbounded\n  Adversarial Attack", "comments": "Published at AAAI'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multi-armed bandit formalism has been extensively studied under various\nattack models, in which an adversary can modify the reward revealed to the\nplayer. Previous studies focused on scenarios where the attack value either is\nbounded at each round or has a vanishing probability of occurrence. These\nmodels do not capture powerful adversaries that can catastrophically perturb\nthe revealed reward. This paper investigates the attack model where an\nadversary attacks with a certain probability at each round, and its attack\nvalue can be arbitrary and unbounded if it attacks. Furthermore, the attack\nvalue does not necessarily follow a statistical distribution. We propose a\nnovel sample median-based and exploration-aided UCB algorithm (called\nmed-E-UCB) and a median-based $\\epsilon$-greedy algorithm (called\nmed-$\\epsilon$-greedy). Both of these algorithms are provably robust to the\naforementioned attack model. More specifically we show that both algorithms\nachieve $\\mathcal{O}(\\log T)$ pseudo-regret (i.e., the optimal regret without\nattacks). We also provide a high probability guarantee of $\\mathcal{O}(\\log T)$\nregret with respect to random rewards and random occurrence of attacks. These\nbounds are achieved under arbitrary and unbounded reward perturbation as long\nas the attack probability does not exceed a certain constant threshold. We\nprovide multiple synthetic simulations of the proposed algorithms to verify\nthese claims and showcase the inability of existing techniques to achieve\nsublinear regret. We also provide experimental results of the algorithm\noperating in a cognitive radio setting using multiple software-defined radios.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 19:21:08 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Guan", "Ziwei", ""], ["Ji", "Kaiyi", ""], ["Bucci", "Donald J", "Jr"], ["Hu", "Timothy Y", ""], ["Palombo", "Joseph", ""], ["Liston", "Michael", ""], ["Liang", "Yingbin", ""]]}, {"id": "2002.07218", "submitter": "Ugo Dal Lago", "authors": "Boaz Barak, Rapha\\\"elle Crubill\\'e, Ugo Dal Lago", "title": "On Higher-Order Cryptography (Long Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Type-two constructions abound in cryptography: adversaries for encryption and\nauthentication schemes, if active, are modeled as algorithms having access to\noracles, i.e. as second-order algorithms. But how about making cryptographic\nschemes themselves higher-order? This paper gives an answer to this question,\nby first describing why higher-order cryptography is interesting as an object\nof study, then showing how the concept of probabilistic polynomial time\nalgorithm can be generalized so as to encompass algorithms of order strictly\nhigher than two, and finally proving some positive and negative results about\nthe existence of higher-order cryptographic primitives, namely authentication\nschemes and pseudorandom functions.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 19:25:22 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Barak", "Boaz", ""], ["Crubill\u00e9", "Rapha\u00eblle", ""], ["Lago", "Ugo Dal", ""]]}, {"id": "2002.07223", "submitter": "AlMaha Abuzraiq", "authors": "Almaha Abuzuraiq, Mouhammd Alkasassbeh, and Mohammad Almseidin", "title": "Intelligent Methods for Accurately Detecting Phishing Websites", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With increasing technology developments, there is a massive number of\nwebsites with varying purposes. But a particular type exists within this large\ncollection, the so-called phishing sites which aim to deceive their users. The\nmain challenge in detecting phishing websites is discovering the techniques\nthat have been used. Where phishers are continually improving their strategies\nand creating web pages that can protect themselves against many forms of\ndetection methods. Therefore, it is very necessary to develop reliable, active\nand contemporary methods of phishing detection to combat the adaptive\ntechniques used by phishers. In this paper, different phishing detection\napproaches are reviewed by classifying them into three main groups. Then, the\nproposed model is presented in two stages. In the first stage, different\nmachine learning algorithms are applied to validate the chosen dataset and\napplying features selection methods on it. Thus, the best accuracy was achieved\nby utilizing only 20 features out of 48 features combined with Random Forest is\n98.11%. While in the second stage, the same dataset is applied to various fuzzy\nlogic algorithms. As well the experimental results from the application of\nFuzzy logic algorithms were incredible. Where in applying the FURIA algorithm\nwith only five features the accuracy rate was 99.98%. Finally, comparison and\ndiscussion of the results between applying machine learning algorithms and\nfuzzy logic algorithms is done. Where the performance of using fuzzy logic\nalgorithms exceeds the use of machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 19:57:03 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Abuzuraiq", "Almaha", ""], ["Alkasassbeh", "Mouhammd", ""], ["Almseidin", "Mohammad", ""]]}, {"id": "2002.07235", "submitter": "Sumegha Garg", "authors": "Sumegha Garg, Pravesh K. Kothari, Ran Raz", "title": "Time-Space Tradeoffs for Distinguishing Distributions and Applications\n  to Security of Goldreich's PRG", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we establish lower-bounds against memory bounded algorithms for\ndistinguishing between natural pairs of related distributions from samples that\narrive in a streaming setting.\n  In our first result, we show that any algorithm that distinguishes between\nuniform distribution on $\\{0,1\\}^n$ and uniform distribution on an\n$n/2$-dimensional linear subspace of $\\{0,1\\}^n$ with non-negligible advantage\nneeds $2^{\\Omega(n)}$ samples or $\\Omega(n^2)$ memory.\n  Our second result applies to distinguishing outputs of Goldreich's local\npseudorandom generator from the uniform distribution on the output domain.\nSpecifically, Goldreich's pseudorandom generator $G$ fixes a predicate\n$P:\\{0,1\\}^k \\rightarrow \\{0,1\\}$ and a collection of subsets $S_1, S_2,\n\\ldots, S_m \\subseteq [n]$ of size $k$. For any seed $x \\in \\{0,1\\}^n$, it\noutputs $P(x_{S_1}), P(x_{S_2}), \\ldots, P(x_{S_m})$ where $x_{S_i}$ is the\nprojection of $x$ to the coordinates in $S_i$. We prove that whenever $P$ is\n$t$-resilient (all non-zero Fourier coefficients of $(-1)^P$ are of degree $t$\nor higher), then no algorithm, with $<n^\\epsilon$ memory, can distinguish the\noutput of $G$ from the uniform distribution on $\\{0,1\\}^m$ with a large inverse\npolynomial advantage, for stretch $m \\le\n\\left(\\frac{n}{t}\\right)^{\\frac{(1-\\epsilon)}{36}\\cdot t}$ (barring some\nrestrictions on $k$). The lower bound holds in the streaming model where at\neach time step $i$, $S_i\\subseteq [n]$ is a randomly chosen (ordered) subset of\nsize $k$ and the distinguisher sees either $P(x_{S_i})$ or a uniformly random\nbit along with $S_i$.\n  Our proof builds on the recently developed machinery for proving time-space\ntrade-offs (Raz 2016 and follow-ups) for search/learning problems.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 20:17:05 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Garg", "Sumegha", ""], ["Kothari", "Pravesh K.", ""], ["Raz", "Ran", ""]]}, {"id": "2002.07309", "submitter": "Ross Horne", "authors": "Ross Horne and Sjouke Mauw", "title": "Discovering ePassport Vulnerabilities using Bisimilarity", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 2 (June 2,\n  2021) lmcs:7537", "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We uncover privacy vulnerabilities in the ICAO 9303 standard implemented by\nePassports worldwide. These vulnerabilities, confirmed by ICAO, enable an\nePassport holder who recently passed through a checkpoint to be reidentified\nwithout opening their ePassport. This paper explains how bisimilarity was used\nto discover these vulnerabilities, which exploit the BAC protocol - the\noriginal ICAO 9303 standard ePassport authentication protocol - and remains\nvalid for the PACE protocol, which improves on the security of BAC in the\nlatest ICAO 9303 standards. In order to tackle such bisimilarity problems, we\ndevelop here a chain of methods for the applied $\\pi$-calculus including a\nsymbolic under-approximation of bisimilarity, called open bisimilarity, and a\nmodal logic, called classical FM, for describing and certifying attacks.\nEvidence is provided to argue for a new scheme for specifying such\nunlinkability problems that more accurately reflects the capabilities of an\nattacker.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 00:26:19 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 18:24:05 GMT"}, {"version": "v3", "created": "Sun, 14 Mar 2021 18:31:43 GMT"}, {"version": "v4", "created": "Thu, 6 May 2021 10:10:34 GMT"}, {"version": "v5", "created": "Tue, 1 Jun 2021 14:29:57 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Horne", "Ross", ""], ["Mauw", "Sjouke", ""]]}, {"id": "2002.07323", "submitter": "Yang Liu", "authors": "Yang Liu, Mingxin Chen, Wenxi Zhang, Junbo Zhang, Yu Zheng", "title": "Federated Extra-Trees with Privacy Preserving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is commonly observed that the data are scattered everywhere and difficult\nto be centralized. The data privacy and security also become a sensitive topic.\nThe laws and regulations such as the European Union's General Data Protection\nRegulation (GDPR) are designed to protect the public's data privacy. However,\nmachine learning requires a large amount of data for better performance, and\nthe current circumstances put deploying real-life AI applications in an\nextremely difficult situation. To tackle these challenges, in this paper we\npropose a novel privacy-preserving federated machine learning model, named\nFederated Extra-Trees, which applies local differential privacy in the\nfederated trees model. A secure multi-institutional machine learning system was\ndeveloped to provide superior performance by processing the modeling jointly on\ndifferent clients without exchanging any raw data. We have validated the\naccuracy of our work by conducting extensive experiments on public datasets and\nthe efficiency and robustness were also verified by simulating the real-world\nscenarios. Overall, we presented an extensible, scalable and practical solution\nto handle the data island problem.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 01:15:18 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Liu", "Yang", ""], ["Chen", "Mingxin", ""], ["Zhang", "Wenxi", ""], ["Zhang", "Junbo", ""], ["Zheng", "Yu", ""]]}, {"id": "2002.07340", "submitter": "He Chen", "authors": "He Chen, Qian Wang, Parthajit Mohapatra, Nikolaos Pappas", "title": "Secure Status Updates under Eavesdropping: Age of Information-based\n  Physical Layer Security Metrics", "comments": "Submitted for possible publication. The first two authors contributed\n  equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This letter studies the problem of maintaining information freshness under\npassive eavesdropping attacks. The classical three-node wiretap channel model\nis considered, in which a source aims to send its latest status wirelessly to\nits intended destination, while protecting the message from being overheard by\nan eavesdropper. Considering that conventional channel capacity-based secrecy\nmetrics are no longer adequate to measure the information timeliness in status\nupdate systems, we define two new age of information-based metrics to\ncharacterize the secrecy performance of the considered system. We further\npropose, analyze, and optimize a randomized stationary transmission policy\nimplemented at the source for further enhancing the secrecy performance.\nSimulation results are provided to validate our analysis and optimization.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 02:32:33 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Chen", "He", ""], ["Wang", "Qian", ""], ["Mohapatra", "Parthajit", ""], ["Pappas", "Nikolaos", ""]]}, {"id": "2002.07346", "submitter": "Thuong Nguyen Canh", "authors": "Thuong Nguyen Canh and Byeungwoo Jeon", "title": "Restricted Structural Random Matrix for Compressive Sensing", "comments": "25 pages, single column, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressive sensing (CS) is well-known for its unique functionalities of\nsensing, compressing, and security (i.e. CS measurements are equally\nimportant). However, there is a tradeoff. Improving sensing and compressing\nefficiency with prior signal information tends to favor particular\nmeasurements, thus decrease the security. This work aimed to improve the\nsensing and compressing efficiency without compromise the security with a novel\nsampling matrix, named Restricted Structural Random Matrix (RSRM). RSRM unified\nthe advantages of frame-based and block-based sensing together with the global\nsmoothness prior (i.e. low-resolution signals are highly correlated). RSRM\nacquired compressive measurements with random projection (equally important) of\nmultiple randomly sub-sampled signals, which was restricted to be the\nlow-resolution signals (equal in energy), thereby, its observations are equally\nimportant. RSRM was proven to satisfies the Restricted Isometry Property and\nshows comparable reconstruction performance with recent state-of-the-art\ncompressive sensing and deep learning-based methods.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 02:52:51 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Canh", "Thuong Nguyen", ""], ["Jeon", "Byeungwoo", ""]]}, {"id": "2002.07355", "submitter": "Yanjun Pan", "authors": "Yanjun Pan, Yao Zheng and Ming Li", "title": "ROBin: Known-Plaintext Attack Resistant Orthogonal Blinding via Channel\n  Randomization", "comments": "To appear in Proceedings of INFOCOM'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Orthogonal blinding based schemes for wireless physical layer security aim to\nachieve secure communication by injecting noise into channels orthogonal to the\nmain channel and corrupting the eavesdropper's signal reception. These methods,\nalbeit practical, have been proven vulnerable against multi-antenna\neavesdroppers who can filter the message from the noise. The vulnerability is\nrooted in the fact that the main channel state remains static in spite of the\nnoise injection, which allows an eavesdropper to estimate it promptly via known\nsymbols and filter out the noise. Our proposed scheme leverages a\nreconfigurable antenna for Alice to rapidly change the channel state during\ntransmission and a compressive sensing based algorithm for her to predict and\ncancel the changing effects for Bob. As a result, the communication between\nAlice and Bob remains clear, whereas randomized channel state prevents Eve from\nlaunching the known-plaintext attack. We formally analyze the security of the\nscheme against both single and multi-antenna eavesdroppers and identify its\nunique anti-eavesdropping properties due to the artificially created\nfast-changing channel. We conduct extensive simulations and real-world\nexperiments to evaluate its performance. Empirical results show that our scheme\ncan suppress Eve's attack success rate to the level of random guessing, even if\nshe knows all the symbols transmitted through other antenna modes.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 03:52:13 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Pan", "Yanjun", ""], ["Zheng", "Yao", ""], ["Li", "Ming", ""]]}, {"id": "2002.07393", "submitter": "Nedra Benletaief", "authors": "Nedra Benletaief and Houria Rezig and Ammar Bouallegue", "title": "Experimental study of continuous variable quantum key distribution", "comments": null, "journal-ref": null, "doi": "10.1109/ISIAS.2015.7492751", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been proven in the literature that the main technological factors\nlimiting the communication rates of quantum cryptography systems by single\nphoton are mainly related to the choice of the encoding method. In fact, the\nefficiency of the used sources is very limited, at best of the order of a few\npercent for the single photon sources and the photon counters can not be\noperated beyond a certain speed and with a low order of detection efficiency.\nIn order to overcome partially these drawbacks, it is advantageous to use\ncontinuous quantum states as an alternative to standard encodings based on\nquantum qubits. In this context, we propose a new reconciliation method based\non Turbo codes. Our theoretical model assumptions are supported by experimental\nresults. Indeed, our method leads to a significant improvement of the protocol\nsecurity and a large decrease of the QBER. The gain is obtained with a\nreasonable complexity increase. Also, the novelty of our work is that it tested\nthe reconciliation method on a real photonic system under VPItransmissionMaker.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 21:50:31 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Benletaief", "Nedra", ""], ["Rezig", "Houria", ""], ["Bouallegue", "Ammar", ""]]}, {"id": "2002.07396", "submitter": "Nedra Benletaief", "authors": "Nedra Benletaief and Houria Rezig and Ammar Bouallegue", "title": "Experimental study and pratical realization of a reconciliation method\n  for quantum key distribution system", "comments": "6 pages, 9 figures, conference", "journal-ref": null, "doi": "10.1109/IACS.2016.7476111", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates a reconciliation method in order to establish an\nerrorless secret key in a QKD protocol. Classical key distribution protocols\nare no longer unconditionally secure because computational complexity of\nmathematical problems forced hardships. In this context, QKD protocols offer a\nhighest level of security because they are based on the quantum laws of\nphysics. But, the protocol performances can be lowered by multiples errors. It\nappears clearly that reconciliation should be performed in such a situation in\norder to remove the errors as for the legitimate partners. The proposed method\naccomplishes reconciliation by using QTC in the special problem of\nsideinformation source coding (Slepian-Wolf coding model). Our theoretical\nhypothesis are sustained by experimental results that confirm the advantage of\nour method in resolving reconciliation problem compared to a recent related\nwork. Indeed, the integration of our method generates an important progess in\nsecurity and a large decrease of the QBER. The gain is obtained with a\nreasonable complexity increase. Also, the novelty of our work is that it tested\nthe reconciliation method on a real photonic system under VPItransmissionMaker.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 21:40:36 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Benletaief", "Nedra", ""], ["Rezig", "Houria", ""], ["Bouallegue", "Ammar", ""]]}, {"id": "2002.07419", "submitter": "Aleksey Fedorov", "authors": "M.A. Kudinov, E.O. Kiktenko, A.K. Fedorov", "title": "Security analysis of the W-OTS$^+$ signature scheme: Updating security\n  bounds", "comments": "16 pages, 1 figure, 1 table", "journal-ref": "Mat. Vopr. Kriptogr. 12, 129 (2021)", "doi": "10.4213/mvk362", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we discuss in detail a flaw in the original security proof of\nthe W-OTS${^+}$ variant of the Winternitz one-time signature scheme, which is\nan important component for various stateless and stateful many-time hash-based\ndigital signature schemes. We update the security proof for the W-OTS${^+}$\nscheme and derive the corresponding security level. Our result is of importance\nfor the security analysis of hash-based digital signature schemes.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 07:59:59 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 08:27:26 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Kudinov", "M. A.", ""], ["Kiktenko", "E. O.", ""], ["Fedorov", "A. K.", ""]]}, {"id": "2002.07512", "submitter": "Guntur Dharma Putra", "authors": "Guntur Dharma Putra, Volkan Dedeoglu, Salil S Kanhere, Raja Jurdak", "title": "Poster Abstract: Towards Scalable and Trustworthy Decentralized\n  Collaborative Intrusion Detection System for IoT", "comments": "Accepted to ACM/IEEE IoTDI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An Intrusion Detection System (IDS) aims to alert users of incoming attacks\nby deploying a detector that monitors network traffic continuously. As an\neffort to increase detection capabilities, a set of independent IDS detectors\ntypically work collaboratively to build intelligence of holistic network\nrepresentation, which is referred to as Collaborative Intrusion Detection\nSystem (CIDS). However, developing an effective CIDS, particularly for the IoT\necosystem raises several challenges. Recent trends and advances in blockchain\ntechnology, which provides assurance in distributed trust and secure immutable\nstorage, may contribute towards the design of effective CIDS. In this poster\nabstract, we present our ongoing work on a decentralized CIDS for IoT, which is\nbased on blockchain technology. We propose an architecture that provides\naccountable trust establishment, which promotes incentives and penalties, and\nscalable intrusion information storage by exchanging bloom filters. We are\ncurrently implementing a proof-of-concept of our modular architecture in a\nlocal test-bed and evaluate its effectiveness in detecting common attacks in\nIoT networks and the associated overhead.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 12:15:26 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Putra", "Guntur Dharma", ""], ["Dedeoglu", "Volkan", ""], ["Kanhere", "Salil S", ""], ["Jurdak", "Raja", ""]]}, {"id": "2002.07539", "submitter": "Oded Naor", "authors": "Oded Naor, Idit Keidar", "title": "Expected Linear Round Synchronization: The Missing Link for Linear\n  Byzantine SMR", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State Machine Replication (SMR) solutions often divide time into rounds, with\na designated leader driving decisions in each round. Progress is guaranteed\nonce all correct processes synchronize to the same round, and the leader of\nthat round is correct. Recently suggested Byzantine SMR solutions such as\nHotStuff, Tendermint, and LibraBFT achieve progress with a linear message\ncomplexity and a constant time complexity once such round synchronization\noccurs. But round synchronization itself incurs an additional cost. By Dolev\nand Reischuk's lower bound, any deterministic solution must have $\\Omega(n^2)$\ncommunication complexity. Yet the question of randomized round synchronization\nwith an expected linear message complexity remained open.\n  We present an algorithm that, for the first time, achieves round\nsynchronization with expected linear message complexity and expected constant\nlatency. Existing protocols can use our round synchronization algorithm to\nsolve Byzantine SMR with the same asymptotic performance.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 13:11:51 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 07:40:26 GMT"}, {"version": "v3", "created": "Mon, 10 Aug 2020 08:24:12 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Naor", "Oded", ""], ["Keidar", "Idit", ""]]}, {"id": "2002.07648", "submitter": "Lum Ramabaja", "authors": "Lum Ramabaja, Arber Avdullahu", "title": "Compact Merkle Multiproofs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The compact Merkle multiproof is a new and significantly more\nmemory-efficient way to generate and verify sparse Merkle multiproofs. A\nstandard sparse Merkle multiproof requires to store an index for every non-leaf\nhash in the multiproof. The compact Merkle multiproof on the other hand\nrequires only $k$ leaf indices, where $k$ is the number of elements used for\ncreating a multiproof. This significantly reduces the size of multirpoofs,\nespecially for larger Merke trees.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 15:35:47 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 18:14:29 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Ramabaja", "Lum", ""], ["Avdullahu", "Arber", ""]]}, {"id": "2002.07687", "submitter": "Zhichuang Sun", "authors": "Zhichuang Sun, Ruimin Sun, Long Lu, Alan Mislove", "title": "Mind Your Weight(s): A Large-scale Study on Insufficient Machine\n  Learning Model Protection in Mobile Apps", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On-device machine learning (ML) is quickly gaining popularity among mobile\napps. It allows offline model inference while preserving user privacy. However,\nML models, considered as core intellectual properties of model owners, are now\nstored on billions of untrusted devices and subject to potential thefts. Leaked\nmodels can cause both severe financial loss and security consequences. This\npaper presents the first empirical study of ML model protection on mobile\ndevices. Our study aims to answer three open questions with quantitative\nevidence: How widely is model protection used in apps? How robust are existing\nmodel protection techniques? What impacts can (stolen) models incur? To that\nend, we built a simple app analysis pipeline and analyzed 46,753 popular apps\ncollected from the US and Chinese app markets. We identified 1,468 ML apps\nspanning all popular app categories. We found that, alarmingly, 41% of ML apps\ndo not protect their models at all, which can be trivially stolen from app\npackages. Even for those apps that use model protection or encryption, we were\nable to extract the models from 66% of them via unsophisticated dynamic\nanalysis techniques. The extracted models are mostly commercial products and\nused for face recognition, liveness detection, ID/bank card recognition, and\nmalware detection. We quantitatively estimated the potential financial and\nsecurity impact of a leaked model, which can amount to millions of dollars for\ndifferent stakeholders. Our study reveals that on-device models are currently\nat high risk of being leaked; attackers are highly motivated to steal such\nmodels. Drawn from our large-scale study, we report our insights into this\nemerging security problem and discuss the technical challenges, hoping to\ninspire future research on robust and practical model protection for mobile\ndevices.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:14:37 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 22:35:34 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Sun", "Zhichuang", ""], ["Sun", "Ruimin", ""], ["Lu", "Long", ""], ["Mislove", "Alan", ""]]}, {"id": "2002.07722", "submitter": "Erivelton Geraldo Nepomuceno", "authors": "R. C. Gonzalez, E. G. Nepomuceno", "title": "Image encryption based on flexible computing of chaotic systems", "comments": "DINCON 2019 - Conferencia Brasileira de Dinamica, Controle e\n  Aplicacoes. Sao Carlos (SP). Brazil. 7 pages. In Portuguese", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increase in data traffic on the internet has significantly increased the\nrelevance of data and image encryption. Among the techniques most used in\ncryptography, chaotic systems have received great attention due to their easy\nimplementation. However, it has recently been observed that these systems can\nlose their chaotic properties due to the finite precision of computers. In this\nwork, we intend to investigate flexible computing tools, particularly interval\nanalysis, to reduce this problem. We opted for the Lorenz System, as it is one\nof the few systems whose chaoticity is proven analytically. The results of this\nstudy, based on the correlation and entropy indexes, were superior to other\nstudies published in the recent literature.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:49:11 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Gonzalez", "R. C.", ""], ["Nepomuceno", "E. G.", ""]]}, {"id": "2002.07747", "submitter": "Sebastian Henningsen", "authors": "Sebastian Henningsen and Martin Florian and Sebastian Rust and Bj\\\"orn\n  Scheuermann", "title": "Mapping the Interplanetary Filesystem", "comments": "The code can be found at https://github.com/scriptkitty/ipfs-crawler", "journal-ref": "Proceedings of IFIP Networking 2020", "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Interplanetary Filesystem (IPFS) is a distributed data storage service\nfrequently used by blockchain applications and for sharing content in a\ncensorship-resistant manner. Data is distributed within an open set of peers\nusing a Kademlia-based distributed hash table (DHT). In this paper, we study\nthe structure of the resulting overlay network, as it significantly influences\nthe robustness and performance of IPFS. We monitor and systematically crawl\nIPFS' DHT towards mapping the IPFS overlay network. Our measurements found an\naverage of 44474 nodes at every given time. At least 52.19% of these reside\nbehind a NAT and are not reachable from the outside, suggesting that a large\nshare of the network is operated by private individuals on an as-needed basis.\nBased on our measurements and our analysis of the IPFS code, we conclude that\nthe topology of the IPFS network is, in its current state, closer to an\nunstructured overlay network than it is to a classical DHT. While such a\nstructure has benefits for robustness and the resistance against Sybil attacks,\nit leaves room for improvement in terms of performance and query privacy.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 17:27:03 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Henningsen", "Sebastian", ""], ["Florian", "Martin", ""], ["Rust", "Sebastian", ""], ["Scheuermann", "Bj\u00f6rn", ""]]}, {"id": "2002.07748", "submitter": "Xiaozhu Meng", "authors": "Xiaozhu Meng, Buddhika Chamith, Ryan Newton", "title": "Profile-Guided, Multi-Version Binary Rewriting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The static instrumentation of machine code, also known as binary rewriting,\nis a power technique, but suffers from high runtime overhead compared to\ncompiler-level instrumentation. Recent research has shown that tools can\nachieve near-to-zero overhead when rewriting binaries (excluding the overhead\nfrom the application specific instrumentation). However, the users of binary\nrewriting tools often have difficulties in understanding why their\ninstrumentation is slow and how to optimize their instrumentation.\n  We are inspired by a traditional program optimization workflow, where one can\nprofile the program execution to identify performance hot spots, modify the\nsource code or apply suitable compiler optimizations, and even apply\nprofile-guided optimization. We present profile-guided, Multi-Version Binary\nRewriting to enable this optimization workflow for static binary\ninstrumentation. Our new techniques include three components. First, we augment\nexisting binary rewriting to support call path profiling; one can interactively\nview instrumentation costs and understand the calling contexts where the costs\nincur. Second, we present Versioned Structure Binary Editing, which is a\ngeneral binary transformation technique. Third, we use call path profiles to\nguide the application of binary transformation.\n  We apply our new techniques to shadow stack and basic block code coverage.\nOur instrumentation optimization workflow helps us identify several\nopportunities with regard to code transformation and instrumentation data\nlayout. Our evaluation on SPEC CPU 2017 shows that the geometric overhead of\nshadow stack and block coverage is reduced from 7.6% and 161.3% to 1.4% and\n4.0%, respectively. We also achieve promising results on Apache HTTP Server,\nwhere the shadow stack overhead is reduced from about 20% to 3.5%.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 17:30:51 GMT"}, {"version": "v2", "created": "Sat, 8 May 2021 16:32:11 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Meng", "Xiaozhu", ""], ["Chamith", "Buddhika", ""], ["Newton", "Ryan", ""]]}, {"id": "2002.07750", "submitter": "Zhen Chen", "authors": "Zhen Chen, Zhuqing Jia, Zhiying Wang and Syed A. Jafar", "title": "GCSA Codes with Noise Alignment for Secure Coded Multi-Party Batch\n  Matrix Multiplication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A secure multi-party batch matrix multiplication problem (SMBMM) is\nconsidered, where the goal is to allow a master to efficiently compute the\npairwise products of two batches of massive matrices, by distributing the\ncomputation across S servers. Any X colluding servers gain no information about\nthe input, and the master gains no additional information about the input\nbeyond the product. A solution called Generalized Cross Subspace Alignment\ncodes with Noise Alignment (GCSA-NA) is proposed in this work, based on\ncross-subspace alignment codes. The state of art solution to SMBMM is a coding\nscheme called polynomial sharing (PS) that was proposed by Nodehi and\nMaddah-Ali. GCSA-NA outperforms PS codes in several key aspects - more\nefficient and secure inter-server communication, lower latency, flexible\ninter-server network topology, efficient batch processing, and tolerance to\nstragglers. The idea of noise alignment can also be combined with N-source\nCross Subspace Alignment (N-CSA) codes and fast matrix multiplication\nalgorithms like Strassen's construction. Moreover, noise alignment can be\napplied to symmetric secure private information retrieval to achieve the\nasymptotic capacity.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 17:36:56 GMT"}, {"version": "v2", "created": "Sun, 6 Sep 2020 05:46:43 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Chen", "Zhen", ""], ["Jia", "Zhuqing", ""], ["Wang", "Zhiying", ""], ["Jafar", "Syed A.", ""]]}, {"id": "2002.07763", "submitter": "Quentin Bramas", "authors": "Jean-Philippe Abegg (ICube, UNISTRA), Quentin Bramas (ICube, UNISTRA),\n  Thomas Noel (ICube, UNISTRA)", "title": "Blockchain using Proof-of-Interaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper we define a new Puzzle called Proof-of-Interaction and we show how\nit can replace, in the Bitcoin protocol, the Proof-of-Work algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 12:55:50 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Abegg", "Jean-Philippe", "", "ICube, UNISTRA"], ["Bramas", "Quentin", "", "ICube, UNISTRA"], ["Noel", "Thomas", "", "ICube, UNISTRA"]]}, {"id": "2002.07769", "submitter": "Issam Damaj", "authors": "Fatma Qatan, Issam Damaj (American University of Kuwait)", "title": "High-speed KATAN Ciphers on-a-Chip", "comments": "6 pages, 8 figures, 5 tables", "journal-ref": "International Conference on Computer Systems and Industrial\n  Informatics. IEEE. Sharjah. United Arab Emirates. (2012)1-6", "doi": "10.1109/ICCSII.2012.6454511", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security in embedded systems has become a main requirement in modern\nelectronic devices. The demand for low-cost and highly secure cryptographic\nalgorithms is increasingly growing in fields such as mobile telecommunications,\nhandheld devices, etc. In this paper, we analyze and evaluate the development\nof cheap and relatively fast hardware implementations of the KATAN family of\nblock ciphers. KATAN is a family of six hardware oriented block ciphers. All\nKATAN ciphers share an 80-bit key and have 32, 48, or 64-bit blocks. We use\nVHDL under Altera Quartus in conjunction with ModelSim to implement and analyze\nour hardware designs. The developed designs are mapped onto high-performance\nField Programmable Gate Arrays. We compare our findings with similar hardware\nimplementations and C software versions of the algorithms. The performance\nanalysis of the C implementations is done using Intel Vtune Amplifier running\non Dell precision T7500 with its dual quad-core Xeon processor and 24 GB of\nRAM. The obtained results show better performance when compared with existing\nhardware and software implementations.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 22:55:44 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Qatan", "Fatma", "", "American University of Kuwait"], ["Damaj", "Issam", "", "American University of Kuwait"]]}, {"id": "2002.07778", "submitter": "Nedra Benletaief", "authors": "Nedra Benletaief and Houria Rezig and Ammar Bouallegue", "title": "Reconciliation for Practical Quantum Key Distribution with BB84 protocol", "comments": "4 pages, 7 figures, conference. arXiv admin note: text overlap with\n  arXiv:2002.04887; text overlap with arXiv:quant-ph/0406001 by other authors", "journal-ref": null, "doi": "10.1109/MMS.2011.6068566", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates a new information reconciliation method for quantum\nkey distribution in the case where two parties exchange key in the presence of\na malevolent eavesdropper. We have observed that reconciliation is a special\ncase of channel coding and for that existing techniques can be adapted for\nreconciliation. We describe an explicit reconciliation method based on Turbo\ncodes. We believe that the proposed method can improve the efficiency of\nquantum key distribution protocols based on discrete quantum states.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 20:46:18 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Benletaief", "Nedra", ""], ["Rezig", "Houria", ""], ["Bouallegue", "Ammar", ""]]}, {"id": "2002.07811", "submitter": "Ehsan Meamari", "authors": "Ehsan Meamari, Hao Guo, Chien-Chung Shen and Junbeom Hur", "title": "Collusion Attacks on Decentralized Attributed-Based Encryption: Analyses\n  and a Solution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribute-based Encryption (ABE) is an information centric security solution\nthat moves beyond traditional restrictions of point-to-point encryption by\nallowing for flexible, fine-grain policy-based and content-based access control\nthat is cryptographically enforced. As the original ABE systems are managed by\na single authority, several efforts have decentralized different ABE schemes to\naddress the key escrow problem, where the authority can issue secret keys to\nitself to decrypt all the ciphertext. However, decentralized ABE (DABE) schemes\nraise the issue of collusion attacks. In this paper, we review two existing\ntypes of collusion attacks on DABE systems, and introduce a new type of\ncollusion among authorities and data users. We show that six existing DABE\nsystems are vulnerable to the newly introduced collusion and propose a model to\nsecure one of the DABE schemes.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 04:30:46 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Meamari", "Ehsan", ""], ["Guo", "Hao", ""], ["Shen", "Chien-Chung", ""], ["Hur", "Junbeom", ""]]}, {"id": "2002.07838", "submitter": "Stephen Moskal", "authors": "Stephen Moskal and Shanchieh Jay Yang", "title": "Cyberattack Action-Intent-Framework for Mapping Intrusion Observables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The techniques and tactics used by cyber adversaries are becoming more\nsophisticated, ironically, as defense getting stronger and the cost of a breach\ncontinuing to rise. Understanding the thought processes and behaviors of\nadversaries is extremely challenging as high profile or even amateur attackers\nhave no incentive to share the trades associated with their illegal activities.\nOne opportunity to observe the actions the adversaries perform is through the\nuse of Intrusion Detection Systems (IDS) which generate alerts in the event\nthat suspicious behavior was detected. The alerts raised by these systems\ntypically describe the suspicious actions via the form of attack 'signature',\nwhich do not necessarily reveal the true intent of the attacker performing the\naction. Meanwhile, several high level frameworks exist to describe the sequence\nor chain of action types an adversary might perform. These frameworks, however,\ndo not connect the action types to observables of standard intrusion detection\nsystems, nor describing the plausible intents of the adversarial actions. To\naddress these gaps, this work proposes the Action-Intent Framework (AIF) to\ncomplement existing Cyber Attack Kill Chains and Attack Taxonomies. The AIF\ndefines a set of Action-Intent States (AIS) at two levels of description: the\nMacro-AIS describes 'what' the attacker is trying to achieve and the Micro-AIS\ndescribes \"how\" the intended goal is achieved. A full description of both the\nMacro is provided along with a set of guiding principals of how the AIS is\nderived and added to the framework.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 19:22:31 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 16:04:19 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Moskal", "Stephen", ""], ["Yang", "Shanchieh Jay", ""]]}, {"id": "2002.07841", "submitter": "Nedra Benletaief", "authors": "Nedra Benletaief and Houria Rezig and Ammar Bouallegue", "title": "Performance of a reconciliation method operating on a discreet quantum\n  key distribution system", "comments": "4 pages, 8 figures, conference. arXiv admin note: substantial text\n  overlap with arXiv:2002.04887, arXiv:2002.07778; text overlap with\n  arXiv:0901.2140 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconciliation is a mechanism allowing to weed out the discrepancies between\ntwo correlated variables. It has great role in every Quantum Key Distribution\nprotocol where the key has to be transmitted through a noisy channel or as in\nour case of study in presence of an eavesdropping. In this paper, we show that\nfor discrete-variable QKD protocols, this problem can be advantageously solved\nwith Turbo codes. In particular, we demonstrate that our method leads to a\nsignificant improvement of Bit Error Rate, may divide it by three in presence\nof a eavesdropper even with great eavesdropping capability.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 21:22:18 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Benletaief", "Nedra", ""], ["Rezig", "Houria", ""], ["Bouallegue", "Ammar", ""]]}, {"id": "2002.07857", "submitter": "Shervin Roshanisefat", "authors": "Shervin Roshanisefat, Hadi Mardani Kamali, Kimia Zamiri Azar, Sai\n  Manoj Pudukotai Dinakarrao, Naghmeh Karimi, Houman Homayoun, Avesta Sasan", "title": "DFSSD: Deep Faults and Shallow State Duality, A Provably Strong\n  Obfuscation Solution for Circuits with Restricted Access to Scan Chain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce DFSSD, a novel logic locking solution for\nsequential and FSM circuits with a restricted (locked) access to the scan\nchain. DFSSD combines two techniques for obfuscation: (1) Deep Faults, and (2)\nShallow State Duality. Both techniques are specifically designed to resist\nagainst sequential SAT attacks based on bounded model checking. The shallow\nstate duality prevents a sequential SAT attack from taking a shortcut for early\ntermination without running an exhaustive unbounded model checker to assess if\nthe attack could be terminated. The deep fault, on the other hand, provides a\ndesigner with a technique for building deep, yet key recoverable faults that\ncould not be discovered by sequential SAT (and bounded model checker based)\nattacks in a reasonable time.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 20:04:26 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Roshanisefat", "Shervin", ""], ["Kamali", "Hadi Mardani", ""], ["Azar", "Kimia Zamiri", ""], ["Dinakarrao", "Sai Manoj Pudukotai", ""], ["Karimi", "Naghmeh", ""], ["Homayoun", "Houman", ""], ["Sasan", "Avesta", ""]]}, {"id": "2002.07891", "submitter": "Pu Zhao", "authors": "Pu Zhao, Pin-Yu Chen, Siyue Wang, Xue Lin", "title": "Towards Query-Efficient Black-Box Adversary with Zeroth-Order Natural\n  Gradient Descent", "comments": "accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the great achievements of the modern deep neural networks (DNNs), the\nvulnerability/robustness of state-of-the-art DNNs raises security concerns in\nmany application domains requiring high reliability. Various adversarial\nattacks are proposed to sabotage the learning performance of DNN models. Among\nthose, the black-box adversarial attack methods have received special\nattentions owing to their practicality and simplicity. Black-box attacks\nusually prefer less queries in order to maintain stealthy and low costs.\nHowever, most of the current black-box attack methods adopt the first-order\ngradient descent method, which may come with certain deficiencies such as\nrelatively slow convergence and high sensitivity to hyper-parameter settings.\nIn this paper, we propose a zeroth-order natural gradient descent (ZO-NGD)\nmethod to design the adversarial attacks, which incorporates the zeroth-order\ngradient estimation technique catering to the black-box attack scenario and the\nsecond-order natural gradient descent to achieve higher query efficiency. The\nempirical evaluations on image classification datasets demonstrate that ZO-NGD\ncan obtain significantly lower model query complexities compared with\nstate-of-the-art attack methods.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 21:48:54 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Zhao", "Pu", ""], ["Chen", "Pin-Yu", ""], ["Wang", "Siyue", ""], ["Lin", "Xue", ""]]}, {"id": "2002.07923", "submitter": "Ming-Deh Huang", "authors": "Ming-Deh A. Huang", "title": "Algebraic blinding and cryptographic trilinear maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown recently that cryptographic trilinear maps are sufficient\nfor achieving indistinguishability obfuscation. In this paper we develop\nalgebraic blinding techniques for constructing such maps. An earlier approach\ninvolving Weil restriction can be regarded as a special case of blinding in our\nframework. However, the techniques developed in this paper are more general,\nmore robust, and easier to analyze. The trilinear maps constructed in this\npaper are efficiently computable. The relationship between the published\nentities and the hidden entities under the blinding scheme is described by\nalgebraic conditions. Finding points on an algebraic set defined by such\nconditions for the purpose of unblinding is difficult as these algebraic sets\nhave dimension at least linear in $n$ and involves $\\Omega(n^2)$ variables,\nwhere $n$ is the security parameter. Finding points on such algebraic sets in\ngeneral takes time exponential in $n^2\\log n$ with the best known methods.\nAdditionally these algebraic sets are characterized as being {\\em triply\nconfusing} and most likely {\\em uniformly confusing} as well. These properties\nprovide additional evidence that efficient algorithms to find points on such\nalgebraic sets seems unlikely to exist. In addition to algebraic blinding, the\nsecurity of the trilinear maps also depends on the computational complexity of\na trapdoor discrete logarithm problem which is defined in terms of an\nassociative non-commutative polynomial algebra acting on torsion points of a\nblinded product of elliptic curves.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 23:23:41 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 04:47:35 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Huang", "Ming-Deh A.", ""]]}, {"id": "2002.07936", "submitter": "Reza Mirzazade Farkhani", "authors": "Reza Mirzazade Farkhani, Mansour Ahmadi, Long Lu", "title": "PTAuth: Temporal Memory Safety via Robust Points-to Authentication", "comments": "The 30th USENIX Security Symposium (USENIX Security '21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal memory corruptions are commonly exploited software vulnerabilities\nthat can lead to powerful attacks. Despite significant progress made by decades\nof research on mitigation techniques, existing countermeasures fall short due\nto either limited coverage or overly high overhead. Furthermore, they require\nexternal mechanisms (e.g., spatial memory safety) to protect their metadata.\nOtherwise, their protection can be bypassed or disabled. To address these\nlimitations, we present robust points-to authentication, a novel runtime scheme\nfor detecting all kinds of temporal memory corruptions. We built a prototype\nsystem, called PTAuth, that realizes this scheme on ARM architectures. PTAuth\ncontains a customized compiler for code analysis and instrumentation and a\nruntime library for performing the points-to authentication as a protected\nprogram runs. PTAuth leverages the Pointer Authentication Code (PAC) feature,\nprovided by the ARMv8.3 and later CPUs, which serves as a simple hardware-based\nencryption primitive. PTAuth uses minimal in-memory metadata and protects its\nmetadata without requiring spatial memory safety. We report our evaluation of\nPTAuth in terms of security, robustness and performance using 150 vulnerable\nprograms from Juliet test suite and the SPEC CPU2006 benchmarks. PTAuth detects\nall three categories of heap-based temporal memory corruptions, generates zero\nfalse alerts, and slows down program execution by 26% (this number was measured\nbased on software-emulated PAC; it is expected to decrease to 20% when using\nhardware-based PAC). We also show that PTAuth incurs 2% memory overhead thanks\nto the efficient use of metadata.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 00:14:12 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 04:30:39 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 04:51:06 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Farkhani", "Reza Mirzazade", ""], ["Ahmadi", "Mansour", ""], ["Lu", "Long", ""]]}, {"id": "2002.07955", "submitter": "Rajendra Kumar", "authors": "Divesh Aggarwal, Yanlin Chen, Rajendra Kumar and Yixin Shen", "title": "Improved (Provable) Algorithms for the Shortest Vector Problem via\n  Bounded Distance Decoding", "comments": "25 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most important computational problem on lattices is the Shortest Vector\nProblem (SVP). In this paper, we present new algorithms that improve the\nstate-of-the-art for provable classical/quantum algorithms for SVP. We present\nthe following results.\n  $\\bullet$ A new algorithm for SVP that provides a smooth tradeoff between\ntime complexity and memory requirement. For any positive integer $4\\leq q\\leq\n\\sqrt{n}$, our algorithm takes $q^{13n+o(n)}$ time and requires $poly(n)\\cdot\nq^{16n/q^2}$ memory. This tradeoff which ranges from enumeration ($q=\\sqrt{n}$)\nto sieving ($q$ constant), is a consequence of a new time-memory tradeoff for\nDiscrete Gaussian sampling above the smoothing parameter.\n  $\\bullet$ A quantum algorithm that runs in time $2^{0.9535n+o(n)}$ and\nrequires $2^{0.5n+o(n)}$ classical memory and poly(n) qubits. This improves\nover the previously fastest classical (which is also the fastest quantum)\nalgorithm due to [ADRSD15] that has a time and space complexity $2^{n+o(n)}$.\n  $\\bullet$ A classical algorithm for SVP that runs in time $2^{1.741n+o(n)}$\ntime and $2^{0.5n+o(n)}$ space. This improves over an algorithm of [CCL18] that\nhas the same space complexity.\n  The time complexity of our classical and quantum algorithms are obtained\nusing a known upper bound of the kissing number which is $2^{0.402n}$. In\npractice most lattices have a much smaller kissing number which is often\n$2^{o(n)}$. In that case, our classical algorithm runs in time $2^{1.292n}$ and\nour quantum algorithm runs in time $2^{0.750n}$.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 01:38:34 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 12:02:40 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2020 04:26:01 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Aggarwal", "Divesh", ""], ["Chen", "Yanlin", ""], ["Kumar", "Rajendra", ""], ["Shen", "Yixin", ""]]}, {"id": "2002.08000", "submitter": "Guanlin Liu", "authors": "Guanlin Liu and Lifeng lai", "title": "Action-Manipulation Attacks Against Stochastic Bandits: Attacks and\n  Defense", "comments": "13 pages, 7 figures, submitted to IEEE Transaction on Signal\n  Processing", "journal-ref": null, "doi": "10.1109/TSP.2020.3021525", "report-no": null, "categories": "cs.LG cs.CR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the broad range of applications of stochastic multi-armed bandit\nmodel, understanding the effects of adversarial attacks and designing bandit\nalgorithms robust to attacks are essential for the safe applications of this\nmodel. In this paper, we introduce a new class of attack named\naction-manipulation attack. In this attack, an adversary can change the action\nsignal selected by the user. We show that without knowledge of mean rewards of\narms, our proposed attack can manipulate Upper Confidence Bound (UCB)\nalgorithm, a widely used bandit algorithm, into pulling a target arm very\nfrequently by spending only logarithmic cost. To defend against this class of\nattacks, we introduce a novel algorithm that is robust to action-manipulation\nattacks when an upper bound for the total attack cost is given. We prove that\nour algorithm has a pseudo-regret upper bounded by $\\mathcal{O}(\\max\\{\\log\nT,A\\})$, where $T$ is the total number of rounds and $A$ is the upper bound of\nthe total attack cost.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 04:09:15 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 22:14:33 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Liu", "Guanlin", ""], ["lai", "Lifeng", ""]]}, {"id": "2002.08007", "submitter": "Monther Aldwairi", "authors": "Saeed Ibrahim, Nawwaf Al Herami, Ebrahim Al Naqbi and Monther Aldwairi", "title": "Detection and Analysis of Drive-by Downloads and Malicious Websites", "comments": null, "journal-ref": "Seventh International Symposium on Security in Computing and\n  Communications (SSCC'19), December 18-21, 2019, Trivandrum, Kerala, India", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A drive by download is a download that occurs without users action or\nknowledge. It usually triggers an exploit of vulnerability in a browser to\ndownloads an unknown file. The malicious program in the downloaded file\ninstalls itself on the victims machine. Moreover, the downloaded file can be\ncamouflaged as an installer that would further install malicious software.\nDrive by downloads is a very good example of the exponential increase in\nmalicious activity over the Internet and how it affects the daily use of the\nweb. In this paper, we try to address the problem caused by drive by downloads\nfrom different standpoints. We provide in depth understanding of the\ndifficulties in dealing with drive by downloads and suggest appropriate\nsolutions. We propose machine learning and feature selection solutions to\nremedy the the drive-by download problem. Experimental results reported 98.2%\nprecision, 98.2% F-Measure and 97.2% ROC area.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 05:11:49 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 10:24:35 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Ibrahim", "Saeed", ""], ["Herami", "Nawwaf Al", ""], ["Naqbi", "Ebrahim Al", ""], ["Aldwairi", "Monther", ""]]}, {"id": "2002.08012", "submitter": "Tsubasa Takahashi", "authors": "Tsubasa Takahashi", "title": "Indirect Adversarial Attacks via Poisoning Neighbors for Graph\n  Convolutional Networks", "comments": "Accepted in IEEE BigData 2019", "journal-ref": null, "doi": "10.1109/BigData47090.2019.9006004", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional neural networks, which learn aggregations over neighbor\nnodes, have achieved great performance in node classification tasks. However,\nrecent studies reported that such graph convolutional node classifier can be\ndeceived by adversarial perturbations on graphs. Abusing graph convolutions, a\nnode's classification result can be influenced by poisoning its neighbors.\nGiven an attributed graph and a node classifier, how can we evaluate robustness\nagainst such indirect adversarial attacks? Can we generate strong adversarial\nperturbations which are effective on not only one-hop neighbors, but more far\nfrom the target? In this paper, we demonstrate that the node classifier can be\ndeceived with high-confidence by poisoning just a single node even two-hops or\nmore far from the target. Towards achieving the attack, we propose a new\napproach which searches smaller perturbations on just a single node far from\nthe target. In our experiments, our proposed method shows 99% attack success\nrate within two-hops from the target in two datasets. We also demonstrate that\nm-layer graph convolutional neural networks have chance to be deceived by our\nindirect attack within m-hop neighbors. The proposed attack can be used as a\nbenchmark in future defense attempts to develop graph convolutional neural\nnetworks with having adversary robustness.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 05:44:09 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Takahashi", "Tsubasa", ""]]}, {"id": "2002.08025", "submitter": "Minghong Fang", "authors": "Minghong Fang, Neil Zhenqiang Gong, Jia Liu", "title": "Influence Function based Data Poisoning Attacks to Top-N Recommender\n  Systems", "comments": "Accepted by WWW 2020; This is technical report version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender system is an essential component of web services to engage users.\nPopular recommender systems model user preferences and item properties using a\nlarge amount of crowdsourced user-item interaction data, e.g., rating scores;\nthen top-$N$ items that match the best with a user's preference are recommended\nto the user. In this work, we show that an attacker can launch a data poisoning\nattack to a recommender system to make recommendations as the attacker desires\nvia injecting fake users with carefully crafted user-item interaction data.\nSpecifically, an attacker can trick a recommender system to recommend a target\nitem to as many normal users as possible. We focus on matrix factorization\nbased recommender systems because they have been widely deployed in industry.\nGiven the number of fake users the attacker can inject, we formulate the\ncrafting of rating scores for the fake users as an optimization problem.\nHowever, this optimization problem is challenging to solve as it is a\nnon-convex integer programming problem. To address the challenge, we develop\nseveral techniques to approximately solve the optimization problem. For\ninstance, we leverage influence function to select a subset of normal users who\nare influential to the recommendations and solve our formulated optimization\nproblem based on these influential users. Our results show that our attacks are\neffective and outperform existing methods.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 06:41:51 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 20:45:44 GMT"}, {"version": "v3", "created": "Sun, 31 May 2020 21:24:05 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Fang", "Minghong", ""], ["Gong", "Neil Zhenqiang", ""], ["Liu", "Jia", ""]]}, {"id": "2002.08027", "submitter": "Minghong Fang", "authors": "Minghong Fang, Jia Liu", "title": "Toward Low-Cost and Stable Blockchain Networks", "comments": "Accepted by IEEE ICC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Envisioned to be the future of secured distributed systems, blockchain\nnetworks have received increasing attention from both the industry and academia\nin recent years. However, blockchain mining processes demand high hardware\ncosts and consume a vast amount of energy (studies have shown that the amount\nof energy consumed in Bitcoin mining is almost the same as the electricity used\nin Ireland). To address the high mining cost problem of blockchain networks, in\nthis paper, we propose a blockchain mining resources allocation algorithm to\nreduce the mining cost in PoW-based (proof-of-work-based) blockchain networks.\nWe first propose an analytical queueing model for general blockchain networks.\nIn our queueing model, transactions arrive randomly to the queue and are served\nin a batch manner with unknown service rate probability distribution and\nagnostic to any priority mechanism. Then, we leverage the Lyapunov optimization\ntechniques to propose a dynamic mining resources allocation algorithm (DMRA),\nwhich is parameterized by a tuning parameter $K>0$. We show that our algorithm\nachieves an $[O(1/K), O(K)]$ cost-optimality-gap-vs-delay tradeoff. Our\nsimulation results also demonstrate the effectiveness of DMRA in reducing\nmining costs.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 06:42:33 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 20:39:50 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Fang", "Minghong", ""], ["Liu", "Jia", ""]]}, {"id": "2002.08099", "submitter": "Lewis Gudgeon", "authors": "Lewis Gudgeon, Daniel Perez, Dominik Harz, Benjamin Livshits, Arthur\n  Gervais", "title": "The Decentralized Financial Crisis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Global Financial Crisis of 2008, caused by the accumulation of excessive\nfinancial risk, inspired Satoshi Nakamoto to create Bitcoin. Now, more than ten\nyears later, Decentralized Finance (DeFi), a peer-to-peer financial paradigm\nwhich leverages blockchain-based smart contracts to ensure its integrity and\nsecurity, contains over 702m USD of capital as of April 15th, 2020. As this\necosystem develops, it is at risk of the very sort of financial meltdown it is\nsupposed to be preventing. In this paper we explore how design weaknesses and\nprice fluctuations in DeFi protocols could lead to a DeFi crisis. We focus on\nDeFi lending protocols as they currently constitute most of the DeFi ecosystem\nwith a 76% market share by capital as of April 15th, 2020.\n  First, we demonstrate the feasibility of attacking Maker's governance design\nto take full control of the protocol, the largest DeFi protocol by market\nshare, which would have allowed the theft of 0.5bn USD of collateral and the\nminting of an unlimited supply of DAI tokens. In doing so, we present a novel\nstrategy utilizing so-called flash loans that would have in principle allowed\nthe execution of the governance attack in just two transactions and without the\nneed to lock any assets. Approximately two weeks after we disclosed the attack\ndetails, Maker modified the governance parameters mitigating the attack\nvectors. Second, we turn to a central component of financial risk in DeFi\nlending protocols. Inspired by stress-testing as performed by central banks, we\ndevelop a stress-testing framework for a stylized DeFi lending protocol,\nfocusing our attention on the impact of a drying-up of liquidity on protocol\nsolvency. Based on our parameters, we find that with sufficiently illiquidity a\nlending protocol with a total debt of 400m USD could become undercollateralized\nwithin 19 days.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 10:33:02 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 15:40:28 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Gudgeon", "Lewis", ""], ["Perez", "Daniel", ""], ["Harz", "Dominik", ""], ["Livshits", "Benjamin", ""], ["Gervais", "Arthur", ""]]}, {"id": "2002.08101", "submitter": "Martin Florian", "authors": "Martin Florian, Sebastian Henningsen, Charmaine Ndolo, Bj\\\"orn\n  Scheuermann", "title": "The Sum of Its Parts: Analysis of Federated Byzantine Agreement Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Byzantine Agreement Systems (FBASs) are a fascinating new paradigm\nin the context of consensus protocols. Originally proposed for powering the\nStellar payment network, FBASs can instantiate Byzantine quorum systems without\nrequiring out-of-band agreement on a common set of validators; every node is\nfree to decide for itself with whom it requires agreement. Sybil-resistant and\nyet energy-efficient consensus protocols can therefore be built upon FBASs, and\nthe \"decentrality\" possible with the FBAS paradigm might be sufficient to\nreduce the use of environmentally unsustainable proof-of-work protocols. In\nthis paper, we first demonstrate how the robustness of individual FBASs can be\ndetermined, by precisely determining their safety and liveness buffers and\ntherefore enabling a comparison with threshold-based quorum systems. Using\nsimulations and example node configuration strategies, we then empirically\ninvestigate the hypothesis that while FBASs can be bootstrapped in a bottom-up\nfashion from individual preferences, strategic considerations should\nadditionally be applied by node operators in order to arrive at FBASs that are\nrobust and amenable to monitoring. Finally, we investigate the reported\n\"open-membership\" property of FBASs. We observe that an often small group of\nnodes is exclusively relevant for determining safety and liveness buffers, and\nprove that membership in this top tier is conditional on the approval by\ncurrent top tier nodes if maintaining safety is a core requirement.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 10:57:21 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 07:53:09 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Florian", "Martin", ""], ["Henningsen", "Sebastian", ""], ["Ndolo", "Charmaine", ""], ["Scheuermann", "Bj\u00f6rn", ""]]}, {"id": "2002.08210", "submitter": "Ernest Wozniak PhD", "authors": "Henrik J. Putzer and Ernest Wozniak", "title": "A Structured Approach to Trustworthy Autonomous/Cognitive Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous systems with cognitive features are on their way into the market.\nWithin complex environments, they promise to implement complex and goal\noriented behavior even in a safety related context. This behavior is based on a\ncertain level of situational awareness (perception) and advanced de-cision\nmaking (deliberation). These systems in many cases are driven by artificial\nintelligence (e.g. neural networks). The problem with such complex systems and\nwith using AI technology is that there is no generally accepted approach to\nensure trustworthiness. This paper presents a framework to exactly fill this\ngap. It proposes a reference lifecycle as a structured approach that is based\non current safety standards and enhanced to meet the requirements of\nautonomous/cog-nitive systems and trustworthiness.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 14:36:27 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Putzer", "Henrik J.", ""], ["Wozniak", "Ernest", ""]]}, {"id": "2002.08313", "submitter": "Akshaj Kumar Veldanda", "authors": "Akshaj Kumar Veldanda, Kang Liu, Benjamin Tan, Prashanth\n  Krishnamurthy, Farshad Khorrami, Ramesh Karri, Brendan Dolan-Gavitt, and\n  Siddharth Garg", "title": "NNoculation: Broad Spectrum and Targeted Treatment of Backdoored DNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel two-stage defense (NNoculation) against\nbackdoored neural networks (BadNets) that, unlike existing defenses, makes\nminimal assumptions on the shape, size and location of backdoor triggers and\nBadNet's functioning. In the pre-deployment stage, NNoculation retrains the\nnetwork using \"broad-spectrum\" random perturbations of inputs drawn from a\nclean validation set to partially reduce the adversarial impact of a backdoor.\nIn the post-deployment stage, NNoculation detects and quarantines backdoored\ntest inputs by recording disagreements between the original and pre-deployment\npatched networks. A CycleGAN is then trained to learn transformations between\nclean validation inputs and quarantined inputs; i.e., it learns to add triggers\nto clean validation images. This transformed set of backdoored validation\nimages along with their correct labels is used to further retrain the BadNet,\nyielding our final defense. NNoculation outperforms state-of-the-art defenses\nNeuralCleanse and Artificial Brain Simulation (ABS) that we show are\nineffective when their restrictive assumptions are circumvented by the\nattacker.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 17:51:21 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Veldanda", "Akshaj Kumar", ""], ["Liu", "Kang", ""], ["Tan", "Benjamin", ""], ["Krishnamurthy", "Prashanth", ""], ["Khorrami", "Farshad", ""], ["Karri", "Ramesh", ""], ["Dolan-Gavitt", "Brendan", ""], ["Garg", "Siddharth", ""]]}, {"id": "2002.08320", "submitter": "Diane Staheli", "authors": "Dennis Ross, Arunesh Sinha, Diane Staheli, Bill Streilein", "title": "Proceedings of the Artificial Intelligence for Cyber Security (AICS)\n  Workshop 2020", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The workshop will focus on the application of artificial intelligence to\nproblems in cyber security. AICS 2020 emphasis will be on human-machine teaming\nwithin the context of cyber security problems and will specifically explore\ncollaboration between human operators and AI technologies. The workshop will\naddress applicable areas of AI, such as machine learning, game theory, natural\nlanguage processing, knowledge representation, automated and assistive\nreasoning and human machine interactions. Further, cyber security application\nareas with a particular emphasis on the characterization and deployment of\nhuman-machine teaming will be the focus.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 18:12:00 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 22:03:20 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Ross", "Dennis", ""], ["Sinha", "Arunesh", ""], ["Staheli", "Diane", ""], ["Streilein", "Bill", ""]]}, {"id": "2002.08322", "submitter": "Maxime Bros", "authors": "Magali Bardet, Maxime Bros, Daniel Cabarcas, Philippe Gaborit, Ray\n  Perlner, Daniel Smith-Tone, Jean-Pierre Tillich, Javier Verbel", "title": "Improvements of Algebraic Attacks for solving the Rank Decoding and\n  MinRank problems", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-64837-4_17", "report-no": null, "categories": "cs.CR math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rank Decoding (RD) is the main underlying problem in rank-based cryptography.\nBased on this problem and quasi-cyclic versions of it, very efficient schemes\nhave been proposed recently, such as those in the ROLLO and RQC submissions,\nwhich have reached the second round of the NIST Post-Quantum competition. Two\nmain approaches have been studied to solve RD: combinatorial ones and algebraic\nones. While the former has been studied extensively, a better understanding of\nthe latter was recently obtained by Bardet et al. (EUROCRYPT20) where it\nappeared that algebraic attacks can often be more efficient than combinatorial\nones for cryptographic parameters. This paper gives substantial improvements\nupon this attack in terms both of complexity and of the assumptions required by\nthe cryptanalysis. We present attacks for ROLLO-I-128, 192, and 256 with bit\ncomplexity respectively in 70, 86, and 158, to be compared to 117, 144, and 197\nfor the aforementionned previous attack. Moreover, unlike this previous attack,\nours does not need generic Gr\\\"obner basis algorithms since it only requires to\nsolve a linear system. For a case called overdetermined, this modeling allows\nus to avoid Gr\\\"obner basis computations by going directly to solving a linear\nsystem. For the other case, called underdetermined, we also improve the results\nfrom the previous attack by combining the Ourivski-Johansson modeling together\nwith a new modeling for a generic MinRank instance; the latter modeling allows\nus to refine the analysis of MinRank's complexity given in the paper by Verbel\net al. (PQC19). Finally, since the proposed parameters of ROLLO and RQC are\ncompletely broken by our new attack, we give examples of new parameters for\nROLLO and RQC that make them resistant to our attacks. These new parameters\nshow that these systems remain attractive, with a loss of only about 50\\% in\nterms of key size for ROLLO-I.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 08:06:57 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 15:23:27 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 15:41:11 GMT"}, {"version": "v4", "created": "Tue, 9 Feb 2021 10:14:22 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Bardet", "Magali", ""], ["Bros", "Maxime", ""], ["Cabarcas", "Daniel", ""], ["Gaborit", "Philippe", ""], ["Perlner", "Ray", ""], ["Smith-Tone", "Daniel", ""], ["Tillich", "Jean-Pierre", ""], ["Verbel", "Javier", ""]]}, {"id": "2002.08327", "submitter": "Shawn Shan", "authors": "Shawn Shan, Emily Wenger, Jiayun Zhang, Huiying Li, Haitao Zheng, Ben\n  Y. Zhao", "title": "Fawkes: Protecting Privacy against Unauthorized Deep Learning Models", "comments": null, "journal-ref": "USENIX Security Symposium 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's proliferation of powerful facial recognition systems poses a real\nthreat to personal privacy. As Clearview.ai demonstrated, anyone can canvas the\nInternet for data and train highly accurate facial recognition models of\nindividuals without their knowledge. We need tools to protect ourselves from\npotential misuses of unauthorized facial recognition systems. Unfortunately, no\npractical or effective solutions exist.\n  In this paper, we propose Fawkes, a system that helps individuals inoculate\ntheir images against unauthorized facial recognition models. Fawkes achieves\nthis by helping users add imperceptible pixel-level changes (we call them\n\"cloaks\") to their own photos before releasing them. When used to train facial\nrecognition models, these \"cloaked\" images produce functional models that\nconsistently cause normal images of the user to be misidentified. We\nexperimentally demonstrate that Fawkes provides 95+% protection against user\nrecognition regardless of how trackers train their models. Even when clean,\nuncloaked images are \"leaked\" to the tracker and used for training, Fawkes can\nstill maintain an 80+% protection success rate. We achieve 100% success in\nexperiments against today's state-of-the-art facial recognition services.\nFinally, we show that Fawkes is robust against a variety of countermeasures\nthat try to detect or disrupt image cloaks.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 18:00:22 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 03:54:20 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Shan", "Shawn", ""], ["Wenger", "Emily", ""], ["Zhang", "Jiayun", ""], ["Li", "Huiying", ""], ["Zheng", "Haitao", ""], ["Zhao", "Ben Y.", ""]]}, {"id": "2002.08343", "submitter": "Pedro Hecht", "authors": "Pedro Hecht", "title": "Algebraic Extension Ring Framework for Non-Commutative Asymmetric\n  Cryptography", "comments": "4 pages, 3 tables, 1 figure", "journal-ref": null, "doi": "10.13140/RG.2.2.34977.84329", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Post-Quantum Cryptography PQC attempts to find cryptographic protocols\nresistant to attacks using Shors polynomial time algorithm for numerical field\nproblems or Grovers algorithm to find the unique input to a black-box function\nthat produces a particular output value. The use of non-standard algebraic\nstructures like non-commutative or non-associative structures, combined with\none-way trapdoor functions derived from combinatorial group theory, are mainly\nunexplored choices for these new kinds of protocols and overlooked in current\nPQC solutions. In this paper, we develop an algebraic extension ring framework\nwho could be applied to different asymmetric protocols, i.e. key exchange, key\ntransport, enciphering, digital signature, zero-knowledge authentication,\noblivious transfer, secret sharing etc.. A valuable feature is that there is no\nneed for big number libraries as all arithmetic is performed in F256 extension\nfield operations (precisely the AES field). We assume that the new framework is\ncryptographical secure against strong classical attacks like the\nsometimes-useful length-based attack, Romankovs linearization attacks and\nTsabans algebraic span attack. This statement is based on the non-linear\nstructure of the selected platform which proved to be useful protecting the AES\nprotocol. Otherwise, it could resist post-quantum attacks Grover, Shor and be\nparticularly useful for computational platforms with limited capabilities like\nUSB cryptographic keys or smartcards. Semantic security IND-CCA2 could also be\ninferred for this new platform.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 18:44:07 GMT"}, {"version": "v2", "created": "Sun, 2 Aug 2020 14:01:20 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Hecht", "Pedro", ""]]}, {"id": "2002.08347", "submitter": "Florian Tram\\`er", "authors": "Florian Tramer, Nicholas Carlini, Wieland Brendel, Aleksander Madry", "title": "On Adaptive Attacks to Adversarial Example Defenses", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive attacks have (rightfully) become the de facto standard for\nevaluating defenses to adversarial examples. We find, however, that typical\nadaptive evaluations are incomplete. We demonstrate that thirteen defenses\nrecently published at ICLR, ICML and NeurIPS---and chosen for illustrative and\npedagogical purposes---can be circumvented despite attempting to perform\nevaluations using adaptive attacks. While prior evaluation papers focused\nmainly on the end result---showing that a defense was ineffective---this paper\nfocuses on laying out the methodology and the approach necessary to perform an\nadaptive attack. We hope that these analyses will serve as guidance on how to\nproperly perform adaptive attacks against defenses to adversarial examples, and\nthus will allow the community to make further progress in building more robust\nmodels.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 18:50:29 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 12:07:41 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Tramer", "Florian", ""], ["Carlini", "Nicholas", ""], ["Brendel", "Wieland", ""], ["Madry", "Aleksander", ""]]}, {"id": "2002.08362", "submitter": "Wen-Kai Yu", "authors": "Wen-Kai Yu, Ya-Xin Li, Jian Leng, and Shuo-Fei Wang", "title": "Fragment-synthesis-based multiparty cryptographic key distribution over\n  a public network", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A secure optical communication requires both high transmission efficiency and\nhigh authentication performance, while existing cryptographic key distribution\nprotocols based on ghost imaging have many shortcomings. Here, based on\ncomputational ghost imaging, we propose an interactive protocol that enables\nmulti-party cryptographic key distribution over a public network and\nself-authentication by setting an intermediary that shares partial roles of the\nserver. This fragment-synthesis-based authentication method may facilitate the\nremote distribution of cryptographic keys.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 17:23:11 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Yu", "Wen-Kai", ""], ["Li", "Ya-Xin", ""], ["Leng", "Jian", ""], ["Wang", "Shuo-Fei", ""]]}, {"id": "2002.08423", "submitter": "Vaikkunth Mugunthan", "authors": "Vaikkunth Mugunthan, Anton Peraire-Bueno and Lalana Kagal", "title": "PrivacyFL: A simulator for privacy-preserving and secure federated\n  learning", "comments": null, "journal-ref": null, "doi": "10.1145/3340531.3412771", "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a technique that enables distributed clients to\ncollaboratively learn a shared machine learning model while keeping their\ntraining data localized. This reduces data privacy risks, however, privacy\nconcerns still exist since it is possible to leak information about the\ntraining dataset from the trained model's weights or parameters. Setting up a\nfederated learning environment, especially with security and privacy\nguarantees, is a time-consuming process with numerous configurations and\nparameters that can be manipulated. In order to help clients ensure that\ncollaboration is feasible and to check that it improves their model accuracy, a\nreal-world simulator for privacy-preserving and secure federated learning is\nrequired. In this paper, we introduce PrivacyFL, which is an extensible, easily\nconfigurable and scalable simulator for federated learning environments. Its\nkey features include latency simulation, robustness to client departure,\nsupport for both centralized and decentralized learning, and configurable\nprivacy and security mechanisms based on differential privacy and secure\nmultiparty computation. In this paper, we motivate our research, describe the\narchitecture of the simulator and associated protocols, and discuss its\nevaluation in numerous scenarios that highlight its wide range of functionality\nand its advantages. Our paper addresses a significant real-world problem:\nchecking the feasibility of participating in a federated learning environment\nunder a variety of circumstances. It also has a strong practical impact because\norganizations such as hospitals, banks, and research institutes, which have\nlarge amounts of sensitive data and would like to collaborate, would greatly\nbenefit from having a system that enables them to do so in a privacy-preserving\nand secure manner.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 20:16:13 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 03:30:36 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Mugunthan", "Vaikkunth", ""], ["Peraire-Bueno", "Anton", ""], ["Kagal", "Lalana", ""]]}, {"id": "2002.08437", "submitter": "Daniel Moghimi", "authors": "Daniel Moghimi, Jo Van Bulck, Nadia Heninger, Frank Piessens, Berk\n  Sunar", "title": "CopyCat: Controlled Instruction-Level Attacks on Enclaves", "comments": "This paper will be presented at USENIX Security Symposium 2020.\n  Please cite this work as: Daniel Moghimi, Jo Van Bulck, Nadia Heninger, Frank\n  Piessens, Berk Sunar, \"CopyCat: Controlled Instruction-Level Attacks on\n  Enclaves\" in Proceedings of the 29th USENIX Security Symposium, Boston, MA,\n  August 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The adversarial model presented by trusted execution environments (TEEs) has\nprompted researchers to investigate unusual attack vectors. One particularly\npowerful class of controlled-channel attacks abuses page-table modifications to\nreliably track enclave memory accesses at a page-level granularity. In contrast\nto noisy microarchitectural timing leakage, this line of deterministic\ncontrolled-channel attacks abuses indispensable architectural interfaces and\nhence cannot be mitigated by tweaking microarchitectural resources.\n  We propose an innovative controlled-channel attack, named CopyCat, that\ndeterministically counts the number of instructions executed within a single\nenclave code page. We show that combining the instruction counts harvested by\nCopyCat with traditional, coarse-grained page-level leakage allows the accurate\nreconstruction of enclave control flow at a maximal instruction-level\ngranularity. CopyCat can identify intra-page and intra-cache line branch\ndecisions that ultimately may only differ in a single instruction, underscoring\nthat even extremely subtle control flow deviations can be deterministically\nleaked from secure enclaves. We demonstrate the improved resolution and\npracticality of CopyCat on Intel SGX in an extensive study of single-trace and\ndeterministic attacks against cryptographic implementations, and give novel\nalgorithmic attacks to perform single-trace key extraction that exploit subtle\nvulnerabilities in the latest versions of widely-used cryptographic libraries.\nOur findings highlight the importance of stricter verification of cryptographic\nimplementations, especially in the context of TEEs.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 20:43:43 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 21:44:26 GMT"}, {"version": "v3", "created": "Fri, 26 Jun 2020 01:56:20 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Moghimi", "Daniel", ""], ["Van Bulck", "Jo", ""], ["Heninger", "Nadia", ""], ["Piessens", "Frank", ""], ["Sunar", "Berk", ""]]}, {"id": "2002.08439", "submitter": "Siyue Wang", "authors": "Xiao Wang, Siyue Wang, Pin-Yu Chen, Xue Lin, Peter Chin", "title": "AdvMS: A Multi-source Multi-cost Defense Against Adversarial Attacks", "comments": "Accepted by 45th International Conference on Acoustics, Speech, and\n  Signal Processing (ICASSP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing effective defense against adversarial attacks is a crucial topic as\ndeep neural networks have been proliferated rapidly in many security-critical\ndomains such as malware detection and self-driving cars. Conventional defense\nmethods, although shown to be promising, are largely limited by their\nsingle-source single-cost nature: The robustness promotion tends to plateau\nwhen the defenses are made increasingly stronger while the cost tends to\namplify. In this paper, we study principles of designing multi-source and\nmulti-cost schemes where defense performance is boosted from multiple defending\ncomponents. Based on this motivation, we propose a multi-source and multi-cost\ndefense scheme, Adversarially Trained Model Switching (AdvMS), that inherits\nadvantages from two leading schemes: adversarial training and random model\nswitching. We show that the multi-source nature of AdvMS mitigates the\nperformance plateauing issue and the multi-cost nature enables improving\nrobustness at a flexible and adjustable combination of costs over different\nfactors which can better suit specific restrictions and needs in practice.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 20:46:54 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Wang", "Xiao", ""], ["Wang", "Siyue", ""], ["Chen", "Pin-Yu", ""], ["Lin", "Xue", ""], ["Chin", "Peter", ""]]}, {"id": "2002.08454", "submitter": "Arun Ravindran", "authors": "Anusha Bableshwar and Arun Ravindran and Manoj Iyer", "title": "A Recurrent Neural Network Based Patch Recommender for Linux Kernel Bugs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software bugs in a production environment have an undesirable impact on\nquality of service, unplanned system downtime, and disruption in good customer\nexperience, resulting in loss of revenue and reputation. Existing approaches to\nautomated software bug repair focuses on known bug templates detected using\nstatic code analysis tools and test suites, and in automatic generation of\npatch code for these bugs. We describe the typical bug fixing process employed\nin the Linux kernel, and motivate the need for a new automated tool flow to fix\nbugs. We present an initial design of such an automated tool that uses\nRecurrent Neural Network (RNN) based Natural Language Processing to generate\npatch recommendations from user generated bug reports. At the 50th percentile\nof the test bugs, the correct patch occurs within the top 11.5 patch\nrecommendations output by the model. Further, we present a Linux kernel\ndeveloper's assessment of the quality of patches recommended for new unresolved\nkernel bugs.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 21:35:51 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Bableshwar", "Anusha", ""], ["Ravindran", "Arun", ""], ["Iyer", "Manoj", ""]]}, {"id": "2002.08463", "submitter": "Mohammad Ghafari", "authors": "Mohammadreza Hazhirpasand, Mohammad Ghafari, Oscar Nierstrasz", "title": "Tricking Johnny into Granting Web Permissions", "comments": "The 24th International Conference on Evaluation and Assessment in\n  Software Engineering (EASE 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We studied the web permission API dialog box in popular mobile and desktop\nbrowsers, and found that it typically lacks measures to protect users from\nunwittingly granting web permission when clicking too fast.\n  We developed a game that exploits this issue, and tricks users into granting\nwebcam permission. We conducted three experiments, each with 40 different\nparticipants, on both desktop and mobile browsers. The results indicate that in\nthe absence of a prevention mechanism, we achieve a considerably high success\nrate in tricking 95% and 72% of participants on mobile and desktop browsers,\nrespectively. Interestingly, we also tricked 47% of participants on a desktop\nbrowser where a prevention mechanism exists.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 21:55:54 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Hazhirpasand", "Mohammadreza", ""], ["Ghafari", "Mohammad", ""], ["Nierstrasz", "Oscar", ""]]}, {"id": "2002.08527", "submitter": "Aritran Piplai", "authors": "Aritran Piplai, Sai Sree Laya Chukkapalli, Anupam Joshi", "title": "NAttack! Adversarial Attacks to bypass a GAN based classifier trained to\n  detect Network intrusion", "comments": "6 pages, 2 figures. 6th IEEE International Conference on Big Data\n  Security on Cloud (BigDataSecurity 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent developments in artificial intelligence and machine learning,\nanomalies in network traffic can be detected using machine learning approaches.\nBefore the rise of machine learning, network anomalies which could imply an\nattack, were detected using well-crafted rules. An attacker who has knowledge\nin the field of cyber-defence could make educated guesses to sometimes\naccurately predict which particular features of network traffic data the\ncyber-defence mechanism is looking at. With this information, the attacker can\ncircumvent a rule-based cyber-defense system. However, after the advancements\nof machine learning for network anomaly, it is not easy for a human to\nunderstand how to bypass a cyber-defence system. Recently, adversarial attacks\nhave become increasingly common to defeat machine learning algorithms. In this\npaper, we show that even if we build a classifier and train it with adversarial\nexamples for network data, we can use adversarial attacks and successfully\nbreak the system. We propose a Generative Adversarial Network(GAN)based\nalgorithm to generate data to train an efficient neural network based\nclassifier, and we subsequently break the system using adversarial attacks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 01:54:45 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Piplai", "Aritran", ""], ["Chukkapalli", "Sai Sree Laya", ""], ["Joshi", "Anupam", ""]]}, {"id": "2002.08568", "submitter": "Reza Mirzazade Farkhani", "authors": "Yaohui Chen, Mansour Ahmadi, Reza Mirzazade farkhani, Boyu Wang, and\n  Long Lu", "title": "MEUZZ: Smart Seed Scheduling for Hybrid Fuzzing", "comments": "The 23rd International Symposium on Research in Attacks, Intrusions\n  and Defenses (RAID), Donostia / San Sebastian, Spain, October 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Seed scheduling is a prominent factor in determining the yields of hybrid\nfuzzing. Existing hybrid fuzzers schedule seeds based on fixed heuristics that\naim to predict input utilities. However, such heuristics are not generalizable\nas there exists no one-size-fits-all rule applicable to different programs.\nThey may work well on the programs from which they were derived, but not\nothers. To overcome this problem, we design a Machine learning-Enhanced hybrid\nfUZZing system (MEUZZ), which employs supervised machine learning for adaptive\nand generalizable seed scheduling. MEUZZ determines which new seeds are\nexpected to produce better fuzzing yields based on the knowledge learned from\npast seed scheduling decisions made on the same or similar programs. MEUZZ's\nlearning is based on a series of features extracted via code reachability and\ndynamic analysis, which incurs negligible runtime overhead (in microseconds).\nMoreover, MEUZZ automatically infers the data labels by evaluating the fuzzing\nperformance of each selected seed. As a result, MEUZZ is generally applicable\nto, and performs well on, various kinds of programs. Our evaluation shows MEUZZ\nsignificantly outperforms the state-of-the-art grey-box and hybrid fuzzers,\nachieving 27.1% more code coverage than QSYM. The learned models are reusable\nand transferable, which boosts fuzzing performance by 7.1% on average and\nimproves 68% of the 56 cross-program fuzzing campaigns. MEUZZ discovered 47\ndeeply hidden and previously unknown bugs--with 21 confirmed and fixed by the\ndevelopers--when fuzzing 8 well-tested programs with the same configurations as\nused in previous work.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 05:02:25 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 03:27:51 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Chen", "Yaohui", ""], ["Ahmadi", "Mansour", ""], ["farkhani", "Reza Mirzazade", ""], ["Wang", "Boyu", ""], ["Lu", "Long", ""]]}, {"id": "2002.08569", "submitter": "Shangwei Guo", "authors": "Shangwei Guo, Tianwei Zhang, Xiaofei Xie, Lei Ma, Tao Xiang, and Yang\n  Liu", "title": "Towards Byzantine-resilient Learning in Decentralized Systems", "comments": "We would like to extensively revise the paper and submit it to a\n  conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the proliferation of IoT and edge computing, decentralized learning is\nbecoming more promising. When designing a distributed learning system, one\nmajor challenge to consider is Byzantine Fault Tolerance (BFT). Past works have\nresearched Byzantine-resilient solutions for centralized distributed learning.\nHowever, there are currently no satisfactory solutions with strong efficiency\nand security in decentralized systems. In this paper, we propose a novel\nalgorithm, Mozi, to achieve BFT in decentralized learning systems.\nSpecifically, Mozi provides a uniform Byzantine-resilient aggregation rule for\nbenign nodes to select the useful parameter updates and filter out the\nmalicious ones in each training iteration. It guarantees that each benign node\nin a decentralized system can train a correct model under very strong Byzantine\nattacks with an arbitrary number of faulty nodes. We perform the theoretical\nanalysis to prove the uniform convergence of our proposed algorithm.\nExperimental evaluations demonstrate the high security and efficiency of Mozi\ncompared to all existing solutions.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 05:11:04 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 03:44:43 GMT"}, {"version": "v3", "created": "Sat, 1 Aug 2020 05:12:04 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Guo", "Shangwei", ""], ["Zhang", "Tianwei", ""], ["Xie", "Xiaofei", ""], ["Ma", "Lei", ""], ["Xiang", "Tao", ""], ["Liu", "Yang", ""]]}, {"id": "2002.08619", "submitter": "Tianyu Pang", "authors": "Tianyu Pang, Xiao Yang, Yinpeng Dong, Kun Xu, Jun Zhu, Hang Su", "title": "Boosting Adversarial Training with Hypersphere Embedding", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training (AT) is one of the most effective defenses against\nadversarial attacks for deep learning models. In this work, we advocate\nincorporating the hypersphere embedding (HE) mechanism into the AT procedure by\nregularizing the features onto compact manifolds, which constitutes a\nlightweight yet effective module to blend in the strength of representation\nlearning. Our extensive analyses reveal that AT and HE are well coupled to\nbenefit the robustness of the adversarially trained models from several\naspects. We validate the effectiveness and adaptability of HE by embedding it\ninto the popular AT frameworks including PGD-AT, ALP, and TRADES, as well as\nthe FreeAT and FastAT strategies. In the experiments, we evaluate our methods\nunder a wide range of adversarial attacks on the CIFAR-10 and ImageNet\ndatasets, which verifies that integrating HE can consistently enhance the model\nrobustness for each AT framework with little extra computation.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 08:42:29 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 13:27:17 GMT"}, {"version": "v3", "created": "Wed, 25 Nov 2020 16:18:38 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Pang", "Tianyu", ""], ["Yang", "Xiao", ""], ["Dong", "Yinpeng", ""], ["Xu", "Kun", ""], ["Zhu", "Jun", ""], ["Su", "Hang", ""]]}, {"id": "2002.08740", "submitter": "Ilia Shumailov", "authors": "Ilia Shumailov, Yiren Zhao, Robert Mullins, Ross Anderson", "title": "Towards Certifiable Adversarial Sample Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Convolutional Neural Networks (CNNs) are deployed in more and more\nclassification systems, but adversarial samples can be maliciously crafted to\ntrick them, and are becoming a real threat. There have been various proposals\nto improve CNNs' adversarial robustness but these all suffer performance\npenalties or other limitations. In this paper, we provide a new approach in the\nform of a certifiable adversarial detection scheme, the Certifiable Taboo Trap\n(CTT). The system can provide certifiable guarantees of detection of\nadversarial inputs for certain $l_{\\infty}$ sizes on a reasonable assumption,\nnamely that the training data have the same distribution as the test data. We\ndevelop and evaluate several versions of CTT with a range of defense\ncapabilities, training overheads and certifiability on adversarial samples.\nAgainst adversaries with various $l_p$ norms, CTT outperforms existing defense\nmethods that focus purely on improving network robustness. We show that CTT has\nsmall false positive rates on clean test data, minimal compute overheads when\ndeployed, and can support complex security policies.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 14:10:00 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Shumailov", "Ilia", ""], ["Zhao", "Yiren", ""], ["Mullins", "Robert", ""], ["Anderson", "Ross", ""]]}, {"id": "2002.08774", "submitter": "Victor-Emmanuel Brunel", "authors": "Victor-Emmanuel Brunel and Marco Avella-Medina", "title": "Propose, Test, Release: Differentially private estimation with high\n  probability", "comments": "arXiv admin note: text overlap with arXiv:1906.11923", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive concentration inequalities for differentially private median and\nmean estimators building on the \"Propose, Test, Release\" (PTR) mechanism\nintroduced by Dwork and Lei (2009). We introduce a new general version of the\nPTR mechanism that allows us to derive high probability error bounds for\ndifferentially private estimators. Our algorithms provide the first statistical\nguarantees for differentially private estimation of the median and mean without\nany boundedness assumptions on the data, and without assuming that the target\npopulation parameter lies in some known bounded interval. Our procedures do not\nrely on any truncation of the data and provide the first sub-Gaussian high\nprobability bounds for differentially private median and mean estimation, for\npossibly heavy tailed random variables.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 01:29:05 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Brunel", "Victor-Emmanuel", ""], ["Avella-Medina", "Marco", ""]]}, {"id": "2002.08859", "submitter": "Eitan Richardson", "authors": "Eitan Richardson and Yair Weiss", "title": "A Bayes-Optimal View on Adversarial Examples", "comments": "Minor revision per journal review, 28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Since the discovery of adversarial examples - the ability to fool modern CNN\nclassifiers with tiny perturbations of the input, there has been much\ndiscussion whether they are a \"bug\" that is specific to current neural\narchitectures and training methods or an inevitable \"feature\" of high\ndimensional geometry. In this paper, we argue for examining adversarial\nexamples from the perspective of Bayes-Optimal classification. We construct\nrealistic image datasets for which the Bayes-Optimal classifier can be\nefficiently computed and derive analytic conditions on the distributions under\nwhich these classifiers are provably robust against any adversarial attack even\nin high dimensions. Our results show that even when these \"gold standard\"\noptimal classifiers are robust, CNNs trained on the same datasets consistently\nlearn a vulnerable classifier, indicating that adversarial examples are often\nan avoidable \"bug\". We further show that RBF SVMs trained on the same data\nconsistently learn a robust classifier. The same trend is observed in\nexperiments with real images in different datasets.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 16:43:47 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 09:47:10 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Richardson", "Eitan", ""], ["Weiss", "Yair", ""]]}, {"id": "2002.08912", "submitter": "Yang Xiao", "authors": "Yang Xiao, Ning Zhang, Wenjing Lou, Y. Thomas Hou", "title": "Modeling the Impact of Network Connectivity on Consensus Security of\n  Proof-of-Work Blockchain", "comments": "In proceedings of 2020 IEEE International Conference on Computer\n  Communications (INFOCOM 2020)", "journal-ref": "IEEE INFOCOM 2020 - IEEE Conference on Computer Communications,\n  2020, pp. 1648-1657", "doi": "10.1109/INFOCOM41043.2020.9155451", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain, the technology behind the popular Bitcoin, is considered a\n\"security by design\" system as it is meant to create security among a group of\ndistrustful parties yet without a central trusted authority. The security of\nblockchain relies on the premise of honest-majority, namely, the blockchain\nsystem is assumed to be secure as long as the majority of consensus voting\npower is honest. And in the case of proof-of-work (PoW) blockchain, adversaries\ncannot control more than 50% of the network's gross computing power. However,\nthis 50% threshold is based on the analysis of computing power only, with\nimplicit and idealistic assumptions on the network and node behavior. Recent\nresearches have alluded that factors such as network connectivity, presence of\nblockchain forks, and mining strategy could undermine the consensus security\nassured by the honest-majority, but neither concrete analysis nor quantitative\nevaluation is provided. In this paper we fill the gap by proposing an\nanalytical model to assess the impact of network connectivity on the consensus\nsecurity of PoW blockchain under different adversary models. We apply our\nanalytical model to two adversarial scenarios: 1)\nhonest-but-potentially-colluding, 2) selfish mining. For each scenario, we\nquantify the communication capability of nodes involved in a fork race and\nestimate the adversary's mining revenue and its impact on security properties\nof the consensus protocol. Simulation results validated our analysis. Our\nmodeling and analysis provide a paradigm for assessing the security impact of\nvarious factors in a distributed consensus system.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 17:54:57 GMT"}, {"version": "v2", "created": "Sat, 23 May 2020 18:07:46 GMT"}, {"version": "v3", "created": "Mon, 31 Aug 2020 23:56:40 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Xiao", "Yang", ""], ["Zhang", "Ning", ""], ["Lou", "Wenjing", ""], ["Hou", "Y. Thomas", ""]]}, {"id": "2002.08944", "submitter": "Yassine Hamoudi", "authors": "Yassine Hamoudi and Fr\\'ed\\'eric Magniez", "title": "Quantum Time-Space Tradeoff for Finding Multiple Collision Pairs", "comments": "21 pages; v3: title and presentation changed. Previous title:\n  \"Quantum Time-Space Tradeoffs by Recording Queries\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of finding $K$ collision pairs in a random function $f :\n[N] \\rightarrow [N]$ by using a quantum computer. We prove that the number of\nqueries to the function in the quantum random oracle model must increase\nsignificantly when the size of the available memory is limited. Namely, we\ndemonstrate that any algorithm using $S$ qubits of memory must perform a number\n$T$ of queries that satisfies the tradeoff $T^3 S \\geq \\Omega(K^3 N)$.\nClassically, the same question has only been settled recently by Dinur\n[Eurocrypt'20], who showed that the Parallel Collision Search algorithm of van\nOorschot and Wiener achieves the optimal time-space tradeoff of $T^2 S =\n\\Theta(K^2 N)$. Our result limits the extent to which quantum computing may\ndecrease this tradeoff. We further show that any improvement to our lower bound\nwould imply a breakthrough for a related question about the Element\nDistinctness problem. Our method is based on a novel application of Zhandry's\nrecording query technique [Crypto'19] for proving lower bounds in the\nexponentially small success probability regime.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 18:48:51 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 17:37:10 GMT"}, {"version": "v3", "created": "Sun, 25 Oct 2020 10:49:29 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Hamoudi", "Yassine", ""], ["Magniez", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "2002.08972", "submitter": "Onur G\\\"unl\\\"u Dr.-Ing.", "authors": "Efe Bozkir and Onur G\\\"unl\\\"u, Wolfgang Fuhl, Rafael F. Schaefer, and\n  Enkelejda Kasneci", "title": "Differential Privacy for Eye Tracking with Temporal Correlations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New generation head-mounted displays, such as VR and AR glasses, are coming\ninto the market with already integrated eye tracking and are expected to enable\nnovel ways of human-computer interaction in many applications. However, since\neye movement properties contain biometric information, privacy concerns have to\nbe handled properly. Privacy-preservation techniques such as differential\nprivacy mechanisms have recently been applied to the eye movement data obtained\nfrom such displays. Standard differential privacy mechanisms; however, are\nvulnerable to temporal correlations in the eye movement features. In this work,\nwe propose a novel transform-coding based differential privacy mechanism to\nfurther adapt it to the statistics of eye movement feature data by comparing\nvarious low-complexity methods. We extent Fourier Perturbation Algorithm, which\nis a differential privacy mechanism, and correct a scaling mistake in its\nproof. Furthermore, we illustrate significant reductions in sample correlations\nin addition to query sensitivities, which provide the best utility-privacy\ntrade-off in the eye tracking literature. Our results show significantly high\nprivacy without loss in classification accuracies as well.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 19:01:34 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 14:04:54 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Bozkir", "Efe", ""], ["G\u00fcnl\u00fc", "Onur", ""], ["Fuhl", "Wolfgang", ""], ["Schaefer", "Rafael F.", ""], ["Kasneci", "Enkelejda", ""]]}, {"id": "2002.09069", "submitter": "Mohammad Sujan Miah", "authors": "Iffat Anjum, Mohammad Sujan Miah, Mu Zhu, Nazia Sharmin, Christopher\n  Kiekintveld, William Enck, Munindar P Singh", "title": "Optimizing Vulnerability-Driven Honey Traffic Using Game Theory", "comments": null, "journal-ref": "AAAI Workshop on Artificial Intelligence for Cyber Security\n  (AICS), 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enterprises are increasingly concerned about adversaries that slowly and\ndeliberately exploit resources over the course of months or even years. A key\nstep in this kill chain is network reconnaissance, which has historically been\nactive (e.g., network scans) and therefore detectable. However, new networking\ntechnology increases the possibility of passive network reconnaissance, which\nwill be largely undetectable by defenders. In this paper, we propose Snaz, a\ntechnique that uses deceptively crafted honey traffic to confound the knowledge\ngained through passive network reconnaissance. We present a two-player\nnon-zero-sum Stackelberg game model that characterizes how a defender should\ndeploy honey traffic in the presence of an adversary who is aware of Snaz. In\ndoing so, we demonstrate the existence of optimal defender strategies that will\neither dissuade an adversary from acting on the existence of real\nvulnerabilities observed within network traffic, or reveal the adversary's\npresence when it attempts to unknowingly attack an intrusion detection node.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 00:14:44 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Anjum", "Iffat", ""], ["Miah", "Mohammad Sujan", ""], ["Zhu", "Mu", ""], ["Sharmin", "Nazia", ""], ["Kiekintveld", "Christopher", ""], ["Enck", "William", ""], ["Singh", "Munindar P", ""]]}, {"id": "2002.09096", "submitter": "Olivia Choudhury", "authors": "Olivia Choudhury, Aris Gkoulalas-Divanis, Theodoros Salonidis, Issa\n  Sylla, Yoonyoung Park, Grace Hsu, Amar Das", "title": "Anonymizing Data for Privacy-Preserving Federated Learning", "comments": "24th European Conference on Artificial Intelligence (ECAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning enables training a global machine learning model from data\ndistributed across multiple sites, without having to move the data. This is\nparticularly relevant in healthcare applications, where data is rife with\npersonal, highly-sensitive information, and data analysis methods must provably\ncomply with regulatory guidelines. Although federated learning prevents sharing\nraw data, it is still possible to launch privacy attacks on the model\nparameters that are exposed during the training process, or on the generated\nmachine learning model. In this paper, we propose the first syntactic approach\nfor offering privacy in the context of federated learning. Unlike the\nstate-of-the-art differential privacy-based frameworks, our approach aims to\nmaximize utility or model performance, while supporting a defensible level of\nprivacy, as demanded by GDPR and HIPAA. We perform a comprehensive empirical\nevaluation on two important problems in the healthcare domain, using real-world\nelectronic health data of 1 million patients. The results demonstrate the\neffectiveness of our approach in achieving high model performance, while\noffering the desired level of privacy. Through comparative studies, we also\nshow that, for varying datasets, experimental setups, and privacy budgets, our\napproach offers higher model performance than differential privacy-based\ntechniques in federated learning.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 02:30:16 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Choudhury", "Olivia", ""], ["Gkoulalas-Divanis", "Aris", ""], ["Salonidis", "Theodoros", ""], ["Sylla", "Issa", ""], ["Park", "Yoonyoung", ""], ["Hsu", "Grace", ""], ["Das", "Amar", ""]]}, {"id": "2002.09125", "submitter": "Hong-Bin Chen", "authors": "Hong-Bin Chen, Hsiang-Chun Hsu and Justie Su-Tzu Juan", "title": "An Easy-to-implement Construction for $(k,n)$-threshold Progressive\n  Visual Secret Sharing Schemes", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual cryptography encrypts the secret image into $n$ shares (transparency)\nso that only stacking a qualified number of shares can recover the secret image\nby the human visual system while no information can be revealed without a large\nenough number of shares. This paper investigates the $(k,n)$-threshold Visual\nSecret Sharing (VSS) model, where one can decrypt the original image by\nstacking at least $k$ shares and get nothing with less than $k$ shares. There\nare two main approaches in the literature: codebook-based schemes and\nrandom-grid-based schemes; the former is the case of this paper. In general,\ngiven any positive integers $k$ and $n$, it is not easy to design a valid\nscheme for the $(k,n)$-threshold VSS model. In this paper, we propose a simple\nstrategy to construct an efficient scheme for the $(k,n)$-threshold VSS model\nfor any positive integers $2\\leq k\\leq n$. The crucial idea is to establish a\nseemingly unrelated connection between the $(k,n)$-threshold VSS scheme and a\nmathematical structure -- the generalized Pascal's triangle. This paper\nimproves and extends previous results in four aspects: Our construction offers\na unified viewpoint and covers several known results;\n  The resulting scheme has a progressive-viewing property that means the more\nshares being stacked together the clearer the secret image would be revealed.\n  The proposed scheme can be constructed explicitly and efficiently based on\nthe generalized Pascal's triangle without a computer. Performance of the\nproposed scheme is comparable with known results.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 04:30:45 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Chen", "Hong-Bin", ""], ["Hsu", "Hsiang-Chun", ""], ["Juan", "Justie Su-Tzu", ""]]}, {"id": "2002.09169", "submitter": "Dinghuai Zhang", "authors": "Dinghuai Zhang, Mao Ye, Chengyue Gong, Zhanxing Zhu, Qiang Liu", "title": "Black-Box Certification with Randomized Smoothing: A Functional\n  Optimization Based Framework", "comments": "Accepted by NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized classifiers have been shown to provide a promising approach for\nachieving certified robustness against adversarial attacks in deep learning.\nHowever, most existing methods only leverage Gaussian smoothing noise and only\nwork for $\\ell_2$ perturbation. We propose a general framework of adversarial\ncertification with non-Gaussian noise and for more general types of attacks,\nfrom a unified functional optimization perspective. Our new framework allows us\nto identify a key trade-off between accuracy and robustness via designing\nsmoothing distributions, helping to design new families of non-Gaussian\nsmoothing distributions that work more efficiently for different $\\ell_p$\nsettings, including $\\ell_1$, $\\ell_2$ and $\\ell_\\infty$ attacks. Our proposed\nmethods achieve better certification results than previous works and provide a\nnew perspective on randomized smoothing certification.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 07:52:47 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 08:27:06 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Zhang", "Dinghuai", ""], ["Ye", "Mao", ""], ["Gong", "Chengyue", ""], ["Zhu", "Zhanxing", ""], ["Liu", "Qiang", ""]]}, {"id": "2002.09182", "submitter": "Farhan Musanna", "authors": "Farhan Musanna, Sanjeev Kumar", "title": "Quantum secret sharing using GHZ state qubit positioning and selective\n  qubits strategy for secret reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The work presents a novel quantum secret sharing strategy based on GHZ\nproduct state sharing between three parties. The dealer, based on the classical\ninformation to be shared, toggles his qubit and shares the product state. The\nother parties make their Bell measurements and collude to reconstruct the\nsecret. Unlike the other protocols, this protocol does not involve the entire\ninitial state reconstruction, rather uses selective qubits to discard the\nredundant qubits at the time of reconstruction to decrypt the secret. The\nprotocol also allows for security against malicious attacks by an adversary\nwithout affecting the integrity of the secret. The security of the protocol\nlies in the fact that each party's correct announcement of their measurement is\nrequired for reconstruction, failing which the reconstruction process is\njeopardized, thereby ascertaining the $(3,3)$ scheme which can further be\nextended for a $(n,n)$ scheme.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 08:45:07 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Musanna", "Farhan", ""], ["Kumar", "Sanjeev", ""]]}, {"id": "2002.09190", "submitter": "Chadni Islam", "authors": "Chadni Islam, M. Ali Babar and Surya Nepal", "title": "A Multi-Vocal Review of Security Orchestration", "comments": "This paper is published in ACM Computing Survey", "journal-ref": "ACM Comput. Surv. 52, 2, Article 37 (April 2019), 45 pages", "doi": "10.1145/3305268", "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Organizations use diverse types of security solutions to prevent\ncyberattacks. Multiple vendors provide security solutions developed using\nheterogeneous technologies and paradigms. Hence, it is a challenging rather\nimpossible to easily make security solutions to work an integrated fashion.\nSecurity orchestration aims at smoothly integrating multivendor security tools\nthat can effectively and efficiently interoperate to support security staff of\na Security Operation Centre (SOC). Given the increasing role and importance of\nsecurity orchestration, there has been an increasing amount of literature on\ndifferent aspects of security orchestration solutions. However, there has been\nno effort to systematically review and analyze the reported solutions. We\nreport a Multivocal Literature Review that has systematically selected and\nreviewed both academic and grey (blogs, web pages, white papers) literature on\ndifferent aspects of security orchestration published from January 2007 until\nJuly 2017. The review has enabled us to provide a working definition of\nsecurity orchestration and classify the main functionalities of security\norchestration into three main areas: unification, orchestration, and\nautomation. We have also identified the core components of a security\norchestration platform and categorized the drivers of security orchestration\nbased on technical and socio-technical aspects. We also provide a taxonomy of\nsecurity orchestration based on the execution environment, automation strategy,\ndeployment type, mode of task and resource type. This review has helped us to\nreveal several areas of further research and development in security\norchestration.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 09:08:35 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Islam", "Chadni", ""], ["Babar", "M. Ali", ""], ["Nepal", "Surya", ""]]}, {"id": "2002.09239", "submitter": "Omar Reyad", "authors": "O. Reyad, M. E. Karar, K. Hamed", "title": "Random Bit Generator Mechanism Based on Elliptic Curves and Secure Hash\n  Function", "comments": "6 pages, 8 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pseudorandom bit generators (PRBG) can be designed to take the advantage of\nsome hard number theoretic problems such as the discrete logarithm problem\n(DLP). Such type of generators will have good randomness and unpredictability\nproperties as it is so difficult to find an easy solution to the regarding\nmathematical dilemma. Hash functions in turn play a remarkable role in many\ncryptographic tasks to achieve various security strengths. In this paper, a\npseudorandom bit generator mechanism that is based mainly on the elliptic curve\ndiscrete logarithm problem (ECDLP) and hash derivation function is proposed.\nThe cryptographic hash functions are used in consuming applications that\nrequire various security strengths. In a good hash function, finding whatever\nthe input that can be mapped to any pre-specified output is considered\ncomputationally infeasible. The obtained pseudorandom bits are tested with NIST\nstatistical tests and it also could fulfill the up-to-date standards. Moreover,\na $256 \\times 256$ grayscale images are encrypted with the obtained\npseudorandom bits following by necessary analysis of the cipher images for\nsecurity prove.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 11:53:51 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Reyad", "O.", ""], ["Karar", "M. E.", ""], ["Hamed", "K.", ""]]}, {"id": "2002.09463", "submitter": "Huanyu Zhang", "authors": "Huanyu Zhang, Gautam Kamath, Janardhan Kulkarni, Zhiwei Steven Wu", "title": "Privately Learning Markov Random Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning Markov Random Fields (including the\nprototypical example, the Ising model) under the constraint of differential\nprivacy. Our learning goals include both structure learning, where we try to\nestimate the underlying graph structure of the model, as well as the harder\ngoal of parameter learning, in which we additionally estimate the parameter on\neach edge. We provide algorithms and lower bounds for both problems under a\nvariety of privacy constraints -- namely pure, concentrated, and approximate\ndifferential privacy. While non-privately, both learning goals enjoy roughly\nthe same complexity, we show that this is not the case under differential\nprivacy. In particular, only structure learning under approximate differential\nprivacy maintains the non-private logarithmic dependence on the dimensionality\nof the data, while a change in either the learning goal or the privacy notion\nwould necessitate a polynomial dependence. As a result, we show that the\nprivacy constraint imposes a strong separation between these two learning\nproblems in the high-dimensional data regime.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 18:30:48 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 14:24:58 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Zhang", "Huanyu", ""], ["Kamath", "Gautam", ""], ["Kulkarni", "Janardhan", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "2002.09464", "submitter": "Vikrant Singhal", "authors": "Gautam Kamath, Vikrant Singhal, Jonathan Ullman", "title": "Private Mean Estimation of Heavy-Tailed Distributions", "comments": "Appeared in COLT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give new upper and lower bounds on the minimax sample complexity of\ndifferentially private mean estimation of distributions with bounded $k$-th\nmoments. Roughly speaking, in the univariate case, we show that $n =\n\\Theta\\left(\\frac{1}{\\alpha^2} +\n\\frac{1}{\\alpha^{\\frac{k}{k-1}}\\varepsilon}\\right)$ samples are necessary and\nsufficient to estimate the mean to $\\alpha$-accuracy under\n$\\varepsilon$-differential privacy, or any of its common relaxations. This\nresult demonstrates a qualitatively different behavior compared to estimation\nabsent privacy constraints, for which the sample complexity is identical for\nall $k \\geq 2$. We also give algorithms for the multivariate setting whose\nsample complexity is a factor of $O(d)$ larger than the univariate case.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 18:30:48 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 22:24:31 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 17:06:17 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Kamath", "Gautam", ""], ["Singhal", "Vikrant", ""], ["Ullman", "Jonathan", ""]]}, {"id": "2002.09465", "submitter": "Gautam Kamath", "authors": "Sivakanth Gopi, Gautam Kamath, Janardhan Kulkarni, Aleksandar Nikolov,\n  Zhiwei Steven Wu, Huanyu Zhang", "title": "Locally Private Hypothesis Selection", "comments": "To appear in COLT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the study of hypothesis selection under local differential\nprivacy. Given samples from an unknown probability distribution $p$ and a set\nof $k$ probability distributions $\\mathcal{Q}$, we aim to output, under the\nconstraints of $\\varepsilon$-local differential privacy, a distribution from\n$\\mathcal{Q}$ whose total variation distance to $p$ is comparable to the best\nsuch distribution. This is a generalization of the classic problem of $k$-wise\nsimple hypothesis testing, which corresponds to when $p \\in \\mathcal{Q}$, and\nwe wish to identify $p$. Absent privacy constraints, this problem requires\n$O(\\log k)$ samples from $p$, and it was recently shown that the same\ncomplexity is achievable under (central) differential privacy. However, the\nnaive approach to this problem under local differential privacy would require\n$\\tilde O(k^2)$ samples.\n  We first show that the constraint of local differential privacy incurs an\nexponential increase in cost: any algorithm for this problem requires at least\n$\\Omega(k)$ samples. Second, for the special case of $k$-wise simple hypothesis\ntesting, we provide a non-interactive algorithm which nearly matches this\nbound, requiring $\\tilde O(k)$ samples. Finally, we provide sequentially\ninteractive algorithms for the general case, requiring $\\tilde O(k)$ samples\nand only $O(\\log \\log k)$ rounds of interactivity. Our algorithms are achieved\nthrough a reduction to maximum selection with adversarial comparators, a\nproblem of independent interest for which we initiate study in the parallel\nsetting. For this problem, we provide a family of algorithms for each number of\nallowed rounds of interaction $t$, as well as lower bounds showing that they\nare near-optimal for every $t$. Notably, our algorithms result in exponential\nimprovements on the round complexity of previous methods.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 18:30:48 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 02:58:48 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Gopi", "Sivakanth", ""], ["Kamath", "Gautam", ""], ["Kulkarni", "Janardhan", ""], ["Nikolov", "Aleksandar", ""], ["Wu", "Zhiwei Steven", ""], ["Zhang", "Huanyu", ""]]}, {"id": "2002.09546", "submitter": "Muhammad Ali Siddiqi", "authors": "Muhammad Ali Siddiqi, Christian Doerr, Christos Strydis", "title": "IMDfence: Architecting a Secure Protocol for Implantable Medical Devices", "comments": "17 pages, Accepted by IEEE Access", "journal-ref": "IEEE Access, 2020", "doi": "10.1109/ACCESS.2020.3015686", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over the past decade, focus on the security and privacy aspects of\nimplantable medical devices (IMDs) has intensified, driven by the multitude of\ncybersecurity vulnerabilities found in various existing devices. However, due\nto their strict computational, energy and physical constraints, conventional\nsecurity protocols are not directly applicable to IMDs. Custom-tailored schemes\nhave been proposed instead which, however, fail to cover the full spectrum of\nsecurity features that modern IMDs and their ecosystems so critically require.\nIn this paper we propose IMDfence, a security protocol for IMD ecosystems that\nprovides a comprehensive yet practical security portfolio, which includes\navailability, non-repudiation, access control, entity authentication, remote\nmonitoring and system scalability. The protocol also allows emergency access\nthat results in the graceful degradation of offered services without\ncompromising security and patient safety. The performance of the security\nprotocol as well as its feasibility and impact on modern IMDs are extensively\nanalyzed and evaluated. We find that IMDfence achieves the above security\nrequirements at a mere less than 7% increase in total IMD energy consumption,\nand less than 14 ms and 9 kB increase in system delay and memory footprint,\nrespectively.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 20:46:05 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 11:27:51 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 22:11:03 GMT"}, {"version": "v4", "created": "Thu, 13 Aug 2020 09:34:22 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Siddiqi", "Muhammad Ali", ""], ["Doerr", "Christian", ""], ["Strydis", "Christos", ""]]}, {"id": "2002.09560", "submitter": "Eunjung Yoon", "authors": "Eunjung Yoon, Peng Liu", "title": "Practical Verification of MapReduce Computation Integrity via Partial\n  Re-execution", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big data processing is often outsourced to powerful, but untrusted cloud\nservice providers that provide agile and scalable computing resources to weaker\nclients. However, untrusted cloud services do not ensure the integrity of data\nand computations while clients have no control over the outsourced computation\nor no means to check the correctness of the execution. Despite a growing\ninterest and recent progress in verifiable computation, the existing techniques\nare still not practical enough for big data processing due to high verification\noverhead. In this paper, we present a solution called V-MR (Verifiable\nMapReduce), which is a framework that verifies the integrity of MapReduce\ncomputation outsourced in the untrusted cloud via partial re-execution. V-MR is\npractically effective and efficient in that (1) it can detect the violation of\nMapReduce computation integrity and identify the malicious workers involved in\nthe that produced the incorrect computation. (2) it can reduce the overhead of\nverification via partial re-execution with carefully selected input data and\nprogram code using program analysis. The experiment results of a prototype of\nV-MR show that V-MR can verify the integrity of MapReduce computation\neffectively with small overhead for partial re-execution.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 21:49:21 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Yoon", "Eunjung", ""], ["Liu", "Peng", ""]]}, {"id": "2002.09565", "submitter": "Micah Goldblum", "authors": "Micah Goldblum, Avi Schwarzschild, Ankit B. Patel, Tom Goldstein", "title": "Adversarial Attacks on Machine Learning Systems for High-Frequency\n  Trading", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic trading systems are often completely automated, and deep learning\nis increasingly receiving attention in this domain. Nonetheless, little is\nknown about the robustness properties of these models. We study valuation\nmodels for algorithmic trading from the perspective of adversarial machine\nlearning. We introduce new attacks specific to this domain with size\nconstraints that minimize attack costs. We further discuss how these attacks\ncan be used as an analysis tool to study and evaluate the robustness properties\nof financial models. Finally, we investigate the feasibility of realistic\nadversarial attacks in which an adversarial trader fools automated trading\nsystems into making inaccurate predictions.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 22:04:35 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 18:20:18 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 01:55:01 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Goldblum", "Micah", ""], ["Schwarzschild", "Avi", ""], ["Patel", "Ankit B.", ""], ["Goldstein", "Tom", ""]]}, {"id": "2002.09576", "submitter": "Scott Freitas", "authors": "Scott Freitas, Shang-Tse Chen, Zijie J. Wang, Duen Horng Chau", "title": "UnMask: Adversarial Detection and Defense Through Robust Feature\n  Alignment", "comments": "Accepted into IEEE Big Data 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models are being integrated into a wide range of high-impact,\nsecurity-critical systems, from self-driving cars to medical diagnosis.\nHowever, recent research has demonstrated that many of these deep learning\narchitectures are vulnerable to adversarial attacks--highlighting the vital\nneed for defensive techniques to detect and mitigate these attacks before they\noccur. To combat these adversarial attacks, we developed UnMask, an adversarial\ndetection and defense framework based on robust feature alignment. The core\nidea behind UnMask is to protect these models by verifying that an image's\npredicted class (\"bird\") contains the expected robust features (e.g., beak,\nwings, eyes). For example, if an image is classified as \"bird\", but the\nextracted features are wheel, saddle and frame, the model may be under attack.\nUnMask detects such attacks and defends the model by rectifying the\nmisclassification, re-classifying the image based on its robust features. Our\nextensive evaluation shows that UnMask (1) detects up to 96.75% of attacks, and\n(2) defends the model by correctly classifying up to 93% of adversarial images\nproduced by the current strongest attack, Projected Gradient Descent, in the\ngray-box setting. UnMask provides significantly better protection than\nadversarial training across 8 attack vectors, averaging 31.18% higher accuracy.\nWe open source the code repository and data with this paper:\nhttps://github.com/safreita1/unmask.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 23:20:23 GMT"}, {"version": "v2", "created": "Sat, 14 Nov 2020 20:21:11 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Freitas", "Scott", ""], ["Chen", "Shang-Tse", ""], ["Wang", "Zijie J.", ""], ["Chau", "Duen Horng", ""]]}, {"id": "2002.09629", "submitter": "Aron Laszka", "authors": "Sadegh Farhang, Mehmet Bahadir Kirdan, Aron Laszka, Jens Grossklags", "title": "An Empirical Study of Android Security Bulletins in Different Vendors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile devices encroach on almost every part of our lives, including work and\nleisure, and contain a wealth of personal and sensitive information. It is,\ntherefore, imperative that these devices uphold high security standards. A key\naspect is the security of the underlying operating system. In particular,\nAndroid plays a critical role due to being the most dominant platform in the\nmobile ecosystem with more than one billion active devices and due to its\nopenness, which allows vendors to adopt and customize it. Similar to other\nplatforms, Android maintains security by providing monthly security patches and\nannouncing them via the Android security bulletin. To absorb this information\nsuccessfully across the Android ecosystem, impeccable coordination by many\ndifferent vendors is required.\n  In this paper, we perform a comprehensive study of 3,171 Android-related\nvulnerabilities and study to which degree they are reflected in the Android\nsecurity bulletin, as well as in the security bulletins of three leading\nvendors: Samsung, LG, and Huawei. In our analysis, we focus on the metadata of\nthese security bulletins (e.g., timing, affected layers, severity, and CWE\ndata) to better understand the similarities and differences among vendors. We\nfind that (i) the studied vendors in the Android ecosystem have adopted\ndifferent structures for vulnerability reporting, (ii) vendors are less likely\nto react with delay for CVEs with Android Git repository references, (iii)\nvendors handle Qualcomm-related CVEs differently from the rest of external\nlayer CVEs.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 05:25:07 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Farhang", "Sadegh", ""], ["Kirdan", "Mehmet Bahadir", ""], ["Laszka", "Aron", ""], ["Grossklags", "Jens", ""]]}, {"id": "2002.09632", "submitter": "Guanxiong Liu", "authors": "Guanxiong Liu, Issa Khalil, Abdallah Khreishah", "title": "Using Single-Step Adversarial Training to Defend Iterative Adversarial\n  Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples have become one of the largest challenges that machine\nlearning models, especially neural network classifiers, face. These adversarial\nexamples break the assumption of attack-free scenario and fool state-of-the-art\n(SOTA) classifiers with insignificant perturbations to human. So far,\nresearchers achieved great progress in utilizing adversarial training as a\ndefense. However, the overwhelming computational cost degrades its\napplicability and little has been done to overcome this issue. Single-Step\nadversarial training methods have been proposed as computationally viable\nsolutions, however they still fail to defend against iterative adversarial\nexamples. In this work, we first experimentally analyze several different SOTA\ndefense methods against adversarial examples. Then, based on observations from\nexperiments, we propose a novel single-step adversarial training method which\ncan defend against both single-step and iterative adversarial examples. Lastly,\nthrough extensive evaluations, we demonstrate that our proposed method\noutperforms the SOTA single-step and iterative adversarial training defense.\nCompared with ATDA (single-step method) on CIFAR10 dataset, our proposed method\nachieves 35.67% enhancement in test accuracy and 19.14% reduction in training\ntime. When compared with methods that use BIM or Madry examples (iterative\nmethods) on CIFAR10 dataset, it saves up to 76.03% in training time with less\nthan 3.78% degeneration in test accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 05:36:35 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 17:24:24 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Liu", "Guanxiong", ""], ["Khalil", "Issa", ""], ["Khreishah", "Abdallah", ""]]}, {"id": "2002.09689", "submitter": "Carlos Sarraute PhD", "authors": "Ariel Futoransky, Carlos Sarraute, Daniel Fernandez, Matias Travizano,\n  Ariel Waissbein", "title": "Fair and Decentralized Exchange of Digital Goods", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We construct a privacy-preserving, distributed and decentralized marketplace\nwhere parties can exchange data for tokens. In this market, buyers and sellers\nmake transactions in a blockchain and interact with a third party, called\nnotary, who has the ability to vouch for the authenticity and integrity of the\ndata.\n  We introduce a protocol for the data-token exchange where neither party gains\nmore information than what it is paying for, and the exchange is fair: either\nboth parties gets the other's item or neither does. No third party involvement\nis required after setup, and no dispute resolution is needed.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 11:32:16 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Futoransky", "Ariel", ""], ["Sarraute", "Carlos", ""], ["Fernandez", "Daniel", ""], ["Travizano", "Matias", ""], ["Waissbein", "Ariel", ""]]}, {"id": "2002.09745", "submitter": "Judy Hanwen Shen", "authors": "Sivakanth Gopi, Pankaj Gulhane, Janardhan Kulkarni, Judy Hanwen Shen,\n  Milad Shokouhi and Sergey Yekhanin", "title": "Differentially Private Set Union", "comments": "23 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the basic operation of set union in the global model of differential\nprivacy. In this problem, we are given a universe $U$ of items, possibly of\ninfinite size, and a database $D$ of users. Each user $i$ contributes a subset\n$W_i \\subseteq U$ of items. We want an ($\\epsilon$,$\\delta$)-differentially\nprivate algorithm which outputs a subset $S \\subset \\cup_i W_i$ such that the\nsize of $S$ is as large as possible. The problem arises in countless real world\napplications; it is particularly ubiquitous in natural language processing\n(NLP) applications as vocabulary extraction. For example, discovering words,\nsentences, $n$-grams etc., from private text data belonging to users is an\ninstance of the set union problem.\n  Known algorithms for this problem proceed by collecting a subset of items\nfrom each user, taking the union of such subsets, and disclosing the items\nwhose noisy counts fall above a certain threshold. Crucially, in the above\nprocess, the contribution of each individual user is always independent of the\nitems held by other users, resulting in a wasteful aggregation process, where\nsome item counts happen to be way above the threshold. We deviate from the\nabove paradigm by allowing users to contribute their items in a\n$\\textit{dependent fashion}$, guided by a $\\textit{policy}$. In this new\nsetting ensuring privacy is significantly delicate. We prove that any policy\nwhich has certain $\\textit{contractive}$ properties would result in a\ndifferentially private algorithm. We design two new algorithms, one using\nLaplace noise and other Gaussian noise, as specific instances of policies\nsatisfying the contractive properties. Our experiments show that the new\nalgorithms significantly outperform previously known mechanisms for the\nproblem.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 18:33:14 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Gopi", "Sivakanth", ""], ["Gulhane", "Pankaj", ""], ["Kulkarni", "Janardhan", ""], ["Shen", "Judy Hanwen", ""], ["Shokouhi", "Milad", ""], ["Yekhanin", "Sergey", ""]]}, {"id": "2002.09772", "submitter": "Aly El Gamal", "authors": "Kirthi Shankar Sivamani, Rajeev Sahay, Aly El Gamal", "title": "Non-Intrusive Detection of Adversarial Deep Learning Attacks via\n  Observer Networks", "comments": "5 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that deep learning models are vulnerable to\nspecifically crafted adversarial inputs that are quasi-imperceptible to humans.\nIn this letter, we propose a novel method to detect adversarial inputs, by\naugmenting the main classification network with multiple binary detectors\n(observer networks) which take inputs from the hidden layers of the original\nnetwork (convolutional kernel outputs) and classify the input as clean or\nadversarial. During inference, the detectors are treated as a part of an\nensemble network and the input is deemed adversarial if at least half of the\ndetectors classify it as so. The proposed method addresses the trade-off\nbetween accuracy of classification on clean and adversarial samples, as the\noriginal classification network is not modified during the detection process.\nThe use of multiple observer networks makes attacking the detection mechanism\nnon-trivial even when the attacker is aware of the victim classifier. We\nachieve a 99.5% detection accuracy on the MNIST dataset and 97.5% on the\nCIFAR-10 dataset using the Fast Gradient Sign Attack in a semi-white box setup.\nThe number of false positive detections is a mere 0.12% in the worst case\nscenario.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 21:13:00 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Sivamani", "Kirthi Shankar", ""], ["Sahay", "Rajeev", ""], ["Gamal", "Aly El", ""]]}, {"id": "2002.09834", "submitter": "Lior Rokach", "authors": "Sigal Shaked, Lior Rokach", "title": "PrivGen: Preserving Privacy of Sequences Through Data Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential data is everywhere, and it can serve as a basis for research that\nwill lead to improved processes. For example, road infrastructure can be\nimproved by identifying bottlenecks in GPS data, or early diagnosis can be\nimproved by analyzing patterns of disease progression in medical data. The main\nobstacle is that access and use of such data is usually limited or not\npermitted at all due to concerns about violating user privacy, and rightly so.\nAnonymizing sequence data is not a simple task, since a user creates an almost\nunique signature over time. Existing anonymization methods reduce the quality\nof information in order to maintain the level of anonymity required. Damage to\nquality may disrupt patterns that appear in the original data and impair the\npreservation of various characteristics. Since in many cases the researcher\ndoes not need the data as is and instead is only interested in the patterns\nthat exist in the data, we propose PrivGen, an innovative method for generating\ndata that maintains patterns and characteristics of the source data. We\ndemonstrate that the data generation mechanism significantly limits the risk of\nprivacy infringement. Evaluating our method with real-world datasets shows that\nits generated data preserves many characteristics of the data, including the\nsequential model, as trained based on the source data. This suggests that the\ndata generated by our method could be used in place of actual data for various\ntypes of analysis, maintaining user privacy and the data's integrity at the\nsame time.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 05:43:15 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Shaked", "Sigal", ""], ["Rokach", "Lior", ""]]}, {"id": "2002.09843", "submitter": "Yan Feng", "authors": "Xue Yang, Yan Feng, Weijun Fang, Jun Shao, Xiaohu Tang, Shu-Tao Xia,\n  Rongxing Lu", "title": "Computation-efficient Deep Model Training for Ciphertext-based\n  Cross-silo Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although cross-silo federated learning improves privacy of training data by\nexchanging model updates rather than raw data, sharing updates (e.g., local\ngradients or parameters) may still involve risks. To ensure no updates are\nrevealed to the server, industrial FL schemes allow clients (e.g., financial or\nmedical) to mask local gradients by homomorphic encryption (HE). In this case,\nthe server cannot obtain the updates, but the curious clients can obtain this\ninformation to infer other clients' private data. To alleviate this situation,\nthe most direct idea is to let clients train deep models on encrypted domain.\nUnfortunately, the resulting solution is of poor accuracy and high cost, since\nthe existing advanced HE is incompatible with non-linear activation functions\nand inefficient in terms of computational cost. In this paper, we propose a\n\\emph{computational-efficient deep model training scheme for ciphertext-based\ncross-silo federated learning} to comprehensively guarantee privacy. First, we\ncustomize \\emph{a novel one-time-pad-style model encryption method} to directly\nsupports non-linear activation functions and decimal arithmetic operations on\nthe encrypted domain. Then, we design a hybrid privacy-preserving scheme by\ncombining our model encryption method with secret sharing techniques to keep\nupdates secret from the clients and prevent the server from obtaining local\ngradients of each client. Extensive experiments demonstrate that for both\nregression and classification tasks, our scheme achieves the same accuracy as\nnon-private approaches and outperforms the state-of-the-art HE-based scheme.\nBesides, training time of our scheme is almost the same as non-private\napproaches and much more efficient than HE-based schemes. Our scheme trains a\n$9$-layer neural network on the MNIST dataset in less than one hour.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 06:50:20 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 02:24:04 GMT"}, {"version": "v3", "created": "Thu, 6 Aug 2020 15:10:37 GMT"}, {"version": "v4", "created": "Mon, 25 Jan 2021 08:35:48 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Yang", "Xue", ""], ["Feng", "Yan", ""], ["Fang", "Weijun", ""], ["Shao", "Jun", ""], ["Tang", "Xiaohu", ""], ["Xia", "Shu-Tao", ""], ["Lu", "Rongxing", ""]]}, {"id": "2002.09864", "submitter": "Daniel Teitelman Mr", "authors": "Daniel Teitelman, Itay Naeh and Shie Mannor", "title": "Stealing Black-Box Functionality Using The Deep Neural Tree Architecture", "comments": "8 pages, 7 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper makes a substantial step towards cloning the functionality of\nblack-box models by introducing a Machine learning (ML) architecture named Deep\nNeural Trees (DNTs). This new architecture can learn to separate different\ntasks of the black-box model, and clone its task-specific behavior. We propose\nto train the DNT using an active learning algorithm to obtain faster and more\nsample-efficient training. In contrast to prior work, we study a complex\n\"victim\" black-box model based solely on input-output interactions, while at\nthe same time the attacker and the victim model may have completely different\ninternal architectures. The attacker is a ML based algorithm whereas the victim\nis a generally unknown module, such as a multi-purpose digital chip, complex\nanalog circuit, mechanical system, software logic or a hybrid of these. The\ntrained DNT module not only can function as the attacked module, but also\nprovides some level of explainability to the cloned model due to the tree-like\nnature of the proposed architecture.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 09:04:30 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Teitelman", "Daniel", ""], ["Naeh", "Itay", ""], ["Mannor", "Shie", ""]]}, {"id": "2002.10009", "submitter": "Matthew Nance Hall", "authors": "Matthew Hall, Ramakrishnan Durairajan, Vyas Sekar", "title": "Fighting Fire with Light: A Case for Defending DDoS Attacks Using the\n  Optical Layer", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The DDoS attack landscape is growing at an unprecedented pace. Inspired by\nthe recent advances in optical networking, we make a case for optical\nlayer-aware DDoS defense (O-LAD) in this paper. Our approach leverages the\noptical layer to isolate attack traffic rapidly via dynamic reconfiguration of\n(backup) wavelengths using ROADMs---bridging the gap between (a) evolution of\nthe DDoS attack landscape and (b) innovations in the optical layer (e.g.,\nreconfigurable optics). We show that the physical separation of traffic\nprofiles allows finer-grained handling of suspicious flows and offers better\nperformance for benign traffic in the face of an attack. We present preliminary\nresults modeling throughput and latency for legitimate flows while scaling the\nstrength of attacks. We also identify a number of open problems for the\nsecurity, optical, and systems communities: modeling diverse DDoS attacks\n(e.g., fixed vs. variable rate, detectable vs. undetectable), building a\nfull-fledged defense system with optical advancements (e.g., OpenConfig), and\noptical layer-aware defenses for a broader class of attacks (e.g., network\nreconnaissance).\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 22:54:30 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Hall", "Matthew", ""], ["Durairajan", "Ramakrishnan", ""], ["Sekar", "Vyas", ""]]}, {"id": "2002.10055", "submitter": "Alireza Partovi", "authors": "Alireza Partovi, Wei Zheng, Taeho Jung, and Hai Lin", "title": "Ensuring Privacy in Location-Based Services: A Model-based Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the widespread of mobile devices equipped with GPS and\ncommunication chips has led to the growing use of location-based services (LBS)\nin which a user receives a service based on his current location. The\ndisclosure of user's location, however, can raise serious concerns about user\nprivacy in general, and location privacy in particular which led to the\ndevelopment of various location privacy-preserving mechanisms aiming to enhance\nthe location privacy while using LBS applications. In this paper, we propose to\nmodel the user mobility pattern and utility of the LBS as a Markov decision\nprocess (MDP), and inspired by probabilistic current state opacity notation, we\nintroduce a new location privacy metric, namely $\\epsilon-$privacy, that\nquantifies the adversary belief over the user's current location. We exploit\nthis dynamic model to design a LPPM that while it ensures the utility of\nservice is being fully utilized, independent of the adversary prior knowledge\nabout the user, it can guarantee a user-specified privacy level can be achieved\nfor an infinite time horizon. The overall privacy-preserving framework,\nincluding the construction of the user mobility model as a MDP, and design of\nthe proposed LPPM, are demonstrated and validated with real-world experimental\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 03:07:08 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Partovi", "Alireza", ""], ["Zheng", "Wei", ""], ["Jung", "Taeho", ""], ["Lin", "Hai", ""]]}, {"id": "2002.10252", "submitter": "Negin Entezari", "authors": "Negin Entezari, Evangelos E. Papalexakis", "title": "TensorShield: Tensor-based Defense Against Adversarial Attacks on Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have demonstrated that machine learning approaches like deep\nneural networks (DNNs) are easily fooled by adversarial attacks. Subtle and\nimperceptible perturbations of the data are able to change the result of deep\nneural networks. Leveraging vulnerable machine learning methods raises many\nconcerns especially in domains where security is an important factor.\nTherefore, it is crucial to design defense mechanisms against adversarial\nattacks. For the task of image classification, unnoticeable perturbations\nmostly occur in the high-frequency spectrum of the image. In this paper, we\nutilize tensor decomposition techniques as a preprocessing step to find a\nlow-rank approximation of images which can significantly discard high-frequency\nperturbations. Recently a defense framework called Shield could \"vaccinate\"\nConvolutional Neural Networks (CNN) against adversarial examples by performing\nrandom-quality JPEG compressions on local patches of images on the ImageNet\ndataset. Our tensor-based defense mechanism outperforms the SLQ method from\nShield by 14% against FastGradient Descent (FGSM) adversarial attacks, while\nmaintaining comparable speed.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 00:39:49 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Entezari", "Negin", ""], ["Papalexakis", "Evangelos E.", ""]]}, {"id": "2002.10289", "submitter": "Alberto Sonnino", "authors": "Zhiyi Zhang, Micha{\\l} Kr\\'ol, Alberto Sonnino, Lixia Zhang, Etienne\n  Rivi\\`ere", "title": "EL PASSO: Privacy-preserving, Asynchronous Single Sign-On", "comments": null, "journal-ref": "Privacy Enhancing Technologies Symposium (PETS); 2021 (2): 70-87", "doi": "10.2478/popets-2021-0018", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce EL PASSO, a privacy-preserving, asynchronous Single Sign-On\n(SSO) system. It enables personal authentication while protecting users'\nprivacy against both identity providers and relying parties, and allows\nselective attribute disclosure. EL PASSO is based on anonymous credentials, yet\nit supports users' accountability. Selected authorities may recover the\nidentity of allegedly misbehaving users, and users can prove properties about\ntheir identity without revealing it in the clear. EL PASSO does not require\nspecific secure hardware or a third party (other than existing participants in\nSSO). The generation and use of authentication credentials are asynchronous,\nallowing users to sign on when identity providers are temporarily unavailable.\nWe evaluate EL PASSO in a distributed environment and prove its low\ncomputational cost, yielding faster sign-on operations than OIDC from a regular\nlaptop, one-second user-perceived latency from a low-power device, and scaling\nto more than 50 sign-on operations per second at a relying party using a single\n4-core server in the cloud.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 14:40:48 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 08:49:21 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Zhang", "Zhiyi", ""], ["Kr\u00f3l", "Micha\u0142", ""], ["Sonnino", "Alberto", ""], ["Zhang", "Lixia", ""], ["Rivi\u00e8re", "Etienne", ""]]}, {"id": "2002.10294", "submitter": "Fateh Boucenna", "authors": "Fateh Boucenna", "title": "Semantic, Efficient, and Secure Search over Encrypted Cloud Data", "comments": "180 pages, PhD Thesis, University of Sciences and Technology Houari\n  Boumediene (USTHB) Algiers Algeria, searchable encryption, cloud computing,\n  semantic search, homomorphic encryption, data privacy, weighting formula", "journal-ref": null, "doi": null, "report-no": "01/2020-D/INF", "categories": "cs.CR cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Companies and individuals demand more and more storage space and computing\npower. For this purpose, several new technologies have been designed and\nimplemented, such as the cloud computing. This technology provides its users\nwith storage space and computing power according to their needs in a flexible\nand personalized way. However, the outsourced data such as emails, electronic\nhealth records, and company reports are sensitive and confidential. Therefore,\nIt is primordial to protect the outsourced data against possible external\nattacks and the cloud server itself. That is why it is highly recommended to\nencrypt the sensitive data before being outsourced to a remote server. To\nperform searches over outsourced data, it is no longer possible to exploit\ntraditional search engines given that these data are encrypted. Consequently,\nlots of searchable encryption (SE) schemes have been proposed in the\nliterature. Three major research axes of searchable encryption area have been\nstudied in the literature. The first axis consists in ensuring the security of\nthe search approach. Indeed, the search process should be performed without\ndecryption any data and without causing any sensitive information leakage. The\nsecond axis consists in studying the search performance. In fact, the encrypted\nindexes are less efficient than the plaintext indexes, which makes the\nsearchable encryption schemes very slow in practice. More the approach is\nsecure, less it is efficient, thus, the challenge consists in finding the best\ncompromise between security and performance. Finally, the third research axis\nconsists in the quality of the returned results in terms of relevance and\nrecall. The problem is that the encryption of the index causes the degradation\nof the recall and the precision. Therefore, the goal is to propose a technique\nthat is able to obtain almost the same result obtained in the traditional\nsearch.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 14:53:57 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Boucenna", "Fateh", ""]]}, {"id": "2002.10333", "submitter": "Yaser Ebazadeh", "authors": "Reza Fotohi, Yaser Ebazadeh, Mohammad Seyyar Geshlag", "title": "A New Approach for Improvement Security against DoS Attacks in Vehicular\n  Ad-hoc Network", "comments": "7 pages, 12 figures, 2 tables, 4 equation, journal", "journal-ref": "Int J Adv Comput Sci Appl, 7(7), 10-16 (2016)", "doi": "10.14569/IJACSA.2016.070702", "report-no": null, "categories": "cs.CR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicular Ad-Hoc Networks (VANET) are a proper subset of mobile wireless\nnetworks, where nodes are revulsive, the vehicles are armed with special\nelectronic devices on the motherboard OBU (On Board Unit) which enables them to\ntrasmit and receive messages from other vehicles in the VANET. Furthermore the\ncommunication between the vehicles, the VANET interface is donated by the\ncontact points with road infrastructure. VANET is a subgroup of MANETs. Unlike\nthe MANETs nodes, VANET nodes are moving very fast. Impound a permanent route\nfor the dissemination of emergency messages and alerts from a danger zone is a\nvery challenging task. Therefore, routing plays a significant duty in VANETs.\ndecreasing network overhead, avoiding network congestion, increasing traffic\ncongestion and packet delivery ratio are the most important issues associated\nwith routing in VANETs. In addition, VANET network is subject to various\nsecurity attacks. In base VANET systems, an algorithm is used to dicover\nattacks at the time of confirmation in which overhead delay occurs. This paper\nproposes (P-Secure) approach which is used for the detection of DoS attacks\nbefore the confirmation time. This reduces the overhead delays for processing\nand increasing the security in VANETs. Simulation results show that the\nP-Secure approach, is more efficient than OBUmodelVaNET approach in terms of\nPDR, e2e_delay, throughput and drop packet rate.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 16:01:36 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Fotohi", "Reza", ""], ["Ebazadeh", "Yaser", ""], ["Geshlag", "Mohammad Seyyar", ""]]}, {"id": "2002.10362", "submitter": "Marzieh Gheisari", "authors": "Marzieh Gheisari, Teddy Furon, Laurent Amsaleg", "title": "Group Membership Verification with Privacy: Sparse or Dense?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Group membership verification checks if a biometric trait corresponds to one\nmember of a group without revealing the identity of that member. Recent\ncontributions provide privacy for group membership protocols through the joint\nuse of two mechanisms: quantizing templates into discrete embeddings and\naggregating several templates into one group representation. However, this\nscheme has one drawback: the data structure representing the group has a\nlimited size and cannot recognize noisy queries when many templates are\naggregated. Moreover, the sparsity of the embeddings seemingly plays a crucial\nrole on the performance verification. This paper proposes a mathematical model\nfor group membership verification allowing to reveal the impact of sparsity on\nboth security, compactness, and verification performances. This model bridges\nthe gap towards a Bloom filter robust to noisy queries. It shows that a dense\nsolution is more competitive unless the queries are almost noiseless.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 16:47:19 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Gheisari", "Marzieh", ""], ["Furon", "Teddy", ""], ["Amsaleg", "Laurent", ""]]}, {"id": "2002.10363", "submitter": "Marzieh Gheisari", "authors": "Marzieh Gheisari, Teddy Furon, Laurent Amsaleg", "title": "Joint Learning of Assignment and Representation for Biometric Group\n  Membership", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a framework for group membership protocols preventing the\ncurious but honest server from reconstructing the enrolled biometric signatures\nand inferring the identity of querying clients. This framework learns the\nembedding parameters, group representations and assignments simultaneously.\nExperiments show the trade-off between security/privacy and\nverification/identification performances.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 16:48:30 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Gheisari", "Marzieh", ""], ["Furon", "Teddy", ""], ["Amsaleg", "Laurent", ""]]}, {"id": "2002.10390", "submitter": "Henger Li", "authors": "Henger Li, Wen Shen, Zizhan Zheng", "title": "Spatial-Temporal Moving Target Defense: A Markov Stackelberg Game Model", "comments": "accepted by AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Moving target defense has emerged as a critical paradigm of protecting a\nvulnerable system against persistent and stealthy attacks. To protect a system,\na defender proactively changes the system configurations to limit the exposure\nof security vulnerabilities to potential attackers. In doing so, the defender\ncreates asymmetric uncertainty and complexity for the attackers, making it much\nharder for them to compromise the system. In practice, the defender incurs a\nswitching cost for each migration of the system configurations. The switching\ncost usually depends on both the current configuration and the following\nconfiguration. Besides, different system configurations typically require a\ndifferent amount of time for an attacker to exploit and attack. Therefore, a\ndefender must simultaneously decide both the optimal sequences of system\nconfigurations and the optimal timing for switching. In this paper, we propose\na Markov Stackelberg Game framework to precisely characterize the defender's\nspatial and temporal decision-making in the face of advanced attackers. We\nintroduce a relative value iteration algorithm that computes the defender's\noptimal moving target defense strategies. Empirical evaluation on real-world\nproblems demonstrates the advantages of the Markov Stackelberg game model for\nspatial-temporal moving target defense.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 17:23:06 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Li", "Henger", ""], ["Shen", "Wen", ""], ["Zheng", "Zizhan", ""]]}, {"id": "2002.10530", "submitter": "Lucas Layman", "authors": "William Roden, Lucas Layman", "title": "Cry Wolf: Toward an Experimentation Platform and Dataset for Human\n  Factors in Cyber Security Analysis", "comments": "The definitive Version of Record was published in the 2020 ACM\n  Southeast Conference (ACMSE 2020), April 2--4, 2020, Tampa, FL, USA", "journal-ref": null, "doi": "10.1145/3374135.3385301", "report-no": null, "categories": "cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer network defense is a partnership between automated systems and human\ncyber security analysts. The system behaviors, for example raising a high\nproportion of false alarms, likely impact cyber analyst performance.\nExperimentation in the analyst-system domain is challenging due to lack of\naccess to security experts, the usability of attack datasets, and the training\nrequired to use security analysis tools. This paper describes Cry Wolf, an open\nsource web application for user studies of cyber security analysis tasks. This\npaper also provides an open-access dataset of 73 true and false Intrusion\nDetection System (IDS) alarms derived from real-world examples of \"impossible\ntravel\" scenarios. Cry Wolf and the impossible travel dataset were used in an\nexperiment on the impact of IDS false alarm rate on analysts' abilities to\ncorrectly classify IDS alerts as true or false alarms. Results from that\nexperiment are used to evaluate the quality of the dataset using difficulty and\ndiscrimination index measures drawn from classical test theory. Many alerts in\nthe dataset provide good discrimination for participants' overall task\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 20:38:23 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Roden", "William", ""], ["Layman", "Lucas", ""]]}, {"id": "2002.10635", "submitter": "Prashant Vasudevan", "authors": "Sanjam Garg and Shafi Goldwasser and Prashant Nalini Vasudevan", "title": "Formalizing Data Deletion in the Context of the Right to be Forgotten", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The right of an individual to request the deletion of their personal data by\nan entity that might be storing it -- referred to as the right to be forgotten\n-- has been explicitly recognized, legislated, and exercised in several\njurisdictions across the world, including the European Union, Argentina, and\nCalifornia. However, much of the discussion surrounding this right offers only\nan intuitive notion of what it means for it to be fulfilled -- of what it means\nfor such personal data to be deleted.\n  In this work, we provide a formal definitional framework for the right to be\nforgotten using tools and paradigms from cryptography. In particular, we\nprovide a precise definition of what could be (or should be) expected from an\nentity that collects individuals' data when a request is made of it to delete\nsome of this data. Our framework captures several, though not all, relevant\naspects of typical systems involved in data processing. While it cannot be\nviewed as expressing the statements of current laws (especially since these are\nrather vague in this respect), our work offers technically precise definitions\nthat represent possibilities for what the law could reasonably expect, and\nalternatives for what future versions of the law could explicitly require.\n  Finally, with the goal of demonstrating the applicability of our framework\nand definitions, we consider various natural and simple scenarios where the\nright to be forgotten comes up. For each of these scenarios, we highlight the\npitfalls that arise even in genuine attempts at implementing systems offering\ndeletion guarantees, and also describe technological solutions that provably\nsatisfy our definitions. These solutions bring together techniques built by\nvarious communities.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 02:48:14 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Garg", "Sanjam", ""], ["Goldwasser", "Shafi", ""], ["Vasudevan", "Prashant Nalini", ""]]}, {"id": "2002.10667", "submitter": "David Bowman", "authors": "Callum Baillie, Maxwell Standen, Jonathon Schwartz, Michael Docking,\n  David Bowman, and Junae Kim", "title": "CybORG: An Autonomous Cyber Operations Research Gym", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Autonomous Cyber Operations (ACO) involves the consideration of blue team\n(defender) and red team (attacker) decision-making models in adversarial\nscenarios. To support the application of machine learning algorithms to solve\nthis problem, and to encourage such practitioners to attend to problems in the\nACO setting, a suitable gym (toolkit for experiments) is necessary. We\nintroduce CybORG, a work-in-progress gym for ACO research. Driven by the need\nto efficiently support reinforcement learning to train adversarial\ndecision-making models through simulation and emulation, our design differs\nfrom prior related work. Our early evaluation provides some evidence that\nCybORG is appropriate for our purpose and may provide a basis for advancing ACO\nresearch towards practical applications.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 04:59:24 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 02:24:11 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Baillie", "Callum", ""], ["Standen", "Maxwell", ""], ["Schwartz", "Jonathon", ""], ["Docking", "Michael", ""], ["Bowman", "David", ""], ["Kim", "Junae", ""]]}, {"id": "2002.10687", "submitter": "Jonathan Oakley", "authors": "Jonathan Oakley, Lu Yu, Xingsi Zhong, Ganesh Kumar Venayagamoorthy,\n  Richard Brooks", "title": "Protocol Proxy: An FTE-based Covert Channel", "comments": null, "journal-ref": null, "doi": "10.1016/j.cose.2020.101777", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a hostile network environment, users must communicate without being\ndetected. This involves blending in with the existing traffic. In some cases, a\nhigher degree of secrecy is required. We present a proof-of-concept format\ntransforming encryption (FTE)-based covert channel for tunneling TCP traffic\nthrough protected static protocols. Protected static protocols are UDP-based\nprotocols with variable fields that cannot be blocked without collateral\ndamage, such as power grid failures. We (1) convert TCP traffic to UDP traffic,\n(2) introduce observation-based FTE, and (3) model interpacket timing with a\ndeterministic Hidden Markov Model (HMM). The resulting Protocol Proxy has a\nvery low probability of detection and is an alternative to current covert\nchannels. We tunnel a TCP session through a UDP protocol and guarantee\ndelivery. Observation-based FTE ensures traffic cannot be detected by\ntraditional rule-based analysis or DPI. A deterministic HMM ensures the\nProtocol Proxy accurately models interpacket timing to avoid detection by\nside-channel analysis. Finally, the choice of a protected static protocol foils\nstateful protocol analysis and causes collateral damage with false positives.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 05:54:39 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 03:42:53 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Oakley", "Jonathan", ""], ["Yu", "Lu", ""], ["Zhong", "Xingsi", ""], ["Venayagamoorthy", "Ganesh Kumar", ""], ["Brooks", "Richard", ""]]}, {"id": "2002.10722", "submitter": "Peter Hillmann", "authors": "Peter Hillmann, Marcus Kn\\\"upfer, Tobias Guggemos, Klement Streit", "title": "CAKE: An Efficient Group Key Management for Dynamic Groups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With rapid increase of mobile computing and wireless network linkage, the\ninformation exchange between connected systems and within groups increases\nheavily. Exchanging confidential information within groups via unsecured\ncommunication channels is a high security threat. In order to prevent third\nparties from accessing this data, it is essential to encrypt it. For this\npurpose, the group participants need a common group key to enable encrypted\nbroadcast messages. But efficient key management of secured group communication\nis a challenging task, if participants rely on low performance hardware and\nsmall bandwidth. For coordination and distribution, we present the modular\ngroup key management procedure CAKE that is centrally organized and meets\nstrict security requirements. The lightweight G-IKEv2 protocol in combination\nwith the key exchange concept of CAKE leads to an efficiently integrated\nsolution. The hybrid approach combines the advantages of the existing protocols\nwith the objective to reduce the computation and communication effort. It is\nshown that the procedure is more suitable for changing MANET groups than the\nexisting ones. Moreover, the exchanged group key can be used for any services\nwhich provides a wide range of applications.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 08:09:08 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Hillmann", "Peter", ""], ["Kn\u00fcpfer", "Marcus", ""], ["Guggemos", "Tobias", ""], ["Streit", "Klement", ""]]}, {"id": "2002.10736", "submitter": "Daniel Moroz", "authors": "Daniel J. Moroz, Daniel J. Aronoff, Neha Narula, David C. Parkes", "title": "Double-Spend Counterattacks: Threat of Retaliation in Proof-of-Work\n  Systems", "comments": "Appearing in Cryptoeconomic Systems 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proof-of-Work mining is intended to provide blockchains with robustness\nagainst double-spend attacks. However, an economic analysis that follows from\nBudish (2018), which considers free entry conditions together with the ability\nto rent sufficient hashrate to conduct an attack, suggests that the resulting\nblock rewards can make an attack cheap. We formalize a defense to double-spend\nattacks. We show that when the victim can counterattack in the same way as the\nattacker, this leads to a variation on the classic game-theoretic War of\nAttrition model. The threat of this kind of counterattack induces a subgame\nperfect equilibrium in which no attack occurs in the first place.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 08:44:52 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Moroz", "Daniel J.", ""], ["Aronoff", "Daniel J.", ""], ["Narula", "Neha", ""], ["Parkes", "David C.", ""]]}, {"id": "2002.10751", "submitter": "Manh-Dung Nguyen", "authors": "Manh-Dung Nguyen, S\\'ebastien Bardin, Richard Bonichon, Roland Groz,\n  Matthieu Lemerre", "title": "Binary-level Directed Fuzzing for Use-After-Free Vulnerabilities", "comments": "The long version of paper appeared in the 23rd International\n  Symposium on Research in Attacks, Intrusions and Defenses (RAID 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Directed fuzzing focuses on automatically testing specific parts of the code\nby taking advantage of additional information such as (partial) bug stack\ntrace, patches or risky operations. Key applications include bug reproduction,\npatch testing and static analysis report verification. Although directed\nfuzzing has received a lot of attention recently, hard-to-detect\nvulnerabilities such as Use-After-Free (UAF) are still not well addressed,\nespecially at the binary level. We propose UAFuzz, the first (binary-level)\ndirected greybox fuzzer dedicated to UAF bugs. The technique features a fuzzing\nengine tailored to UAF specifics, a lightweight code instrumentation and an\nefficient bug triage step. Experimental evaluation for bug reproduction on real\ncases demonstrates that UAFuzz significantly outperforms state-of-the-art\ndirected fuzzers in terms of fault detection rate, time to exposure and bug\ntriaging. UAFuzz has also been proven effective in patch testing, leading to\nthe discovery of 30 new bugs (7 CVEs) in programs such as Perl, GPAC and GNU\nPatch. Finally, we provide to the community a large fuzzing benchmark dedicated\nto UAF, built on both real codes and real bugs.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 09:09:54 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 08:33:50 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Nguyen", "Manh-Dung", ""], ["Bardin", "S\u00e9bastien", ""], ["Bonichon", "Richard", ""], ["Groz", "Roland", ""], ["Lemerre", "Matthieu", ""]]}, {"id": "2002.10944", "submitter": "Minghui Li", "authors": "Minghui Li, Sherman S. M. Chow, Shengshan Hu, Yuejing Yan, Chao Shen,\n  Qian Wang", "title": "Optimizing Privacy-Preserving Outsourced Convolutional Neural Network\n  Predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural network is a machine-learning model widely applied in\nvarious prediction tasks, such as computer vision and medical image analysis.\nTheir great predictive power requires extensive computation, which encourages\nmodel owners to host the prediction service in a cloud platform. Recent\nresearches focus on the privacy of the query and results, but they do not\nprovide model privacy against the model-hosting server and may leak partial\ninformation about the results. Some of them further require frequent\ninteractions with the querier or heavy computation overheads, which discourages\nquerier from using the prediction service. This paper proposes a new scheme for\nprivacy-preserving neural network prediction in the outsourced setting, i.e.,\nthe server cannot learn the query, (intermediate) results, and the model.\nSimilar to SecureML (S&P'17), a representative work that provides model\nprivacy, we leverage two non-colluding servers with secret sharing and triplet\ngeneration to minimize the usage of heavyweight cryptography. Further, we adopt\nasynchronous computation to improve the throughput, and design garbled circuits\nfor the non-polynomial activation function to keep the same accuracy as the\nunderlying network (instead of approximating it). Our experiments on MNIST\ndataset show that our scheme achieves an average of 122x, 14.63x, and 36.69x\nreduction in latency compared to SecureML, MiniONN (CCS'17), and EzPC\n(EuroS&P'19), respectively. For the communication costs, our scheme outperforms\nSecureML by 1.09x, MiniONN by 36.69x, and EzPC by 31.32x on average. On the\nCIFAR dataset, our scheme achieves a lower latency by a factor of 7.14x and\n3.48x compared to MiniONN and EzPC, respectively. Our scheme also provides\n13.88x and 77.46x lower communication costs than MiniONN and EzPC on the CIFAR\ndataset.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 08:47:22 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 11:29:51 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 16:52:16 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Li", "Minghui", ""], ["Chow", "Sherman S. M.", ""], ["Hu", "Shengshan", ""], ["Yan", "Yuejing", ""], ["Shen", "Chao", ""], ["Wang", "Qian", ""]]}, {"id": "2002.11000", "submitter": "Marcel Gygli", "authors": "Philipp L\\\"uthi, Thibault Gagnaux, Marcel Gygli", "title": "Distributed Ledger for Provenance Tracking of Artificial Intelligence\n  Assets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High availability of data is responsible for the current trends in Artificial\nIntelligence (AI) and Machine Learning (ML). However, high-grade datasets are\nreluctantly shared between actors because of lacking trust and fear of losing\ncontrol. Provenance tracing systems are a possible measure to build trust by\nimproving transparency. Especially the tracing of AI assets along complete AI\nvalue chains bears various challenges such as trust, privacy, confidentiality,\ntraceability, and fair remuneration. In this paper we design a graph-based\nprovenance model for AI assets and their relations within an AI value chain.\nMoreover, we propose a protocol to exchange AI assets securely to selected\nparties. The provenance model and exchange protocol are then combined and\nimplemented as a smart contract on a permission-less blockchain. We show how\nthe smart contract enables the tracing of AI assets in an existing industry use\ncase while solving all challenges. Consequently, our smart contract helps to\nincrease traceability and transparency, encourages trust between actors and\nthus fosters collaboration between them.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 16:16:31 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["L\u00fcthi", "Philipp", ""], ["Gagnaux", "Thibault", ""], ["Gygli", "Marcel", ""]]}, {"id": "2002.11021", "submitter": "Jakub Breier", "authors": "Jakub Breier, Dirmanto Jap, Xiaolu Hou, Shivam Bhasin, Yang Liu", "title": "SNIFF: Reverse Engineering of Neural Networks with Fault Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have been shown to be vulnerable against fault injection\nattacks. These attacks change the physical behavior of the device during the\ncomputation, resulting in a change of value that is currently being computed.\nThey can be realized by various fault injection techniques, ranging from\nclock/voltage glitching to application of lasers to rowhammer. In this paper we\nexplore the possibility to reverse engineer neural networks with the usage of\nfault attacks. SNIFF stands for sign bit flip fault, which enables the reverse\nengineering by changing the sign of intermediate values. We develop the first\nexact extraction method on deep-layer feature extractor networks that provably\nallows the recovery of the model parameters. Our experiments with Keras library\nshow that the precision error for the parameter recovery for the tested\nnetworks is less than $10^{-13}$ with the usage of 64-bit floats, which\nimproves the current state of the art by 6 orders of magnitude. Additionally,\nwe discuss the protection techniques against fault injection attacks that can\nbe applied to enhance the fault resistance.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 05:39:54 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Breier", "Jakub", ""], ["Jap", "Dirmanto", ""], ["Hou", "Xiaolu", ""], ["Bhasin", "Shivam", ""], ["Liu", "Yang", ""]]}, {"id": "2002.11064", "submitter": "Aviv Yaish", "authors": "Aviv Yaish, Aviv Zohar", "title": "Pricing ASICs for Cryptocurrency Mining", "comments": "13 pages, 10 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cryptocurrencies that are based on Proof-of-Work often rely on special\npurpose hardware (ASICs) to perform mining operations that secure the system.\n  We argue that ASICs have been mispriced by miners and sellers that only\nconsider their expected returns, and that in fact mining hardware should be\ntreated as a bundle of \\emph{financial options}, that when exercised, convert\nelectricity to virtual coins.\n  We provide a method of pricing ASICs based on this insight, and compare the\nprices we derive to actual market prices. Contrary to the widespread belief\nthat ASICs are worth less if the cryptocurrency is highly volatile, we show the\nopposite effect: volatility significantly increases value. Thus, if a coin's\nvolatility decreases, some miners may leave, affecting security. To prevent\nthis, we suggest a new reward mechanism.\n  Finally we construct a portfolio of coins and bonds that provides returns\nimitating an ASIC, and evaluate its behavior: historically, realized revenues\nof such portfolios have significantly outperformed ASICs, showing that indeed\nthere is a mispricing of hardware, and offering an alternative investment route\nfor would-be miners.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 12:32:56 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 17:02:23 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 18:34:15 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Yaish", "Aviv", ""], ["Zohar", "Aviv", ""]]}, {"id": "2002.11078", "submitter": "Hao Guo", "authors": "Hao Guo, Wanxin Li, Ehsan Meamari, Chien-Chung Shen, Mark Nejad", "title": "Attribute-based Multi-Signature and Encryption for EHR Management: A\n  Blockchain-based Solution", "comments": "This paper is accepted to the Short Paper track by 2020 IEEE\n  International Conference on Blockchain and Cryptocurrency (ICBC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The global Electronic Health Record (EHR) market is growing dramatically and\nhas already hit $31.5 billion in 2018. To safeguard the security of EHR data\nand privacy of patients, fine-grained information access and sharing mechanisms\nare essential for EHR management. This paper proposes a hybrid architecture of\nblockchain and edge nodes to facilitate EHR management. In this architecture,\nwe utilize attribute-based multi-signature (ABMS) scheme to authenticate user's\nsignatures without revealing the sensitive information and multi-authority\nattribute-based encryption (ABE) scheme to encrypt EHR data which is stored on\nthe edge node. We develop the blockchain module on Hyperledger Fabric platform\nand the ABMS module on Hyperledger Ursa library. We measure the signing and\nverifying time of the ABMS scheme under different settings, and experiment with\nthe authentication events and access activities which are logged as\ntransactions in blockchain.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 18:24:16 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Guo", "Hao", ""], ["Li", "Wanxin", ""], ["Meamari", "Ehsan", ""], ["Shen", "Chien-Chung", ""], ["Nejad", "Mark", ""]]}, {"id": "2002.11108", "submitter": "Xinhui Lai", "authors": "Xinhui Lai, Maksim Jenihhin, Jaan Raik, Kolin Paul", "title": "PASCAL: Timing SCA Resistant Design and Verification Flow", "comments": "Total page number: 4 pages; Figures: 5 figures; conference: 25th IEEE\n  International Symposium on On-Line Testing and Robust System Design 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large number of crypto accelerators are being deployed with the widespread\nadoption of IoT. It is vitally important that these accelerators and other\nsecurity hardware IPs are provably secure. Security is an extra functional\nrequirement and hence many security verification tools are not mature. We\npropose an approach/flow-PASCAL-that works on RTL designs and discovers\npotential Timing Side-Channel Attack(SCA) vulnerabilities in them. Based on\ninformation flow analysis, this is able to identify Timing Disparate Security\nPaths that could lead to information leakage. This flow also (automatically)\neliminates the information leakage caused by the timing channel. The insertion\nof a lightweight Compensator Block as balancing or compliance FSM removes the\ntiming channel with minimum modifications to the design with no impact on the\nclock cycle time or combinational delay of the critical path in the circuit.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 14:08:25 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 11:42:56 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Lai", "Xinhui", ""], ["Jenihhin", "Maksim", ""], ["Raik", "Jaan", ""], ["Paul", "Kolin", ""]]}, {"id": "2002.11269", "submitter": "Parth Sane", "authors": "Parth Sane", "title": "Is the OWASP Top 10 list comprehensive enough for writing secure code?", "comments": "5 pages, Pre-print 2020 ICISE-IEEE Conference at University of\n  Manchester, Manchester UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The OWASP Top 10 is a list that is published by the Open Web Application\nSecurity Project (OWASP). The general purpose is to serve as a watchlist for\nbugs to avoid while writing code. This paper compares how many of those\nweakness as described in the top ten list are actually reported in\nvulnerabilities listed in the National Vulnerability Database (NVD). That way\nit makes it possible to empirically show whether the OWASP Top 10 list is\ncomprehensive enough or not, for code weaknesses that have been found in the\npast decade.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 02:53:52 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Sane", "Parth", ""]]}, {"id": "2002.11288", "submitter": "Yue Zhang", "authors": "Zhijian Shao, Jian Weng, Yue Zhang, Yongdong Wu, Ming Li, Jiasi Weng,\n  Weiqi Luo, Shui Yu", "title": "Peripheral-free Device Pairing by Randomly Switching Power", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The popularity of Internet-of-Things (IoT) comes with security concerns.\nAttacks against wireless communication venues of IoT (e.g., Man-in-the-Middle\nattacks) have grown at an alarming rate over the past decade. Pairing, which\nallows the establishment of the secure communicating channels for IoT devices\nwithout a prior relationship, is thus a paramount capability. Existing secure\npairing protocols require auxiliary equipment/peripheral (e.g., displays,\nspeakers and sensors) to achieve authentication, which is unacceptable for\nlow-priced devices such as smart lamps. This paper studies how to design a\nperipheral-free secure pairing protocol. Concretely, we design the protocol,\ntermed SwitchPairing, via out-of-box power supplying chargers and on-board\nclocks, achieving security and economics at the same time. When a user wants to\npair two or more devices, he/she connects the pairing devices to the same power\nsource, and presses/releases the switch on/off button several times. Then, the\npress and release timing can be used to derive symmetric keys. We implement a\nprototype via two CC2640R2F development boards from Texas Instruments (TI) due\nto its prevalence. Extensive experiments and user studies are also conducted to\nbenchmark our protocol in terms of efficiency and security.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 03:52:14 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Shao", "Zhijian", ""], ["Weng", "Jian", ""], ["Zhang", "Yue", ""], ["Wu", "Yongdong", ""], ["Li", "Ming", ""], ["Weng", "Jiasi", ""], ["Luo", "Weiqi", ""], ["Yu", "Shui", ""]]}, {"id": "2002.11321", "submitter": "Zhuolun Xiang", "authors": "Kartik Nayak, Ling Ren, Elaine Shi, Nitin H. Vaidya, Zhuolun Xiang", "title": "Improved Extension Protocols for Byzantine Broadcast and Agreement", "comments": "Will appear in DISC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Byzantine broadcast (BB) and Byzantine agreement (BA) are two most\nfundamental problems and essential building blocks in distributed computing,\nand improving their efficiency is of interest to both theoreticians and\npractitioners. In this paper, we study extension protocols of BB and BA, i.e.,\nprotocols that solve BB/BA with long inputs of $l$ bits using lower costs than\n$l$ single-bit instances. We present new protocols with improved communication\ncomplexity in almost all settings: authenticated BA/BB with $t<n/2$,\nauthenticated BB with $t<(1-\\epsilon)n$, unauthenticated BA/BB with $t<n/3$,\nand asynchronous reliable broadcast and BA with $t<n/3$. The new protocols are\nadvantageous and significant in several aspects. First, they achieve the\nbest-possible communication complexity of $\\Theta(nl)$ for wider ranges of\ninput sizes compared to prior results. Second, the authenticated extension\nprotocols achieve optimal communication complexity given the current best\navailable BB/BA protocols for short messages. Third, to the best of our\nknowledge, our asynchronous and authenticated protocols in the setting are the\nfirst extension protocols in that setting.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 06:31:32 GMT"}, {"version": "v2", "created": "Sat, 8 Aug 2020 22:57:06 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 22:47:52 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Nayak", "Kartik", ""], ["Ren", "Ling", ""], ["Shi", "Elaine", ""], ["Vaidya", "Nitin H.", ""], ["Xiang", "Zhuolun", ""]]}, {"id": "2002.11331", "submitter": "Mark Overton", "authors": "Mark A. Overton", "title": "Romu: Fast Nonlinear Pseudo-Random Number Generators Providing High\n  Quality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Romu family of pseudo-random number generators (PRNGs) which\ncombines the nonlinear operation of rotation with the linear operations of\nmultiplication and (optionally) addition. Compared to conventional linear-only\nPRNGs, this mixture of linear and nonlinear operations achieves a greater\ndegree of randomness using the same number of arithmetic operations. Or\nequivalently, it achieves the same randomness with fewer operations, resulting\nin higher speed. The statistical properties of these generators are strong, as\nthey pass BigCrush and PractRand -- the most stringent test suites available.\nIn addition, Romu generators take maximum advantage of instruction-level\nparallelism in modern superscalar processors, giving them an output latency of\nzero clock-cycles when inlined, thus adding no delay to an application.\nScaled-down versions of these generators can be created and tested, enabling\none to estimate the maximum number of values the full-size generators can\nsupply before their randomness declines, ensuring the success of large jobs.\nSuch capacity-estimates are rare for conventional PRNGs. A linear PRNG has a\nsingle cycle of states of known length comprising almost all possible states.\nHowever, a Romu generator computes pseudo-random permutations of those states,\ncreating multiple cycles with pseudo-random lengths which cannot be determined\nby theory. But the ease of creating state-sizes of 128 or more bits allows (1)\nshort cycles to be constrained to vanishingly low probabilities, and (2)\nthousands of parallel streams to be created having infinitesimal probabilities\nof overlap.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 07:27:05 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Overton", "Mark A.", ""]]}, {"id": "2002.11497", "submitter": "Sanghyun Hong", "authors": "Sanghyun Hong, Varun Chandrasekaran, Yi\\u{g}itcan Kaya, Tudor\n  Dumitra\\c{s}, Nicolas Papernot", "title": "On the Effectiveness of Mitigating Data Poisoning Attacks with Gradient\n  Shaping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms are vulnerable to data poisoning attacks. Prior\ntaxonomies that focus on specific scenarios, e.g., indiscriminate or targeted,\nhave enabled defenses for the corresponding subset of known attacks. Yet, this\nintroduces an inevitable arms race between adversaries and defenders. In this\nwork, we study the feasibility of an attack-agnostic defense relying on\nartifacts that are common to all poisoning attacks. Specifically, we focus on a\ncommon element between all attacks: they modify gradients computed to train the\nmodel. We identify two main artifacts of gradients computed in the presence of\npoison: (1) their $\\ell_2$ norms have significantly higher magnitudes than\nthose of clean gradients, and (2) their orientation differs from clean\ngradients. Based on these observations, we propose the prerequisite for a\ngeneric poisoning defense: it must bound gradient magnitudes and minimize\ndifferences in orientation. We call this gradient shaping. As an exemplar tool\nto evaluate the feasibility of gradient shaping, we use differentially private\nstochastic gradient descent (DP-SGD), which clips and perturbs individual\ngradients during training to obtain privacy guarantees. We find that DP-SGD,\neven in configurations that do not result in meaningful privacy guarantees,\nincreases the model's robustness to indiscriminate attacks. It also mitigates\nworst-case targeted attacks and increases the adversary's cost in multi-poison\nscenarios. The only attack we find DP-SGD to be ineffective against is a\nstrong, yet unrealistic, indiscriminate attack. Our results suggest that, while\nwe currently lack a generic poisoning defense, gradient shaping is a promising\ndirection for future research.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 14:04:16 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 19:00:01 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Hong", "Sanghyun", ""], ["Chandrasekaran", "Varun", ""], ["Kaya", "Yi\u011fitcan", ""], ["Dumitra\u015f", "Tudor", ""], ["Papernot", "Nicolas", ""]]}, {"id": "2002.11565", "submitter": "Raphael Ettedgui", "authors": "Rafael Pinot, Raphael Ettedgui, Geovani Rizk, Yann Chevaleyre, Jamal\n  Atif", "title": "Randomization matters. How to defend against strong adversarial attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Is there a classifier that ensures optimal robustness against all adversarial\nattacks? This paper answers this question by adopting a game-theoretic point of\nview. We show that adversarial attacks and defenses form an infinite zero-sum\ngame where classical results (e.g. Sion theorem) do not apply. We demonstrate\nthe non-existence of a Nash equilibrium in our game when the classifier and the\nAdversary are both deterministic, hence giving a negative answer to the above\nquestion in the deterministic regime. Nonetheless, the question remains open in\nthe randomized regime. We tackle this problem by showing that, undermild\nconditions on the dataset distribution, any deterministic classifier can be\noutperformed by a randomized one. This gives arguments for using randomization,\nand leads us to a new algorithm for building randomized classifiers that are\nrobust to strong adversarial attacks. Empirical results validate our\ntheoretical analysis, and show that our defense method considerably outperforms\nAdversarial Training against state-of-the-art attacks.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 15:31:31 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 11:27:26 GMT"}, {"version": "v3", "created": "Thu, 10 Dec 2020 10:11:46 GMT"}, {"version": "v4", "created": "Tue, 5 Jan 2021 12:52:40 GMT"}, {"version": "v5", "created": "Wed, 6 Jan 2021 12:53:03 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Pinot", "Rafael", ""], ["Ettedgui", "Raphael", ""], ["Rizk", "Geovani", ""], ["Chevaleyre", "Yann", ""], ["Atif", "Jamal", ""]]}, {"id": "2002.11572", "submitter": "Aditya Saligrama", "authors": "Aditya Saligrama and Guillaume Leclerc", "title": "Revisiting Ensembles in an Adversarial Context: Improving Natural\n  Accuracy", "comments": "5 pages, accepted to ICLR 2020 Workshop on Towards Trustworthy ML:\n  Rethinking Security and Privacy for ML", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A necessary characteristic for the deployment of deep learning models in real\nworld applications is resistance to small adversarial perturbations while\nmaintaining accuracy on non-malicious inputs. While robust training provides\nmodels that exhibit better adversarial accuracy than standard models, there is\nstill a significant gap in natural accuracy between robust and non-robust\nmodels which we aim to bridge. We consider a number of ensemble methods\ndesigned to mitigate this performance difference. Our key insight is that model\ntrained to withstand small attacks, when ensembled, can often withstand\nsignificantly larger attacks, and this concept can in turn be leveraged to\noptimize natural accuracy. We consider two schemes, one that combines\npredictions from several randomly initialized robust models, and the other that\nfuses features from robust and standard models.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 15:45:58 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Saligrama", "Aditya", ""], ["Leclerc", "Guillaume", ""]]}, {"id": "2002.11625", "submitter": "Gregory Falco", "authors": "Gregory Falco", "title": "Death by AI: Where Assured Autonomy in Smart Cities Meets the End-to-End\n  Argument", "comments": "PREPRINT, 6 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A smart city involves critical infrastructure systems that have been\ndigitally enabled. Increasingly, many smart city cyber-physical systems are\nbecoming automated. The extent of automation ranges from basic logic gates to\nsophisticated, artificial intelligence (AI) that enables fully autonomous\nsystems. Because of modern society's reliance on autonomous systems in smart\ncities, it is crucial for them to operate in a safe manner; otherwise, it is\nfeasible for these systems to cause considerable physical harm or even death.\nBecause smart cities could involve thousands of autonomous systems operating in\nconcert in densely populated areas, safety assurances are required. Challenges\nabound to consistently manage the safety of such autonomous systems due to\ntheir disparate developers, manufacturers, operators and users. A novel network\nand a sample of associated network functions for autonomous systems is proposed\nthat aims to provide a baseline of safety for autonomous systems. This is\naccomplished by establishing a custom-designed network for autonomous systems\nthat is separate from the Internet, and can handle certain functions that\nenable safety through active networking. Such a network design sits at the\nmargins of the end-to-end principle, which is warranted considering the safety\nof autonomous systems is at stake as is argued in this paper. Without a\nscalable safety strategy for autonomous systems as proposed, assured autonomy\nin smart cities will remain elusive.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 20:14:25 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Falco", "Gregory", ""]]}, {"id": "2002.11686", "submitter": "Jaidip Kotak", "authors": "Jaidip Kotak and Yuval Elovici", "title": "IoT Device Identification Using Deep Learning", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-57805-3_8", "report-no": null, "categories": "cs.CR cs.LG cs.NI eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing use of IoT devices in organizations has increased the number of\nattack vectors available to attackers due to the less secure nature of the\ndevices. The widely adopted bring your own device (BYOD) policy which allows an\nemployee to bring any IoT device into the workplace and attach it to an\norganization's network also increases the risk of attacks. In order to address\nthis threat, organizations often implement security policies in which only the\nconnection of white-listed IoT devices is permitted. To monitor adherence to\nsuch policies and protect their networks, organizations must be able to\nidentify the IoT devices connected to their networks and, more specifically, to\nidentify connected IoT devices that are not on the white-list (unknown\ndevices). In this study, we applied deep learning on network traffic to\nautomatically identify IoT devices connected to the network. In contrast to\nprevious work, our approach does not require that complex feature engineering\nbe applied on the network traffic, since we represent the communication\nbehavior of IoT devices using small images built from the IoT devices network\ntraffic payloads. In our experiments, we trained a multiclass classifier on a\npublicly available dataset, successfully identifying 10 different IoT devices\nand the traffic of smartphones and computers, with over 99% accuracy. We also\ntrained multiclass classifiers to detect unauthorized IoT devices connected to\nthe network, achieving over 99% overall average detection accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 12:24:49 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Kotak", "Jaidip", ""], ["Elovici", "Yuval", ""]]}, {"id": "2002.11687", "submitter": "Onur G\\\"unl\\\"u Dr.-Ing.", "authors": "Onur G\\\"unl\\\"u, Tasnad Kernetzky, Onurcan \\.I\\c{s}can, Vladimir\n  Sidorenko, Gerhard Kramer, and Rafael F. Schaefer", "title": "Secure and Reliable Key Agreement with Physical Unclonable Functions", "comments": "An extra term in the last page due to the mismatch between the Arxiv\n  compiler and MDPI template is eliminated. No other changes", "journal-ref": "MDPI Entropy Journal 20 (2018) 340:1-340:19", "doi": "10.3390/e20050340", "report-no": null, "categories": "cs.CR cs.IT eess.IV eess.SP math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different transforms used in binding a secret key to correlated\nphysical-identifier outputs are compared. Decorrelation efficiency is the\nmetric used to determine transforms that give highly-uncorrelated outputs.\nScalar quantizers are applied to transform outputs to extract uniformly\ndistributed bit sequences to which secret keys are bound. A set of transforms\nthat perform well in terms of the decorrelation efficiency is applied to ring\noscillator (RO) outputs to improve the uniqueness and reliability of extracted\nbit sequences, to reduce the hardware area and information leakage about the\nkey and RO outputs, and to maximize the secret-key length. Low-complexity\nerror-correction codes are proposed to illustrate two complete key-binding\nsystems with perfect secrecy, and better secret-key and privacy-leakage rates\nthan existing methods. A reference hardware implementation is also provided to\ndemonstrate that the transform-coding approach occupies a small hardware area.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 18:26:38 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 10:52:02 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["G\u00fcnl\u00fc", "Onur", ""], ["Kernetzky", "Tasnad", ""], ["\u0130\u015fcan", "Onurcan", ""], ["Sidorenko", "Vladimir", ""], ["Kramer", "Gerhard", ""], ["Schaefer", "Rafael F.", ""]]}, {"id": "2002.11711", "submitter": "Yuan Liu Prof.", "authors": "Yuan Liu, Shuai Sun, Zhengpeng Ai, Shuangfeng Zhang, Zelei Liu, Han Yu", "title": "FedCoin: A Peer-to-Peer Payment System for Federated Learning", "comments": "7 pages, 6 figures,21 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Federated learning (FL) is an emerging collaborative machine learning method\nto train models on distributed datasets with privacy concerns. To properly\nincentivize data owners to contribute their efforts, Shapley Value (SV) is\noften adopted to fairly assess their contribution. However, the calculation of\nSV is time-consuming and computationally costly. In this paper, we propose\nFedCoin, a blockchain-based peer-to-peer payment system for FL to enable a\nfeasible SV based profit distribution. In FedCoin, blockchain consensus\nentities calculate SVs and a new block is created based on the proof of Shapley\n(PoSap) protocol. It is in contrast to the popular BitCoin network where\nconsensus entities \"mine\" new blocks by solving meaningless puzzles. Based on\nthe computed SVs, a scheme for dividing the incentive payoffs among FL clients\nwith nonrepudiation and tamper-resistance properties is proposed. Experimental\nresults based on real-world data show that FedCoin can promote high-quality\ndata from FL clients through accurately computing SVs with an upper bound on\nthe computational resources required for reaching consensus. It opens\nopportunities for non-data owners to play a role in FL.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 03:43:48 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Liu", "Yuan", ""], ["Sun", "Shuai", ""], ["Ai", "Zhengpeng", ""], ["Zhang", "Shuangfeng", ""], ["Liu", "Zelei", ""], ["Yu", "Han", ""]]}, {"id": "2002.11750", "submitter": "Binghui Wang", "authors": "Binghui Wang, Xiaoyu Cao, Jinyuan jia, and Neil Zhenqiang Gong", "title": "On Certifying Robustness against Backdoor Attacks via Randomized\n  Smoothing", "comments": "CVPR 2020 Workshop on Adversarial Machine Learning in Computer\n  Vision, 2020. DeepMind Best Extended Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backdoor attack is a severe security threat to deep neural networks (DNNs).\nWe envision that, like adversarial examples, there will be a cat-and-mouse game\nfor backdoor attacks, i.e., new empirical defenses are developed to defend\nagainst backdoor attacks but they are soon broken by strong adaptive backdoor\nattacks. To prevent such cat-and-mouse game, we take the first step towards\ncertified defenses against backdoor attacks. Specifically, in this work, we\nstudy the feasibility and effectiveness of certifying robustness against\nbackdoor attacks using a recent technique called randomized smoothing.\nRandomized smoothing was originally developed to certify robustness against\nadversarial examples. We generalize randomized smoothing to defend against\nbackdoor attacks. Our results show the theoretical feasibility of using\nrandomized smoothing to certify robustness against backdoor attacks. However,\nwe also find that existing randomized smoothing methods have limited\neffectiveness at defending against backdoor attacks, which highlight the needs\nof new theory and methods to certify robustness against backdoor attacks.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 19:15:46 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2020 18:53:12 GMT"}, {"version": "v3", "created": "Tue, 14 Apr 2020 13:02:37 GMT"}, {"version": "v4", "created": "Mon, 20 Jul 2020 16:15:42 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Wang", "Binghui", ""], ["Cao", "Xiaoyu", ""], ["jia", "Jinyuan", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "2002.11768", "submitter": "Maximilian Wolff", "authors": "Max Wolff, Stuart Wolff", "title": "Attacking Neural Text Detectors", "comments": "Accepted at the ICLR 2020 workshop \"Towards Trustworthy ML:\n  Rethinking Security and Privacy for ML.\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning based language models have recently made significant\nprogress, which introduces a danger to spread misinformation. To combat this\npotential danger, several methods have been proposed for detecting text written\nby these language models. This paper presents two classes of black-box attacks\non these detectors, one which randomly replaces characters with homoglyphs, and\nthe other a simple scheme to purposefully misspell words. The homoglyph and\nmisspelling attacks decrease a popular neural text detector's recall on neural\ntext from 97.44% to 0.26% and 22.68%, respectively. Results also indicate that\nthe attacks are transferable to other neural text detectors.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 04:18:45 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 07:08:21 GMT"}, {"version": "v3", "created": "Sat, 12 Dec 2020 05:15:18 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Wolff", "Max", ""], ["Wolff", "Stuart", ""]]}, {"id": "2002.11798", "submitter": "Sicheng Zhu", "authors": "Sicheng Zhu, Xiao Zhang, David Evans", "title": "Learning Adversarially Robust Representations via Worst-Case Mutual\n  Information Maximization", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training machine learning models that are robust against adversarial inputs\nposes seemingly insurmountable challenges. To better understand adversarial\nrobustness, we consider the underlying problem of learning robust\nrepresentations. We develop a notion of representation vulnerability that\ncaptures the maximum change of mutual information between the input and output\ndistributions, under the worst-case input perturbation. Then, we prove a\ntheorem that establishes a lower bound on the minimum adversarial risk that can\nbe achieved for any downstream classifier based on its representation\nvulnerability. We propose an unsupervised learning method for obtaining\nintrinsically robust representations by maximizing the worst-case mutual\ninformation between the input and output distributions. Experiments on\ndownstream classification tasks support the robustness of the representations\nfound using unsupervised learning with our training principle.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 21:20:40 GMT"}, {"version": "v2", "created": "Sun, 5 Jul 2020 15:18:54 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Zhu", "Sicheng", ""], ["Zhang", "Xiao", ""], ["Evans", "David", ""]]}, {"id": "2002.11805", "submitter": "Sundar Krishnan", "authors": "Sundar Krishnan", "title": "Exploitation of Human Trust, Curiosity and Ignorance by Malware", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite defensive advances in the Internet realm, Malware (malicious\nsoftware) remains a Cybersecurity threat. These days, Malware can be purchased\nand licensed on the Internet to further customize and deploy. With hundreds of\nMalware variants discovered every day, organizations and users experience\nenormous financial losses as cybercriminals steal financial and user data. In\nthis article surveys the human characteristics that are key to the defense\nchain against Malware. The article starts with the attack models/vectors that\nhumans often fall prey to and their fallouts. Next, analysis of their root\ncause and suggest preventive measures that may be employed is detailed. The\narticle concludes that while Internet user education, training, awareness can\nreduce the chances of Malware attacks,it cannot entirely eliminate them.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 21:46:30 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Krishnan", "Sundar", ""]]}, {"id": "2002.11828", "submitter": "Konstantin Berlin", "authors": "Konstantin Berlin and Ajay Lakshminarayanarao", "title": "A Simple and Agile Cloud Infrastructure to Support Cybersecurity\n  Oriented Machine Learning Workflows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating up to date, well labeled datasets for machine learning (ML)\nsecurity models is a unique engineering challenge, as large data volumes,\ncomplexity of labeling, and constant concept drift makes it difficult to\ngenerate effective training datasets. Here we describe a simple, resilient\ncloud infrastructure for generating ML training and testing datasets, that has\nenhanced the speed at which our team is able to research and keep in production\na multitude of security ML models.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 22:38:40 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Berlin", "Konstantin", ""], ["Lakshminarayanarao", "Ajay", ""]]}, {"id": "2002.11998", "submitter": "Andrea Coladangelo", "authors": "Andrea Coladangelo, Or Sattath", "title": "A Quantum Money Solution to the Blockchain Scalability Problem", "comments": "This work supersedes arXiv:1902.05214", "journal-ref": "Quantum 4, 297 (2020)", "doi": "10.22331/q-2020-07-16-297", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We put forward the idea that classical blockchains and smart contracts are\npotentially useful primitives not only for classical cryptography, but for\nquantum cryptography as well. Abstractly, a smart contract is a functionality\nthat allows parties to deposit funds, and release them upon fulfillment of\nalgorithmically checkable conditions, and can thus be employed as a formal tool\nto enforce monetary incentives.\n  In this work, we give the first example of the use of smart contracts in a\nquantum setting. We describe a simple hybrid classical-quantum payment system\nwhose main ingredients are a classical blockchain capable of handling stateful\nsmart contracts, and quantum lightning, a strengthening of public-key quantum\nmoney introduced by Zhandry (Eurocrypt'19). Our hybrid payment system employs\nquantum states as banknotes and a classical blockchain to settle disputes and\nto keep track of the valid serial numbers. It has several desirable properties:\nit is decentralized, requiring no trust in any single entity; payments are as\nquick as quantum communication, regardless of the total number of users; when a\nquantum banknote is damaged or lost, the rightful owner can recover the lost\nvalue.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 09:40:18 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 07:40:04 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Coladangelo", "Andrea", ""], ["Sattath", "Or", ""]]}, {"id": "2002.12062", "submitter": "Jiacheng Li", "authors": "Jiacheng Li, Ninghui Li, Bruno Ribeiro", "title": "Membership Inference Attacks and Defenses in Classification Models", "comments": null, "journal-ref": null, "doi": "10.1145/3422337.3447836", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the membership inference (MI) attack against classifiers, where the\nattacker's goal is to determine whether a data instance was used for training\nthe classifier. Through systematic cataloging of existing MI attacks and\nextensive experimental evaluations of them, we find that a model's\nvulnerability to MI attacks is tightly related to the generalization gap -- the\ndifference between training accuracy and test accuracy. We then propose a\ndefense against MI attacks that aims to close the gap by intentionally reduces\nthe training accuracy. More specifically, the training process attempts to\nmatch the training and validation accuracies, by means of a new {\\em set\nregularizer} using the Maximum Mean Discrepancy between the softmax output\nempirical distributions of the training and validation sets. Our experimental\nresults show that combining this approach with another simple defense (mix-up\ntraining) significantly improves state-of-the-art defense against MI attacks,\nwith minimal impact on testing accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 12:35:36 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 03:53:24 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2021 01:43:20 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Li", "Jiacheng", ""], ["Li", "Ninghui", ""], ["Ribeiro", "Bruno", ""]]}, {"id": "2002.12162", "submitter": "Kaidi Xu", "authors": "Kaidi Xu, Sijia Liu, Pin-Yu Chen, Pu Zhao, Xue Lin", "title": "Defending against Backdoor Attack on Deep Neural Networks", "comments": "This workshop manuscript is not a publication and will not be\n  published anywhere", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep neural networks (DNNs) have achieved a great success in various\ncomputer vision tasks, it is recently found that they are vulnerable to\nadversarial attacks. In this paper, we focus on the so-called \\textit{backdoor\nattack}, which injects a backdoor trigger to a small portion of training data\n(also known as data poisoning) such that the trained DNN induces\nmisclassification while facing examples with this trigger. To be specific, we\ncarefully study the effect of both real and synthetic backdoor attacks on the\ninternal response of vanilla and backdoored DNNs through the lens of Gard-CAM.\nMoreover, we show that the backdoor attack induces a significant bias in neuron\nactivation in terms of the $\\ell_\\infty$ norm of an activation map compared to\nits $\\ell_1$ and $\\ell_2$ norm. Spurred by our results, we propose the\n\\textit{$\\ell_\\infty$-based neuron pruning} to remove the backdoor from the\nbackdoored DNN. Experiments show that our method could effectively decrease the\nattack success rate, and also hold a high classification accuracy for clean\nimages.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 02:03:00 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 16:13:32 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Xu", "Kaidi", ""], ["Liu", "Sijia", ""], ["Chen", "Pin-Yu", ""], ["Zhao", "Pu", ""], ["Lin", "Xue", ""]]}, {"id": "2002.12200", "submitter": "Hengrui Jia", "authors": "Hengrui Jia, Christopher A. Choquette-Choo, Varun Chandrasekaran,\n  Nicolas Papernot", "title": "Entangled Watermarks as a Defense against Model Extraction", "comments": "published in 30th USENIX Security Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning involves expensive data collection and training procedures.\nModel owners may be concerned that valuable intellectual property can be leaked\nif adversaries mount model extraction attacks. As it is difficult to defend\nagainst model extraction without sacrificing significant prediction accuracy,\nwatermarking instead leverages unused model capacity to have the model overfit\nto outlier input-output pairs. Such pairs are watermarks, which are not sampled\nfrom the task distribution and are only known to the defender. The defender\nthen demonstrates knowledge of the input-output pairs to claim ownership of the\nmodel at inference. The effectiveness of watermarks remains limited because\nthey are distinct from the task distribution and can thus be easily removed\nthrough compression or other forms of knowledge transfer.\n  We introduce Entangled Watermarking Embeddings (EWE). Our approach encourages\nthe model to learn features for classifying data that is sampled from the task\ndistribution and data that encodes watermarks. An adversary attempting to\nremove watermarks that are entangled with legitimate data is also forced to\nsacrifice performance on legitimate data. Experiments on MNIST, Fashion-MNIST,\nCIFAR-10, and Speech Commands validate that the defender can claim model\nownership with 95\\% confidence with less than 100 queries to the stolen copy,\nat a modest cost below 0.81 percentage points on average in the defended\nmodel's performance.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 15:47:00 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 15:07:24 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Jia", "Hengrui", ""], ["Choquette-Choo", "Christopher A.", ""], ["Chandrasekaran", "Varun", ""], ["Papernot", "Nicolas", ""]]}, {"id": "2002.12307", "submitter": "Ziqi Liu", "authors": "Ziqi Liu, Chaochao Chen, Xinxing Yang, Jun Zhou, Xiaolong Li, Le Song", "title": "Heterogeneous Graph Neural Networks for Malicious Account Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present, GEM, the first heterogeneous graph neural network approach for\ndetecting malicious accounts at Alipay, one of the world's leading mobile\ncashless payment platform. Our approach, inspired from a connected subgraph\napproach, adaptively learns discriminative embeddings from heterogeneous\naccount-device graphs based on two fundamental weaknesses of attackers, i.e.\ndevice aggregation and activity aggregation. For the heterogeneous graph\nconsists of various types of nodes, we propose an attention mechanism to learn\nthe importance of different types of nodes, while using the sum operator for\nmodeling the aggregation patterns of nodes in each type. Experiments show that\nour approaches consistently perform promising results compared with competitive\nmethods over time.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 18:26:44 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Liu", "Ziqi", ""], ["Chen", "Chaochao", ""], ["Yang", "Xinxing", ""], ["Zhou", "Jun", ""], ["Li", "Xiaolong", ""], ["Song", "Le", ""]]}, {"id": "2002.12321", "submitter": "Wanrong Zhang", "authors": "Wanrong Zhang, Gautam Kamath, Rachel Cummings", "title": "PAPRIKA: Private Online False Discovery Rate Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.DS cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In hypothesis testing, a false discovery occurs when a hypothesis is\nincorrectly rejected due to noise in the sample. When adaptively testing\nmultiple hypotheses, the probability of a false discovery increases as more\ntests are performed. Thus the problem of False Discovery Rate (FDR) control is\nto find a procedure for testing multiple hypotheses that accounts for this\neffect in determining the set of hypotheses to reject. The goal is to minimize\nthe number (or fraction) of false discoveries, while maintaining a high true\npositive rate (i.e., correct discoveries).\n  In this work, we study False Discovery Rate (FDR) control in multiple\nhypothesis testing under the constraint of differential privacy for the sample.\nUnlike previous work in this direction, we focus on the online setting, meaning\nthat a decision about each hypothesis must be made immediately after the test\nis performed, rather than waiting for the output of all tests as in the offline\nsetting. We provide new private algorithms based on state-of-the-art results in\nnon-private online FDR control. Our algorithms have strong provable guarantees\nfor privacy and statistical performance as measured by FDR and power. We also\nprovide experimental results to demonstrate the efficacy of our algorithms in a\nvariety of data environments.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 18:42:23 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 03:06:54 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Zhang", "Wanrong", ""], ["Kamath", "Gautam", ""], ["Cummings", "Rachel", ""]]}, {"id": "2002.12412", "submitter": "Ipsita Koley", "authors": "Ipsita Koley, Saurav Kumar Ghosh, Soumyajit Dey, Debdeep Mukhopadhyay,\n  Amogh Kashyap K N, Sachin Kumar Singh, Lavanya Lokesh, Jithin Nalu Purakkal,\n  Nishant Sinha", "title": "Formal Synthesis of Monitoring and Detection Systems for Secure CPS\n  Implementations", "comments": "4 Pages, Date 2019 Poster Presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of securing a given control loop implementation of a\ncyber-physical system (CPS) in the presence of Man-in-the-Middle attacks on\ndata exchange between plant and controller over a compromised network. To this\nend, there exist various detection schemes that provide mathematical guarantees\nagainst such attacks for the theoretical control model. However, such\nguarantees may not hold for the actual control software implementation. In this\narticle, we propose a formal approach towards synthesizing attack detectors\nwith varying thresholds which can prevent performance degrading stealthy\nattacks while minimizing false alarms.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 19:54:08 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Koley", "Ipsita", ""], ["Ghosh", "Saurav Kumar", ""], ["Dey", "Soumyajit", ""], ["Mukhopadhyay", "Debdeep", ""], ["N", "Amogh Kashyap K", ""], ["Singh", "Sachin Kumar", ""], ["Lokesh", "Lavanya", ""], ["Purakkal", "Jithin Nalu", ""], ["Sinha", "Nishant", ""]]}, {"id": "2002.12438", "submitter": "Amit Behera", "authors": "Amit Behera, Or Sattath", "title": "Almost Public Quantum Coins", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a quantum money scheme, a bank can issue money that users cannot\ncounterfeit. Similar to bills of paper money, most quantum money schemes assign\na unique serial number to each money state, thus potentially compromising the\nprivacy of the users of quantum money. However in a quantum coins scheme, just\nlike the traditional currency coin scheme, all the money states are exact\ncopies of each other, providing a better level of privacy for the users.\n  A quantum money scheme can be private, i.e., only the bank can verify the\nmoney states, or public, meaning anyone can verify. In this work, we propose a\nway to lift any private quantum coin scheme -- which is known to exist based on\nthe existence of one-way functions, due to Ji, Liu, and Song (CRYPTO'18) -- to\na scheme that closely resembles a public quantum coin scheme. Verification of a\nnew coin is done by comparing it to the coins the user already possesses, by\nusing a projector on to the symmetric subspace. No public coin scheme was known\nprior to this work. It is also the first construction that is very close to a\npublic quantum money scheme and is provably secure based on standard\nassumptions. The lifting technique when instantiated with the private quantum\ncoins scheme, due to Mosca and Stebila 2010, gives rise to the first\nconstruction that is very close to an inefficient unconditionally secure public\nquantum money scheme.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 21:00:57 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 09:48:13 GMT"}, {"version": "v3", "created": "Sun, 22 Nov 2020 14:07:07 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Behera", "Amit", ""], ["Sattath", "Or", ""]]}, {"id": "2002.12439", "submitter": "Xavier Bonnetain", "authors": "Xavier Bonnetain, Akinori Hosoyamada, Mar\\'ia Naya-Plasencia, Yu\n  Sasaki, and Andr\\'e Schrottenloher", "title": "Quantum Attacks without Superposition Queries: the Offline Simon's\n  Algorithm", "comments": "ASIACRYPT 2019", "journal-ref": null, "doi": "10.1007/978-3-030-34578-5_20", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In symmetric cryptanalysis, the model of superposition queries has led to\nsurprising results, with many constructions being broken in polynomial time\nthanks to Simon's period-finding algorithm. But the practical implications of\nthese attacks remain blurry. In contrast, the results obtained so far for a\nquantum adversary making classical queries only are less impressive. In this\npaper, we introduce a new quantum algorithm which uses Simon's subroutines in a\nnovel way. We manage to leverage the algebraic structure of cryptosystems in\nthe context of a quantum attacker limited to classical queries and offline\nquantum computations. We obtain improved quantum-time/classical-data tradeoffs\nwith respect to the current literature, while using only as much hardware\nrequirements (quantum and classical) as a standard exhaustive search with\nGrover's algorithm. In particular, we are able to break the Even-Mansour\nconstruction in quantum time $\\tilde{O}(2^{n/3})$, with $O(2^{n/3})$ classical\nqueries and $O(n^2)$ qubits only. In addition, we improve some previous\nsuperposition attacks by reducing the data complexity from exponential to\npolynomial, with the same time complexity. Our approach can be seen in two\ncomplementary ways: \\emph{reusing} superposition queries during the iteration\nof a search using Grover's algorithm, or alternatively, removing the memory\nrequirement in some quantum attacks based on a collision search, thanks to\ntheir algebraic structure. We provide a list of cryptographic applications,\nincluding the Even-Mansour construction, the FX construction, some Sponge\nauthenticated modes of encryption, and many more.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 21:05:54 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Bonnetain", "Xavier", ""], ["Hosoyamada", "Akinori", ""], ["Naya-Plasencia", "Mar\u00eda", ""], ["Sasaki", "Yu", ""], ["Schrottenloher", "Andr\u00e9", ""]]}, {"id": "2002.12463", "submitter": "Marc Fischer", "authors": "Marc Fischer, Maximilian Baader, Martin Vechev", "title": "Certified Defense to Image Transformations via Randomized Smoothing", "comments": "Conference Paper at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend randomized smoothing to cover parameterized transformations (e.g.,\nrotations, translations) and certify robustness in the parameter space (e.g.,\nrotation angle). This is particularly challenging as interpolation and rounding\neffects mean that image transformations do not compose, in turn preventing\ndirect certification of the perturbed image (unlike certification with $\\ell^p$\nnorms). We address this challenge by introducing three different defenses, each\nwith a different guarantee (heuristic, distributional and individual) stemming\nfrom the method used to bound the interpolation error. Importantly, in the\nindividual case, we show how to efficiently compute the inverse of an image\ntransformation, enabling us to provide individual guarantees in the online\nsetting. We provide an implementation of all methods at\nhttps://github.com/eth-sri/transformation-smoothing.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 22:02:32 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 10:40:34 GMT"}, {"version": "v3", "created": "Mon, 4 Jan 2021 15:03:08 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Fischer", "Marc", ""], ["Baader", "Maximilian", ""], ["Vechev", "Martin", ""]]}, {"id": "2002.12506", "submitter": "Jaehyeok Han", "authors": "Jaehyeok Han, Jungheum Park, Hyunji Chung and Sangjin Lee (Center for\n  Information Security Technologies, School of Cybersecurity, Korea University)", "title": "Forensic analysis of the Windows telemetry for diagnostics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Telemetry is the automated sensing and collection of data from a remote\ndevice. It is often used to provide better services for users. Microsoft uses\ntelemetry to periodically collect information about Windows systems and to help\nimprove user experience and fix potential issues. Windows telemetry service\nfunctions by creating RBS files on the local system to reliably transfer and\nmanage the telemetry data, and these files can provide useful information in a\ndigital forensic investigation. Combined with the information derived from\ntraditional Windows forensics, investigators can have greater confidence in the\nevidence derived from various artifacts. It is possible to acquire information\nthat can be confirmed only for live systems, such as the computer hardware\nserial number, the connection records for external storage devices, and traces\nof executed processes. This information is included in the RBS files that are\ncreated for use in Windows telemetry. In this paper, we introduced how to\nacquire RBS files telemetry and analyzed the data structure of these RBS files,\nwhich are able to determine the types of information that Windows OS have been\ncollected. We also discussed the reliability and the novelty by comparing the\nconventional artifacts with the RBS files, which could be useful in digital\nforensic investigation.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 01:37:07 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Han", "Jaehyeok", "", "Center for\n  Information Security Technologies, School of Cybersecurity, Korea University"], ["Park", "Jungheum", "", "Center for\n  Information Security Technologies, School of Cybersecurity, Korea University"], ["Chung", "Hyunji", "", "Center for\n  Information Security Technologies, School of Cybersecurity, Korea University"], ["Lee", "Sangjin", "", "Center for\n  Information Security Technologies, School of Cybersecurity, Korea University"]]}, {"id": "2002.12618", "submitter": "Marialena Akriotou", "authors": "M. Akriotou (1), A. Fragkos (2), D. Syvridis (1) ((1) Department of\n  Informatics & Telecommunications, National and Kapodistrian University of\n  Athens, Athens, Greece, (2) Eulambia Advanced Technologies Ltd., Athens,\n  Greece)", "title": "Photonic Physical Unclonable Functions: From the Concept to Fully\n  Functional Device Operating in the Field", "comments": null, "journal-ref": "Proc. SPIE 11274, Physics and Simulation of Optoelectronic Devices\n  XXVIII, 112740N (9 March 2020)", "doi": "10.1117/12.2551272", "report-no": null, "categories": "cs.CR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scope of this paper is to demonstrate a fully working and compact\nphotonic Physical Unclonable Function (PUF) device capable of operating in real\nlife scenarios as an authentication mechanism and random number generator. For\nthis purpose, an extensive experimental investigation of a Polymer Optical\nFiber (POF) and a diffuser as PUF tokens is performed and the most significant\nproperties are evaluated using the proper mathematical tools. Two different\nsoftware algorithms, the Random Binary Method (RBM) and Singular Value\nDecomposition (SVD), were tested for optimized key extraction and error\ncorrection codes have been incorporated for enhancing key reproducibility. By\ntaking into consideration the limitations and overall performance derived by\nthe experimental evaluation of the system, the designing details towards the\nimplementation of a miniaturized, energy efficient and low-cost device are\nextensively discussed. The performance of the final device is thoroughly\nevaluated, demonstrating a long-term stability of 1 week, an operating\ntemperature range of 50C, an exponentially large pool of unique\nChallenge-Response Pairs (CRPs), recovery after power failure and capability of\ngenerating NIST compliant true random numbers.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 09:37:32 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Akriotou", "M.", ""], ["Fragkos", "A.", ""], ["Syvridis", "D.", ""]]}, {"id": "2002.12785", "submitter": "Violetta Weger", "authors": "Violetta Weger, Karan Khathuria, Anna-Lena Horlemann, Massimo\n  Battaglioni, Paolo Santini, Edoardo Persichetti", "title": "On the Hardness of the Lee Syndrome Decoding Problem", "comments": "Part of this work appeared as preliminary results in arXiv:2001.08425", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the hardness of the syndrome decoding problem over\nfinite rings endowed with the Lee metric. We first prove that the decisional\nversion of the problem is NP-complete, by a reduction from the 3-dimensional\nmatching problem. Then, we study the actual complexity of solving the problem,\nby translating the best known solvers in the Hamming metric over finite fields\nto the Lee metric over finite rings, as well as proposing some novel solutions.\nFor the analyzed algorithms, we assess the computational complexity in both the\nfinite and asymptotic regimes.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 15:04:18 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 16:14:50 GMT"}, {"version": "v3", "created": "Tue, 2 Mar 2021 14:49:25 GMT"}, {"version": "v4", "created": "Wed, 30 Jun 2021 12:27:08 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Weger", "Violetta", ""], ["Khathuria", "Karan", ""], ["Horlemann", "Anna-Lena", ""], ["Battaglioni", "Massimo", ""], ["Santini", "Paolo", ""], ["Persichetti", "Edoardo", ""]]}, {"id": "2002.12789", "submitter": "Chen Liang", "authors": "Chen Liang, Ziqi Liu, Bin Liu, Jun Zhou, Xiaolong Li, Shuang Yang,\n  Yuan Qi", "title": "Uncovering Insurance Fraud Conspiracy with Network Learning", "comments": "Accepted by SIGIR '19. Proceedings of the 42nd International ACM\n  SIGIR Conference on Research and Development in Information Retrieval. 2019", "journal-ref": null, "doi": "10.1145/3331184.3331372", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fraudulent claim detection is one of the greatest challenges the insurance\nindustry faces. Alibaba's return-freight insurance, providing return-shipping\npostage compensations over product return on the e-commerce platform, receives\nthousands of potentially fraudulent claims every day. Such deliberate abuse of\nthe insurance policy could lead to heavy financial losses. In order to detect\nand prevent fraudulent insurance claims, we developed a novel data-driven\nprocedure to identify groups of organized fraudsters, one of the major\ncontributions to financial losses, by learning network information. In this\npaper, we introduce a device-sharing network among claimants, followed by\ndeveloping an automated solution for fraud detection based on graph learning\nalgorithms, to separate fraudsters from regular customers and uncover groups of\norganized fraudsters. This solution applied at Alibaba achieves more than 80%\nprecision while covering 44% more suspicious accounts compared with a\npreviously deployed rule-based classifier after human expert investigations.\nOur approach can easily and effectively generalizes to other types of\ninsurance.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 13:15:30 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Liang", "Chen", ""], ["Liu", "Ziqi", ""], ["Liu", "Bin", ""], ["Zhou", "Jun", ""], ["Li", "Xiaolong", ""], ["Yang", "Shuang", ""], ["Qi", "Yuan", ""]]}, {"id": "2002.12837", "submitter": "Marten Sigwart", "authors": "Philipp Frauenthaler, Marten Sigwart, Christof Spanring, Stefan\n  Schulte", "title": "Testimonium: A Cost-Efficient Blockchain Relay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current blockchain technologies provide very limited means of\ninteroperability. In particular, solutions enabling blockchains to verify the\nexistence of data on other blockchains are either very costly or are not fully\ndecentralized. To overcome these limitations, we introduce Testimonium, a novel\nblockchain relay scheme that applies a validation-on-demand pattern and the\non-chain execution of Simplified Payment Verifications to enable the\nverification of data across blockchains while remaining fully decentralized.\nEvaluating the scheme for Ethereum-based blockchains shows that Testimonium\nachieves a cost reduction of up to 92% over existing solutions. As such, the\nscheme lays a strong foundation for generic blockchain interoperability. For\ninstance, it enables the development of an atomic-commit protocol for\ndistributed transactions across blockchains.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 13:49:47 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Frauenthaler", "Philipp", ""], ["Sigwart", "Marten", ""], ["Spanring", "Christof", ""], ["Schulte", "Stefan", ""]]}]