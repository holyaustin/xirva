[{"id": "1909.00056", "submitter": "Nicolas Papernot", "authors": "Dan Boneh and Andrew J. Grotto and Patrick McDaniel and Nicolas\n  Papernot", "title": "How Relevant is the Turing Test in the Age of Sophisbots?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Popular culture has contemplated societies of thinking machines for\ngenerations, envisioning futures from utopian to dystopian. These futures are,\narguably, here now-we find ourselves at the doorstep of technology that can at\nleast simulate the appearance of thinking, acting, and feeling. The real\nquestion is: now what?\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 20:18:18 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Boneh", "Dan", ""], ["Grotto", "Andrew J.", ""], ["McDaniel", "Patrick", ""], ["Papernot", "Nicolas", ""]]}, {"id": "1909.00102", "submitter": "Alexander Hanbo Li", "authors": "Alexander Hanbo Li, Abhinav Sethy", "title": "Knowledge Enhanced Attention for Robust Natural Language Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network models have been very successful at achieving high accuracy on\nnatural language inference (NLI) tasks. However, as demonstrated in recent\nliterature, when tested on some simple adversarial examples, most of the models\nsuffer a significant drop in performance. This raises the concern about the\nrobustness of NLI models. In this paper, we propose to make NLI models robust\nby incorporating external knowledge to the attention mechanism using a simple\ntransformation. We apply the new attention to two popular types of NLI models:\none is Transformer encoder, and the other is a decomposable model, and show\nthat our method can significantly improve their robustness. Moreover, when\ncombined with BERT pretraining, our method achieves the human-level performance\non the adversarial SNLI data set.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 01:04:58 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Li", "Alexander Hanbo", ""], ["Sethy", "Abhinav", ""]]}, {"id": "1909.00104", "submitter": "Shuaike Dong", "authors": "Shuaike Dong, Zhou Li, Di Tang, Jiongyi Chen, Menghan Sun, Kehuan\n  Zhang", "title": "Your Smart Home Can't Keep a Secret: Towards Automated Fingerprinting of\n  IoT Traffic with Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The IoT (Internet of Things) technology has been widely adopted in recent\nyears and has profoundly changed the people's daily lives. However, in the\nmeantime, such a fast-growing technology has also introduced new privacy\nissues, which need to be better understood and measured. In this work, we look\ninto how private information can be leaked from network traffic generated in\nthe smart home network. Although researchers have proposed techniques to infer\nIoT device types or user behaviors under clean experiment setup, the\neffectiveness of such approaches become questionable in the complex but\nrealistic network environment, where common techniques like Network Address and\nPort Translation (NAPT) and Virtual Private Network (VPN) are enabled. Traffic\nanalysis using traditional methods (e.g., through classical machine-learning\nmodels) is much less effective under those settings, as the features picked\nmanually are not distinctive any more. In this work, we propose a traffic\nanalysis framework based on sequence-learning techniques like LSTM and\nleveraged the temporal relations between packets for the attack of device\nidentification. We evaluated it under different environment settings (e.g.,\npure-IoT and noisy environment with multiple non-IoT devices). The results\nshowed our framework was able to differentiate device types with a high\naccuracy. This result suggests IoT network communications pose prominent\nchallenges to users' privacy, even when they are protected by encryption and\nmorphed by the network gateway. As such, new privacy protection methods on IoT\ntraffic need to be developed towards mitigating this new issue.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 01:20:00 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Dong", "Shuaike", ""], ["Li", "Zhou", ""], ["Tang", "Di", ""], ["Chen", "Jiongyi", ""], ["Sun", "Menghan", ""], ["Zhang", "Kehuan", ""]]}, {"id": "1909.00268", "submitter": "Ankit Gangwal", "authors": "Ankit Gangwal, Samuele Giuliano Piazzetta, Gianluca Lain, Mauro Conti", "title": "Detecting Covert Cryptomining using HPC", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cybercriminals have been exploiting cryptocurrencies to commit various unique\nfinancial frauds. Covert cryptomining - which is defined as an unauthorized\nharnessing of victims' computational resources to mine cryptocurrencies - is\none of the prevalent ways nowadays used by cybercriminals to earn financial\nbenefits. Such exploitation of resources causes financial losses to the\nvictims.\n  In this paper, we present our novel and efficient approach to detect covert\ncryptomining. Our solution is a generic solution that, unlike currently\navailable solutions to detect covert cryptomining, is not tailored to a\nspecific cryptocurrency or a particular form of cryptomining. In particular, we\nfocus on the core mining algorithms and utilize Hardware Performance Counters\n(HPC) to create clean signatures that grasp the execution pattern of these\nalgorithms on a processor. We built a complete implementation of our solution\nemploying advanced machine learning techniques. We evaluated our methodology on\ntwo different processors through an exhaustive set of experiments. In our\nexperiments, we considered all the cryptocurrencies mined by the top-10 mining\npools, which collectively represent the largest share (84% during Q3 2018) of\nthe cryptomining market. Our results show that our classifier can achieve a\nnear-perfect classification with samples of length as low as five seconds. Due\nto its robust and practical design, our solution can even adapt to zero-day\ncryptocurrencies. Finally, we believe our solution is scalable and can be\ndeployed to tackle the uprising problem of covert cryptomining.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 19:33:21 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 11:02:38 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Gangwal", "Ankit", ""], ["Piazzetta", "Samuele Giuliano", ""], ["Lain", "Gianluca", ""], ["Conti", "Mauro", ""]]}, {"id": "1909.00280", "submitter": "Yunior Ram\\'irez-Cruz", "authors": "Xihui Chen, Sjouke Mauw, Yunior Ram\\'irez-Cruz", "title": "Publishing Community-Preserving Attributed Social Graphs with a\n  Differential Privacy Guarantee", "comments": null, "journal-ref": "Proceedings on Privacy Enhancing Technologies 2020(4):131-152,\n  2020", "doi": "10.2478/popets-2020-0066", "report-no": null, "categories": "cs.SI cs.CR physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel method for publishing differentially private synthetic\nattributed graphs. Unlike preceding approaches, our method is able to preserve\nthe community structure of the original graph without sacrificing the ability\nto capture global structural properties. Our proposal relies on C-AGM, a new\ncommunity-preserving generative model for attributed graphs. We equip C-AGM\nwith efficient methods for attributed graph sampling and parameter estimation.\nFor the latter, we introduce differentially private computation methods, which\nallow us to release community-preserving synthetic attributed social graphs\nwith a strong formal privacy guarantee. Through comprehensive experiments, we\nshow that our new model outperforms its most relevant counterparts in\nsynthesising differentially private attributed social graphs that preserve the\ncommunity structure of the original graph, as well as degree sequences and\nclustering coefficients.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 20:16:51 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Chen", "Xihui", ""], ["Mauw", "Sjouke", ""], ["Ram\u00edrez-Cruz", "Yunior", ""]]}, {"id": "1909.00299", "submitter": "Kien Nguyen", "authors": "Kien Nguyen, Gabriel Ghinita, Muhammad Naveed, Cyrus Shahabi", "title": "A Privacy-Preserving, Accountable and Spam-Resilient Geo-Marketplace", "comments": "SIGSPATIAL'19, 10 pages", "journal-ref": null, "doi": "10.1145/3347146.3359072", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile devices with rich features can record videos, traffic parameters or\nair quality readings along user trajectories. Although such data may be\nvaluable, users are seldom rewarded for collecting them. Emerging digital\nmarketplaces allow owners to advertise their data to interested buyers. We\nfocus on geo-marketplaces, where buyers search data based on geo-tags. Such\nmarketplaces present significant challenges. First, if owners upload data with\nrevealed geo-tags, they expose themselves to serious privacy risks. Second,\nowners must be accountable for advertised data, and must not be allowed to\nsubsequently alter geo-tags. Third, such a system may be vulnerable to\nintensive spam activities, where dishonest owners flood the system with fake\nadvertisements. We propose a geo-marketplace that addresses all these concerns.\nWe employ searchable encryption, digital commitments, and blockchain to protect\nthe location privacy of owners while at the same time incorporating\naccountability and spam-resilience mechanisms. We implement a prototype with\ntwo alternative designs that obtain distinct trade-offs between trust\nassumptions and performance. Our experiments on real location data show that\none can achieve the above design goals with practical performance and\nreasonable financial overhead.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 00:30:58 GMT"}, {"version": "v2", "created": "Sun, 22 Sep 2019 22:05:13 GMT"}, {"version": "v3", "created": "Mon, 30 Sep 2019 18:39:34 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Nguyen", "Kien", ""], ["Ghinita", "Gabriel", ""], ["Naveed", "Muhammad", ""], ["Shahabi", "Cyrus", ""]]}, {"id": "1909.00300", "submitter": "Sahar Abdelnabi", "authors": "Sahar Abdelnabi and Katharina Krombholz and Mario Fritz", "title": "VisualPhishNet: Zero-Day Phishing Website Detection by Visual Similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phishing websites are still a major threat in today's Internet ecosystem.\nDespite numerous previous efforts, similarity-based detection methods do not\noffer sufficient protection for the trusted websites - in particular against\nunseen phishing pages. This paper contributes VisualPhishNet, a new\nsimilarity-based phishing detection framework, based on a triplet Convolutional\nNeural Network (CNN). VisualPhishNet learns profiles for websites in order to\ndetect phishing websites by a similarity metric that can generalize to pages\nwith new visual appearances. We furthermore present VisualPhish, the largest\ndataset to date that facilitates visual phishing detection in an ecologically\nvalid manner. We show that our method outperforms previous visual similarity\nphishing detection approaches by a large margin while being robust against a\nrange of evasion attacks.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 00:55:10 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 20:39:38 GMT"}, {"version": "v3", "created": "Thu, 14 May 2020 16:22:37 GMT"}, {"version": "v4", "created": "Sun, 5 Jul 2020 15:24:44 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Abdelnabi", "Sahar", ""], ["Krombholz", "Katharina", ""], ["Fritz", "Mario", ""]]}, {"id": "1909.00493", "submitter": "Hadi Mardani Kamali", "authors": "Kimia Zamiri Azar, Farnoud Farahmand, Hadi Mardani Kamali, Shervin\n  Roshanisefat, Houman Homayoun, William Diehl, Kris Gaj, Avesta Sasan", "title": "COMA: Communication and Obfuscation Management Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel Communication and Obfuscation Management\nArchitecture (COMA) to handle the storage of the obfuscation key and to secure\nthe communication to/from untrusted yet obfuscated circuits. COMA addresses\nthree challenges related to the obfuscated circuits: First, it removes the need\nfor the storage of the obfuscation unlock key at the untrusted chip. Second, it\nimplements a mechanism by which the key sent for unlocking an obfuscated\ncircuit changes after each activation (even for the same device), transforming\nthe key into a dynamically changing license. Third, it protects the\ncommunication to/from the COMA protected device and additionally introduces two\nnovel mechanisms for the exchange of data to/from COMA protected architectures:\n(1) a highly secure but slow double encryption, which is used for exchange of\nkey and sensitive data (2) a high-performance and low-energy yet leaky\nencryption, secured by means of frequent key renewal. We demonstrate that\ncompared to state-of-the-art key management architectures, COMA reduces the\narea overhead by 14%, while allowing additional features including unique chip\nauthentication, enabling activation as a service (for IoT devices), reducing\nthe side channel threats on key management architecture, and providing two new\nmeans of secure communication to/from an untrusted chip.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 23:51:02 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Azar", "Kimia Zamiri", ""], ["Farahmand", "Farnoud", ""], ["Kamali", "Hadi Mardani", ""], ["Roshanisefat", "Shervin", ""], ["Homayoun", "Houman", ""], ["Diehl", "William", ""], ["Gaj", "Kris", ""], ["Sasan", "Avesta", ""]]}, {"id": "1909.00647", "submitter": "Guanhua Wang", "authors": "Guanhua Wang, Sudipta Chattopadhyay, Arnab Kumar Biswas, Tulika Mitra,\n  Abhik Roychoudhury", "title": "KLEESPECTRE: Detecting Information Leakage through Speculative Cache\n  Attacks via Symbolic Execution", "comments": null, "journal-ref": "ACM Transactions on Software Engineering and Methodology, 2020", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectre attacks disclosed in early 2018 expose data leakage scenarios via\ncache side channels. Specifically, speculatively executed paths due to branch\nmis-prediction may bring secret data into the cache which are then exposed via\ncache side channels even after the speculative execution is squashed. Symbolic\nexecution is a well-known test generation method to cover program paths at the\nlevel of the application software. In this paper, we extend symbolic execution\nwith modelingof cache and speculative execution. Our tool KLEESPECTRE, built on\ntop of the KLEE symbolic execution engine, can thus provide a testing engine to\ncheck for the data leakage through cache side-channel as shown via Spectre\nattacks. Our symbolic cache model can verify whether the sensitive data leakage\ndue to speculative execution can be observed by an attacker at a given program\npoint. Our experiments show that KLEESPECTREcan effectively detect data leakage\nalong speculatively executed paths and our cache model can further make the\nleakage detection much more precise.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 10:18:03 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Wang", "Guanhua", ""], ["Chattopadhyay", "Sudipta", ""], ["Biswas", "Arnab Kumar", ""], ["Mitra", "Tulika", ""], ["Roychoudhury", "Abhik", ""]]}, {"id": "1909.00882", "submitter": "Kien Nguyen", "authors": "Hien To, Kien Nguyen, Cyrus Shahabi", "title": "Differentially Private Publication of Location Entropy", "comments": "SIGSPATIAL'16, 10 pages", "journal-ref": "Proceedings of the 24th ACM SIGSPATIAL International Conference on\n  Advances in Geographic Information Systems, 2019", "doi": "10.1145/2996913.2996985", "report-no": null, "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Location entropy (LE) is a popular metric for measuring the popularity of\nvarious locations (e.g., points-of-interest). Unlike other metrics computed\nfrom only the number of (unique) visits to a location, namely frequency, LE\nalso captures the diversity of the users' visits, and is thus more accurate\nthan other metrics. Current solutions for computing LE require full access to\nthe past visits of users to locations, which poses privacy threats. This paper\ndiscusses, for the first time, the problem of perturbing location entropy for a\nset of locations according to differential privacy. The problem is challenging\nbecause removing a single user from the dataset will impact multiple records of\nthe database; i.e., all the visits made by that user to various locations.\nTowards this end, we first derive non-trivial, tight bounds for both local and\nglobal sensitivity of LE, and show that to satisfy $\\epsilon$-differential\nprivacy, a large amount of noise must be introduced, rendering the published\nresults useless. Hence, we propose a thresholding technique to limit the number\nof users' visits, which significantly reduces the perturbation error but\nintroduces an approximation error. To achieve better utility, we extend the\ntechnique by adopting two weaker notions of privacy: smooth sensitivity\n(slightly weaker) and crowd-blending (strictly weaker). Extensive experiments\non synthetic and real-world datasets show that our proposed techniques preserve\noriginal data distribution without compromising location privacy.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 22:25:51 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["To", "Hien", ""], ["Nguyen", "Kien", ""], ["Shahabi", "Cyrus", ""]]}, {"id": "1909.00900", "submitter": "Chengzhi Mao", "authors": "Chengzhi Mao, Ziyuan Zhong, Junfeng Yang, Carl Vondrick, Baishakhi Ray", "title": "Metric Learning for Adversarial Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks are well-known to be fragile to adversarial attacks. We conduct\nan empirical analysis of deep representations under the state-of-the-art attack\nmethod called PGD, and find that the attack causes the internal representation\nto shift closer to the \"false\" class. Motivated by this observation, we propose\nto regularize the representation space under attack with metric learning to\nproduce more robust classifiers. By carefully sampling examples for metric\nlearning, our learned representation not only increases robustness, but also\ndetects previously unseen adversarial samples. Quantitative experiments show\nimprovement of robustness accuracy by up to 4% and detection efficiency by up\nto 6% according to Area Under Curve score over prior work. The code of our work\nis available at\nhttps://github.com/columbia/Metric_Learning_Adversarial_Robustness.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 00:39:40 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 00:43:15 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Mao", "Chengzhi", ""], ["Zhong", "Ziyuan", ""], ["Yang", "Junfeng", ""], ["Vondrick", "Carl", ""], ["Ray", "Baishakhi", ""]]}, {"id": "1909.00902", "submitter": "Omid Setayeshfar", "authors": "Omid Setayeshfar, Christian Adkins, Matthew Jones, Kyu Hyung Lee,\n  Prashant Doshi", "title": "GrAALF:Supporting Graphical Analysis of Audit Logs for Forensics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  System-level audit logs often play a critical role in computer forensics.\nThey capture low-level interactions between programs and users in much detail,\nmaking them a rich source of insight and provenance on malicious user activity.\nHowever, using these logs to discover and understand malicious activities when\na typical computer generates more than 2.5 million system events hourly is both\ncompute and time-intensive. We introduce a graphical system called GrAALF for\nefficiently loading, storing, processing, querying, and displaying system\nevents to support computer forensics. In comparison to other related systems\nsuch as AIQL [13] and SAQL [12], GrAALF offers the flexibility of multiple\nbackend storage solutions, easy-to-use and intuitive querying of logs, and the\nability to trace back longer sequences of system events in (near) real-time to\nhelp identify and isolate attacks. Equally important, both AIQL and SAQL are\nnot available for public use, whereas GrAALF is open-source. GrAALF offers the\nchoice of compactly storing the logs in main memory, in a relational database\nsystem, in a hybrid main memory-database system, and a graph-based database. We\ncompare the responsiveness of each of these options, using multiple huge\nsystem-call log files. Next, in multiple real-world attack scenarios, we\ndemonstrate the efficacy and usefulness of GrAALF in identifying the attack and\ndiscovering its provenance. Consequently, GrAALF offers a robust solution for\nanalysis of audit logs to support computer forensics.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 00:44:17 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 16:24:56 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Setayeshfar", "Omid", ""], ["Adkins", "Christian", ""], ["Jones", "Matthew", ""], ["Lee", "Kyu Hyung", ""], ["Doshi", "Prashant", ""]]}, {"id": "1909.00938", "submitter": "Fan Zhang", "authors": "Fan Zhang, Sai Krishna Deepak Maram, Harjasleen Malvai, Steven\n  Goldfeder, Ari Juels", "title": "DECO: Liberating Web Data Using Decentralized Oracles for TLS", "comments": "This is the extended version of the CCS'20 paper", "journal-ref": null, "doi": "10.1145/3372297.3417239", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thanks to the widespread deployment of TLS, users can access private data\nover channels with end-to-end confidentiality and integrity. What they cannot\ndo, however, is prove to third parties the {\\em provenance} of such data, i.e.,\nthat it genuinely came from a particular website. Existing approaches either\nintroduce undesirable trust assumptions or require server-side modifications.\n  As a result, the value of users' private data is locked up in its point of\norigin. Users cannot export their data with preserved integrity to other\napplications without help and permission from the current data holder.\n  We propose DECO (short for \\underline{dec}entralized \\underline{o}racle) to\naddress the above problems. DECO allows users to prove that a piece of data\naccessed via TLS came from a particular website and optionally prove statements\nabout such data in zero-knowledge, keeping the data itself secret. DECO is the\nfirst such system that works without trusted hardware or server-side\nmodifications.\n  DECO can liberate data from centralized web-service silos, making it\naccessible to a rich spectrum of applications. To demonstrate the power of\nDECO, we implement three applications that are hard to achieve without it: a\nprivate financial instrument using smart contracts, converting legacy\ncredentials to anonymous credentials, and verifiable claims against price\ndiscrimination.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 03:42:46 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 18:42:34 GMT"}, {"version": "v3", "created": "Fri, 3 Jan 2020 17:02:06 GMT"}, {"version": "v4", "created": "Tue, 18 Aug 2020 18:38:14 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Zhang", "Fan", ""], ["Maram", "Sai Krishna Deepak", ""], ["Malvai", "Harjasleen", ""], ["Goldfeder", "Steven", ""], ["Juels", "Ari", ""]]}, {"id": "1909.01091", "submitter": "Projjal Gipta", "authors": "Projjal Gupta", "title": "Usage of Permissioned Blockchain Architecture for Big Data in Electronic\n  Medical Records", "comments": "4 pages, 3 figures, 3 Code Objects", "journal-ref": null, "doi": "10.13140/RG.2.2.26981.35048", "report-no": null, "categories": "cs.CY cs.CR cs.DB cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the advent of blockchain technology, multiple research avenues and\nplatforms for dialogue have opened up. However technology transfer to the pubic\nhas not been implemented, such that regular public can access and make use of\nsecure and decentralized software. Most blockchain solutions till date deal\nwith financial applications or monetary transactions, which may not be helpful\nor be accessible to the general public, especially the lower levels of the\nfinancial society. Medi-Chain is a people-first medical blockchain with a\nusable desktop application and interface which makes use of cutting-edge\nblockchain technology along with BFT consensus protocols to ensure highly\nsecure and private medical data records. This paper aims to bring about a\nchange in how blockchains-as-a-service is perceived and how adoption of new\ntechnology is largely based on usability and ease of adoption.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 10:06:57 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Gupta", "Projjal", ""]]}, {"id": "1909.01135", "submitter": "Chidimma Opara", "authors": "Chidimma Opara, Bo Wei, and Yingke Chen", "title": "HTMLPhish: Enabling Phishing Web Page Detection by Applying Deep\n  Learning Techniques on HTML Analysis", "comments": null, "journal-ref": "International Joint Conference on Neural Networks (IJCNN) 2020", "doi": "10.1109/IJCNN48605.2020.9207707", "report-no": null, "categories": "cs.CR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the development and implementation of phishing attacks require\nlittle technical skills and costs. This uprising has led to an ever-growing\nnumber of phishing attacks on the World Wide Web. Consequently, proactive\ntechniques to fight phishing attacks have become extremely necessary. In this\npaper, we propose HTMLPhish, a deep learning based data-driven end-to-end\nautomatic phishing web page classification approach. Specifically, HTMLPhish\nreceives the content of the HTML document of a web page and employs\nConvolutional Neural Networks (CNNs) to learn the semantic dependencies in the\ntextual contents of the HTML. The CNNs learn appropriate feature\nrepresentations from the HTML document embeddings without extensive manual\nfeature engineering. Furthermore, our proposed approach of the concatenation of\nthe word and character embeddings allows our model to manage new features and\nensure easy extrapolation to test data. We conduct comprehensive experiments on\na dataset of more than 50,000 HTML documents that provides a distribution of\nphishing to benign web pages obtainable in the real-world that yields over 93\npercent Accuracy and True Positive Rate. Also, HTMLPhish is a completely\nlanguage-independent and client-side strategy which can, therefore, conduct web\npage phishing detection regardless of the textual language.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 23:58:50 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 17:10:56 GMT"}, {"version": "v3", "created": "Fri, 15 May 2020 10:30:32 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Opara", "Chidimma", ""], ["Wei", "Bo", ""], ["Chen", "Yingke", ""]]}, {"id": "1909.01147", "submitter": "Michael De Oliveira", "authors": "Michael de Oliveira, Isaac Nape, Jonathan Pinnell, Najmeh TabeBordbar,\n  and Andrew Forbes", "title": "Experimental quantum secret sharing with spin-orbit structured photons", "comments": "10 pages, 7 figures, structure and figures revised", "journal-ref": "Phys. Rev. A 101, 042303 (2020)", "doi": "10.1103/PhysRevA.101.042303", "report-no": null, "categories": "quant-ph cs.CR physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secret sharing allows three or more parties to share secret information which\ncan only be decrypted through collaboration. It complements quantum key\ndistribution as a valuable resource for securely distributing information. Here\nwe take advantage of hybrid spin and orbital angular momentum states to access\na high dimensional encoding space, demonstrating a protocol that is easily\nscalable in both dimension and participants. To illustrate the versatility of\nour approach, we first demonstrate the protocol in two dimensions, extending\nthe number of participants to ten, and then demonstrate the protocol in three\ndimensions with three participants, the highest realisation of participants and\ndimensions thus far. We reconstruct secrets depicted as images with a fidelity\nof up to 0.979. Moreover, our scheme exploits the use of conventional linear\noptics to emulate the quantum gates needed for transitions between basis modes\non a high dimensional Hilbert space with the potential of up to 1.225 bits of\nencoding capacity per transmitted photon. Our work offers a practical approach\nfor sharing information across multiple parties, a crucial element of any\nquantum network.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 17:10:19 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 08:11:47 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["de Oliveira", "Michael", ""], ["Nape", "Isaac", ""], ["Pinnell", "Jonathan", ""], ["TabeBordbar", "Najmeh", ""], ["Forbes", "Andrew", ""]]}, {"id": "1909.01162", "submitter": "Zuphit Fidelman", "authors": "Zuphit Fidelman", "title": "A Generic Sharding Scheme for Blockchain Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis introduces a formal general framework for scaling blockchain\nprotocols by sharding. The framework is modular and it can be adjusted for\ndifferent needs or sets of assumptions. We prove that sharded protocols\nobtained by following our scheme (with correct modules in place) live up to the\nsame safety and liveness guarantees as their non-sharded counterparts. The\nproof is general and relies on well-defined specifications of certain\ncomponents. This lays the ground for simple proofs of correctness for sharded\nprotocols obtained by following the proposed scheme.\n  The framework is not left as an obscure specification of some high level\nstructure; explicit use is demonstrated by applying it to shard Algorand. As\npart of this concrete construction, a tamper-proof mechanism to assign nodes to\nshards is introduced. This mechanism is constructed by using verifiable random\nfunctions and can safely withstand a powerful adaptive adversary.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 13:25:55 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Fidelman", "Zuphit", ""]]}, {"id": "1909.01392", "submitter": "Matheus D'E\\c{c}a Torquato De Melo", "authors": "Matheus Torquato, Marco Vieira", "title": "Towards Models for Availability and Security Evaluation of Cloud\n  Computing with Moving Target Defense", "comments": "Student Forum paper of the 15th European Dependable Computing\n  Conference (EDCC 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security is one of the most relevant concerns in cloud computing. With the\nevolution of cyber-security threats, developing innovative techniques to thwart\nattacks is of utmost importance. One recent method to improve cloud computing\nsecurity is Moving Target Defense (MTD). MTD makes use of dynamic\nreconfiguration in virtualized environments to \"confuse\" attackers or to\nnullify their knowledge about the system state. However, there is still no\nconsolidated mechanism to evaluate the trade-offs between availability and\nsecurity when using MTD on cloud computing. The evaluation through measurements\nis complex as one needs to deal with unexpected events as failures and attacks.\nTo overcome this challenge, we intend to propose a set of models to evaluate\nthe availability and security of MTD in cloud computing environments. The\nexpected results include the quantification of availability and security levels\nunder different conditions (e.g., different software aging rates, varying\nworkloads, different attack intensities).\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 18:38:37 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Torquato", "Matheus", ""], ["Vieira", "Marco", ""]]}, {"id": "1909.01432", "submitter": "Kai Zhou", "authors": "Kai Zhou, Tomasz P. Michalak, and Yevgeniy Vorobeychik", "title": "Adversarial Robustness of Similarity-Based Link Prediction", "comments": "ICDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link prediction is one of the fundamental problems in social network\nanalysis. A common set of techniques for link prediction rely on similarity\nmetrics which use the topology of the observed subnetwork to quantify the\nlikelihood of unobserved links. Recently, similarity metrics for link\nprediction have been shown to be vulnerable to attacks whereby observations\nabout the network are adversarially modified to hide target links. We propose a\nnovel approach for increasing robustness of similarity-based link prediction by\nendowing the analyst with a restricted set of reliable queries which accurately\nmeasure the existence of queried links. The analyst aims to robustly predict a\ncollection of possible links by optimally allocating the reliable queries. We\nformalize the analyst problem as a Bayesian Stackelberg game in which they\nfirst choose the reliable queries, followed by an adversary who deletes a\nsubset of links among the remaining (unreliable) queries by the analyst. The\nanalyst in our model is uncertain about the particular target link the\nadversary attempts to hide, whereas the adversary has full information about\nthe analyst and the network. Focusing on similarity metrics using only local\ninformation, we show that the problem is NP-Hard for both players, and devise\ntwo principled and efficient approaches for solving it approximately. Extensive\nexperiments with real and synthetic networks demonstrate the effectiveness of\nour approach.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 20:20:45 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Zhou", "Kai", ""], ["Michalak", "Tomasz P.", ""], ["Vorobeychik", "Yevgeniy", ""]]}, {"id": "1909.01492", "submitter": "Po-Sen Huang", "authors": "Po-Sen Huang, Robert Stanforth, Johannes Welbl, Chris Dyer, Dani\n  Yogatama, Sven Gowal, Krishnamurthy Dvijotham, Pushmeet Kohli", "title": "Achieving Verified Robustness to Symbol Substitutions via Interval Bound\n  Propagation", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are part of many contemporary NLP systems, yet their\nempirical successes come at the price of vulnerability to adversarial attacks.\nPrevious work has used adversarial training and data augmentation to partially\nmitigate such brittleness, but these are unlikely to find worst-case\nadversaries due to the complexity of the search space arising from discrete\ntext perturbations. In this work, we approach the problem from the opposite\ndirection: to formally verify a system's robustness against a predefined class\nof adversarial attacks. We study text classification under synonym replacements\nor character flip perturbations. We propose modeling these input perturbations\nas a simplex and then using Interval Bound Propagation -- a formal model\nverification method. We modify the conventional log-likelihood training\nobjective to train models that can be efficiently verified, which would\notherwise come with exponential search complexity. The resulting models show\nonly little difference in terms of nominal accuracy, but have much improved\nverified accuracy under perturbations and come with an efficiently computable\nformal guarantee on worst case adversaries.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 23:03:10 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 18:21:49 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Huang", "Po-Sen", ""], ["Stanforth", "Robert", ""], ["Welbl", "Johannes", ""], ["Dyer", "Chris", ""], ["Yogatama", "Dani", ""], ["Gowal", "Sven", ""], ["Dvijotham", "Krishnamurthy", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1909.01496", "submitter": "Zachary Ziegler", "authors": "Zachary M. Ziegler, Yuntian Deng, Alexander M. Rush", "title": "Neural Linguistic Steganography", "comments": "EMNLP 2019 Accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whereas traditional cryptography encrypts a secret message into an\nunintelligible form, steganography conceals that communication is taking place\nby encoding a secret message into a cover signal. Language is a particularly\npragmatic cover signal due to its benign occurrence and independence from any\none medium. Traditionally, linguistic steganography systems encode secret\nmessages in existing text via synonym substitution or word order\nrearrangements. Advances in neural language models enable previously\nimpractical generation-based techniques. We propose a steganography technique\nbased on arithmetic coding with large-scale neural language models. We find\nthat our approach can generate realistic looking cover sentences as evaluated\nby humans, while at the same time preserving security by matching the cover\nmessage distribution with the language model distribution.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 23:15:19 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Ziegler", "Zachary M.", ""], ["Deng", "Yuntian", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1909.01502", "submitter": "Riley Spahn", "authors": "Mathias Lecuyer, Riley Spahn, Kiran Vodrahalli, Roxana Geambasu,\n  Daniel Hsu", "title": "Privacy Accounting and Quality Control in the Sage Differentially\n  Private ML Platform", "comments": "Extended version of a paper presented at the 27th ACM Symposium on\n  Operating Systems Principles (SOSP '19)", "journal-ref": null, "doi": "10.1145/3341301.3359639", "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Companies increasingly expose machine learning (ML) models trained over\nsensitive user data to untrusted domains, such as end-user devices and\nwide-access model stores. We present Sage, a differentially private (DP) ML\nplatform that bounds the cumulative leakage of training data through models.\nSage builds upon the rich literature on DP ML algorithms and contributes\npragmatic solutions to two of the most pressing systems challenges of global\nDP: running out of privacy budget and the privacy-utility tradeoff. To address\nthe former, we develop block composition, a new privacy loss accounting method\nthat leverages the growing database regime of ML workloads to keep training\nmodels endlessly on a sensitive data stream while enforcing a global DP\nguarantee for the stream. To address the latter, we develop privacy-adaptive\ntraining, a process that trains a model on growing amounts of data and/or with\nincreasing privacy parameters until, with high probability, the model meets\ndeveloper-configured quality criteria. They illustrate how a systems focus on\ncharacteristics of ML workloads enables pragmatic solutions that are not\napparent when one focuses on individual algorithms, as most DP ML literature\ndoes.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 00:23:21 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 18:25:27 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Lecuyer", "Mathias", ""], ["Spahn", "Riley", ""], ["Vodrahalli", "Kiran", ""], ["Geambasu", "Roxana", ""], ["Hsu", "Daniel", ""]]}, {"id": "1909.01531", "submitter": "Duc Le", "authors": "Duc V. Le and Lizzy Tengana Hurtado and Adil Ahmad and Mohsen Minaei\n  and Byoungyoung Lee and Aniket Kate", "title": "A Tale of Two Trees: One Writes, and Other Reads. Optimized Oblivious\n  Accesses to Large-Scale Blockchains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bitcoin network has offered a new way of securely performing financial\ntransactions over the insecure network. Nevertheless, this ability comes with\nthe cost of storing a large (distributed) ledger, which has become unsuitable\nfor personal devices of any kind. Although the simplified payment verification\n(SPV) clients can address this storage issue, a Bitcoin SPV client has to rely\non other Bitcoin nodes to obtain its transaction history and the current\napproaches offer no privacy guarantees to the SPV clients.\n  This work presents $T^3$, a trusted hardware-secured Bitcoin full client that\nsupports efficient oblivious search/update for Bitcoin SPV clients without\nsacrificing the privacy of the clients. In this design, we leverage the trusted\nexecution and attestation capabilities of a trusted execution environment (TEE)\nand the ability to hide access patterns of oblivious random access memory\n(ORAM) to protect SPV clients' requests from a potentially malicious server.\nThe key novelty of $T^3$ lies in the optimizations introduced to conventional\nORAM, tailored for expected SPV client usages. In particular, by making a\nnatural assumption about the access patterns of SPV clients, we are able to\npropose a two-tree ORAM construction that overcomes the concurrency limitation\nassociated with traditional ORAMs. We have implemented and tested our system\nusing the current Bitcoin Unspent Transaction Output database. Our experiment\nshows that the system is feasible to be deployed in practice while providing\nstrong privacy and security guarantees to Bitcoin SPV clients.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 03:00:22 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 18:05:04 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Le", "Duc V.", ""], ["Hurtado", "Lizzy Tengana", ""], ["Ahmad", "Adil", ""], ["Minaei", "Mohsen", ""], ["Lee", "Byoungyoung", ""], ["Kate", "Aniket", ""]]}, {"id": "1909.01590", "submitter": "Xiaoqing Sun", "authors": "Xiaoqing Sun, Mingkai Tong, Jiahai Yang", "title": "HinDom: A Robust Malicious Domain Detection System based on\n  Heterogeneous Information Network with Transductive Classification", "comments": "RAID2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain name system (DNS) is a crucial part of the Internet, yet has been\nwidely exploited by cyber attackers. Apart from making static methods like\nblacklists or sinkholes infeasible, some weasel attackers can even bypass\ndetection systems with machine learning based classifiers. As a solution to\nthis problem, we propose a robust domain detection system named HinDom. Instead\nof relying on manually selected features, HinDom models the DNS scene as a\nHeterogeneous Information Network (HIN) consist of clients, domains, IP\naddresses and their diverse relationships. Besides, the metapath-based\ntransductive classification method enables HinDom to detect malicious domains\nwith only a small fraction of labeled samples. So far as we know, this is the\nfirst work to apply HIN in DNS analysis. We build a prototype of HinDom and\nevaluate it in CERNET2 and TUNET. The results reveal that HinDom is accurate,\nrobust and can identify previously unknown malicious domains.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 07:30:54 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Sun", "Xiaoqing", ""], ["Tong", "Mingkai", ""], ["Yang", "Jiahai", ""]]}, {"id": "1909.01640", "submitter": "Ramtine Tofighi-Shirazi", "authors": "Ramtine Tofighi-Shirazi (TL, IF), Irina As\\u{a}voae (TL), Philippe\n  Elbaz-Vincent (IF), Thanh-Ha Le (TL)", "title": "Defeating Opaque Predicates Statically through Machine Learning and\n  Binary Analysis", "comments": null, "journal-ref": "3rd International Workshop on Software PROtection, Nov 2019,\n  London, United Kingdom", "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.PL cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach that bridges binary analysis techniques with\nmachine learning classification for the purpose of providing a static and\ngeneric evaluation technique for opaque predicates, regardless of their\nconstructions. We use this technique as a static automated deobfuscation tool\nto remove the opaque predicates introduced by obfuscation mechanisms. According\nto our experimental results, our models have up to 98% accuracy at detecting\nand deob-fuscating state-of-the-art opaque predicates patterns. By contrast,\nthe leading edge deobfuscation methods based on symbolic execution show less\naccuracy mostly due to the SMT solvers constraints and the lack of scalability\nof dynamic symbolic analyses. Our approach underlines the efficiency of hybrid\nsymbolic analysis and machine learning techniques for a static and generic\ndeobfuscation methodology.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 09:19:14 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Tofighi-Shirazi", "Ramtine", "", "TL, IF"], ["As\u0103voae", "Irina", "", "TL"], ["Elbaz-Vincent", "Philippe", "", "IF"], ["Le", "Thanh-Ha", "", "TL"]]}, {"id": "1909.01681", "submitter": "Solomia Fedushko", "authors": "Artem Zakharchenko, Yuliia Maksimtsova, Valentyn Iurchenko, Viktoriya\n  Shevchenko, Solomiia Fedushko", "title": "Under the Conditions of Non-Agenda Ownership: Social Media Users in the\n  2019 Ukrainian Presidential Elections Campaign", "comments": "21 pages, 8 figures", "journal-ref": "CEUR Workshop Proceedings. Vol 2392: Proceedings of the 1st\n  International Workshop on Control, Optimisation and Analytical Processing of\n  Social Networks, COAPSN-2019, 2019", "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Owing to its history and challenging circumstances, social networks community\nin Ukraine is a very interesting polygon for the study of communications in the\nconstantly changing environment, especially in the political discourse. This\nunique environment requires three dimensions to ascertain the political\nposition of its participant. But 2019 presidential elections made this object\neven more spectacular. The winner of elections comedian Volodymyr Zelenskyi\nreached 73% of votes without any issue ownership, with empty agenda, and this\ninfluenced the electoral content of social networks and their authors behavior.\nWe saw, that the issue ownership by other candidates succeeds in making their\nissues more salient in social networks. But the new phenomena, the non-agenda\nownership, overcome any ideological influence, especially under the conditions\nof punishment mechanism applied to old politicians. Analyzing social media\ncontent and users behavior in the period between two rounds of elections, we\nfound considerable overlaps between this campaign and the 2016 Trump campaign.\nWe approved the widespread of filter bubbles, negative campaign messages, fake\nnews and conspiracy theories. Active and powerful core of Ukrainian Facebook\nthat was responsible for the Revolution of dignity now became less significant\nand even turns into the huge filter bubble of active people. We also proved\nthat manipulations and fake news in the environment of private groups may be as\nmuch powerful as in a case of classical communication based around the opinion\nleaders.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 10:30:03 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Zakharchenko", "Artem", ""], ["Maksimtsova", "Yuliia", ""], ["Iurchenko", "Valentyn", ""], ["Shevchenko", "Viktoriya", ""], ["Fedushko", "Solomiia", ""]]}, {"id": "1909.01752", "submitter": "Peter Garba", "authors": "Peter Garba, Matteo Favaro", "title": "SATURN -- Software Deobfuscation Framework Based on LLVM", "comments": "reverse engineering, llvm, code lifting, obfuscation, deobfuscation,\n  static software analysis, binary recompilation, binary rewriting", "journal-ref": "3rd International Workshop on Software PROtection, Nov 2019,\n  London, United Kingdom", "doi": null, "report-no": null, "categories": "cs.CR cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The strength of obfuscated software has increased over the recent years.\nCompiler based obfuscation has become the de facto standard in the industry and\nrecent papers also show that injection of obfuscation techniques is done at the\ncompiler level. In this paper we discuss a generic approach for deobfuscation\nand recompilation of obfuscated code based on the compiler framework LLVM. We\nshow how binary code can be lifted back into the compiler intermediate language\nLLVM-IR and explain how we recover the control flow graph of an obfuscated\nbinary function with an iterative control flow graph construction algorithm\nbased on compiler optimizations and SMT solving. Our approach does not make any\nassumptions about the obfuscated code, but instead uses strong compiler\noptimizations available in LLVM and Souper Optimizer to simplify away the\nobfuscation. Our experimental results show that this approach can be effective\nto weaken or even remove the applied obfuscation techniques like constant\nunfolding, certain arithmetic-based opaque expressions, dead code insertions,\nbogus control flow or integer encoding found in public and commercial\nobfuscators. The recovered LLVM-IR can be further processed by custom\ndeobfuscation passes that are now applied at the same level as the injected\nobfuscation techniques or recompiled with one of the available LLVM backends.\nThe presented work is implemented in a deobfuscation tool called SATURN.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 12:50:21 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 08:25:32 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Garba", "Peter", ""], ["Favaro", "Matteo", ""]]}, {"id": "1909.01783", "submitter": "Giuseppe Vietri", "authors": "Seth Neel, Aaron Roth, Giuseppe Vietri, Zhiwei Steven Wu", "title": "Oracle Efficient Private Non-Convex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most effective algorithms for differentially private learning and\noptimization is objective perturbation. This technique augments a given\noptimization problem (e.g. deriving from an ERM problem) with a random linear\nterm, and then exactly solves it. However, to date, analyses of this approach\ncrucially rely on the convexity and smoothness of the objective function,\nlimiting its generality. We give two algorithms that extend this approach\nsubstantially. The first algorithm requires nothing except boundedness of the\nloss function, and operates over a discrete domain. Its privacy and accuracy\nguarantees hold even without assuming convexity. This gives an oracle-efficient\noptimization algorithm over arbitrary discrete domains that is comparable in\nits generality to the exponential mechanism. The second algorithm operates over\na continuous domain and requires only that the loss function be bounded and\nLipschitz in its continuous parameter. Its privacy analysis does not require\nconvexity. Its accuracy analysis does require convexity, but does not require\nsecond order conditions like smoothness. Even without convexity, this algorithm\ncan be generically used as an oracle-efficient optimization algorithm, with\naccuracy evaluated empirically. We complement our theoretical results with an\nempirical evaluation of the non-convex case, in which we use an integer program\nsolver as our optimization oracle. We find that for the problem of learning\nlinear classifiers, directly optimizing for 0/1 loss using our approach can\nout-perform the more standard approach of privately optimizing a\nconvex-surrogate loss function on the Adult dataset.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 14:31:11 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 18:29:31 GMT"}, {"version": "v3", "created": "Tue, 29 Dec 2020 15:06:40 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Neel", "Seth", ""], ["Roth", "Aaron", ""], ["Vietri", "Giuseppe", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "1909.01785", "submitter": "Billy Bob Brumley", "authors": "Cesar Pereida Garc\\'ia, Sohaib ul Hassan, Nicola Tuveri, Iaroslav\n  Gridin, Alejandro Cabrera Aldaya, Billy Bob Brumley", "title": "Certified Side Channels", "comments": "Accepted to USENIX Security Symposium 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We demonstrate that the format in which private keys are persisted impacts\nSide Channel Analysis (SCA) security. Surveying several widely deployed\nsoftware libraries, we investigate the formats they support, how they parse\nthese keys, and what runtime decisions they make. We uncover a combination of\nweaknesses and vulnerabilities, in extreme cases inducing completely disjoint\nmulti-precision arithmetic stacks deep within the cryptosystem level for keys\nthat otherwise seem logically equivalent. Exploiting these vulnerabilities, we\ndesign and implement key recovery attacks utilizing signals ranging from\nelectromagnetic (EM) emanations, to granular microarchitecture cache timings,\nto coarse traditional wall clock timings.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 13:27:36 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 13:12:57 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Garc\u00eda", "Cesar Pereida", ""], ["Hassan", "Sohaib ul", ""], ["Tuveri", "Nicola", ""], ["Gridin", "Iaroslav", ""], ["Aldaya", "Alejandro Cabrera", ""], ["Brumley", "Billy Bob", ""]]}, {"id": "1909.01837", "submitter": "Siddhartha Datta", "authors": "Siddhartha Datta", "title": "DeepObfusCode: Source Code Obfuscation Through Sequence-to-Sequence\n  Networks", "comments": "Accepted in Advances in Intelligent Systems and Computing 2021 &\n  Computing Conference 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper explores a novel methodology in source code obfuscation through the\napplication of text-based recurrent neural network (RNN) encoder-decoder models\nin ciphertext generation and key generation. Sequence-to-sequence models are\nincorporated into the model architecture to generate obfuscated code, generate\nthe deobfuscation key, and live execution. Quantitative benchmark comparison to\nexisting obfuscation methods indicate significant improvement in stealth and\nexecution cost for the proposed solution, and experiments regarding the model's\nproperties yield positive results regarding its character variation,\ndissimilarity to the original codebase, and consistent length of obfuscated\ncode.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 17:22:39 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 18:01:16 GMT"}, {"version": "v3", "created": "Thu, 25 Feb 2021 11:30:06 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Datta", "Siddhartha", ""]]}, {"id": "1909.01838", "submitter": "Matthew Jagielski", "authors": "Matthew Jagielski, Nicholas Carlini, David Berthelot, Alex Kurakin,\n  Nicolas Papernot", "title": "High Accuracy and High Fidelity Extraction of Neural Networks", "comments": "USENIX Security 2020, 18 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a model extraction attack, an adversary steals a copy of a remotely\ndeployed machine learning model, given oracle prediction access. We taxonomize\nmodel extraction attacks around two objectives: *accuracy*, i.e., performing\nwell on the underlying learning task, and *fidelity*, i.e., matching the\npredictions of the remote victim classifier on any input.\n  To extract a high-accuracy model, we develop a learning-based attack\nexploiting the victim to supervise the training of an extracted model. Through\nanalytical and empirical arguments, we then explain the inherent limitations\nthat prevent any learning-based strategy from extracting a truly high-fidelity\nmodel---i.e., extracting a functionally-equivalent model whose predictions are\nidentical to those of the victim model on all possible inputs. Addressing these\nlimitations, we expand on prior work to develop the first practical\nfunctionally-equivalent extraction attack for direct extraction (i.e., without\ntraining) of a model's weights.\n  We perform experiments both on academic datasets and a state-of-the-art image\nclassifier trained with 1 billion proprietary images. In addition to broadening\nthe scope of model extraction research, our work demonstrates the practicality\nof model extraction attacks against production-grade systems.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 17:33:09 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 22:08:02 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Jagielski", "Matthew", ""], ["Carlini", "Nicholas", ""], ["Berthelot", "David", ""], ["Kurakin", "Alex", ""], ["Papernot", "Nicolas", ""]]}, {"id": "1909.01851", "submitter": "Mututhanthrige Fernando", "authors": "Praveen Fernando, Jin Wei", "title": "Blockchain-Powered Software Defined Network-Enabled Networking\n  Infrastructure for Cloud Management", "comments": "6 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud architecture has become a valuable solution for different applications,\nsuch as big data analytics, due to its high-degree of availability, scalability\nand strategic value. However, there still remain challenges in managing cloud\narchitecture, in areas such as cloud security. In this paper, we exploit\nsoftware-defined networking (SDN) and blockchain technologies to secure cloud\nmanagement platforms from a networking perspective. We develop a\nblockchain-powered SDN-enabled networking infrastructure in which the\nintegration between blockchain-based security and autonomy management layer and\nmulti-controller SDN networking layer is defined to enhance the integrity of\nthe control and management messages. Furthermore, our proposed networking\ninfrastructure also enables the autonomous bandwidth provisioning to enhance\nthe availability of cloud architecture. In the simulation section, we evaluate\nthe performance of our proposed blockchain-powered SDN-enabled networking\ninfrastructure by considering different scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 14:50:18 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Fernando", "Praveen", ""], ["Wei", "Jin", ""]]}, {"id": "1909.01862", "submitter": "Ryan Shah", "authors": "Ryan Shah, Shishir Nagaraja", "title": "Privacy with Surgical Robotics: Challenges in Applying Contextual\n  Privacy Theory", "comments": "5 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The use of connected surgical robotics to automate medical procedures\npresents new privacy challenges. We argue that conventional patient consent\nprotocols no longer work. Indeed robots that replace human surgeons take on an\nextraordinary level of responsibility. Surgeons undergo years of training and\npeer review in a strongly regulated environment, and derive trust via a\npatient's faith in the hospital system. Robots on the other hand derive trust\ndifferently, via the integrity of the software that governs their operation.\nFrom a privacy perspective, there are two fundamental shifts. First, the threat\nmodel has shifted from one where the humans involved were untrusted to one\nwhere the robotic software is untrusted. Second, the basic unit of privacy\ncontrol is no longer a medical record, but is replaced by four new basic units:\nthe subject on which the robot is taking action; the tools used by the robot;\nthe sensors (i.e data) the robot can access; and, finally access to monitoring\nand calibration services which afford correct operation of the robot. We\nsuggest that contextual privacy provides useful theoretical tools to solve the\nprivacy problems posed by surgical robots. However, it also poses some\nchallenges: not least that the complexity of the contextual-privacy policies,\nif rigorously specified to achieve verification and enforceability, will be\nexceedingly high to directly expose to humans that review contextual privacy\npolicies. A medical robot works with both information and physical material.\nWhile informational norms allow for judgements about contextual integrity and\nthe transmission principle governs the constraints applied on information\ntransfer, nothing is said about material property. Certainly, contextual\nprivacy provides an anchor for useful notions of privacy in this scenario and\nthus should be considered to be extended to cover both information and material\nflows.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 15:09:24 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Shah", "Ryan", ""], ["Nagaraja", "Shishir", ""]]}, {"id": "1909.01904", "submitter": "Ryan Shah", "authors": "Shishir Nagaraja, Ryan Shah", "title": "VoIPLoc: Passive VoIP call provenance via acoustic side-channels", "comments": "12 pages, 8 figures, 5 tables", "journal-ref": null, "doi": "10.1145/3448300.3467816", "report-no": null, "categories": "cs.CR cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose VoIPLoc, a novel location fingerprinting technique and apply it to\nthe VoIP call provenance problem. It exploits echo-location information\nembedded within VoIP audio to support fine-grained location inference. We found\nconsistent statistical features induced by the echo-reflection characteristics\nof the location into recorded speech. These features are discernible within\ntraces received at the VoIP destination, enabling location inference. We\nevaluated VoIPLoc by developing a dataset of audio traces received through VoIP\nchannels over the Tor network. We show that recording locations can be\nfingerprinted and detected remotely with a low false-positive rate, even when a\nmajority of the audio samples are unlabelled. Finally, we note that the\ntechnique is fully passive and thus undetectable, unlike prior art. VoIPLoc is\nrobust to the impact of environmental noise and background sounds, as well as\nthe impact of compressive codecs and network jitter. The technique is also\nhighly scalable and offers several degrees of freedom terms of the\nfingerprintable space.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 15:55:46 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 10:14:28 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Nagaraja", "Shishir", ""], ["Shah", "Ryan", ""]]}, {"id": "1909.01910", "submitter": "Valerio Formicola Dr.", "authors": "Vincenzo Giuliano and Valerio Formicola", "title": "ICSrange: A Simulation-based Cyber Range Platform for Industrial Control\n  Systems", "comments": "Student Forum paper of the 15th European Dependable Computing\n  Conference (EDCC 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Maintenance staff of Industrial Control Systems (ICS) is generally not aware\nabout information technologies, and even less about cyber security problems.\nThe scary impact of cyber attacks in the industrial world calls for tools to\ntrain defensive skills and test effective security measures. Cyber range offers\nthis opportunity, but current research is lacking cost-effective solutions\nverticalized for the industrial domain. This work proposes ICSrange, a\nsimulation-based cyber range platform for Industrial Control Systems. ICSrange\nadopts Commercial-Off-The-Shelf (COTS) technologies to virtualize an enterprise\nnetwork connected to Industrial Control Systems. ICSrange is the outcome of a\npreliminary study intended to investigate challenges and opportunities to build\na configurable and extensible cyber range with simulated industrial processes.\nLiterature shows that testbeds based on realistic mock-ups are effectively\nemployed to develop complex exploits like Advanced Persistent Threats (APTs),\nhence motivating their usage to train and test security in ICS. We prove the\neffectiveness of ICSrange through the execution of a multi-staged attack that\nbreaches an enterprise network and progressively intrudes a simulated ICS with\nwater tanks. The attack mimics lateral movements as observed in APTs.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 16:03:08 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Giuliano", "Vincenzo", ""], ["Formicola", "Valerio", ""]]}, {"id": "1909.01917", "submitter": "Damien Desfontaines", "authors": "Royce J Wilson, Celia Yuxin Zhang, William Lam, Damien Desfontaines,\n  Daniel Simmons-Marengo, Bryant Gipson", "title": "Differentially Private SQL with Bounded User Contribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Differential privacy (DP) provides formal guarantees that the output of a\ndatabase query does not reveal too much information about any individual\npresent in the database. While many differentially private algorithms have been\nproposed in the scientific literature, there are only a few end-to-end\nimplementations of differentially private query engines. Crucially, existing\nsystems assume that each individual is associated with at most one database\nrecord, which is unrealistic in practice. We propose a generic and scalable\nmethod to perform differentially private aggregations on databases, even when\nindividuals can each be associated with arbitrarily many rows. We express this\nmethod as an operator in relational algebra, and implement it in an SQL engine.\nTo validate this system, we test the utility of typical queries on industry\nbenchmarks, and verify its correctness with a stochastic test framework we\ndeveloped. We highlight the promises and pitfalls learned when deploying such a\nsystem in practice, and we publish its core components as open-source software.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 16:14:29 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 09:05:32 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 23:08:41 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Wilson", "Royce J", ""], ["Zhang", "Celia Yuxin", ""], ["Lam", "William", ""], ["Desfontaines", "Damien", ""], ["Simmons-Marengo", "Daniel", ""], ["Gipson", "Bryant", ""]]}, {"id": "1909.02237", "submitter": "Victor Oswaldo Salazar Vilchez", "authors": "Jorge Buzzio Garc\\'ia, Victor Salazar Vilchez, Jeffrey Zavala Castro,\n  Jose L. Quiroz Arroyo", "title": "Using Cyber Threat Intelligence to Prevent Malicious Known Traffic in a\n  SDN Physical Testbed", "comments": "Accepted to IEEE XXVI International Conference on Electronics,\n  Electrical Engineering and Computing (INTERCON 2019). Lima, Peru", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the use of applications and communication tools has increased, one of\nthe concerns of the responsible for network security has been to protect\ninformation and information systems, as well as to provide trust to end users\nfor the use of information and communication technologies. Nowadays, attacks on\nthe network have increased and undergone modifications, which make the task for\ntraditional security devices difficult, being necessary to add the intelligence\nto face the new attacks generated in the network. Hence the need to incorporate\nCyber Threat Intelligence (CTI) as a new component in the network. This work\nfocuses on the use of information provided by a CTI to improve the security of\nSoftware Defined Networks (SDN), and at the same time, analyze how malicious\ntraffic could be blocked in a physical testbed.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 07:12:27 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Garc\u00eda", "Jorge Buzzio", ""], ["Vilchez", "Victor Salazar", ""], ["Castro", "Jeffrey Zavala", ""], ["Arroyo", "Jose L. Quiroz", ""]]}, {"id": "1909.02352", "submitter": "Peilun Wu", "authors": "Peilun Wu, Hui Guo and Richard Buckland", "title": "A Transfer Learning Approach for Network Intrusion Detection", "comments": null, "journal-ref": null, "doi": "10.1109/ICBDA.2019.8713213", "report-no": null, "categories": "cs.LG cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolution Neural Network (ConvNet) offers a high potential to generalize\ninput data. It has been widely used in many application areas, such as visual\nimagery, where comprehensive learning datasets are available and a ConvNet\nmodel can be well trained and perform the required function effectively.\nConvNet can also be applied to network intrusion detection. However, the\ncurrently available datasets related to the network intrusion are often\ninadequate, which makes the ConvNet learning deficient, hence the trained model\nis not competent in detecting unknown intrusions. In this paper, we propose a\nConvNet model using transfer learning for network intrusion detection. The\nmodel consists of two concatenated ConvNets and is built on a two-stage\nlearning process: learning a base dataset and transferring the learned\nknowledge to the learning of the target dataset. Our experiments on the NSL-KDD\ndataset show that the proposed model can improve the detection accuracy not\nonly on the test dataset containing mostly known attacks (KDDTest+) but also on\nthe test dataset featuring many novel attacks (KDDTest-21) -- about 2.68\\%\nimprovement on KDDTest+ and 22.02\\% on KDDTest-21 can be achieved, as compared\nto the traditional ConvNet model.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 12:11:07 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 16:02:08 GMT"}, {"version": "v3", "created": "Tue, 12 Nov 2019 07:40:59 GMT"}, {"version": "v4", "created": "Wed, 18 Dec 2019 19:14:40 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Wu", "Peilun", ""], ["Guo", "Hui", ""], ["Buckland", "Richard", ""]]}, {"id": "1909.02398", "submitter": "Ruoyu Deng", "authors": "Ruoyu Deng, Na Ruan", "title": "FraudJudger: Real-World Data Oriented Fraud Detection on Digital Payment\n  Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated fraud behaviors detection on electronic payment platforms is a\ntough problem. Fraud users often exploit the vulnerability of payment platforms\nand the carelessness of users to defraud money, steal passwords, do money\nlaundering, etc, which causes enormous losses to digital payment platforms and\nusers. There are many challenges for fraud detection in practice. Traditional\nfraud detection methods require a large-scale manually labeled dataset, which\nis hard to obtain in reality. Manually labeled data cost tremendous human\nefforts. Besides, the continuous and rapid evolution of fraud users makes it\nhard to find new fraud patterns based on existing detection rules. In our work,\nwe propose a real-world data oriented detection paradigm which can detect fraud\nusers and upgrade its detection ability automatically. Based on the new\nparadigm, we design a novel fraud detection model, FraudJudger, to analyze\nusers behaviors on digital payment platforms and detect fraud users with fewer\nlabeled data in training. FraudJudger can learn the latent representations of\nusers from unlabeled data with the help of Adversarial Autoencoder (AAE).\nFurthermore, FraudJudger can find new fraud patterns from unknown users by\ncluster analysis. Our experiment is based on a real-world electronic payment\ndataset. Comparing with other well-known fraud detection methods, FraudJudger\ncan achieve better detection performance with only 10% labeled data.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 13:31:52 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Deng", "Ruoyu", ""], ["Ruan", "Na", ""]]}, {"id": "1909.02441", "submitter": "Jukka Ruohonen", "authors": "Jukka Ruohonen and Kalle Rindell", "title": "Empirical Notes on the Interaction Between Continuous Kernel Fuzzing and\n  Development", "comments": "The 4th IEEE International Workshop on Reliability and Security Data\n  Analysis (RSDA), 2019 IEEE International Symposium on Software Reliability\n  Engineering Workshops (ISSREW), Berlin, IEEE", "journal-ref": null, "doi": "10.1109/ISSREW.2019.00084", "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzing has been studied and applied ever since the 1990s. Automated and\ncontinuous fuzzing has recently been applied also to open source software\nprojects, including the Linux and BSD kernels. This paper concentrates on the\npractical aspects of continuous kernel fuzzing in four open source kernels.\nAccording to the results, there are over 800 unresolved crashes reported for\nthe four kernels by the syzkaller/syzbot framework. Many of these have been\nreported relatively long ago. Interestingly, fuzzing-induced bugs have been\nresolved in the BSD kernels more rapidly. Furthermore, assertions and debug\nchecks, use-after-frees, and general protection faults account for the majority\nof bug types in the Linux kernel. About 23% of the fixed bugs in the Linux\nkernel have either went through code review or additional testing. Finally,\nonly code churn provides a weak statistical signal for explaining the\nassociated bug fixing times in the Linux kernel.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 14:23:23 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Ruohonen", "Jukka", ""], ["Rindell", "Kalle", ""]]}, {"id": "1909.02463", "submitter": "Qiong Li", "authors": "Qiong Li, Yaxing Wang, Haokun Mao, Jiameng Yao, Qi Han", "title": "Mathematical Model and Topology Evaluation of Quantum Secure\n  Communication Network", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": "10.1364/OE.387697", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the intrinsic point-to-point characteristic of quantum key\ndistribution (QKD) systems, it is necessary to study and develop QKD network\ntechnology to provide a secure communication service for a large-scale of nodes\nover a large area. Considering the quality assurance required for such a\nnetwork and the cost limitations, building an effective mathematical model of a\nQKD network becomes a critical task. In this paper, a flow-based mathematical\nmodel is proposed to describe a QKD network using mathematical concepts and\nlanguage. In addition, an investigation on QKD network topology evaluation was\nconducted using a unique and novel QKD network performance indicator, the\nInformation-Theoretic Secure communication bound, and the corresponding linear\nprogramming-based calculation algorithm. A large number of simulation results\nbased on the topologies of SECOQC network and NSFNET network validate the\neffectiveness of the proposed model and indicator.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 14:54:17 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 00:54:43 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Li", "Qiong", ""], ["Wang", "Yaxing", ""], ["Mao", "Haokun", ""], ["Yao", "Jiameng", ""], ["Han", "Qi", ""]]}, {"id": "1909.02481", "submitter": "Joseph Near", "authors": "Joseph P. Near, David Darais, Chike Abuah, Tim Stevens, Pranav\n  Gaddamadugu, Lun Wang, Neel Somani, Mu Zhang, Nikhil Sharma, Alex Shan, Dawn\n  Song", "title": "Duet: An Expressive Higher-order Language and Linear Type System for\n  Statically Enforcing Differential Privacy", "comments": "Extended version of OOPSLA 2019 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the past decade, differential privacy has become the gold standard for\nprotecting the privacy of individuals. However, verifying that a particular\nprogram provides differential privacy often remains a manual task to be\ncompleted by an expert in the field. Language-based techniques have been\nproposed for fully automating proofs of differential privacy via type system\ndesign, however these results have lagged behind advances in\ndifferentially-private algorithms, leaving a noticeable gap in programs which\ncan be automatically verified while also providing state-of-the-art bounds on\nprivacy.\n  We propose Duet, an expressive higher-order language, linear type system and\ntool for automatically verifying differential privacy of general-purpose\nhigher-order programs. In addition to general purpose programming, Duet\nsupports encoding machine learning algorithms such as stochastic gradient\ndescent, as well as common auxiliary data analysis tasks such as clipping,\nnormalization and hyperparameter tuning - each of which are particularly\nchallenging to encode in a statically verified differential privacy framework.\n  We present a core design of the Duet language and linear type system, and\ncomplete key proofs about privacy for well-typed programs. We then show how to\nextend Duet to support realistic machine learning applications and recent\nvariants of differential privacy which result in improved accuracy for many\npractical differentially private algorithms. Finally, we implement several\ndifferentially private machine learning algorithms in Duet which have never\nbefore been automatically verified by a language-based tool, and we present\nexperimental results which demonstrate the benefits of Duet's language design\nin terms of accuracy of trained machine learning models.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 15:35:07 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Near", "Joseph P.", ""], ["Darais", "David", ""], ["Abuah", "Chike", ""], ["Stevens", "Tim", ""], ["Gaddamadugu", "Pranav", ""], ["Wang", "Lun", ""], ["Somani", "Neel", ""], ["Zhang", "Mu", ""], ["Sharma", "Nikhil", ""], ["Shan", "Alex", ""], ["Song", "Dawn", ""]]}, {"id": "1909.02583", "submitter": "Xian Yeow Lee", "authors": "Xian Yeow Lee, Sambit Ghadai, Kai Liang Tan, Chinmay Hegde, Soumik\n  Sarkar", "title": "Spatiotemporally Constrained Action Space Attacks on Deep Reinforcement\n  Learning Agents", "comments": "Version 2 with supplementary materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustness of Deep Reinforcement Learning (DRL) algorithms towards\nadversarial attacks in real world applications such as those deployed in\ncyber-physical systems (CPS) are of increasing concern. Numerous studies have\ninvestigated the mechanisms of attacks on the RL agent's state space.\nNonetheless, attacks on the RL agent's action space (AS) (corresponding to\nactuators in engineering systems) are equally perverse; such attacks are\nrelatively less studied in the ML literature. In this work, we first frame the\nproblem as an optimization problem of minimizing the cumulative reward of an RL\nagent with decoupled constraints as the budget of attack. We propose a\nwhite-box Myopic Action Space (MAS) attack algorithm that distributes the\nattacks across the action space dimensions. Next, we reformulate the\noptimization problem above with the same objective function, but with a\ntemporally coupled constraint on the attack budget to take into account the\napproximated dynamics of the agent. This leads to the white-box Look-ahead\nAction Space (LAS) attack algorithm that distributes the attacks across the\naction and temporal dimensions. Our results shows that using the same amount of\nresources, the LAS attack deteriorates the agent's performance significantly\nmore than the MAS attack. This reveals the possibility that with limited\nresource, an adversary can utilize the agent's dynamics to malevolently craft\nattacks that causes the agent to fail. Additionally, we leverage these attack\nstrategies as a possible tool to gain insights on the potential vulnerabilities\nof DRL agents.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 18:04:04 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 03:36:57 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Lee", "Xian Yeow", ""], ["Ghadai", "Sambit", ""], ["Tan", "Kai Liang", ""], ["Hegde", "Chinmay", ""], ["Sarkar", "Soumik", ""]]}, {"id": "1909.02717", "submitter": "Weizhao Tang", "authors": "Weizhao Tang, Weina Wang, Giulia Fanti and Sewoong Oh", "title": "Privacy-Utility Tradeoffs in Routing Cryptocurrency over Payment Channel\n  Networks", "comments": "This revision corrects an error in Thm. 3.2, which previously\n  under-estimated the converse bound by a factor of 2/n", "journal-ref": "Proc. ACM Meas. Anal. Comput. Syst. 4, 2, Article 29 (June 2020),\n  39 pages", "doi": "10.1145/3392147", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Payment channel networks (PCNs) are viewed as one of the most promising\nscalability solutions for cryptocurrencies today. Roughly, PCNs are networks\nwhere each node represents a user and each directed, weighted edge represents\nfunds escrowed on a blockchain; these funds can be transacted only between the\nendpoints of the edge. Users efficiently transmit funds from node A to B by\nrelaying them over a path connecting A to B, as long as each edge in the path\ncontains enough balance (escrowed funds) to support the transaction. Whenever a\ntransaction succeeds, the edge weights are updated accordingly. However, in\ndeployed PCNs, channel balances (i.e., edge weights) are not revealed to users\nfor privacy reasons; users know only the initial weights at time 0. Hence, when\nrouting transactions, users first guess a path, then check if it supports the\ntransaction. This guess-and-check process dramatically reduces the success rate\nof transactions. At the other extreme, knowing full channel balances can give\nsubstantial improvements in success rate at the expense of privacy. In this\nwork, we study whether a network can reveal noisy channel balances to trade off\nprivacy for utility. We show fundamental limits on such a tradeoff, and propose\nnoise mechanisms that achieve the fundamental limit for a general class of\ngraph topologies. Our results suggest that in practice, PCNs should operate\neither in the low-privacy or low-utility regime; it is not possible to get\nlarge gains in utility by giving up a little privacy, or large gains in privacy\nby sacrificing a little utility.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 05:18:06 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 17:18:50 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 02:21:32 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Tang", "Weizhao", ""], ["Wang", "Weina", ""], ["Fanti", "Giulia", ""], ["Oh", "Sewoong", ""]]}, {"id": "1909.02742", "submitter": "Shaofeng Li", "authors": "Shaofeng Li, Minhui Xue, Benjamin Zi Hao Zhao, Haojin Zhu, Xinpeng\n  Zhang", "title": "Invisible Backdoor Attacks on Deep Neural Networks via Steganography and\n  Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have been proven vulnerable to backdoor attacks,\nwhere hidden features (patterns) trained to a normal model, which is only\nactivated by some specific input (called triggers), trick the model into\nproducing unexpected behavior. In this paper, we create covert and scattered\ntriggers for backdoor attacks, invisible backdoors, where triggers can fool\nboth DNN models and human inspection. We apply our invisible backdoors through\ntwo state-of-the-art methods of embedding triggers for backdoor attacks. The\nfirst approach on Badnets embeds the trigger into DNNs through steganography.\nThe second approach of a trojan attack uses two types of additional\nregularization terms to generate the triggers with irregular shape and size. We\nuse the Attack Success Rate and Functionality to measure the performance of our\nattacks. We introduce two novel definitions of invisibility for human\nperception; one is conceptualized by the Perceptual Adversarial Similarity\nScore (PASS) and the other is Learned Perceptual Image Patch Similarity\n(LPIPS). We show that the proposed invisible backdoors can be fairly effective\nacross various DNN models as well as four datasets MNIST, CIFAR-10, CIFAR-100,\nand GTSRB, by measuring their attack success rates for the adversary,\nfunctionality for the normal users, and invisibility scores for the\nadministrators. We finally argue that the proposed invisible backdoor attacks\ncan effectively thwart the state-of-the-art trojan backdoor detection\napproaches, such as Neural Cleanse and TABOR.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 07:11:26 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 03:17:24 GMT"}, {"version": "v3", "created": "Mon, 31 Aug 2020 04:14:46 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Li", "Shaofeng", ""], ["Xue", "Minhui", ""], ["Zhao", "Benjamin Zi Hao", ""], ["Zhu", "Haojin", ""], ["Zhang", "Xinpeng", ""]]}, {"id": "1909.02750", "submitter": "Wenqing Su", "authors": "Wenqing Su, Xiao Guo, Hai Zhang", "title": "Differentially Private Precision Matrix Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of precision matrix estimation when the\ndataset contains sensitive information. In the differential privacy framework,\nwe develop a differentially private ridge estimator by perturbing the sample\ncovariance matrix. Then we develop a differentially private graphical lasso\nestimator by using the alternating direction method of multipliers (ADMM)\nalgorithm. The theoretical results and empirical results that show the utility\nof the proposed methods are also provided.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 07:46:12 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Su", "Wenqing", ""], ["Guo", "Xiao", ""], ["Zhang", "Hai", ""]]}, {"id": "1909.02786", "submitter": "Daegeon Kim", "authors": "Daegeon Kim and Huy Kang Kim", "title": "Security Requirements of Commercial Drones for Public Authorities by\n  Vulnerability Analysis of Applications", "comments": "12 pages, 12 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the ability to overcome the geospatial limitations and to the\npossibility to converge the various information communication technologies, the\napplication domains and the market size of drones are increasing\ninternationally. Public authorities in South Korean are investing for the\ndomestic drone industry and the technological advancement as a power of\ninnovation and growth of the country. They are also increasing the utilization\nof drones for various purposes.\n  The South Korean government ensures the security of IT equipment introduced\nto the public authorities by enforcing policies such as security compatibility\nverification and CCTV security certification. Considering the increase of the\nneeds of drones and the possible security effects to the organization operating\nthem, the government needs to develop the security requirements during\nintroducing drones, but there are no such requirements yet.\n  In this paper, we inspect the vulnerabilities of drones by analyzing the\napplications of commercial drones made by 4 manufacturers. We also propose the\nminimum security requirements to resolve the vulnerabilities. We expect our\nwork contributes to the security improvements of drones operated in public\nauthorities.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 09:20:40 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Kim", "Daegeon", ""], ["Kim", "Huy Kang", ""]]}, {"id": "1909.02788", "submitter": "Chia-Wei Tsai", "authors": "Chia-Wei Tsai and Chun-Wei Yang", "title": "Lightweight Mediated Semi-Quantum Key Distribution Protocol with a\n  Dishonest Third Party based on Bell States", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mediated semi-quantum key distribution (MSQKD) protocol is an important\nresearch issue that lets two classical participants share secret keys securely\nbetween each other with the help of a third party (TP). However, in the\nexisting MSQKD protocols, there are two improvable issues, namely (1) the\nclassical participants must be equipped with expensive detectors to avoid\nTrojan horse attacks and (2) the trustworthiness level of TP must be honest. To\nthe best of our knowledge, none of the existing MSQKD protocols can resolve\nboth these issues. Therefore, this study takes Bell states as the quantum\nresource to propose a new MSQKD protocol, in which the classical participants\ndo not need a Trojan horse detector and the TP is dishonest. Furthermore, the\nproposed protocol is shown to be secure against well-known attacks and the\nclassical participants only need two quantum capabilities. Therefore, in\ncomparison to the existing MSQKD protocols, the proposed protocol is better\npractical.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 09:21:53 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 23:52:00 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Tsai", "Chia-Wei", ""], ["Yang", "Chun-Wei", ""]]}, {"id": "1909.02815", "submitter": "Emil Pricop", "authors": "Snehal Sathwara, Nitul Dutta, Emil Pricop", "title": "IoT Forensic -- A digital investigation framework for IoT systems", "comments": "Paper presented at 10th International Conference on Electronics,\n  Computers and Artificial Intelligence, , ECAI 2018 - 28-30 June 2018 - Iasi,\n  Romania", "journal-ref": "018 10th International Conference on Electronics, Computers and\n  Artificial Intelligence (ECAI), Iasi, Romania, 2018, pp. 1-4", "doi": "10.1109/ECAI.2018.8679017", "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security issues, threats, and attacks in relation with the IoT have been\nidentified as promising and challenging area of research. Eventually, the need\nfor a forensics methodology for investigating IoT-related crime is therefore\nessential. However, the IoT poses many challenges for forensics investigators.\nThese include the wide range and variety of information, the unclear lines of\ndifferentiation between networks, for example private networks increasingly\nfading into public networks. Further, integration of a large number of objects\nin IoT forensic interest, along with the relevance of identified and collected\ndevices makes forensic of IoT devices more complicated. The scope of this paper\nis to present a framework for IoT forensic. We aimed at the study and\ndevelopment of the link to support digital investigations of IoT devices and\ntackle emerging challenges in digital forensics. We emphasize on various steps\nfor digital forensic with respect to IoT devices.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 11:00:01 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Sathwara", "Snehal", ""], ["Dutta", "Nitul", ""], ["Pricop", "Emil", ""]]}, {"id": "1909.02893", "submitter": "Fabrizio Romano Genovese", "authors": "Fabrizio Genovese, Andre Knispel, Joshua Fitzgerald", "title": "Mapping finite state machines to zk-SNARKS Using Category Theory", "comments": "18 pages total, 10 pages body, 2 pages addendum, 5 pages appendix, 36\n  figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.FL math.CT", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We provide a categorical procedure to turn graphs corresponding to state\nspaces of finite state machines into boolean circuits, leveraging on the fact\nthat boolean circuits can be easily turned into zk-SNARKS. Our circuits verify\nthat a given sequence of edges and nodes is indeed a path in the graph they\nrepresent. We then generalize to circuits verifying paths in arbitrary graphs.\nWe prove that all of our correspondences are pseudofunctorial, and behave\nnicely with respect to each other.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 13:27:23 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 11:51:13 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Genovese", "Fabrizio", ""], ["Knispel", "Andre", ""], ["Fitzgerald", "Joshua", ""]]}, {"id": "1909.02895", "submitter": "Zolt\\'an Andr\\'as Lux", "authors": "Zolt\\'an Andr\\'as Lux, Felix Beierle, Sebastian Zickau, Sebastian\n  G\\\"ond\\\"or", "title": "Full-text Search for Verifiable Credential Metadata on Distributed\n  Ledgers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-sovereign Identity (SSI) powered by distributed ledger technologies\nenables more flexible and faster digital identification workflows, while at the\nsame time limiting the control and influence of central authorities. However, a\nglobal identity solution must be able to handle myriad credential types from\nmillions of issuing organizations. As metadata about types of digital\ncredentials is readable by everyone on the public permissioned ledger with\nHyperledger Indy, anyone could find relevant and trusted credential types for\ntheir use cases by looking at the records on the blockchain. To this date, no\nefficient full-text search mechanism exists that would allow users to search\nfor credential types in a simple and efficient fashion tightly integrated into\ntheir applications. In this work, we propose a full-text search framework based\non the publicly available metadata on the Hyperledger Indy ledger for\nretrieving matching credential types. The proposed solution is able to find\ncredential types based on textual input from the user by using a full-text\nsearch engine and maintaining a local copy of the ledger. Thus, we do not need\nto rely on information about credentials coming from a very large candidate\npool of third parties we would need to trust, such as the website of a company\ndisplaying its own identifier and a list of issued credentials. We have also\nproven the feasiblity of the concept by implementing and evaluating a prototype\nof the full-text credential metadata search service.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 13:31:13 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Lux", "Zolt\u00e1n Andr\u00e1s", ""], ["Beierle", "Felix", ""], ["Zickau", "Sebastian", ""], ["G\u00f6nd\u00f6r", "Sebastian", ""]]}, {"id": "1909.02914", "submitter": "Naveed  Ul Hassan", "authors": "Naveed UL Hassan, Chau Yuen, and Dusit Niyato", "title": "Blockchain Technologies for Smart Energy Systems: Fundamentals,\n  Challenges and Solutions", "comments": "Submitted to IEEE Industrial Electronics Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss the integration of blockchain in smart energy\nsystems. We present various blockchain technology solutions, review important\nblockchain platforms, and several blockchain based smart energy projects in\ndifferent smart energy domains. The majority of blockchain platforms with\nembedded combination of blockchain technology solutions are computing- and\nresource- intensive, and hence not entirely suitable for smart energy\napplications. We consider the requirements of smart energy systems and\naccordingly identify appropriate blockchain technology solutions for smart\nenergy applications. Our analysis can help in the development of flexible\nblockchain platforms for smart energy systems.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 13:55:14 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Hassan", "Naveed UL", ""], ["Yuen", "Chau", ""], ["Niyato", "Dusit", ""]]}, {"id": "1909.02918", "submitter": "Ilia Shumailov", "authors": "Yiren Zhao, Ilia Shumailov, Han Cui, Xitong Gao, Robert Mullins, Ross\n  Anderson", "title": "Blackbox Attacks on Reinforcement Learning Agents Using Approximated\n  Temporal Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Recent research on reinforcement learning (RL) has suggested that trained\nagents are vulnerable to maliciously crafted adversarial samples. In this work,\nwe show how such samples can be generalised from White-box and Grey-box attacks\nto a strong Black-box case, where the attacker has no knowledge of the agents,\ntheir training parameters and their training methods. We use\nsequence-to-sequence models to predict a single action or a sequence of future\nactions that a trained agent will make. First, we show our approximation model,\nbased on time-series information from the agent, consistently predicts RL\nagents' future actions with high accuracy in a Black-box setup on a wide range\nof games and RL algorithms. Second, we find that although adversarial samples\nare transferable from the target model to our RL agents, they often outperform\nrandom Gaussian noise only marginally. This highlights a serious methodological\ndeficiency in previous work on such agents; random jamming should have been\ntaken as the baseline for evaluation. Third, we propose a novel use for\nadversarial samplesin Black-box attacks of RL agents: they can be used to\ntrigger a trained agent to misbehave after a specific time delay. This appears\nto be a genuinely new type of attack. It potentially enables an attacker to use\ndevices controlled by RL agents as time bombs.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 14:06:21 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 19:07:45 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Zhao", "Yiren", ""], ["Shumailov", "Ilia", ""], ["Cui", "Han", ""], ["Gao", "Xitong", ""], ["Mullins", "Robert", ""], ["Anderson", "Ross", ""]]}, {"id": "1909.02923", "submitter": "Georgios Bakirtzis", "authors": "Georgios Bakirtzis, Brandon J. Simon, Aidan G. Collins, Cody H.\n  Fleming, Carl R. Elks", "title": "Data Driven Vulnerability Exploration for Design Phase System Analysis", "comments": null, "journal-ref": null, "doi": "10.1109/JSYST.2019.2940145", "report-no": null, "categories": "eess.SY cs.CR cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying security as a lifecycle practice is becoming increasingly important\nto combat targeted attacks in safety-critical systems. Among others there are\ntwo significant challenges in this area: (1) the need for models that can\ncharacterize a realistic system in the absence of an implementation and (2) an\nautomated way to associate attack vector information; that is, historical data,\nto such system models. We propose the cybersecurity body of knowledge (CYBOK),\nwhich takes in sufficiently characteristic models of systems and acts as a\nsearch engine for potential attack vectors. CYBOK is fundamentally an\nalgorithmic approach to vulnerability exploration, which is a significant\nextension to the body of knowledge it builds upon. By using CYBOK, security\nanalysts and system designers can work together to assess the overall security\nposture of systems early in their lifecycle, during major design decisions and\nbefore final product designs. Consequently, assisting in applying security\nearlier and throughout the systems lifecycle.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 14:14:49 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Bakirtzis", "Georgios", ""], ["Simon", "Brandon J.", ""], ["Collins", "Aidan G.", ""], ["Fleming", "Cody H.", ""], ["Elks", "Carl R.", ""]]}, {"id": "1909.02961", "submitter": "Ehab ElSalamouny", "authors": "Ehab ElSalamouny and Catuscia Palamidessi", "title": "Full Convergence of the Iterative Bayesian Update and Applications to\n  Mechanisms for Privacy Protection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The iterative Bayesian update (IBU) and the matrix inversion (INV) are the\nmain methods to retrieve the original distribution from noisy data resulting\nfrom the application of privacy protection mechanisms. We show that the\ntheoretical foundations of the IBU established in the literature are flawed, as\nthey rely on an assumption that in general is not satisfied in typical real\ndatasets. We then fix the theory of the IBU, by providing a general convergence\nresult for the underlying Expectation-Maximization method. Our framework does\nnot rely on the above assumption, and also covers a more general local privacy\nmodel. Finally we evaluate the precision of the IBU on data sanitized with the\nGeometric, $k$-RR, and RAPPOR mechanisms, and we show that it outperforms INV\nin the first case, while it is comparable to INV in the other two cases.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 15:08:33 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["ElSalamouny", "Ehab", ""], ["Palamidessi", "Catuscia", ""]]}, {"id": "1909.03325", "submitter": "James Davenport", "authors": "James H. Davenport", "title": "Formal Methods and CyberSecurity", "comments": "To appear in \"Short Papers FROM 2019\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Formal methods have been largely thought of in the context of safety-critical\nsystems, where they have achieved major acceptance. Tens of millions of people\ntrust their lives every day to such systems, based on formal proofs rather than\n``we haven't found a bug'' (yet!). Why is ``we haven't found a bug'' an\nacceptable basis for systems trusted with hundreds of millions of people's\npersonal data?\n  This paper looks at some of the issues in CyberSecurity, and the extent to\nwhich formal methods, ranging from ``fully verified'' to better tool support,\ncould help. Alas The Royal Society (2016) only recommended formal methods in\nthe limited context of ``safety critical applications'': we suggest this is too\nlimited.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 19:49:19 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Davenport", "James H.", ""]]}, {"id": "1909.03334", "submitter": "Uyeong Jang", "authors": "Uyeong Jang, Susmit Jha, Somesh Jha", "title": "On the Need for Topology-Aware Generative Models for Manifold-Based\n  Defenses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-learning (ML) algorithms or models, especially deep neural networks\n(DNNs), have shown significant promise in several areas. However, researchers\nhave recently demonstrated that ML algorithms, especially DNNs, are vulnerable\nto adversarial examples (slightly perturbed samples that cause\nmisclassification). The existence of adversarial examples has hindered the\ndeployment of ML algorithms in safety-critical sectors, such as security.\nSeveral defenses for adversarial examples exist in the literature. One of the\nimportant classes of defenses are manifold-based defenses, where a sample is\n``pulled back\" into the data manifold before classifying. These defenses rely\non the assumption that data lie in a manifold of a lower dimension than the\ninput space. These defenses use a generative model to approximate the input\ndistribution. In this paper, we investigate the following question: do the\ngenerative models used in manifold-based defenses need to be topology-aware? We\nsuggest the answer is yes, and we provide theoretical and empirical evidence to\nsupport our claim.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 20:36:17 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 16:53:23 GMT"}, {"version": "v3", "created": "Tue, 8 Oct 2019 22:52:08 GMT"}, {"version": "v4", "created": "Mon, 17 Feb 2020 21:20:01 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Jang", "Uyeong", ""], ["Jha", "Susmit", ""], ["Jha", "Somesh", ""]]}, {"id": "1909.03367", "submitter": "Yue Zhang", "authors": "Yue Zhang, Jian Weng, Jiasi Weng, Ming Li, Weiqi Luo", "title": "Onionchain: Towards Balancing Privacy and Traceability of\n  Blockchain-Based Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the popularity of Blockchain comes grave security-related concerns.\nAchieving privacy and traceability simultaneously remains an open question.\nEfforts have been made to address the issues, while they may subject to\nspecific scenarios. This paper studies how to provide a more general solution\nfor this open question. Concretely, we propose Onionchain, featuring a suite of\nprotocols, offering both traceability and privacy. As the term implies, our\nOnionchain is inspired by Onion routing. We investigate the principles of Onion\nrouting carefully and integrate its mechanism together with Blockchain\ntechnology. We advocate the Blockchain community to adopt Onionchain with the\nregards of privacy and traceability. To this end, a case-study of Onionchain,\nwhich runs in the context of Vehicular Ad Hoc Networks (VANETs), is proposed,\nproviding the community a guideline to follow. Systematic security analysis and\nextensive experiments are also conducted to validate our secure and\ncost-effective Onionchain.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 01:59:05 GMT"}, {"version": "v2", "created": "Tue, 31 Dec 2019 15:26:15 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Zhang", "Yue", ""], ["Weng", "Jian", ""], ["Weng", "Jiasi", ""], ["Li", "Ming", ""], ["Luo", "Weiqi", ""]]}, {"id": "1909.03418", "submitter": "Asaf Shabtai", "authors": "Gil Fidel, Ron Bitton, Asaf Shabtai", "title": "When Explainability Meets Adversarial Learning: Detecting Adversarial\n  Examples using SHAP Signatures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art deep neural networks (DNNs) are highly effective in solving\nmany complex real-world problems. However, these models are vulnerable to\nadversarial perturbation attacks, and despite the plethora of research in this\ndomain, to this day, adversaries still have the upper hand in the cat and mouse\ngame of adversarial example generation methods vs. detection and prevention\nmethods. In this research, we present a novel detection method that uses\nShapley Additive Explanations (SHAP) values computed for the internal layers of\na DNN classifier to discriminate between normal and adversarial inputs. We\nevaluate our method by building an extensive dataset of adversarial examples\nover the popular CIFAR-10 and MNIST datasets, and training a neural\nnetwork-based detector to distinguish between normal and adversarial inputs. We\nevaluate our detector against adversarial examples generated by diverse\nstate-of-the-art attacks and demonstrate its high detection accuracy and strong\ngeneralization ability to adversarial inputs generated with different attack\nmethods.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 10:00:44 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Fidel", "Gil", ""], ["Bitton", "Ron", ""], ["Shabtai", "Asaf", ""]]}, {"id": "1909.03461", "submitter": "Gabriel Ryan", "authors": "Gabriel Ryan, Abhishek Shah, Dongdong She, Koustubha Bhat, Suman Jana", "title": "Fine Grained Dataflow Tracking with Proximal Gradients", "comments": "To appear in USENIX Security 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dataflow tracking with Dynamic Taint Analysis (DTA) is an important method in\nsystems security with many applications, including exploit analysis, guided\nfuzzing, and side-channel information leak detection. However, DTA is\nfundamentally limited by the Boolean nature of taint labels, which provide no\ninformation about the significance of detected dataflows and lead to false\npositives/negatives on complex real world programs.\n  We introduce proximal gradient analysis (PGA), a novel, theoretically\ngrounded approach that can track more accurate and fine-grained dataflow\ninformation. PGA uses proximal gradients, a generalization of gradients for\nnon-differentiable functions, to precisely compose gradients over\nnon-differentiable operations in programs. Composing gradients over programs\neliminates many of the dataflow propagation errors that occur in DTA and\nprovides richer information about how each measured dataflow effects a program.\n  We compare our prototype PGA implementation to three state of the art DTA\nimplementations on 7 real-world programs. Our results show that PGA can improve\nthe F1 accuracy of data flow tracking by up to 33% over taint tracking (20% on\naverage) without introducing any significant overhead (<5% on average). We\nfurther demonstrate the effectiveness of PGA by discovering 22 bugs (20\nconfirmed by developers) and 2 side-channel leaks, and identifying exploitable\ndataflows in 19 existing CVEs in the tested programs.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 13:25:17 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 12:33:27 GMT"}, {"version": "v3", "created": "Thu, 17 Oct 2019 18:00:41 GMT"}, {"version": "v4", "created": "Fri, 19 Feb 2021 16:32:53 GMT"}, {"version": "v5", "created": "Mon, 22 Feb 2021 15:46:09 GMT"}, {"version": "v6", "created": "Wed, 24 Feb 2021 17:04:45 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Ryan", "Gabriel", ""], ["Shah", "Abhishek", ""], ["She", "Dongdong", ""], ["Bhat", "Koustubha", ""], ["Jana", "Suman", ""]]}, {"id": "1909.03496", "submitter": "Yaqin Zhou", "authors": "Yaqin Zhou, Shangqing Liu, Jingkai Siow, Xiaoning Du, Yang Liu", "title": "Devign: Effective Vulnerability Identification by Learning Comprehensive\n  Program Semantics via Graph Neural Networks", "comments": "accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vulnerability identification is crucial to protect the software systems from\nattacks for cyber security. It is especially important to localize the\nvulnerable functions among the source code to facilitate the fix. However, it\nis a challenging and tedious process, and also requires specialized security\nexpertise. Inspired by the work on manually-defined patterns of vulnerabilities\nfrom various code representation graphs and the recent advance on graph neural\nnetworks, we propose Devign, a general graph neural network based model for\ngraph-level classification through learning on a rich set of code semantic\nrepresentations. It includes a novel Conv module to efficiently extract useful\nfeatures in the learned rich node representations for graph-level\nclassification. The model is trained over manually labeled datasets built on 4\ndiversified large-scale open-source C projects that incorporate high complexity\nand variety of real source code instead of synthesis code used in previous\nworks. The results of the extensive evaluation on the datasets demonstrate that\nDevign outperforms the state of the arts significantly with an average of\n10.51% higher accuracy and 8.68\\% F1 score, increases averagely 4.66% accuracy\nand 6.37% F1 by the Conv module.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 16:14:31 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Zhou", "Yaqin", ""], ["Liu", "Shangqing", ""], ["Siow", "Jingkai", ""], ["Du", "Xiaoning", ""], ["Liu", "Yang", ""]]}, {"id": "1909.03576", "submitter": "Amirali Sanatinia", "authors": "Amirali Sanatinia, Jeman Park, Erik-Oliver Blass, Aziz Mohaisen,\n  Guevara Noubir", "title": "A Privacy-Preserving Longevity Study of Tor's Hidden Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tor and hidden services have emerged as a practical solution to protect user\nprivacy against tracking and censorship. At the same time, little is known\nabout the lifetime and nature of hidden services. Data collection and study of\nTor hidden services is challenging due to its nature of providing privacy.\nStudying the lifetime of hidden services provides several benefits. For\nexample, it allows investigation of the maliciousness of domains based on their\nlifetime. Short-lived hidden services are more likely not to be legitimate\ndomains, e.g., used by ransomware, as compared to long-lived domains. In this\nwork, we investigate the lifetime of hidden services by collecting data from a\nsmall (2%) subset of all Tor HSDir relays in a privacy-preserving manner. Based\non the data collected, we devise protocols and extrapolation techniques to\ninfer the lifetime of hidden services. Moreover we show that, due to Tor's\nspecifics, our small subset of HSDir relays is sufficient to extrapolate\nlifetime with high accuracy, while respecting Tor user and service privacy and\nfollowing Tor's research safety guidelines. Our results indicate that a large\nmajority of the hidden services have a very short lifetime. In particular, 50%\nof all current Tor hidden services have an estimate lifetime of only 10 days or\nless, and 80% have a lifetime of less than a month.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 00:43:41 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Sanatinia", "Amirali", ""], ["Park", "Jeman", ""], ["Blass", "Erik-Oliver", ""], ["Mohaisen", "Aziz", ""], ["Noubir", "Guevara", ""]]}, {"id": "1909.03577", "submitter": "Christopher Jung", "authors": "Christopher Jung, Katrina Ligett, Seth Neel, Aaron Roth, Saeed\n  Sharifi-Malvajerdi, Moshe Shenfeld", "title": "A New Analysis of Differential Privacy's Generalization Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new proof of the \"transfer theorem\" underlying adaptive data\nanalysis: that any mechanism for answering adaptively chosen statistical\nqueries that is differentially private and sample-accurate is also accurate\nout-of-sample. Our new proof is elementary and gives structural insights that\nwe expect will be useful elsewhere. We show: 1) that differential privacy\nensures that the expectation of any query on the posterior distribution on\ndatasets induced by the transcript of the interaction is close to its true\nvalue on the data distribution, and 2) sample accuracy on its own ensures that\nany query answer produced by the mechanism is close to its posterior\nexpectation with high probability. This second claim follows from a thought\nexperiment in which we imagine that the dataset is resampled from the posterior\ndistribution after the mechanism has committed to its answers. The transfer\ntheorem then follows by summing these two bounds, and in particular, avoids the\n\"monitor argument\" used to derive high probability bounds in prior work. An\nupshot of our new proof technique is that the concrete bounds we obtain are\nsubstantially better than the best previously known bounds, even though the\nimprovements are in the constants, rather than the asymptotics (which are known\nto be tight). As we show, our new bounds outperform the naive\n\"sample-splitting\" baseline at dramatically smaller dataset sizes compared to\nthe previous state of the art, bringing techniques from this literature closer\nto practicality.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 00:49:03 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Jung", "Christopher", ""], ["Ligett", "Katrina", ""], ["Neel", "Seth", ""], ["Roth", "Aaron", ""], ["Sharifi-Malvajerdi", "Saeed", ""], ["Shenfeld", "Moshe", ""]]}, {"id": "1909.03628", "submitter": "Pantelimon Stanica", "authors": "Pal Ellingsen, Patrick Felke, Constanza Riera, Pantelimon Stanica,\n  Anton Tkachenko", "title": "$C$-differentials, multiplicative uniformity and (almost) perfect\n  $c$-nonlinearity", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we define a new (output) multiplicative differential, and the\ncorresponding $c$-differential uniformity. With this new concept, even for\ncharacteristic $2$, there are perfect $c$-nonlinear (PcN) functions. We first\ncharacterize the $c$-differential uniformity of a function in terms of its\nWalsh transform. We further look at some of the known perfect nonlinear (PN)\nand show that only one remains a PcN function, under a different condition on\nthe parameters. In fact, the $p$-ary Gold PN function increases its\n$c$-differential uniformity significantly, under some conditions on the\nparameters. We then precisely characterize the $c$-differential uniformity of\nthe inverse function (in any dimension and characteristic), relevant for the\nRijndael (and Advanced Encryption Standard) block cipher.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 04:08:13 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Ellingsen", "Pal", ""], ["Felke", "Patrick", ""], ["Riera", "Constanza", ""], ["Stanica", "Pantelimon", ""], ["Tkachenko", "Anton", ""]]}, {"id": "1909.03730", "submitter": "Simon Duque Anton", "authors": "Simon D. Duque Anton, Anna Pia Lohfink, Christoph Garth, and Hans\n  Dieter Schotten", "title": "Security in Process: Detecting Attacks in Industrial Process Data", "comments": null, "journal-ref": null, "doi": "10.1145/3360664.3360669", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the fourth industrial revolution, industrial applications make use of\nthe progress in communication and embedded devices. This allows industrial\nusers to increase efficiency and manageability while reducing cost and effort.\nFurthermore, the fourth industrial revolution, creating the so-called Industry\n4.0, opens a variety of novel use and business cases in the industrial\nenvironment. However, this progress comes at the cost of an enlarged attack\nsurface of industrial companies. Operational networks that have previously been\nphyiscally separated from public networks are now connected in order to make\nuse of new communication capabilites. This motivates the need for industrial\nintrusion detection solutions that are compatible to the long-term operation\nmachines in industry as well as the heterogeneous and fast-changing networks.\nIn this work, process data is analysed. The data is created and monitored on\nreal-world hardware. After a set up phase, attacks are introduced into the\nsystems that influence the process behaviour. A time series-based anomaly\ndetection approach, the Matrix Profiles, are adapted to the specific needs and\napplied to the intrusion detection. The results indicate an applicability of\nthese methods to detect attacks in the process behaviour. Furthermore, they are\neasily integrated into existing process environments. Additionally, one-class\nclassifiers One-Class Support Vector Machines and Isolation Forest are applied\nto the data without a notion of timing. While Matrix Profiles perform well in\nterms of creating and visualising results, the one-class classifiers perform\npoorly.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 09:53:06 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Anton", "Simon D. Duque", ""], ["Lohfink", "Anna Pia", ""], ["Garth", "Christoph", ""], ["Schotten", "Hans Dieter", ""]]}, {"id": "1909.03753", "submitter": "Simon Duque Anton", "authors": "Simon D. Duque Anton, Anna Pia Lohfink, and Hans Dieter Schotten", "title": "Discussing the Feasibility of Acoustic Sensors for Side Channel-aided\n  Industrial Intrusion Detection: An Essay", "comments": null, "journal-ref": null, "doi": "10.1145/3360664.3360667", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fourth industrial revolution leads to an increased use of embedded\ncomputation and intercommunication in an industrial environment. While reducing\ncost and effort for set up, operation and maintenance, and increasing the time\nto operation or market respectively as well as the efficiency, this also\nincreases the attack surface of enterprises. Industrial enterprises have become\ntargets of cyber criminals in the last decade, reasons being espionage but also\npolitically motivated. Infamous attack campaigns as well as easily available\nmalware that hits industry in an unprepared state create a large threat\nlandscape. As industrial systems often operate for many decades and are\ndifficult or impossible to upgrade in terms of security, legacy-compatible\nindustrial security solutions are necessary in order to create a security\nparameter. One plausible approach in industry is the implementation and\nemployment of side-channel sensors. Combining readily available sensor data\nfrom different sources via different channels can provide an enhanced insight\nabout the security state. In this work, a data set of an experimental\nindustrial set up containing side channel sensors is discussed conceptually and\ninsights are derived.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 10:48:56 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Anton", "Simon D. Duque", ""], ["Lohfink", "Anna Pia", ""], ["Schotten", "Hans Dieter", ""]]}, {"id": "1909.03758", "submitter": "Marie-Therese Walter", "authors": "Marie-Therese Walter and David Pfaff and Stefan N\\\"urnberger and\n  Michael Backes", "title": "Proconda -- Protected Control Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory corruption vulnerabilities often enable attackers to take control of a\ntarget system by overwriting control-flow relevant data (such as return\naddresses and function pointers), which are potentially stored in close\nproximity of related, typically user-controlled data on the stack. In this\npaper, we propose ProConDa, a general approach for protecting control-flow\nrelevant data on the stack ProConDa leverages hardware features to enforce a\nstrict separation between control-flow relevant and regular data of programs\nwritten in non-memory-safe languages such as C. Contrary to related approaches,\nProConDa does not rely on information hiding and is therefore not susceptible\nto several recent attacks specifically targeting information hiding as a\nfoundation for memory isolation. We show that ProConDa enforcement is\ncompatible with existing software by applying a software-based prototype to\nindustry benchmarks on an ARM CPU running Linux.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 11:04:33 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Walter", "Marie-Therese", ""], ["Pfaff", "David", ""], ["N\u00fcrnberger", "Stefan", ""], ["Backes", "Michael", ""]]}, {"id": "1909.03837", "submitter": "Ji Wang", "authors": "Ji Wang, Qi Jing, Jianbo Gao", "title": "SEdroid: A Robust Android Malware Detector using Selective Ensemble\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the dramatic increase of Android malware and low efficiency of manual\ncheck process, deep learning methods started to be an auxiliary means for\nAndroid malware detection these years. However, these models are highly\ndependent on the quality of datasets, and perform unsatisfactory results when\nthe quality of training data is not good enough. In the real world, the quality\nof datasets without manually check cannot be guaranteed, even Google Play may\ncontain malicious applications, which will cause the trained model failure. To\naddress the challenge, we propose a robust Android malware detection approach\nbased on selective ensemble learning, trying to provide an effective solution\nnot that limited to the quality of datasets. The proposed model utilizes\ngenetic algorithm to help find the best combination of the component learners\nand improve robustness of the model. Our results show that the proposed\napproach achieves a more robust performance than other approaches in the same\narea.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 08:59:35 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Wang", "Ji", ""], ["Jing", "Qi", ""], ["Gao", "Jianbo", ""]]}, {"id": "1909.03848", "submitter": "Zvezdin Besarabov", "authors": "Zvezdin Besarabov and Todor Kolev", "title": "Distributed creation of Machine learning agents for Blockchain analysis", "comments": "arXiv admin note: text overlap with arXiv:1810.06696", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating efficient deep neural networks involves repetitive manual\noptimization of the topology and the hyperparameters. This human intervention\nsignificantly inhibits the process. Recent publications propose various Neural\nArchitecture Search (NAS) algorithms that automate this work. We have applied a\ncustomized NAS algorithm with network morphism and Bayesian optimization to the\nproblem of cryptocurrency predictions, where it achieved results on par with\nour best manually designed models. This is consistent with the findings of\nother teams, while several known experiments suggest that given enough\ncomputing power, NAS algorithms can surpass state-of-the-art neural network\nmodels designed by humans. In this paper, we propose a blockchain network\nprotocol that incentivises independent computing nodes to run NAS algorithms\nand compete in finding better neural network models for a particular task. If\nimplemented, such network can be an autonomous and self-improving source of\nmachine learning models, significantly boosting and democratizing the access to\nAI capabilities for many industries.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 16:52:03 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Besarabov", "Zvezdin", ""], ["Kolev", "Todor", ""]]}, {"id": "1909.03935", "submitter": "Dingfan Chen", "authors": "Dingfan Chen, Ning Yu, Yang Zhang, Mario Fritz", "title": "GAN-Leaks: A Taxonomy of Membership Inference Attacks against Generative\n  Models", "comments": "CCS 2020, 20 pages", "journal-ref": "Proceedings of the 2020 ACM SIGSAC Conference on Computer and\n  Communications Security (CCS)", "doi": "10.1145/3372297.3417238", "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has achieved overwhelming success, spanning from discriminative\nmodels to generative models. In particular, deep generative models have\nfacilitated a new level of performance in a myriad of areas, ranging from media\nmanipulation to sanitized dataset generation. Despite the great success, the\npotential risks of privacy breach caused by generative models have not been\nanalyzed systematically. In this paper, we focus on membership inference attack\nagainst deep generative models that reveals information about the training data\nused for victim models. Specifically, we present the first taxonomy of\nmembership inference attacks, encompassing not only existing attacks but also\nour novel ones. In addition, we propose the first generic attack model that can\nbe instantiated in a large range of settings and is applicable to various kinds\nof deep generative models. Moreover, we provide a theoretically grounded attack\ncalibration technique, which consistently boosts the attack performance in all\ncases, across different attack settings, data modalities, and training\nconfigurations. We complement the systematic analysis of attack performance by\na comprehensive experimental study, that investigates the effectiveness of\nvarious attacks w.r.t. model type and training configurations, over three\ndiverse application scenarios (i.e., images, medical data, and location data).\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 15:34:07 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 19:31:24 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2020 18:11:05 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Chen", "Dingfan", ""], ["Yu", "Ning", ""], ["Zhang", "Yang", ""], ["Fritz", "Mario", ""]]}, {"id": "1909.03951", "submitter": "Vikrant Singhal", "authors": "Gautam Kamath, Or Sheffet, Vikrant Singhal, Jonathan Ullman", "title": "Differentially Private Algorithms for Learning Mixtures of Separated\n  Gaussians", "comments": "To appear in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the parameters of Gaussian mixture models is a fundamental and\nwidely studied problem with numerous applications. In this work, we give new\nalgorithms for learning the parameters of a high-dimensional, well separated,\nGaussian mixture model subject to the strong constraint of differential\nprivacy. In particular, we give a differentially private analogue of the\nalgorithm of Achlioptas and McSherry. Our algorithm has two key properties not\nachieved by prior work: (1) The algorithm's sample complexity matches that of\nthe corresponding non-private algorithm up to lower order terms in a wide range\nof parameters. (2) The algorithm does not require strong a priori bounds on the\nparameters of the mixture components.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 15:58:52 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 21:48:40 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Kamath", "Gautam", ""], ["Sheffet", "Or", ""], ["Singhal", "Vikrant", ""], ["Ullman", "Jonathan", ""]]}, {"id": "1909.03955", "submitter": "Xinyu Li", "authors": "Xinyu Li, Jing Xu, Xiong Fan, Yuchen Wang and Zhenfeng Zhang", "title": "Puncturable Signatures and Applications in Proof-of-Stake Blockchain\n  Protocol", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proof-of-stake blockchain protocols are becoming one of the most promising\nalternatives to the energy-consuming proof-of-work protocols. However, one\nparticularly critical threat in the PoS setting is the well-known long-range\nattacks caused by secret key leakage (LRSL attack). Specifically, an adversary\ncan attempt to control/compromise accounts possessing substantial stake at some\npast moment such that double-spend or erase past transactions, violating the\nfundamental persistence property of blockchain. Puncturable signatures provide\na satisfying solution to construct practical proof-of-stake blockchain\nresilient to LRSL attack, despite of the fact that existent constructions are\nnot efficient enough for practical deployments.\n  In this paper, we provide an in-depth study of puncturable signatures and\nexplore its applications in the proof-of-stake blockchain. We formalize a\nsecurity model that allows the adversary for adaptive signing and puncturing\nqueries, and show a construction with efficient puncturing operations based on\nthe Bloom filter data structure and strong Diffie-Hellman assumption. The\npuncturing functionality we desire is for a particular part of message, like\nprefix, instead of the whole message. Furthermore, we use puncturable\nsignatures to construct practical proof-of-stake blockchain protocols that are\nresilient to LRSL attack, while previously the forward-secure signature is used\nto immunize this attack. We implement our scheme and provide experimental\nresults showing that in comparison with the forward-secure signature, our\nconstruction performs substantially better on signature size, signing and\nverification efficiency, significantly on key update efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 16:02:36 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 09:29:37 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Li", "Xinyu", ""], ["Xu", "Jing", ""], ["Fan", "Xiong", ""], ["Wang", "Yuchen", ""], ["Zhang", "Zhenfeng", ""]]}, {"id": "1909.04126", "submitter": "Ang Li", "authors": "Ang Li, Jiayi Guo, Huanrui Yang, Flora D. Salim, Yiran Chen", "title": "DeepObfuscator: Obfuscating Intermediate Representations with\n  Privacy-Preserving Adversarial Learning on Smartphones", "comments": "This paper is to be published in IoTDI'21", "journal-ref": null, "doi": "10.1145/3450268.3453519", "report-no": null, "categories": "cs.CR cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has been widely applied in many computer vision applications,\nwith remarkable success. However, running deep learning models on mobile\ndevices is generally challenging due to the limitation of computing resources.\nA popular alternative is to use cloud services to run deep learning models to\nprocess raw data. This, however, imposes privacy risks. Some prior arts\nproposed sending the features extracted from raw data to the cloud.\nUnfortunately, these extracted features can still be exploited by attackers to\nrecover raw images and to infer embedded private attributes. In this paper, we\npropose an adversarial training framework, DeepObfuscator, which prevents the\nusage of the features for reconstruction of the raw images and inference of\nprivate attributes. This is done while retaining useful information for the\nintended cloud service. DeepObfuscator includes a learnable obfuscator that is\ndesigned to hide privacy-related sensitive information from the features by\nperforming our proposed adversarial training algorithm. The proposed algorithm\nis designed by simulating the game between an attacker who makes efforts to\nreconstruct raw image and infer private attributes from the extracted features\nand a defender who aims to protect user privacy. By deploying the trained\nobfuscator on the smartphone, features can be locally extracted and then sent\nto the cloud. Our experiments on CelebA and LFW datasets show that the quality\nof the reconstructed images from the obfuscated features of the raw image is\ndramatically decreased from 0.9458 to 0.3175 in terms of multi-scale structural\nsimilarity. The person in the reconstructed image, hence, becomes hardly to be\nre-identified. The classification accuracy of the inferred private attributes\nthat can be achieved by the attacker is significantly reduced to a\nrandom-guessing level.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 19:57:01 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 02:46:26 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Li", "Ang", ""], ["Guo", "Jiayi", ""], ["Yang", "Huanrui", ""], ["Salim", "Flora D.", ""], ["Chen", "Yiran", ""]]}, {"id": "1909.04172", "submitter": "Mostafa Safi", "authors": "Mostafa Safi", "title": "A Filtering Approach for Resiliency of Distributed Observers against\n  Smart Spoofers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A network of observers is considered, where through asynchronous (with\nbounded delay) communications, they all estimate the states of a Linear\nTime-Invariant (LTI) system. In such setting, a new type of adversarial nodes\nmight affect the observation process by impersonating the identity of the\nregular nodes, which is a violation against communication authenticity. These\nadversaries also inherit the capabilities of Byzantine nodes making them more\npowerful threats called smart spoofers. We show how asynchronous networks are\nvulnerable to smart spoofing attack. In the estimation scheme considered in\nthis paper, information are flowed from the sets of source nodes, which can\ndetect a portion of the state variables each, to the other follower nodes. The\nregular nodes, to avoid getting misguided by the threats, distributively filter\nthe extreme values received from the nodes in their neighborhood. Topological\nconditions based on graph strong robustness are proposed to guarantee the\nconvergence. Two simulation scenarios are provided to verify the results.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 21:48:28 GMT"}, {"version": "v2", "created": "Sat, 4 Jan 2020 23:53:27 GMT"}, {"version": "v3", "created": "Sun, 8 Nov 2020 20:21:13 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Safi", "Mostafa", ""]]}, {"id": "1909.04198", "submitter": "Shimaa Ahmed", "authors": "Shimaa Ahmed, Amrita Roy Chowdhury, Kassem Fawaz, Parmesh Ramanathan", "title": "Preech: A System for Privacy-Preserving Speech Transcription", "comments": "21 pages, 8 figures, 5 tables. The paper is accepted at the 29th\n  USENIX Security Symposium - URL:\n  https://www.usenix.org/conference/usenixsecurity20/presentation/ahmed-shimaa", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New Advances in machine learning have made Automated Speech Recognition (ASR)\nsystems practical and more scalable. These systems, however, pose serious\nprivacy threats as speech is a rich source of sensitive acoustic and textual\ninformation. Although offline and open-source ASR eliminates the privacy risks,\nits transcription performance is inferior to that of cloud-based ASR systems,\nespecially for real-world use cases. In this paper, we propose\nPr$\\epsilon\\epsilon$ch, an end-to-end speech transcription system which lies at\nan intermediate point in the privacy-utility spectrum. It protects the acoustic\nfeatures of the speakers' voices and protects the privacy of the textual\ncontent at an improved performance relative to offline ASR. Additionally,\nPr$\\epsilon\\epsilon$ch provides several control knobs to allow customizable\nutility-usability-privacy trade-off. It relies on cloud-based services to\ntranscribe a speech file after applying a series of privacy-preserving\noperations on the user's side. We perform a comprehensive evaluation of\nPr$\\epsilon\\epsilon$ch, using diverse real-world datasets, that demonstrates\nits effectiveness. Pr$\\epsilon\\epsilon$ch provides transcriptions at a 2% to\n32.25% (mean 17.34%) relative improvement in word error rate over Deep Speech,\nwhile fully obfuscating the speakers' voice biometrics and allowing only a\ndifferentially private view of the textual content.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 23:59:10 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 04:21:03 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 20:52:21 GMT"}, {"version": "v4", "created": "Fri, 3 Jul 2020 05:40:08 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Ahmed", "Shimaa", ""], ["Chowdhury", "Amrita Roy", ""], ["Fawaz", "Kassem", ""], ["Ramanathan", "Parmesh", ""]]}, {"id": "1909.04213", "submitter": "Pengfei Sun", "authors": "Pengfei Sun and Saman Zonouz", "title": "Selfie: User-defined Sensitive Memory Protection and Recovery", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different users always have different requirement for sensitive memory\ndefinition. It is not flexible for aborting program execution once detecting\nmemory corruption. Because the users may loose some sensitive data. We\npresented Selfie, a hybrid solution to provide one flexible solution to protect\nthe sensitive memory according to users' requirements in runtime. Finally,\nSelfie can provide one solution to decide whether execution needs to be\nrecovered. If the memory corruption doesn't belong sensitive memory, Selfie\nprovides symbolic solver that can help figure out whether the memory corruption\ncan affect the sensitive memory in future.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 00:58:37 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Sun", "Pengfei", ""], ["Zonouz", "Saman", ""]]}, {"id": "1909.04421", "submitter": "Mohammad Malekzadeh", "authors": "Mohammad Malekzadeh, Dimitrios Athanasakis, Hamed Haddadi and Benjamin\n  Livshits", "title": "Privacy-Preserving Bandits", "comments": "13 pages, 7 figures", "journal-ref": "In Proceedings of the 3rd Conference on Machine Learning and\n  Systems (MLSys 2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual bandit algorithms~(CBAs) often rely on personal data to provide\nrecommendations. Centralized CBA agents utilize potentially sensitive data from\nrecent interactions to provide personalization to end-users. Keeping the\nsensitive data locally, by running a local agent on the user's device, protects\nthe user's privacy, however, the agent requires longer to produce useful\nrecommendations, as it does not leverage feedback from other users. This paper\nproposes a technique we call Privacy-Preserving Bandits (P2B); a system that\nupdates local agents by collecting feedback from other local agents in a\ndifferentially-private manner. Comparisons of our proposed approach with a\nnon-private, as well as a fully-private (local) system, show competitive\nperformance on both synthetic benchmarks and real-world data. Specifically, we\nobserved only a decrease of 2.6% and 3.6% in multi-label classification\naccuracy, and a CTR increase of 0.0025 in online advertising for a privacy\nbudget $\\epsilon \\approx 0.693$. These results suggest P2B is an effective\napproach to challenges arising in on-device privacy-preserving personalization.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 11:39:58 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 22:36:09 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2020 16:12:00 GMT"}, {"version": "v4", "created": "Wed, 11 Mar 2020 12:39:06 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Malekzadeh", "Mohammad", ""], ["Athanasakis", "Dimitrios", ""], ["Haddadi", "Hamed", ""], ["Livshits", "Benjamin", ""]]}, {"id": "1909.04428", "submitter": "Lilas Alrahis", "authors": "Lilas Alrahis, Muhammad Yasin, Nimisha Limaye, Hani Saleh, Baker\n  Mohammad, Mahmoud Al-Qutayri and Ozgur Sinanoglu", "title": "ScanSAT: Unlocking Static and Dynamic Scan Obfuscation", "comments": "16 pages, 14 figures, IEEE Transactions on Emerging Topics in\n  Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While financially advantageous, outsourcing key steps, such as testing, to\npotentially untrusted Outsourced Assembly and Test (OSAT) companies may pose a\nrisk of compromising on-chip assets. Obfuscation of scan chains is a technique\nthat hides the actual scan data from the untrusted testers; logic inserted\nbetween the scan cells, driven by a secret key, hides the transformation\nfunctions that map the scan-in stimulus (scan-out response) and the delivered\nscan pattern (captured response). While static scan obfuscation utilizes the\nsame secret key, and thus, the same secret transformation functions throughout\nthe lifetime of the chip, dynamic scan obfuscation updates the key\nperiodically. In this paper, we propose ScanSAT: an attack that transforms a\nscan obfuscated circuit to its logic-locked version and applies the Boolean\nsatisfiability (SAT) based attack, thereby extracting the secret key. We\nimplement our attack, apply on representative scan obfuscation techniques, and\nshow that ScanSAT can break both static and dynamic scan obfuscation schemes\nwith 100% success rate. Moreover, ScanSAT is effective even for large key sizes\nand in the presence of scan compression.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 12:07:27 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Alrahis", "Lilas", ""], ["Yasin", "Muhammad", ""], ["Limaye", "Nimisha", ""], ["Saleh", "Hani", ""], ["Mohammad", "Baker", ""], ["Al-Qutayri", "Mahmoud", ""], ["Sinanoglu", "Ozgur", ""]]}, {"id": "1909.04472", "submitter": "Khoa Nguyen", "authors": "Martianus Frederic Ezerman, Hyung Tae Lee, San Ling, Khoa Nguyen,\n  Huaxiong Wang", "title": "Provably Secure Group Signature Schemes from Code-Based Assumptions", "comments": "Full extension of an earlier work published in the proceedings of\n  ASIACRYPT 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We solve an open question in code-based cryptography by introducing two\nprovably secure group signature schemes from code-based assumptions. Our basic\nscheme satisfies the CPA-anonymity and traceability requirements in the random\noracle model, assuming the hardness of the McEliece problem, the Learning\nParity with Noise problem, and a variant of the Syndrome Decoding problem. The\nconstruction produces smaller key and signature sizes than the previous group\nsignature schemes from lattices, as long as the cardinality of the underlying\ngroup does not exceed $2^{24}$, which is roughly comparable to the current\npopulation of the Netherlands. We develop the basic scheme further to achieve\nthe strongest anonymity notion, i.e., CCA-anonymity, with a small overhead in\nterms of efficiency. The feasibility of two proposed schemes is supported by\nimplementation results. Our two schemes are the first in their respective\nclasses of provably secure groups signature schemes. Additionally, the\ntechniques introduced in this work might be of independent interest. These are\na new verifiable encryption protocol for the randomized McEliece encryption and\na novel approach to design formal security reductions from the Syndrome\nDecoding problem.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 13:35:47 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 04:11:21 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Ezerman", "Martianus Frederic", ""], ["Lee", "Hyung Tae", ""], ["Ling", "San", ""], ["Nguyen", "Khoa", ""], ["Wang", "Huaxiong", ""]]}, {"id": "1909.04495", "submitter": "Yulun Hsieh", "authors": "Yu-Lun Hsieh and Minhao Cheng and Da-Cheng Juan and Wei Wei and\n  Wen-Lian Hsu and Cho-Jui Hsieh", "title": "Natural Adversarial Sentence Generation with Gradient-based Perturbation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This work proposes a novel algorithm to generate natural language adversarial\ninput for text classification models, in order to investigate the robustness of\nthese models. It involves applying gradient-based perturbation on the sentence\nembeddings that are used as the features for the classifier, and learning a\ndecoder for generation. We employ this method to a sentiment analysis model and\nverify its effectiveness in inducing incorrect predictions by the model. We\nalso conduct quantitative and qualitative analysis on these examples and\ndemonstrate that our approach can generate more natural adversaries. In\naddition, it can be used to successfully perform black-box attacks, which\ninvolves attacking other existing models whose parameters are not known. On a\npublic sentiment analysis API, the proposed method introduces a 20% relative\ndecrease in average accuracy and 74% relative increase in absolute error.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 07:22:01 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Hsieh", "Yu-Lun", ""], ["Cheng", "Minhao", ""], ["Juan", "Da-Cheng", ""], ["Wei", "Wei", ""], ["Hsu", "Wen-Lian", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1909.04685", "submitter": "Ajay Shrestha", "authors": "Ramita Maharjan, Ajay Kumar Shrestha and Rejina Basnet", "title": "Image Steganography: Protection of Digital Properties against\n  Eavesdropping", "comments": "8 pages, 11 figures, 9TH International conference on software,\n  knowledge, information management and applications (SKIMA 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Steganography is the art of hiding the fact that communication is taking\nplace, by hiding information in other information. Different types of carrier\nfile formats can be used, but digital images are the most popular ones because\nof their frequency on the internet. For hiding secret information in images,\nthere exists a large variety of steganography techniques. Some are more complex\nthan others and all of them have respective strong and weak points. Many\napplications may require absolute invisibility of the secret information. This\npaper intends to give an overview of image steganography, it's usage and\ntechniques, basically, to store the confidential information within images such\nas details of working strategy, secret missions, criminal and confidential\ninformation in various organizations that work for the national security such\nas army, police, FBI, secret service etc. We develop a desktop application that\nincorporates Advanced Encryption Standard for encryption of the original\nmessage, and Spatially Desynchronized Steganography Algorithm for hiding the\ntext file inside the image.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 18:00:53 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Maharjan", "Ramita", ""], ["Shrestha", "Ajay Kumar", ""], ["Basnet", "Rejina", ""]]}, {"id": "1909.04697", "submitter": "Zheyu Yan", "authors": "Zheyu Yan, Yiyu Shi, Wang Liao, Masanori Hashimoto, Xichuan Zhou,\n  Cheng Zhuo", "title": "When Single Event Upset Meets Deep Neural Networks: Observations,\n  Explorations, and Remedies", "comments": "7 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Network has proved its potential in various perception tasks and\nhence become an appealing option for interpretation and data processing in\nsecurity sensitive systems. However, security-sensitive systems demand not only\nhigh perception performance, but also design robustness under various\ncircumstances. Unlike prior works that study network robustness from software\nlevel, we investigate from hardware perspective about the impact of Single\nEvent Upset (SEU) induced parameter perturbation (SIPP) on neural networks. We\nsystematically define the fault models of SEU and then provide the definition\nof sensitivity to SIPP as the robustness measure for the network. We are then\nable to analytically explore the weakness of a network and summarize the key\nfindings for the impact of SIPP on different types of bits in a floating point\nparameter, layer-wise robustness within the same network and impact of network\ndepth. Based on those findings, we propose two remedy solutions to protect DNNs\nfrom SIPPs, which can mitigate accuracy degradation from 28% to 0.27% for\nResNet with merely 0.24-bit SRAM area overhead per parameter.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 18:24:43 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Yan", "Zheyu", ""], ["Shi", "Yiyu", ""], ["Liao", "Wang", ""], ["Hashimoto", "Masanori", ""], ["Zhou", "Xichuan", ""], ["Zhuo", "Cheng", ""]]}, {"id": "1909.04750", "submitter": "Omid Hajihassani", "authors": "Saleh Khalaj Monfared, Omid Hajihassani, Soroush Meghdadi Zanjani,\n  Mohammadsina Kiarostami, Dara Rahmati, Saeid Gorgin", "title": "Generating High Quality Random Numbers: A High Throughput Parallel\n  Bitsliced Approach", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this work, by employing a bitsliced data representation as building blocks\nof algorithms, we showcase the capability and scalability of our proposed\nmethod in a variety of PRNG methods in the category of block and stream\nciphers. While demonstrating the suitability of stream-ciphers for high\nthroughput PRNG, as an example, we implement and investigate a bitsliced MICKEY\n2.0 PRNG by altering the paradigm of internal functions and data structure. The\nLFSR-based (Linear Feedback Shift Register) nature of the PRNG in our\nimplementation perfectly suits the GPU's many-core structure due to its\nregister oriented architecture and allows the usage of bit slicing technique to\nfurther improve the performance. In our SIMD vectorized fully parallel GPU\nimplementation, each GPU thread is capable of generating a remarkable number of\n32 pseudo-random bits in each LFSR clock cycle. We then compare our\nimplementation with some of the most significant PRNGs that display a\nsatisfactory performance in both throughput and randomness criteria. The\nproposed implementation successfully passes the NIST test for statistical\nrandomness and bit-wise correlation criteria. To the best of authors' best\nknowledge, our method outperforms the current best implementations in the\nliterature for computer-based PRNG and the optical solutions in terms of\nperformance and performance per cost, while maintaining an acceptable measure\nof randomness. Our highest performance among all of the implemented CPRNGs with\nthe proposed method is achieved by the MICKEY 2.0 algorithm which shows 1.9x\nimprovement over the state of the art NVIDIA's proprietary high-performance\nPRNG, cuRAND library, achieving 1.6 Tb/s of throughput on the affordable NVIDIA\nGTX 980 Ti.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 20:51:02 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 05:22:29 GMT"}, {"version": "v3", "created": "Sun, 20 Oct 2019 19:07:54 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Monfared", "Saleh Khalaj", ""], ["Hajihassani", "Omid", ""], ["Zanjani", "Soroush Meghdadi", ""], ["Kiarostami", "Mohammadsina", ""], ["Rahmati", "Dara", ""], ["Gorgin", "Saeid", ""]]}, {"id": "1909.04778", "submitter": "Robert Podschwadt", "authors": "Robert Podschwadt, Hassan Takabi", "title": "Effectiveness of Adversarial Examples and Defenses for Malware\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks have been successfully used for many different\nclassification tasks including malware detection and distinguishing between\nmalicious and non-malicious programs. Although artificial neural networks\nperform very well on these tasks, they are also vulnerable to adversarial\nexamples. An adversarial example is a sample that has minor modifications made\nto it so that the neural network misclassifies it. Many techniques have been\nproposed, both for crafting adversarial examples and for hardening neural\nnetworks against them. Most previous work has been done in the image domain.\nSome of the attacks have been adopted to work in the malware domain which\ntypically deals with binary feature vectors. In order to better understand the\nspace of adversarial examples in malware classification, we study different\napproaches of crafting adversarial examples and defense techniques in the\nmalware domain and compare their effectiveness on multiple datasets.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 22:20:32 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Podschwadt", "Robert", ""], ["Takabi", "Hassan", ""]]}, {"id": "1909.04779", "submitter": "Eitan Rothberg", "authors": "Eitan Rothberg, Tingting Chen, Luo Jie, Hao Ji", "title": "Localized Adversarial Training for Increased Accuracy and Robustness in\n  Image Classification", "comments": "4 pages (excluding references). Presented at AdvML: 1st Workshop on\n  Adversarial Learning Methods for Machine Learning and Data Mining at KDD '19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's state-of-the-art image classifiers fail to correctly classify\ncarefully manipulated adversarial images. In this work, we develop a new,\nlocalized adversarial attack that generates adversarial examples by\nimperceptibly altering the backgrounds of normal images. We first use this\nattack to highlight the unnecessary sensitivity of neural networks to changes\nin the background of an image, then use it as part of a new training technique:\nlocalized adversarial training. By including locally adversarial images in the\ntraining set, we are able to create a classifier that suffers less loss than a\nnon-adversarially trained counterpart model on both natural and adversarial\ninputs. The evaluation of our localized adversarial training algorithm on MNIST\nand CIFAR-10 datasets shows decreased accuracy loss on natural images, and\nincreased robustness against adversarial inputs.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 22:26:48 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Rothberg", "Eitan", ""], ["Chen", "Tingting", ""], ["Jie", "Luo", ""], ["Ji", "Hao", ""]]}, {"id": "1909.04837", "submitter": "Xiaojun Jia", "authors": "Xiaojun Jia, Xingxing Wei, Xiaochun Cao", "title": "Identifying and Resisting Adversarial Videos Using Temporal Consistency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Video classification is a challenging task in computer vision. Although Deep\nNeural Networks (DNNs) have achieved excellent performance in video\nclassification, recent research shows adding imperceptible perturbations to\nclean videos can make the well-trained models output wrong labels with high\nconfidence. In this paper, we propose an effective defense framework to\ncharacterize and defend adversarial videos. The proposed method contains two\nphases: (1) adversarial video detection using temporal consistency between\nadjacent frames, and (2) adversarial perturbation reduction via denoisers in\nthe spatial and temporal domains respectively. Specifically, because of the\nlinear nature of DNNs, the imperceptible perturbations will enlarge with the\nincreasing of DNNs depth, which leads to the inconsistency of DNNs output\nbetween adjacent frames. However, the benign video frames often have the same\noutputs with their neighbor frames owing to the slight changes. Based on this\nobservation, we can distinguish between adversarial videos and benign videos.\nAfter that, we utilize different defense strategies against different attacks.\nWe propose the temporal defense, which reconstructs the polluted frames with\ntheir temporally neighbor clean frames, to deal with the adversarial videos\nwith sparse polluted frames. For the videos with dense polluted frames, we use\nan efficient adversarial denoiser to process each frame in the spatial domain,\nand thus purify the perturbations (we call it as spatial defense). A series of\nexperiments conducted on the UCF-101 dataset demonstrate that the proposed\nmethod significantly improves the robustness of video classifiers against\nadversarial attacks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 03:11:52 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Jia", "Xiaojun", ""], ["Wei", "Xingxing", ""], ["Cao", "Xiaochun", ""]]}, {"id": "1909.04841", "submitter": "Mohammadkazem Taram", "authors": "Mohammadkazem Taram, Ashish Venkat, Dean Tullsen", "title": "Packet Chasing: Spying on Network Packets over a Cache Side-Channel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Packet Chasing, an attack on the network that does not\nrequire access to the network, and works regardless of the privilege level of\nthe process receiving the packets. A spy process can easily probe and discover\nthe exact cache location of each buffer used by the network driver. Even more\nuseful, it can discover the exact sequence in which those buffers are used to\nreceive packets. This then enables packet frequency and packet sizes to be\nmonitored through cache side channels. This allows both covert channels between\na sender and a remote spy with no access to the network, as well as direct\nattacks that can identify, among other things, the web page access patterns of\na victim on the network. In addition to identifying the potential attack, this\nwork proposes a software-based short-term mitigation as well as a light-weight,\nadaptive, cache partitioning mitigation that blocks the interference of I/O and\nCPU requests in the last-level cache.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 04:03:14 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 03:29:28 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Taram", "Mohammadkazem", ""], ["Venkat", "Ashish", ""], ["Tullsen", "Dean", ""]]}, {"id": "1909.05028", "submitter": "Ajay Shrestha", "authors": "Ajay Kumar Shrestha, Ralph Deters and Julita Vassileva", "title": "User-Controlled Privacy-Preserving User Profile Data Sharing based on\n  Blockchain", "comments": "10 pages, 11 figures, 4 tables, Future Technologies Conference (FTC)\n  2017, \"for associated proceeding paper, see\n  https://saiconference.com/Downloads/FTC2017/Proceedings/3_Paper_127-User-Controlled_Privacy-Preserving_User_Profile_Data_Sharing.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tremendous technological advancement in the last few decades has brought\nmany enterprises to collaborate in a better way while making intelligent\ndecisions. The use of Information Technology tools in obtaining data of\npeople's everyday life from various autonomous data sources allowing\nunrestricted access to user data has emerged as an important practical issue\nand has given rise to legal implications. Various innovative models for data\nsharing and management have privacy and centrality issues. To alleviate these\nlimitations, we have incorporated blockchain in user modeling. In this paper,\nwe constructed a decentralized data sharing architecture with MultiChain\nblockchain in the travel domain, which is also applicable to other similar\ndomains including education, health, and sports. Businesses that operate in the\ntourism industries including travel and tour agencies, hotels and resorts,\nshopping malls are connected to the MultiChain and they share their user\nprofile data via stream in the MultiChain. The paper presents the hotel booking\nservice for an imaginary hotel as one of the enterprise nodes, which collects\nuser profile data with proper validation and will allow users to decide which\nof their data to be shared thus ensuring user control over their data and the\npreservation of privacy. The data from the repository is converted into an open\ndata format while sharing via stream in the blockchain so that other enterprise\nnodes, after receiving the data, can easily convert them and store into their\nown repositories. The paper presents an evaluation of the performance of the\nmodel by measuring the latency and memory consumption with three test scenarios\nthat mostly affect the user experience. The node responded quickly in all of\nthese cases.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 17:10:22 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Shrestha", "Ajay Kumar", ""], ["Deters", "Ralph", ""], ["Vassileva", "Julita", ""]]}, {"id": "1909.05040", "submitter": "Francesco Croce", "authors": "Francesco Croce, Matthias Hein", "title": "Sparse and Imperceivable Adversarial Attacks", "comments": "Accepted to ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have been proven to be vulnerable to a variety of adversarial\nattacks. From a safety perspective, highly sparse adversarial attacks are\nparticularly dangerous. On the other hand the pixelwise perturbations of sparse\nattacks are typically large and thus can be potentially detected. We propose a\nnew black-box technique to craft adversarial examples aiming at minimizing\n$l_0$-distance to the original image. Extensive experiments show that our\nattack is better or competitive to the state of the art. Moreover, we can\nintegrate additional bounds on the componentwise perturbation. Allowing pixels\nto change only in region of high variation and avoiding changes along\naxis-aligned edges makes our adversarial examples almost non-perceivable.\nMoreover, we adapt the Projected Gradient Descent attack to the $l_0$-norm\nintegrating componentwise constraints. This allows us to do adversarial\ntraining to enhance the robustness of classifiers against sparse and\nimperceivable adversarial manipulations.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 13:28:44 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Croce", "Francesco", ""], ["Hein", "Matthias", ""]]}, {"id": "1909.05193", "submitter": "Adnan Siraj Rakin", "authors": "Adnan Siraj Rakin, Zhezhi He and Deliang Fan", "title": "TBT: Targeted Neural Network Attack with Bit Trojan", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security of modern Deep Neural Networks (DNNs) is under severe scrutiny as\nthe deployment of these models become widespread in many intelligence-based\napplications. Most recently, DNNs are attacked through Trojan which can\neffectively infect the model during the training phase and get activated only\nthrough specific input patterns (i.e, trigger) during inference. In this work,\nfor the first time, we propose a novel Targeted Bit Trojan(TBT) method, which\ncan insert a targeted neural Trojan into a DNN through the bit-flip attack. Our\nalgorithm efficiently generates a trigger specifically designed to locate\ncertain vulnerable bits of DNN weights stored in main memory (i.e., DRAM). The\nobjective is that once the attacker flips these vulnerable bits, the network\nstill operates with normal inference accuracy with benign input. However, when\nthe attacker activates the trigger by embedding it with any input, the network\nis forced to classify all inputs to a certain target class. We demonstrate that\nflipping only several vulnerable bits identified by our method, using available\nbit-flip techniques (i.e, row-hammer), can transform a fully functional DNN\nmodel into a Trojan-infected model. We perform extensive experiments of\nCIFAR-10, SVHN and ImageNet datasets on both VGG-16 and Resnet-18\narchitectures. Our proposed TBT could classify 92 % of test images to a target\nclass with as little as 84 bit-flips out of 88 million weight bits on Resnet-18\nfor CIFAR10 dataset.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 07:51:26 GMT"}, {"version": "v2", "created": "Sun, 1 Mar 2020 03:32:09 GMT"}, {"version": "v3", "created": "Sun, 29 Mar 2020 00:16:32 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Rakin", "Adnan Siraj", ""], ["He", "Zhezhi", ""], ["Fan", "Deliang", ""]]}, {"id": "1909.05243", "submitter": "Fabian Schillinger", "authors": "Fabian Schillinger, Christian Schindelhauer", "title": "Crucial and Redundant Shares and Compartments in Secret Sharing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secret sharing is the well-known problem of splitting a secret into multiple\nshares, which are distributed to shareholders. When enough or the correct\ncombination of shareholders work together the secret can be restored. We\nintroduce two new types of shares to the secret sharing scheme of Shamir.\nCrucial shares are always needed for the reconstruction of the secret, whereas\nmutual redundant shares only help once in reconstructing the secret. Further,\nwe extend the idea of crucial and redundant shares to a compartmented secret\nsharing scheme. The scheme, which is based on Shamir's, allows distributing the\nsecret to different compartments, that hold shareholders themselves. In each\ncompartment, another secret sharing scheme can be applied. Using the\nmodifications the overall complexity of general access structures realized\nthrough compartmented secret sharing schemes can be reduced. This improves the\ncomputational complexity. Also, the number of shares can be reduced and some\ncomplex access structures can be realized with ideal amount and size of shares.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 15:00:09 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 16:14:55 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 09:21:12 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Schillinger", "Fabian", ""], ["Schindelhauer", "Christian", ""]]}, {"id": "1909.05300", "submitter": "Boyang Li", "authors": "Boyang Li, Jie Wu and Yiyu Shi", "title": "Privacy-Aware Cost-Effective Scheduling Considering Non-Schedulable\n  Appliances in Smart Home", "comments": "8 pages, 9 fgiures. The 15th IEEE International Conference on\n  Embedded Software and Systems (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Smart Home provides integrating and electronic information services to help\nresidential users manage their energy usage and bill cost but also exposes\nusers to significant privacy risks due to fine-grained information collected by\nsmart meters. Taking account of users' privacy concerns, this paper focuses on\ncost-effective runtime scheduling designed for schedulable and non-schedulable\nappliances. To alleviate the influence of operation uncertainties introduced by\nnon-schedulable appliances, we formulate the problem by minimizing the expected\nsum of electricity cost under the worst privacy situation. Inventing the\niterative alternative algorithm, we effectively schedule the appliances and\nrechargeable battery in a cost-effective way while satisfying users' privacy\nrequirement. Experimental evaluation based on real-world data demonstrates the\neffectiveness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 18:43:50 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Li", "Boyang", ""], ["Wu", "Jie", ""], ["Shi", "Yiyu", ""]]}, {"id": "1909.05410", "submitter": "Christopher M. Poskitt", "authors": "Yuqi Chen, Christopher M. Poskitt, Jun Sun, Sridhar Adepu, Fan Zhang", "title": "Learning-Guided Network Fuzzing for Testing Cyber-Physical System\n  Defences", "comments": "Accepted by ASE 2019", "journal-ref": "In Proc. IEEE/ACM International Conference on Automated Software\n  Engineering (ASE 2019), pages 962-973. IEEE, 2019", "doi": "10.1109/ASE.2019.00093", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The threat of attack faced by cyber-physical systems (CPSs), especially when\nthey play a critical role in automating public infrastructure, has motivated\nresearch into a wide variety of attack defence mechanisms. Assessing their\neffectiveness is challenging, however, as realistic sets of attacks to test\nthem against are not always available. In this paper, we propose smart fuzzing,\nan automated, machine learning guided technique for systematically finding\n'test suites' of CPS network attacks, without requiring any knowledge of the\nsystem's control programs or physical processes. Our approach uses predictive\nmachine learning models and metaheuristic search algorithms to guide the\nfuzzing of actuators so as to drive the CPS into different unsafe physical\nstates. We demonstrate the efficacy of smart fuzzing by implementing it for two\nreal-world CPS testbeds---a water purification plant and a water distribution\nsystem---finding attacks that drive them into 27 different unsafe states\ninvolving water flow, pressure, and tank levels, including six that were not\ncovered by an established attack benchmark. Finally, we use our approach to\ntest the effectiveness of an invariant-based defence system for the water\ntreatment plant, finding two attacks that were not detected by its physical\ninvariant checks, highlighting a potential weakness that could be exploited in\ncertain conditions.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 00:23:45 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Chen", "Yuqi", ""], ["Poskitt", "Christopher M.", ""], ["Sun", "Jun", ""], ["Adepu", "Sridhar", ""], ["Zhang", "Fan", ""]]}, {"id": "1909.05709", "submitter": "Bonaventure Ngala Mr", "authors": "Bonaventure Ngala", "title": "E-Crime Legal Brief: A Case Study on Talk Talk Hacking", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  E-crime has had various definitions for different countries and\norganisations. There is no universal definition of E-crime and therefore the\ninterpretation is left to cybercrime investigators and judges to apply related\ncrimes to within the scope where possible. E-crime legal brief should include\nCitation, facts of the case, issues, reasoning, decision of the judges and\nanalysis. The analysis outlines applicable laws in e-crime, case laws relevant\nto the facts of the case and crime committed.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 14:22:34 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Ngala", "Bonaventure", ""]]}, {"id": "1909.05747", "submitter": "Hans Liljestrand", "authors": "Hans Liljestrand, Zaheer Gauhar, Thomas Nyman, Jan-Erik Ekberg, N.\n  Asokan", "title": "Protecting the stack with PACed canaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stack canaries remain a widely deployed defense against memory corruption\nattacks. Despite their practical usefulness, canaries are vulnerable to memory\ndisclosure and brute-forcing attacks. We propose PCan, a new approach based on\nARMv8.3-A pointer authentication (PA), that uses dynamically-generated canaries\nto mitigate these weaknesses and show that it provides more fine-grained\nprotection with minimal performance overhead.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 15:21:55 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Liljestrand", "Hans", ""], ["Gauhar", "Zaheer", ""], ["Nyman", "Thomas", ""], ["Ekberg", "Jan-Erik", ""], ["Asokan", "N.", ""]]}, {"id": "1909.05771", "submitter": "Marc Schink", "authors": "Marc Schink and Johannes Obermaier", "title": "Taking a Look into Execute-Only Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development process of microcontroller firmware often involves multiple\nparties. In such a scenario, the Intellectual Property (IP) is not protected\nagainst adversarial developers which have unrestricted access to the firmware\nbinary. For this reason, microcontroller manufacturers integrate eXecute-Only\nMemory (XOM) which shall prevent an unauthorized read-out of third-party\nfirmware during development. The concept allows execution of code but disallows\nany read access to it. Our security analysis shows that this concept is\ninsufficient for firmware protection due to the use of shared resources such as\nthe CPU and SRAM. We present a method to infer instructions from observed state\ntransitions in shared hardware. We demonstrate our method via an automatic\nrecovery of protected firmware. We successfully performed experiments on\ndevices from different manufacturers to confirm the practicability of our\nattack. Our research also reveals implementation flaws in some of the analyzed\ndevices which enables an adversary to bypass the read-out restrictions.\nAltogether, the paper shows the insufficient security of the XOM concept as\nwell as several implementations.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 16:08:02 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Schink", "Marc", ""], ["Obermaier", "Johannes", ""]]}, {"id": "1909.05801", "submitter": "Emiliano De Cristofaro", "authors": "Aravindh Raman, Sagar Joglekar, Emiliano De Cristofaro, Nishanth\n  Sastry, and Gareth Tyson", "title": "Challenges in the Decentralised Web: The Mastodon Case", "comments": null, "journal-ref": "Proceedings of 19th ACM Internet Measurement Conference (IMC 2019)", "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Decentralised Web (DW) has recently seen a renewed momentum, with a\nnumber of DW platforms like Mastodon, Peer-Tube, and Hubzilla gaining\nincreasing traction. These offer alternatives to traditional social networks\nlike Twitter, YouTube, and Facebook, by enabling the operation of web\ninfrastructure and services without centralised ownership or control. Although\ntheir services differ greatly, modern DW platforms mostly rely on two key\ninnovations: first, their open source software allows anybody to setup\nindependent servers (\"instances\") that people can sign-up to and use within a\nlocal community; and second, they build on top of federation protocols so that\ninstances can mesh together, in a peer-to-peer fashion, to offer a globally\nintegrated platform. In this paper, we present a measurement-driven exploration\nof these two innovations, using a popular DW microblogging platform (Mastodon)\nas a case study. We focus on identifying key challenges that might disrupt\ncontinuing efforts to decentralise the web, and empirically highlight a number\nof properties that are creating natural pressures towards recentralisation.\nFinally, our measurements shed light on the behaviour of both administrators\n(i.e., people setting up instances) and regular users who sign-up to the\nplatforms, also discussing a few techniques that may address some of the issues\nobserved.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 17:00:34 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Raman", "Aravindh", ""], ["Joglekar", "Sagar", ""], ["De Cristofaro", "Emiliano", ""], ["Sastry", "Nishanth", ""], ["Tyson", "Gareth", ""]]}, {"id": "1909.05819", "submitter": "Danushka Bollegala", "authors": "Danushka Bollegala, Tomoya Machide, Ken-ichi Kawarabayashi", "title": "Anonymising Queries by Semantic Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protecting the privacy of search engine users is an important requirement in\nmany information retrieval scenarios. A user might not want a search engine to\nguess his or her information need despite requesting relevant results. We\npropose a method to protect the privacy of search engine users by decomposing\nthe queries using semantically \\emph{related} and unrelated \\emph{distractor}\nterms. Instead of a single query, the search engine receives multiple\ndecomposed query terms. Next, we reconstruct the search results relevant to the\noriginal query term by aggregating the search results retrieved for the\ndecomposed query terms. We show that the word embeddings learnt using a\ndistributed representation learning method can be used to find semantically\nrelated and distractor query terms. We derive the relationship between the\n\\emph{anonymity} achieved through the proposed query anonymisation method and\nthe \\emph{reconstructability} of the original search results using the\ndecomposed queries. We analytically study the risk of discovering the search\nengine users' information intents under the proposed query anonymisation\nmethod, and empirically evaluate its robustness against clustering-based\nattacks. Our experimental results show that the proposed method can accurately\nreconstruct the search results for user queries, without compromising the\nprivacy of the search engine users.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 17:27:46 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Bollegala", "Danushka", ""], ["Machide", "Tomoya", ""], ["Kawarabayashi", "Ken-ichi", ""]]}, {"id": "1909.05830", "submitter": "Jeffrey Li", "authors": "Jeffrey Li, Mikhail Khodak, Sebastian Caldas, Ameet Talwalkar", "title": "Differentially Private Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameter-transfer is a well-known and versatile approach for meta-learning,\nwith applications including few-shot learning, federated learning, and\nreinforcement learning. However, parameter-transfer algorithms often require\nsharing models that have been trained on the samples from specific tasks, thus\nleaving the task-owners susceptible to breaches of privacy. We conduct the\nfirst formal study of privacy in this setting and formalize the notion of\ntask-global differential privacy as a practical relaxation of more commonly\nstudied threat models. We then propose a new differentially private algorithm\nfor gradient-based parameter transfer that not only satisfies this privacy\nrequirement but also retains provable transfer learning guarantees in convex\nsettings. Empirically, we apply our analysis to the problems of federated\nlearning with personalization and few-shot classification, showing that\nallowing the relaxation to task-global privacy from the more commonly studied\nnotion of local privacy leads to dramatically increased performance in\nrecurrent neural language modeling and image classification.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 17:37:08 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 17:08:10 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Li", "Jeffrey", ""], ["Khodak", "Mikhail", ""], ["Caldas", "Sebastian", ""], ["Talwalkar", "Ameet", ""]]}, {"id": "1909.05977", "submitter": "Brandon Paulsen", "authors": "Brandon Paulsen, Chungha Sung, Peter A.H. Peterson, Chao Wang", "title": "Debreach: Mitigating Compression Side Channels via Static Analysis and\n  Transformation", "comments": "Published as a conference paper at ASE 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compression is an emerging source of exploitable side-channel leakage that\nthreatens data security, particularly in web applications where compression is\nindispensable for performance reasons. Current approaches to mitigating\ncompression side channels have drawbacks in that they either degrade\ncompression ratio drastically or require too much effort from developers to be\nwidely adopted. To bridge the gap, we develop Debreach, a static analysis and\nprogram transformation based approach to mitigating compression side channels.\nDebreach consists of two steps. First, it uses taint analysis to soundly\nidentify flows of sensitive data in the program and uses code instrumentation\nto annotate data before feeding them to the compressor. Second, it enhances the\ncompressor to exploit the freedom to not compress of standard compression\nprotocols, thus removing the dependency between sensitive data and the size of\nthe compressor's output. Since Debreach automatically instruments applications\nand does not change the compression protocols, it has the advantage of being\nnon-disruptive and compatible with existing systems. We have evaluated Debreach\non a set of web server applications written in PHP. Our experiments show that,\nwhile ensuring leakage-freedom, Debreach can achieve significantly higher\ncompression performance than state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 22:41:29 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Paulsen", "Brandon", ""], ["Sung", "Chungha", ""], ["Peterson", "Peter A. H.", ""], ["Wang", "Chao", ""]]}, {"id": "1909.06122", "submitter": "Run Wang", "authors": "Run Wang, Felix Juefei-Xu, Lei Ma, Xiaofei Xie, Yihao Huang, Jian\n  Wang, Yang Liu", "title": "FakeSpotter: A Simple yet Robust Baseline for Spotting AI-Synthesized\n  Fake Faces", "comments": "Accepted to IJCAI 2020; SOLE copyright holder is IJCAI (international\n  Joint Conferences on Artificial Intelligence), all rights reserved.\n  https://www.ijcai.org/Proceedings/2020/333", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, generative adversarial networks (GANs) and its variants have\nachieved unprecedented success in image synthesis. They are widely adopted in\nsynthesizing facial images which brings potential security concerns to humans\nas the fakes spread and fuel the misinformation. However, robust detectors of\nthese AI-synthesized fake faces are still in their infancy and are not ready to\nfully tackle this emerging challenge. In this work, we propose a novel\napproach, named FakeSpotter, based on monitoring neuron behaviors to spot\nAI-synthesized fake faces. The studies on neuron coverage and interactions have\nsuccessfully shown that they can be served as testing criteria for deep\nlearning systems, especially under the settings of being exposed to adversarial\nattacks. Here, we conjecture that monitoring neuron behavior can also serve as\nan asset in detecting fake faces since layer-by-layer neuron activation\npatterns may capture more subtle features that are important for the fake\ndetector. Experimental results on detecting four types of fake faces\nsynthesized with the state-of-the-art GANs and evading four perturbation\nattacks show the effectiveness and robustness of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 10:08:44 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 06:02:29 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 06:44:53 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Wang", "Run", ""], ["Juefei-Xu", "Felix", ""], ["Ma", "Lei", ""], ["Xie", "Xiaofei", ""], ["Huang", "Yihao", ""], ["Wang", "Jian", ""], ["Liu", "Yang", ""]]}, {"id": "1909.06189", "submitter": "Guang Cheng", "authors": "Fang Chen, Hong Wan, Hua Cai, and Guang Cheng", "title": "Machine Learning in/for Blockchain: Future and Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning and blockchain are two of the most noticeable technologies\nin recent years. The first one is the foundation of artificial intelligence and\nbig data, and the second one has significantly disrupted the financial\nindustry. Both technologies are data-driven, and thus there are rapidly growing\ninterests in integrating them for more secure and efficient data sharing and\nanalysis. In this paper, we review the research on combining blockchain and\nmachine learning technologies and demonstrate that they can collaborate\nefficiently and effectively. In the end, we point out some future directions\nand expect more researches on deeper integration of the two promising\ntechnologies.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 16:37:42 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 01:29:16 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2020 23:50:57 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Chen", "Fang", ""], ["Wan", "Hong", ""], ["Cai", "Hua", ""], ["Cheng", "Guang", ""]]}, {"id": "1909.06300", "submitter": "Daniel Shiu", "authors": "Daniel Shiu", "title": "Analysis of Solitaire", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Solitaire cipher was designed by Bruce Schneier as a plot point in the\nnovel Cryptonomicon by Neal Stephenson. The cipher is intended to fit the\narchetype of a modern stream cipher whilst being implementable by hand using a\nstandard deck of cards with two jokers. We find a model for repetitions in the\nkeystream in the stream cipher Solitaire that accounts for the large majority\nof the repetition bias. Other phenomena merit further investigation. We have\nproposed modifications to the cipher that would reduce the repetition bias, but\nat the cost of increasing the complexity of the cipher (probably beyond the\ngoal of allowing manual implementation). We have argued that the state update\nfunction is unlikely to lead to cycles significantly shorter than those of a\nrandom bijection.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 15:48:10 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Shiu", "Daniel", ""]]}, {"id": "1909.06322", "submitter": "Quanquan Gu", "authors": "Lingxiao Wang and Quanquan Gu", "title": "A Knowledge Transfer Framework for Differentially Private Sparse\n  Learning", "comments": "24 pages, 2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating high dimensional models with underlying\nsparse structures while preserving the privacy of each training example. We\ndevelop a differentially private high-dimensional sparse learning framework\nusing the idea of knowledge transfer. More specifically, we propose to distill\nthe knowledge from a \"teacher\" estimator trained on a private dataset, by\ncreating a new dataset from auxiliary features, and then train a differentially\nprivate \"student\" estimator using this new dataset. In addition, we establish\nthe linear convergence rate as well as the utility guarantee for our proposed\nmethod. For sparse linear regression and sparse logistic regression, our method\nachieves improved utility guarantees compared with the best known results\n(Kifer et al., 2012; Wang and Gu, 2019). We further demonstrate the superiority\nof our framework through both synthetic and real-world data experiments.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 16:46:02 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Wang", "Lingxiao", ""], ["Gu", "Quanquan", ""]]}, {"id": "1909.06357", "submitter": "Sheikh Ariful Islam", "authors": "Rohith Prasad Challa, Sheikh Ariful Islam and Srinivas Katkoori", "title": "An SR Flip-Flop based Physical Unclonable Functions for Hardware\n  Security", "comments": "Accepted to MWSCAS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical Unclonable Functions (PUFs) have emerged as a promising solution to\nidentify and authenticate Integrated Circuits (ICs). In this paper, we propose\na novel NAND-based Set-Reset (SR) Flip-flop (FF) PUF design for security\nenclosures of the area- and power-constrained Internet-of-Things (IoT) edge\nnode. Such SR-FF based PUF is constructed during a unique race condition that\nis (normally) avoided due to inconsistency. We have shown, when both inputs (S\nand R) are logic high ('1') and followed by logic zero ('0'), the outputs Q and\nQbar can settle down to either 0 or 1 or vice-versa depending on statistical\ndelay variations in cross-coupled paths. We incorporate the process variations\nduring SPICE-level simulations to leverage the capability of SR-FF in\ngenerating the unique identifier of an IC. Experimental results for 90nm, 45nm,\nand 32nm process nodes show the robustness of SR-FF PUF responses in terms of\nuniqueness, randomness, uniformity, and bit(s) biases. Furthermore, we perform\nphysical synthesis to evaluate the applicability of SR FF PUF on five designs\nfrom OpenCores in three design corners. The estimated overhead for power,\ntiming, and area in three design corners are negligible.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 21:39:53 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Challa", "Rohith Prasad", ""], ["Islam", "Sheikh Ariful", ""], ["Katkoori", "Srinivas", ""]]}, {"id": "1909.06369", "submitter": "Richard Jiang", "authors": "Bing Xu, Tobechukwu Agbele, Qiang Ni and Richard Jiang", "title": "Biometric Blockchain: A Secure Solution for Intelligent Vehicle Data\n  Sharing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.NI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The intelligent vehicle (IV) has become a promising technology that could\nrevolutionize our life in smart cities sooner or later. However, it yet suffers\nfrom many security vulnerabilities. Traditional security methods are incapable\nto secure the IV data sharing against malicious attacks. Blockchain, as\nexpected by both research and industry communities, has emerged as a good\nsolution to address these issues. The major issues in IV data sharing are\ntrust, data accuracy and reliability of data sharing in the communication\nchannel. Blockchain technology, previously working for the cryptocurrency, has\nrecently applied to build trust and reliability in peer-to-peer networks with\nsimilar topologies of IV data sharing. In this chapter, we present a new\nframework, namely biometric blockchain (BBC), for secure IV data sharing. In\nour new scheme, biometric information is exploited as a cue to record who is\nresponsible in the data sharing activities, while the proposed BBC technology\nserves as the backbone of the IV data-sharing architecture. Hence, the proposed\nBBC technology provides a more reliable trust environment between the vehicles\nwhile personal identities are traceable in the proposed new scheme.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 19:23:01 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Xu", "Bing", ""], ["Agbele", "Tobechukwu", ""], ["Ni", "Qiang", ""], ["Jiang", "Richard", ""]]}, {"id": "1909.06371", "submitter": "Yucel Aydin", "authors": "Yucel Aydin, Gunes Karabulut Kurt, Enver \\\"Ozdemir, Halim\n  Yanikomeroglu", "title": "A Flexible and Lightweight Group Authentication Scheme", "comments": "arXiv admin note: text overlap with arXiv:1908.10320", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) networks are becoming a part of our daily lives, as\nthe number of IoT devices around us are surging. The authentication of millions\nof connected things and the distribution and management of secret keys between\nthese devices pose challenging research problems. Current one-to-one\nauthentication schemes do not take the resource limitations of IoT devices into\nconsideration. Nor do they address the scalability problem of massive machine\ntype communication (mMTC) networks. Group authentication schemes (GAS), on the\nother hand, have emerged as novel approaches for many-to-many authentication\nproblems. They can be used to simultaneously authenticate numerous\nresource-constrained devices. However, existing GAS are not energy efficient,\nand they do not provide enough security for widespread use. In this paper, we\npropose a lightweight GAS that significantly reduces energy consumption on\ndevices, providing almost 80% energy savings when compared to the\nstate-of-the-art solutions. Our approach is also resistant to the replay and\nman-in-the-middle attacks. The proposed approach also includes a solution for\nkey agreement and key distribution problems in mMTC environments. Moreover,\nthis approach can be used in both centralized and decentralized group\nauthentication scenarios. The proposed approach has the potential to address\nthe fast authentication requirements of the envisioned agile 6G networks,\nsupported through aerial networking nodes.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 14:24:36 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 19:44:21 GMT"}, {"version": "v3", "created": "Fri, 3 Apr 2020 11:29:20 GMT"}, {"version": "v4", "created": "Fri, 1 May 2020 02:37:56 GMT"}, {"version": "v5", "created": "Fri, 19 Jun 2020 21:23:38 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Aydin", "Yucel", ""], ["Kurt", "Gunes Karabulut", ""], ["\u00d6zdemir", "Enver", ""], ["Yanikomeroglu", "Halim", ""]]}, {"id": "1909.06462", "submitter": "Maximilian Schiedermeier", "authors": "Maximilian Schiedermeier, Omar Hasan, Tobias Mayer, Lionel Brunie,\n  Harald Kosch", "title": "A transparent referendum protocol with immutable proceedings and\n  verifiable outcome for trustless networks", "comments": "14 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High voter turnout in elections and referendums is very desirable in order to\nensure a robust democracy. Secure electronic voting is a vision for the future\nof elections and referendums. Such a system can counteract factors that hinder\nstrong voter turnout such as the requirement of physical presence during\nlimited hours at polling stations. However, this vision brings transparency and\nconfidentiality requirements that render the design of such solutions\nchallenging. Specifically, the counting must be implemented in a reproducible\nway and the ballots of individual voters must remain concealed. In this paper,\nwe propose and evaluate a referendum protocol that ensures transparency,\nconfidentiality, and integrity, in trustless networks. The protocol is built by\ncombining Secure Multi-Party Computation (SMPC) and Distributed Ledger or\nBlockchain technology. The persistence and immutability of the protocol\ncommunication allows verifiability of the referendum outcome on the client\nside. Voters therefore do not need to trust in third parties. We provide a\nformal description and conduct a thorough security evaluation of our proposal.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 21:41:05 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Schiedermeier", "Maximilian", ""], ["Hasan", "Omar", ""], ["Mayer", "Tobias", ""], ["Brunie", "Lionel", ""], ["Kosch", "Harald", ""]]}, {"id": "1909.06472", "submitter": "Bo Feng", "authors": "Bo Feng, Alejandro Mera, Long Lu", "title": "P$^2$IM: Scalable and Hardware-independent Firmware Testing via\n  Automatic Peripheral Interface Modeling (extended version)", "comments": "USENIX Security'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic testing or fuzzing of embedded firmware is severely limited by\nhardware-dependence and poor scalability, partly contributing to the widespread\nvulnerable IoT devices. We propose a software framework that continuously\nexecutes a given firmware binary while channeling inputs from an off-the-shelf\nfuzzer, enabling hardware-independent and scalable firmware testing. Our\nframework, using a novel technique called P$^2$IM, abstracts diverse\nperipherals and handles firmware I/O on the fly based on automatically\ngenerated models. P$^2$IM is oblivious to peripheral designs and generic to\nfirmware implementations, and therefore, applicable to a wide range of embedded\ndevices. We evaluated our framework using 70 sample firmware and 10 firmware\nfrom real devices, including a drone, a robot, and a PLC. It successfully\nexecuted 79% of the sample firmware without any manual assistance. We also\nperformed a limited fuzzing test on the real firmware, which unveiled 7 unique\nunknown bugs.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 22:13:29 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 00:23:59 GMT"}, {"version": "v3", "created": "Thu, 26 Sep 2019 01:49:00 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Feng", "Bo", ""], ["Mera", "Alejandro", ""], ["Lu", "Long", ""]]}, {"id": "1909.06496", "submitter": "Saraju Mohanty", "authors": "Saraju P. Mohanty, Venkata P. Yanambaka, Elias Kougianos and Deepak\n  Puthal", "title": "PUFchain: Hardware-Assisted Blockchain for Sustainable Simultaneous\n  Device and Data Security in the Internet of Everything (IoE)", "comments": "37 pages, 22 figures, 6 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents the first-ever blockchain which can simultaneously\nhandle device and data security, which is important for the emerging\nInternet-of-Everything (IoE). This article presents a unique concept of\nblockchain that integrates hardware security primitives called Physical\nUnclonable Functions (PUFs) to solve scalability, latency, and energy\nrequirement challenges and is called PUFchain. Data management and security\n(and privacy) of data, devices, and individuals, are some of the issues in the\nIoE architectures that need to be resolved. Integrating the blockchain into the\nIoE environment can help solve these issues and helps in the aspects of data\nstorage and security. This article introduces a new blockchain architecture\ncalled PUFchain and introduces a new consensus algorithm called \"Proof of\nPUF-Enabled Authentication\" (PoP) for deployment in PUFchain. The proposed PoP\nis the PUF integration into our previously proposed Proof-of-Authentication\n(PoAh) consensus algorithm and can be called \"Hardware-Assisted\nProof-of-Authentication (HA-PoAh)\". However, PUF integration is possible in the\nexisting and new consensus algorithms. PoP utilizes PUFs which are responsible\nfor generating a unique key that cannot be cloned and hence provide the highest\nlevel of security. A PUF uses the nanoelectronic manufacturing variations that\nare introduced during the fabrication of an integrated circuit to generate the\nkeys. Hence, once generated from a PUF module, the keys cannot be cloned or\ngenerated from any other module. PUFchain uses a PUF and Hashing module which\nperforms the necessary cryptographic functions. Hence the mining process is\noffloaded to the hardware module which reduces the processing times. PoP is\napproximately 1,000X faster than the well-established Proof-of-Work (PoW) and\n5X faster than Proof-of-Authentication (PoAh).\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 00:58:39 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Mohanty", "Saraju P.", ""], ["Yanambaka", "Venkata P.", ""], ["Kougianos", "Elias", ""], ["Puthal", "Deepak", ""]]}, {"id": "1909.06535", "submitter": "Zhimin Gao", "authors": "Zhimin Gao, Lei Xu, Keshav Kasichainula, Lin Chen, Bogdan Carbunar,\n  Weidong Shi", "title": "Private and Atomic Exchange of Assets over Zero Knowledge Based Payment\n  Ledger", "comments": "Single column, 19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin brings a new type of digital currency that does not rely on a central\nsystem to maintain transactions. By benefiting from the concept of\ndecentralized ledger, users who do not know or trust each other can still\nconduct transactions in a peer-to-peer manner. Inspired by Bitcoin, other\ncryptocurrencies were invented in recent years such as Ethereum, Dash, Zcash,\nMonero, Grin, etc. Some of these focus on enhancing privacy for instance crypto\nnote or systems that apply the similar concept of encrypted notes used for\ntransactions to enhance privacy (e.g., Zcash, Monero). However, there are few\nmechanisms to support the exchange of privacy-enhanced notes or assets on the\nchain, and at the same time preserving the privacy of the exchange operations.\nExisting approaches for fair exchanges of assets with privacy mostly rely on\noff-chain/side-chain, escrow or centralized services. Thus, we propose a\nsolution that supports oblivious and privacy-protected fair exchange of crypto\nnotes or privacy enhanced crypto assets. The technology is demonstrated by\nextending zero-knowledge based crypto notes. To address \"privacy\" and\n\"multi-currency\", we build a new zero-knowledge proving system and extend note\nformat with new property to represent various types of tokenized assets or\ncryptocurrencies. By extending the payment protocol, exchange operations are\nrealized through privacy enhanced transactions (e.g., shielded transactions).\nBased on the possible scenarios during the exchange operation, we add new\nconstraints and conditions to the zero-knowledge proving system used for\nvalidating transactions publicly.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 05:14:26 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Gao", "Zhimin", ""], ["Xu", "Lei", ""], ["Kasichainula", "Keshav", ""], ["Chen", "Lin", ""], ["Carbunar", "Bogdan", ""], ["Shi", "Weidong", ""]]}, {"id": "1909.06543", "submitter": "Yiwei Sun", "authors": "Yiwei Sun, Suhang Wang, Xianfeng Tang, Tsung-Yu Hsieh, Vasant Honavar", "title": "Node Injection Attacks on Graphs via Reinforcement Learning", "comments": "Preprint, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world graph applications, such as advertisements and product\nrecommendations make profits based on accurately classify the label of the\nnodes. However, in such scenarios, there are high incentives for the\nadversaries to attack such graph to reduce the node classification performance.\nPrevious work on graph adversarial attacks focus on modifying existing graph\nstructures, which is infeasible in most real-world applications. In contrast,\nit is more practical to inject adversarial nodes into existing graphs, which\ncan also potentially reduce the performance of the classifier. In this paper,\nwe study the novel node injection poisoning attacks problem which aims to\npoison the graph. We describe a reinforcement learning based method, namely\nNIPA, to sequentially modify the adversarial information of the injected nodes.\nWe report the results of experiments using several benchmark data sets that\nshow the superior performance of the proposed method NIPA, relative to the\nexisting state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 06:35:22 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Sun", "Yiwei", ""], ["Wang", "Suhang", ""], ["Tang", "Xianfeng", ""], ["Hsieh", "Tsung-Yu", ""], ["Honavar", "Vasant", ""]]}, {"id": "1909.06587", "submitter": "Jun Zhao", "authors": "Jun Zhao, Jing Tang, Li Zengxiang, Huaxiong Wang, Kwok-Yan Lam,\n  Kaiping Xue", "title": "An Analysis of Blockchain Consistency in Asynchronous Networks: Deriving\n  a Neat Bound", "comments": "This paper appears in the Proceedings of IEEE International\n  Conference on Distributed Computing Systems (ICDCS) 2020. Please feel free to\n  contact us for questions or remarks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal analyses of blockchain protocols have received much attention\nrecently. Consistency results of Nakamoto's blockchain protocol are often\nexpressed in a quantity $c$, which denotes the expected number of network\ndelays before some block is mined. With $\\mu$ (resp., $\\nu$) denoting the\nfraction of computational power controlled by benign miners (resp., the\nadversary), where $\\mu + \\nu = 1$, we prove for the first time that to ensure\nthe consistency property of Nakamoto's blockchain protocol in an asynchronous\nnetwork, it suffices to have $c$ to be just slightly greater than\n$\\frac{2\\mu}{\\ln (\\mu/\\nu)}$. Such a result is both neater and stronger than\nexisting ones. In the proof, we formulate novel Markov chains which\ncharacterize the numbers of mined blocks in different rounds.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 12:43:53 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 14:59:35 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Zhao", "Jun", ""], ["Tang", "Jing", ""], ["Zengxiang", "Li", ""], ["Wang", "Huaxiong", ""], ["Lam", "Kwok-Yan", ""], ["Xue", "Kaiping", ""]]}, {"id": "1909.06605", "submitter": "Yi Li", "authors": "Haijun Wang and Yi Li and Shang-Wei Lin and Cyrille Artho and Lei Ma\n  and Yang Liu", "title": "Oracle-Supported Dynamic Exploit Generation for Smart Contracts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the high stakes involved in smart contracts, they are often developed\nin an undisciplined manner, leaving the security and reliability of blockchain\ntransactions at risk. In this paper, we introduce ContraMaster: an\noracle-supported dynamic exploit generation framework for smart contracts.\nExisting approaches mutate only single transactions; ContraMaster exceeds these\nby mutating the transaction sequences. ContraMaster uses data-flow,\ncontrol-flow, and the dynamic contract state to guide its mutations. It then\nmonitors the executions of target contract programs, and validates the results\nagainst a general-purpose semantic test oracle to discover vulnerabilities.\nBeing a dynamic technique, it guarantees that each discovered vulnerability is\na violation of the test oracle and is able to generate the attack script to\nexploit this vulnerability. In contrast to rule-based approaches, ContraMaster\nhas not shown any false positives, and it easily generalizes to unknown types\nof vulnerabilities (e.g., logic errors). We evaluate ContraMaster on 218\nvulnerable smart contracts. The experimental results confirm its practical\napplicability and advantages over the state-of-the-art techniques, and also\nreveal three new types of attacks.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 14:48:22 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 16:58:01 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Wang", "Haijun", ""], ["Li", "Yi", ""], ["Lin", "Shang-Wei", ""], ["Artho", "Cyrille", ""], ["Ma", "Lei", ""], ["Liu", "Yang", ""]]}, {"id": "1909.06767", "submitter": "Amir Pasha Motamed", "authors": "Amir Pasha Motamed, Behnam Bahrak", "title": "Quantitative analysis of cryptocurrencies transaction graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptocurrencies as a new way of transferring assets and securing financial\ntransactions have gained popularity in recent years. Transactions in\ncryptocurrencies are publicly available, hence, statistical studies on\ndifferent aspects of these currencies are possible. However, previous\nstatistical analysis on cryptocurrencies transactions have been very limited\nand mostly devoted to Bitcoin, with no comprehensive comparison between these\ncurrencies. In this study, we intend to compare the transaction graph of\nBitcoin, Ethereum, Litecoin, Dash, and Z-Cash, with respect to the dynamics of\ntheir transaction graphs over time, and discuss their properties. In\nparticular, we observed that the growth rate of the nodes and edges of the\ntransaction graphs, and the density of these graphs, are closely related to the\nprice of these currencies. We also found that the transaction graph of these\ncurrencies is non-assortative, and the degree sequence of their transaction\ngraph follows the power law distribution.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 09:13:50 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Motamed", "Amir Pasha", ""], ["Bahrak", "Behnam", ""]]}, {"id": "1909.06781", "submitter": "Sunil Kumar", "authors": "Sunil Kumar, Sandeep Kumar, Gaurav Mittal and Shiv Narain", "title": "A Vector Space Approach to Generate Dynamic Keys for Hill Cipher", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, a variant of the Hill cipher is proposed. In the classical\nHill cipher, an invertible matrix is used for encryption but the scheme is\nvulnerable to the known-plaintext attack which can reveal the matrix. In our\nproposed cryptosystem, each plaintext block is encrypted by a new invertible\nkey matrix that thwarts the known-plaintext attack. To generate the invertible\nmatrices which serve as the dynamic keys we make use of the vector spaces,\nrandomly generated basis and non-singular linear transformation. Resulting\ncipher is secure against the known-plaintext attack.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 11:21:03 GMT"}, {"version": "v2", "created": "Sun, 22 Sep 2019 17:22:54 GMT"}, {"version": "v3", "created": "Wed, 5 May 2021 08:50:32 GMT"}, {"version": "v4", "created": "Mon, 10 May 2021 18:18:50 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Kumar", "Sunil", ""], ["Kumar", "Sandeep", ""], ["Mittal", "Gaurav", ""], ["Narain", "Shiv", ""]]}, {"id": "1909.06865", "submitter": "Miles Q. Li", "authors": "Miles Q. Li, Benjamin C. M. Fung, Philippe Charland, Steven H.H. Ding", "title": "I-MAD: Interpretable Malware Detector Using Galaxy Transformer", "comments": "Published by Elsevier Computers & Security", "journal-ref": null, "doi": "10.1016/j.cose.2021.102371", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware currently presents a number of serious threats to computer users.\nSignature-based malware detection methods are limited in detecting new malware\nsamples that are significantly different from known ones. Therefore, machine\nlearning-based methods have been proposed, but there are two challenges these\nmethods face. The first is to model the full semantics behind the assembly code\nof malware. The second challenge is to provide interpretable results while\nkeeping excellent detection performance. In this paper, we propose an\nInterpretable MAlware Detector (I-MAD) that outperforms state-of-the-art static\nmalware detection models regarding accuracy with excellent interpretability. To\nimprove the detection performance, I-MAD incorporates a novel network component\ncalled the Galaxy Transformer network that can understand assembly code at the\nbasic block, function, and executable levels. It also incorporates our proposed\ninterpretable feed-forward neural network to provide interpretations for its\ndetection results by quantifying the impact of each feature with respect to the\nprediction. Experiment results show that our model significantly outperforms\nexisting state-of-the-art static malware detection models and presents\nmeaningful interpretations.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 19:40:38 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 14:37:26 GMT"}, {"version": "v3", "created": "Mon, 21 Jun 2021 01:33:26 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Li", "Miles Q.", ""], ["Fung", "Benjamin C. M.", ""], ["Charland", "Philippe", ""], ["Ding", "Steven H. H.", ""]]}, {"id": "1909.06890", "submitter": "Saar Tochner", "authors": "Saar Tochner, Stefan Schmid and Aviv Zohar", "title": "Hijacking Routes in Payment Channel Networks: A Predictability Tradeoff", "comments": "13 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT cs.MA cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-chain transaction networks can mitigate the scalability issues of today's\ntrustless electronic cash systems such as Bitcoin. However, these peer-to-peer\nnetworks also introduce a new attack surface which is not well-understood\ntoday. This paper identifies and analyzes, a novel Denial-of-Service attack\nwhich is based on route hijacking, i.e., which exploits the way transactions\nare routed and executed along the created channels of the network. This attack\nis conceptually interesting as even a limited attacker that manipulates the\ntopology through the creation of new channels can navigate tradeoffs related to\nthe way it attacks the network. Furthermore, the attack also highlights a\nfundamental design tradeoff for the defender (who determines its own routes):\nto become less predictable and hence secure, a rational node has to pay higher\nfees to nodes that forward its payments. We find that the three most common\nimplementations for payment channels in Bitcoin (lnd, C-lightning, Eclair)\napproach routing differently. We begin by surveying the current state of the\nLightning network and explore the routes chosen by these implementations. We\nfind that in the current network nearly 60\\% of all routes pass through only\nfive nodes, while 80\\% go through only 10 nodes. Thus, a relatively small\nnumber of colluding nodes can deny service to a large fraction of the network.\n  We then turn to study an external attacker who creates links to the network\nand draws more routes through its nodes by asking for lower fees. We find that\njust five new links are enough to draw the majority (65\\% - 75\\%) of the\ntraffic regardless of the implementation being used. The cost of creating these\nlinks is very low.\n  We discuss the differences between implementations and eventually derive our\nown suggested routing policy, which is based on a novel combination of existing\napproaches.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 21:34:59 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Tochner", "Saar", ""], ["Schmid", "Stefan", ""], ["Zohar", "Aviv", ""]]}, {"id": "1909.06961", "submitter": "Lingchen Zhao", "authors": "Lingchen Zhao, Qian Wang, Cong Wang, Qi Li, Chao Shen, Xiaodong Lin,\n  Shengshan Hu and Minxin Du", "title": "VeriML: Enabling Integrity Assurances and Fair Payments for Machine\n  Learning as a Service", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning as a Service (MLaaS) allows clients with limited resources\nto outsource their expensive ML tasks to powerful servers. Despite the huge\nbenefits, current MLaaS solutions still lack strong assurances on: 1) service\ncorrectness (i.e., whether the MLaaS works as expected); 2) trustworthy\naccounting (i.e., whether the bill for the MLaaS resource consumption is\ncorrectly accounted); 3) fair payment (i.e., whether a client gets the entire\nMLaaS result before making the payment). Without these assurances, unfaithful\nservice providers can return improperly-executed ML task results or partially\ntrained ML models while asking for over-claimed rewards. Moreover, it is hard\nto argue for wide adoption of MLaaS to both the client and the service\nprovider, especially in the open market without a trusted third party. In this\npaper, we present VeriML, a novel and efficient framework to bring integrity\nassurances and fair payments to MLaaS. With VeriML, clients can be assured that\nML tasks are correctly executed on an untrusted server and the resource\nconsumption claimed by the service provider equals to the actual workload. We\nstrategically use succinct non-interactive arguments of knowledge (SNARK) on\nrandomly-selected iterations during the ML training phase for efficiency with\ntunable probabilistic assurance. We also develop multiple ML-specific\noptimizations to the arithmetic circuit required by SNARK. Our system\nimplements six common algorithms: linear regression, logistic regression,\nneural network, support vector machine, Kmeans and decision tree. The\nexperimental results have validated the practical performance of VeriML.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 03:05:31 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Zhao", "Lingchen", ""], ["Wang", "Qian", ""], ["Wang", "Cong", ""], ["Li", "Qi", ""], ["Shen", "Chao", ""], ["Lin", "Xiaodong", ""], ["Hu", "Shengshan", ""], ["Du", "Minxin", ""]]}, {"id": "1909.07039", "submitter": "Ricardo Neisse", "authors": "Ricardo Neisse, Jos\\'e L. Hern\\'andez-Ramos, Sara N. Matheu, Gianmarco\n  Baldini and Antonio Skarmeta", "title": "Toward a Blockchain-based Platform to Manage Cybersecurity Certification\n  of IoT devices", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to propose a blockchain-based platform to enhance\ntransparency and traceability of cybersecurity certification information\nmotivated by the recently adopted EU Cybersecurity Act. The proposed platform\nis generic and intended to support the trusted exchange of cybersecurity\ncertification information for any electronic product, service, or process.\nHowever, for the purposes of this paper, we focus on the case study of the\ncybersecurity certification of IoT devices, which are explicitly referenced in\nthe recently adopted Cybersecurity Act as one of the main domains where it is\nhighlighted the need for an increased level of trust.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 07:42:58 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Neisse", "Ricardo", ""], ["Hern\u00e1ndez-Ramos", "Jos\u00e9 L.", ""], ["Matheu", "Sara N.", ""], ["Baldini", "Gianmarco", ""], ["Skarmeta", "Antonio", ""]]}, {"id": "1909.07099", "submitter": "Constantinos Patsakis", "authors": "Constantinos Patsakis, Fran Casino and Vasilios Katos", "title": "Encrypted and Covert DNS Queries for Botnets: Challenges and\n  Countermeasures", "comments": null, "journal-ref": null, "doi": "10.1016/j.cose.2019.101614", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a continuous increase in the sophistication that modern malware\nexercise in order to bypass the deployed security mechanisms. A typical\napproach to evade the identification and potential takedown of a botnet command\nand control server is domain fluxing through the use of Domain Generation\nAlgorithms (DGAs). These algorithms produce a vast amount of domain names that\nthe infected device tries to communicate with to find the C&C server, yet only\na small fragment of them is actually registered. This allows the botmaster to\npivot the control and make the work of seizing the botnet control rather\ndifficult.\n  Current state of the art and practice considers that the DNS queries\nperformed by a compromised device are transparent to the network administrator\nand therefore can be monitored, analysed, and blocked. In this work, we\nshowcase that the latter is a strong assumption as malware could efficiently\nhide its DNS queries using covert and/or encrypted channels bypassing the\ndetection mechanisms. To this end, we discuss possible mitigation measures\nbased on traffic analysis to address the new challenges that arise f\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 10:07:15 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Patsakis", "Constantinos", ""], ["Casino", "Fran", ""], ["Katos", "Vasilios", ""]]}, {"id": "1909.07220", "submitter": "Daniel Perez Hernandez", "authors": "Daniel Perez and Benjamin Livshits", "title": "Broken Metre: Attacking Resource Metering in EVM", "comments": "Published at Network and Distributed Systems Security (NDSS)\n  Symposium 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Blockchain systems, such as Ethereum, use an approach called \"metering\" to\nassign a cost to smart contract execution, an approach which is designed to\nincentivise miners to operate the network and protect it against DoS attacks.\nIn the past, the imperfections of Ethereum metering allowed several DoS attacks\nwhich were countered through modification of the metering mechanism.\n  This paper presents a new DoS attack on Ethereum which systematically\nexploits its metering mechanism. We first replay and analyse several months of\ntransactions, during which we discover a number of discrepancies in the\nmetering model, such as significant inconsistencies in the pricing of the\ninstructions. We further demonstrate that there is very little correlation\nbetween the execution cost and the utilised resources, such as CPU and memory.\nBased on these observations, we present a new type of DoS attack we call\nResource Exhaustion Attack, which uses these imperfections to generate\nlow-throughput contracts. To do this, we design a genetic algorithm that\ngenerates contracts with a throughput on average 200 times slower than typical\ncontracts. We then show that all major Ethereum client implementations are\nvulnerable and, if running on commodity hardware, would be unable to stay in\nsync with the network when under attack. We argue that such an attack could be\nfinancially attractive not only for Ethereum competitors and speculators, but\nalso for Ethereum miners. Finally, we discuss short-term and potential\nlong-term fixes against such attacks. Our attack has been responsibly disclosed\nto the Ethereum Foundation and awarded a bug bounty reward of 5,000 USD.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 14:14:50 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 14:50:33 GMT"}, {"version": "v3", "created": "Tue, 10 Mar 2020 01:56:20 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Perez", "Daniel", ""], ["Livshits", "Benjamin", ""]]}, {"id": "1909.07227", "submitter": "Phu H Phung", "authors": "Duc-Ly Vu, Trong-Kha Nguyen, Tam V. Nguyen, Tu N. Nguyen, Fabio\n  Massacci, and Phu H. Phung", "title": "A Convolutional Transformation Network for Malware Classification", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern malware evolves various detection avoidance techniques to bypass the\nstate-of-the-art detection methods. An emerging trend to deal with this issue\nis the combination of image transformation and machine learning techniques to\nclassify and detect malware. However, existing works in this field only perform\nsimple image transformation methods that limit the accuracy of the detection.\nIn this paper, we introduce a novel approach to classify malware by using a\ndeep network on images transformed from binary samples. In particular, we first\ndevelop a novel hybrid image transformation method to convert binaries into\ncolor images that convey the binary semantics. The images are trained by a deep\nconvolutional neural network that later classifies the test inputs into benign\nor malicious categories. Through the extensive experiments, our proposed method\nsurpasses all baselines and achieves 99.14% in terms of accuracy on the testing\nset.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 14:17:04 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Vu", "Duc-Ly", ""], ["Nguyen", "Trong-Kha", ""], ["Nguyen", "Tam V.", ""], ["Nguyen", "Tu N.", ""], ["Massacci", "Fabio", ""], ["Phung", "Phu H.", ""]]}, {"id": "1909.07426", "submitter": "Ayush Jain", "authors": "Ayush Jain, Ziqi Zhou and Ujjwal Guin", "title": "TAAL: Tampering Attack on Any Key-based Logic Locked Circuits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the globalization of semiconductor manufacturing and test processes,\nthe system-on-a-chip (SoC) designers no longer design the complete SoC and\nmanufacture chips on their own. This outsourcing of the design and\nmanufacturing of Integrated Circuits (ICs) has resulted in several threats,\nsuch as overproduction of ICs, sale of out-of-specification/rejected ICs, and\npiracy of Intellectual Properties (IPs). Logic locking has emerged as a\npromising defense strategy against these threats. However, various attacks\nabout the extraction of secret keys have undermined the security of logic\nlocking techniques. Over the years, researchers have proposed different\ntechniques to prevent existing attacks. In this paper, we propose a novel\nattack that can break any logic locking techniques that rely on the stored\nsecret key. This proposed TAAL attack is based on implanting a hardware Trojan\nin the netlist, which leaks the secret key to an adversary once activated. As\nan untrusted foundry can extract the netlist of a design from the layout/mask\ninformation, it is feasible to implement such a hardware Trojan. All three\nproposed types of TAAL attacks can be used for extracting secret keys. We have\nintroduced the models for both the combinational and sequential hardware\nTrojans that evade manufacturing tests. An adversary only needs to choose one\nhardware Trojan out of a large set of all possible Trojans to launch the TAAL\nattack.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 18:22:26 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 05:15:13 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Jain", "Ayush", ""], ["Zhou", "Ziqi", ""], ["Guin", "Ujjwal", ""]]}, {"id": "1909.07433", "submitter": "Clinton Ehrlich", "authors": "Clinton Ehrlich, Anna Guzova", "title": "KRNC: New Foundations for Permissionless Byzantine Consensus and Global\n  Monetary Stability", "comments": "104 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper applies biomimetic engineering to the problem of permissionless\nByzantine consensus and achieves results that surpass the prior state of the\nart by four orders of magnitude. It introduces a biologically inspired\nasymmetric Sybil-resistance mechanism, Proof-of-Balance, which can replace\nsymmetric Proof-of-Work and Proof-of-Stake weighting schemes.\n  The biomimetic mechanism is incorporated into a permissionless blockchain\nprotocol, Key Retroactivity Network Consensus (\"KRNC\"), which delivers ~40,000\ntimes the security and speed of today's decentralized ledgers. KRNC allows the\nfiat money that the public already owns to be upgraded with cryptographic\ninflation protection, eliminating the problems inherent in bootstrapping new\ncurrencies like Bitcoin and Ethereum.\n  The paper includes two independently significant contributions to the\nliterature. First, it replaces the non-structural axioms invoked in prior work\nwith a new formal method for reasoning about trust, liveness, and safety from\nfirst principles. Second, it demonstrates how two previously overlooked\nexploits, book-prize attacks and pseudo-transfer attacks, collectively\nundermine the security guarantees of all prior permissionless ledgers.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 18:43:35 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 20:15:13 GMT"}, {"version": "v3", "created": "Thu, 21 Nov 2019 02:05:55 GMT"}, {"version": "v4", "created": "Tue, 6 Oct 2020 03:55:55 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Ehrlich", "Clinton", ""], ["Guzova", "Anna", ""]]}, {"id": "1909.07438", "submitter": "Emil Pricop", "authors": "Emil Pricop", "title": "On the design of an innovative solution for increasing hazardous\n  materials transportation safety", "comments": "Paper presented at the 17th International Conference on System\n  Theory, Control and Computing (ICSTCC 2013), Sinaia, Romania - 11-13 October\n  2013", "journal-ref": "Proceedings of the 7th International Conference on System Theory,\n  Control and Computing (ICSTCC 2013)", "doi": "10.1109/ICSTCC.2013.6689029", "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transportation of hazardous materials represent a high risk operation all\nover the world. Flammable substances such as oil, kerosene, hydrocarbons,\nammonium nitrate or toxic products are shipped every day on busy roads by\ntrucks. An innovative solution for increasing hazardous materials\ntransportation safety is presented in this paper. The solution integrates three\nsystems: one mounted on the truck that can alert authorities in case of an\naccident, one portable system for quick identification of the carried\nsubstances and intervention method and a component for real-time road\nmonitoring. The proposed solution is based on RFID card with a special memory\nstructure presented in this paper\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 06:45:51 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Pricop", "Emil", ""]]}, {"id": "1909.07445", "submitter": "David Cerezo S\\'anchez", "authors": "David Cerezo S\\'anchez", "title": "Truthful and Faithful Monetary Policy for a Stablecoin Conducted by a\n  Decentralised, Encrypted Artificial Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.GT cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Holy Grail of a decentralised stablecoin is achieved on rigorous\nmathematical frameworks, obtaining multiple advantageous proofs: stability,\nconvergence, truthfulness, faithfulness, and malicious-security. These\nproperties could only be attained by the novel and interdisciplinary\ncombination of previously unrelated fields: model predictive control, deep\nlearning, alternating direction method of multipliers (consensus-ADMM),\nmechanism design, secure multi-party computation, and zero-knowledge proofs.\nFor the first time, this paper proves:\n  - the feasibility of decentralising the central bank while securely\npreserving its independence in a decentralised computation setting\n  - the benefits for price stability of combining mechanism design, provable\nsecurity, and control theory, unlike the heuristics of previous stablecoins\n  - the implementation of complex monetary policies on a stablecoin, equivalent\nto the ones used by central banks and beyond the current fixed rules of\ncryptocurrencies that hinder their price stability\n  - methods to circumvent the impossibilities of Guaranteed Output Delivery\n(G.O.D.) and fairness: standing on truthfulness and faithfulness, we reach\nG.O.D. and fairness under the assumption of rational parties\n  As a corollary, a decentralised artificial intelligence is able to conduct\nthe monetary policy of a stablecoin, minimising human intervention.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 19:28:26 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["S\u00e1nchez", "David Cerezo", ""]]}, {"id": "1909.07452", "submitter": "Paritosh Ramanan", "authors": "Paritosh Ramanan, Kiyoshi Nakayama", "title": "BAFFLE : Blockchain Based Aggregator Free Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key aspect of Federated Learning (FL) is the requirement of a centralized\naggregator to maintain and update the global model. However, in many cases\norchestrating a centralized aggregator might be infeasible due to numerous\noperational constraints. In this paper, we introduce BAFFLE, an aggregator\nfree, blockchain driven, FL environment that is inherently decentralized.\nBAFFLE leverages Smart Contracts (SC) to coordinate the round delineation,\nmodel aggregation and update tasks in FL. BAFFLE boosts computational\nperformance by decomposing the global parameter space into distinct chunks\nfollowed by a score and bid strategy. In order to characterize the performance\nof BAFFLE, we conduct experiments on a private Ethereum network and use the\ncentralized and aggregator driven methods as our benchmark. We show that BAFFLE\nsignificantly reduces the gas costs for FL on the blockchain as compared to a\ndirect adaptation of the aggregator based method. Our results also show that\nBAFFLE achieves high scalability and computational efficiency while delivering\nsimilar accuracy as the benchmark methods.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 19:47:26 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 23:00:13 GMT"}, {"version": "v3", "created": "Sun, 18 Oct 2020 17:57:29 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Ramanan", "Paritosh", ""], ["Nakayama", "Kiyoshi", ""]]}, {"id": "1909.07539", "submitter": "Tatsuya Mori Dr.", "authors": "Hiroaki Suzuki, Daiki Chiba, Yoshiro Yoneya, Tatsuya Mori, and Shigeki\n  Goto", "title": "ShamFinder: An Automated Framework for Detecting IDN Homographs", "comments": "16 pages, 12 figures, 14 tables. Proceedings of 19th ACM Internet\n  Measurement Conference (IMC 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The internationalized domain name (IDN) is a mechanism that enables us to use\nUnicode characters in domain names. The set of Unicode characters contains\nseveral pairs of characters that are visually identical with each other; e.g.,\nthe Latin character 'a' (U+0061) and Cyrillic character 'a' (U+0430). Visually\nidentical characters such as these are generally known as homoglyphs. IDN\nhomograph attacks, which are widely known, abuse Unicode homoglyphs to create\nlookalike URLs. Although the threat posed by IDN homograph attacks is not new,\nthe recent rise of IDN adoption in both domain name registries and web browsers\nhas resulted in the threat of these attacks becoming increasingly widespread,\nleading to large-scale phishing attacks such as those targeting cryptocurrency\nexchange companies. In this work, we developed a framework named \"ShamFinder,\"\nwhich is an automated scheme to detect IDN homographs. Our key contribution is\nthe automatic construction of a homoglyph database, which can be used for\ndirect countermeasures against the attack and to inform users about the context\nof an IDN homograph. Using the ShamFinder framework, we perform a large-scale\nmeasurement study that aims to understand the IDN homographs that exist in the\nwild. On the basis of our approach, we provide insights into an effective\ncounter-measure against the threats caused by the IDN homograph attack.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 01:16:25 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Suzuki", "Hiroaki", ""], ["Chiba", "Daiki", ""], ["Yoneya", "Yoshiro", ""], ["Mori", "Tatsuya", ""], ["Goto", "Shigeki", ""]]}, {"id": "1909.07568", "submitter": "Vishal Sharma", "authors": "Vishal Sharma, Jiyoon Kim, Yongho Ko, Ilsun You, Jung Taek Seo", "title": "An optimal security management framework for backhaul-aware 5G-Vehicle\n  to Everything (V2X)", "comments": "14 pages, 11 figures, 3 tables, Journal of Internet Technology (JIT)\n  (Accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cellular (C) setups facilitate the connectivity amongst the devices with\nbetter provisioning of services to its users. Vehicular networks are one of the\nrepresentative setups that aim at expanding their functionalities by using the\navailable cellular systems like Long Term Evolution (LTE)-based Evolved\nUniversal Terrestrial Radio Access Network (E-UTRAN) as well as the upcoming\nFifth Generation (5G)-based functional architecture. The vehicular networks\ninclude Vehicle to Vehicle (V2V), Vehicle to Infrastructure (V2I), Vehicle to\nPedestrian (V2P) and Vehicle to Network (V2N), all of which are referred to as\nVehicle to Everything (V2X). 5G has dominated the vehicular network and most of\nthe upcoming research is motivated towards the fully functional utilization of\n5G-V2X. Despite that, credential management and edge-initiated security are yet\nto be resolved under 5G-V2X. To further understand the issue, this paper\npresents security management as a principle of sustainability and\nkey-management. The performance tradeoff is evaluated with the key-updates\nrequired to maintain a secure connection between the vehicles and the\n5G-terminals. The proposed approach aims at the utilization of high-speed\nmmWave-based backhaul for enhancing the security operations between the core\nand the sub-divided functions at the edge of the network through a dual\nsecurity management framework. The evaluations are conducted using numerical\nsimulations, which help to understand the impact on the sustainability of\nconnections as well as identification of the fail-safe points for secure and\nfast operations. Furthermore, the evaluations help to follow the multiple\ntradeoffs of security and performance based on the metrics like mandatory key\nupdates, the range of operations and the probability of connectivity.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 03:17:19 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Sharma", "Vishal", ""], ["Kim", "Jiyoon", ""], ["Ko", "Yongho", ""], ["You", "Ilsun", ""], ["Seo", "Jung Taek", ""]]}, {"id": "1909.07630", "submitter": "Ateeq Sharfuddin", "authors": "Chris Balles and Ateeq Sharfuddin", "title": "Breaking Imphash", "comments": "5 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are numerous schemes to generically signature artifacts. We\nspecifically consider how to circumvent signatures based on imphash. Imphash is\nused to signature Portable Executable (PE) files and an imphash of a PE file is\nan MD5 digest over all the symbols that PE file imports. Imphash has been used\nin numerous cases to accurately tie a PE file seen in one environment to PE\nfiles in other environments, although each of these PE files' contents was\ndifferent. An argument made for imphash is that alteration of imphashes of\nderived PE file artifacts is unlikely since it is an expensive process, such\nthat you will need to either modify the source code and recompile or relink in\na different order. Nevertheless, we present a novel algorithm that generates\nderivative PE files such that its imphash is different from the original PE\nfile. This straightforward algorithm produces feasible solutions that defeat\napproaches relying on the impash algorithm to signature PE files.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 07:39:49 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Balles", "Chris", ""], ["Sharfuddin", "Ateeq", ""]]}, {"id": "1909.07632", "submitter": "Juncheng Shen", "authors": "Juncheng Shen, Juzheng Liu, Yiran Chen, Hai Li", "title": "Towards Efficient and Secure Delivery of Data for Deep Learning with\n  Privacy-Preserving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy recently emerges as a severe concern in deep learning, that is,\nsensitive data must be prohibited from being shared with the third party during\ndeep neural network development. In this paper, we propose Morphed Learning\n(MoLe), an efficient and secure scheme to deliver deep learning data. MoLe has\ntwo main components: data morphing and Augmented Convolutional (Aug-Conv)\nlayer. Data morphing allows data providers to send morphed data without privacy\ninformation, while Aug-Conv layer helps deep learning developers to apply their\nnetworks on the morphed data without performance penalty. MoLe provides\nstronger security while introducing lower overhead compared to GAZELLE (USENIX\nSecurity 2018), which is another method with no performance penalty on the\nneural network. When using MoLe for VGG-16 network on CIFAR dataset, the\ncomputational overhead is only 9% and the data transmission overhead is 5.12%.\nAs a comparison, GAZELLE has computational overhead of 10,000 times and data\ntransmission overhead of 421,000 times. In this setting, the attack success\nrate of adversary is 7.9 x 10^{-90} for MoLe and 2.9 x 10^{-30} for GAZELLE,\nrespectively.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 07:50:38 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Shen", "Juncheng", ""], ["Liu", "Juzheng", ""], ["Chen", "Yiran", ""], ["Li", "Hai", ""]]}, {"id": "1909.07637", "submitter": "Zhili Chen Prof.", "authors": "Yin Xu, Zhili Chen, Hong Zhong", "title": "Privacy-preserving Double Auction Mechanism Based on Homomorphic\n  Encryption and Sorting Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an effective resource allocation approach, double auctions (DAs) have been\nextensively studied in electronic commerce. Most previous studies have focused\non how to design strategy-proof DA mechanisms, while not much research effort\nhas been done concerning privacy and security issues. However, security,\nespecially privacy issues have become such a public concern that the European\ngovernments lay down the law to enforce the privacy guarantees recently. In\nthis paper, to address the privacy issue in electronic auctions, we concentrate\non how to design a privacy-preserving mechanism for double auctions by\nemploying Goldwasser-Micali homomorphic encryption and sorting networks. We\nachieve provable privacy such that the auctions do not reveal any bid\ninformation except the auction results, resulting in a strict privacy\nguarantee. Moreover, to achieve practical system performance, we compare\ndifferent sorting algorithms, and suggest using the faster ones. Experimental\nresults show that different sorting algorithms may have great effect on the\nperformance of our mechanism, and demonstrate the practicality of our protocol\nfor real-world applications in electronic commerce.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 07:58:17 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Xu", "Yin", ""], ["Chen", "Zhili", ""], ["Zhong", "Hong", ""]]}, {"id": "1909.07694", "submitter": "V\\'aclav Barto\\v{s}", "authors": "Vaclav Bartos, Martin Zadnik, Sheikh Mahbub Habib, Emmanouil\n  Vasilomanolakis", "title": "Network entity characterization and attack prediction", "comments": "30 pages, 8 figures", "journal-ref": "Future Generation Computer Systems 97 (2019) 674-686", "doi": "10.1016/j.future.2019.03.016", "report-no": null, "categories": "cs.CR cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The devastating effects of cyber-attacks, highlight the need for novel attack\ndetection and prevention techniques. Over the last years, considerable work has\nbeen done in the areas of attack detection as well as in collaborative defense.\nHowever, an analysis of the state of the art suggests that many challenges\nexist in prioritizing alert data and in studying the relation between a\nrecently discovered attack and the probability of it occurring again. In this\narticle, we propose a system that is intended for characterizing network\nentities and the likelihood that they will behave maliciously in the future.\nOur system, namely Network Entity Reputation Database System (NERDS), takes\ninto account all the available information regarding a network entity (e. g. IP\naddress) to calculate the probability that it will act maliciously. The latter\npart is achieved via the utilization of machine learning. Our experimental\nresults show that it is indeed possible to precisely estimate the probability\nof future attacks from each entity using information about its previous\nmalicious behavior and other characteristics. Ranking the entities by this\nprobability has practical applications in alert prioritization, assembly of\nhighly effective blacklists of a limited length and other use cases.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 10:12:55 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Bartos", "Vaclav", ""], ["Zadnik", "Martin", ""], ["Habib", "Sheikh Mahbub", ""], ["Vasilomanolakis", "Emmanouil", ""]]}, {"id": "1909.07814", "submitter": "Nishanth Chandran", "authors": "Nishant Kumar, Mayank Rathee, Nishanth Chandran, Divya Gupta, Aseem\n  Rastogi, and Rahul Sharma", "title": "CrypTFlow: Secure TensorFlow Inference", "comments": "To appear at 41st IEEE Symposium on Security and Privacy 2020. Code\n  available at: https://github.com/mpc-msri/EzPC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present CrypTFlow, a first of its kind system that converts TensorFlow\ninference code into Secure Multi-party Computation (MPC) protocols at the push\nof a button. To do this, we build three components. Our first component, Athos,\nis an end-to-end compiler from TensorFlow to a variety of semi-honest MPC\nprotocols. The second component, Porthos, is an improved semi-honest 3-party\nprotocol that provides significant speedups for TensorFlow like applications.\nFinally, to provide malicious secure MPC protocols, our third component,\nAramis, is a novel technique that uses hardware with integrity guarantees to\nconvert any semi-honest MPC protocol into an MPC protocol that provides\nmalicious security. The malicious security of the protocols output by Aramis\nrelies on integrity of the hardware and semi-honest security of MPC. Moreover,\nour system matches the inference accuracy of plaintext TensorFlow.\n  We experimentally demonstrate the power of our system by showing the secure\ninference of real-world neural networks such as ResNet50 and DenseNet121 over\nthe ImageNet dataset with running times of about 30 seconds for semi-honest\nsecurity and under two minutes for malicious security. Prior work in the area\nof secure inference has been limited to semi-honest security of small networks\nover tiny datasets such as MNIST or CIFAR. Even on MNIST/CIFAR, CrypTFlow\noutperforms prior work.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 03:55:05 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 02:13:56 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Kumar", "Nishant", ""], ["Rathee", "Mayank", ""], ["Chandran", "Nishanth", ""], ["Gupta", "Divya", ""], ["Rastogi", "Aseem", ""], ["Sharma", "Rahul", ""]]}, {"id": "1909.07821", "submitter": "Sheikh Ariful Islam", "authors": "Love Kumar Sah, Sheikh Ariful Islam, and Srinivas Katkoori", "title": "Variable Record Table: A Run-time Solution for Mitigating Buffer\n  Overflow Attack", "comments": "Accepted for publication in MWSCAS2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach to mitigate buffer overflow attack using Variable\nRecord Table (VRT). Dedicated memory space is used to automatically record base\nand bound information of variables extracted during runtime. We instrument\nframe pointer and function(s) related registers to decode variable memory space\nin stack and heap. We have modified Simplescalar/PISA simulator to extract\nvariables space of six (6) benchmark suites from MiBench. We have tested 290\nsmall C programs (MIT corpus suite) having 22 different buffer overflow\nvulnerabilities in stack and heap. Experimental results show that our approach\ncan detect buffer overflow attack with zero instruction overhead with the\nmemory space requirement up to 13Kb to maintain VRT for a program with 324\nvariables.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 14:01:01 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Sah", "Love Kumar", ""], ["Islam", "Sheikh Ariful", ""], ["Katkoori", "Srinivas", ""]]}, {"id": "1909.07830", "submitter": "Chee Seng Chan", "authors": "Lixin Fan, Kam Woh Ng, Chee Seng Chan", "title": "[Extended version] Rethinking Deep Neural Network Ownership\n  Verification: Embedding Passports to Defeat Ambiguity Attacks", "comments": "This paper is accepted by NeurIPS 2019; Our code is available at\n  https://github.com/kamwoh/DeepIPR. This is the extended version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With substantial amount of time, resources and human (team) efforts invested\nto explore and develop successful deep neural networks (DNN), there emerges an\nurgent need to protect these inventions from being illegally copied,\nredistributed, or abused without respecting the intellectual properties of\nlegitimate owners. Following recent progresses along this line, we investigate\na number of watermark-based DNN ownership verification methods in the face of\nambiguity attacks, which aim to cast doubts on the ownership verification by\nforging counterfeit watermarks. It is shown that ambiguity attacks pose serious\nthreats to existing DNN watermarking methods. As remedies to the\nabove-mentioned loophole, this paper proposes novel passport-based DNN\nownership verification schemes which are both robust to network modifications\nand resilient to ambiguity attacks. The gist of embedding digital passports is\nto design and train DNN models in a way such that, the DNN inference\nperformance of an original task will be significantly deteriorated due to\nforged passports. In other words, genuine passports are not only verified by\nlooking for the predefined signatures, but also reasserted by the unyielding\nDNN model inference performances. Extensive experimental results justify the\neffectiveness of the proposed passport-based DNN ownership verification\nschemes. Code and models are available at https://github.com/kamwoh/DeepIPR\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 13:48:08 GMT"}, {"version": "v2", "created": "Sat, 21 Sep 2019 10:28:38 GMT"}, {"version": "v3", "created": "Sat, 2 Nov 2019 16:03:32 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Fan", "Lixin", ""], ["Ng", "Kam Woh", ""], ["Chan", "Chee Seng", ""]]}, {"id": "1909.07866", "submitter": "Maximilian Bachl", "authors": "Maximilian Bachl, Alexander Hartl, Joachim Fabini, Tanja Zseby", "title": "Walling up Backdoors in Intrusion Detection Systems", "comments": null, "journal-ref": "3rd ACM CoNEXT Workshop on Big DAta, Machine Learning and\n  Artificial Intelligence for Data Communication Networks (Big-DAMA '19),\n  December 9, 2019, Orlando, FL, USA", "doi": "10.1145/3359992.3366638", "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Interest in poisoning attacks and backdoors recently resurfaced for Deep\nLearning (DL) applications. Several successful defense mechanisms have been\nrecently proposed for Convolutional Neural Networks (CNNs), for example in the\ncontext of autonomous driving. We show that visualization approaches can aid in\nidentifying a backdoor independent of the used classifier. Surprisingly, we\nfind that common defense mechanisms fail utterly to remove backdoors in DL for\nIntrusion Detection Systems (IDSs). Finally, we devise pruning-based approaches\nto remove backdoors for Decision Trees (DTs) and Random Forests (RFs) and\ndemonstrate their effectiveness for two different network security datasets.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 14:57:32 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 11:36:46 GMT"}, {"version": "v3", "created": "Sun, 5 Apr 2020 18:49:28 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Bachl", "Maximilian", ""], ["Hartl", "Alexander", ""], ["Fabini", "Joachim", ""], ["Zseby", "Tanja", ""]]}, {"id": "1909.07891", "submitter": "Sheikh Ariful Islam", "authors": "Vishalini R. Laguduva, Sheikh Ariful Islam, Sathyanarayanan Aakur,\n  Srinivas Katkoori and Robert Karam", "title": "Machine Learning based IoT Edge Node Security Attack and Countermeasures", "comments": "Accepted in ISVLSI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in technology have enabled tremendous progress in the development of\na highly connected ecosystem of ubiquitous computing devices collectively\ncalled the Internet of Things (IoT). Ensuring the security of IoT devices is a\nhigh priority due to the sensitive nature of the collected data. Physically\nUnclonable Functions (PUFs) have emerged as critical hardware primitive for\nensuring the security of IoT nodes. Malicious modeling of PUF architectures has\nproven to be difficult due to the inherently stochastic nature of PUF\narchitectures. Extant approaches to malicious PUF modeling assume that a priori\nknowledge and physical access to the PUF architecture is available for\nmalicious attack on the IoT node. However, many IoT networks make the\nunderlying assumption that the PUF architecture is sufficiently tamper-proof,\nboth physically and mathematically. In this work, we show that knowledge of the\nunderlying PUF structure is not necessary to clone a PUF. We present a novel\nnon-invasive, architecture independent, machine learning attack for strong PUF\ndesigns with a cloning accuracy of 93.5% and improvements of up to 48.31% over\nan alternative, two-stage brute force attack model. We also propose a\nmachine-learning based countermeasure, discriminator, which can distinguish\ncloned PUF devices and authentic PUFs with an average accuracy of 96.01%. The\nproposed discriminator can be used for rapidly authenticating millions of IoT\nnodes remotely from the cloud server.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 15:33:52 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Laguduva", "Vishalini R.", ""], ["Islam", "Sheikh Ariful", ""], ["Aakur", "Sathyanarayanan", ""], ["Katkoori", "Srinivas", ""], ["Karam", "Robert", ""]]}, {"id": "1909.07914", "submitter": "Yixin Zhang", "authors": "Yixin Zhang", "title": "Blockchain of Signature Material Combining Cryptographic Hash Function\n  and DNA Steganography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An ideal signature material and method, which can be used to prove the\nauthenticity of a physical item and against forgery, should be immune to the\nfast developments in digital and engineering technologies. Herein, the design\nof signature material combining cryptographic hash function and DNA\nsteganography is proposed. The encrypting materials are used to construct a\nseries of time-stamped records (blockchain) associated with published hash\nvalues, while each DNA-encrypted block is associated with a set of DNA keys.\nThe decrypted DNA information, as digital keys, can be validated through a hash\nfunction to compare with the published hash values. The blocks can also be\ncross-referenced among different related signatures. While both digital\ncryptography and DNA steganography can have large key size, automated brutal\nforce search is far more labor intensive and expensive for DNA steganography\nwith wet lab experiments, as compared to its digital counterpart. Moreover, the\ntime-stamped blockchain structure permits the incorporation of new\ncryptographic functions and DNA steganographies over time, thus can evolve over\ntime without losing the continuous history line.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 16:14:15 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Zhang", "Yixin", ""]]}, {"id": "1909.07917", "submitter": "Yinghua Hu", "authors": "Yinghua Hu and Vivek V. Menon and Andrew Schmidt and Joshua Monson and\n  Matthew French and Pierluigi Nuzzo", "title": "Toward Efficient Evaluation of Logic Encryption Schemes: Models and\n  Metrics", "comments": "This report is an extended version of \"Y. Hu, V. Venugopalan, A.\n  Schmidt, J. Monson, M. French, and P. Nuzzo. Security-driven metrics and\n  models for efficient evaluation of logic encryption schemes. In 2019 17th\n  ACM/IEEE International Conference on Formal Methods and Models for System\n  Design (MEMOCODE). ACM, 2019.\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in logic encryption over the last decade has resulted in various\ntechniques to prevent different security threats such as Trojan insertion,\nintellectual property leakage, and reverse engineering. However, there is\nlittle agreement on a uniform set of metrics and models to efficiently assess\nthe achieved security level and the trade-offs between security and overhead.\nThis paper addresses the above challenges by relying on a general logic\nencryption model that can encompass all the existing techniques, and a uniform\nset of metrics that can capture multiple, possibly conflicting, security\nconcerns. We apply our modeling approach to four state-of-the-art encryption\ntechniques, showing that it enables fast and accurate evaluation of design\ntrade-offs, average prediction errors that are at least 2X smaller than\nprevious approaches, and the evaluation of compound encryption methods.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 06:18:58 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 18:32:25 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Hu", "Yinghua", ""], ["Menon", "Vivek V.", ""], ["Schmidt", "Andrew", ""], ["Monson", "Joshua", ""], ["French", "Matthew", ""], ["Nuzzo", "Pierluigi", ""]]}, {"id": "1909.07918", "submitter": "Elisabet Lobo-Vesga", "authors": "Elisabet Lobo-Vesga (1), Alejandro Russo (1), Marco Gaboardi (2) ((1)\n  Chalmers University of Technology, (2) Boston University)", "title": "A Programming Framework for Differential Privacy with Accuracy\n  Concentration Bounds", "comments": "22 pages, 11 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy offers a formal framework for reasoning about privacy\nand accuracy of computations on private data. It also offers a rich set of\nbuilding blocks for constructing data analyses. When carefully calibrated,\nthese analyses simultaneously guarantee privacy of the individuals contributing\ntheir data, and accuracy of their results for inferring useful properties about\nthe population. The compositional nature of differential privacy has motivated\nthe design and implementation of several programming languages aimed at helping\na data analyst in programming differentially private analyses. However, most of\nthe programming languages for differential privacy proposed so far provide\nsupport for reasoning about privacy but not for reasoning about the accuracy of\ndata analyses. To overcome this limitation, in this work we present DPella, a\nprogramming framework providing data analysts with support for reasoning about\nprivacy, accuracy and their trade-offs. The distinguishing feature of DPella is\na novel component which statically tracks the accuracy of different data\nanalyses. In order to make tighter accuracy estimations, this component\nleverages taint analysis for automatically inferring statistical independence\nof the different noise quantities added for guaranteeing privacy. We show the\nflexibility of our approach by not only implementing classical counting queries\n(e.g., CDFs) but also by analyzing hierarchical counting queries (like those\ndone by Census Bureaus), where accuracy have different constraints per level\nand data analysts should figure out the best manner to calibrate privacy to\nmeet the accuracy requirements.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 20:29:08 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Lobo-Vesga", "Elisabet", ""], ["Russo", "Alejandro", ""], ["Gaboardi", "Marco", ""]]}, {"id": "1909.07969", "submitter": "Linda Senigagliesi", "authors": "Linda Senigagliesi, Marco Baldi, Ennio Gambi", "title": "Statistical and Machine Learning-based Decision Techniques for Physical\n  Layer Authentication", "comments": "To be presented at IEEE Globecom 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we assess the security performance of key-less physical layer\nauthentication schemes in the case of time-varying fading channels, considering\nboth partial and no channel state information (CSI) on the receiver's side. We\nfirst present a generalization of a well-known protocol previously proposed for\nflat fading channels and we study different statistical decision methods and\nthe corresponding optimal attack strategies in order to improve the\nauthentication performance in the considered scenario. We then consider the\napplication of machine learning techniques in the same setting, exploiting\ndifferent one-class nearest neighbor (OCNN) classification algorithms. We\nobserve that, under the same probability of false alarm, one-class\nclassification (OCC) algorithms achieve the lowest probability of missed\ndetection when a low spatial correlation exists between the main channel and\nthe adversary one, while statistical methods are advantageous when the spatial\ncorrelation between the two channels is higher.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 20:15:54 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Senigagliesi", "Linda", ""], ["Baldi", "Marco", ""], ["Gambi", "Ennio", ""]]}, {"id": "1909.08048", "submitter": "Rasheed Hussain", "authors": "Fatima Hussain and Rasheed Hussain and Brett Noye and Salah Sharieh", "title": "Enterprise API Security and GDPR Compliance: Design and Implementation\n  Perspective", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advancements in the enterprise-level business development, the\ndemand for new applications and services is overwhelming. For the development\nand delivery of such applications and services, enterprise businesses rely on\nApplication Programming Interfaces (APIs). In essence, API is a double-edged\nsword. On one hand, API provides ease of expanding the business through sharing\nvalue and utility, but on another hand it raises security and privacy issues.\nSince the applications usually use APIs to retrieve important data, therefore\nit is extremely important to make sure that an effective access control and\nsecurity mechanism are in place , and the data does not fall into wrong hands.\nIn this article, we discuss the current state of the enterprise API security\nand the role of Machine Learning (ML) in API security. We also discuss the\nGeneral Data Protection Regulation (GDPR) compliance and its effect on the API\nsecurity.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 19:36:12 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Hussain", "Fatima", ""], ["Hussain", "Rasheed", ""], ["Noye", "Brett", ""], ["Sharieh", "Salah", ""]]}, {"id": "1909.08063", "submitter": "Paul Patras", "authors": "Marco Cominelli and Paul Patras and Francesco Gringoli", "title": "Dead on Arrival: An Empirical Study of The Bluetooth 5.1 Positioning\n  System", "comments": "8 pages, 11 figures", "journal-ref": "ACM WiNTECH 2019", "doi": "10.1145/3349623.3355475", "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently released Bluetooth 5.1 specification introduces fine-grained\npositioning capabilities in this wireless technology, which is deemed essential\nto context-/location-based Internet of Things (IoT) applications. In this\npaper, we evaluate experimentally, for the first time, the accuracy of a\npositioning system based on the Angle of Arrival (AoA) mechanism adopted by the\nBluetooth standard. We first scrutinize the fidelity of angular detection and\nthen assess the feasibility of using angle information from multiple fixed\nreceivers to determine the position of a device. Our results reveal that\nangular detection is limited to a restricted range. On the other hand, even in\na simple deployment with only two antennas per receiver, the AoA-based\npositioning technique can achieve sub-meter accuracy; yet attaining\nlocalization within a few centimeters remains a difficult endeavor. We then\ndemonstrate that a malicious device may be able to easily alter the\ntruthfulness of the measured AoA, by tampering with the packet structure. To\ncounter this protocol weakness, we propose simple remedies that are missing in\nthe standard, but which can be adopted with little effort by manufacturers, to\nsecure the Bluetooth 5.1 positioning system.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 12:45:08 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Cominelli", "Marco", ""], ["Patras", "Paul", ""], ["Gringoli", "Francesco", ""]]}, {"id": "1909.08072", "submitter": "Han Xu", "authors": "Han Xu, Yao Ma, Haochen Liu, Debayan Deb, Hui Liu, Jiliang Tang, Anil\n  K. Jain", "title": "Adversarial Attacks and Defenses in Images, Graphs and Text: A Review", "comments": "survey, adversarial attacks, defenses", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN) have achieved unprecedented success in numerous\nmachine learning tasks in various domains. However, the existence of\nadversarial examples has raised concerns about applying deep learning to\nsafety-critical applications. As a result, we have witnessed increasing\ninterests in studying attack and defense mechanisms for DNN models on different\ndata types, such as images, graphs and text. Thus, it is necessary to provide a\nsystematic and comprehensive overview of the main threats of attacks and the\nsuccess of corresponding countermeasures. In this survey, we review the state\nof the art algorithms for generating adversarial examples and the\ncountermeasures against adversarial examples, for the three popular data types,\ni.e., images, graphs and text.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 20:07:23 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 15:58:43 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Xu", "Han", ""], ["Ma", "Yao", ""], ["Liu", "Haochen", ""], ["Deb", "Debayan", ""], ["Liu", "Hui", ""], ["Tang", "Jiliang", ""], ["Jain", "Anil K.", ""]]}, {"id": "1909.08168", "submitter": "Flavio Toffalini", "authors": "Alessandro Visintin, Flavio Toffalini, Mauro Conti, Jianying Zhou", "title": "SAFE^d: Self-Attestation For Networks of Heterogeneous Embedded Devices", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) is an emerging paradigm that allows to set large\nnetworks of small and independent devices. To ensure their integrity,\npractitioners employ so-called Remote Attestation (RA) schemes. Classic RA\nschemes require a central and powerful entity, called Verifier, that has mainly\ntwo duties: (i) it manages the entire process of attestation, and (ii) it\ncontains all the proofs for validating the devices' integrity. However, having\na central Verifier makes the network dependent upon an external entity and\nintroduces a single point of failure for security.\n  In this work, we propose SAFE^d: the first RA schema that allows a pair of\nIoT devices to validate their integrity without relying on an external\nVerifier. Our approach overcomes previous limitations by spreading the proofs\namong multiple IoT devices and using novel cryptographic mechanisms to ensure\nsecure communications. Moreover, the entire IoT network can collaboratively\nisolate tampered devices and recover missing proofs in case of anomalies. We\nevaluate our schema through an implementation for Raspberry Pi platform and a\nnetwork simulation. The results show that SAFE^d can detect infected devices\nand recover up to 99.9% of proofs in case of faults or attacks. Moreover, we\nmanaged to protect up to 10K devices with a logarithmic overhead on the network\nand on the devices' memory.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 02:03:36 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 13:52:07 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Visintin", "Alessandro", ""], ["Toffalini", "Flavio", ""], ["Conti", "Mauro", ""], ["Zhou", "Jianying", ""]]}, {"id": "1909.08331", "submitter": "Guozhen Hu", "authors": "Guozhen Hu, Baobin Li", "title": "Coupling Chaotic System Based on Unit Transform and Its Applications in\n  Image Encryption", "comments": "41 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chaotic maps are very important for establishing chaos-based image encryption\nsystems. This paper introduces a coupling chaotic system based on a certain\nunit transform, which can combine any two 1D chaotic maps to generate a new one\nwith excellent performance. The chaotic behavior analysis has verified this\ncoupling system's effectiveness and progress. In particular, we give a specific\nstrategy about selecting an appropriate unit transform function to enhance\nchaos of generated maps. Besides, a new chaos based pseudo-random number\ngenerator, shorted as CBPRNG, is designed to improve the distribution of\nchaotic sequences. We give a mathematical illustration on the uniformity of\nCBPRNG, and test the randomness of it. Moreover, based on CBPRNG, an image\nencryption algorithm is introduced. Simulation results and security analysis\nindicate that the proposed image encryption scheme is competitive with some\nadvanced existing methods.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 10:11:39 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Hu", "Guozhen", ""], ["Li", "Baobin", ""]]}, {"id": "1909.08347", "submitter": "Anselme Tueno", "authors": "Anselme Tueno, Florian Kerschbaum, Stefan Katzenbeisser, Yordan Boev,\n  Mubashir Qureshi", "title": "Secure Computation of the kth-Ranked Element in a Star Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of securely computing the kth-ranked element in a\nsequence of n private integers distributed among n parties. The kth-ranked\nelement (e.g., minimum, maximum, median) is of particular interest in\nbenchmarking, which allows a company to compare its own key performance\nindicator to the statistics of its peer group. The individual integers are\nsensitive data, yet the kth-ranked element is of mutual interest to the\nparties. Previous secure computation protocols for the kth-ranked element\nrequire a communication channel between each pair of parties. They do not scale\nto a large number of parties as they are highly interactive resulting in longer\ndelays. Moreover, they are difficult to deploy as special arrangements are\nrequired between each pair of parties to establish a secure connection. A\nserver model naturally fits with the client-server architecture of Internet\napplications in which clients are connected to the server and not to other\nclients. It can simplify secure computation by reducing the number of rounds,\nand as a result, improve its performance and scalability. In this model, there\nare communication channels only between each client and the server, while only\nclients provide inputs to the computation. Hence, it is a centralized\ncommunication pattern, i.e., a star network. We propose different approaches\nfor privately computing the kth-ranked element in the server model, using\neither garbled circuits or threshold homomorphic encryption. Our schemes have a\nconstant number of rounds and can compute the kth-ranked element within seconds\nfor up to 50 clients in a WAN.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 10:50:46 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Tueno", "Anselme", ""], ["Kerschbaum", "Florian", ""], ["Katzenbeisser", "Stefan", ""], ["Boev", "Yordan", ""], ["Qureshi", "Mubashir", ""]]}, {"id": "1909.08362", "submitter": "Anselme Tueno", "authors": "Anselme Tueno, Yordan Boev, Florian Kerschbaum", "title": "Non-Interactive Private Decision Tree Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision trees are a powerful prediction model with many applications in\nstatistics, data mining, and machine learning. In some settings, the model and\nthe data to be classified may contain sensitive information belonging to\ndifferent parties. In this paper, we, therefore, address the problem of\nprivately evaluating a decision tree on private data. This scenario consists of\na server holding a private decision tree model and a client interested in\nclassifying its private attribute vector using the server's private model. The\ngoal of the computation is to obtain the classification while preserving the\nprivacy of both - the decision tree and the client input. After the\ncomputation, the classification result is revealed only to the client, and\nnothing else is revealed neither to the client nor to the server. Existing\nprivacy-preserving protocols that address this problem use or combine different\ngeneric secure multiparty computation approaches resulting in several\ninteractions between the client and the server. Our goal is to design and\nimplement a novel client-server protocol that delegates the complete tree\nevaluation to the server while preserving privacy and reducing the overhead.\nThe idea is to use fully (somewhat) homomorphic encryption and evaluate the\ntree on ciphertexts encrypted under the client's public key. However, since\ncurrent somewhat homomorphic encryption schemes have high overhead, we combine\nefficient data representations with different algorithmic optimizations to keep\nthe computational overhead and the communication cost low. As a result, we are\nable to provide the first non-interactive protocol, that allows the client to\ndelegate the evaluation to the server by sending an encrypted input and\nreceiving only the encryption of the result. Our scheme has only one round and\ncan evaluate a complete tree of depth 10 within seconds.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 11:18:32 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Tueno", "Anselme", ""], ["Boev", "Yordan", ""], ["Kerschbaum", "Florian", ""]]}, {"id": "1909.08407", "submitter": "Wissam Aoudi", "authors": "Nasser Nowdehi, Wissam Aoudi, Magnus Almgren and Tomas Olovsson", "title": "CASAD: CAN-Aware Stealthy-Attack Detection for In-Vehicle Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, vehicles have complex in-vehicle networks (IVNs) with millions of\nlines of code controlling almost every function in the vehicle including\nsafety-critical functions. It has recently been shown that IVNs are becoming\nincreasingly vulnerable to cyber-attacks capable of taking control of vehicles,\nthereby threatening the safety of the passengers. Several countermeasures have\nbeen proposed in the literature in response to the arising threats, however,\nhurdle requirements imposed by the industry is hindering their adoption in\npractice. In particular, detecting attacks on IVNs is challenged by strict\nresource constraints and utterly complex communication patterns that vary even\nfor vehicles of the same model. In addition, existing solutions suffer from two\nmain drawbacks. First, they depend on the underlying vehicle configuration, and\nsecond, they are incapable of detecting certain attacks of a stealthy nature.\nIn this paper, we propose CASAD, a CAN-Aware Stealthy-Attack Detection\nmechanism that does not abide by the strict specifications predefined for every\nvehicle model and addresses key real-world deployability challenges. Our fast,\nlightweight, and system-agnostic approach learns the normal behavior of IVN\ndynamics from historical data and detects deviations by continuously monitoring\nIVN traffic. We demonstrate the effectiveness of CASAD by conducting various\nexperiments on a CAN bus prototype, a 2018 Volvo XC60, and publicly available\ndata from two real vehicles. Our approach is experimentally shown to be\neffective against different attack scenarios, including the prompt detection of\nstealthy attacks, and has considerable potential applicability to real\nvehicles.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 12:45:34 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Nowdehi", "Nasser", ""], ["Aoudi", "Wissam", ""], ["Almgren", "Magnus", ""], ["Olovsson", "Tomas", ""]]}, {"id": "1909.08500", "submitter": "Ranya Aloufi", "authors": "Ranya Aloufi, Hamed Haddadi, David Boyle", "title": "Emotion Filtering at the Edge", "comments": "6 pages, 6 figures, Sensys-ML19 workshop in conjunction with the 17th\n  ACM Conference on Embedded Networked Sensor Systems (SenSys 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CR cs.HC cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice controlled devices and services have become very popular in the\nconsumer IoT. Cloud-based speech analysis services extract information from\nvoice inputs using speech recognition techniques. Services providers can thus\nbuild very accurate profiles of users' demographic categories, personal\npreferences, emotional states, etc., and may therefore significantly compromise\ntheir privacy. To address this problem, we have developed a privacy-preserving\nintermediate layer between users and cloud services to sanitize voice input\ndirectly at edge devices. We use CycleGAN-based speech conversion to remove\nsensitive information from raw voice input signals before regenerating\nneutralized signals for forwarding. We implement and evaluate our emotion\nfiltering approach using a relatively cheap Raspberry Pi 4, and show that\nperformance accuracy is not compromised at the edge. In fact, signals generated\nat the edge differ only slightly (~0.16%) from cloud-based approaches for\nspeech recognition. Experimental evaluation of generated signals show that\nidentification of the emotional state of a speaker can be reduced by ~91%.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 15:28:12 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Aloufi", "Ranya", ""], ["Haddadi", "Hamed", ""], ["Boyle", "David", ""]]}, {"id": "1909.08526", "submitter": "Jinyuan Jia", "authors": "Jinyuan Jia and Neil Zhenqiang Gong", "title": "Defending against Machine Learning based Inference Attacks via\n  Adversarial Examples: Opportunities and Challenges", "comments": "Book chapter. arXiv admin note: substantial text overlap with\n  arXiv:1805.04810", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning (ML) becomes more and more powerful and easily\naccessible, attackers increasingly leverage ML to perform automated large-scale\ninference attacks in various domains. In such an ML-equipped inference attack,\nan attacker has access to some data (called public data) of an individual, a\nsoftware, or a system; and the attacker uses an ML classifier to automatically\ninfer their private data. Inference attacks pose severe privacy and security\nthreats to individuals and systems. Inference attacks are successful because\nprivate data are statistically correlated with public data, and ML classifiers\ncan capture such statistical correlations. In this chapter, we discuss the\nopportunities and challenges of defending against ML-equipped inference attacks\nvia adversarial examples. Our key observation is that attackers rely on ML\nclassifiers in inference attacks. The adversarial machine learning community\nhas demonstrated that ML classifiers have various vulnerabilities. Therefore,\nwe can turn the vulnerabilities of ML into defenses against inference attacks.\nFor example, ML classifiers are vulnerable to adversarial examples, which add\ncarefully crafted noise to normal examples such that an ML classifier makes\npredictions for the examples as we desire. To defend against inference attacks,\nwe can add carefully crafted noise into the public data to turn them into\nadversarial examples, such that attackers' classifiers make incorrect\npredictions for the private data. However, existing methods to construct\nadversarial examples are insufficient because they did not consider the unique\nchallenges and requirements for the crafted noise at defending against\ninference attacks. In this chapter, we take defending against inference attacks\nin online social networks as an example to illustrate the opportunities and\nchallenges.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 12:34:06 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 02:26:14 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Jia", "Jinyuan", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "1909.08535", "submitter": "Nektarios Koukourakis", "authors": "Stefan Rothe, Nektarios Koukourakis, Hannes Radner, Andrew Lonnstrom,\n  Eduard Jorswieck, and J\\\"urgen W. Czarske", "title": "Physical Layer Security in Multimode Fiber Optical Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse precoding algorithms in multimode fiber based communication networks\nare used to exploit mode dependent losses on the physical layer. This provides\nan asymmetry between legitimate (Bob) and unlegitimate (Eve) receiver of\nmessages resulting in a significant SNR advantage for Bob. In combination with\ndynamic mode channel changes, Eve has no chance to reconstruct a sent message\neven in a worst case scenario in which she is almighty. This is the first time,\nPhysical Layer Security in a fiber optical network is investigated on the basis\nof measured transmission matrices. These results show that messages can be sent\nsecurely with conventional communication techniques. Translating the task of\nsecuring data from software to hardware represents the potential of a\nscientific paradigm shift. The introduced technique is a step towards the\ndevelopment of cyber physical systems.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 11:10:27 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Rothe", "Stefan", ""], ["Koukourakis", "Nektarios", ""], ["Radner", "Hannes", ""], ["Lonnstrom", "Andrew", ""], ["Jorswieck", "Eduard", ""], ["Czarske", "J\u00fcrgen W.", ""]]}, {"id": "1909.08607", "submitter": "Thomas Hardjono", "authors": "Thomas Hardjono, Alexander Lipton, Alex Pentland", "title": "Towards a Public Key Management Framework for Virtual Assets and Virtual\n  Asset Service Providers", "comments": "33 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The recent FATF Recommendations defines virtual assets and virtual assets\nservice providers (VASP), and requires under the Travel Rule that originating\nVASPs obtain and hold required and accurate originator information and required\nbeneficiary information on virtual asset transfers. In this paper we discuss\nthe notion of key ownership evidence as a core part of originator and\nbeneficiary information required by the FATF Recommendation. We discuss\napproaches to securely communicate the originator and beneficiary information\nbetween VASPs, and review existing standards for public key certificates as\napplied to VASPs and virtual asset transfers. We propose the notion of a trust\nnetwork of VASPs in which originator and beneficiary information, including key\nownership information, can be exchanged securely while observing individual\nprivacy requirements.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 17:52:25 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Hardjono", "Thomas", ""], ["Lipton", "Alexander", ""], ["Pentland", "Alex", ""]]}, {"id": "1909.08703", "submitter": "Ioannis Agadakos", "authors": "Ioannis Agadakos and Nikolaos Agadakos and Jason Polakis and Mohamed\n  R. Amer", "title": "Deep Complex Networks for Protocol-Agnostic Radio Frequency Device\n  Fingerprinting in the Wild", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers have demonstrated various techniques for fingerprinting and\nidentifying devices. Previous approaches have identified devices from their\nnetwork traffic or transmitted signals while relying on software or operating\nsystem specific artifacts (e.g., predictability of protocol header fields) or\ncharacteristics of the underlying protocol (e.g.,frequency offset). As these\nconstraints can be a hindrance in real-world settings, we introduce a\npractical, generalizable approach that offers significant operational value for\na variety of scenarios, including as an additional factor of authentication for\npreventing impersonation attacks. Our goal is to identify artifacts in\ntransmitted signals that are caused by a device's unique hardware\n\"imperfections\" without any knowledge about the nature of the signal. We\ndevelop RF-DCN, a novel Deep Complex-valued Neural Network (DCN) that operates\non raw RF signals and is completely agnostic of the underlying applications and\nprotocols. We present two DCN variations: (i) Convolutional DCN (CDCN) for\nmodeling full signals, and (ii) Recurrent DCN (RDCN) for modeling time series.\nOur system handles raw I/Q data from open air captures within a given spectrum\nwindow, without knowledge of the modulation scheme or even the carrier\nfrequencies. While our experiments demonstrate the effectiveness of our system,\nespecially under challenging conditions where other neural network\narchitectures break down, we identify additional challenges in signal-based\nfingerprinting and provide guidelines for future explorations. Our work lays\nthe foundation for more research within this vast and challenging space by\nestablishing fundamental directions for using raw RF I/Q data in novel\ncomplex-valued networks.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 20:57:35 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Agadakos", "Ioannis", ""], ["Agadakos", "Nikolaos", ""], ["Polakis", "Jason", ""], ["Amer", "Mohamed R.", ""]]}, {"id": "1909.08719", "submitter": "Ranvir Rana", "authors": "Giulia Fanti, Jiantao Jiao, Ashok Makkuva, Sewoong Oh, Ranvir Rana,\n  Pramod Viswanath", "title": "Barracuda: The Power of $\\ell$-polling in Proof-of-Stake Blockchains", "comments": "ACM Mobihoc 2019, Best paper award", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A blockchain is a database of sequential events that is maintained by a\ndistributed group of nodes. A key consensus problem in blockchains is that of\ndetermining the next block (data element) in the sequence. Many blockchains\naddress this by electing a new node to propose each new block. The new block is\n(typically) appended to the tip of the proposer's local blockchain, and\nsubsequently broadcast to the rest of the network. Without network delay (or\nadversarial behavior), this procedure would give a perfect chain, since each\nproposer would have the same view of the blockchain. A major challenge in\npractice is forking. Due to network delays, a proposer may not yet have the\nmost recent block, and may, therefore, create a side chain that branches from\nthe middle of the main chain. Forking reduces throughput, since only one a\nsingle main chain can survive, and all other blocks are discarded. We propose a\nnew P2P protocol for blockchains called Barracuda, in which each proposer,\nprior to proposing a block, polls $\\ell$ other nodes for their local blocktree\ninformation. Under a stochastic network model, we prove that this lightweight\nprimitive improves throughput as if the entire network were a factor of $\\ell$\nfaster. We provide guidelines on how to implement Barracuda in practice,\nguaranteeing robustness against several real-world factors.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 21:43:24 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Fanti", "Giulia", ""], ["Jiao", "Jiantao", ""], ["Makkuva", "Ashok", ""], ["Oh", "Sewoong", ""], ["Rana", "Ranvir", ""], ["Viswanath", "Pramod", ""]]}, {"id": "1909.08725", "submitter": "Eric Ficke", "authors": "Eric Ficke, Kristin M. Schweitzer, Raymond M. Bateman, Shouhuai Xu", "title": "Analyzing Root Causes of Intrusion Detection False-Negatives:\n  Methodology and Case Study", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrusion Detection Systems (IDSs) are a necessary cyber defense mechanism.\nUnfortunately, their capability has fallen behind that of attackers. This\nmotivates us to improve our understanding of the root causes of their\nfalse-negatives. In this paper we make a first step towards the ultimate goal\nof drawing useful insights and principles that can guide the design of\nnext-generation IDSs. Specifically, we propose a methodology for analyzing the\nroot causes of IDS false-negatives and conduct a case study based on Snort and\na real-world dataset of cyber attacks. The case study allows us to draw useful\ninsights.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 22:16:20 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Ficke", "Eric", ""], ["Schweitzer", "Kristin M.", ""], ["Bateman", "Raymond M.", ""], ["Xu", "Shouhuai", ""]]}, {"id": "1909.08729", "submitter": "Han Wang", "authors": "Han Wang and Shangyu Xie and Yuan Hong", "title": "VideoDP: A Universal Platform for Video Analytics with Differential\n  Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive amounts of video data are ubiquitously generated in personal devices\nand dedicated video recording facilities. Analyzing such data would be\nextremely beneficial in real world (e.g., urban traffic analysis, pedestrian\nbehavior analysis, video surveillance). However, videos contain considerable\nsensitive information, such as human faces, identities and activities. Most of\nthe existing video sanitization techniques simply obfuscate the video by\ndetecting and blurring the region of interests (e.g., faces, vehicle plates,\nlocations and timestamps) without quantifying and bounding the privacy leakage\nin the sanitization. In this paper, to the best of our knowledge, we propose\nthe first differentially private video analytics platform (VideoDP) which\nflexibly supports different video analyses with rigorous privacy guarantee.\nDifferent from traditional noise-injection based differentially private\nmechanisms, given the input video, VideoDP randomly generates a utility-driven\nprivate video in which adding or removing any sensitive visual element (e.g.,\nhuman, object) does not significantly affect the output video. Then, different\nvideo analyses requested by untrusted video analysts can be flexibly performed\nover the utility-driven video while ensuring differential privacy. Finally, we\nconduct experiments on real videos, and the experimental results demonstrate\nthat our VideoDP effectively functions video analytics with good utility.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 22:36:40 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 16:47:47 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Wang", "Han", ""], ["Xie", "Shangyu", ""], ["Hong", "Yuan", ""]]}, {"id": "1909.08844", "submitter": "Vishal Sharma", "authors": "Gaurav Choudhary, Vishal Sharma", "title": "A Survey on the Security and the Evolution of Osmotic and Catalytic\n  Computing for 5G Networks", "comments": "34 pages, 7 tables, 7 figures, Published In 5G Enabled Secure\n  Wireless Networks, pp. 69-102. Springer, Cham, 2019", "journal-ref": "In 5G Enabled Secure Wireless Networks, pp. 69-102. Springer,\n  Cham, 2019", "doi": "10.1007/978-3-030-03508-2_3", "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 5G networks have the capability to provide high compatibility for the new\napplications, industries, and business models. These networks can tremendously\nimprove the quality of life by enabling various use cases that require high\ndata-rate, low latency, and continuous connectivity for applications pertaining\nto eHealth, automatic vehicles, smart cities, smart grid, and the Internet of\nThings (IoT). However, these applications need secure servicing as well as\nresource policing for effective network formations. There have been a lot of\nstudies, which emphasized the security aspects of 5G networks while focusing\nonly on the adaptability features of these networks. However, there is a gap in\nthe literature which particularly needs to follow recent computing paradigms as\nalternative mechanisms for the enhancement of security. To cover this, a\ndetailed description of the security for the 5G networks is presented in this\narticle along with the discussions on the evolution of osmotic and catalytic\ncomputing-based security modules. The taxonomy on the basis of security\nrequirements is presented, which also includes the comparison of the existing\nstate-of-the-art solutions. This article also provides a security model,\n\"CATMOSIS\", which idealizes the incorporation of security features on the basis\nof catalytic and osmotic computing in the 5G networks. Finally, various\nsecurity challenges and open issues are discussed to emphasize the works to\nfollow in this direction of research.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 08:10:54 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Choudhary", "Gaurav", ""], ["Sharma", "Vishal", ""]]}, {"id": "1909.08848", "submitter": "Anjith George", "authors": "Anjith George and Zohreh Mostaani and David Geissenbuhler and Olegs\n  Nikisins and Andre Anjos and Sebastien Marcel", "title": "Biometric Face Presentation Attack Detection with Multi-Channel\n  Convolutional Neural Network", "comments": "16 pages", "journal-ref": "IEEE Transactions on Information Forensics and Security, 2019", "doi": "10.1109/TIFS.2019.2916652", "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face recognition is a mainstream biometric authentication method. However,\nvulnerability to presentation attacks (a.k.a spoofing) limits its usability in\nunsupervised applications. Even though there are many methods available for\ntackling presentation attacks (PA), most of them fail to detect sophisticated\nattacks such as silicone masks. As the quality of presentation attack\ninstruments improves over time, achieving reliable PA detection with visual\nspectra alone remains very challenging. We argue that analysis in multiple\nchannels might help to address this issue. In this context, we propose a\nmulti-channel Convolutional Neural Network based approach for presentation\nattack detection (PAD). We also introduce the new Wide Multi-Channel\npresentation Attack (WMCA) database for face PAD which contains a wide variety\nof 2D and 3D presentation attacks for both impersonation and obfuscation\nattacks. Data from different channels such as color, depth, near-infrared and\nthermal are available to advance the research in face PAD. The proposed method\nwas compared with feature-based approaches and found to outperform the\nbaselines achieving an ACER of 0.3% on the introduced dataset. The database and\nthe software to reproduce the results are made available publicly.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 08:16:35 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["George", "Anjith", ""], ["Mostaani", "Zohreh", ""], ["Geissenbuhler", "David", ""], ["Nikisins", "Olegs", ""], ["Anjos", "Andre", ""], ["Marcel", "Sebastien", ""]]}, {"id": "1909.08864", "submitter": "Michael Smith", "authors": "Michael Thomas Smith, Kathrin Grosse, Michael Backes, Mauricio A\n  Alvarez", "title": "Adversarial Vulnerability Bounds for Gaussian Process Classification", "comments": "10 pages + 2 pages references + 7 pages of supplementary. 12 figures.\n  Submitted to AAAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) classification is increasingly used in safety-critical\nsystems. Protecting ML classifiers from adversarial examples is crucial. We\npropose that the main threat is that of an attacker perturbing a confidently\nclassified input to produce a confident misclassification. To protect against\nthis we devise an adversarial bound (AB) for a Gaussian process classifier,\nthat holds for the entire input domain, bounding the potential for any future\nadversarial method to cause such misclassification. This is a formal guarantee\nof robustness, not just an empirically derived result. We investigate how to\nconfigure the classifier to maximise the bound, including the use of a sparse\napproximation, leading to the method producing a practical, useful and provably\nrobust classifier, which we test using a variety of datasets.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 08:50:01 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Smith", "Michael Thomas", ""], ["Grosse", "Kathrin", ""], ["Backes", "Michael", ""], ["Alvarez", "Mauricio A", ""]]}, {"id": "1909.08901", "submitter": "Ankan Pal", "authors": "Daniele Di Tullio and Ankan Pal", "title": "A New Method for Geometric Interpretation of Elliptic Curve Discrete\n  Logarithm Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CG math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we intend to study the geometric meaning of the discrete\nlogarithm problem defined over an Elliptic Curve. The key idea is to reduce the\nElliptic Curve Discrete Logarithm Problem (EC-DLP) into a system of equations.\nThese equations arise from the interesection of quadric hypersurfaces in an\naffine space of lower dimension. In cryptography, this interpretation can be\nused to design attacks on EC-DLP. Presently, the best known attack algorithm\nhaving a sub-exponential time complexity is through the implementation of\nSummation Polynomials and Weil Descent. It is expected that the proposed\ngeometric interpretation can result in faster reduction of the problem into a\nsystem of equations. These overdetermined system of equations are hard to\nsolve. We have used F4 (Faugere) algorithms and got results for primes less\nthan 500,000. Quantum Algorithms can expedite the process of solving these\nover-determined system of equations. In the absence of fast algorithms for\ncomputing summation polynomials, we expect that this could be an alternative.\nWe do not claim that the proposed algorithm would be faster than Shor's\nalgorithm for breaking EC-DLP but this interpretation could be a candidate as\nan alternative to the 'summation polynomial attack' in the post-quantum era.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 10:13:07 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Di Tullio", "Daniele", ""], ["Pal", "Ankan", ""]]}, {"id": "1909.09047", "submitter": "Brian Powell", "authors": "Brian A. Powell", "title": "Detecting malicious logins as graph anomalies", "comments": "10 pages, 8 figures. Major revisions, expanded analysis", "journal-ref": "Journal of Information Security and Applications, 54, 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Authenticated lateral movement via compromised accounts is a common\nadversarial maneuver that is challenging to discover with signature- or\nrules-based intrusion detection systems. In this work a behavior-based approach\nto detecting malicious logins to novel systems indicative of lateral movement\nis presented, in which a user's historical login activity is used to build a\nmodel of putative \"normal\" behavior. This historical login activity is\nrepresented as a collection of daily login graphs, which encode authentications\namong accessed systems. Each system, or graph vertex, is described by a set of\ngraph centrality measures that characterize it and the local topology of its\nlogin graph. The unsupervised technique of non-negative matrix factorization is\nthen applied to this set of features to assign each vertex to a role that\nsummarizes how the system participates in logins. The reconstruction error\nquantifying how well each vertex fits into its role is then computed, and the\nstatistics of this error can be used to identify outlier vertices that\ncorrespond to systems involved in unusual logins. We test this technique with a\nsmall cohort of privileged accounts using real login data from an operational\nenterprise network. The ability of the method to identify malicious logins\namong normal activity is tested with simulated graphs of login activity\nrepresentative of adversarial lateral movement. We find that the method is\ngenerally successful at detecting a broad range of lateral movement for each\nuser, with false positive rates significantly lower than those resulting from\nalerts based solely on login novelty.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 15:28:59 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 01:04:45 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Powell", "Brian A.", ""]]}, {"id": "1909.09123", "submitter": "Richard Matovu", "authors": "Richard Matovu, Isaac Griswold-Steiner, Abdul Serwadda", "title": "Kinetic Song Comprehension: Deciphering Personal Listening Habits via\n  Phone Vibrations", "comments": "25 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Music is an expression of our identity, showing a significant correlation\nwith other personal traits, beliefs, and habits. If accessed by a malicious\nentity, an individual's music listening habits could be used to make critical\ninferences about the user. In this paper, we showcase an attack in which the\nvibrations propagated through a user's phone while playing music via its\nspeakers can be used to detect and classify songs.\n  Our attack shows that known songs can be detected with an accuracy of just\nunder 80%, while a corpus of 100 songs can be classified with an accuracy\ngreater than 80%. We investigate such questions under a wide variety of\nexperimental scenarios involving three surfaces and five phone speaker volumes.\nAlthough users can mitigate some of the risk by using a phone cover to dampen\nthe vibrations, we show that a sophisticated attacker could adapt the attack to\nstill classify songs with a decent accuracy.\n  This paper demonstrates a new way in which motion sensor data can be\nleveraged to intrude on user music preferences without their express\npermission. Whether this information is leveraged for financial gain or\npolitical purposes, our research makes a case for why more rigorous methods of\nprotecting user data should be utilized by companies, and if necessary,\nindividuals.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 17:52:56 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Matovu", "Richard", ""], ["Griswold-Steiner", "Isaac", ""], ["Serwadda", "Abdul", ""]]}, {"id": "1909.09147", "submitter": "Michael Smith", "authors": "Michael Thomas Smith, Mauricio A. Alvarez, Neil D. Lawrence", "title": "Differentially Private Regression and Classification with Sparse\n  Gaussian Processes", "comments": "26 pages, 6 figures. Submitted to JMLR 4th January, 2019 (in review)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A continuing challenge for machine learning is providing methods to perform\ncomputation on data while ensuring the data remains private. In this paper we\nbuild on the provable privacy guarantees of differential privacy which has been\ncombined with Gaussian processes through the previously published\n\\emph{cloaking method}. In this paper we solve several shortcomings of this\nmethod, starting with the problem of predictions in regions with low data\ndensity. We experiment with the use of inducing points to provide a sparse\napproximation and show that these can provide robust differential privacy in\noutlier areas and at higher dimensions. We then look at classification, and\nmodify the Laplace approximation approach to provide differentially private\npredictions. We then combine this with the sparse approximation and demonstrate\nthe capability to perform classification in high dimensions. We finally explore\nthe issue of hyperparameter selection and develop a method for their private\nselection. This paper and associated libraries provide a robust toolkit for\ncombining differential privacy and GPs in a practical manner.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 07:20:38 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Smith", "Michael Thomas", ""], ["Alvarez", "Mauricio A.", ""], ["Lawrence", "Neil D.", ""]]}, {"id": "1909.09294", "submitter": "Christopher Jelesnianski", "authors": "Christopher Jelesnianski, Jinwoo Yom, Changwoo Min, Yeongjin Jang", "title": "Making Code Re-randomization Practical with MARDU", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Defense techniques such as Data Execution Prevention (DEP) and Address Space\nLayout Randomization (ASLR) were the early role models preventing primitive\ncode injection and return-oriented programming (ROP) attacks. Notably, these\ntechniques did so in an elegant and utilitarian manner, keeping performance and\nscalability in the forefront, making them one of the few widely-adopted defense\ntechniques. As code re-use has evolved in complexity from JIT-ROP, to BROP and\ndata-only attacks, defense techniques seem to have tunneled on defending at all\ncosts, losing-their-way in pragmatic defense design. Some fail to provide\ncomprehensive coverage, being too narrow in scope, while others provide\nunrealistic overheads leaving users willing to take their chances to maintain\nperformance expectations.\n  We present Mardu, an on-demand system-wide re-randomization technique that\nimproves re-randomization and refocuses efforts to simultaneously embrace key\ncharacteristics of defense techniques: security, performance, and scalability.\nOur code sharing with diversification is achieved by implementing reactive and\nscalable, rather than continuous or one-time diversification while the use of\nhardware supported eXecute-only Memory (XoM) and shadow stack prevent memory\ndisclosure; entwining and enabling code sharing further minimizes needed\ntracking, patching costs, and memory overhead. Mardu's evaluation shows\nperformance and scalability to have low average overhead in both\ncompute-intensive (5.5% on SPEC) and real-world applications (4.4% on NGINX).\nWith this design, Mardu demonstrates that strong and scalable security\nguarantees are possible to achieve at a practical cost to encourage deployment.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 02:08:24 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Jelesnianski", "Christopher", ""], ["Yom", "Jinwoo", ""], ["Min", "Changwoo", ""], ["Jang", "Yeongjin", ""]]}, {"id": "1909.09472", "submitter": "Shengshan Hu", "authors": "Shengshan Hu, Chengjun Cai, Qian Wang, Cong Wang, Minghui Li, Zhibo\n  Wang, Dengpan Ye", "title": "Augmenting Encrypted Search: A Decentralized Service Realization with\n  Enforced Execution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Searchable symmetric encryption (SSE) allows the data owner to outsource an\nencrypted database to a remote server in a private manner while maintaining the\nability for selectively search. So far, most existing solutions focus on an\nhonest-but-curious server, while security designs against a malicious server\nhave not drawn enough attention. A few recent works have attempted to construct\nverifiable SSE that enables the data owner to verify the integrity of search\nresults. Nevertheless, these verification mechanisms are highly dependent on\nspecific SSE schemes, and fail to support complex queries. A general\nverification mechanism is desired that can be applied to all SSE schemes.\n  In this work, instead of concentrating on a central server, we explore the\npotential of the smart contract, an emerging blockchain-based decentralized\ntechnology, and construct decentralized SSE schemes where the data owner can\nreceive correct search results with assurance without worrying about potential\nwrongdoings of a malicious server. We study both public and private blockchain\nenvironments and propose two designs with a trade-off between security and\nefficiency. To better support practical applications, the multi-user setting of\nSSE is further investigated where the data owner allows authenticated users to\nsearch keywords in shared documents. We implement prototypes of our two designs\nand present experiments and evaluations to demonstrate the practicability of\nour decentralized SSE schemes.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 12:49:14 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Hu", "Shengshan", ""], ["Cai", "Chengjun", ""], ["Wang", "Qian", ""], ["Wang", "Cong", ""], ["Li", "Minghui", ""], ["Wang", "Zhibo", ""], ["Ye", "Dengpan", ""]]}, {"id": "1909.09567", "submitter": "Thorsten Wissmann", "authors": "Cristian Ene, Laurent Mounier, Marie-Laure Potet", "title": "Output-sensitive Information flow analysis", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 17, Issue 1 (February\n  12, 2021) lmcs:7172", "doi": null, "report-no": null, "categories": "cs.CR cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Constant-time programming is a countermeasure to prevent cache based attacks\nwhere programs should not perform memory accesses that depend on secrets. In\nsome cases this policy can be safely relaxed if one can prove that the program\ndoes not leak more information than the public outputs of the computation. We\npropose a novel approach for verifying constant-time programming based on a new\ninformation flow property, called output-sensitive noninterference.\nNoninterference states that a public observer cannot learn anything about the\nprivate data. Since real systems need to intentionally declassify some\ninformation, this property is too strong in practice. In order to take into\naccount public outputs we proceed as follows: instead of using complex explicit\ndeclassification policies, we partition variables in three sets: input, output\nand leakage variables. Then, we propose a typing system to statically check\nthat leakage variables do not leak more information about the secret inputs\nthan the public normal output. The novelty of our approach is that we track the\ndependence of leakage variables with respect not only to the initial values of\ninput variables (as in classical approaches for noninterference), but taking\nalso into account the final values of output variables. We adapted this\napproach to LLVM IR and we developed a prototype to verify LLVM\nimplementations.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 15:42:41 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 16:42:03 GMT"}, {"version": "v3", "created": "Thu, 17 Dec 2020 12:10:09 GMT"}, {"version": "v4", "created": "Sun, 24 Jan 2021 17:42:48 GMT"}, {"version": "v5", "created": "Thu, 11 Feb 2021 13:34:17 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Ene", "Cristian", ""], ["Mounier", "Laurent", ""], ["Potet", "Marie-Laure", ""]]}, {"id": "1909.09599", "submitter": "Ghada Dessouky", "authors": "Ghada Dessouky, Tommaso Frassetto, and Ahmad-Reza Sadeghi", "title": "HybCache: Hybrid Side-Channel-Resilient Caches for Trusted Execution\n  Environments", "comments": "Accepted on 18 June 2019 to appear in USENIX Security 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern multi-core processors share cache resources for maximum cache\nutilization and performance gains. However, this leaves the cache vulnerable to\nside-channel attacks, where timing differences in shared cache behavior are\nexploited to infer information on the victim's execution patterns, ultimately\nleaking private information. The root cause for these attacks is mutually\ndistrusting processes sharing cache entries and accessing them in a\ndeterministic manner. Various defenses against cache side-channel attacks have\nbeen proposed. However, they either degrade performance significantly, impose\nimpractical restrictions, or can only defeat certain classes of these attacks.\nMore importantly, they assume that side-channel-resilient caches are required\nfor the entire execution workload and do not allow to selectively enable the\nmitigation only for the security-critical portion of the workload. We present a\ngeneric mechanism for a flexible and soft partitioning of set-associative\ncaches and propose a hybrid cache architecture, called HybCache. HybCache can\nbe configured to selectively apply side-channel-resilient cache behavior only\nfor isolated execution domains, while providing the non-isolated execution with\nconventional cache behavior, capacity and performance. An isolation domain can\ninclude one or more processes, specific portions of code, or a Trusted\nExecution Environment. We show that, with minimal hardware modifications and\nkernel support, HybCache can provide side-channel-resilient cache only for\nisolated execution with a performance overhead of 3.5-5%, while incurring no\nperformance overhead for the remaining execution workload. We provide a\nsimulator-based and hardware implementation of HybCache to evaluate the\nperformance and area overheads, and show how it mitigates typical access-based\nand contention-based cache attacks.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 16:26:03 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Dessouky", "Ghada", ""], ["Frassetto", "Tommaso", ""], ["Sadeghi", "Ahmad-Reza", ""]]}, {"id": "1909.09630", "submitter": "Jonathan Ullman", "authors": "Albert Cheu and Adam Smith and Jonathan Ullman", "title": "Manipulation Attacks in Local Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local differential privacy is a widely studied restriction on distributed\nalgorithms that collect aggregates about sensitive user data, and is now\ndeployed in several large systems. We initiate a systematic study of a\nfundamental limitation of locally differentially private protocols: they are\nhighly vulnerable to adversarial manipulation. While any algorithm can be\nmanipulated by adversaries who lie about their inputs, we show that any\nnon-interactive locally differentially private protocol can be manipulated to a\nmuch greater extent. Namely, when the privacy level is high or the input domain\nis large, an attacker who controls a small fraction of the users in the\nprotocol can completely obscure the distribution of the users' inputs. We also\nshow that existing protocols differ greatly in their resistance to\nmanipulation, even when they offer the same accuracy guarantee with honest\nexecution. Our results suggest caution when deploying local differential\nprivacy and reinforce the importance of efficient cryptographic techniques for\nemulating mechanisms from central differential privacy in distributed settings.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 17:42:22 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Cheu", "Albert", ""], ["Smith", "Adam", ""], ["Ullman", "Jonathan", ""]]}, {"id": "1909.09697", "submitter": "Anirban Pathak", "authors": "Srikara S, Kishore Thapliyal and Anirban Pathak", "title": "Continuous variable direct secure quantum communication using Gaussian\n  states", "comments": "Continuous Variable protocols are designed for one-way and\n  controlled-two-way secure direct quantum communication using single-mode\n  squeezed coherent states", "journal-ref": "Quantum Information Processing (2020) 19:132", "doi": "10.1007/s11128-020-02627-3", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous variable one-way and controlled-two-way secure direct quantum\ncommunication schemes have been designed using Gaussian states. Specifically, a\nscheme for continuous variable quantum secure direct communication and another\nscheme for continuous variable controlled quantum dialogue are proposed using\nsingle-mode squeezed coherent states. The security of the proposed schemes\nagainst a set of attacks (e.g., Gaussian quantum cloning machine and intercept\nresend attacks) has been proved. Further, it is established that the proposed\nschemes do not require two-mode squeezed states which are essential for a set\nof existing proposals. The controlled two-way communication scheme is shown to\nbe very general in nature as it can be reduced to schemes for various\nrelatively simpler cryptographic tasks like controlled deterministic secure\ncommunication, quantum dialogue, quantum key distribution. In addition, it is\nbriefly discussed that the proposed schemes can provide us tools to design\nquantum cryptographic solutions for several socioeconomic problems.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 19:42:03 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 20:13:50 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["S", "Srikara", ""], ["Thapliyal", "Kishore", ""], ["Pathak", "Anirban", ""]]}, {"id": "1909.09731", "submitter": "M Sadegh Riazi", "authors": "M. Sadegh Riazi and Kim Laine and Blake Pelton and Wei Dai", "title": "HEAX: An Architecture for Computing on Encrypted Data", "comments": "To appear in proceedings of ACM ASPLOS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.AR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid increase in cloud computing, concerns surrounding data\nprivacy, security, and confidentiality also have been increased significantly.\nNot only cloud providers are susceptible to internal and external hacks, but\nalso in some scenarios, data owners cannot outsource the computation due to\nprivacy laws such as GDPR, HIPAA, or CCPA. Fully Homomorphic Encryption (FHE)\nis a groundbreaking invention in cryptography that, unlike traditional\ncryptosystems, enables computation on encrypted data without ever decrypting\nit. However, the most critical obstacle in deploying FHE at large-scale is the\nenormous computation overhead.\n  In this paper, we present HEAX, a novel hardware architecture for FHE that\nachieves unprecedented performance improvement. HEAX leverages multiple levels\nof parallelism, ranging from ciphertext-level to fine-grained modular\narithmetic level. Our first contribution is a new highly-parallelizable\narchitecture for number-theoretic transform (NTT) which can be of independent\ninterest as NTT is frequently used in many lattice-based cryptography systems.\nBuilding on top of NTT engine, we design a novel architecture for computation\non homomorphically encrypted data. We also introduce several techniques to\nenable an end-to-end, fully pipelined design as well as reducing on-chip memory\nconsumption. Our implementation on reconfigurable hardware demonstrates\n164-268x performance improvement for a wide range of FHE parameters.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 22:27:06 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 21:17:05 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Riazi", "M. Sadegh", ""], ["Laine", "Kim", ""], ["Pelton", "Blake", ""], ["Dai", "Wei", ""]]}, {"id": "1909.09735", "submitter": "Ahmed Abusnaina", "authors": "Aminollah Khormali, Ahmed Abusnaina, Songqing Chen, DaeHun Nyang, Aziz\n  Mohaisen", "title": "COPYCAT: Practical Adversarial Attacks on Visualization-Based Malware\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite many attempts, the state-of-the-art of adversarial machine learning\non malware detection systems generally yield unexecutable samples. In this\nwork, we set out to examine the robustness of visualization-based malware\ndetection system against adversarial examples (AEs) that not only are able to\nfool the model, but also maintain the executability of the original input. As\nsuch, we first investigate the application of existing off-the-shelf\nadversarial attack approaches on malware detection systems through which we\nfound that those approaches do not necessarily maintain the functionality of\nthe original inputs. Therefore, we proposed an approach to generate adversarial\nexamples, COPYCAT, which is specifically designed for malware detection systems\nconsidering two main goals; achieving a high misclassification rate and\nmaintaining the executability and functionality of the original input. We\ndesigned two main configurations for COPYCAT, namely AE padding and sample\ninjection. While the first configuration results in untargeted\nmisclassification attacks, the sample injection configuration is able to force\nthe model to generate a targeted output, which is highly desirable in the\nmalware attribution setting. We evaluate the performance of COPYCAT through an\nextensive set of experiments on two malware datasets, and report that we were\nable to generate adversarial samples that are misclassified at a rate of 98.9%\nand 96.5% with Windows and IoT binary datasets, respectively, outperforming the\nmisclassification rates in the literature. Most importantly, we report that\nthose AEs were executable unlike AEs generated by off-the-shelf approaches. Our\ntransferability study demonstrates that the generated AEs through our proposed\nmethod can be generalized to other models.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 22:40:33 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Khormali", "Aminollah", ""], ["Abusnaina", "Ahmed", ""], ["Chen", "Songqing", ""], ["Nyang", "DaeHun", ""], ["Mohaisen", "Aziz", ""]]}, {"id": "1909.09804", "submitter": "Mengyao Zheng", "authors": "Mengyao Zheng, Dixing Xu, Linshan Jiang, Chaojie Gu, Rui Tan, Peng\n  Cheng", "title": "Challenges of Privacy-Preserving Machine Learning in IoT", "comments": "In First International Workshop on Challenges in Artificial\n  Intelligence and Machine Learning (AIChallengeIoT'19) November 10-13, 2019. 7\n  pages", "journal-ref": null, "doi": "10.1145/3363347.3363357", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) will be a main data generation infrastructure\nfor achieving better system intelligence. However, the extensive data\ncollection and processing in IoT also engender various privacy concerns. This\npaper provides a taxonomy of the existing privacy-preserving machine learning\napproaches developed in the context of cloud computing and discusses the\nchallenges of applying them in the context of IoT. Moreover, we present a\nprivacy-preserving inference approach that runs a lightweight neural network at\nIoT objects to obfuscate the data before transmission and a deep neural network\nin the cloud to classify the obfuscated data. Evaluation based on the MNIST\ndataset shows satisfactory performance.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 10:12:48 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Zheng", "Mengyao", ""], ["Xu", "Dixing", ""], ["Jiang", "Linshan", ""], ["Gu", "Chaojie", ""], ["Tan", "Rui", ""], ["Cheng", "Peng", ""]]}, {"id": "1909.09836", "submitter": "Dana Yang", "authors": "Jiaming Xu, Kuang Xu and Dana Yang", "title": "Optimal query complexity for private sequential learning against\n  eavesdropping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the query complexity of a learner-private sequential learning\nproblem, motivated by the privacy and security concerns due to eavesdropping\nthat arise in practical applications such as pricing and Federated Learning. A\nlearner tries to estimate an unknown scalar value, by sequentially querying an\nexternal database and receiving binary responses; meanwhile, a third-party\nadversary observes the learner's queries but not the responses. The learner's\ngoal is to design a querying strategy with the minimum number of queries\n(optimal query complexity) so that she can accurately estimate the true value,\nwhile the eavesdropping adversary even with the complete knowledge of her\nquerying strategy cannot.\n  We develop new querying strategies and analytical techniques and use them to\nprove tight upper and lower bounds on the optimal query complexity. The bounds\nalmost match across the entire parameter range, substantially improving upon\nexisting results. We thus obtain a complete picture of the optimal query\ncomplexity as a function of the estimation accuracy and the desired levels of\nprivacy. We also extend the results to sequential learning models in higher\ndimensions, and where the binary responses are noisy. Our analysis leverages a\ncrucial insight into the nature of private learning problem, which suggests\nthat the query trajectory of an optimal learner can be divided into distinct\nphases that focus on pure learning versus learning and obfuscation,\nrespectively.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 14:39:02 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 00:28:08 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Xu", "Jiaming", ""], ["Xu", "Kuang", ""], ["Yang", "Dana", ""]]}, {"id": "1909.09848", "submitter": "Danny Yuxing Huang", "authors": "Danny Yuxing Huang, Noah Apthorpe, Gunes Acar, Frank Li, Nick Feamster", "title": "IoT Inspector: Crowdsourcing Labeled Network Traffic from Smart Home\n  Devices at Scale", "comments": null, "journal-ref": "Proceedings of the ACM on Interactive, Mobile, Wearable and\n  Ubiquitous Technologies. Volume 4, Issue 2, Article 46. June 2020", "doi": "10.1145/3397333", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of smart home devices has created new opportunities for\nempirical research in ubiquitous computing, ranging from security and privacy\nto personal health. Yet, data from smart home deployments are hard to come by,\nand existing empirical studies of smart home devices typically involve only a\nsmall number of devices in lab settings. To contribute to data-driven smart\nhome research, we crowdsource the largest known dataset of labeled network\ntraffic from smart home devices from within real-world home networks. To do so,\nwe developed and released IoT Inspector, an open-source tool that allows users\nto observe the traffic from smart home devices on their own home networks.\nSince April 2019, 4,322 users have installed IoT Inspector, allowing us to\ncollect labeled network traffic from 44,956 smart home devices across 13\ncategories and 53 vendors. We demonstrate how this data enables new research\ninto smart homes through two case studies focused on security and privacy.\nFirst, we find that many device vendors use outdated TLS versions and advertise\nweak ciphers. Second, we discover about 350 distinct third-party advertiser and\ntracking domains on smart TVs. We also highlight other research areas, such as\nnetwork management and healthcare, that can take advantage of IoT Inspector's\ndataset. To facilitate future reproducible research in smart homes, we will\nrelease the IoT Inspector data to the public.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 15:57:09 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Huang", "Danny Yuxing", ""], ["Apthorpe", "Noah", ""], ["Acar", "Gunes", ""], ["Li", "Frank", ""], ["Feamster", "Nick", ""]]}, {"id": "1909.09904", "submitter": "Hadi Ahmadi", "authors": "Hadi Ahmadi and Derek Small", "title": "Graph Model Implementation of Attribute-Based Access Control Policies", "comments": "20 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Attribute-based access control (ABAC) promises a powerful way of formalizing\naccess policies in support of a wide range of access management scenarios.\nEfficient implementation of ABAC in its general form is still a challenge,\nespecially when addressing the complexity of privacy regulations and access\nmanagement required to support the explosive growth of social and IoT networks.\nIn this paper, we introduce a graph model implementation for expressing and\nevaluating access policies and illustrate a sample use-case implementation over\nNeo4 Graph Database. Graph databases excel at querying connected data and hence\ncan evaluate complex policies efficiently via graph traversal algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 21:41:02 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Ahmadi", "Hadi", ""], ["Small", "Derek", ""]]}, {"id": "1909.09925", "submitter": "Andrey Kuehlkamp", "authors": "Evan Brinckman, Andrey Kuehlkamp, Jarek Nabrzyski, Ian J. Taylor", "title": "Techniques and Applications for Crawling, Ingesting and Analyzing\n  Blockchain Data", "comments": "Manuscript accepted for publication at ICTC 2019 (ictc.org)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the public Ethereum network surpasses half a billion transactions and\nenterprise Blockchain systems becoming highly capable of meeting the demands of\nglobal deployments, production Blockchain applications are fast becoming\ncommonplace across a diverse range of business and scientific verticals. In\nthis paper, we reflect on work we have been conducting recently surrounding the\ningestion, retrieval and analysis of Blockchain data. We describe the scaling\nand semantic challenges when extracting Blockchain data in a way that preserves\nthe original metadata of each transaction by cross referencing the Smart\nContract interface with the on-chain data. We then discuss a scientific use\ncase in the area of Scientific workflows by describing how we can harvest data\nfrom tasks and dependencies in a generic way. We then discuss how crawled\npublic blockchain data can be analyzed using two unsupervised machine learning\nalgorithms, which are designed to identify outlier accounts or smart contracts\nin the system. We compare and contrast the two machine learning methods and\ncross correlate with public Websites to illustrate the effectiveness such\napproaches.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 01:38:08 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Brinckman", "Evan", ""], ["Kuehlkamp", "Andrey", ""], ["Nabrzyski", "Jarek", ""], ["Taylor", "Ian J.", ""]]}, {"id": "1909.09936", "submitter": "Mayra Samaniego Mrs", "authors": "Mayra Samaniego, Ralph Deters", "title": "Pushing Software-Defined Blockchain Components onto Edge Hosts", "comments": "Proceedings of the 52nd Hawaii International Conference on System\n  Sciences. 2019", "journal-ref": null, "doi": "10.24251/HICSS.2019.849", "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of blockchain technology, some management tasks of IoT\nnetworks can be moved from central systems to distributed validation\nauthorities. Cloud-centric blockchain implementations for IoT have shown\nsatisfactory performance. However, some features of blockchain are not\nnecessary for IoT. For instance, a competitive consensus. This research\npresents the idea of customizing and encapsulating the features of blockchain\ninto software-defined components to host them on edge devices. Thus, blockchain\nresources can be provisioned by edge devices (e-miners) working together closer\nto the things layer in a cooperative manner. This research uses Edison SoC as\ne-miners to test the software-defined blockchain components.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 04:00:21 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Samaniego", "Mayra", ""], ["Deters", "Ralph", ""]]}, {"id": "1909.09938", "submitter": "Saurabh Bagchi", "authors": "Jinkyu Koo, Michael Roth and Saurabh Bagchi", "title": "HAWKEYE: Adversarial Example Detector for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples (AEs) are images that can mislead deep neural network\n(DNN) classifiers via introducing slight perturbations into original images.\nRecent work has shown that detecting AEs can be more effective against AEs than\npreventing them from being generated. However, the state-of-the-art AE\ndetection still shows a high false positive rate, thereby rejecting a\nconsiderable amount of normal images. To address this issue, we propose\nHAWKEYE, which is a separate neural network that analyzes the output layer of\nthe DNN, and detects AEs. HAWKEYE's AE detector utilizes a quantized version of\nan input image as a reference, and is trained to distinguish the variation\ncharacteristics of the DNN output on an input image from the DNN output on its\nreference image. We also show that cascading our AE detectors that are trained\nfor different quantization step sizes can drastically reduce a false positive\nrate, while keeping a detection rate high.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 04:19:33 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Koo", "Jinkyu", ""], ["Roth", "Michael", ""], ["Bagchi", "Saurabh", ""]]}, {"id": "1909.09942", "submitter": "Shujun Li", "authors": "Yang Lu, Shujun Li, Athina Ioannou and Iis Tussyadiah", "title": "From Data Disclosure to Privacy Nudges: A Privacy-aware and User-centric\n  Personal Data Management Framework", "comments": "18 pages, 6 figures, accepted to DependSys 2019 (5th International\n  Conference on Dependability in Sensor, Cloud, and Big Data Systems and\n  Applications), to be held from November 12-15, 2019 in Guangzhou, China, to\n  be published in a volume of Communications in Computer and Information\n  Science by Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.HC cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Although there are privacy-enhancing tools designed to protect users' online\nprivacy, it is surprising to see a lack of user-centric solutions allowing\nprivacy control based on the joint assessment of privacy risks and benefits,\ndue to data disclosure to multiple platforms. In this paper, we propose a\nconceptual framework to fill the gap: aiming at the user-centric privacy\nprotection, we show the framework can not only assess privacy risks in using\nonline services but also the added values earned from data disclosure. Through\nfollowing a human-in-the-loop approach, it is expected the framework provides a\npersonalized solution via preference learning, continuous privacy assessment,\nbehavior monitoring and nudging. Finally, we describe a case study towards\n\"leisure travelers\" and several future areas to be studied in the ongoing\nproject.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 05:55:56 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Lu", "Yang", ""], ["Li", "Shujun", ""], ["Ioannou", "Athina", ""], ["Tussyadiah", "Iis", ""]]}, {"id": "1909.10057", "submitter": "Sanjay Madria", "authors": "Ayan Roy and Sanjay Madria", "title": "Secured Traffic Monitoring in VANET", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicular Ad hoc Networks (VANETs) facilitate vehicles to wirelessly\ncommunicate with neighboring vehicles as well as with roadside units (RSUs).\nHowever, the existence of inaccurate information within the network can cause\ntraffic aberrations and also disrupt the normal functioning of any traffic\nmonitoring system. Thus, determining the credibility of broadcast messages\noriginating from the region of interest (ROI) is crucial under a malicious\nenvironment. Additionally, a breach of privacy involving a vehicle's private\ninformation, such as location and velocity, can lead to severe consequences\nlike unauthorized tracking and masquerading attack. Thus, we propose an edge\ncloud based privacy-preserving secured decision making model that employs a\nheuristic based on vehicular data such as GPS location and velocity to\nauthenticate traffic-related information from the ROI under different traffic\nscenarios such as congestion. The effectiveness of the proposed model has been\nvalidated using VENTOS, SUMO, and Omnet++ simulators, and also by using a\nsimulated cloud environment. We compare our proposed model to the existing\npeer-based authentication model, the majority voting model, and the\nreputation-based system under different attack scenarios. We show that our\nmodel is capable of filtering malicious vehicles effectively and provide\naccurate traffic information under the presence of at least one non-malicious\nvehicle within the ROI.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 18:08:59 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 02:29:35 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Roy", "Ayan", ""], ["Madria", "Sanjay", ""]]}, {"id": "1909.10278", "submitter": "Daniel Lerch Hostalot PhD", "authors": "Daniel Lerch-Hostalot, David Meg\\'ias", "title": "Detection of Classifier Inconsistencies in Image Steganalysis", "comments": null, "journal-ref": null, "doi": "10.1145/3335203.3335738", "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a methodology to detect inconsistencies in\nclassification-based image steganalysis is presented. The proposed approach\nuses two classifiers: the usual one, trained with a set formed by cover and\nstego images, and a second classifier trained with the set obtained after\nembedding additional random messages into the original training set. When the\ndecisions of these two classifiers are not consistent, we know that the\nprediction is not reliable. The number of inconsistencies in the predictions of\na testing set may indicate that the classifier is not performing correctly in\nthe testing scenario. This occurs, for example, in case of cover source\nmismatch, or when we are trying to detect a steganographic method that the\nclassifier is no capable of modelling accurately. We also show how the number\nof inconsistencies can be used to predict the reliability of the classifier\n(classification errors).\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 11:03:16 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Lerch-Hostalot", "Daniel", ""], ["Meg\u00edas", "David", ""]]}, {"id": "1909.10380", "submitter": "Zhaojun Lu", "authors": "Zhaojun Lu, Qian Wang, Xi Chen, Gang Qu, Yongqiang Lyu, and Zhenglin\n  Liu", "title": "LEAP: A Lightweight Encryption and Authentication Protocol for\n  In-Vehicle Communications", "comments": "7 pages, 9 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Controller Area Network (CAN) is considered as the de-facto standard for\nthe in-vehicle communications due to its real-time performance and high\nreliability. Unfortunately, the lack of security protection on the CAN bus\ngives attackers the opportunity to remotely compromise a vehicle. In this\npaper, we propose a Lightweight Encryption and Authentication Protocol (LEAP)\nwith low cost and high efficiency to address the security issue of the CAN bus.\nLEAP exploits the security-enhanced stream cipher primitive to provide\nencryption and authentication for the CAN messages. Compared with the\nstate-of-the-art Message Authentication Code (MAC) based approaches, LEAP\nrequires less memory, is 8X faster, and thwarts the most recently proposed\nattacks.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 14:15:24 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Lu", "Zhaojun", ""], ["Wang", "Qian", ""], ["Chen", "Xi", ""], ["Qu", "Gang", ""], ["Lyu", "Yongqiang", ""], ["Liu", "Zhenglin", ""]]}, {"id": "1909.10480", "submitter": "Alesia Chernikova", "authors": "Alesia Chernikova and Alina Oprea", "title": "FENCE: Feasible Evasion Attacks on Neural Networks in Constrained\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As advances in Deep Neural Networks (DNNs) demonstrate unprecedented levels\nof performance in many critical applications, their vulnerability to attacks is\nstill an open question. We consider evasion attacks at the testing time against\nDeep Learning in constrained environments, in which dependencies between\nfeatures need to be satisfied. These situations may arise naturally in tabular\ndata or may be the result of feature engineering in specific application\ndomains, such as threat detection. We propose a general iterative\ngradient-based framework called FENCE for crafting evasion attacks that take\ninto consideration the specifics of constrained domains. We apply it against\nFeed-Forward Neural Networks in two threat detection applications: network\ntraffic botnet classification and malicious domain classification, to generate\nfeasible adversarial examples. We extensively evaluate the success rate and\nperformance of our attacks, compare their significant improvement over several\nbaselines, and analyze several factors that impact the attack success rate,\nincluding the optimization objective and the data imbalance. We show that with\nminimal effort (e.g., generating 12 additional network connections), an\nattacker can change the model's prediction to the target one. We found that\nmodels trained on datasets with higher imbalance are more vulnerable to our\nFENCE attacks. Finally, we show the potential of adversarial training in\nconstrained domains to increase the DNN resilience against these attacks.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 16:59:15 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 20:00:26 GMT"}, {"version": "v3", "created": "Wed, 16 Sep 2020 03:19:13 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Chernikova", "Alesia", ""], ["Oprea", "Alina", ""]]}, {"id": "1909.10565", "submitter": "Amit Kumar Sikder", "authors": "AKM Iqtidar Newaz, Amit Kumar Sikder, Mohammad Ashiqur Rahman, A.\n  Selcuk Uluagac", "title": "HealthGuard: A Machine Learning-Based Security Framework for Smart\n  Healthcare Systems", "comments": "Accepted to be appeared in The International Symposium on Health and\n  Medical informatics, Management and Security (HMiMS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The integration of Internet-of-Things and pervasive computing in medical\ndevices have made the modern healthcare system \"smart\". Today, the function of\nthe healthcare system is not limited to treat the patients only. With the help\nof implantable medical devices and wearables, Smart Healthcare System (SHS) can\ncontinuously monitor different vital signs of a patient and automatically\ndetect and prevent critical medical conditions. However, these increasing\nfunctionalities of SHS raise several security concerns and attackers can\nexploit the SHS in numerous ways: they can impede normal function of the SHS,\ninject false data to change vital signs, and tamper a medical device to change\nthe outcome of a medical emergency. In this paper, we propose HealthGuard, a\nnovel machine learning-based security framework to detect malicious activities\nin a SHS. HealthGuard observes the vital signs of different connected devices\nof a SHS and correlates the vitals to understand the changes in body functions\nof the patient to distinguish benign and malicious activities. HealthGuard\nutilizes four different machine learning-based detection techniques (Artificial\nNeural Network, Decision Tree, Random Forest, k-Nearest Neighbor) to detect\nmalicious activities in a SHS. We trained HealthGuard with data collected for\neight different smart medical devices for twelve benign events including seven\nnormal user activities and five disease-affected events. Furthermore, we\nevaluated the performance of HealthGuard against three different malicious\nthreats. Our extensive evaluation shows that HealthGuard is an effective\nsecurity framework for SHS with an accuracy of 91% and an F-1 score of 90%.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 18:36:15 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Newaz", "AKM Iqtidar", ""], ["Sikder", "Amit Kumar", ""], ["Rahman", "Mohammad Ashiqur", ""], ["Uluagac", "A. Selcuk", ""]]}, {"id": "1909.10586", "submitter": "Augustine Musukwa", "authors": "Augustine Musukwa, Massimiliano Sala and Marco Zaninelli", "title": "On some cryptographic properties of Boolean functions and their\n  second-order derivatives", "comments": "17 pages, WCC 2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper some cryptographic properties of Boolean functions, including\nweight, balancedness and nonlinearity, are studied, particularly focusing on\nsplitting functions and cubic Boolean functions. Moreover, we present some\nquantities derived from the behaviour of second-order derivatives which allow\nus to determine whether a quadratic or cubic function is APN.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 19:34:20 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Musukwa", "Augustine", ""], ["Sala", "Massimiliano", ""], ["Zaninelli", "Marco", ""]]}, {"id": "1909.10594", "submitter": "Jinyuan Jia", "authors": "Jinyuan Jia, Ahmed Salem, Michael Backes, Yang Zhang, Neil Zhenqiang\n  Gong", "title": "MemGuard: Defending against Black-Box Membership Inference Attacks via\n  Adversarial Examples", "comments": "ACM CCS 2019, code is available at this:\n  https://github.com/jjy1994/MemGuard", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a membership inference attack, an attacker aims to infer whether a data\nsample is in a target classifier's training dataset or not. Specifically, given\na black-box access to the target classifier, the attacker trains a binary\nclassifier, which takes a data sample's confidence score vector predicted by\nthe target classifier as an input and predicts the data sample to be a member\nor non-member of the target classifier's training dataset. Membership inference\nattacks pose severe privacy and security threats to the training dataset. Most\nexisting defenses leverage differential privacy when training the target\nclassifier or regularize the training process of the target classifier. These\ndefenses suffer from two key limitations: 1) they do not have formal\nutility-loss guarantees of the confidence score vectors, and 2) they achieve\nsuboptimal privacy-utility tradeoffs.\n  In this work, we propose MemGuard, the first defense with formal utility-loss\nguarantees against black-box membership inference attacks. Instead of tampering\nthe training process of the target classifier, MemGuard adds noise to each\nconfidence score vector predicted by the target classifier. Our key observation\nis that attacker uses a classifier to predict member or non-member and\nclassifier is vulnerable to adversarial examples. Based on the observation, we\npropose to add a carefully crafted noise vector to a confidence score vector to\nturn it into an adversarial example that misleads the attacker's classifier.\nOur experimental results on three datasets show that MemGuard can effectively\ndefend against membership inference attacks and achieve better privacy-utility\ntradeoffs than existing defenses. Our work is the first one to show that\nadversarial examples can be used as defensive mechanisms to defend against\nmembership inference attacks.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 19:46:51 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 01:54:50 GMT"}, {"version": "v3", "created": "Wed, 18 Dec 2019 21:38:34 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Jia", "Jinyuan", ""], ["Salem", "Ahmed", ""], ["Backes", "Michael", ""], ["Zhang", "Yang", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "1909.10644", "submitter": "Mayra Samaniego Mrs", "authors": "Mayra Samaniego, Cristian Espana, Ralph Deters", "title": "Suspicious Transactions in Smart Spaces", "comments": "Accepted in the HICSS 53 conference\n  (https://hicss.hawaii.edu/program-hicss53/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IoT systems have enabled ubiquitous communication in physical spaces, making\nthem smart Nowadays, there is an emerging concern about evaluating suspicious\ntransactions in smart spaces. Suspicious transactions might have a logical\nstructure, but they are not correct under the present contextual information of\nsmart spaces. This research reviews suspicious transactions in smart spaces and\nevaluates the characteristics of blockchain technology to manage them.\nAdditionally, this research presents a blockchain-based system model with the\nnovel idea of iContracts (interactive contracts) to enable contextual\nevaluation through proof-of-provenance to detect suspicious transactions in\nsmart spaces.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 22:36:37 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Samaniego", "Mayra", ""], ["Espana", "Cristian", ""], ["Deters", "Ralph", ""]]}, {"id": "1909.10816", "submitter": "Nasrollah Pakniat", "authors": "Nasrollah Pakniat", "title": "Security analysis of two lightweight certificateless signature schemes", "comments": "20 pages, 0 figure", "journal-ref": "Journal of Computing and Security, 5(2), 1-7 (2019)", "doi": "10.22108/jcs.2019.110889", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Certificateless cryptography can be considered as an intermediate solution to\novercome the issues in traditional public key infrastructure (PKI) and\nidentity-based public key cryptography (ID-PKC). There exist a vast number of\ncertificateless signature (CLS) schemes in the literature; however, most of\nthem are not efficient enough to be utilized in limited resources environments\nsuch as Internet of things (IoT) or Healthcare Wireless Sensor Networks (HWSN).\nRecently, two lightweight CLS schemes have been proposed by Karati et al. and\nKumar et al. to be employed in IoT and HWSNs, respectively. While both schemes\nare claimed to be existentially unforgeable, in this paper, we show that both\nthese signatures can easily be forged. More specifically, it is shown that 1)\nin Karati et al.'s scheme, a type 1 adversary, considered in certificateless\ncryptography, can generate a valid partial private key corresponding to any\nuser of its choice and as a consequence, it can forge any users' signature on\nany message of its choice, and 2) in Kumar et al.'s scheme, both types of\nadversaries which are considered in certificateless cryptography are able to\nforge any signer's signature on an arbitrary message.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 11:23:18 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Pakniat", "Nasrollah", ""]]}, {"id": "1909.10841", "submitter": "Basel Halak", "authors": "Robert Cockell and Basel Halak", "title": "On the Design and Analysis of a Biometric Authentication System using\n  Keystroke Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a portable hardware token for user authentication, it is\nbased on the use of keystroke dynamics to verify users in a bio-metric manner.\nThe proposed approach allows for a multifactor authentication scheme in which\nusers are not allowed access unless they provide the correct password and their\nunique bio-metric signature. The proposed system is implemented in hardware and\nits security is evaluated.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 12:35:50 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Cockell", "Robert", ""], ["Halak", "Basel", ""]]}, {"id": "1909.10874", "submitter": "Mostafa Safi", "authors": "Mostafa Safi, Seyed Mehran Dibaji and Mohammad Pirani", "title": "Resilient Coordinated Movement of Connected Autonomous Vehicles", "comments": "10 pages, 7 figures, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider coordinated movement of a network of vehicles\nconsisting of a bounded number of malicious agents, that is, vehicles must\nreach consensus in longitudinal position and a common predefined velocity. The\nmotions of vehicles are modeled by double-integrator dynamics and\ncommunications over the network are asynchronous with delays. Each normal\nvehicle updates its states by utilizing the information it receives from\nvehicles in its vicinity. On the other hand, misbehaving vehicles make updates\narbitrarily and might threaten the consensus within the network by\nintentionally changing their moving direction or broadcasting faulty\ninformation in their neighborhood. We propose an asynchronous updating strategy\nfor normal vehicles, based on filtering extreme values received from\nneighboring vehicles, to save them from being misguided by malicious vehicles.\nWe show that there exist topological constraints on the network in terms of\ngraph robustness under which the vehicles resiliently achieve coordinated\nmovement. Numerical simulations are provided to evaluate the results.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 00:57:48 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 17:06:42 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2020 12:06:50 GMT"}, {"version": "v4", "created": "Thu, 29 Jul 2021 06:45:56 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Safi", "Mostafa", ""], ["Dibaji", "Seyed Mehran", ""], ["Pirani", "Mohammad", ""]]}, {"id": "1909.10926", "submitter": "Jakub Sliwinski", "authors": "Jakub Sliwinski and Roger Wattenhofer", "title": "ABC: Proof-of-Stake without Consensus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new permissionless blockchain architecture called ABC. ABC is\ncompletely asynchronous, and does rely on neither randomness nor proof-of-work.\nABC can be parallelized, and transactions have finality within one round trip\nof communication. However, ABC satisfies only a relaxed form of consensus by\nintroducing a weaker termination property. Without full consensus, ABC cannot\nsupport certain applications, in particular ABC cannot support general smart\ncontracts. However, many important applications do not need general smart\ncontracts, and ABC is a better solution for these applications. In particular,\nABC can implement the functionality of a cryptocurrency like Bitcoin, replacing\nBitcoin's energy-hungry proof-of-work with a proof-of-stake validation.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 13:50:24 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 17:56:43 GMT"}, {"version": "v3", "created": "Mon, 20 Jul 2020 10:20:46 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Sliwinski", "Jakub", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "1909.11013", "submitter": "Jo\\~ao Santos", "authors": "Jo\\~ao Amaral Santos, Pedro R. M. In\\'acio, Bruno M. Silva", "title": "Towards the Uses of Blockchain in Mobile Health Services and\n  Applications: A Survey", "comments": "Re-organization of the paper is required until it is published", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of Bitcoin and blockchain, the growth and adaptation of\ncryptographic features and capabilities were quickly extended to new and\nunderexplored areas, such as healthcare. Currently, blockchain is being\nimplemented mainly as a mechanism to secure Electronic Health Records (EHRs).\nHowever, new studies have shown that this technology can be a powerful tool in\nempowering patients to control their own health data, as well for enabling a\nfool-proof health data history and establishing medical responsibility. With\nthe advent of mobile health (m-Health) sustained on service-oriented\narchitectures, the adaptation of blockchain mechanisms into m-Health\napplications creates the possibility for a more decentralized and available\nhealthcare service. Hence, this paper presents a review of the current security\nbest practices for m-Health including blockchain technologies in healthcare.\nMoreover, it discusses and elaborates on identified open-issues and\npotentialities regarding the uses of Blockchain. Finally, the paper proposes\nconceptual solutions for future blockchain implementations for m-Health\nServices and Applications.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 15:50:22 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 15:00:21 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Santos", "Jo\u00e3o Amaral", ""], ["In\u00e1cio", "Pedro R. M.", ""], ["Silva", "Bruno M.", ""]]}, {"id": "1909.11021", "submitter": "Mahdi Miraz", "authors": "Junaid Chaudhry, Uvais Qidwai and Mahdi H. Miraz", "title": "Securing Big Data from Eavesdropping Attacks in SCADA/ICS Network Data\n  Streams through Impulsive Statistical Fingerprinting", "comments": null, "journal-ref": "Springer Nature LNICST Series, vol. 285, pp. 77-89, August 2019,\n  https://link.springer.com/chapter/10.1007/978-3-030-23943-5_6", "doi": "10.1007/978-3-030-23943-5_6", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While data from Supervisory Control And Data Acquisition (SCADA) systems is\nsent upstream, it is both the length of pulses as well as their frequency\npresent an excellent opportunity to incor-porate statistical fingerprinting.\nThis is so, because datagrams in SCADA traffic follow a poison distribution.\nAlthough wrapping the SCADA traffic in a protective IPsec stream is an obvious\nchoice, thin clients and unreliable communication channels make is less than\nideal to use crypto-graphic solutions for security SCADA traffic. In this\npaper, we propose a smart alternative of data obfuscation in the form of\nImpulsive Statistical Fingerprinting (ISF). We provide important insights into\nour research in healthcare SCADA data security and the use of ISF. We\nsubstantiate the conversion of sensor data through the ISF into HL7 format and\ndefine policies of a seamless switch to a non HL7-based non-secure HIS to a\nsecure HIS.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 04:03:51 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Chaudhry", "Junaid", ""], ["Qidwai", "Uvais", ""], ["Miraz", "Mahdi H.", ""]]}, {"id": "1909.11073", "submitter": "Badih Ghazi", "authors": "Badih Ghazi, Pasin Manurangsi, Rasmus Pagh, Ameya Velingker", "title": "Private Aggregation from Fewer Anonymous Messages", "comments": "31 pages; 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the setup where $n$ parties are each given a number $x_i \\in\n\\mathbb{F}_q$ and the goal is to compute the sum $\\sum_i x_i$ in a secure\nfashion and with as little communication as possible. We study this problem in\nthe anonymized model of Ishai et al. (FOCS 2006) where each party may broadcast\nanonymous messages on an insecure channel.\n  We present a new analysis of the one-round \"split and mix\" protocol of Ishai\net al. In order to achieve the same security parameter, our analysis reduces\nthe required number of messages by a $\\Theta(\\log n)$ multiplicative factor. We\ncomplement our positive result with lower bounds showing that the dependence of\nthe number of messages on the domain size, the number of parties, and the\nsecurity parameter is essentially tight.\n  Using a reduction of Balle et al. (2019), our improved analysis of the\nprotocol of Ishai et al. yields, in the same model, an $\\left(\\varepsilon,\n\\delta\\right)$-differentially private protocol for aggregation that, for any\nconstant $\\varepsilon > 0$ and any $\\delta = \\frac{1}{\\mathrm{poly}(n)}$,\nincurs only a constant error and requires only a constant number of messages\nper party. Previously, such a protocol was known only for $\\Omega(\\log n)$\nmessages per party.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 17:52:14 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 18:06:28 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Ghazi", "Badih", ""], ["Manurangsi", "Pasin", ""], ["Pagh", "Rasmus", ""], ["Velingker", "Ameya", ""]]}, {"id": "1909.11164", "submitter": "Fan Sang", "authors": "Fan Sang, Daehee Jang, Ming-Wei Shih, Taesoo Kim", "title": "P2FAAS: Toward Privacy-Preserving Fuzzing as a Service", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global corporations (e.g., Google and Microsoft) have recently introduced a\nnew model of cloud services, fuzzing-as-a-service (FaaS). Despite effectively\nalleviating the cost of fuzzing, the model comes with privacy concerns. For\nexample, the end user has to trust both cloud and service providers who have\naccess to the application to be fuzzed. Such concerns are due to the platform\nis under the control of its provider and the application and the fuzzer are\nhighly coupled. In this paper, we propose P2FaaS, a new ecosystem that\npreserves end user's privacy while providing FaaS in the cloud. The key idea of\nP2FaaS is to utilize Intel SGX for preventing cloud and service providers from\nlearning information about the application. Our preliminary evaluation shows\nthat P2FaaS imposes 45% runtime overhead to the fuzzing compared to the\nbaseline. In addition, P2FaaS demonstrates that, with recently introduced\nhardware, Intel SGX Card, the fuzzing service can be scaled up to multiple\nservers without native SGX support.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 20:32:42 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Sang", "Fan", ""], ["Jang", "Daehee", ""], ["Shih", "Ming-Wei", ""], ["Kim", "Taesoo", ""]]}, {"id": "1909.11166", "submitter": "Aaron Yi Ding", "authors": "Aaron Yi Ding, Gianluca Limon De Jesus, Marijn Janssen", "title": "Ethical Hacking for IoT Security: A First Look into Bug Bounty Programs\n  and Responsible Disclosure", "comments": "Pre-print version for conference publication at ICTRS 2019", "journal-ref": null, "doi": "10.1145/3357767.3357774", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The security of the Internet of Things (IoT) has attracted much attention due\nto the growing number of IoT-oriented security incidents. IoT hardware and\nsoftware security vulnerabilities are exploited affecting many companies and\npersons. Since the causes of vulnerabilities go beyond pure technical measures,\nthere is a pressing demand nowadays to demystify IoT \"security complex\" and\ndevelop practical guidelines for both companies, consumers, and regulators. In\nthis paper, we present an initial study targeting an unexplored sphere in IoT\nby illuminating the potential of crowdsource ethical hacking approaches for\nenhancing IoT vulnerability management. We focus on Bug Bounty Programs (BBP)\nand Responsible Disclosure (RD), which stimulate hackers to report\nvulnerability in exchange for monetary rewards. We carried out a qualitative\ninvestigation supported by literature survey and expert interviews to explore\nhow BBP and RD can facilitate the practice of identifying, classifying,\nprioritizing, remediating, and mitigating IoT vulnerabilities in an effective\nand cost-efficient manner. Besides deriving tangible guidelines for IoT\nstakeholders, our study also sheds light on a systematic integration path to\ncombine BBP and RD with existing security practices (e.g., penetration test) to\nfurther boost overall IoT security.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 20:48:10 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Ding", "Aaron Yi", ""], ["De Jesus", "Gianluca Limon", ""], ["Janssen", "Marijn", ""]]}, {"id": "1909.11187", "submitter": "James Cheney", "authors": "Sheung Chi Chan, James Cheney, Pramod Bhatotia, Thomas Pasquier,\n  Ashish Gehani, Hassaan Irshad, Lucian Carata, and Margo Seltzer", "title": "ProvMark: A Provenance Expressiveness Benchmarking System", "comments": "To appear, Middleware 2019", "journal-ref": null, "doi": "10.1145/3361525.3361552", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  System level provenance is of widespread interest for applications such as\nsecurity enforcement and information protection. However, testing the\ncorrectness or completeness of provenance capture tools is challenging and\ncurrently done manually. In some cases there is not even a clear consensus\nabout what behavior is correct. We present an automated tool, ProvMark, that\nuses an existing provenance system as a black box and reliably identifies the\nprovenance graph structure recorded for a given activity, by a reduction to\nsubgraph isomorphism problems handled by an external solver. ProvMark is a\nbeginning step in the much needed area of testing and comparing the\nexpressiveness of provenance systems. We demonstrate ProvMark's usefuless in\ncomparing three capture systems with different architectures and distinct\ndesign philosophies.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 21:10:15 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Chan", "Sheung Chi", ""], ["Cheney", "James", ""], ["Bhatotia", "Pramod", ""], ["Pasquier", "Thomas", ""], ["Gehani", "Ashish", ""], ["Irshad", "Hassaan", ""], ["Carata", "Lucian", ""], ["Seltzer", "Margo", ""]]}, {"id": "1909.11201", "submitter": "Shusen Wang", "authors": "Mengjiao Zhang and Shusen Wang", "title": "Matrix Sketching for Secure Collaborative Machine Learning", "comments": "In International Conference on Machine Learning (ICML), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative learning allows participants to jointly train a model without\ndata sharing. To update the model parameters, the central server broadcasts\nmodel parameters to the clients, and the clients send updating directions such\nas gradients to the server. While data do not leave a client device, the\ncommunicated gradients and parameters will leak a client's privacy. Attacks\nthat infer clients' privacy from gradients and parameters have been developed\nby prior work. Simple defenses such as dropout and differential privacy either\nfail to defend the attacks or seriously hurt test accuracy.\n  We propose a practical defense which we call Double-Blind Collaborative\nLearning (DBCL). The high-level idea is to apply random matrix sketching to the\nparameters (aka weights) and re-generate random sketching after each iteration.\nDBCL prevents clients from conducting gradient-based privacy inferences which\nare the most effective attacks. DBCL works because from the attacker's\nperspective, sketching is effectively random noise that outweighs the signal.\nNotably, DBCL does not much increase computation and communication costs and\ndoes not hurt test accuracy at all.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 21:55:26 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 21:05:22 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 14:07:12 GMT"}, {"version": "v4", "created": "Thu, 8 Jul 2021 13:27:37 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Zhang", "Mengjiao", ""], ["Wang", "Shusen", ""]]}, {"id": "1909.11202", "submitter": "Christopher Collins", "authors": "Brandon Laughlin, Christopher Collins, Karthik Sankaranarayanan,\n  Khalil El-Khatib", "title": "A Visual Analytics Framework for Adversarial Text Generation", "comments": null, "journal-ref": "2019 IEEE Symposium on Visualization for Cyber Security (VizSec)", "doi": "10.1109/VizSec48167.2019.9161563", "report-no": null, "categories": "cs.HC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a framework which enables a user to more easily make\ncorrections to adversarial texts. While attack algorithms have been\ndemonstrated to automatically build adversaries, changes made by the algorithms\ncan often have poor semantics or syntax. Our framework is designed to\nfacilitate human intervention by aiding users in making corrections. The\nframework extends existing attack algorithms to work within an evolutionary\nattack process paired with a visual analytics loop. Using an interactive\ndashboard a user is able to review the generation process in real time and\nreceive suggestions from the system for edits to be made. The adversaries can\nbe used to both diagnose robustness issues within a single classifier or to\ncompare various classifier options. With the weaknesses identified, the\nframework can also be used as a first step in mitigating adversarial threats.\nThe framework can be used as part of further research into defense methods in\nwhich the adversarial examples are used to evaluate new countermeasures. We\ndemonstrate the framework with a word swapping attack for the task of sentiment\nclassification.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 21:56:53 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Laughlin", "Brandon", ""], ["Collins", "Christopher", ""], ["Sankaranarayanan", "Karthik", ""], ["El-Khatib", "Khalil", ""]]}, {"id": "1909.11225", "submitter": "Adria Gascon", "authors": "Borja Balle, James Bell, Adria Gascon, Kobbi Nissim", "title": "Improved Summation from Shuffling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A protocol by Ishai et al.\\ (FOCS 2006) showing how to implement distributed\n$n$-party summation from secure shuffling has regained relevance in the context\nof the recently proposed \\emph{shuffle model} of differential privacy, as it\nallows to attain the accuracy levels of the curator model at a moderate\ncommunication cost. To achieve statistical security $2^{-\\sigma}$, the protocol\nby Ishai et al.\\ requires the number of messages sent by each party to {\\em\ngrow} logarithmically with $n$ as $O(\\log n + \\sigma)$. In this note we give an\nimproved analysis achieving a dependency of the form $O(1+\\sigma/\\log n)$.\nConceptually, this addresses the intuitive question left open by Ishai et al.\\\nof whether the shuffling step in their protocol provides a \"hiding in the\ncrowd\" amplification effect as $n$ increases. From a practical perspective, our\nanalysis provides explicit constants and shows, for example, that the method of\nIshai et al.\\ applied to summation of $32$-bit numbers from $n=10^4$ parties\nsending $12$ messages each provides statistical security $2^{-40}$.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 23:28:19 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Balle", "Borja", ""], ["Bell", "James", ""], ["Gascon", "Adria", ""], ["Nissim", "Kobbi", ""]]}, {"id": "1909.11245", "submitter": "Shubhang Kulkarni", "authors": "Jeremiah Blocki, Shubhang Kulkarni and Samson Zhou", "title": "On Locally Decodable Codes in Resource Bounded Channels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructions of locally decodable codes (LDCs) have one of two undesirable\nproperties: low rate or high locality (polynomial in the length of the\nmessage). In settings where the encoder/decoder have already exchanged\ncryptographic keys and the channel is a probabilistic polynomial time (PPT)\nalgorithm, it is possible to circumvent these barriers and design LDCs with\nconstant rate and small locality. However, the assumption that the\nencoder/decoder have exchanged cryptographic keys is often prohibitive. We thus\nconsider the problem of designing explicit and efficient LDCs in settings where\nthe channel is slightly more constrained than the encoder/decoder with respect\nto some resource e.g., space or (sequential) time. Given an explicit function\n$f$ that the channel cannot compute, we show how the encoder can transmit a\nrandom secret key to the local decoder using $f(\\cdot)$ and a random oracle\n$H(\\cdot)$. This allows bootstrap from the private key LDC construction of\nOstrovsky, Pandey and Sahai (ICALP, 2007), thereby answering an open question\nposed by Guruswami and Smith (FOCS 2010) of whether such bootstrapping\ntechniques may apply to LDCs in weaker channel models than just PPT algorithms.\nSpecifically, in the random oracle model we show how to construct explicit\nconstant rate LDCs with locality of polylog in the security parameter against\nvarious resource constrained channels.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 00:55:03 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2019 05:44:01 GMT"}, {"version": "v3", "created": "Sun, 5 Apr 2020 05:47:51 GMT"}, {"version": "v4", "created": "Fri, 5 Jun 2020 03:21:29 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Blocki", "Jeremiah", ""], ["Kulkarni", "Shubhang", ""], ["Zhou", "Samson", ""]]}, {"id": "1909.11261", "submitter": "Lei Yang", "authors": "Lei Yang, Vivek Bagaria, Gerui Wang, Mohammad Alizadeh, David Tse,\n  Giulia Fanti, Pramod Viswanath", "title": "Prism: Scaling Bitcoin by 10,000x", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin is the first fully decentralized permissionless blockchain protocol\nand achieves a high level of security: the ledger it maintains has guaranteed\nliveness and consistency properties as long as the adversary has less compute\npower than the honest nodes. However, its throughput is only 7 transactions per\nsecond and the confirmation latency can be up to hours. Prism is a new\nblockchain protocol which is designed to achieve a natural scaling of Bitcoin's\nperformance while maintaining its full security guarantees. We present an\nimplementation of Prism which achieves a throughput of 70,000 transactions per\nsecond and confirmation latencies of tens of seconds.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 02:42:25 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 14:00:55 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Yang", "Lei", ""], ["Bagaria", "Vivek", ""], ["Wang", "Gerui", ""], ["Alizadeh", "Mohammad", ""], ["Tse", "David", ""], ["Fanti", "Giulia", ""], ["Viswanath", "Pramod", ""]]}, {"id": "1909.11265", "submitter": "Steven Silverman", "authors": "Nils Paz, Steven Silverman, John Harmon", "title": "Quantum Entanglement in Time for a Distributed Ledger", "comments": "4 pages, 3 figures, 10 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Ledger Technology (DLT) is a shared, synchronized and replicated\ndata spread spatially and temporally with no centralized administration and/or\nstorage. Each node has a complete and identical set of records. All\nparticipants contribute to building and maintaining the distributed ledger.\nCurrent DLT technologies fall into two broad categories. Those that use\nblock-chains such as in Bitcoin or Ethereum, and newer approaches which reduce\ncomputational loads for verification. All current approaches though difficult\nto crack can be vulnerable to quantum algorithms using Quantum Information\nTechnologies (QIT). This effort joins the 2 technologies, constructing a\nQuantum Distributed Ledger (QDL) which provides a higher level of security\nusing QIT and a decentralized data depository using DLT. This enhanced security\nprevents middleman attacks with quantum computers yet retains the advantages of\na decentralized ledger of data.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 03:13:01 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Paz", "Nils", ""], ["Silverman", "Steven", ""], ["Harmon", "John", ""]]}, {"id": "1909.11326", "submitter": "Marie Euler", "authors": "M. Euler and C. Petit", "title": "New results on quasi-subfield polynomials", "comments": "31 pages (Accepted manuscript) Finite Fields and Their Applications,\n  Elsevier, In press, 75", "journal-ref": null, "doi": "10.1016/j.ffa.2021.101881", "report-no": null, "categories": "cs.CR math.NT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Quasi-subfield polynomials were introduced by Huang et al. together with a\nnew algorithm to solve the Elliptic Curve Discrete Logarithm Problem (ECDLP)\nover finite fields of small characteristic. In this paper we provide both new\nquasi-subfield polynomial families and a new theorem limiting their existence.\nOur results do not allow to derive any speedup for the new ECDLP algorithm\ncompared to previous approaches.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 07:56:40 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 07:32:44 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Euler", "M.", ""], ["Petit", "C.", ""]]}, {"id": "1909.11355", "submitter": "Xinxin Fan", "authors": "Xinxin Fan and Ling Liu and Rui Zhang and Quanliang Jing and Jingping\n  Bi", "title": "Decentralized Trust Management: Risk Analysis and Trust Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized trust management is used as a referral benchmark for assisting\ndecision making by human or intelligence machines in open collaborative\nsystems. During any given period of time, each participant may only interact\nwith a few of other participants. Simply relying on direct trust may frequently\nresort to random team formation. Thus, trust aggregation becomes critical. It\ncan leverage decentralized trust management to learn about indirect trust of\nevery participant based on past transaction experiences. This paper presents\nalternative designs of decentralized trust management and their efficiency and\nrobustness from three perspectives. First, we study the risk factors and\nadverse effects of six common threat models. Second, we review the\nrepresentative trust aggregation models and trust metrics. Third, we present an\nin-depth analysis and comparison of these reference trust aggregation methods\nwith respect to effectiveness and robustness. We show our comparative study\nresults through formal analysis and experimental evaluation. This comprehensive\nstudy advances the understanding of adverse effects of present and future\nthreats and the robustness of different trust metrics. It may also serve as a\nguideline for research and development of next generation trust aggregation\nalgorithms and services in the anticipation of risk factors and mischievous\nthreats.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 09:07:18 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Fan", "Xinxin", ""], ["Liu", "Ling", ""], ["Zhang", "Rui", ""], ["Jing", "Quanliang", ""], ["Bi", "Jingping", ""]]}, {"id": "1909.11401", "submitter": "Mohsen Ahmadvand", "authors": "Mohsen Ahmadvand, Dennis Fischer, and Sebastian Banescu", "title": "SIP Shaker: Software Integrity Protection Composition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Man-At-The-End (MATE) attackers are almighty adversaries against whom there\nexists no silver-bullet countermeasure. To raise the bar, a wide range of\nprotection measures were proposed in the literature each of which adds\nresilience against certain attacks on certain digital assets of a program.\nIntuitively, composing a set of protections (rather than applying just one of\nthem) can mitigate a wider range of attacks and hence offer a higher level of\nsecurity. Despite the potential benefits, very limited research has been done\non the composition of protections. Naive compositions could lead to conflicts\nwhich, in turn, limit the application of protections, raise false alarms, and\nworse yet, yield corrupted binaries. More importantly, inadequate compositions\nof such protections are not tailored for the program at hand and thus the\noffered security and performance are sub-optimal. In this paper, we first lay\nout a set of generic constraints for a conflict-free composition of\nprotections. Then, we develop a composition framework based on a defense graph\nin which nodes and edges capture protections, their relations, and constraints.\nThe conflicts problem together with optimization requirements are then\ntranslated into a set of integer constraints. We then use Integer Linear\nProgramming (ILP) to handle conflicts while optimizing for a higher security\nand lower overhead. To measure the overhead, we use a set of real-world\nprograms (MiBench dataset and open source games). Our evaluation results\nindicate that our composition framework reduces the overhead by $\\approx$ 39%\nwhile maximizing the coverage. Moreover, our approach yields a 5-fold decrease\nin overhead compared to state-of-the-art heuristics.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 10:53:25 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Ahmadvand", "Mohsen", ""], ["Fischer", "Dennis", ""], ["Banescu", "Sebastian", ""]]}, {"id": "1909.11404", "submitter": "Mohsen Ahmadvand", "authors": "Mohsen Ahmadvand, Daniel Below, Sebastian Banescu, and Alexander\n  Pretschner", "title": "VirtSC: Combining Virtualization Obfuscation with Self-Checksumming", "comments": null, "journal-ref": null, "doi": "10.1145/3338503.3357723", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-checksumming (SC) is a tamper-proofing technique that ensures certain\nprogram segments (code) in memory hash to known values at runtime. SC has few\nrestrictions on application and hence can protect a vast majority of programs.\nThe code verification in SC requires computation of the expected hashes after\ncompilation, as the machine-code is not known before. This means the expected\nhash values need to be adjusted in the binary executable, hence combining SC\nwith other protections is limited due to this adjustment step. However,\nobfuscation protections are often necessary, as SC protections can be otherwise\neasily detected and disabled via pattern matching. In this paper, we present a\nlayered protection using virtualization obfuscation, yielding an\narchitecture-agnostic SC protection that requires no post-compilation\nadjustment. We evaluate the performance of our scheme using a dataset of 25\nreal-world programs (MiBench and 3 CLI games). Our results show that the SC\nscheme induces an average overhead of 43% for a complete protection (100%\ncoverage). The overhead is tolerable for less CPU-intensive programs (e.g.\ngames) and when only parts of programs (e.g. license checking) are protected.\nHowever, large overheads stemming from the virtualization obfuscation were\nencountered.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 11:00:36 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Ahmadvand", "Mohsen", ""], ["Below", "Daniel", ""], ["Banescu", "Sebastian", ""], ["Pretschner", "Alexander", ""]]}, {"id": "1909.11424", "submitter": "Irfan Ul Haq", "authors": "Irfan Ul Haq and Juan Caballero", "title": "A Survey of Binary Code Similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary code similarity approaches compare two or more pieces of binary code\nto identify their similarities and differences. The ability to compare binary\ncode enables many real-world applications on scenarios where source code may\nnot be available such as patch analysis, bug search, and malware detection and\nanalysis. Over the past 20 years numerous binary code similarity approaches\nhave been proposed, but the research area has not yet been systematically\nanalyzed. This paper presents a first survey of binary code similarity. It\nanalyzes 61 binary code similarity approaches, which are systematized on four\naspects: (1) the applications they enable, (2) their approach characteristics,\n(3) how the approaches are implemented, and (4) the benchmarks and\nmethodologies used to evaluate them. In addition, the survey discusses the\nscope and origins of the area, its evolution over the past two decades, and the\nchallenges that lie ahead.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 12:01:36 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Haq", "Irfan Ul", ""], ["Caballero", "Juan", ""]]}, {"id": "1909.11465", "submitter": "Augustine Musukwa", "authors": "Augustine Musukwa and Massimiliano Sala", "title": "On the linear structures of Balanced functions and quadratic APN\n  functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The set of linear structures of most known balanced Boolean functions is\nnontrivial. In this paper, some balanced Boolean functions whose set of linear\nstructures is trivial are constructed. We show that any APN function in even\ndimension must have a component whose set of linear structures is trivial. We\ndetermine a general form for the number of bent components in quadratic APN\nfunctions in even dimension and some bounds on the number are produced. We also\ncount bent components in any quadratic power functions.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 13:04:49 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Musukwa", "Augustine", ""], ["Sala", "Massimiliano", ""]]}, {"id": "1909.11512", "submitter": "Sergey Nikolenko", "authors": "Sergey I. Nikolenko", "title": "Synthetic Data for Deep Learning", "comments": "156 pages, 24 figures, 719 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthetic data is an increasingly popular tool for training deep learning\nmodels, especially in computer vision but also in other areas. In this work, we\nattempt to provide a comprehensive survey of the various directions in the\ndevelopment and application of synthetic data. First, we discuss synthetic\ndatasets for basic computer vision problems, both low-level (e.g., optical flow\nestimation) and high-level (e.g., semantic segmentation), synthetic\nenvironments and datasets for outdoor and urban scenes (autonomous driving),\nindoor scenes (indoor navigation), aerial navigation, simulation environments\nfor robotics, applications of synthetic data outside computer vision (in neural\nprogramming, bioinformatics, NLP, and more); we also survey the work on\nimproving synthetic data development and alternative ways to produce it such as\nGANs. Second, we discuss in detail the synthetic-to-real domain adaptation\nproblem that inevitably arises in applications of synthetic data, including\nsynthetic-to-real refinement with GAN-based models and domain adaptation at the\nfeature/model level without explicit data transformations. Third, we turn to\nprivacy-related applications of synthetic data and review the work on\ngenerating synthetic datasets with differential privacy guarantees. We conclude\nby highlighting the most promising directions for further work in synthetic\ndata studies.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 14:20:57 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Nikolenko", "Sergey I.", ""]]}, {"id": "1909.11592", "submitter": "Soumajyoti Sarkar Mr.", "authors": "Soumajyoti Sarkar, Mohammad Almukaynizi, Jana Shakarian, Paulo\n  Shakarian", "title": "Mining user interaction patterns in the darkweb to predict enterprise\n  cyber incidents", "comments": "arXiv admin note: text overlap with arXiv:1811.06537", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With rise in security breaches over the past few years, there has been an\nincreasing need to mine insights from social media platforms to raise alerts of\npossible attacks in an attempt to defend conflict during competition. In this\nstudy, we attempt to build a framework that utilizes unconventional signals\nfrom the darkweb forums by leveraging the reply network structure of user\ninteractions with the goal of predicting enterprise related external cyber\nattacks. We use both unsupervised and supervised learning models that address\nthe challenges that come with the lack of enterprise attack metadata for ground\ntruth validation as well as insufficient data for training the models. We\nvalidate our models on a binary classification problem that attempts to predict\ncyber attacks on a daily basis for an organization. Using several controlled\nstudies on features leveraging the network structure, we measure the extent to\nwhich the indicators from the darkweb forums can be successfully used to\npredict attacks. We use information from 53 forums in the darkweb over a span\nof 17 months for the task. Our framework to predict real world organization\ncyber attacks of 3 different security events, suggest that focusing on the\nreply path structure between groups of users based on random walk transitions\nand community structures has an advantage in terms of better performance solely\nrelying on forum or user posting statistics prior to attacks.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 05:00:46 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 19:26:32 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Sarkar", "Soumajyoti", ""], ["Almukaynizi", "Mohammad", ""], ["Shakarian", "Jana", ""], ["Shakarian", "Paulo", ""]]}, {"id": "1909.11601", "submitter": "Yoshimichi Nakatsuka", "authors": "Yoshimichi Nakatsuka, Andrew Paverd, Gene Tsudik", "title": "PDoT: Private DNS-over-TLS with TEE Support", "comments": "To appear: ACSAC 2019", "journal-ref": null, "doi": "10.1145/3359789.3359793", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security and privacy of the Internet Domain Name System (DNS) have been\nlongstanding concerns. Recently, there is a trend to protect DNS traffic using\nTransport Layer Security (TLS). However, at least two major issues remain: (1)\nhow do clients authenticate DNS-over-TLS endpoints in a scalable and extensible\nmanner; and (2) how can clients trust endpoints to behave as expected? In this\npaper, we propose a novel Private DNS-over-TLS (PDoT ) architecture. PDoT\nincludes a DNS Recursive Resolver (RecRes) that operates within a Trusted\nExecution Environment (TEE). Using Remote Attestation, DNS clients can\nauthenticate, and receive strong assurance of trustworthiness of PDoT RecRes.\nWe provide an open-source proof-of-concept implementation of PDoT and use it to\nexperimentally demonstrate that its latency and throughput match that of the\npopular Unbound DNS-over-TLS resolver.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 16:36:12 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Nakatsuka", "Yoshimichi", ""], ["Paverd", "Andrew", ""], ["Tsudik", "Gene", ""]]}, {"id": "1909.11624", "submitter": "Shujie Cui", "authors": "Shujie Cui, Xiangfu Song, Muhammad Rizwan Asghar, Steven D Galbraith,\n  and Giovanni Russello", "title": "Privacy-preserving Searchable Databases with Controllable Leakage", "comments": "16 pages, 6 figures, Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Searchable Encryption (SE) is a technique that allows Cloud Service Providers\n(CSPs) to search over encrypted datasets without learning the content of\nqueries and records. In recent years, many SE schemes have been proposed to\nprotect outsourced data from CSPs. Unfortunately, most of them leak sensitive\ninformation, from which the CSPs could still infer the content of queries and\nrecords by mounting leakage-based inference attacks, such as the count attack\nand file injection attack.\n  In this work, first we define the leakage in searchable encrypted databases\nand analyse how the leakage is leveraged in existing leakage-based attacks.\nSecond, we propose a Privacy-preserving Multi-cloud based dynamic symmetric SE\n(SSE) scheme for relational Database (P-McDb). P-McDb has minimal leakage,\nwhich not only ensures confidentiality of queries and records, but also\nprotects the search, access, and size patterns from CSPs. Moreover, P-McDb\nensures both forward and backward privacy of the database. Thus, P-McDb could\nresist existing leakage-based attacks, e.g., active file/record-injection\nattacks. We give security definition and analysis to show how P-McDb hides the\naforementioned patterns. Finally, we implemented a prototype of P-McDb and test\nit using the TPC-H benchmark dataset. Our evaluation results show the\nfeasibility and practical efficiency of P-McDb.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 17:11:45 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 10:13:24 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Cui", "Shujie", ""], ["Song", "Xiangfu", ""], ["Asghar", "Muhammad Rizwan", ""], ["Galbraith", "Steven D", ""], ["Russello", "Giovanni", ""]]}, {"id": "1909.11701", "submitter": "Mariano Lemus Mr.", "authors": "Mariano Lemus, Mariana F. Ramos, Preeti Yadav, Nuno A. Silva, Nelson\n  J. Muga, Andre Souto, Nikola Paunkovic, Paulo Mateus and Armando N. Pinto", "title": "Generation and Distribution of Quantum Oblivious Keys for Secure\n  Multiparty Computation", "comments": "11 pages, 5 figures", "journal-ref": "Appl. Sci. 2020, 10(12), 4080", "doi": "10.3390/app10124080", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The oblivious transfer primitive is sufficient to implement secure multiparty\ncomputation. However, secure multiparty computation based only on classical\ncryptography is severely limited by the security and efficiency of the\noblivious transfer implementation. We present a method to efficiently and\nsecurely generate and distribute oblivious keys by exchanging qubits and by\nperforming commitments using classical hash functions. With the presented\nhybrid approach, quantum and classical, we obtain a practical and high-speed\noblivious transfer protocol, secure even against quantum computer attacks. The\noblivious distributed keys allow implementing a fast and secure oblivious\ntransfer protocol, which can pave the way for the widespread of applications\nbased on secure multiparty computation.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 18:35:13 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 17:44:31 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Lemus", "Mariano", ""], ["Ramos", "Mariana F.", ""], ["Yadav", "Preeti", ""], ["Silva", "Nuno A.", ""], ["Muga", "Nelson J.", ""], ["Souto", "Andre", ""], ["Paunkovic", "Nikola", ""], ["Mateus", "Paulo", ""], ["Pinto", "Armando N.", ""]]}, {"id": "1909.11707", "submitter": "Yunjie Yi", "authors": "Yunjie Yi and Guang Gong", "title": "Implementation of three LWC Schemes in the WiFi 4-Way Handshake with\n  Software Defined Radio", "comments": "NIST Lightweight Cryptography Workshop 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the implementation setup of the IEEE 802.1X 4-way\nhandshake mutual authentication and IEEE 802.11i amending protected\ncommunication by using lightweight cryptography (LWC) schemes. The\ncryptographic functions including message integrity check (MIC) code (or\nequivalently message authentication code), key deviation function, and\nauthenticated encryption are implemented by each of three LWC schemes, i.e.,\nACE, SPIX, and WAGE, in three different types of microcontrollers: 8-bit\n(Atmega128), 16-bit (MSP430f2013/MSP430f22370) and 32-bit (Cortex-m3lm3s9d96)\nmicrocontrollers. Software defined radio (SDR), contained two Universal\nSoftware Radio Peripheral (USRP) devices, is used to setup 802.11a physical\nlayer orthogonal frequency division multiplexing (OFDM) transmission systems\nfor the devices. We provide the experimental timing including cryptographic\noperations, OFDM modulation and radio transmission in the air.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 18:45:47 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Yi", "Yunjie", ""], ["Gong", "Guang", ""]]}, {"id": "1909.11778", "submitter": "Zhuolun Xiang", "authors": "Zhuolun Xiang, Bolin Ding, Xi He and Jingren Zhou", "title": "Linear and Range Counting under Metric-based Local Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local differential privacy (LDP) enables private data sharing and analytics\nwithout the need for a trusted data collector. Error-optimal primitives (for,\ne.g., estimating means and item frequencies) under LDP have been well studied.\nFor analytical tasks such as range queries, however, the best known error bound\nis dependent on the domain size of private data, which is potentially\nprohibitive. This deficiency is inherent as LDP protects the same level of\nindistinguishability between any pair of private data values for each data\ndowner.\n  In this paper, we utilize an extension of $\\epsilon$-LDP called Metric-LDP or\n$E$-LDP, where a metric $E$ defines heterogeneous privacy guarantees for\ndifferent pairs of private data values and thus provides a more flexible knob\nthan $\\epsilon$ does to relax LDP and tune utility-privacy trade-offs. We show\nthat, under such privacy relaxations, for analytical workloads such as linear\ncounting, multi-dimensional range counting queries, and quantile queries, we\ncan achieve significant gains in utility. In particular, for range queries\nunder $E$-LDP where the metric $E$ is the $L^1$-distance function scaled by\n$\\epsilon$, we design mechanisms with errors independent on the domain sizes;\ninstead, their errors depend on the metric $E$, which specifies in what\ngranularity the private data is protected. We believe that the primitives we\ndesign for $E$-LDP will be useful in developing mechanisms for other analytical\ntasks, and encourage the adoption of LDP in practice.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 21:22:03 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 03:56:48 GMT"}, {"version": "v3", "created": "Sat, 16 May 2020 13:04:09 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Xiang", "Zhuolun", ""], ["Ding", "Bolin", ""], ["He", "Xi", ""], ["Zhou", "Jingren", ""]]}, {"id": "1909.11812", "submitter": "Farhad Farokhi", "authors": "Farhad Farokhi", "title": "Differential Privacy for Evolving Almost-Periodic Datasets with\n  Continual Linear Queries: Application to Energy Data Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT cs.SY eess.SY math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For evolving datasets with continual reports, the composition rule for\ndifferential privacy (DP) dictates that the scale of DP noise must grow\nlinearly with the number of the queries, or that the privacy budget must be\nsplit equally between all the queries, so that the privacy budget across all\nthe queries remains bounded and consistent with the privacy guarantees. To\navoid this drawback of DP, we consider datasets containing almost periodic time\nseries, composed of periodic components and noisy variations on top that are\nindependent across periods. Our interest in these datasets is motivated by\nthat, for reporting on private periodic time series, we do not need to divide\nthe privacy budget across the entire, possibly infinite, horizon. Instead, for\nperiodic time series, we generate DP reports for the first period and report\nthe same DP reports periodically. In practice, however, exactly periodic time\nseries do not exist as the data always contains small variations due to random\nor uncertain events. For instance, the energy consumption of a household may\nrepeat the same daily pattern with slight variations due to minor changes to\nthe habits of the individuals. The underlying periodic pattern is a function of\nthe private information of the households. It might be desired to protect the\nprivacy of households by not leaking information about the recurring patterns\nwhile the individual daily variations are almost noise-like with little to no\nprivacy concerns (depending on the situation). Motivated by this, we define DP\nfor almost periodic datasets and develop a Laplace mechanism for responding to\nlinear queries. We provide statistical tools for testing the validity of almost\nperiodicity assumption. We use multiple energy datasets containing smart-meter\nmeasurements of households to validate almost periodicity assumption. We\ngenerate DP aggregate reports and investigate their utility.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 23:29:25 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Farokhi", "Farhad", ""]]}, {"id": "1909.12095", "submitter": "Scott Stoller", "authors": "Thang Bui and Scott D. Stoller", "title": "A Decision Tree Learning Approach for Mining Relationship-Based Access\n  Control Policies", "comments": "arXiv admin note: text overlap with arXiv:1903.07530,\n  arXiv:1708.04749", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relationship-based access control (ReBAC) provides a high level of\nexpressiveness and flexibility that promotes security and information sharing,\nby allowing policies to be expressed in terms of chains of relationships\nbetween entities. ReBAC policy mining algorithms have the potential to\nsignificantly reduce the cost of migration from legacy access control systems\nto ReBAC, by partially automating the development of a ReBAC policy.\n  This paper presents new algorithms, called DTRM (Decision Tree ReBAC Miner)\nand DTRM$^-$, based on decision trees, for mining ReBAC policies from access\ncontrol lists (ACLs) and information about entities. Compared to\nstate-of-the-art ReBAC mining algorithms, our algorithms are significantly\nfaster, achieve comparable policy quality, and can mine policies in a richer\nlanguage.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 18:32:46 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 21:32:29 GMT"}, {"version": "v3", "created": "Sat, 29 Feb 2020 21:09:40 GMT"}, {"version": "v4", "created": "Fri, 10 Apr 2020 00:21:32 GMT"}, {"version": "v5", "created": "Tue, 12 May 2020 21:58:34 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Bui", "Thang", ""], ["Stoller", "Scott D.", ""]]}, {"id": "1909.12161", "submitter": "Muhammad Usama", "authors": "Salah-ud-din Farooq, Muhammad Usama, Junaid Qadir, Muhammad Ali Imran", "title": "Adversarial ML Attack on Self Organizing Cellular Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNN) have been widely adopted in self-organizing\nnetworks (SON) for automating different networking tasks. Recently, it has been\nshown that DNN lack robustness against adversarial examples where an adversary\ncan fool the DNN model into incorrect classification by introducing a small\nimperceptible perturbation to the original example. SON is expected to use DNN\nfor multiple fundamental cellular tasks and many DNN-based solutions for\nperforming SON tasks have been proposed in the literature have not been tested\nagainst adversarial examples. In this paper, we have tested and explained the\nrobustness of SON against adversarial example and investigated the performance\nof an important SON use case in the face of adversarial attacks. We have also\ngenerated explanations of incorrect classifications by utilizing an explainable\nartificial intelligence (AI) technique.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 14:44:43 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Farooq", "Salah-ud-din", ""], ["Usama", "Muhammad", ""], ["Qadir", "Junaid", ""], ["Imran", "Muhammad Ali", ""]]}, {"id": "1909.12167", "submitter": "Muhammad Usama", "authors": "Muhammad Usama, Muhammad Asim, Junaid Qadir, Ala Al-Fuqaha, Muhammad\n  Ali Imran", "title": "Adversarial Machine Learning Attack on Modulation Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modulation classification is an important component of cognitive self-driving\nnetworks. Recently many ML-based modulation classification methods have been\nproposed. We have evaluated the robustness of 9 ML-based modulation classifiers\nagainst the powerful Carlini \\& Wagner (C-W) attack and showed that the current\nML-based modulation classifiers do not provide any deterrence against\nadversarial ML examples. To the best of our knowledge, we are the first to\nreport the results of the application of the C-W attack for creating\nadversarial examples against various ML models for modulation classification.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 14:52:28 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Usama", "Muhammad", ""], ["Asim", "Muhammad", ""], ["Qadir", "Junaid", ""], ["Al-Fuqaha", "Ala", ""], ["Imran", "Muhammad Ali", ""]]}, {"id": "1909.12272", "submitter": "Arjun Nitin Bhagoji", "authors": "Arjun Nitin Bhagoji, Daniel Cullina, Prateek Mittal", "title": "Lower Bounds on Adversarial Robustness from Optimal Transport", "comments": "Accepted for the 33rd Conference on Neural Information Processing\n  Systems (NeurIPS 2019); 18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While progress has been made in understanding the robustness of machine\nlearning classifiers to test-time adversaries (evasion attacks), fundamental\nquestions remain unresolved. In this paper, we use optimal transport to\ncharacterize the minimum possible loss in an adversarial classification\nscenario. In this setting, an adversary receives a random labeled example from\none of two classes, perturbs the example subject to a neighborhood constraint,\nand presents the modified example to the classifier. We define an appropriate\ncost function such that the minimum transportation cost between the\ndistributions of the two classes determines the minimum $0-1$ loss for any\nclassifier. When the classifier comes from a restricted hypothesis class, the\noptimal transportation cost provides a lower bound. We apply our framework to\nthe case of Gaussian data with norm-bounded adversaries and explicitly show\nmatching bounds for the classification and transport problems as well as the\noptimality of linear classifiers. We also characterize the sample complexity of\nlearning in this setting, deriving and extending previously known results as a\nspecial case. Finally, we use our framework to study the gap between the\noptimal classification performance possible and that currently achieved by\nstate-of-the-art robustly trained neural networks for datasets of interest,\nnamely, MNIST, Fashion MNIST and CIFAR-10.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 17:30:16 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 22:09:50 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Bhagoji", "Arjun Nitin", ""], ["Cullina", "Daniel", ""], ["Mittal", "Prateek", ""]]}, {"id": "1909.12282", "submitter": "Mahya Soleimani Jadidi Ms.", "authors": "Mahya Soleimani Jadidi (1), Mariusz Zaborski (2), Brian Kidney (1),\n  Jonathan Anderson (1) ((1) Memorial University of Newfoundland, (2) Fudo\n  Security Inc.)", "title": "CapExec: Towards Transparently-Sandboxed Services (Extended Version)", "comments": "This paper is the extended version of our paper accepted in CNSM2019\n  (15th International Conference on Network and Service Management). The short\n  version is going to appear in the conference proceedings. It contains 7 pages\n  including references and 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network services are among the riskiest programs executed by production\nsystems. Such services execute large quantities of complex code and process\ndata from arbitrary and untrusted network sources, often with high levels of\nsystem privilege. It is desirable to confine system services to a\nleast-privileged environment so that the potential damage from a malicious\nattacker can be limited, but existing mechanisms for sandboxing services\nrequire invasive and system-specific code changes and are insufficient to\nconfine broad classes of network services.\n  Rather than sandboxing one service at a time, we propose that the best place\nto add sandboxing to network services is in the service manager that starts\nthose services. As a first step towards this vision, we propose CapExec, a\nprocess supervisor that can execute a single service within a sandbox based on\na service declaration file in which, required resources whose limited access to\nare supported by Caper services, are specified. Using the Capsicum\ncompartmentalization framework and its Casper service framework, CapExec\nprovides robust application sandboxing without requiring any modifications to\nthe application itself. We believe that this is a first step towards ubiquitous\nsandboxing of network services without the costs of virtualization.\n  Keywords: application security, sandboxing, service manager, Capsicum,\ncompartmentalization\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 17:44:08 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Jadidi", "Mahya Soleimani", ""], ["Zaborski", "Mariusz", ""], ["Kidney", "Brian", ""], ["Anderson", "Jonathan", ""]]}, {"id": "1909.12302", "submitter": "Kartik Ramkrishnan", "authors": "Kartik Ramkrishnan, Antonia Zhai, Stephen McCamant, Pen Chung Yew", "title": "New Attacks and Defenses for Randomized Caches", "comments": "21 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last level cache is vulnerable to timing based side channel attacks\nbecause it is shared by the attacker and the victim processes even if they are\nlocated on different cores. These timing attacks evict the victim cache lines\nusing small conflict groups(SCG), and monitor the cache to observe when the\nvictim uses these cache lines again. A conflict group is a collection of cache\nlines which will evict the target cache line. Randomization is often used by\ndefenses to prevent creation of SCGs.\n  We introduce new attacks to demonstrate that the current randomization\nschemes require an extremely high refresh rate to be secure, on average a 15\\%\nperformance overhead, and upto 50\\% in the worst case. Next, we propose a new\nrandomization strategy using an indirection table, which mitigates this issue.\nAddresses of cache lines are encrypted and used to lookup the indirection table\nentry. Each indirection table entry stores a mapping to a randomly chosen cache\nset. The cache line is placed into this randomly chosen set. The encryption key\nchanges upto 50x faster than CEASER's default rate, by using evictions to\ntrigger the re-randomization. Instead of moving cache lines, this mechanism\nre-randomizes one iTable entry at a time, whenever the cache lines\ncorresponding to the iTable entry are naturally evicted. Thus, the miss rate is\nnot much worse than the baseline.\n  We quantitatively show that our scheme does almost as well as a fully\nassociative cache to defend against these attacks. We also demonstrate new\nattacks that target the iTable by oversubscribing its entries, and\nquantitatively show that our scheme is resilient against new attacks for\ntrillions of years. We estimate low area ( < 7\\%) and power overhead compared\nto a baseline inclusive last-level cache. Lastly, we evaluate a low performance\noverhead (<4%) using the SPECrate 2017 and PARSEC 3.0 benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 01:54:19 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Ramkrishnan", "Kartik", ""], ["Zhai", "Antonia", ""], ["McCamant", "Stephen", ""], ["Yew", "Pen Chung", ""]]}, {"id": "1909.12338", "submitter": "Mark Aagaard", "authors": "Mark D. Aagaard, Marat Sattarov, Nusa Zidaric", "title": "Hardware Design and Analysis of the ACE and WAGE Ciphers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the hardware design and analysis of ACE and WAGE, two\ncandidate ciphers for the NIST Lightweight Cryptography standardization. Both\nciphers use sLiSCP's unified sponge duplex mode. ACE has an internal state of\n320 bits, uses three 64 bit Simeck boxes, and implements both authenticated\nencryption and hashing. WAGE is based on the Welch-Gong stream cipher and\nprovides authenticated encryption. WAGE has 259 bits of state, two 7 bit\nWelch-Gong permutations, and four lightweight 7 bit S-boxes. ACE and WAGE have\nthe same external interface and follow the same I/O protocol to transition\nbetween phases. The paper illustrates how a hardware perspective influenced key\naspects of the ACE and WAGE algorithms. The paper reports area, power, and\nenergy results for both serial and parallel (unrolled) implementations using\nfour different ASIC libraries: two 65 nm libraries, a 90 nm library, and a 130\nnm library. ACE implementations range from a throughput of 0.5 bits-per-clock\ncycle (bpc) and an area of 4210 GE (averaged across the four ASIC libraries) up\nto 4 bpc and 7260 GE. WAGE results range from 0.57 bpc with 2920 GE to 4.57 bpc\nwith 11080 GE.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 19:03:38 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 16:33:26 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Aagaard", "Mark D.", ""], ["Sattarov", "Marat", ""], ["Zidaric", "Nusa", ""]]}, {"id": "1909.12381", "submitter": "Hongjian Sun Dr", "authors": "Alnasser Aljawharah and Sun Hongjian", "title": "Global Roaming Trust-based Model for V2X Communications", "comments": "6 pages, 7 figures, accepted by IEEE Conference on Computer\n  Communications Workshops (INFOCOM), Apr. 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Smart cities need to connect physical devices as a network to improve the\nefficiency of city operations and services. Intelligent Transportation System\n(ITS) is one of the key components in smart cities, due to its capability of\nsupporting communications between vehicles to improve the driving experience.\nWhilst Vehicle-to-Everything (V2X) communications are essential, cyber-security\nposes a significant challenge in V2X communications. A V2X communication link\nis vulnerable to various cyber-attacks including internal and external attacks.\nInternal attacks cannot be detected by conventional security schemes because\nthe compromised nodes have valid credentials. Thus, a new trust model is\nurgently needed to mitigate cyber-security risks. In this paper, a global\nroaming trust-based security model is proposed for V2X communications. Each\nvehicle has a global knowledge about malicious nodes in the network. In\naddition, various experiments are conducted with different percentage of\nmalicious nodes to measure the performance of the proposed model. Simulation\nresults show that the proposed model improves False Negative Rate (FNR) by\n33.5% in comparison with the existing method.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 20:46:15 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Aljawharah", "Alnasser", ""], ["Hongjian", "Sun", ""]]}, {"id": "1909.12432", "submitter": "Hamidreza Mahyar", "authors": "Soroush Aalibagi, Hamidreza Mahyar, Ali Movaghar, and H. Eugene\n  Stanley", "title": "A Matrix Factorization Model for Hellinger-based Trust Management in\n  Social Internet of Things", "comments": null, "journal-ref": null, "doi": "10.1109/TDSC.2021.3052953", "report-no": null, "categories": "cs.LG cs.CR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Social Internet of Things (SIoT), integration of the Internet of Things\nand Social Networks paradigms, has been introduced to build a network of smart\nnodes that are capable of establishing social links. In order to deal with\nmisbehaving service provider nodes, service requestor nodes must evaluate their\ntrustworthiness levels. In this paper, we propose a novel trust management\nmechanism in the SIoT to predict the most reliable service providers for each\nservice requestor, which leads to reduce the risk of being exposed to malicious\nnodes. We model the SIoT with a flexible bipartite graph (containing two sets\nof nodes: service providers and service requestors), then build a social\nnetwork among the service requestor nodes, using the Hellinger distance.\nAfterward, we develop a social trust model using nodes' centrality and\nsimilarity measures to extract trust behaviors among the social network nodes.\nFinally, a matrix factorization technique is designed to extract latent\nfeatures of SIoT nodes, find trustworthy nodes, and mitigate the data sparsity\nand cold start problems. We analyze the effect of parameters in the proposed\ntrust prediction mechanism on prediction accuracy. The results indicate that\nfeedbacks from the neighboring nodes of a specific service requestor with high\nHellinger similarity in our mechanism outperforms the best existing methods. We\nalso show that utilizing the social trust model, which only considers a\nsimilarity measure, significantly improves the accuracy of the prediction\nmechanism. Furthermore, we evaluate the effectiveness of the proposed trust\nmanagement system through a real-world SIoT use case. Our results demonstrate\nthat the proposed mechanism is resilient to different types of network attacks,\nand it can accurately find the most proper and trustworthy service provider.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 23:18:40 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 21:06:52 GMT"}, {"version": "v3", "created": "Tue, 2 Mar 2021 20:59:08 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Aalibagi", "Soroush", ""], ["Mahyar", "Hamidreza", ""], ["Movaghar", "Ali", ""], ["Stanley", "H. Eugene", ""]]}, {"id": "1909.12454", "submitter": "Scott Ruoti", "authors": "Scott Ruoti, Ben Kaiser, Arkady Yerukhimovich, Jeremy Clark, Robert\n  Cunningham", "title": "SoK: Blockchain Technology and Its Potential Use Cases", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin's success has led to significant interest in its underlying\ncomponents, particularly Blockchain technology. Over 10 years after Bitcoin's\ninitial release, the community still suffers from a lack of clarity regarding\nwhat properties defines Blockchain technology, its relationship to similar\ntechnologies, and which of its proposed use-cases are tenable and which are\nlittle more than hype. In this paper we answer four common questions regarding\nBlockchain technology: (1) what exactly is Blockchain technology, (2) what\ncapabilities does it provide, and (3) what are good applications for Blockchain\ntechnology, and (4) how does it relate to other approache distributed\ntechnologies (e.g., distributed databases). We accomplish this goal by using\ngrounded theory (a structured approach to gathering and analyzing qualitative\ndata) to thoroughly analyze a large corpus of literature on Blockchain\ntechnology. This method enables us to answer the above questions while limiting\nresearcher bias, separating thought leadership from peddled hype and\nidentifying open research questions related to Blockchain technology. The\naudience for this paper is broad as it aims to help researchers in a variety of\nareas come to a better understanding of Blockchain technology and identify\nwhether it may be of use in their own research.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 01:27:52 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Ruoti", "Scott", ""], ["Kaiser", "Ben", ""], ["Yerukhimovich", "Arkady", ""], ["Clark", "Jeremy", ""], ["Cunningham", "Robert", ""]]}, {"id": "1909.12496", "submitter": "Qiong Li", "authors": "Xuan Wen and Qiong Li and Haokun Mao and Yi Luo and Bingze Yan", "title": "Novel Reconciliation Protocol Based on Spinal Code for\n  Continuous-variable Quantum Key Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconciliation is a crucial procedure in post-processing of continuous\nvariable quantum key distribution (CV-QKD) system, which is used to make two\ndistant legitimate parties share identical corrected keys. The adaptive\nreconciliation is necessary and important for practical systems to cope with\nthe variable channel. Many researchers adopt the punctured LDPC codes to\nimplement adaptive reconciliation. In this paper, a novel rateless\nreconciliation protocol based on spinal code is proposed, which can achieve a\nhigh-efficiency and adaptive reconciliation in a larger range of SNRs. Due to\nthe short codes length and simple tructure, our protocol is easy to implement\nwithout the complex codes designs of fixed rate codes, e.g., LDPC codes.\nMeanwhile, the structure of our protocol is highly parallel, which is suitable\nfor hardware implementation, thus it also has the potential of high-speed\nhardware implementation. Besides, the security of proposed protocol is proved\nin theory. Experiment results show that the reconciliation efficiency maintains\naround 95% for ranging SNRs in a larger range (0,0.5), even exceeds 96.5% at\nextremely low SNR (<= 0.03) by using this novel scheme. The proposed protocol\nmakes the long-distance CV-QKD systems much easier and stable to perform a\nhigh-performance and adaptive reconciliation.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 05:20:22 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Wen", "Xuan", ""], ["Li", "Qiong", ""], ["Mao", "Haokun", ""], ["Luo", "Yi", ""], ["Yan", "Bingze", ""]]}, {"id": "1909.12540", "submitter": "Ximeng Liu", "authors": "Ximeng Liu, Robert H. Deng, Pengfei Wu, Yang Yang", "title": "Lightning-Fast and Privacy-Preserving Outsourced Computation in the\n  Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a framework for lightning-fast privacy-preserving\noutsourced computation framework in the cloud, which we refer to as LightCom.\nUsing LightCom, a user can securely achieve the outsource data storage and fast\nsecure data processing in a single cloud server different from the existing\nmulti-server outsourced computation model. Specifically, we first present a\ngeneral secure computation framework for LightCom under the cloud server\nequipped with multiple Trusted Processing Units (TPUs) which face the\nside-channel attack. Under the LightCom, we design two specified fast\nprocessing toolkits which allow the user to achieve the commonly-used secure\ninteger computation and secure floating-point computation against the\nside-channel information leakage of TPUs, respectively. Furthermore, our\nLightCom can also guarantee access pattern protection during the data\nprocessing and achieve user private information retrieve after the computation.\nWe prove that the proposed LightCom can successfully achieve the goal of single\ncloud outsourced data processing to avoid the extra computation server and\ntrusted computation server, and demonstrate the utility and the efficiency of\nLightCom using simulations.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 07:59:12 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Liu", "Ximeng", ""], ["Deng", "Robert H.", ""], ["Wu", "Pengfei", ""], ["Yang", "Yang", ""]]}, {"id": "1909.12584", "submitter": "Wei Li", "authors": "Wei Li, Shengmei Zhao", "title": "Upper Bound of Collective Attacks on Quantum Key Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating the theoretical limit of the amount of information Eve can steal\nfrom a quantum key distribution protocol under given conditions is one of the\nmost important things that need to be done in security proof. In addition to\nsource loopholes and detection loopholes, channel attacks are considered to be\nthe main ways of information leakage, while collective attacks are considered\nto be the most powerful active channel attacks. Here we deduce in detail the\ncapability limit of Eve's collective attack in non-entangled quantum key\ndistribution, like BB84 and measurement-device-independent protocols, and\nentangled quantum key distribution, like device-independent protocol, in which\ncollective attack is composed of quantum weak measurement and quantum\nunambiguous state discrimination detection. The theoretical results show that\ncollective attacks are equivalent in entangled and non-entangled quantum key\ndistribution protocols. We also find that compared with the security proof\nbased on entanglement purification, the security proof based on collective\nattack not only improves the system's tolerable bit error rate, but also\nimproves the key rate.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 09:53:12 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 02:07:10 GMT"}, {"version": "v3", "created": "Tue, 8 Oct 2019 04:31:08 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Li", "Wei", ""], ["Zhao", "Shengmei", ""]]}, {"id": "1909.12752", "submitter": "Zhihong Liu", "authors": "Zhihong Liu, Jiajia Liu, Yong Zeng, Jianfeng Ma", "title": "Hiding Communications in AWGN Channels and THz Band with Interference\n  Uncertainty", "comments": "arXiv admin note: substantial text overlap with arXiv:1712.05099", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Covert communication can prevent an adversary from knowing that a wireless\ntransmission has occurred. In additive white Gaussian noise (AWGN) channels, a\nsquare root law is found that Alice can reliably and covertly transmit\n$\\mathcal{O}(\\sqrt{n})$ bits to Bob in $n$ channel uses. In this paper, we\nconsider covert communications in noisy wireless networks, where the receivers\nnot only experience the background noise, but also the aggregate interference\nfrom other transmitters. Our results show that uncertainty in interference\nexperienced by the adversary Willie is beneficial to Alice. In AWGN channels,\nwhen the distance between Alice and Willie $d_{a,w}=\\omega(n^{1/(2\\alpha)})$\n($\\alpha$ is the path loss exponent), Alice can reliably and covertly transmit\n$\\mathcal{O}(\\log_2\\sqrt{n})$ bits to Bob in $n$ channel uses. Although the\ncovert throughput is lower than the square root law, the spatial throughput is\nhigher. In THz (Terahertz) Band networks,covert communication is more difficult\nbecause Willie can simply place a receiver in the narrow beam between Alice and\nBob to detect or block their LOS (Line-of-Sight) communications. We then\npresent a covert communication scheme that utilizes the reflection or diffuse\nscattering from a rough surface to prevent being detected by Willie. From the\nnetwork perspective, the communications are hidden in the interference of noisy\nwireless networks, and what Willie sees is merely a \"shadow\" wireless network.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 03:17:47 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Liu", "Zhihong", ""], ["Liu", "Jiajia", ""], ["Zeng", "Yong", ""], ["Ma", "Jianfeng", ""]]}, {"id": "1909.12946", "submitter": "Toyotaro Suzumura Prof", "authors": "Toyotaro Suzumura, Yi Zhou, Natahalie Baracaldo, Guangnan Ye, Keith\n  Houck, Ryo Kawahara, Ali Anwar, Lucia Larise Stavarache, Yuji Watanabe, Pablo\n  Loyola, Daniel Klyashtorny, Heiko Ludwig, Kumar Bhaskaran", "title": "Towards Federated Graph Learning for Collaborative Financial Crimes\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.LG cs.SI q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial crime is a large and growing problem, in some way touching almost\nevery financial institution. Financial institutions are the front line in the\nwar against financial crime and accordingly, must devote substantial human and\ntechnology resources to this effort. Current processes to detect financial\nmisconduct have limitations in their ability to effectively differentiate\nbetween malicious behavior and ordinary financial activity. These limitations\ntend to result in gross over-reporting of suspicious activity that necessitate\ntime-intensive and costly manual review. Advances in technology used in this\ndomain, including machine learning based approaches, can improve upon the\neffectiveness of financial institutions' existing processes, however, a key\nchallenge that most financial institutions continue to face is that they\naddress financial crimes in isolation without any insight from other firms.\nWhere financial institutions address financial crimes through the lens of their\nown firm, perpetrators may devise sophisticated strategies that may span across\ninstitutions and geographies. Financial institutions continue to work\nrelentlessly to advance their capabilities, forming partnerships across\ninstitutions to share insights, patterns and capabilities. These public-private\npartnerships are subject to stringent regulatory and data privacy requirements,\nthereby making it difficult to rely on traditional technology solutions. In\nthis paper, we propose a methodology to share key information across\ninstitutions by using a federated graph learning platform that enables us to\nbuild more accurate machine learning models by leveraging federated learning\nand also graph learning approaches. We demonstrated that our federated model\noutperforms local model by 20% with the UK FCA TechSprint data set. This new\nplatform opens up a door to efficiently detecting global money laundering\nactivity.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 21:31:14 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 22:32:23 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Suzumura", "Toyotaro", ""], ["Zhou", "Yi", ""], ["Baracaldo", "Natahalie", ""], ["Ye", "Guangnan", ""], ["Houck", "Keith", ""], ["Kawahara", "Ryo", ""], ["Anwar", "Ali", ""], ["Stavarache", "Lucia Larise", ""], ["Watanabe", "Yuji", ""], ["Loyola", "Pablo", ""], ["Klyashtorny", "Daniel", ""], ["Ludwig", "Heiko", ""], ["Bhaskaran", "Kumar", ""]]}, {"id": "1909.12962", "submitter": "Yuezun Li", "authors": "Yuezun Li, Xin Yang, Pu Sun, Honggang Qi and Siwei Lyu", "title": "Celeb-DF: A Large-scale Challenging Dataset for DeepFake Forensics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI-synthesized face-swapping videos, commonly known as DeepFakes, is an\nemerging problem threatening the trustworthiness of online information. The\nneed to develop and evaluate DeepFake detection algorithms calls for\nlarge-scale datasets. However, current DeepFake datasets suffer from low visual\nquality and do not resemble DeepFake videos circulated on the Internet. We\npresent a new large-scale challenging DeepFake video dataset, Celeb-DF, which\ncontains 5,639 high-quality DeepFake videos of celebrities generated using\nimproved synthesis process. We conduct a comprehensive evaluation of DeepFake\ndetection methods and datasets to demonstrate the escalated level of challenges\nposed by Celeb-DF.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 21:26:34 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 00:23:11 GMT"}, {"version": "v3", "created": "Wed, 27 Nov 2019 03:46:36 GMT"}, {"version": "v4", "created": "Mon, 16 Mar 2020 16:20:16 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Li", "Yuezun", ""], ["Yang", "Xin", ""], ["Sun", "Pu", ""], ["Qi", "Honggang", ""], ["Lyu", "Siwei", ""]]}, {"id": "1909.12982", "submitter": "Congzheng Song", "authors": "Congzheng Song, Reza Shokri", "title": "Robust Membership Encoding: Inference Attacks and Copyright Protection\n  for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning as a service (MLaaS), and algorithm marketplaces are on a\nrise. Data holders can easily train complex models on their data using third\nparty provided learning codes. Training accurate ML models requires massive\nlabeled data and advanced learning algorithms. The resulting models are\nconsidered as intellectual property of the model owners and their copyright\nshould be protected. Also, MLaaS needs to be trusted not to embed secret\ninformation about the training data into the model, such that it could be later\nretrieved when the model is deployed.\n  In this paper, we present \\emph{membership encoding} for training deep neural\nnetworks and encoding the membership information, i.e. whether a data point is\nused for training, for a subset of training data. Membership encoding has\nseveral applications in different scenarios, including robust watermarking for\nmodel copyright protection, and also the risk analysis of stealthy data\nembedding privacy attacks. Our encoding algorithm can determine the membership\nof significantly redacted data points, and is also robust to model compression\nand fine-tuning. It also enables encoding a significant fraction of the\ntraining set, with negligible drop in the model's prediction accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 23:17:13 GMT"}, {"version": "v2", "created": "Sun, 22 Mar 2020 01:28:12 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Song", "Congzheng", ""], ["Shokri", "Reza", ""]]}, {"id": "1909.13094", "submitter": "Georgios M. Nikolopoulos Ph. D", "authors": "Georgios M. Nikolopoulos", "title": "Optical scheme for cryptographic commitments with physical unclonable\n  keys", "comments": "\\copyright 2019 Optical Society of America. Users may use, reuse, and\n  build upon the article, or use the article for text or data mining, so long\n  as such uses are for non-commercial purposes and appropriate attribution is\n  maintained. All other rights are reserved", "journal-ref": "Optics Express Vol. 27, 29367-29379 (2019)", "doi": "10.1364/OE.27.029367", "report-no": null, "categories": "quant-ph cs.CR physics.app-ph physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the possibility of using multiple-scattering optical media, as\nresources of randomness in cryptographic tasks pertaining to commitments and\nauctions. The proposed commitment protocol exploits standard wavefront-shaping\nand heterodyne-detection techniques, and can be implemented with current\ntechnology. Its security is discussed in the framework of a tamper-resistant\ntrusted setup.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 13:31:39 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Nikolopoulos", "Georgios M.", ""]]}, {"id": "1909.13223", "submitter": "Feng Liu", "authors": "Feng Liu, Qi Wang", "title": "IBRS: An Efficient Identity-based Batch Verification Scheme for VANETs\n  Based on Ring Signature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicular ad-hoc networks (VANETs) are one of the most important components\nin an Intelligent Transportation System (ITS), which aims to provide\ninformation communication between vehicles. A safety-critical vehicular\ncommunication requires security, privacy, auditability, and efficiency. To\nsatisfy these requirements simultaneously, several conditional\nprivacy-preserving authentication schemes are proposed by employing ring\nsignature. However, these methods have been paid too little attention to the\nissues like \\textit{how to choose the valid ring members} or \\textit{how to set\nup a ring}. In this paper, we introduce an efficient conditional\nprivacy-preserving scheme which provides an appropriate approach establishing\nthe list of ring members. Moreover, our proposed scheme also supports batch\nverification to significantly reduce the computational cost. According to the\nanalysis of security, our scheme is sufficiently resistant against several\ncommon attacks in VANETs. The performance results show that the proposed scheme\nis efficient and practical with both low computation and communication cost.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 07:17:46 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Liu", "Feng", ""], ["Wang", "Qi", ""]]}, {"id": "1909.13256", "submitter": "Jason R.C. Nurse Dr", "authors": "Maria Bada and Jason R. C. Nurse", "title": "The Social and Psychological Impact of Cyber-Attacks", "comments": "21 pages", "journal-ref": "Benson, Vladlena and McAlaney, John, eds. (2019). Emerging Cyber\n  Threats and Cognitive Vulnerabilities. pp. 73-92", "doi": "10.1016/B978-0-12-816203-3.00004-6", "report-no": null, "categories": "cs.CY cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-attacks have become as commonplace as the Internet itself. Each year,\nindustry reports, media outlets and academic articles highlight this increased\nprevalence, spanning both the amount and variety of attacks and cybercrimes. In\nthis article, we seek to further advance discussions on cyber threats,\ncognitive vulnerabilities and cyberpsychology through a critical reflection on\nthe social and psychological aspects related to cyber-attacks. In particular,\nwe are interested in understanding how members of the public perceive and\nengage with risk and how they are impacted during and after a cyber-attack has\noccurred. This research focuses on key cognitive issues relevant to\ncomprehending public reactions to malicious cyber events including risk\nperception, protection motivation, culture, and attacker characteristics (e.g.,\nattacker identity, target identity and scale of attack). To consider the\napplicability of our findings, we investigate two significant cyber-attacks\nover the last few years, namely the WannaCry attack of 2017 and the Lloyds\nBanking Group attack in the same year.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 11:11:57 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Bada", "Maria", ""], ["Nurse", "Jason R. C.", ""]]}, {"id": "1909.13441", "submitter": "Xiaodan Xi", "authors": "Ye Wang, Xiaodan Xi, Michael Orshansky", "title": "Lattice PUF: A Strong Physical Unclonable Function Provably Secure\n  against Machine Learning Attacks", "comments": "11 pages, 8 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a strong physical unclonable function (PUF) provably secure\nagainst machine learning (ML) attacks with both classical and quantum\ncomputers. Its security is derived from cryptographic hardness of learning\ndecryption functions of public-key cryptosystems. Our design compactly realizes\nthe decryption function of the learning-with-errors (LWE) cryptosystem. Due to\nthe fundamental connection of LWE to lattice problems, we call the construction\nthe lattice PUF.\n  Lattice PUF is constructed using a physically obfuscated key (POK), an LWE\ndecryption function block, and a linear-feedback shift register (LFSR) as a\npseudo-random number generator. The POK provides the secret key of the LWE\ndecryption function; its stability is ensured by a fuzzy extractor (FE). To\nreduce the challenge size, we exploit distributional relaxations of\nspace-efficient LWEs. That allows only a small challenge-seed to be transmitted\nwith the full-length challenge generated by the LFSR, resulting in a 100X\nreduction of communication cost. To prevent an active challenge-manipulation\nattack, a self-incrementing counter is embedded into the challenge seed.\n  We prototyped the lattice PUF with 2^136 challenge-response pairs (CRPs) on a\nSpartan 6 FPGA, which required 45 slices for the PUF logic proper and 233\nslices for the FE. Simulation-based evaluation shows the mean (std) of\nuniformity to be 49.98% (1.58%), of uniqueness to be 50.00% (1.58%), and of\nreliability to be 1.26% (2.88%). The LWE concrete hardness estimator guarantees\nthat a successful ML attack of the lattice PUF will require the infeasible\n2^128 CPU operations. Several classes of empirical ML attacks, including\nsupport vector machine, logistic regression, and deep neural networks, are\nused: in all attacks, the prediction error remains above 49.76% after 1 million\ntraining CRPs.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 03:33:58 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 21:24:23 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Wang", "Ye", ""], ["Xi", "Xiaodan", ""], ["Orshansky", "Michael", ""]]}, {"id": "1909.13683", "submitter": "Steven Reiss", "authors": "Steven P. Reiss", "title": "Continuous Flow Analysis to Detect Security Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a tool that supports continuous flow analysis in order to detect\nsecurity problems as the user edits. The tool uses abstract interpretation over\nboth byte codes and abstract syntax trees to trace the flow of both type\nannotations and system states from their sources to security problems. The flow\nanalysis achieves a balance between performance and accuracy in order to detect\nsecurity vulnerabilities within seconds, and uses incremental update to provide\nimmediate feedback to the programmer. Resource files are used to specify the\nspecific security constraints of an application and to tune the analysis. The\nsystem can also provide detailed information to the programmer as to why it\nflagged a particular problem. The tool is integrated into the Code Bubbles\ndevelopment environment.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 13:28:19 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Reiss", "Steven P.", ""]]}, {"id": "1909.13708", "submitter": "Rog\\'erio De Lemos", "authors": "Lionel Montrieux, Rogerio de Lemos, Chris Bailey", "title": "Engineering Self-adaptive Authorisation Infrastructures", "comments": "A shorter version of the this paper appeared in: Montrieux L., de\n  Lemos R., Bailey C. (2019) Challenges in Engineering Self-Adaptive\n  Authorisation Infrastructures. In: Yu Y. et al. (eds) Engineering Adaptive\n  Software Systems. Springer, Singapore", "journal-ref": null, "doi": "10.1007/978-981-13-2185-6_3", "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As organisations expand and interconnect, authorisation infrastructures\nbecome increasingly difficult to manage. Several solutions have been proposed,\nincluding self-adaptive authorisation, where the access control policies are\ndynamically adapted at run-time to respond to misuse and malicious behaviour.\nThe ultimate goal of self-adaptive authorisation is to reduce human\nintervention, make authorisation infrastructures more responsive to malicious\nbehaviour, and manage access control in a more cost effective way. In this\npaper, we scope and define the emerging area of self-adaptive authorisation by\ndescribing some of its developments, trends and challenges. For that, we start\nby identifying key concepts related to access control and authorisation\ninfrastructures, and provide a brief introduction to self-adaptive software\nsystems, which provides the foundation for investigating how self-adaptation\ncan enable the enforcement of authorisation policies. The outcome of this study\nis the identification of several technical challenges related to self-adaptive\nauthorisation, which are classified according to the different stages of a\nfeedback control loop.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 13:59:09 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Montrieux", "Lionel", ""], ["de Lemos", "Rogerio", ""], ["Bailey", "Chris", ""]]}, {"id": "1909.13721", "submitter": "Andrey Sapegin", "authors": "Andrey Sapegin and Christoph Meinel", "title": "K-Metamodes: frequency- and ensemble-based distributed k-modes\n  clustering for security analytics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays processing of Big Security Data, such as log messages, is commonly\nused for intrusion detection purposed. Its heterogeneous nature, as well as\ncombination of numerical and categorical attributes does not allow to apply the\nexisting data mining methods directly on the data without feature\npreprocessing. Therefore, a rather computationally expensive conversion of\ncategorical attributes into vector space should be utilised for analysis of\nsuch data. However, a well-known k-modes algorithm allows to cluster the\ncategorical data directly and avoid conversion into the vector space. The\nexisting implementations of k-modes for Big Data processing are ensemble-based\nand utilise two-step clustering, where data subsets are first clustered\nindependently, whereas the resulting cluster modes are clustered again in order\nto calculate metamodes valid for all data subsets. In this paper, the novel\nfrequency-based distance function is proposed for the second step of\nensemble-based k-modes clustering. Besides this, the existing feature\ndiscretisation method from the previous work is utilised in order to adapt\nk-modes for processing of mixed data sets. The resulting k-metamodes algorithm\nwas tested on two public security data sets and reached higher effectiveness in\ncomparison with the previous work.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 14:05:50 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Sapegin", "Andrey", ""], ["Meinel", "Christoph", ""]]}, {"id": "1909.13770", "submitter": "Christian Schaffner", "authors": "Yfke Dulek, Alex B. Grilo, Stacey Jeffery, Christian Majenz, Christian\n  Schaffner", "title": "Secure Multi-party Quantum Computation with a Dishonest Majority", "comments": "v2: added summarizing section about complexity, a few figures, and\n  various minor improvements. Main text: 29 pages, appendices: 22 pages", "journal-ref": "Advances in Cryptology - EUROCRYPT 2020. EUROCRYPT 2020. Lecture\n  Notes in Computer Science, vol 12107. Springer, Cham", "doi": "10.1007/978-3-030-45727-3_25", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cryptographic task of secure multi-party (classical) computation has\nreceived a lot of attention in the last decades. Even in the extreme case where\na computation is performed between $k$ mutually distrustful players, and\nsecurity is required even for the single honest player if all other players are\ncolluding adversaries, secure protocols are known. For quantum computation, on\nthe other hand, protocols allowing arbitrary dishonest majority have only been\nproven for $k=2$. In this work, we generalize the approach taken by Dupuis,\nNielsen and Salvail (CRYPTO 2012) in the two-party setting to devise a secure,\nefficient protocol for multi-party quantum computation for any number of\nplayers $k$, and prove security against up to $k-1$ colluding adversaries. The\nquantum round complexity of the protocol for computing a quantum circuit of\n$\\{\\mathsf{CNOT, T}\\}$ depth $d$ is $O(k \\cdot (d + \\log n))$, where $n$ is the\nsecurity parameter. To achieve efficiency, we develop a novel public\nverification protocol for the Clifford authentication code, and a testing\nprotocol for magic-state inputs, both using classical multi-party computation.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 15:11:04 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 18:42:58 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Dulek", "Yfke", ""], ["Grilo", "Alex B.", ""], ["Jeffery", "Stacey", ""], ["Majenz", "Christian", ""], ["Schaffner", "Christian", ""]]}, {"id": "1909.13830", "submitter": "Ryan Rogers", "authors": "Jinshuo Dong, David Durfee, Ryan Rogers", "title": "Optimal Differential Privacy Composition for Exponential Mechanisms and\n  the Cost of Adaptivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Composition is one of the most important properties of differential privacy\n(DP), as it allows algorithm designers to build complex private algorithms from\nDP primitives. We consider precise composition bounds of the overall privacy\nloss for exponential mechanisms, one of the fundamental classes of mechanisms\nin DP. We give explicit formulations of the optimal privacy loss for both the\nadaptive and non-adaptive settings. For the non-adaptive setting in which each\nmechanism has the same privacy parameter, we give an efficiently computable\nformulation of the optimal privacy loss. Furthermore, we show that there is a\ndifference in the privacy loss when the exponential mechanism is chosen\nadaptively versus non-adaptively. To our knowledge, it was previously unknown\nwhether such a gap existed for any DP mechanisms with fixed privacy parameters,\nand we demonstrate the gap for a widely used class of mechanism in a natural\nsetting. We then improve upon the best previously known upper bounds for\nadaptive composition of exponential mechanisms with efficiently computable\nformulations and show the improvement.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 16:45:50 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 19:39:52 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Dong", "Jinshuo", ""], ["Durfee", "David", ""], ["Rogers", "Ryan", ""]]}]