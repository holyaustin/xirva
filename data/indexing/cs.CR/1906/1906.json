[{"id": "1906.00029", "submitter": "Elan Rosenfeld", "authors": "Elan Rosenfeld, Santosh Vempala, Manuel Blum", "title": "Human-Usable Password Schemas: Beyond Information-Theoretic Security", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Password users frequently employ passwords that are too simple, or they just\nreuse passwords for multiple websites. A common complaint is that utilizing\nsecure passwords is too difficult. One possible solution to this problem is to\nuse a password schema. Password schemas are deterministic functions which map\nchallenges (typically the website name) to responses (passwords). Previous work\nhas been done on developing and analyzing publishable schemas, but these\nanalyses have been information-theoretic, not complexity-theoretic; they\nconsider an adversary with infinite computing power.\n  We perform an analysis with respect to adversaries having currently\nachievable computing capabilities, assessing the realistic practical security\nof such schemas. We prove for several specific schemas that a computer is no\nworse off than an infinite adversary and that it can successfully extract all\ninformation from leaked challenges and their respective responses, known as\nchallenge-response pairs. We also show that any schema that hopes to be secure\nagainst adversaries with bounded computation should obscure information in a\nvery specific way, by introducing many possible constraints with each\nchallenge-response pair. These surprising results put the analyses of password\nschemas on a more solid and practical footing.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 18:51:18 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Rosenfeld", "Elan", ""], ["Vempala", "Santosh", ""], ["Blum", "Manuel", ""]]}, {"id": "1906.00076", "submitter": "Tugba Erpek", "authors": "Yalin E. Sagduyu, Yi Shi, Tugba Erpek", "title": "IoT Network Security from the Perspective of Adversarial Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning finds rich applications in Internet of Things (IoT) networks\nsuch as information retrieval, traffic management, spectrum sensing, and signal\nauthentication. While there is a surge of interest to understand the security\nissues of machine learning, their implications have not been understood yet for\nwireless applications such as those in IoT systems that are susceptible to\nvarious attacks due the open and broadcast nature of wireless communications.\nTo support IoT systems with heterogeneous devices of different priorities, we\npresent new techniques built upon adversarial machine learning and apply them\nto three types of over-the-air (OTA) wireless attacks, namely jamming, spectrum\npoisoning, and priority violation attacks. By observing the spectrum, the\nadversary starts with an exploratory attack to infer the channel access\nalgorithm of an IoT transmitter by building a deep neural network classifier\nthat predicts the transmission outcomes. Based on these prediction results, the\nwireless attack continues to either jam data transmissions or manipulate\nsensing results over the air (by transmitting during the sensing phase) to fool\nthe transmitter into making wrong transmit decisions in the test phase\n(corresponding to an evasion attack). When the IoT transmitter collects sensing\nresults as training data to retrain its channel access algorithm, the adversary\nlaunches a causative attack to manipulate the input data to the transmitter\nover the air. We show that these attacks with different levels of energy\nconsumption and stealthiness lead to significant loss in throughput and success\nratio in wireless communications for IoT systems. Then we introduce a defense\nmechanism that systematically increases the uncertainty of the adversary at the\ninference stage and improves the performance. Results provide new insights on\nhow to attack and defend IoT networks using deep learning.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 20:54:54 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Sagduyu", "Yalin E.", ""], ["Shi", "Yi", ""], ["Erpek", "Tugba", ""]]}, {"id": "1906.00148", "submitter": "Qian Lou", "authors": "Qian Lou and Lei Jiang", "title": "SHE: A Fast and Accurate Deep Neural Network for Encrypted Data", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Homomorphic Encryption (HE) is one of the most promising security solutions\nto emerging Machine Learning as a Service (MLaaS). Leveled-HE (LHE)-enabled\nConvolutional Neural Networks (LHECNNs) are proposed to implement MLaaS to\navoid large bootstrapping overhead. However, prior LHECNNs have to pay\nsignificant computing overhead but achieve only low inference accuracy, due to\ntheir polynomial approximation activations and poolings. Stacking many\npolynomial approximation activation layers in a network greatly reduces\ninference accuracy, since the polynomial approximation activation errors lead\nto a low distortion of the output distribution of the next batch normalization\nlayer. So the polynomial approximation activations and poolings have become the\nobstacle to a fast and accurate LHECNN model.\n  In this paper, we propose a Shift-accumulation-based LHE-enabled deep neural\nnetwork (SHE) for fast and accurate inferences on encrypted data. We use the\nbinary-operation-friendly Leveled Fast Homomorphic Encryption over Torus\n(LTFHE) encryption scheme to implement ReLU activations and max poolings. We\nalso adopt the logarithmic quantization to accelerate inferences by replacing\nexpensive LTFHE multiplications with cheap LTFHE shifts. We propose a mixed\nbitwidth accumulator to accelerate accumulations. Since the LTFHE ReLU\nactivations, max poolings, shifts and accumulations have small multiplicative\ndepth overhead, SHE can implement much deeper network architectures with more\nconvolutional and activation layers. Our experimental results show SHE achieves\nthe state-of-the-art inference accuracy and reduces the inference latency by\n76.21% ~ 94.23% over prior LHECNNs on MNIST and CIFAR-10. The source code of\nSHE is available at https://github.com/qianlou/SHE.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 03:53:27 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 21:19:09 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Lou", "Qian", ""], ["Jiang", "Lei", ""]]}, {"id": "1906.00166", "submitter": "Muhammad Ikram", "authors": "Saad Sajid Hashmi, Muhammad Ikram, Mohamed Ali Kaafar", "title": "A Longitudinal Analysis of Online Ad-Blocking Blacklists", "comments": "9", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Websites employ third-party ads and tracking services leveraging cookies and\nJavaScript code, to deliver ads and track users' behavior, causing privacy\nconcerns. To limit online tracking and block advertisements, several\nad-blocking (black) lists have been curated consisting of URLs and domains of\nwell-known ads and tracking services. Using Internet Archive's Wayback Machine\nin this paper, we collect a retrospective view of the Web to analyze the\nevolution of ads and tracking services and evaluate the effectiveness of\nad-blocking blacklists. We propose metrics to capture the efficacy of\nad-blocking blacklists to investigate whether these blacklists have been\nreactive or proactive in tackling the online ad and tracking services. We\nintroduce a stability metric to measure the temporal changes in ads and\ntracking domains blocked by ad-blocking blacklists, and a diversity metric to\nmeasure the ratio of new ads and tracking domains detected. We observe that ads\nand tracking domains in websites change over time, and among the ad-blocking\nblacklists that we investigated, our analysis reveals that some blacklists were\nmore informed with the existence of ads and tracking domains, but their rate of\nchange was slower than other blacklists. Our analysis also shows that Alexa top\n5K websites in the US, Canada, and the UK have the most number of ads and\ntracking domains per website, and have the highest proactive scores. This\nsuggests that ad-blocking blacklists are updated by prioritizing ads and\ntracking domains reported in the popular websites from these countries.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 06:52:18 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Hashmi", "Saad Sajid", ""], ["Ikram", "Muhammad", ""], ["Kaafar", "Mohamed Ali", ""]]}, {"id": "1906.00204", "submitter": "Sid Ahmed Fezza", "authors": "Sid Ahmed Fezza, Yassine Bakhti, Wassim Hamidouche, Olivier D\\'eforges", "title": "Perceptual Evaluation of Adversarial Attacks for CNN-based Image\n  Classification", "comments": "Eleventh International Conference on Quality of Multimedia Experience\n  (QoMEX 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have recently achieved state-of-the-art\nperformance and provide significant progress in many machine learning tasks,\nsuch as image classification, speech processing, natural language processing,\netc. However, recent studies have shown that DNNs are vulnerable to adversarial\nattacks. For instance, in the image classification domain, adding small\nimperceptible perturbations to the input image is sufficient to fool the DNN\nand to cause misclassification. The perturbed image, called \\textit{adversarial\nexample}, should be visually as close as possible to the original image.\nHowever, all the works proposed in the literature for generating adversarial\nexamples have used the $L_{p}$ norms ($L_{0}$, $L_{2}$ and $L_{\\infty}$) as\ndistance metrics to quantify the similarity between the original image and the\nadversarial example. Nonetheless, the $L_{p}$ norms do not correlate with human\njudgment, making them not suitable to reliably assess the perceptual\nsimilarity/fidelity of adversarial examples. In this paper, we present a\ndatabase for visual fidelity assessment of adversarial examples. We describe\nthe creation of the database and evaluate the performance of fifteen\nstate-of-the-art full-reference (FR) image fidelity assessment metrics that\ncould substitute $L_{p}$ norms. The database as well as subjective scores are\npublicly available to help designing new metrics for adversarial examples and\nto facilitate future research works.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 11:26:22 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Fezza", "Sid Ahmed", ""], ["Bakhti", "Yassine", ""], ["Hamidouche", "Wassim", ""], ["D\u00e9forges", "Olivier", ""]]}, {"id": "1906.00230", "submitter": "Matthew Willetts", "authors": "Matthew Willetts, Alexander Camuto, Tom Rainforth, Stephen Roberts,\n  Chris Holmes", "title": "Improving VAEs' Robustness to Adversarial Attack", "comments": "Main paper of 9 pages, followed by appendix", "journal-ref": "International Conference on Learning Representations (ICLR) 2021", "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAEs) have recently been shown to be vulnerable to\nadversarial attacks, wherein they are fooled into reconstructing a chosen\ntarget image. However, how to defend against such attacks remains an open\nproblem. We make significant advances in addressing this issue by introducing\nmethods for producing adversarially robust VAEs. Namely, we first demonstrate\nthat methods proposed to obtain disentangled latent representations produce\nVAEs that are more robust to these attacks. However, this robustness comes at\nthe cost of reducing the quality of the reconstructions. We ameliorate this by\napplying disentangling methods to hierarchical VAEs. The resulting models\nproduce high-fidelity autoencoders that are also adversarially robust. We\nconfirm their capabilities on several different datasets and with current\nstate-of-the-art VAE adversarial attacks, and also show that they increase the\nrobustness of downstream tasks to attack.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 14:29:01 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 17:25:01 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 15:51:04 GMT"}, {"version": "v4", "created": "Tue, 14 Jul 2020 16:17:46 GMT"}, {"version": "v5", "created": "Wed, 13 Jan 2021 18:25:42 GMT"}, {"version": "v6", "created": "Fri, 29 Jan 2021 18:54:23 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Willetts", "Matthew", ""], ["Camuto", "Alexander", ""], ["Rainforth", "Tom", ""], ["Roberts", "Stephen", ""], ["Holmes", "Chris", ""]]}, {"id": "1906.00389", "submitter": "Bogdan Kulynych", "authors": "Mohammad Yaghini, Bogdan Kulynych, Giovanni Cherubin, Carmela Troncoso", "title": "Disparate Vulnerability: on the Unfairness of Privacy Attacks Against\n  Machine Learning", "comments": "Mohammad Yaghini and Bogdan Kulynych contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A membership inference attack (MIA) against a machine learning model enables\nan attacker to determine whether a given data record was part of the model's\ntraining data or not. The effectiveness of these attacks is reported using\nmetrics computed across the whole population (e.g., average attack accuracy).\nIn this paper, we show that the attack success varies across different\nsubgroups of the data (e.g., race, gender), i.e., there is \\emph{disparate\nvulnerability}. Even if MIA's success looks no better than random guessing over\nthe whole population, subgroups can still be vulnerable. We study the necessary\nand sufficient conditions for a classifier to exhibit disparate vulnerability,\nand we determine to what extent certain learning techniques (e.g., fairness\nconstraints, differential privacy) can prevent it. Our work provides a\ntheoretical framework for studying MIA attacks from a new perspective.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 11:37:00 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 12:33:38 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Yaghini", "Mohammad", ""], ["Kulynych", "Bogdan", ""], ["Cherubin", "Giovanni", ""], ["Troncoso", "Carmela", ""]]}, {"id": "1906.00426", "submitter": "Igor Semaev", "authors": "Igor Semaev", "title": "New non-linearity parameters of Boolean functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of non-linearity (linearity) of Boolean function was initiated by\nRothaus in 1976. The classical non-linearity of a Boolean function is the\nminimum Hamming distance of its truth table to that of affine functions. In\nthis note we introduce new \"multidimensional\" non-linearity parameters\n$(N_f,H_f)$ for conventional and vectorial Boolean functions $f$ with $m$\ncoordinates in $n$ variables. The classical non-linearity may be treated as a\n1-dimensional parameter in the new definition. $r$-dimensional parameters for\n$r\\geq 2$ are relevant to possible multidimensional extensions of the Fast\nCorrelation Attack in stream ciphers and Linear Cryptanalysis in block ciphers.\nBesides we introduce a notion of optimal vectorial Boolean functions relevant\nto the new parameters. For $r=1$ and even $n\\geq 2m$ optimal Boolean functions\nare exactly perfect nonlinear functions (generalizations of Rothaus' bent\nfunctions) defined by Nyberg in 1991. By a computer search we find that this\nproperty holds for $r=2, m=1, n=4$ too. That is an open problem for larger\n$n,m$ and $r\\geq 2$. The definitions may be easily extended to $q$-ary\nfunctions.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 15:35:18 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Semaev", "Igor", ""]]}, {"id": "1906.00567", "submitter": "Aidin Ferdowsi", "authors": "Aidin Ferdowsi and Walid Saad", "title": "Generative Adversarial Networks for Distributed Intrusion Detection in\n  the Internet of Things", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To reap the benefits of the Internet of Things (IoT), it is imperative to\nsecure the system against cyber attacks in order to enable mission critical and\nreal-time applications. To this end, intrusion detection systems (IDSs) have\nbeen widely used to detect anomalies caused by a cyber attacker in IoT systems.\nHowever, due to the large-scale nature of the IoT, an IDS must operate in a\ndistributed manner with minimum dependence on a central controller. Moreover,\nin many scenarios such as health and financial applications, the datasets are\nprivate and IoTDs may not intend to share such data. To this end, in this\npaper, a distributed generative adversarial network (GAN) is proposed to\nprovide a fully distributed IDS for the IoT so as to detect anomalous behavior\nwithout reliance on any centralized controller. In this architecture, every\nIoTD can monitor its own data as well as neighbor IoTDs to detect internal and\nexternal attacks. In addition, the proposed distributed IDS does not require\nsharing the datasets between the IoTDs, thus, it can be implemented in IoTs\nthat preserve the privacy of user data such as health monitoring systems or\nfinancial applications. It is shown analytically that the proposed distributed\nGAN has higher accuracy of detecting intrusion compared to a standalone IDS\nthat has access to only a single IoTD dataset. Simulation results show that,\nthe proposed distributed GAN-based IDS has up to 20% higher accuracy, 25%\nhigher precision, and 60% lower false positive rate compared to a standalone\nGAN-based IDS.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 04:32:46 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Ferdowsi", "Aidin", ""], ["Saad", "Walid", ""]]}, {"id": "1906.00574", "submitter": "Alex James Dr", "authors": "Alex Pappachen James", "title": "An overview of memristive cryptography", "comments": "European Physical Journal: Special Topics, Special Issue on\n  \"Memristor-based systems: Nonlinearity, dynamics and application", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smaller, smarter and faster edge devices in the Internet of things era\ndemands secure data analysis and transmission under resource constraints of\nhardware architecture. Lightweight cryptography on edge hardware is an emerging\ntopic that is essential to ensure data security in near-sensor computing\nsystems such as mobiles, drones, smart cameras, and wearables. In this article,\nthe current state of memristive cryptography is placed in the context of\nlightweight hardware cryptography. The paper provides a brief overview of the\ntraditional hardware lightweight cryptography and cryptanalysis approaches. The\ncontrast for memristive cryptography with respect to traditional approaches is\nevident through this article, and need to develop a more concrete approach to\ndeveloping memristive cryptanalysis to test memristive cryptographic approaches\nis highlighted.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 04:58:42 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["James", "Alex Pappachen", ""]]}, {"id": "1906.00621", "submitter": "Roberto Natella", "authors": "Domenico Cotroneo, Antonio Ken Iannillo, Roberto Natella", "title": "Evolutionary Fuzzing of Android OS Vendor System Services", "comments": null, "journal-ref": null, "doi": "10.1007/s10664-019-09725-6", "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Android devices are shipped in several flavors by more than 100 manufacturer\npartners, which extend the Android \"vanilla\" OS with new system services, and\nmodify the existing ones. These proprietary extensions expose Android devices\nto reliability and security issues. In this paper, we propose a coverage-guided\nfuzzing platform (Chizpurfle) based on evolutionary algorithms to test\nproprietary Android system services. A key feature of this platform is the\nability to profile coverage on the actual, unmodified Android device, by taking\nadvantage of dynamic binary re-writing techniques. We applied this solution on\nthree high-end commercial Android smartphones. The results confirmed that\nevolutionary fuzzing is able to test Android OS system services more\nefficiently than blind fuzzing. Furthermore, we evaluate the impact of\ndifferent choices for the fitness function and selection algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 08:09:53 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Cotroneo", "Domenico", ""], ["Iannillo", "Antonio Ken", ""], ["Natella", "Roberto", ""]]}, {"id": "1906.00639", "submitter": "Peichen Xie", "authors": "Peichen Xie, Bingzhe Wu, Guangyu Sun", "title": "BAYHENN: Combining Bayesian Deep Learning and Homomorphic Encryption for\n  Secure DNN Inference", "comments": "accepted by IJCAI 2019; camera ready", "journal-ref": null, "doi": "10.24963/ijcai.2019/671", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep learning as a service (DLaaS) has emerged as a promising way\nto facilitate the employment of deep neural networks (DNNs) for various\npurposes. However, using DLaaS also causes potential privacy leakage from both\nclients and cloud servers. This privacy issue has fueled the research interests\non the privacy-preserving inference of DNN models in the cloud service. In this\npaper, we present a practical solution named BAYHENN for secure DNN inference.\nIt can protect both the client's privacy and server's privacy at the same time.\nThe key strategy of our solution is to combine homomorphic encryption and\nBayesian neural networks. Specifically, we use homomorphic encryption to\nprotect a client's raw data and use Bayesian neural networks to protect the DNN\nweights in a cloud server. To verify the effectiveness of our solution, we\nconduct experiments on MNIST and a real-life clinical dataset. Our solution\nachieves consistent latency decreases on both tasks. In particular, our method\ncan outperform the best existing method (GAZELLE) by about 5x, in terms of\nend-to-end latency.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 08:51:07 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 06:04:11 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Xie", "Peichen", ""], ["Wu", "Bingzhe", ""], ["Sun", "Guangyu", ""]]}, {"id": "1906.00745", "submitter": "Violetta Weger", "authors": "Karan Khathuria and Joachim Rosenthal and Violetta Weger", "title": "Encryption Scheme Based on Expanded Reed-Solomon Codes", "comments": null, "journal-ref": null, "doi": "10.3934/amc.2020053", "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a code-based public-key cryptosystem, in which we use Reed-Solomon\ncodes over an extension field as secret codes and disguise it by considering\nits shortened expanded code over the base field. Considering shortened expanded\ncodes provides a safeguard against distinguisher attacks based on the Schur\nproduct. Moreover, without using a cyclic or a quasi-cyclic structure we obtain\na key size reduction of nearly $45 \\%$ compared to the classic McEliece\ncryptosystem proposed by Bernstein et al.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 12:32:11 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 13:20:30 GMT"}, {"version": "v3", "created": "Fri, 25 Oct 2019 10:34:54 GMT"}, {"version": "v4", "created": "Tue, 26 Nov 2019 10:47:25 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Khathuria", "Karan", ""], ["Rosenthal", "Joachim", ""], ["Weger", "Violetta", ""]]}, {"id": "1906.00830", "submitter": "Sebastian Szyller", "authors": "Sebastian Szyller, Buse Gul Atli, Samuel Marchal, N. Asokan", "title": "DAWN: Dynamic Adversarial Watermarking of Neural Networks", "comments": "Shorter version of this work to appear in Proceedings of the ACM\n  Multimedia 2021; 16 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training machine learning (ML) models is expensive in terms of computational\npower, amounts of labeled data and human expertise. Thus, ML models constitute\nintellectual property (IP) and business value for their owners. Embedding\ndigital watermarks during model training allows a model owner to later identify\ntheir models in case of theft or misuse. However, model functionality can also\nbe stolen via model extraction, where an adversary trains a surrogate model\nusing results returned from a prediction API of the original model. Recent work\nhas shown that model extraction is a realistic threat. Existing watermarking\nschemes are ineffective against IP theft via model extraction since it is the\nadversary who trains the surrogate model. In this paper, we introduce DAWN\n(Dynamic Adversarial Watermarking of Neural Networks), the first approach to\nuse watermarking to deter model extraction IP theft. Unlike prior watermarking\nschemes, DAWN does not impose changes to the training process but it operates\nat the prediction API of the protected model, by dynamically changing the\nresponses for a small subset of queries (e.g., <0.5%) from API clients. This\nset is a watermark that will be embedded in case a client uses its queries to\ntrain a surrogate model. We show that DAWN is resilient against two\nstate-of-the-art model extraction attacks, effectively watermarking all\nextracted surrogate models, allowing model owners to reliably demonstrate\nownership (with confidence $>1- 2^{-64}$), incurring negligible loss of\nprediction accuracy (0.03-0.5%).\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 14:25:30 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 11:35:09 GMT"}, {"version": "v3", "created": "Wed, 18 Sep 2019 21:15:41 GMT"}, {"version": "v4", "created": "Thu, 18 Jun 2020 08:28:41 GMT"}, {"version": "v5", "created": "Fri, 16 Jul 2021 12:11:57 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Szyller", "Sebastian", ""], ["Atli", "Buse Gul", ""], ["Marchal", "Samuel", ""], ["Asokan", "N.", ""]]}, {"id": "1906.00861", "submitter": "Niclas Kannengie{\\ss}er", "authors": "Niclas Kannengie{\\ss}er, Sebastian Lins, Tobias Dehling, Ali Sunyaev", "title": "Mind the Gap: Trade-Offs between Distributed Ledger Technology\n  Characteristics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When developing peer-to-peer applications on Distributed Ledger Technology\n(DLT), a crucial decision is the selection of a suitable DLT design (e.g.,\nEthereum) because it is hard to change the underlying DLT design post hoc. To\nfacilitate the selection of suitable DLT designs, we review DLT characteristics\nand identify trade-offs between them. Furthermore, we assess how DLT designs\naccount for these trade-offs and we develop archetypes for DLT designs that\ncater to specific quality requirements. The main purpose of our article is to\nintroduce scientific and practical audiences to the intricacies of DLT designs\nand to support development of viable applications on DLT.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 15:16:34 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 19:49:50 GMT"}, {"version": "v3", "created": "Tue, 7 Jan 2020 13:48:31 GMT"}, {"version": "v4", "created": "Tue, 4 Feb 2020 17:22:39 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Kannengie\u00dfer", "Niclas", ""], ["Lins", "Sebastian", ""], ["Dehling", "Tobias", ""], ["Sunyaev", "Ali", ""]]}, {"id": "1906.00865", "submitter": "Mouhammd Alkasassbeh Dr.", "authors": "Ghazi Al-Naymatm, Ahmed Hambouz, Mouhammd Alkasassbeh", "title": "Network Attacks Anomaly Detection Using SNMP MIB Interface Parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many approaches have evolved to enhance network attacks detection anomaly\nusing SNMP-MIBs. Most of these approaches focus on machine learning algorithms\nwith a lot of SNMP-MIB database parameters, which may consume most of hardware\nresources (CPU, memory, and bandwidth). In this paper we introduce an efficient\ndetection model to detect network attacks anomaly using Lazy.IBk as a machine\nlearning classifier and Correlation, and ReliefF as attribute evaluators on\nSNMP-MIB interface parameters. This model achieved accurate results (100%) with\nminimal hardware resources consumption. Thus, this model can be adopted in\nintrusion detection system (IDS) to increase its performance and efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 16:58:00 GMT"}, {"version": "v2", "created": "Sat, 19 Oct 2019 19:43:26 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Al-Naymatm", "Ghazi", ""], ["Hambouz", "Ahmed", ""], ["Alkasassbeh", "Mouhammd", ""]]}, {"id": "1906.00887", "submitter": "Yanjie Dong", "authors": "Yanjie Dong and Julian Cheng and Md. Jahangir Hossain and Victor C. M.\n  Leung", "title": "Secure Distributed On-Device Learning Networks With Byzantine\n  Adversaries", "comments": "This work was in part accepted by IEEE Network", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The privacy concern exists when the central server has the copies of\ndatasets. Hence, there is a paradigm shift for the learning networks to change\nfrom centralized in-cloud learning to distributed \\mbox{on-device} learning.\nBenefit from the parallel computing, the on-device learning networks have a\nlower bandwidth requirement than the in-cloud learning networks. Moreover, the\non-device learning networks also have several desirable characteristics such as\nprivacy preserving and flexibility. However, the \\mbox{on-device} learning\nnetworks are vulnerable to the malfunctioning terminals across the networks.\nThe worst-case malfunctioning terminals are the Byzantine adversaries, that can\nperform arbitrary harmful operations to compromise the learned model based on\nthe full knowledge of the networks. Hence, the design of secure learning\nalgorithms becomes an emerging topic in the on-device learning networks with\nByzantine adversaries. In this article, we present a comprehensive overview of\nthe prevalent secure learning algorithms for the two promising on-device\nlearning networks: Federated-Learning networks and decentralized-learning\nnetworks. We also review several future research directions in the\n\\mbox{Federated-Learning} and decentralized-learning networks.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 15:47:47 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Dong", "Yanjie", ""], ["Cheng", "Julian", ""], ["Hossain", "Md. Jahangir", ""], ["Leung", "Victor C. M.", ""]]}, {"id": "1906.01017", "submitter": "Sanghyun Hong", "authors": "Sanghyun Hong, Pietro Frigo, Yi\\u{g}itcan Kaya, Cristiano Giuffrida,\n  Tudor Dumitra\\c{s}", "title": "Terminal Brain Damage: Exposing the Graceless Degradation in Deep Neural\n  Networks Under Hardware Fault Attacks", "comments": "Accepted to USENIX Security Symposium (USENIX) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have been shown to tolerate \"brain damage\":\ncumulative changes to the network's parameters (e.g., pruning, numerical\nperturbations) typically result in a graceful degradation of classification\naccuracy. However, the limits of this natural resilience are not well\nunderstood in the presence of small adversarial changes to the DNN parameters'\nunderlying memory representation, such as bit-flips that may be induced by\nhardware fault attacks. We study the effects of bitwise corruptions on 19 DNN\nmodels---six architectures on three image classification tasks---and we show\nthat most models have at least one parameter that, after a specific bit-flip in\ntheir bitwise representation, causes an accuracy loss of over 90%. We employ\nsimple heuristics to efficiently identify the parameters likely to be\nvulnerable. We estimate that 40-50% of the parameters in a model might lead to\nan accuracy drop greater than 10% when individually subjected to such\nsingle-bit perturbations. To demonstrate how an adversary could take advantage\nof this vulnerability, we study the impact of an exemplary hardware fault\nattack, Rowhammer, on DNNs. Specifically, we show that a Rowhammer enabled\nattacker co-located in the same physical machine can inflict significant\naccuracy drops (up to 99%) even with single bit-flip corruptions and no\nknowledge of the model. Our results expose the limits of DNNs' resilience\nagainst parameter perturbations induced by real-world fault attacks. We\nconclude by discussing possible mitigations and future research directions\ntowards fault attack-resilient DNNs.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 18:28:09 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Hong", "Sanghyun", ""], ["Frigo", "Pietro", ""], ["Kaya", "Yi\u011fitcan", ""], ["Giuffrida", "Cristiano", ""], ["Dumitra\u015f", "Tudor", ""]]}, {"id": "1906.01030", "submitter": "Yichen Yang", "authors": "Yichen Yang, Martin Rinard", "title": "Correctness Verification of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first verification that a neural network produces a correct\noutput within a specified tolerance for every input of interest. We define\ncorrectness relative to a specification which identifies 1) a state space\nconsisting of all relevant states of the world and 2) an observation process\nthat produces neural network inputs from the states of the world. Tiling the\nstate and input spaces with a finite number of tiles, obtaining ground truth\nbounds from the state tiles and network output bounds from the input tiles,\nthen comparing the ground truth and network output bounds delivers an upper\nbound on the network output error for any input of interest. Results from a\ncase study highlight the ability of our technique to deliver tight error bounds\nfor all inputs of interest and show how the error bounds vary over the state\nand input spaces.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 19:13:24 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 16:03:29 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Yang", "Yichen", ""], ["Rinard", "Martin", ""]]}, {"id": "1906.01055", "submitter": "Nour Moustafa", "authors": "Nour Moustafa", "title": "A Systemic IoT-Fog-Cloud Architecture for Big-Data Analytics and Cyber\n  Security Systems: A Review of Fog Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Abstract--- With the rapid growth of the Internet of Things (IoT), current\nCloud systems face various drawbacks such as lack of mobility support,\nlocation-awareness, geo-distribution, high latency, as well as cyber threats.\nFog/Edge computing has been proposed for addressing some of the drawbacks, as\nit enables computing resources at the network's edges and it locally offers\nbig-data analytics rather than transmitting them to the Cloud. The Fog is\ndefined as a Cloud-like system having similar functions, including software-,\nplatform- and infrastructure-as services. The deployment of Fog applications\nfaces various security issues related to virtualisation, network monitoring,\ndata protection and attack detection. This paper proposes a systemic\nIoT-Fog-Cloud architecture that clarifies the interactions between the three\nlayers of IoT, Fog and Cloud for effectively implementing big-data analytics\nand cyber security applications. It also reviews security challenges, solutions\nand future research directions in the architecture.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 05:42:00 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Moustafa", "Nour", ""]]}, {"id": "1906.01110", "submitter": "Vahid Behzadan", "authors": "Vahid Behzadan and William Hsu", "title": "RL-Based Method for Benchmarking the Adversarial Resilience and\n  Robustness of Deep Reinforcement Learning Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the resilience and robustness of Deep Reinforcement\nLearning (DRL) policies to adversarial perturbations in the state space. We\nfirst present an approach for the disentanglement of vulnerabilities caused by\nrepresentation learning of DRL agents from those that stem from the sensitivity\nof the DRL policies to distributional shifts in state transitions. Building on\nthis approach, we propose two RL-based techniques for quantitative benchmarking\nof adversarial resilience and robustness in DRL policies against perturbations\nof state transitions. We demonstrate the feasibility of our proposals through\nexperimental evaluation of resilience and robustness in DQN, A2C, and PPO2\npolicies trained in the Cartpole environment.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 22:43:54 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Behzadan", "Vahid", ""], ["Hsu", "William", ""]]}, {"id": "1906.01119", "submitter": "Vahid Behzadan", "authors": "Vahid Behzadan and William Hsu", "title": "Analysis and Improvement of Adversarial Training in DQN Agents With\n  Adversarially-Guided Exploration (AGE)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the effectiveness of adversarial training in\nenhancing the robustness of Deep Q-Network (DQN) policies to state-space\nperturbations. We first present a formal analysis of adversarial training in\nDQN agents and its performance with respect to the proportion of adversarial\nperturbations to nominal observations used for training. Next, we consider the\nsample-inefficiency of current adversarial training techniques, and propose a\nnovel Adversarially-Guided Exploration (AGE) mechanism based on a modified\nhybrid of the $\\epsilon$-greedy algorithm and Boltzmann exploration. We verify\nthe feasibility of this exploration mechanism through experimental evaluation\nof its performance in comparison with the traditional decaying\n$\\epsilon$-greedy and parameter-space noise exploration algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 23:31:25 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Behzadan", "Vahid", ""], ["Hsu", "William", ""]]}, {"id": "1906.01121", "submitter": "Vahid Behzadan", "authors": "Vahid Behzadan and William Hsu", "title": "Adversarial Exploitation of Policy Imitation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates a class of attacks targeting the confidentiality\naspect of security in Deep Reinforcement Learning (DRL) policies. Recent\nresearch have established the vulnerability of supervised machine learning\nmodels (e.g., classifiers) to model extraction attacks. Such attacks leverage\nthe loosely-restricted ability of the attacker to iteratively query the model\nfor labels, thereby allowing for the forging of a labeled dataset which can be\nused to train a replica of the original model. In this work, we demonstrate the\nfeasibility of exploiting imitation learning techniques in launching model\nextraction attacks on DRL agents. Furthermore, we develop proof-of-concept\nattacks that leverage such techniques for black-box attacks against the\nintegrity of DRL policies. We also present a discussion on potential solution\nconcepts for mitigation techniques.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 23:38:33 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Behzadan", "Vahid", ""], ["Hsu", "William", ""]]}, {"id": "1906.01126", "submitter": "Vahid Behzadan", "authors": "Vahid Behzadan and William Hsu", "title": "Sequential Triggers for Watermarking of Deep Reinforcement Learning\n  Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel scheme for the watermarking of Deep Reinforcement\nLearning (DRL) policies. This scheme provides a mechanism for the integration\nof a unique identifier within the policy in the form of its response to a\ndesignated sequence of state transitions, while incurring minimal impact on the\nnominal performance of the policy. The applications of this watermarking scheme\ninclude detection of unauthorized replications of proprietary policies, as well\nas enabling the graceful interruption or termination of DRL activities by\nauthorized entities. We demonstrate the feasibility of our proposal via\nexperimental evaluation of watermarking a DQN policy trained in the Cartpole\nenvironment.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 23:42:44 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Behzadan", "Vahid", ""], ["Hsu", "William", ""]]}, {"id": "1906.01167", "submitter": "Lingjuan Lyu", "authors": "Lingjuan Lyu, Jiangshan Yu, Karthik Nandakumar, Yitong Li, Xingjun Ma,\n  Jiong Jin, Han Yu, and Kee Siong Ng", "title": "Towards Fair and Privacy-Preserving Federated Deep Models", "comments": "Accepted for publication in TPDS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current standalone deep learning framework tends to result in overfitting\nand low utility. This problem can be addressed by either a centralized\nframework that deploys a central server to train a global model on the joint\ndata from all parties, or a distributed framework that leverages a parameter\nserver to aggregate local model updates. Server-based solutions are prone to\nthe problem of a single-point-of-failure. In this respect, collaborative\nlearning frameworks, such as federated learning (FL), are more robust. Existing\nfederated learning frameworks overlook an important aspect of participation:\nfairness. All parties are given the same final model without regard to their\ncontributions. To address these issues, we propose a decentralized Fair and\nPrivacy-Preserving Deep Learning (FPPDL) framework to incorporate fairness into\nfederated deep learning models. In particular, we design a local credibility\nmutual evaluation mechanism to guarantee fairness, and a three-layer\nonion-style encryption scheme to guarantee both accuracy and privacy. Different\nfrom existing FL paradigm, under FPPDL, each participant receives a different\nversion of the FL model with performance commensurate with his contributions.\nExperiments on benchmark datasets demonstrate that FPPDL balances fairness,\nprivacy and accuracy. It enables federated learning ecosystems to detect and\nisolate low-contribution parties, thereby promoting responsible participation.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 02:43:42 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 01:09:35 GMT"}, {"version": "v3", "created": "Tue, 19 May 2020 10:43:55 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Lyu", "Lingjuan", ""], ["Yu", "Jiangshan", ""], ["Nandakumar", "Karthik", ""], ["Li", "Yitong", ""], ["Ma", "Xingjun", ""], ["Jin", "Jiong", ""], ["Yu", "Han", ""], ["Ng", "Kee Siong", ""]]}, {"id": "1906.01188", "submitter": "Hao Guo", "authors": "Hao Guo and Wanxin Li and Mark Nejad and Chien-Chung Shen", "title": "Access Control for Electronic Health Records with Hybrid Blockchain-Edge\n  Architecture", "comments": "Accepted to Proc. of the IEEE 2nd International Conference on\n  Blockchain (Blockchain-2019), Atlanta, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The global Electronic Health Record (EHR) market is growing dramatically and\nexpected to reach $39.7 billions by 2022. To safe-guard security and privacy of\nEHR, access control is an essential mechanism for managing EHR data. This paper\nproposes a hybrid architecture to facilitate access control of EHR data by\nusing both blockchain and edge node. Within the architecture, a\nblockchain-based controller manages identity and access control policies and\nserves as a tamper-proof log of access events. In addition, off-chain edge\nnodes store the EHR data and apply policies specified in Abbreviated Language\nFor Authorization (ALFA) to enforce attribute-based access control on EHR data\nin collaboration with the blockchain-based access control logs. We evaluate the\nproposed hybrid architecture by utilizing Hyperledger Composer Fabric\nblockchain to measure the performance of executing smart contracts and ACL\npolicies in terms of transaction processing time and response time against\nunauthorized data retrieval.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 04:01:08 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Guo", "Hao", ""], ["Li", "Wanxin", ""], ["Nejad", "Mark", ""], ["Shen", "Chien-Chung", ""]]}, {"id": "1906.01276", "submitter": "AKM Bahalul Haque", "authors": "AKM Bahalul Haque, Sharaban Tahura Nisa, Md. Amdadul Bari, Ayvee\n  Nusreen Anika", "title": "Anonymity Network Tor and Performance Analysis of ARANEA; an IOT Based\n  Privacy-Preserving Router", "comments": "16 Pages, 12 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There was a time when the word security was only confined to the physical\nprotection of things that were valuable which must be guarded against all the\nodds. Today, in a world where people can do things virtually have emerged the\nnecessity to protect the virtual world. Every single facet of our life is being\ncontrolled by the internet one way or another. There is no privacy in the\ncyberspace as the data which we are browsing on the internet is being monitored\non the other side by someone. Each work we are doing on the internet is getting\ntracked or the data are getting leaked without consent. To browse the internet\nsecurely we developed a router named Aranea which relates to the browser Tor.\nTor gives traffic anonymity and security. The Tor browser can be used in both\npositive and negative purpose. Tor encrypts data, it hides the location and\nidentity of the user, it hides the IP address of the device, it hides the\nnetwork traffic and many more. By using Tor browser each user can browse the\ninternet safely in the cyber world. Our goal is to create an additional\nsecurity bridge through the router Aranea for every user so that each user can\nsimply browse the internet anonymously.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 08:52:38 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Haque", "AKM Bahalul", ""], ["Nisa", "Sharaban Tahura", ""], ["Bari", "Md. Amdadul", ""], ["Anika", "Ayvee Nusreen", ""]]}, {"id": "1906.01285", "submitter": "AKM Bahalul Haque", "authors": "AKM Bahalul Haque", "title": "Need for Critical Cyber Defence, Security Strategy and Privacy Policy in\n  Bangladesh - Hype or Reality?", "comments": "14 Pages, 8 Figures , 1 Table", "journal-ref": "International Journal of Managing Information Technology (IJMIT)\n  Vol.11, No.1,February 2019", "doi": "10.5121/ijmit.2019.11103", "report-no": null, "categories": "cs.SI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cyber security is one of the burning issues in modern world. Increased IT\ninfrastructure has given rise to enormous chances of security breach.\nBangladesh being a relatively new member of cyber security arena has its own\ndemand and appeal. Digitalization is happening in Bangladesh for last few years\nat an appreciable rate. People are being connected to the worldwide web\ncommunity with their smart devices. These devices have their own vulnerability\nissues as well as the data shared over the internet has a very good chances of\ngetting breached. Common vulnerability issues like infecting the device with\nmalware, Trojan, virus are on the rise. Moreover, a lack of proper cyber\nsecurity policy and strategy might make the existing situation at the\nvulnerable edge of tipping point. Hence the upcoming new infrastructures will\nbe at a greater risk if the issues are not dealt with at an early age. In this\npaper common vulnerability issues including their recent attacks on cyber space\nof Bangladesh, cyber security strategy and need for data privacy policy is\ndiscussed and analysed briefly.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 09:06:40 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Haque", "AKM Bahalul", ""]]}, {"id": "1906.01337", "submitter": "Damien Desfontaines", "authors": "Damien Desfontaines and Bal\\'azs Pej\\'o", "title": "SoK: Differential Privacies", "comments": "This is the full version of the SoK paper with the same title,\n  accepted at PETS (Privacy Enhancing Technologies Symposium) 2020", "journal-ref": "PoPETS (Proceedings on Privacy Enhancing Technologies Symposium)\n  2020, issue #2", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Shortly after it was first introduced in 2006, differential privacy became\nthe flagship data privacy definition. Since then, numerous variants and\nextensions were proposed to adapt it to different scenarios and attacker\nmodels. In this work, we propose a systematic taxonomy of these variants and\nextensions. We list all data privacy definitions based on differential privacy,\nand partition them into seven categories, depending on which aspect of the\noriginal definition is modified.\n  These categories act like dimensions: variants from the same category cannot\nbe combined, but variants from different categories can be combined to form new\ndefinitions. We also establish a partial ordering of relative strength between\nthese notions by summarizing existing results. Furthermore, we list which of\nthese definitions satisfy some desirable properties, like composition,\npost-processing, and convexity by either providing a novel proof or collecting\nexisting ones.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 10:55:01 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 13:08:56 GMT"}, {"version": "v3", "created": "Tue, 17 Dec 2019 09:43:53 GMT"}, {"version": "v4", "created": "Fri, 10 Jul 2020 08:42:36 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Desfontaines", "Damien", ""], ["Pej\u00f3", "Bal\u00e1zs", ""]]}, {"id": "1906.01345", "submitter": "Esmaeil Mohammadian Koruyeh", "authors": "Esmaeil Mohammadian Koruyeh, Shirin Haji Amin Shirazi, Khaled N.\n  Khasawneh, Chengyu Song, Nael Abu-Ghazaleh", "title": "SPECCFI: Mitigating Spectre Attacks using CFI Informed Speculation", "comments": "To appear in IEEE S&P 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spectre attacks and their many subsequent variants are a new vulnerability\nclass affecting modern CPUs. The attacks rely on the ability to misguide\nspeculative execution, generally by exploiting the branch prediction\nstructures, to execute a vulnerable code sequence speculatively. In this paper,\nwe propose to use Control-Flow Integrity (CFI), a security technique used to\nstop control-flow hijacking attacks, on the committed path, to prevent\nspeculative control-flow from being hijacked to launch the most dangerous\nvariants of the Spectre attacks (Spectre-BTB and Spectre-RSB). Specifically,\nCFI attempts to constrain the possible targets of an indirect branch to a set\nof legal targets defined by a pre-calculated control-flow graph (CFG). As CFI\nis being adopted by commodity software (e.g., Windows and Android) and\ncommodity hardware (e.g., Intel's CET and ARM's BTI), the CFI information\nbecomes readily available through the hardware CFI extensions. With the CFI\ninformation, we apply CFI principles to also constrain illegal control-flow\nduring speculative execution. Specifically, our proposed defense, SPECCFI,\nensures that control flow instructions target legal destinations to constrain\ndangerous speculation on forward control-flow paths (indirect calls and\nbranches). We augment this protection with a precise speculation-aware hardware\nstack to constrain speculation on backward control-flow edges (returns). We\ncombine this solution with existing solutions against branch target predictor\nattacks (Spectre-PHT) to close all known non-vendor-specific Spectre\nvulnerabilities. We show that SPECCFI results in small overheads both in terms\nof performance and additional hardware complexity.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 11:05:30 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 21:20:28 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Koruyeh", "Esmaeil Mohammadian", ""], ["Shirazi", "Shirin Haji Amin", ""], ["Khasawneh", "Khaled N.", ""], ["Song", "Chengyu", ""], ["Abu-Ghazaleh", "Nael", ""]]}, {"id": "1906.01444", "submitter": "NhatHai Phan", "authors": "NhatHai Phan, Minh Vu, Yang Liu, Ruoming Jin, Dejing Dou, Xintao Wu,\n  and My T. Thai", "title": "Heterogeneous Gaussian Mechanism: Preserving Differential Privacy in\n  Deep Learning with Provable Robustness", "comments": "arXiv admin note: text overlap with arXiv:1903.09822", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel Heterogeneous Gaussian Mechanism (HGM) to\npreserve differential privacy in deep neural networks, with provable robustness\nagainst adversarial examples. We first relax the constraint of the privacy\nbudget in the traditional Gaussian Mechanism from (0, 1] to (0, \\infty), with a\nnew bound of the noise scale to preserve differential privacy. The noise in our\nmechanism can be arbitrarily redistributed, offering a distinctive ability to\naddress the trade-off between model utility and privacy loss. To derive\nprovable robustness, our HGM is applied to inject Gaussian noise into the first\nhidden layer. Then, a tighter robustness bound is proposed. Theoretical\nanalysis and thorough evaluations show that our mechanism notably improves the\nrobustness of differentially private deep neural networks, compared with\nbaseline approaches, under a variety of model attacks.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 18:20:36 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Phan", "NhatHai", ""], ["Vu", "Minh", ""], ["Liu", "Yang", ""], ["Jin", "Ruoming", ""], ["Dou", "Dejing", ""], ["Wu", "Xintao", ""], ["Thai", "My T.", ""]]}, {"id": "1906.01454", "submitter": "Ville Vestman", "authors": "Ville Vestman, Tomi Kinnunen, Rosa Gonz\\'alez Hautam\\\"aki, Md\n  Sahidullah", "title": "Voice Mimicry Attacks Assisted by Automatic Speaker Verification", "comments": "Published in Computer Speech and Language. arXiv admin note: text\n  overlap with arXiv:1811.03790", "journal-ref": null, "doi": "10.1016/j.csl.2019.05.005", "report-no": null, "categories": "eess.AS cs.CR cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we simulate a scenario, where a publicly available ASV system\nis used to enhance mimicry attacks against another closed source ASV system. In\nspecific, ASV technology is used to perform a similarity search between the\nvoices of recruited attackers (6) and potential target speakers (7,365) from\nVoxCeleb corpora to find the closest targets for each of the attackers. In\naddition, we consider 'median', 'furthest', and 'common' targets to serve as a\nreference points. Our goal is to gain insights how well similarity rankings\ntransfer from the attacker's ASV system to the attacked ASV system, whether the\nattackers are able to improve their attacks by mimicking, and how the\nproperties of the voices of attackers change due to mimicking. We address these\nquestions through ASV experiments, listening tests, and prosodic and formant\nanalyses. For the ASV experiments, we use i-vector technology in the attacker\nside, and x-vectors in the attacked side. For the listening tests, we recruit\nlisteners through crowdsourcing. The results of the ASV experiments indicate\nthat the speaker similarity scores transfer well from one ASV system to\nanother. Both the ASV experiments and the listening tests reveal that the\nmimicry attempts do not, in general, help in bringing attacker's scores closer\nto the target's. A detailed analysis shows that mimicking does not improve\nattacks, when the natural voices of attackers and targets are similar to each\nother. The analysis of prosody and formants suggests that the attackers were\nable to considerably change their speaking rates when mimicking, but the\nchanges in F0 and formants were modest. Overall, the results suggest that\nuntrained impersonators do not pose a high threat towards ASV systems, but the\nuse of ASV systems to attack other ASV systems is a potential threat.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 11:06:54 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 11:40:56 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Vestman", "Ville", ""], ["Kinnunen", "Tomi", ""], ["Hautam\u00e4ki", "Rosa Gonz\u00e1lez", ""], ["Sahidullah", "Md", ""]]}, {"id": "1906.01465", "submitter": "Jeffrey Uhlmann", "authors": "Truc Le and Jeffrey Uhlmann", "title": "Gap-Measure Tests with Applications to Data Integrity Verification", "comments": null, "journal-ref": "Statistics Research Letters}, Statistics Research Letters, vol. 4,\n  pp. 11-17, 2015", "doi": "10.14355/srl.2015.04.003", "report-no": null, "categories": "stat.ME cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we propose and examine gap statistics for assessing uniform\ndistribution hypotheses. We provide examples relevant to data integrity testing\nfor which max-gap statistics provide greater sensitivity than chi-square\n($\\chi^2$), thus allowing the new test to be used in place of or as a\ncomplement to $\\chi^2$ testing for purposes of distinguishing a larger class of\ndeviations from uniformity. We establish that the proposed max-gap test has the\nsame sequential and parallel computational complexity as $\\chi^2$ and thus is\napplicable for Big Data analytics and integrity verification.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 16:20:14 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Le", "Truc", ""], ["Uhlmann", "Jeffrey", ""]]}, {"id": "1906.01478", "submitter": "Vegard Antun", "authors": "Laura Thesing, Vegard Antun and Anders C. Hansen", "title": "What do AI algorithms actually learn? - On false structures in deep\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are two big unsolved mathematical questions in artificial intelligence\n(AI): (1) Why is deep learning so successful in classification problems and (2)\nwhy are neural nets based on deep learning at the same time universally\nunstable, where the instabilities make the networks vulnerable to adversarial\nattacks. We present a solution to these questions that can be summed up in two\nwords; false structures. Indeed, deep learning does not learn the original\nstructures that humans use when recognising images (cats have whiskers, paws,\nfur, pointy ears, etc), but rather different false structures that correlate\nwith the original structure and hence yield the success. However, the false\nstructure, unlike the original structure, is unstable. The false structure is\nsimpler than the original structure, hence easier to learn with less data and\nthe numerical algorithm used in the training will more easily converge to the\nneural network that captures the false structure. We formally define the\nconcept of false structures and formulate the solution as a conjecture. Given\nthat trained neural networks always are computed with approximations, this\nconjecture can only be established through a combination of theoretical and\ncomputational results similar to how one establishes a postulate in theoretical\nphysics (e.g. the speed of light is constant). Establishing the conjecture\nfully will require a vast research program characterising the false structures.\nWe provide the foundations for such a program establishing the existence of the\nfalse structures in practice. Finally, we discuss the far reaching consequences\nthe existence of the false structures has on state-of-the-art AI and Smale's\n18th problem.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 14:35:32 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Thesing", "Laura", ""], ["Antun", "Vegard", ""], ["Hansen", "Anders C.", ""]]}, {"id": "1906.01562", "submitter": "Teng Wang", "authors": "Teng Wang, Jun Zhao, Han Yu, Jinyan Liu, Xinyu Yang, Xuebin Ren, and\n  Shuyu Shi", "title": "Privacy-preserving Crowd-guided AI Decision-making in Ethical Dilemmas", "comments": "This paper has been published as a full paper in ACM International\n  Conference on Information and Knowledge Management (CIKM) 2019, held in\n  November 3-7, 2019, Beijing, China", "journal-ref": null, "doi": "10.1145/3357384.3357954", "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of artificial intelligence (AI), ethical issues\nsurrounding AI have attracted increasing attention. In particular, autonomous\nvehicles may face moral dilemmas in accident scenarios, such as staying the\ncourse resulting in hurting pedestrians or swerving leading to hurting\npassengers. To investigate such ethical dilemmas, recent studies have adopted\npreference aggregation, in which each voter expresses her/his preferences over\ndecisions for the possible ethical dilemma scenarios, and a centralized system\naggregates these preferences to obtain the winning decision. Although a useful\nmethodology for building ethical AI systems, such an approach can potentially\nviolate the privacy of voters since moral preferences are sensitive information\nand their disclosure can be exploited by malicious parties. In this paper, we\nreport a first-of-its-kind privacy-preserving crowd-guided AI decision-making\napproach in ethical dilemmas. We adopt the notion of differential privacy to\nquantify privacy and consider four granularities of privacy protection by\ntaking voter-/record-level privacy protection and centralized/distributed\nperturbation into account, resulting in four approaches VLCP, RLCP, VLDP, and\nRLDP. Moreover, we propose different algorithms to achieve these privacy\nprotection granularities, while retaining the accuracy of the learned moral\npreference model. Specifically, VLCP and RLCP are implemented with the data\naggregator setting a universal privacy parameter and perturbing the averaged\nmoral preference to protect the privacy of voters' data. VLDP and RLDP are\nimplemented in such a way that each voter perturbs her/his local moral\npreference with a personalized privacy parameter. Extensive experiments on both\nsynthetic and real data demonstrate that the proposed approach can achieve high\naccuracy of preference aggregation while protecting individual voter's privacy.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 16:27:47 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 13:22:08 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Wang", "Teng", ""], ["Zhao", "Jun", ""], ["Yu", "Han", ""], ["Liu", "Jinyan", ""], ["Yang", "Xinyu", ""], ["Ren", "Xuebin", ""], ["Shi", "Shuyu", ""]]}, {"id": "1906.01683", "submitter": "Luyao Niu", "authors": "Luyao Niu and Andrew Clark", "title": "A Differentially Private Incentive Design for Traffic Offload to Public\n  Transportationx", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasingly large trip demands have strained urban transportation capacity,\nwhich consequently leads to traffic congestion and rapid growth of greenhouse\ngas emissions. In this work, we focus on achieving sustainable transportation\nby incentivizing passengers to switch from private cars to public transport. We\naddress the following challenges. First, the passengers incur inconvenience\ncosts when changing their transit behaviors due to delay and discomfort, and\nthus need to be reimbursed. Second, the inconvenience cost, however, is unknown\nto the government when choosing the incentives. Furthermore, changing transit\nbehaviors raises privacy concerns from passengers. An adversary could infer\npersonal information, (e.g., daily routine, region of interest, and wealth), by\nobserving the decisions made by the government, which are known to the public.\nWe adopt the concept of differential privacy and propose privacy-preserving\nincentive designs under two settings, denoted as two-way communication and\none-way communication. Under two-way communication, passengers submit bids and\nthen the government determines the incentives, whereas in one-way communication\nthe government simply sets a price without acquiring information from the\npassengers. Under one-way communication, we focus on how the government should\ndesign the incentives without revealing passengers' inconvenience costs while\nstill preserving differential privacy. We formulate the problem as a convex\nprogram, and propose a differentially private and near-optimal solution\nalgorithm. A numerical case study using Caltrans Performance Measurement System\n(PeMS) data source is presented as evaluation. The results show that the\nproposed approaches achieve a win-win situation in which both the government\nand passengers obtain non-negative utilities.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 19:00:01 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 18:44:42 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Niu", "Luyao", ""], ["Clark", "Andrew", ""]]}, {"id": "1906.01777", "submitter": "Teng Wang", "authors": "Teng Wang, Jun Zhao, Xinyu Yang, and Xuebin Ren", "title": "Locally Differentially Private Data Collection and Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local differential privacy (LDP) can provide each user with strong privacy\nguarantees under untrusted data curators while ensuring accurate statistics\nderived from privatized data. Due to its powerfulness, LDP has been widely\nadopted to protect privacy in various tasks (e.g., heavy hitters discovery,\nprobability estimation) and systems (e.g., Google Chrome, Apple iOS). Although\n${\\epsilon}$-LDP has been proposed for many years, the more general notion of\n$({\\epsilon}, {\\delta})$-LDP has only been studied in very few papers, which\nmainly consider mean estimation for numeric data. Besides, prior solutions\nachieve $({\\epsilon}, {\\delta})$-LDP by leveraging Gaussian mechanism, which\nleads to low accuracy of the aggregated results. In this paper, we propose\nnovel mechanisms that achieve $({\\epsilon}, {\\delta})$-LDP with high utility in\ndata analytics and machine learning. Specifically, we first design\n$({\\epsilon}, {\\delta})$-LDP algorithms for collecting multi-dimensional\nnumeric data, which can ensure higher accuracy than the optimal Gaussian\nmechanism while guaranteeing strong privacy for each user. Then, we investigate\ndifferent local protocols for categorical attributes under $({\\epsilon},\n{\\delta})$-LDP. Furthermore, we conduct theoretical analysis on the error bound\nand variance of the proposed algorithms. Experimental results on real and\nsynthetic datasets demonstrate the high data utility of our proposed algorithms\non both simple data statistics and complex machine learning models.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 01:34:34 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Wang", "Teng", ""], ["Zhao", "Jun", ""], ["Yang", "Xinyu", ""], ["Ren", "Xuebin", ""]]}, {"id": "1906.01785", "submitter": "Michael Huth", "authors": "Kwok Cheung and Michael Huth and Laurence Kirk and Leif-Nissen\n  Lundb{\\ae}k and Rodolphe Marques and Jan Petsche", "title": "Owner-centric sharing of physical resources, data, and data-driven\n  insights in digital ecosystems", "comments": null, "journal-ref": "ACM SACMAT 2019: 73-81", "doi": "10.1145/3322431.3326326", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are living in an age in which digitization will connect more and more\nphysical assets with IT systems and where IoT endpoints will generate a wealth\nof valuable data. Companies, individual users, and organizations alike\ntherefore have the need to control their own physical or non-physical assets\nand data sources. At the same time, they recognize the need for, and\nopportunity to, share access to such data and digitized physical assets. This\npaper sets out our technology vision for such sharing ecosystems, reports\ninitial work in that direction, identifies challenges for realizing this\nvision, and seeks feedback and collaboration from the academic access-control\ncommunity in that R\\&D space.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 02:09:13 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Cheung", "Kwok", ""], ["Huth", "Michael", ""], ["Kirk", "Laurence", ""], ["Lundb\u00e6k", "Leif-Nissen", ""], ["Marques", "Rodolphe", ""], ["Petsche", "Jan", ""]]}, {"id": "1906.01831", "submitter": "Volkan Dedeoglu", "authors": "Sidra Malik, Volkan Dedeoglu, Salil S. Kanhere, and Raja Jurdak", "title": "TrustChain: Trust Management in Blockchain and IoT supported Supply\n  Chains", "comments": "10 pages, IEEE Blockchain 2019 conference paper (accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traceability and integrity are major challenges for the increasingly complex\nsupply chains of today's world. Although blockchain technology has the\npotential to address these challenges through providing a tamper-proof audit\ntrail of supply chain events and data associated with a product life-cycle, it\ndoes not solve the trust problem associated with the data itself. Reputation\nsystems are an effective approach to solve this trust problem. However, current\nreputation systems are not suited to the blockchain based supply chain\napplications as they are based on limited observations, they lack granularity\nand automation, and their overhead has not been explored. In this work, we\npropose TrustChain, as a three-layered trust management framework which uses a\nconsortium blockchain to track interactions among supply chain participants and\nto dynamically assign trust and reputation scores based on these interactions.\nThe novelty of TrustChain stems from: (a) the reputation model that evaluates\nthe quality of commodities, and the trustworthiness of entities based on\nmultiple observations of supply chain events, (b) its support for reputation\nscores that separate between a supply chain participant and products, enabling\nthe assignment of product-specific reputations for the same participant, (c)\nthe use of smart contracts for transparent, efficient, secure, and automated\ncalculation of reputation scores, and (d) its minimal overhead in terms of\nlatency and throughput when compared to a simple blockchain based supply chain\nmodel.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 05:23:57 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Malik", "Sidra", ""], ["Dedeoglu", "Volkan", ""], ["Kanhere", "Salil S.", ""], ["Jurdak", "Raja", ""]]}, {"id": "1906.01838", "submitter": "Hiroshi Sasaki", "authors": "Hiroshi Sasaki, Miguel A. Arroyo, M. Tarek Ibn Ziad, Koustubha Bhat,\n  Kanad Sinha, Simha Sethumadhavan", "title": "Practical Byte-Granular Memory Blacklisting using Califorms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent rapid strides in memory safety tools and hardware have improved\nsoftware quality and security. While coarse-grained memory safety has improved,\nachieving memory safety at the granularity of individual objects remains a\nchallenge due to high performance overheads which can be between ~1.7x-2.2x. In\nthis paper, we present a novel idea called Califorms, and associated program\nobservations, to obtain a low overhead security solution for practical,\nbyte-granular memory safety.\n  The idea we build on is called memory blacklisting, which prohibits a program\nfrom accessing certain memory regions based on program semantics. State of the\nart hardware-supported memory blacklisting while much faster than software\nblacklisting creates memory fragmentation (of the order of few bytes) for each\nuse of the blacklisted location. In this paper, we observe that metadata used\nfor blacklisting can be stored in dead spaces in a program's data memory and\nthat this metadata can be integrated into microarchitecture by changing the\ncache line format. Using these observations, Califorms based system proposed in\nthis paper reduces the performance overheads of memory safety to ~1.02x-1.16x\nwhile providing byte-granular protection and maintaining very low hardware\noverheads.\n  The low overhead offered by Califorms enables always on, memory safety for\nsmall and large objects alike, and the fundamental idea of storing metadata in\nempty spaces, and microarchitecture can be used for other security and\nperformance applications.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 05:52:23 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 02:00:48 GMT"}, {"version": "v3", "created": "Mon, 10 Jun 2019 07:10:07 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Sasaki", "Hiroshi", ""], ["Arroyo", "Miguel A.", ""], ["Ziad", "M. Tarek Ibn", ""], ["Bhat", "Koustubha", ""], ["Sinha", "Kanad", ""], ["Sethumadhavan", "Simha", ""]]}, {"id": "1906.02044", "submitter": "Johann Knechtel", "authors": "Mohammed Nabeel, Mohammed Ashraf, Satwik Patnaik, Vassos Soteriou,\n  Ozgur Sinanoglu, Johann Knechtel", "title": "An Interposer-Based Root of Trust: Seize the Opportunity for Secure\n  System-Level Integration of Untrusted Chiplets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging 2.5D interposer technology, we advocate the integration of\nuntrusted commodity components/chiplets with physically separate, entrusted\nlogic components. Such organization provides a modern root of trust for secure\nsystem-level integration. We showcase our scheme by utilizing industrial ARM\ncomponents that are interconnected via a security-providing active interposer,\nand thoroughly evaluate the achievable security via different threat scenarios.\nFinally, we provide detailed end-to-end physical design results to demonstrate\nthe efficacy of our proposed methodology.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 14:19:07 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Nabeel", "Mohammed", ""], ["Ashraf", "Mohammed", ""], ["Patnaik", "Satwik", ""], ["Soteriou", "Vassos", ""], ["Sinanoglu", "Ozgur", ""], ["Knechtel", "Johann", ""]]}, {"id": "1906.02069", "submitter": "Ivan Geffner", "authors": "Ivan Geffner and Joseph Y. Halpern", "title": "Security in Asynchronous Interactive Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secure function computation has been thoroughly studied and optimized in the\npast decades. We extend techniques used for secure computation to simulate\narbitrary protocols involving a mediator. The key feature of our notion of\nsimulation is that it is bidirectional: not only does the simulation produce\nonly outputs that could happen in the original protocol, but the simulation\nproduces all such outputs. In a synchronous system, it can be shown that this\nrequirement can already be achieved by the standard notion of secure\ncomputation. However, in an asynchronous system, new subtleties arise because\nthe scheduler can influence the output. We provide a construction that is\nsecure if $n > 4t$, where $t$ is the number malicious agents, which is provably\nthe best possible. We also show that our construction satisfies additional\nsecurity properties even if $3t < n \\le 4t$.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 15:22:56 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Geffner", "Ivan", ""], ["Halpern", "Joseph Y.", ""]]}, {"id": "1906.02108", "submitter": "Alexander Warnecke", "authors": "Alexander Warnecke, Daniel Arp, Christian Wressnegger, Konrad Rieck", "title": "Evaluating Explanation Methods for Deep Learning in Security", "comments": "IEEE European Symposium on Security and Privacy, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is increasingly used as a building block of security systems.\nUnfortunately, neural networks are hard to interpret and typically opaque to\nthe practitioner. The machine learning community has started to address this\nproblem by developing methods for explaining the predictions of neural\nnetworks. While several of these approaches have been successfully applied in\nthe area of computer vision, their application in security has received little\nattention so far. It is an open question which explanation methods are\nappropriate for computer security and what requirements they need to satisfy.\nIn this paper, we introduce criteria for comparing and evaluating explanation\nmethods in the context of computer security. These cover general properties,\nsuch as the accuracy of explanations, as well as security-focused aspects, such\nas the completeness, efficiency, and robustness. Based on our criteria, we\ninvestigate six popular explanation methods and assess their utility in\nsecurity systems for malware detection and vulnerability discovery. We observe\nsignificant differences between the methods and build on these to derive\ngeneral recommendations for selecting and applying explanation methods in\ncomputer security.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 16:36:22 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 11:40:02 GMT"}, {"version": "v3", "created": "Tue, 7 Jan 2020 10:50:48 GMT"}, {"version": "v4", "created": "Mon, 27 Apr 2020 08:10:51 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Warnecke", "Alexander", ""], ["Arp", "Daniel", ""], ["Wressnegger", "Christian", ""], ["Rieck", "Konrad", ""]]}, {"id": "1906.02152", "submitter": "Ariah Klages-Mundt", "authors": "Ariah Klages-Mundt, Andreea Minca", "title": "(In)Stability for the Blockchain: Deleveraging Spirals and Stablecoin\n  Attacks", "comments": "To be published in Cryptoeconomic Systems 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a model of stable assets, including non-custodial stablecoins\nbacked by cryptocurrencies. Such stablecoins are popular methods for\nbootstrapping price stability within public blockchain settings. We derive\nfundamental results about dynamics and liquidity in stablecoin markets,\ndemonstrate that these markets face deleveraging feedback effects that cause\nilliquidity during crises and exacerbate collateral drawdown, and characterize\nstable dynamics of the system under particular conditions. The possibility of\nsuch `deleveraging spirals' was first predicted in the initial release of our\npaper in 2019 and later directly observed during the `Black Thursday' crisis in\nDai in 2020. From these insights, we suggest design improvements that aim to\nimprove long-term stability. We also introduce new attacks that exploit\narbitrage-like opportunities around stablecoin liquidations. Using our model,\nwe demonstrate that these can be profitable. These attacks may induce\nvolatility in the `stable' asset and cause perverse incentives for miners,\nposing risks to blockchain consensus. A variant of such attacks also later\noccurred during Black Thursday, taking the form of mempool manipulation to\nclear Dai liquidation auctions at near zero prices, costing $8m.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 17:24:41 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 16:54:42 GMT"}, {"version": "v3", "created": "Tue, 2 Mar 2021 00:33:47 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Klages-Mundt", "Ariah", ""], ["Minca", "Andreea", ""]]}, {"id": "1906.02279", "submitter": "Sridhar Adepu", "authors": "Sridhar Adepu, Venkata Reddy Palleti, Gyanendra Mishra and Aditya\n  Mathur", "title": "Investigation of Cyber Attacks on a Water Distribution System", "comments": "Pre-submission to a journal. arXiv admin note: text overlap with\n  arXiv:1811.03974 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Cyber Physical System (CPS) consists of cyber components for computation\nand communication, and physical components such as sensors and actuators for\nprocess control. These components are networked and interact in a feedback\nloop. CPS are found in critical infrastructure such as water distribution,\npower grid, and mass transportation. Often these systems are vulnerable to\nattacks as the cyber components such as Supervisory Control and Data\nAcquisition workstations, Human Machine Interface and Programmable Logic\nControllers are potential targets for attackers. In this work, we report a\nstudy to investigate the impact of cyber attacks on a water distribution (WADI)\nsystem. Attacks were designed to meet attacker objectives and launched on WADI\nusing a specially designed tool. This tool enables the launch of single and\nmulti-point attacks where the latter are designed to specifically hide one or\nmore attacks. The outcome of the experiments led to a better understanding of\nattack propagation and behavior of WADI in response to the attacks as well as\nto the design of an attack detection mechanism for water distribution system.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 19:55:00 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Adepu", "Sridhar", ""], ["Palleti", "Venkata Reddy", ""], ["Mishra", "Gyanendra", ""], ["Mathur", "Aditya", ""]]}, {"id": "1906.02282", "submitter": "Shiqi Wang", "authors": "Shiqi Wang, Yizheng Chen, Ahmed Abdou, Suman Jana", "title": "Enhancing Gradient-based Attacks with Symbolic Intervals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent breakthroughs in defenses against adversarial examples, like\nadversarial training, make the neural networks robust against various classes\nof attackers (e.g., first-order gradient-based attacks). However, it is an open\nquestion whether the adversarially trained networks are truly robust under\nunknown attacks. In this paper, we present interval attacks, a new technique to\nfind adversarial examples to evaluate the robustness of neural networks.\nInterval attacks leverage symbolic interval propagation, a bound propagation\ntechnique that can exploit a broader view around the current input to locate\npromising areas containing adversarial instances, which in turn can be searched\nwith existing gradient-guided attacks. We can obtain such a broader view using\nsound bound propagation methods to track and over-approximate the errors of the\nnetwork within given input ranges. Our results show that, on state-of-the-art\nadversarially trained networks, interval attack can find on average 47%\nrelatively more violations than the state-of-the-art gradient-guided PGD\nattack.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 19:58:07 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Wang", "Shiqi", ""], ["Chen", "Yizheng", ""], ["Abdou", "Ahmed", ""], ["Jana", "Suman", ""]]}, {"id": "1906.02303", "submitter": "Lichao Sun", "authors": "Lichao Sun, Yingbo Zhou, Ji Wang, Jia Li, Richard Sochar, Philip S.\n  Yu, Caiming Xiong", "title": "Private Deep Learning with Teacher Ensembles", "comments": "fixed updated version will be updated later", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy-preserving deep learning is crucial for deploying deep neural network\nbased solutions, especially when the model works on data that contains\nsensitive information. Most privacy-preserving methods lead to undesirable\nperformance degradation. Ensemble learning is an effective way to improve model\nperformance. In this work, we propose a new method for teacher ensembles that\nuses more informative network outputs under differential private stochastic\ngradient descent and provide provable privacy guarantees. Out method employs\nknowledge distillation and hint learning on intermediate representations to\nfacilitate the training of student model. Additionally, we propose a simple\nweighted ensemble scheme that works more robustly across different teaching\nsettings. Experimental results on three common image datasets benchmark (i.e.,\nCIFAR10, MINST, and SVHN) demonstrate that our approach outperforms previous\nstate-of-the-art methods on both performance and privacy-budget.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 20:48:48 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 16:24:35 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Sun", "Lichao", ""], ["Zhou", "Yingbo", ""], ["Wang", "Ji", ""], ["Li", "Jia", ""], ["Sochar", "Richard", ""], ["Yu", "Philip S.", ""], ["Xiong", "Caiming", ""]]}, {"id": "1906.02325", "submitter": "Rafael Dowsley", "authors": "Devin Reich and Ariel Todoki and Rafael Dowsley and Martine De Cock\n  and Anderson C. A. Nascimento", "title": "Privacy-Preserving Classification of Personal Text Messages with Secure\n  Multi-Party Computation: An Application to Hate-Speech Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification of personal text messages has many useful applications in\nsurveillance, e-commerce, and mental health care, to name a few. Giving\napplications access to personal texts can easily lead to (un)intentional\nprivacy violations. We propose the first privacy-preserving solution for text\nclassification that is provably secure. Our method, which is based on Secure\nMultiparty Computation (SMC), encompasses both feature extraction from texts,\nand subsequent classification with logistic regression and tree ensembles. We\nprove that when using our secure text classification method, the application\ndoes not learn anything about the text, and the author of the text does not\nlearn anything about the text classification model used by the application\nbeyond what is given by the classification result itself. We perform end-to-end\nexperiments with an application for detecting hate speech against women and\nimmigrants, demonstrating excellent runtime results without loss of accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 21:56:33 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 04:56:11 GMT"}, {"version": "v3", "created": "Fri, 12 Mar 2021 05:14:56 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Reich", "Devin", ""], ["Todoki", "Ariel", ""], ["Dowsley", "Rafael", ""], ["De Cock", "Martine", ""], ["Nascimento", "Anderson C. A.", ""]]}, {"id": "1906.02362", "submitter": "Gururaj Saileshwar", "authors": "Gururaj Saileshwar and Moinuddin K. Qureshi", "title": "Lookout for Zombies: Mitigating Flush+Reload Attack on Shared Caches by\n  Monitoring Invalidated Lines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OS-based page sharing is a commonly used optimization in modern systems to\nreduce memory footprint. Unfortunately, such sharing can cause Flush+Reload\ncache attacks, whereby a spy periodically flushes a cache line of shared data\n(using the clflush instruction) and reloads it to infer the access patterns of\na victim application. Current proposals to mitigate Flush+Reload attacks are\nimpractical as they either disable page sharing, or require application\nrewrite, or require OS support, or incur ISA changes. Ideally, we want to\ntolerate attacks without requiring any OS or ISA support and while incurring\nnegligible performance and storage overheads.\n  This paper makes the key observation that when a cache line is invalidated\ndue to a Flush-Caused Invalidation (FCI), the tag and data of the invalidated\nline are still resident in the cache and can be used for detecting Flush-based\nattacks. We call lines invalidated due to FCI as Zombie lines. Our design\nexplicitly marks such lines as Zombies, preserves the Zombie lines in the\ncache, and uses the hits and misses to Zombie lines to tolerate the attacks. We\npropose Zombie-Based Mitigation (ZBM), a simple hardware-based design that\nsuccessfully guards against attacks by simply treating hits on Zombie-lines as\nmisses to avoid any timing leaks to the attacker. We analyze the robustness of\nZBM using three spy programs: attacking AES T-Tables, attacking RSA\nSquare-and-Multiply, and Function Watcher (FW), and show that ZBM successfully\ndefends against these attacks. Our solution requires negligible storage (4-bits\nper cache line), retains OS-based page sharing, requires no OS/ISA changes, and\ndoes not incur slowdown for benign applications.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 00:22:52 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Saileshwar", "Gururaj", ""], ["Qureshi", "Moinuddin K.", ""]]}, {"id": "1906.02439", "submitter": "Ayon Sen", "authors": "Ayon Sen, Xiaojin Zhu, Liam Marshall, Robert Nowak", "title": "Should Adversarial Attacks Use Pixel p-Norm?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks aim to confound machine learning systems, while remaining\nvirtually imperceptible to humans. Attacks on image classification systems are\ntypically gauged in terms of $p$-norm distortions in the pixel feature space.\nWe perform a behavioral study, demonstrating that the pixel $p$-norm for any\n$0\\le p \\le \\infty$, and several alternative measures including earth mover's\ndistance, structural similarity index, and deep net embedding, do not fit human\nperception. Our result has the potential to improve the understanding of\nadversarial attack and defense strategies.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 06:47:55 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Sen", "Ayon", ""], ["Zhu", "Xiaojin", ""], ["Marshall", "Liam", ""], ["Nowak", "Robert", ""]]}, {"id": "1906.02485", "submitter": "Jonathan Grizou", "authors": "Jonathan Grizou", "title": "The Open Vault Challenge -- Learning how to build calibration-free\n  interactive systems by cracking the code of a vault", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This demo takes the form of a challenge to the IJCAI community. A physical\nvault, secured by a 4-digit code, will be placed in the demo area. The author\nwill publicly open the vault by entering the code on a touch-based interface,\nand as many times as requested. The challenge to the IJCAI participants will be\nto crack the code, open the vault, and collect its content. The interface is\nbased on previous work on calibration-free interactive systems that enables a\nuser to start instructing a machine without the machine knowing how to\ninterpret the user's actions beforehand. The intent and the behavior of the\nhuman are simultaneously learned by the machine. An online demo and videos are\navailable for readers to participate in the challenge. An additional interface\nusing vocal commands will be revealed on the demo day, demonstrating the\nscalability of our approach to continuous input signals.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 09:02:16 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Grizou", "Jonathan", ""]]}, {"id": "1906.02492", "submitter": "Holger Ulmer", "authors": "Markus Hanselmann, Thilo Strauss, Katharina Dormann, Holger Ulmer", "title": "CANet: An Unsupervised Intrusion Detection System for High Dimensional\n  CAN Bus Data", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2020.2982544", "report-no": null, "categories": "cs.CR cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel neural network architecture for detecting intrusions on\nthe CAN bus. The Controller Area Network (CAN) is the standard communication\nmethod between the Electronic Control Units (ECUs) of automobiles. However, CAN\nlacks security mechanisms and it has recently been shown that it can be\nattacked remotely. Hence, it is desirable to monitor CAN traffic to detect\nintrusions. In order to detect both, known and unknown intrusion scenarios, we\nconsider a novel unsupervised learning approach which we call CANet. To our\nknowledge, this is the first deep learning based intrusion detection system\n(IDS) that takes individual CAN messages with different IDs and evaluates them\nin the moment they are received. This is a significant advancement because\nmessages with different IDs are typically sent at different times and with\ndifferent frequencies. Our method is evaluated on real and synthetic CAN data.\nFor reproducibility of the method, our synthetic data is publicly available. A\ncomparison with previous machine learning based methods shows that CANet\noutperforms them by a significant margin.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 09:18:53 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Hanselmann", "Markus", ""], ["Strauss", "Thilo", ""], ["Dormann", "Katharina", ""], ["Ulmer", "Holger", ""]]}, {"id": "1906.02499", "submitter": "Johann Knechtel", "authors": "Johann Knechtel, Satwik Patnaik, Ozgur Sinanoglu", "title": "3D Integration: Another Dimension Toward Hardware Security", "comments": "IEEE IOLTS 2019", "journal-ref": null, "doi": "10.1109/IOLTS.2019.8854395", "report-no": null, "categories": "cs.CR cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review threats and selected schemes concerning hardware security at design\nand manufacturing time as well as at runtime. We find that 3D integration can\nserve well to enhance the resilience of different hardware security schemes,\nbut it also requires thoughtful use of the options provided by the umbrella\nterm of 3D integration. Toward enforcing security at runtime, we envision\nsecure 2.5D system-level integration of untrusted chips and \"all around\"\nshielding for 3D ICs.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 09:49:59 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Knechtel", "Johann", ""], ["Patnaik", "Satwik", ""], ["Sinanoglu", "Ozgur", ""]]}, {"id": "1906.02606", "submitter": "Yanan Li", "authors": "Yanan Li, Xuebin Ren, Shusen Yang, and Xinyu Yang", "title": "Impact of Prior Knowledge and Data Correlation on Privacy Leakage: A\n  Unified Analysis", "comments": null, "journal-ref": "IEEE Transactions on Information Forensics and Security, vol. 14,\n  no. 9, pp. 2342-2357, Sept. 2019", "doi": "10.1109/TIFS.2019.2895970", "report-no": null, "categories": "cs.LG cs.CR math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been widely understood that differential privacy (DP) can guarantee\nrigorous privacy against adversaries with arbitrary prior knowledge. However,\nrecent studies demonstrate that this may not be true for correlated data, and\nindicate that three factors could influence privacy leakage: the data\ncorrelation pattern, prior knowledge of adversaries, and sensitivity of the\nquery function. This poses a fundamental problem: what is the mathematical\nrelationship between the three factors and privacy leakage? In this paper, we\npresent a unified analysis of this problem. A new privacy definition, named\n\\textit{prior differential privacy (PDP)}, is proposed to evaluate privacy\nleakage considering the exact prior knowledge possessed by the adversary. We\nuse two models, the weighted hierarchical graph (WHG) and the multivariate\nGaussian model to analyze discrete and continuous data, respectively. We\ndemonstrate that positive, negative, and hybrid correlations have distinct\nimpacts on privacy leakage. Considering general correlations, a closed-form\nexpression of privacy leakage is derived for continuous data, and a chain rule\nis presented for discrete data. Our results are valid for general linear\nqueries, including count, sum, mean, and histogram. Numerical experiments are\npresented to verify our theoretical analysis.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 11:16:13 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Li", "Yanan", ""], ["Ren", "Xuebin", ""], ["Yang", "Shusen", ""], ["Yang", "Xinyu", ""]]}, {"id": "1906.02628", "submitter": "Wanxin Li", "authors": "Wanxin Li, Mark Nejad, Rui Zhang", "title": "A Blockchain-Based Architecture for Traffic Signal Control Systems", "comments": "This paper has been accepted at IEEE International Congress on\n  Internet of Things (IEEE ICIOT 2019), Milan, Italy", "journal-ref": null, "doi": "10.1109/ICIOT.2019.00018", "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ever-growing incorporation of connected vehicle (CV) technologies into\nintelligent traffic signal control systems bring about significant data\nsecurity issues in the connected vehicular networks. This paper presents a\nnovel decentralized and secure by design architecture for connected vehicle\ndata security, which is based on the emerging blockchain paradigm. In a\nsimulation study, we applied this architecture to defend the Intelligent\nTraffic Signal System (I-SIG), a USDOT approved CV pilot program, against\ncongestion attacks. The results show the performance of the proposed\narchitecture for the traffic signal control system.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 15:02:52 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 03:31:39 GMT"}, {"version": "v3", "created": "Fri, 13 Sep 2019 17:34:02 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Li", "Wanxin", ""], ["Nejad", "Mark", ""], ["Zhang", "Rui", ""]]}, {"id": "1906.02686", "submitter": "Brian Thompson", "authors": "Brian Thompson (The MITRE Corporation), Dave Cedel (The MITRE\n  Corporation), Jeremy Martin (The MITRE Corporation), Peter Ryan (The MITRE\n  Corporation), Sarah Kern (The MITRE Corporation)", "title": "Fusion of Mobile Device Signal Data Attributes Enables Multi-Protocol\n  Entity Resolution and Enhanced Large-Scale Tracking", "comments": "21 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Use of persistent identifiers in wireless communication protocols is a known\nprivacy concern as they can be used to track the location of mobile devices.\nFurthermore, inherent structure in the assignment of hardware identifiers as\nwell as upper-layer network protocol data attributes can leak additional device\ninformation. We introduce SEXTANT, a computational framework that combines\nimprovements on previously published device identification techniques with\nnovel spatio-temporal correlation algorithms to perform multi-protocol entity\nresolution, enabling large-scale tracking of mobile devices across protocol\ndomains. Experiments using simulated data representing Las Vegas residents and\nvisitors over a 30-day period, consisting of about 300,000 multi-protocol\nmobile devices generating over 200 million sensor observations, demonstrate\nSEXTANT's ability to perform effectively at scale while being robust to data\nheterogeneity, sparsity, and noise, highlighting the urgent need for the\nadoption of new standards to protect the privacy of mobile device users.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 05:58:17 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Thompson", "Brian", "", "The MITRE Corporation"], ["Cedel", "Dave", "", "The MITRE\n  Corporation"], ["Martin", "Jeremy", "", "The MITRE Corporation"], ["Ryan", "Peter", "", "The MITRE\n  Corporation"], ["Kern", "Sarah", "", "The MITRE Corporation"]]}, {"id": "1906.02816", "submitter": "Juan Carlos Perdomo", "authors": "Juan C. Perdomo, Yaron Singer", "title": "Robust Attacks against Multiple Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the challenge of designing optimal adversarial noise algorithms\nfor settings where a learner has access to multiple classifiers. We demonstrate\nhow this problem can be framed as finding strategies at equilibrium in a\ntwo-player, zero-sum game between a learner and an adversary. In doing so, we\nillustrate the need for randomization in adversarial attacks. In order to\ncompute Nash equilibrium, our main technical focus is on the design of best\nresponse oracles that can then be implemented within a Multiplicative Weights\nUpdate framework to boost deterministic perturbations against a set of models\ninto optimal mixed strategies. We demonstrate the practical effectiveness of\nour approach on a series of image classification tasks using both linear\nclassifiers and deep neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 21:06:28 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Perdomo", "Juan C.", ""], ["Singer", "Yaron", ""]]}, {"id": "1906.02830", "submitter": "Thomas Steinke", "authors": "Mark Bun, Thomas Steinke", "title": "Average-Case Averages: Private Algorithms for Smooth Sensitivity and\n  Mean Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CR cs.DS stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The simplest and most widely applied method for guaranteeing differential\nprivacy is to add instance-independent noise to a statistic of interest that is\nscaled to its global sensitivity. However, global sensitivity is a worst-case\nnotion that is often too conservative for realized dataset instances. We\nprovide methods for scaling noise in an instance-dependent way and demonstrate\nthat they provide greater accuracy under average-case distributional\nassumptions.\n  Specifically, we consider the basic problem of privately estimating the mean\nof a real distribution from i.i.d.~samples. The standard empirical mean\nestimator can have arbitrarily-high global sensitivity. We propose the trimmed\nmean estimator, which interpolates between the mean and the median, as a way of\nattaining much lower sensitivity on average while losing very little in terms\nof statistical accuracy.\n  To privately estimate the trimmed mean, we revisit the smooth sensitivity\nframework of Nissim, Raskhodnikova, and Smith (STOC 2007), which provides a\nframework for using instance-dependent sensitivity. We propose three new\nadditive noise distributions which provide concentrated differential privacy\nwhen scaled to smooth sensitivity. We provide theoretical and experimental\nevidence showing that our noise distributions compare favorably to others in\nthe literature, in particular, when applied to the mean estimation problem.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 21:55:02 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Bun", "Mark", ""], ["Steinke", "Thomas", ""]]}, {"id": "1906.02867", "submitter": "Kewen Wu", "authors": "Mingjia Huo, Kewen Wu, and Qi Ye", "title": "A Note on Lower Digits Extraction Polynomial for Bootstrapping", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bootstrapping is a crucial but computationally expensive step for realizing\nFully Homomorphic Encryption (FHE). Recently, Chen and Han (Eurocrypt 2018)\nintroduced a family of low-degree polynomials to extract the lowest digit with\nrespect to a certain congruence, which helps improve the bootstrapping for both\nFV and BGV schemes.\n  In this note, we present the following relevant findings about the work of\nChen and Han (referred to as CH18):\n  1. We provide a simpler construction of the low-degree polynomials that serve\nthe same purpose and match the asymptotic bound achieved in CH18;\n  2. We show the optimality and limit of our approach by solving a minimal\npolynomial degree problem;\n  3. We consider the problem of extracting other low-order digits using\npolynomials, and provide negative results.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 02:30:17 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Huo", "Mingjia", ""], ["Wu", "Kewen", ""], ["Ye", "Qi", ""]]}, {"id": "1906.02872", "submitter": "Yifan Ou Mr", "authors": "Yifan Ou, Reza Samavi", "title": "Mixed Strategy Game Model Against Data Poisoning Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we use game theory to model poisoning attack scenarios. We\nprove the non-existence of pure strategy Nash Equilibrium in the attacker and\ndefender game. We then propose a mixed extension of our game model and an\nalgorithm to approximate the Nash Equilibrium strategy for the defender. We\nthen demonstrate the effectiveness of the mixed defence strategy generated by\nthe algorithm, in an experiment.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 02:48:56 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Ou", "Yifan", ""], ["Samavi", "Reza", ""]]}, {"id": "1906.02896", "submitter": "Walt Woods", "authors": "Walt Woods, Jack Chen, Christof Teuscher", "title": "Adversarial Explanations for Understanding Image Classification\n  Decisions and Improved Neural Network Robustness", "comments": "23 pages with a 14 page appendix. Submitted to Nature ML for peer\n  review", "journal-ref": "Nature Machine Intelligence (2019)", "doi": "10.1038/s42256-019-0104-6", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For sensitive problems, such as medical imaging or fraud detection, Neural\nNetwork (NN) adoption has been slow due to concerns about their reliability,\nleading to a number of algorithms for explaining their decisions. NNs have also\nbeen found vulnerable to a class of imperceptible attacks, called adversarial\nexamples, which arbitrarily alter the output of the network. Here we\ndemonstrate both that these attacks can invalidate prior attempts to explain\nthe decisions of NNs, and that with very robust networks, the attacks\nthemselves may be leveraged as explanations with greater fidelity to the model.\nWe show that the introduction of a novel regularization technique inspired by\nthe Lipschitz constraint, alongside other proposed improvements, greatly\nimproves an NN's resistance to adversarial examples. On the ImageNet\nclassification task, we demonstrate a network with an Accuracy-Robustness Area\n(ARA) of 0.0053, an ARA 2.4x greater than the previous state of the art.\nImproving the mechanisms by which NN decisions are understood is an important\ndirection for both establishing trust in sensitive domains and learning more\nabout the stimuli to which NNs respond.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 04:52:01 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 21:11:01 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Woods", "Walt", ""], ["Chen", "Jack", ""], ["Teuscher", "Christof", ""]]}, {"id": "1906.02928", "submitter": "Derrick McKee", "authors": "Derrick McKee and Nathan Burow and Mathias Payer", "title": "Software Ethology: An Accurate, Resilient, and Cross-Architecture Binary\n  Analysis Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When reverse engineering a binary, the analyst must first understand the\nsemantics of the binary's functions through either manual or automatic\nanalysis. Manual semantic analysis is time-consuming, because abstractions\nprovided by high level languages, such as type information, variable scope, or\ncomments are lost, and past analyses cannot apply to the current analysis task.\nExisting automated binary analysis tools currently suffer from low accuracy in\ndetermining semantic function identification in the presence of diverse\ncompilation environments.\n  We introduce Software Ethology, a binary analysis approach for determining\nthe semantic similarity of functions. Software Ethology abstracts semantic\nbehavior as classification vectors of program state changes resulting from a\nfunction executing with a specified input state, and uses these vectors as a\nunique fingerprint for identification. All existing semantic identifiers\ndetermine function similarity via code measurements, and suffer from high\ninaccuracy when classifying functions from compilation environments different\nfrom their ground truth source. Since Software Ethology does not rely on code\nmeasurements, its accuracy is resilient to changes in compiler, compiler\nversion, optimization level, or even different source implementing equivalent\nfunctionality.\n  Tinbergen, our prototype Software Ethology implementation, leverages a\nvirtual execution environment and a fuzzer to generate the classification\nvectors. In evaluating Tinbergen's feasibility as a semantic function\nidentifier by identifying functions in coreutils-8.30, we achieve a high .805\naverage accuracy. Compared to the state-of-the-art, Tinbergen is 1.5 orders of\nmagnitude faster when training, 50% faster in answering queries, and, when\nidentifying functions in binaries generated from differing compilation\nenvironments, is 30%-61% more accurate.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 07:17:51 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 12:36:50 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 19:38:18 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["McKee", "Derrick", ""], ["Burow", "Nathan", ""], ["Payer", "Mathias", ""]]}, {"id": "1906.03006", "submitter": "Daniel Bernau", "authors": "Benjamin Hilprecht, Martin H\\\"arterich, Daniel Bernau", "title": "Reconstruction and Membership Inference Attacks against Generative\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two information leakage attacks that outperform previous work on\nmembership inference against generative models. The first attack allows\nmembership inference without assumptions on the type of the generative model.\nContrary to previous evaluation metrics for generative models, like Kernel\nDensity Estimation, it only considers samples of the model which are close to\ntraining data records. The second attack specifically targets Variational\nAutoencoders, achieving high membership inference accuracy. Furthermore,\nprevious work mostly considers membership inference adversaries who perform\nsingle record membership inference. We argue for considering regulatory actors\nwho perform set membership inference to identify the use of specific datasets\nfor training. The attacks are evaluated on two generative model architectures,\nGenerative Adversarial Networks (GANs) and Variational Autoencoders (VAEs),\ntrained on standard image datasets. Our results show that the two attacks yield\nsuccess rates superior to previous work on most data sets while at the same\ntime having only very mild assumptions. We envision the two attacks in\ncombination with the membership inference attack type formalization as\nespecially useful. For example, to enforce data privacy standards and\nautomatically assessing model quality in machine learning as a service setups.\nIn practice, our work motivates the use of GANs since they prove less\nvulnerable against information leakage attacks while producing detailed\nsamples.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 10:52:15 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Hilprecht", "Benjamin", ""], ["H\u00e4rterich", "Martin", ""], ["Bernau", "Daniel", ""]]}, {"id": "1906.03043", "submitter": "Khaled Nagaty Prof.", "authors": "Khaled Ahmed Nagaty", "title": "A Fuzzy-Fuzzy Vault Scheme", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper an enhanced fuzzy vault scheme is proposed which we refer to as\nfuzzy-fuzzy vault scheme. The proposed scheme builds on the classical fuzzy\nvault by adding the concept of uncertainty and imprecision to the classical\nscheme. To lock a secret key K in the classical fuzzy vault the locking and\nunlocking elements are crisp or real elements and consequently the locking and\nunlocking operations are strict imperative. In the fuzzy-fuzzy vault scheme,\nAlice locks the secret key K using a set of fuzzy elements that belong to\nmulti-fuzzy set A~ obtained from a universe public set of fuzzy elements in a\nmulti-fuzzy set F~_q and projecting them on polynomial p. The elements in\nmulti-fuzzy sets F~_q and A~ are fuzzy using m membership functions MF_i,\ni=1,2,...,m. Alice selects a set k of fuzzy elements fuzzy with a specific\nmembership function MF_K from A~ to lock the vault. To hide the genuine locking\npoints Alice generates a set of fuzzy chaff points that some of them do not lie\non polynomial p while the other fuzzy chaff points may lie on polynomial p but\nfuzzy with different membership functions other than the membership function\nMF_K used to lock the vault. To unlock the fuzzy-fuzzy vault and retrieve the\nsecret key K , Bob should have a set of unlocking fuzzy elements belonging to\nmulti-fuzzy set B~ which substantially overlap with A~ is required. Then Bob\nselects t'_(TF_ki) fuzzy elements from B~ which are close to the t_(TF_k) fuzzy\nelements from A~ used by Alice to lock the vault. We show that adding\nuncertainty and imprecision by introducing fuzzy theory will enhance the\nsecurity threshold of the fuzzy vault.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 11:33:33 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Nagaty", "Khaled Ahmed", ""]]}, {"id": "1906.03049", "submitter": "Antti Koskela", "authors": "Antti Koskela, Joonas J\\\"alk\\\"o and Antti Honkela", "title": "Computing Tight Differential Privacy Guarantees Using FFT", "comments": "43 pages, 7 figures", "journal-ref": "AISTATS (2020) 2560-2569", "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Differentially private (DP) machine learning has recently become popular. The\nprivacy loss of DP algorithms is commonly reported using\n$(\\varepsilon,\\delta)$-DP. In this paper, we propose a numerical accountant for\nevaluating the privacy loss for algorithms with continuous one dimensional\noutput. This accountant can be applied to the subsampled multidimensional\nGaussian mechanism which underlies the popular DP stochastic gradient descent.\nThe proposed method is based on a numerical approximation of an integral\nformula which gives the exact $(\\varepsilon,\\delta)$-values. The approximation\nis carried out by discretising the integral and by evaluating discrete\nconvolutions using the fast Fourier transform algorithm. We give both\ntheoretical error bounds and numerical error estimates for the approximation.\nExperimental comparisons with state-of-the-art techniques demonstrate\nsignificant improvements in bound tightness and/or computation time. Python\ncode for the method can be found in Github\n(https://github.com/DPBayes/PLD-Accountant/).\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 12:33:46 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 10:28:15 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Koskela", "Antti", ""], ["J\u00e4lk\u00f6", "Joonas", ""], ["Honkela", "Antti", ""]]}, {"id": "1906.03181", "submitter": "Haibin Zheng", "authors": "Jinyin Chen, Mengmeng Su, Shijing Shen, Hui Xiong, Haibin Zheng", "title": "POBA-GA: Perturbation Optimized Black-Box Adversarial Attacks via\n  Genetic Algorithm", "comments": null, "journal-ref": "Computers and Security, Volume 85, August 2019, Pages 89-106", "doi": "10.1016/j.cose.2019.04.014", "report-no": null, "categories": "cs.CR cs.LG cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most deep learning models are easily vulnerable to adversarial attacks.\nVarious adversarial attacks are designed to evaluate the robustness of models\nand develop defense model. Currently, adversarial attacks are brought up to\nattack their own target model with their own evaluation metrics. And most of\nthe black-box adversarial attack algorithms cannot achieve the expected success\nrate compared with white-box attacks. In this paper, comprehensive evaluation\nmetrics are brought up for different adversarial attack methods. A novel\nperturbation optimized black-box adversarial attack based on genetic algorithm\n(POBA-GA) is proposed for achieving white-box comparable attack performances.\nApproximate optimal adversarial examples are evolved through evolutionary\noperations including initialization, selection, crossover and mutation. Fitness\nfunction is specifically designed to evaluate the example individual in both\naspects of attack ability and perturbation control. Population diversity\nstrategy is brought up in evolutionary process to promise the approximate\noptimal perturbations obtained. Comprehensive experiments are carried out to\ntestify POBA-GA's performances. Both simulation and application results prove\nthat our method is better than current state-of-art black-box attack methods in\naspects of attack capability and perturbation control.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 05:18:53 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Chen", "Jinyin", ""], ["Su", "Mengmeng", ""], ["Shen", "Shijing", ""], ["Xiong", "Hui", ""], ["Zheng", "Haibin", ""]]}, {"id": "1906.03184", "submitter": "Ensar Seker", "authors": "Ensar \\c{S}eker", "title": "The Concept of Cyber Defence Exercises (CDX): Planning, Execution,\n  Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the concept of cyber defence exercises -CDX- that are\nvery important tool when it comes to enhancing the safety awareness of\ncyberspace, testing an organization's ability to put up resistance and respond\nto different cyber events to establish the secure environment, gathering\nempirical data related to security, and looking at the practical training of\nexperts on this subject. The exercises can give ideas to the decision makers\nabout the precautions in the cybersecurity area and to the officials,\ninstitutions, organizations, and staff who are responsible on the cyber tools,\ntechniques, and procedures that can be developed for this field. In the cyber\ndefense exercises, the scenarios that are simulated closest to reality which\nprovides very important contributions by bringing together the necessity of\nmaking the best decisions and management capabilities under the cyber crisis by\nhandling stress and coordinated movement as a team. The objective of this paper\nis to address the issue from a scientific point of view by setting out the\nstages of planning, implementation, and evaluation of these exercises, taking\ninto account and comparing international firefighting exercises. Another aim of\nthe work is to be able to reveal the necessary processes that are required for\nall kind of cyber exercises, regardless of the type, although the processes\ninvolved vary according to the target mass of the planned exercise.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 13:30:15 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["\u015eeker", "Ensar", ""]]}, {"id": "1906.03228", "submitter": "Giovanni Ciampi", "authors": "Ciampi Giovanni", "title": "Cryptanalysis of the SLAP Authentication Protocol", "comments": "This is my bachelor thesis work, carried out at the University of\n  Salerno under the supervision of Prof. Roberto De Prisco. The final work led\n  to the publications 'Confusion and Diffusion in Recent Ultralightweight RFID\n  Authentication Protocols' and 'Design Weaknesses in Recent Ultralightweight\n  RFID Authentication Protocols'", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RFID (Radio Frequency Identification) is a powerful technology that, due to\nits numerous advantages, is supposed to replace the various identification\nsystems such as barcodes or magnetic stripes in a short time. There are three\ndevices involved in an RFID protocol: a Reader, a Tag, and a back-end Database.\nOne of the key factors for the RFID technology is that, in order to be used on\nlarge scale, the price of the Tags has to be cheap: it cannot be expensive\nbecause who is supposed to use it would need a great amount of them,\nfurthermore, Tags must have very small dimensions. The low-cost nature of such\ndevices implies the impossibility to use standard cryptographic protocols on\nthem, furthermore, Ultra-Lightweight Tags even lack the necessary computational\npower to generate random numbers. Many experts are trying to build secure\nprotocols that involve just simple bitwise logical operations for these Tags,\nbut, unfortunately, each of these protocols turned out to be vulnerable to some\nserious attack after short time from publication. The need for a secure RFID\nauthentication protocol today seems more urgent than ever, because this\ntechnology is already used for security purposes, such as electronic passports.\nThe challenge to build a secure protocol for Ultra-Lightweight RFID systems is\nso hard that in several years no one has been able to build one. In this thesis\nwe analyze in great detail a recently proposed protocol for Ultra-Lightweight\nRFID systems called SLAP, with the aim of finding new vulnerabilities. SLAP has\nalready been violated (along with a set of similar protocols) by Safkhani and\nBagheri, that have recently published a de-synchronization attack. At the end\nof our analysis, we will propose an impersonification attack to the protocol,\nalong with a fix for our attack and some considerations on the attacks proposed\non this kind of protocols.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 13:26:58 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Giovanni", "Ciampi", ""]]}, {"id": "1906.03231", "submitter": "Kevin Shi", "authors": "Kevin Shi, Daniel Hsu, Allison Bishop", "title": "A cryptographic approach to black box adversarial machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new randomized ensemble technique with a provable security\nguarantee against black-box transfer attacks. Our proof constructs a new\nsecurity problem for random binary classifiers which is easier to empirically\nverify and a reduction from the security of this new model to the security of\nthe ensemble classifier. We provide experimental evidence of the security of\nour random binary classifiers, as well as empirical results of the adversarial\naccuracy of the overall ensemble to black-box attacks. Our construction\ncrucially leverages hidden randomness in the multiclass-to-binary reduction.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 16:44:08 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 19:24:15 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Shi", "Kevin", ""], ["Hsu", "Daniel", ""], ["Bishop", "Allison", ""]]}, {"id": "1906.03251", "submitter": "Yao Sun", "authors": "Yulong Wu, Yunfei Zha, Yao Sun", "title": "A Unifying Hybrid Consensus Protocol", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Unity, a new consensus algorithm for public blockchain settings.\nUnity is an eventual consistency protocol merging the Proof-of-Work (PoW) and\nProof-of-Stake (PoS) into a coherent stochastic process. It encompasses\nhardware and economic security without sacrificing availability,\nunpredictability and decentralization. Empirical results indicate that the\nproposed protocol is fair and scalable to an arbitrary number of miners and\nstakers.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 17:41:10 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Wu", "Yulong", ""], ["Zha", "Yunfei", ""], ["Sun", "Yao", ""]]}, {"id": "1906.03256", "submitter": "Ali Sharif", "authors": "Shidokht Hejazi-Sepehr, Ross Kitsis and Ali Sharif", "title": "Transwarp Conduit: Interoperable Blockchain Application Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transwarp-Conduit (TWC) is a protocol for message transfers between two\nsmart-contract enabled blockchains. Furthermore, we specify an application\nframework (leveraging the TWC protocol) that enables developers to define\narbitrarily complex cross-blockchain applications, simply by deploying\nframework-compliant smart contracts and hosting a TWC node (daemon process).The\nTWC protocol is implementable without additional effort on part of the base\nblockchain protocol.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 17:49:25 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Hejazi-Sepehr", "Shidokht", ""], ["Kitsis", "Ross", ""], ["Sharif", "Ali", ""]]}, {"id": "1906.03306", "submitter": "Sandra Johnson", "authors": "Sandra Johnson, Peter Robinson, Kishore Atreya, Claudio Lisco", "title": "Invoice Financing of Supply Chains with Blockchain technology and\n  Artificial Intelligence", "comments": "12 pages, 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supply chains lend themselves to blockchain technology, but certain\nchallenges remain, especially around invoice financing. For example, the\nfurther a supplier is removed from the final consumer product, the more\ndifficult it is to get their invoices financed. Moreover, for competitive\nreasons, retailers and manufacturers do not want to disclose their supply\nchains. However, upstream suppliers need to prove that they are part of a\n`stable' supply chain to get their invoices financed, which presents the\nupstream suppliers with huge, and often unsurmountable, obstacles to get the\nnecessary finance to fulfil the next order, or to expand their business. Using\na fictitious supply chain use case, which is based on a real world use case, we\ndemonstrate how these challenges have the potential to be solved by combining\nmore advanced and specialised blockchain technologies with other technologies\nsuch as Artificial Intelligence. We describe how atomic crosschain\nfunctionality can be utilised across private blockchains to retrieve the\ninformation required for an invoice financier to make informed decisions under\nuncertainty, and consider the effect this decision has on the overall stability\nof the supply chain.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 09:06:32 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Johnson", "Sandra", ""], ["Robinson", "Peter", ""], ["Atreya", "Kishore", ""], ["Lisco", "Claudio", ""]]}, {"id": "1906.03310", "submitter": "Yao-Yuan Yang", "authors": "Yao-Yuan Yang, Cyrus Rashtchian, Yizhen Wang, Kamalika Chaudhuri", "title": "Robustness for Non-Parametric Classification: A Generic Attack and\n  Defense", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarially robust machine learning has received much recent attention.\nHowever, prior attacks and defenses for non-parametric classifiers have been\ndeveloped in an ad-hoc or classifier-specific basis. In this work, we take a\nholistic look at adversarial examples for non-parametric classifiers, including\nnearest neighbors, decision trees, and random forests. We provide a general\ndefense method, adversarial pruning, that works by preprocessing the dataset to\nbecome well-separated. To test our defense, we provide a novel attack that\napplies to a wide range of non-parametric classifiers. Theoretically, we derive\nan optimally robust classifier, which is analogous to the Bayes Optimal. We\nshow that adversarial pruning can be viewed as a finite sample approximation to\nthis optimal classifier. We empirically show that our defense and attack are\neither better than or competitive with prior work on non-parametric\nclassifiers. Overall, our results provide a strong and broadly-applicable\nbaseline for future work on robust non-parametrics. Code available at\nhttps://github.com/yangarbiter/adversarial-nonparametrics/ .\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 19:45:52 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 23:12:27 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Yang", "Yao-Yuan", ""], ["Rashtchian", "Cyrus", ""], ["Wang", "Yizhen", ""], ["Chaudhuri", "Kamalika", ""]]}, {"id": "1906.03333", "submitter": "Fanyou Wu", "authors": "Fanyou Wu, Rado Gazo, Eva Haviarova, Bedrich Benes", "title": "Efficient Project Gradient Descent for Ensemble Adversarial Attack", "comments": "6 pages, 2 figures, submit to IJCAI 19 AIBS workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances show that deep neural networks are not robust to deliberately\ncrafted adversarial examples which many are generated by adding human\nimperceptible perturbation to clear input. Consider $l_2$ norms attacks,\nProject Gradient Descent (PGD) and the Carlini and Wagner (C\\&W) attacks are\nthe two main methods, where PGD control max perturbation for adversarial\nexamples while C\\&W approach treats perturbation as a regularization term\noptimized it with loss function together. If we carefully set parameters for\nany individual input, both methods become similar. In general, PGD attacks\nperform faster but obtains larger perturbation to find adversarial examples\nthan the C\\&W when fixing the parameters for all inputs. In this report, we\npropose an efficient modified PGD method for attacking ensemble models by\nautomatically changing ensemble weights and step size per iteration per input.\nThis method generates smaller perturbation adversarial examples than PGD method\nwhile remains efficient as compared to C\\&W method. Our method won the first\nplace in IJCAI19 Targeted Adversarial Attack competition.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 21:07:02 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Wu", "Fanyou", ""], ["Gazo", "Rado", ""], ["Haviarova", "Eva", ""], ["Benes", "Bedrich", ""]]}, {"id": "1906.03397", "submitter": "Mika Juuti Mr", "authors": "Mika Juuti, Buse Gul Atli, N. Asokan", "title": "Making targeted black-box evasion attacks effective and efficient", "comments": "12 pages, 10 figures", "journal-ref": "AISec 2019: Proceedings of the 12th ACM Workshop on Artificial\n  Intelligence and Security", "doi": "10.1145/3338501.3357366", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate how an adversary can optimally use its query budget for\ntargeted evasion attacks against deep neural networks in a black-box setting.\nWe formalize the problem setting and systematically evaluate what benefits the\nadversary can gain by using substitute models. We show that there is an\nexploration-exploitation tradeoff in that query efficiency comes at the cost of\neffectiveness. We present two new attack strategies for using substitute models\nand show that they are as effective as previous query-only techniques but\nrequire significantly fewer queries, by up to three orders of magnitude. We\nalso show that an agile adversary capable of switching through different attack\ntechniques can achieve pareto-optimal efficiency. We demonstrate our attack\nagainst Google Cloud Vision showing that the difficulty of black-box attacks\nagainst real-world prediction APIs is significantly easier than previously\nthought (requiring approximately 500 queries instead of approximately 20,000 as\nin previous works).\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 06:22:25 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Juuti", "Mika", ""], ["Atli", "Buse Gul", ""], ["Asokan", "N.", ""]]}, {"id": "1906.03455", "submitter": "Kenneth Co", "authors": "Kenneth T. Co, Luis Mu\\~noz-Gonz\\'alez, Emil C. Lupu", "title": "Sensitivity of Deep Convolutional Networks to Gabor Noise", "comments": "Accepted to ICML 2019 Workshop on Identifying and Understanding Deep\n  Learning Phenomena", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Convolutional Networks (DCNs) have been shown to be sensitive to\nUniversal Adversarial Perturbations (UAPs): input-agnostic perturbations that\nfool a model on large portions of a dataset. These UAPs exhibit interesting\nvisual patterns, but this phenomena is, as yet, poorly understood. Our work\nshows that visually similar procedural noise patterns also act as UAPs. In\nparticular, we demonstrate that different DCN architectures are sensitive to\nGabor noise patterns. This behaviour, its causes, and implications deserve\nfurther in-depth study.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 13:41:38 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 02:57:48 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Co", "Kenneth T.", ""], ["Mu\u00f1oz-Gonz\u00e1lez", "Luis", ""], ["Lupu", "Emil C.", ""]]}, {"id": "1906.03466", "submitter": "Rajagopal A", "authors": "Rajagopal. A, Nirmala. V", "title": "Strategies to architect AI Safety: Defense to guard AI from Adversaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The impact of designing for security of AI is critical for humanity in the AI\nera. With humans increasingly becoming dependent upon AI, there is a need for\nneural networks that work reliably, inspite of Adversarial attacks. The vision\nfor Safe and secure AI for popular use is achievable. To achieve safety of AI,\nthis paper explores strategies and a novel deep learning architecture. To guard\nAI from adversaries, paper explores combination of 3 strategies:\n  1. Introduce randomness at inference time to hide the representation learning\nfrom adversaries.\n  2. Detect presence of adversaries by analyzing the sequence of inferences.\n  3. Exploit visual similarity.\n  To realize these strategies, this paper designs a novel architecture, Dynamic\nNeural Defense, DND. This defense has 3 deep learning architectural features:\n  1. By hiding the way a neural network learns from exploratory attacks using a\nrandom computation graph, DND evades attack.\n  2. By analyzing input sequence to cloud AI inference engine with LSTM, DND\ndetects attack sequence.\n  3. By inferring with visual similar inputs generated by VAE, any AI defended\nby DND approach does not succumb to hackers.\n  Thus, a roadmap to develop reliable, safe and secure AI is presented.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 14:34:47 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["A", "Rajagopal.", ""], ["V", "Nirmala.", ""]]}, {"id": "1906.03499", "submitter": "Puyudi Yang", "authors": "Puyudi Yang, Jianbo Chen, Cho-Jui Hsieh, Jane-Ling Wang, Michael I.\n  Jordan", "title": "ML-LOO: Detecting Adversarial Examples with Feature Attribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks obtain state-of-the-art performance on a series of\ntasks. However, they are easily fooled by adding a small adversarial\nperturbation to input. The perturbation is often human imperceptible on image\ndata. We observe a significant difference in feature attributions of\nadversarially crafted examples from those of original ones. Based on this\nobservation, we introduce a new framework to detect adversarial examples\nthrough thresholding a scale estimate of feature attribution scores.\nFurthermore, we extend our method to include multi-layer feature attributions\nin order to tackle the attacks with mixed confidence levels. Through vast\nexperiments, our method achieves superior performances in distinguishing\nadversarial examples from popular attack methods on a variety of real data sets\namong state-of-the-art detection methods. In particular, our method is able to\ndetect adversarial examples of mixed confidence levels, and transfer between\ndifferent attacking methods.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 18:36:16 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Yang", "Puyudi", ""], ["Chen", "Jianbo", ""], ["Hsieh", "Cho-Jui", ""], ["Wang", "Jane-Ling", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1906.03526", "submitter": "Maksym Andriushchenko", "authors": "Maksym Andriushchenko, Matthias Hein", "title": "Provably Robust Boosted Decision Stumps and Trees against Adversarial\n  Attacks", "comments": "Camera-ready version (accepted at NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of adversarial robustness has been studied extensively for neural\nnetworks. However, for boosted decision trees and decision stumps there are\nalmost no results, even though they are widely used in practice (e.g. XGBoost)\ndue to their accuracy, interpretability, and efficiency. We show in this paper\nthat for boosted decision stumps the \\textit{exact} min-max robust loss and\ntest error for an $l_\\infty$-attack can be computed in $O(T\\log T)$ time per\ninput, where $T$ is the number of decision stumps and the optimal update step\nof the ensemble can be done in $O(n^2\\,T\\log T)$, where $n$ is the number of\ndata points. For boosted trees we show how to efficiently calculate and\noptimize an upper bound on the robust loss, which leads to state-of-the-art\nrobust test error for boosted trees on MNIST (12.5% for $\\epsilon_\\infty=0.3$),\nFMNIST (23.2% for $\\epsilon_\\infty=0.1$), and CIFAR-10 (74.7% for\n$\\epsilon_\\infty=8/255$). Moreover, the robust test error rates we achieve are\ncompetitive to the ones of provably robust convolutional networks. The code of\nall our experiments is available at\nhttp://github.com/max-andr/provably-robust-boosting\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 21:44:34 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 20:57:31 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Andriushchenko", "Maksym", ""], ["Hein", "Matthias", ""]]}, {"id": "1906.03552", "submitter": "Thomas Hardjono", "authors": "Thomas Hardjono", "title": "A Federated Authorization Framework for Distributed Personal Data and\n  Digital Identity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The digital identity problem is a complex one in large part because it\ninvolves personal data, the algorithms which compute reputations on the data\nand the management of the identifiers that are linked to personal data. The\nreality of today is that personal data of an individual is distributed\nthroughout the Internet, in both private and public institutions, and\nincreasingly also on the user's devices. In order to empower individuals to\nhave a say in who has access to their personal data and to enable individuals\nto make use of their data for their own purposes, a coherent and scalable\naccess authorization architecture is required. Such an architecture must allow\ndifferent data holders, data providers and user-content generators to respond\nto an individual's wishes with regards to consent in a federated fashion. This\nfederation must allow an individual to easily manage access policies and\nprovide consent as required by current and forthcoming data privacy\nregulations. This paper describes the User Managed Access (UMA) architecture\nand protocols that provide the foundation for scalable access authorization.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 02:16:38 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Hardjono", "Thomas", ""]]}, {"id": "1906.03563", "submitter": "Jingkang Wang", "authors": "Jingkang Wang, Tianyun Zhang, Sijia Liu, Pin-Yu Chen, Jiacen Xu, Makan\n  Fardad, Bo Li", "title": "Towards A Unified Min-Max Framework for Adversarial Exploration and\n  Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The worst-case training principle that minimizes the maximal adversarial\nloss, also known as adversarial training (AT), has shown to be a\nstate-of-the-art approach for enhancing adversarial robustness against\nnorm-ball bounded input perturbations. Nonetheless, min-max optimization beyond\nthe purpose of AT has not been rigorously explored in the research of\nadversarial attack and defense. In particular, given a set of risk sources\n(domains), minimizing the maximal loss induced from the domain set can be\nreformulated as a general min-max problem that is different from AT. Examples\nof this general formulation include attacking model ensembles, devising\nuniversal perturbation under multiple inputs or data transformations, and\ngeneralized AT over different types of attack models. We show that these\nproblems can be solved under a unified and theoretically principled min-max\noptimization framework. We also show that the self-adjusted domain weights\nlearned from our method provides a means to explain the difficulty level of\nattack and defense over multiple domains. Extensive experiments show that our\napproach leads to substantial performance improvement over the conventional\naveraging strategy.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 04:32:13 GMT"}, {"version": "v2", "created": "Sun, 29 Sep 2019 15:49:55 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Wang", "Jingkang", ""], ["Zhang", "Tianyun", ""], ["Liu", "Sijia", ""], ["Chen", "Pin-Yu", ""], ["Xu", "Jiacen", ""], ["Fardad", "Makan", ""], ["Li", "Bo", ""]]}, {"id": "1906.03612", "submitter": "Tobias Uelwer", "authors": "Felix Michels, Tobias Uelwer, Eric Upschulte, Stefan Harmeling", "title": "On the Vulnerability of Capsule Networks to Adversarial Attacks", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extensively evaluates the vulnerability of capsule networks to\ndifferent adversarial attacks. Recent work suggests that these architectures\nare more robust towards adversarial attacks than other neural networks.\nHowever, our experiments show that capsule networks can be fooled as easily as\nconvolutional neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 10:22:52 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Michels", "Felix", ""], ["Uelwer", "Tobias", ""], ["Upschulte", "Eric", ""], ["Harmeling", "Stefan", ""]]}, {"id": "1906.03749", "submitter": "Cecilia Summers", "authors": "Cecilia Summers, Michael J. Dinneen", "title": "Improved Adversarial Robustness via Logit Regularization Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While great progress has been made at making neural networks effective across\na wide range of visual tasks, most models are surprisingly vulnerable. This\nfrailness takes the form of small, carefully chosen perturbations of their\ninput, known as adversarial examples, which represent a security threat for\nlearned vision models in the wild -- a threat which should be responsibly\ndefended against in safety-critical applications of computer vision. In this\npaper, we advocate for and experimentally investigate the use of a family of\nlogit regularization techniques as an adversarial defense, which can be used in\nconjunction with other methods for creating adversarial robustness at little to\nno marginal cost. We also demonstrate that much of the effectiveness of one\nrecent adversarial defense mechanism can in fact be attributed to logit\nregularization, and show how to improve its defense against both white-box and\nblack-box attacks, in the process creating a stronger black-box attack against\nPGD-based models. We validate our methods on three datasets and include results\non both gradient-free attacks and strong gradient-based iterative attacks with\nas many as 1,000 steps.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 00:51:44 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Summers", "Cecilia", ""], ["Dinneen", "Michael J.", ""]]}, {"id": "1906.03750", "submitter": "Yao Ma", "authors": "Yao Ma, Suhang Wang, Tyler Derr, Lingfei Wu and Jiliang Tang", "title": "Attacking Graph Convolutional Networks via Rewiring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have boosted the performance of many graph\nrelated tasks such as node classification and graph classification. Recent\nresearches show that graph neural networks are vulnerable to adversarial\nattacks, which deliberately add carefully created unnoticeable perturbation to\nthe graph structure. The perturbation is usually created by adding/deleting a\nfew edges, which might be noticeable even when the number of edges modified is\nsmall. In this paper, we propose a graph rewiring operation which affects the\ngraph in a less noticeable way compared to adding/deleting edges. We then use\nreinforcement learning to learn the attack strategy based on the proposed\nrewiring operation. Experiments on real world graphs demonstrate the\neffectiveness of the proposed framework. To understand the proposed framework,\nwe further analyze how its generated perturbation to the graph structure\naffects the output of the target model.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 01:00:07 GMT"}, {"version": "v2", "created": "Sat, 28 Sep 2019 21:58:52 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Ma", "Yao", ""], ["Wang", "Suhang", ""], ["Derr", "Tyler", ""], ["Wu", "Lingfei", ""], ["Tang", "Jiliang", ""]]}, {"id": "1906.04214", "submitter": "Kaidi Xu", "authors": "Kaidi Xu, Hongge Chen, Sijia Liu, Pin-Yu Chen, Tsui-Wei Weng, Mingyi\n  Hong, Xue Lin", "title": "Topology Attack and Defense for Graph Neural Networks: An Optimization\n  Perspective", "comments": "Accepted by IJCAI 2019, the 28th International Joint Conference on\n  Artificial Intelligence", "journal-ref": "International Joint Conference on Artificial Intelligence\n  (IJCAI-2019)", "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) which apply the deep neural networks to graph\ndata have achieved significant performance for the task of semi-supervised node\nclassification. However, only few work has addressed the adversarial robustness\nof GNNs. In this paper, we first present a novel gradient-based attack method\nthat facilitates the difficulty of tackling discrete graph data. When comparing\nto current adversarial attacks on GNNs, the results show that by only\nperturbing a small number of edge perturbations, including addition and\ndeletion, our optimization-based attack can lead to a noticeable decrease in\nclassification performance. Moreover, leveraging our gradient-based attack, we\npropose the first optimization-based adversarial training for GNNs. Our method\nyields higher robustness against both different gradient based and greedy\nattack methods without sacrificing classification accuracy on original graph.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 18:20:09 GMT"}, {"version": "v2", "created": "Sun, 4 Aug 2019 22:24:33 GMT"}, {"version": "v3", "created": "Mon, 14 Oct 2019 22:09:35 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Xu", "Kaidi", ""], ["Chen", "Hongge", ""], ["Liu", "Sijia", ""], ["Chen", "Pin-Yu", ""], ["Weng", "Tsui-Wei", ""], ["Hong", "Mingyi", ""], ["Lin", "Xue", ""]]}, {"id": "1906.04330", "submitter": "Zhengfeng Ji", "authors": "Zhengfeng Ji, Youming Qiao, Fang Song, Aaram Yun", "title": "General Linear Group Action on Tensors: A Candidate for Post-Quantum\n  Cryptography", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Starting from the one-way group action framework of Brassard and Yung (Crypto\n'90), we revisit building cryptography based on group actions. Several previous\ncandidates for one-way group actions no longer stand, due to progress both on\nclassical algorithms (e.g., graph isomorphism) and quantum algorithms (e.g.,\ndiscrete logarithm).\n  We propose the general linear group action on tensors as a new candidate to\nbuild cryptography based on group actions. Recent works\n(Futorny--Grochow--Sergeichuk, Lin. Alg. Appl., 2019) suggest that the\nunderlying algorithmic problem, the tensor isomorphism problem, is the hardest\none among several isomorphism testing problems arising from areas including\ncoding theory, computational group theory, and multivariate cryptography. We\npresent evidence to justify the viability of this proposal from comprehensive\nstudy of the state-of-art heuristic algorithms, theoretical algorithms, and\nhardness results, as well as quantum algorithms.\n  We then introduce a new notion called pseudorandom group actions to further\ndevelop group-action based cryptography. Briefly speaking, given a group $G$\nacting on a set $S$, we assume that it is hard to distinguish two distributions\nof $(s, t)$ either uniformly chosen from $S\\times S$, or where $s$ is randomly\nchosen from $S$ and $t$ is the result of applying a random group action of\n$g\\in G$ on $s$. This subsumes the classical decisional Diffie-Hellman\nassumption when specialized to a particular group action. We carefully analyze\nvarious attack strategies that support the general linear group action on\ntensors as a candidate for this assumption.\n  Finally, we establish the quantum security of several cryptographic\nprimitives based on the one-way group action assumption and the pseudorandom\ngroup action assumption.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 00:42:47 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Ji", "Zhengfeng", ""], ["Qiao", "Youming", ""], ["Song", "Fang", ""], ["Yun", "Aaram", ""]]}, {"id": "1906.04342", "submitter": "Jiasi Weng", "authors": "Weng Jiasi, Weng Jian, Liu Jia-Nan, Zhang Yue", "title": "Secure Software-Defined Networking Based on Blockchain", "comments": "19 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software-Defined Networking (SDN) separates the network control plane and\ndata plane, which provides a network-wide view with centralized control (in the\ncontrol plane) and programmable network configuration for data plane injected\nby SDN applications (in the application plane). With these features, a number\nof drawbacks of the traditional network architectures such as static\nconfiguration, non-scalability and low efficiency can be effectively avoided.\nHowever, SDN also brings with it some new security challenges, such as\nsingle-point failure of the control plane, malicious flows from applications,\nexposed network-wide resources and a vulnerable channel between the control\nplane and the data plane. In this paper, we design a monolithic security\nmechanism for SDN based on Blockchain. Our mechanism decentralizes the control\nplane to overcome single-point failure while maintaining a network-wide view.\nThe mechanism also guarantees the authenticity, traceability, and\naccountability of application flows, and hence secures the programmable\nconfiguration. Moreover, the mechanism provides a fine-grained access control\nof network-wide resources and a secure controller-switch channel to further\nprotect resources and communication in SDN.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 01:32:05 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Jiasi", "Weng", ""], ["Jian", "Weng", ""], ["Jia-Nan", "Liu", ""], ["Yue", "Zhang", ""]]}, {"id": "1906.04392", "submitter": "Ziang Yan", "authors": "Ziang Yan, Yiwen Guo, Changshui Zhang", "title": "Subspace Attack: Exploiting Promising Subspaces for Query-Efficient\n  Black-box Attacks", "comments": "10 pages + 3 pages supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlike the white-box counterparts that are widely studied and readily\naccessible, adversarial examples in black-box settings are generally more\nHerculean on account of the difficulty of estimating gradients. Many methods\nachieve the task by issuing numerous queries to target classification systems,\nwhich makes the whole procedure costly and suspicious to the systems. In this\npaper, we aim at reducing the query complexity of black-box attacks in this\ncategory. We propose to exploit gradients of a few reference models which\narguably span some promising search subspaces. Experimental results show that,\nin comparison with the state-of-the-arts, our method can gain up to 2x and 4x\nreductions in the requisite mean and medium numbers of queries with much lower\nfailure rates even if the reference models are trained on a small and\ninadequate dataset disjoint to the one for training the victim model. Code and\nmodels for reproducing our results will be made publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 04:55:18 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Yan", "Ziang", ""], ["Guo", "Yiwen", ""], ["Zhang", "Changshui", ""]]}, {"id": "1906.04410", "submitter": "Yutaka Shikano", "authors": "Kentaro Tamura, Yutaka Shikano", "title": "Quantum Random Numbers generated by the Cloud Superconducting Quantum\n  Computer", "comments": "21 pages, 5 figures, submitted to the paper in Book \"Mathematics,\n  Quantum Theory, and Cryptography\" Mathematics for Industry, Springer. In the\n  revised manuscript, the results of the simulator with the noise parameters\n  were added", "journal-ref": "International Symposium on Mathematics, Quantum Theory, and\n  Cryptography, Mathematics for Industry, vol 33 (Springer, Singapore, 2021) 17\n  -- 37", "doi": "10.1007/978-981-15-5191-8_6", "report-no": null, "categories": "quant-ph cs.CR cs.DC physics.data-an stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A cloud quantum computer is similar to a random number generator in that its\nphysical mechanism is inaccessible to its users. In this respect, a cloud\nquantum computer is a black box. In both devices, its users decide the device\ncondition from the output. A framework to achieve this exists in the field of\nrandom number generation in the form of statistical tests for random number\ngenerators. In the present study, we generated random numbers on a 20-qubit\ncloud quantum computer and evaluated the condition and stability of its qubits\nusing statistical tests for random number generators. As a result, we observed\nthat some qubits were more biased than others. Statistical tests for random\nnumber generators may provide a simple indicator of qubit condition and\nstability, enabling users to decide for themselves which qubits inside a cloud\nquantum computer to use.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 06:36:30 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 22:02:17 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Tamura", "Kentaro", ""], ["Shikano", "Yutaka", ""]]}, {"id": "1906.04411", "submitter": "Jia Guo", "authors": "Jia Guo, Miodrag Potkonjak", "title": "Evolutionary Trigger Set Generation for DNN Black-Box Watermarking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The commercialization of deep learning creates a compelling need for\nintellectual property (IP) protection. Deep neural network (DNN) watermarking\nhas been proposed as a promising tool to help model owners prove ownership and\nfight piracy. A popular approach of watermarking is to train a DNN to recognize\nimages with certain \\textit{trigger} patterns. In this paper, we propose a\nnovel evolutionary algorithm-based method to generate and optimize trigger\npatterns. Our method brings a siginificant reduction in false positive rates,\nleading to compelling proof of ownership. At the same time, it maintains the\nrobustness of the watermark against attacks. We compare our method with the\nprior art and demonstrate its effectiveness on popular models and datasets.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 06:46:20 GMT"}, {"version": "v2", "created": "Sun, 14 Feb 2021 03:38:41 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Guo", "Jia", ""], ["Potkonjak", "Miodrag", ""]]}, {"id": "1906.04421", "submitter": "Peter Robinson", "authors": "Peter Robinson", "title": "The merits of using Ethereum MainNet as a Coordination Blockchain for\n  Ethereum Private Sidechains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Coordination Blockchain is a blockchain with the task of coordinating\nactivities of multiple private blockchains. This paper discusses the pros and\ncons of using Ethereum MainNet, the public Ethereum blockchain, as a\nCoordination Blockchain. The requirements Ethereum MainNet needs to fulfil to\nperform this role are discussed within the context of Ethereum Private\nSidechains, a private blockchain technology which allows many blockchains to be\noperated in parallel, and allows atomic crosschain transactions to execute\nacross blockchains. Ethereum MainNet is a permissionless network which aims to\noffer strong authenticity, integrity, and non-repudiation properties, that\nincentivises good behaviour using crypto economics. This paper demonstrates\nthat Ethereum MainNet does deliver these properties. It then provides a\ncomprehensive review of the features of Ethereum Private Sidechains, with a\nfocus on the potential usage of Coordination Blockchains for these features.\nFinally, the merits of using Ethereum MainNet as a Coordination Blockchain are\nassessed. For Ethereum Private Sidechains, we found that Ethereum MainNet is\nbest suited to storing long term static data that needs to be widely available,\nsuch as the Ethereum Registration Authority information. However, due to\nEthereum MainNet's probabilistic finality, it is not well suited to information\nthat needs to be available and acted upon immediately, such as the Sidechain\nPublic Keys and Atomic Crosschain Transaction state information that need to be\naccessible prior to the first atomic crosschain transaction being issued on a\nsidechain. Although this paper examined the use of Ethereum MainNet as a\nCoordination Blockchain within reference to Ethereum Private Sidechains, the\ndiscussions and observations of the typical tasks a Coordination blockchain may\nbe expected to perform are applicable more widely to any multi-blockchain\nsystem.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 07:49:37 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 23:11:57 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Robinson", "Peter", ""]]}, {"id": "1906.04480", "submitter": "Anastasiya Gorodilova", "authors": "Anastasiya Gorodilova, Sergey Agievich, Claude Carlet, Xiang-dong Hou,\n  Valeriya Idrisova, Nikolay Kolomeec, Alexandr Kutsenko, Luca Mariot, Alexey\n  Oblaukhov, Stjepan Picek, Bart Preneel, Razvan Rosie, Natalia Tokareva", "title": "The Fifth International Students' Olympiad in Cryptography -- NSUCRYPTO:\n  problems and their solutions", "comments": null, "journal-ref": null, "doi": "10.1080/01611194.2019.1670282", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Problems and their solutions of the Fifth International Students' Olympiad in\ncryptography NSUCRYPTO'2018 are presented. We consider problems related to\nattacks on ciphers and hash functions, Boolean functions, quantum circuits,\nEnigma, etc. We discuss several open problems on orthogonal arrays, Sylvester\nmatrices and disjunct matrices. The problem of existing an invertible Sylvester\nmatrix whose inverse is again a Sylvester matrix was completely solved during\nthe Olympiad.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 10:13:27 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 06:04:17 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Gorodilova", "Anastasiya", ""], ["Agievich", "Sergey", ""], ["Carlet", "Claude", ""], ["Hou", "Xiang-dong", ""], ["Idrisova", "Valeriya", ""], ["Kolomeec", "Nikolay", ""], ["Kutsenko", "Alexandr", ""], ["Mariot", "Luca", ""], ["Oblaukhov", "Alexey", ""], ["Picek", "Stjepan", ""], ["Preneel", "Bart", ""], ["Rosie", "Razvan", ""], ["Tokareva", "Natalia", ""]]}, {"id": "1906.04494", "submitter": "Rizwan Ahmed Khan", "authors": "Anjum Nazir, Rizwan Ahmed Khan", "title": "Combinatorial Optimization based Feature Selection Method: A study on\n  Network Intrusion Detection", "comments": "Data is ambiguous and multi-dimensional and it is not possible to\n  update this article at the moment", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Advancements in computer networks and communication technologies like\nsoftware defined networks (SDN), Internet of things (IoT), microservices\narchitecture, cloud computing and network function virtualization (NFV) have\nopened new fronts and challenges for security experts to combat against modern\ncyberattacks. Relying on perimeter defense and signature-based network security\nsolutions like Intrusion Detection and Prevention Systems (IDS/IPS) have failed\nto deliver adequate level of security against new attack vectors such as\nadvance persistent threats, zero days, ransomware, botnets and other forms of\ntargeted attacks. Recent developments in machine learning and cognitive\ncomputing have shown great potential to detect unknown and new intrusion events\nwhere legacy misuse and anomaly based intrusion detection systems usually fail.\nIn this research study we applied state of the art machine learning algorithms\non UNSW-NB15 dataset for potential applicability to detect new attacks. We also\nproposed a novel wrapper based feature selection technique TS-RF using\nmetaheuristic Tabu Search (TS) algorithm and Random Forest (RF) ensemble\nclassifier. Results obtained by applying proposed feature selection technique\ni.e. TS-RF on UNSW-NB15 dataset show improvement in overall intrusion detection\naccuracy while it reduces computation complexity as it removes more than 60%\nfeatures.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 10:53:49 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 06:24:25 GMT"}, {"version": "v3", "created": "Tue, 19 Jan 2021 11:26:24 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Nazir", "Anjum", ""], ["Khan", "Rizwan Ahmed", ""]]}, {"id": "1906.04502", "submitter": "Francisco Javier Marmolejo-Coss\\'io", "authors": "Francisco J. Marmolejo-Coss\\'io, Eric Brigham, Benjamin Sela, Jonathan\n  Katz", "title": "Competing (Semi)-Selfish Miners in Bitcoin", "comments": "27 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bitcoin protocol prescribes certain behavior by the miners who are\nresponsible for maintaining and extending the underlying blockchain; in\nparticular, miners who successfully solve a puzzle, and hence can extend the\nchain by a block, are supposed to release that block immediately. Eyal and\nSirer showed, however, that a selfish miner is incentivized to deviate from the\nprotocol and withhold its blocks under certain conditions.\n  The analysis by Eyal and Sirer, as well as in followup work, considers a\n\\emph{single} deviating miner (who may control a large fraction of the hashing\npower in the network) interacting with a remaining pool of honest miners. Here,\nwe extend this analysis to the case where there are \\emph{multiple}\n(non-colluding) selfish miners. We find that with multiple strategic miners,\nspecific deviations from honest mining by multiple strategic agents can\noutperform honest mining, even if individually miners would not be incentivised\nto be dishonest. This previous point effectively renders the Bitcoin protocol\nto be less secure than previously thought.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 11:38:53 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Marmolejo-Coss\u00edo", "Francisco J.", ""], ["Brigham", "Eric", ""], ["Sela", "Benjamin", ""], ["Katz", "Jonathan", ""]]}, {"id": "1906.04584", "submitter": "Hadi Salman", "authors": "Hadi Salman, Greg Yang, Jerry Li, Pengchuan Zhang, Huan Zhang, Ilya\n  Razenshteyn, Sebastien Bubeck", "title": "Provably Robust Deep Learning via Adversarially Trained Smoothed\n  Classifiers", "comments": "Spotlight at the 33rd Conference on Neural Information Processing\n  Systems (NeurIPS 2019), Vancouver, Canada; 9 pages main text; 31 pages total", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have shown the effectiveness of randomized smoothing as a\nscalable technique for building neural network-based classifiers that are\nprovably robust to $\\ell_2$-norm adversarial perturbations. In this paper, we\nemploy adversarial training to improve the performance of randomized smoothing.\nWe design an adapted attack for smoothed classifiers, and we show how this\nattack can be used in an adversarial training setting to boost the provable\nrobustness of smoothed classifiers. We demonstrate through extensive\nexperimentation that our method consistently outperforms all existing provably\n$\\ell_2$-robust classifiers by a significant margin on ImageNet and CIFAR-10,\nestablishing the state-of-the-art for provable $\\ell_2$-defenses. Moreover, we\nfind that pre-training and semi-supervised learning boost adversarially trained\nsmoothed classifiers even further. Our code and trained models are available at\nhttp://github.com/Hadisalman/smoothing-adversarial .\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 15:55:21 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 06:08:27 GMT"}, {"version": "v3", "created": "Sat, 14 Sep 2019 06:28:54 GMT"}, {"version": "v4", "created": "Sun, 3 Nov 2019 09:26:29 GMT"}, {"version": "v5", "created": "Fri, 10 Jan 2020 00:03:27 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Salman", "Hadi", ""], ["Yang", "Greg", ""], ["Li", "Jerry", ""], ["Zhang", "Pengchuan", ""], ["Zhang", "Huan", ""], ["Razenshteyn", "Ilya", ""], ["Bubeck", "Sebastien", ""]]}, {"id": "1906.04593", "submitter": "Renjie Lu", "authors": "Renjie Lu", "title": "Malware Detection with LSTM using Opcode Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, with the booming development of Internet and software industry,\nmore and more malware variants are designed to perform various malicious\nactivities. Traditional signature-based detection methods can not detect\nvariants of malware. In addition, most behavior-based methods require a secure\nand isolated environment to perform malware detection, which is vulnerable to\nbe contaminated. In this paper, similar to natural language processing, we\npropose a novel and efficient approach to perform static malware analysis,\nwhich can automatically learn the opcode sequence patterns of malware. We\npropose modeling malware as a language and assess the feasibility of this\napproach. First, We use the disassembly tool IDA Pro to obtain opcode sequence\nof malware. Then the word embedding technique is used to learn the feature\nvector representation of opcode. Finally, we propose a two-stage LSTM model for\nmalware detection, which use two LSTM layers and one mean-pooling layer to\nobtain the feature representations of opcode sequences of malwares. We perform\nexperiments on the dataset that includes 969 malware and 123 benign files. In\nterms of malware detection and malware classification, the evaluation results\nshow our proposed method can achieve average AUC of 0.99 and average AUC of\n0.987 in best case, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 10:11:49 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Lu", "Renjie", ""]]}, {"id": "1906.04611", "submitter": "Jing Yang", "authors": "Jing Yang, Fang-Wei Fu", "title": "New dynamic and verifiable multi-secret sharing schemes based on LFSR\n  public key cryptosystem", "comments": "21 pages, 1 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A verifiable multi-secret sharing (VMSS) scheme enables the dealer to share\nmultiple secrets, and the deception of both participants and the dealer can be\ndetected. After analyzing the security of VMSS schemes proposed by Mashhadi and\nDehkordi in 2015, we illustrate that they cannot detect some deception of the\ndealer. By using nonhomogeneous linear recursion and LFSR public key\ncryptosystem, we introduce two new VMSS schemes. Our schemes can not only\novercome the drawback mentioned above, but also have shorter private/public key\nlength at the same safety level. Besides, our schemes have dynamism.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 14:08:07 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Yang", "Jing", ""], ["Fu", "Fang-Wei", ""]]}, {"id": "1906.04632", "submitter": "Renjie Lu", "authors": "Renjie Lu", "title": "SCGDet: Malware Detection using Semantic Features Based on Reachability\n  Relation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, with the booming development of software industry, more and more\nmalware variants are designed to perform malicious behaviors. The evolution of\nmalware makes it difficult to detect using traditional signature-based methods.\nMoreover, malware detection has important effect on system security. In this\npaper, we present SCGDet, which is a novel malware detection method based on\nsystem call graph model (SCGM). We first develop a system call pruning method,\nwhich can exclude system calls that have little impact on malware detection.\nThen we propose the SCGM, which can capture the semantic features of run-time\nprogram by grouping the system calls based on the reachability relation. We aim\nto obtain the generic representation of malicious behaviors with similar system\ncall patterns. We evaluate the performance of SCGDet using different machine\nlearning algorithms on the dataset including 854 malware samples and 740 benign\nsamples. Compared with the traditional n-gram method, the SCGDet has the\nsmaller feature space, the higher detection accuracy and the lower false\npositives. Experimental results show that SCGDet can reduce the average FPR of\n14.75% and improve the average Accuracy of 8.887%, and can obtain a TPR of\n97.44%, an FPR of 1.96% and an Accuracy of 97.78% in the best case.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 08:42:57 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Lu", "Renjie", ""]]}, {"id": "1906.04830", "submitter": "\\'Eric Tanter", "authors": "Raimil Cruz, \\'Eric Tanter", "title": "Polymorphic Relaxed Noninterference", "comments": "update affiliation/funding", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Information-flow security typing statically preserves confidentiality by\nenforcing noninterference. To address the practical need of selective and\nflexible declassification of confidential information, several approaches have\ndeveloped a notion of relaxed noninterference, where security labels are either\nfunctions or types. The labels-as-types approach to relaxed noninterference\nsupports expressive declassification policies, including recursive ones, via a\nsimple subtyping-based ordering, and provides a local, modular reasoning\nprinciple. In this work, we extend this expressive declassification approach in\norder to support polymorphic declassification. First, we identify the need for\nbounded polymorphism through concrete examples. We then formalize polymorphic\nrelaxed noninterference in a typed object-oriented calculus, using a\nstep-indexed logical relation to prove that all well-typed terms are secure.\nFinally, we address the case of primitive types, which requires a form of\nad-hoc polymorphism. Therefore, this work addresses practical hurdles to\nproviding controlled and expressive declassification for the construction of\ninformation-flow secure systems.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 21:29:44 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 10:15:08 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Cruz", "Raimil", ""], ["Tanter", "\u00c9ric", ""]]}, {"id": "1906.04862", "submitter": "Amos Treiber", "authors": "Thomas Schneider and Amos Treiber", "title": "A Comment on Privacy-Preserving Scalar Product Protocols as proposed in\n  \"SPOC\"", "comments": "Accepted at IEEE Transactions on Parallel and Distributed Systems", "journal-ref": "IEEE TPDS 2019", "doi": "10.1109/TPDS.2019.2939313", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy-preserving scalar product (PPSP) protocols are an important building\nblock for secure computation tasks in various applications. Lu et al. (TPDS'13)\nintroduced a PPSP protocol that does not rely on cryptographic assumptions and\nthat is used in a wide range of publications to date. In this comment paper, we\nshow that Lu et al.'s protocol is insecure and should not be used. We describe\nspecific attacks against it and, using impossibility results of Impagliazzo and\nRudich (STOC'89), show that it is inherently insecure and cannot be fixed\nwithout relying on at least some cryptographic assumptions.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 23:32:09 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 16:22:27 GMT"}, {"version": "v3", "created": "Sat, 24 Aug 2019 09:07:03 GMT"}, {"version": "v4", "created": "Sun, 1 Sep 2019 09:27:00 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Schneider", "Thomas", ""], ["Treiber", "Amos", ""]]}, {"id": "1906.04951", "submitter": "Sajad Homayoun", "authors": "Sajad Homayoun, Ali Dehghantanha, Reza M. Parizi, Kim-Kwang Raymond\n  Choo", "title": "A Blockchain-based Framework for Detecting Malicious Mobile Applications\n  in App Stores", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The dramatic growth in smartphone malware shows that malicious program\ndevelopers are shifting from traditional PC systems to smartphone devices.\nTherefore, security researchers are also moving towards proposing novel\nantimalware methods to provide adequate protection. This paper proposes a\nBlockchain-Based Malware Detection Framework (B2MDF) for detecting malicious\nmobile applications in mobile applications marketplaces (app stores). The\nframework consists of two internal and external private blockchains forming a\ndual private blockchain as well as a consortium blockchain for the final\ndecision. The internal private blockchain stores feature blocks extracted by\nboth static and dynamic feature extractors, while the external blockchain\nstores detection results as blocks for current versions of applications. B2MDF\nalso shares feature blocks with third parties, and this helps antimalware\nvendors to provide more accurate solutions.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 05:38:30 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Homayoun", "Sajad", ""], ["Dehghantanha", "Ali", ""], ["Parizi", "Reza M.", ""], ["Choo", "Kim-Kwang Raymond", ""]]}, {"id": "1906.04953", "submitter": "Sajad Homayoun", "authors": "Reza M. Parizi, Sajad Homayoun, Abbas Yazdinejad, Ali Dehghantanha,\n  Kim-Kwang Raymond Choo", "title": "Integrating Privacy Enhancing Techniques into Blockchains Using\n  Sidechains", "comments": "Accepted in the IEEE 32nd Canadian Conference of Electrical and\n  Computer Engineering (IEEE CCECE), Edmonton, AB, Canada, May 5-8, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Blockchains are turning into decentralized computing platforms and are\ngetting worldwide recognition for their unique advantages. There is an emerging\ntrend beyond payments that blockchains could enable a new breed of\ndecentralized applications, and serve as the foundation for Internet's security\ninfrastructure. The immutable nature of the blockchain makes it a winner on\nsecurity and transparency; it is nearly inconceivable for ledgers to be altered\nin a way not instantly clear to every single user involved. However, most\nblockchains fall short in privacy aspects, particularly in data protection.\nGarlic Routing and Onion Routing are two of major Privacy Enhancing Techniques\n(PETs) which are popular for anonymization and security. Garlic Routing is a\nmethodology using by I2P Anonymous Network to hide the identity of sender and\nreceiver of data packets by bundling multiple messages into a layered\nencryption structure. The Onion Routing attempts to provide lowlatency\nInternet-based connections that resist traffic analysis, deanonymization\nattack, eavesdropping, and other attacks both by outsiders (e.g. Internet\nrouters) and insiders (Onion Routing servers themselves). As there are a few\ncontroversies over the rate of resistance of these two techniques to privacy\nattacks, we propose a PET-Enabled Sidechain (PETES) as a new privacy enhancing\ntechnique by integrating Garlic Routing and Onion Routing into a Garlic Onion\nRouting (GOR) framework suitable to the structure of blockchains. The\npreliminary proposed GOR aims to improve the privacy of transactions in\nblockchains via PETES structure.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 05:48:04 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Parizi", "Reza M.", ""], ["Homayoun", "Sajad", ""], ["Yazdinejad", "Abbas", ""], ["Dehghantanha", "Ali", ""], ["Choo", "Kim-Kwang Raymond", ""]]}, {"id": "1906.05108", "submitter": "Leye Wang", "authors": "Di Chai, Leye Wang, Kai Chen, Qiang Yang", "title": "Secure Federated Matrix Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To protect user privacy and meet law regulations, federated (machine)\nlearning is obtaining vast interests in recent years. The key principle of\nfederated learning is training a machine learning model without needing to know\neach user's personal raw private data. In this paper, we propose a secure\nmatrix factorization framework under the federated learning setting, called\nFedMF. First, we design a user-level distributed matrix factorization framework\nwhere the model can be learned when each user only uploads the gradient\ninformation (instead of the raw preference data) to the server. While gradient\ninformation seems secure, we prove that it could still leak users' raw data. To\nthis end, we enhance the distributed matrix factorization framework with\nhomomorphic encryption. We implement the prototype of FedMF and test it with a\nreal movie rating dataset. Results verify the feasibility of FedMF. We also\ndiscuss the challenges for applying FedMF in practice for future research.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 13:00:07 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Chai", "Di", ""], ["Wang", "Leye", ""], ["Chen", "Kai", ""], ["Yang", "Qiang", ""]]}, {"id": "1906.05132", "submitter": "Nicolas Liochon", "authors": "Olivier B\\'egassat, Blazej Kolad, Nicolas Gailly, Nicolas Liochon", "title": "Handel: Practical Multi-Signature Aggregation for Large Byzantine\n  Committees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Handel, a Byzantine-tolerant aggregation protocol that allows for\nthe quick aggregation of cryptographic signatures over a WAN. Handel has\npolylogarithmic time, communication and processing complexity. We implemented\nHandel as an open source Go library with a flexible design to support any\nassociative and commutative aggregation function. We tested Handel on 2000 AWS\ninstances running two nodes per instance and located in 10 AWS regions. The\n4000 signatures are aggregated in less than 900 milliseconds with an average\nper-node communication cost of 56KB.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 13:38:25 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 18:18:13 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["B\u00e9gassat", "Olivier", ""], ["Kolad", "Blazej", ""], ["Gailly", "Nicolas", ""], ["Liochon", "Nicolas", ""]]}, {"id": "1906.05268", "submitter": "Jeff Yan", "authors": "Aur\\'elien Bourquard, Jeff Yan", "title": "Differential Imaging Forensics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce some new forensics based on differential imaging, where a novel\ncategory of visual evidence created via subtle interactions of light with a\nscene, such as dim reflections, can be computationally extracted and amplified\nfrom an image of interest through a comparative analysis with an additional\nreference baseline image acquired under similar conditions. This paradigm of\ndifferential imaging forensics (DIF) enables forensic examiners for the first\ntime to retrieve the said visual evidence that is readily available in an image\nor video footage but would otherwise remain faint or even invisible to a human\nobserver. We demonstrate the relevance and effectiveness of our approach\nthrough practical experiments. We also show that DIF provides a novel method\nfor detecting forged images and video clips, including deep fakes.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 17:48:47 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Bourquard", "Aur\u00e9lien", ""], ["Yan", "Jeff", ""]]}, {"id": "1906.05283", "submitter": "Carlos E. Budde", "authors": "Jaime Arias, Carlos E. Budde, Wojciech Penczek, Laure Petrucci,\n  Mari\\\"elle Stoelinga", "title": "Hackers vs. Security: Attack-Defence Trees as Asynchronous Multi-Agent\n  Systems", "comments": "This work was partially funded by the NWO project SEQUOIA (grant\n  15474), EU project SUCCESS (102112) and the PHC van Gogh PAMPAS. The work of\n  Arias and Petrucci has been supported by the BQR project AMoJAS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.FL cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Attack-Defence Trees (ADTs) are well-suited to assess possible attacks to\nsystems and the efficiency of counter-measures. In this paper, we first enrich\nthe available constructs with reactive patterns that cover further security\nscenarios, and equip all constructs with attributes such as time and cost to\nallow quantitative analyses. Then, ADTs are modelled as (an extension of)\nAsynchronous Multi-Agents Systems--EAMAS. The ADT-EAMAS transformation is\nperformed in a systematic manner that ensures correctness. The transformation\nallows us to quantify the impact of different agents configurations on metrics\nsuch as attack time. Using EAMAS also permits parametric verification: we\nderive constraints for property satisfaction. Our approach is exercised on\nseveral case studies using the Uppaal and IMITATOR tools.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 17:27:58 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Arias", "Jaime", ""], ["Budde", "Carlos E.", ""], ["Penczek", "Wojciech", ""], ["Petrucci", "Laure", ""], ["Stoelinga", "Mari\u00eblle", ""]]}, {"id": "1906.05395", "submitter": "Eric Ficke", "authors": "Jose David Mireles, Eric Ficke, Jin-Hee Cho, Patrick Hurley and\n  Shouhuai Xu", "title": "Metrics Towards Measuring Cyber Agility", "comments": null, "journal-ref": null, "doi": "10.1109/TIFS.2019.2912551", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cyberspace, evolutionary strategies are commonly used by both attackers\nand defenders. For example, an attacker's strategy often changes over the\ncourse of time, as new vulnerabilities are discovered and/or mitigated.\nSimilarly, a defender's strategy changes over time. These changes may or may\nnot be in direct response to a change in the opponent's strategy. In any case,\nit is important to have a set of quantitative metrics to characterize and\nunderstand the effectiveness of attackers' and defenders' evolutionary\nstrategies, which reflect their {\\em cyber agility}. Despite its clear\nimportance, few systematic metrics have been developed to quantify the cyber\nagility of attackers and defenders. In this paper, we propose the first metric\nframework for measuring cyber agility in terms of the effectiveness of the\ndynamic evolution of cyber attacks and defenses. The proposed framework is\ngeneric and applicable to transform any relevant, quantitative, and/or\nconventional static security metrics (e.g., false positives and false\nnegatives) into dynamic metrics to capture dynamics of system behaviors. In\norder to validate the usefulness of the proposed framework, we conduct case\nstudies on measuring the evolution of cyber attacks and defenses using two\nreal-world datasets. We discuss the limitations of the current work and\nidentify future research directions.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 21:50:45 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Mireles", "Jose David", ""], ["Ficke", "Eric", ""], ["Cho", "Jin-Hee", ""], ["Hurley", "Patrick", ""], ["Xu", "Shouhuai", ""]]}, {"id": "1906.05457", "submitter": "Shuyuan Zheng", "authors": "Shuyuan Zheng and Yang Cao and Masatoshi Yoshikawa", "title": "Trading Location Data with Bounded Personalized Privacy Loss", "comments": "Proceedings of the Third Workshop on Software Foundations for Data\n  Interoperability (SFDI2019+), October 28, 2019, Fukuoka, Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As personal data have been the new oil of the digital era, there is a growing\ntrend perceiving personal data as a commodity. Although some people are willing\nto trade their personal data for money, they might still expect limited privacy\nloss, and the maximum tolerable privacy loss varies with each individual. In\nthis paper, we propose a framework that enables individuals to trade their\npersonal data with bounded personalized privacy loss, which raises technical\nchallenges in the aspects of budget allocation and arbitrage-freeness. To deal\nwith those challenges,we propose two arbitrage-free trading mechanisms with\ndifferent advantages.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 02:22:32 GMT"}, {"version": "v2", "created": "Sat, 29 Jun 2019 16:58:17 GMT"}, {"version": "v3", "created": "Thu, 24 Oct 2019 07:51:19 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Zheng", "Shuyuan", ""], ["Cao", "Yang", ""], ["Yoshikawa", "Masatoshi", ""]]}, {"id": "1906.05538", "submitter": "Wei Cai", "authors": "Tian Min and Wei Cai", "title": "A Security Case Study for Blockchain Games", "comments": null, "journal-ref": "IEEE Games Entertainment & Media Conference 2019 (GEM 2019), New\n  Haven, Connecticut, United States, June 19-22, 2019", "doi": null, "report-no": null, "categories": "cs.CR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain gaming is an emerging entertainment paradigm. However, blockchain\ngames are still suffering from security issues, due to the immature blockchain\ntechnologies and its unsophisticated developers. In this work, we analyzed the\nblockchain game architecture and reveal the possible penetration methods of\ncracking. We scanned more than 600 commercial blockchain games to summarize a\nsecurity overview from the perspective of the web server and smart contract,\nrespectively. We also conducted three case studies for blockchain games to show\ndetailed vulnerability detection.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 08:11:55 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Min", "Tian", ""], ["Cai", "Wei", ""]]}, {"id": "1906.05599", "submitter": "Aly El Gamal", "authors": "Rajeev Sahay, Rehana Mahfuz, Aly El Gamal", "title": "A Computationally Efficient Method for Defending Adversarial Deep\n  Learning Attacks", "comments": "6 pages, 6 figures, submitted to IEEE Signal Processing Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reliance on deep learning algorithms has grown significantly in recent\nyears. Yet, these models are highly vulnerable to adversarial attacks, which\nintroduce visually imperceptible perturbations into testing data to induce\nmisclassifications. The literature has proposed several methods to combat such\nadversarial attacks, but each method either fails at high perturbation values,\nrequires excessive computing power, or both. This letter proposes a\ncomputationally efficient method for defending the Fast Gradient Sign (FGS)\nadversarial attack by simultaneously denoising and compressing data.\nSpecifically, our proposed defense relies on training a fully connected\nmulti-layer Denoising Autoencoder (DAE) and using its encoder as a defense\nagainst the adversarial attack. Our results show that using this dimensionality\nreduction scheme is not only highly effective in mitigating the effect of the\nFGS attack in multiple threat models, but it also provides a 2.43x speedup in\ncomparison to defense strategies providing similar robustness against the same\nattack.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 10:56:47 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Sahay", "Rajeev", ""], ["Mahfuz", "Rehana", ""], ["Gamal", "Aly El", ""]]}, {"id": "1906.05646", "submitter": "Laura Sargsyan", "authors": "L Sargsyan, J Andreeva, M Jha, E Karavakis, L Kokoszkiewicz, P Saiz, J\n  Schovancova, D Tuckett (on behalf of the Atlas Collaboration)", "title": "Dashboard Task Monitor for Managing ATLAS User Analysis on the Grid", "comments": "7 pages", "journal-ref": "2014 J. Phys.: Conf. Ser.513 032083", "doi": "10.1088/1742-6596/513/3/032083", "report-no": null, "categories": "physics.data-an cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The organization of the distributed user analysis on the Worldwide LHC\nComputing Grid (WLCG) infrastructure is one of the most challenging tasks among\nthe computing activities at the Large Hadron Collider. The Experiment Dashboard\noffers a solution that not only monitors but also manages (kill, resubmit) user\ntasks and jobs via a web interface. The ATLAS Dashboard Task Monitor provides\nanalysis users with a tool that is independent of the operating system and Grid\nenvironment. This contribution describes the functionality of the application\nand its implementation details, in particular authentication, authorization and\naudit of the management operations.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 11:34:05 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Sargsyan", "L", "", "on behalf of the Atlas Collaboration"], ["Andreeva", "J", "", "on behalf of the Atlas Collaboration"], ["Jha", "M", "", "on behalf of the Atlas Collaboration"], ["Karavakis", "E", "", "on behalf of the Atlas Collaboration"], ["Kokoszkiewicz", "L", "", "on behalf of the Atlas Collaboration"], ["Saiz", "P", "", "on behalf of the Atlas Collaboration"], ["Schovancova", "J", "", "on behalf of the Atlas Collaboration"], ["Tuckett", "D", "", "on behalf of the Atlas Collaboration"]]}, {"id": "1906.05754", "submitter": "Tin Tironsakkul", "authors": "Tin Tironsakkul, Manuel Maarek, Andrea Eross, and Mike Just", "title": "Probing the Mystery of Cryptocurrency Theft: An Investigation into\n  Methods for Taint Analysis", "comments": "13 pages 12 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the creation of Bitcoin, transaction tracking is one of the prominent\nmeans for following the movement of Bitcoins involved in illegal activities.\nAlthough every Bitcoin transaction is recorded in the blockchain database,\nwhich is transparent for anyone to observe and analyse, Bitcoin's pseudonymity\nsystem and transaction obscuring techniques still allow criminals to disguise\ntheir transaction trail. While there have been a few attempts to develop\ntracking methods, there is no accepted evaluation method to measure their\naccuracy. Therefore, this paper investigates strategies for transaction\ntracking by introducing two new tainting methods, and proposes an address\nprofiling approach with a metrics-based evaluation framework. We use our\napproach and framework to compare the accuracy of our new tainting methods with\nthe previous tainting techniques, using data from two real Bitcoin theft\ntransactions and several related control transactions.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 15:33:41 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 23:44:27 GMT"}, {"version": "v3", "created": "Thu, 5 Dec 2019 14:24:59 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Tironsakkul", "Tin", ""], ["Maarek", "Manuel", ""], ["Eross", "Andrea", ""], ["Just", "Mike", ""]]}, {"id": "1906.05799", "submitter": "Thanh Thi Nguyen", "authors": "Thanh Thi Nguyen and Vijay Janapa Reddi", "title": "Deep Reinforcement Learning for Cyber Security", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scale of Internet-connected systems has increased considerably, and these\nsystems are being exposed to cyber attacks more than ever. The complexity and\ndynamics of cyber attacks require protecting mechanisms to be responsive,\nadaptive, and scalable. Machine learning, or more specifically deep\nreinforcement learning (DRL), methods have been proposed widely to address\nthese issues. By incorporating deep learning into traditional RL, DRL is highly\ncapable of solving complex, dynamic, and especially high-dimensional cyber\ndefense problems. This paper presents a survey of DRL approaches developed for\ncyber security. We touch on different vital aspects, including DRL-based\nsecurity methods for cyber-physical systems, autonomous intrusion detection\ntechniques, and multi-agent DRL-based game theory simulations for defense\nstrategies against cyber attacks. Extensive discussions and future research\ndirections on DRL-based cyber security are also given. We expect that this\ncomprehensive review provides the foundations for and facilitates future\nstudies on exploring the potential of emerging DRL to cope with increasingly\ncomplex cyber security problems.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 16:34:12 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 17:55:14 GMT"}, {"version": "v3", "created": "Tue, 21 Jul 2020 10:06:00 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Nguyen", "Thanh Thi", ""], ["Reddi", "Vijay Janapa", ""]]}, {"id": "1906.05815", "submitter": "Mohammad Mahmoody", "authors": "Dimitrios I. Diochnos, Saeed Mahloujifar, Mohammad Mahmoody", "title": "Lower Bounds for Adversarially Robust PAC Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we initiate a formal study of probably approximately correct\n(PAC) learning under evasion attacks, where the adversary's goal is to\n\\emph{misclassify} the adversarially perturbed sample point $\\widetilde{x}$,\ni.e., $h(\\widetilde{x})\\neq c(\\widetilde{x})$, where $c$ is the ground truth\nconcept and $h$ is the learned hypothesis. Previous work on PAC learning of\nadversarial examples have all modeled adversarial examples as corrupted inputs\nin which the goal of the adversary is to achieve $h(\\widetilde{x}) \\neq c(x)$,\nwhere $x$ is the original untampered instance. These two definitions of\nadversarial risk coincide for many natural distributions, such as images, but\nare incomparable in general.\n  We first prove that for many theoretically natural input spaces of high\ndimension $n$ (e.g., isotropic Gaussian in dimension $n$ under $\\ell_2$\nperturbations), if the adversary is allowed to apply up to a sublinear\n$o(||x||)$ amount of perturbations on the test instances, PAC learning requires\nsample complexity that is exponential in $n$. This is in contrast with results\nproved using the corrupted-input framework, in which the sample complexity of\nrobust learning is only polynomially more.\n  We then formalize hybrid attacks in which the evasion attack is preceded by a\npoisoning attack. This is perhaps reminiscent of \"trapdoor attacks\" in which a\npoisoning phase is involved as well, but the evasion phase here uses the\nerror-region definition of risk that aims at misclassifying the perturbed\ninstances. In this case, we show PAC learning is sometimes impossible all\ntogether, even when it is possible without the attack (e.g., due to the bounded\nVC dimension).\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 17:01:19 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Diochnos", "Dimitrios I.", ""], ["Mahloujifar", "Saeed", ""], ["Mahmoody", "Mohammad", ""]]}, {"id": "1906.05919", "submitter": "Danilo Francati", "authors": "Adriano Di Luzio, Danilo Francati, Giuseppe Ateniese", "title": "Arcula: A Secure Hierarchical Deterministic Wallet for Multi-asset\n  Blockchains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents Arcula, a new design for hierarchical deterministic\nwallets that brings identity-based addresses to the blockchain. Arcula is built\non top of provably secure cryptographic primitives. It generates all its\ncryptographic secrets from a user-provided seed and enables the derivation of\nnew public keys based on the identities of users, without requiring any secret\ninformation. Unlike other wallets, it achieves all these properties while being\nsecure against privilege escalation. We formalize the security model of\nhierarchical deterministic wallets and prove that an attacker compromising an\narbitrary number of users within an Arcula wallet cannot escalate his\nprivileges and compromise users higher in the access hierarchy. Our design\nworks out-of-the-box with any blockchain that enables the verification of\nsignatures on arbitrary messages. We evaluate its usage in a real-world\nscenario on the Bitcoin Cash network.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 20:39:11 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 19:13:19 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Di Luzio", "Adriano", ""], ["Francati", "Danilo", ""], ["Ateniese", "Giuseppe", ""]]}, {"id": "1906.06009", "submitter": "Wang Kang", "authors": "Wang Kang", "title": "U2Fi: A Provisioning Scheme of IoT Devices with Universal Cryptographic\n  Tokens", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Provisioning is the starting point of the whole life-cycle of IoT devices.\nThe traditional provisioning methods of IoT devices are facing several issues,\neither about user experience or privacy harvesting. Moreover, IoT devices are\nvulnerable to different levels of attacks due to limited resources and long\nonline duration. In this paper, we proposed U2Fi, a novel provisioning scheme\nfor IoT devices. We provide a solution to make the U2F device that has been\ntrusted by the cloud in the distribution process, via WiFi or its side channel,\nto provision the new IoT device. Further, subsequent device settings\nmodification, setting update, and owner transfer can also be performed by using\na U2F device that has been trusted to improve security and provide a better\nuser experience. This could provide helpful user friendliness to some valuable\nnew application scenarios in IoT, such as smart hotel. Users could migrate the\nwhole authentication of smart devices into a new site by simply inserting the\nuniversal cryptographic token into the secure gateway and authorizing by\npressing the user-presence button on the token. Besides, the relevant unbinding\nprocess could also be done with a single cryptographic operation signed by the\ncryptographic token.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 04:01:44 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Kang", "Wang", ""]]}, {"id": "1906.06026", "submitter": "Shashank Kotyan", "authors": "Shashank Kotyan, Danilo Vasconcellos Vargas", "title": "Adversarial Robustness Assessment: Why both $L_0$ and $L_\\infty$ Attacks\n  Are Necessary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There exists a vast number of adversarial attacks and defences for machine\nlearning algorithms of various types which makes assessing the robustness of\nalgorithms a daunting task. To make matters worse, there is an intrinsic bias\nin these adversarial algorithms. Here, we organise the problems faced: a) Model\nDependence, b) Insufficient Evaluation, c) False Adversarial Samples, and d)\nPerturbation Dependent Results). Based on this, we propose a model agnostic\ndual quality assessment method, together with the concept of robustness levels\nto tackle them. We validate the dual quality assessment on state-of-the-art\nneural networks (WideResNet, ResNet, AllConv, DenseNet, NIN, LeNet and CapsNet)\nas well as adversarial defences for image classification problem. We further\nshow that current networks and defences are vulnerable at all levels of\nrobustness. The proposed robustness assessment reveals that depending on the\nmetric used (i.e., $L_0$ or $L_\\infty$), the robustness may vary significantly.\nHence, the duality should be taken into account for a correct evaluation.\nMoreover, a mathematical derivation, as well as a counter-example, suggest that\n$L_1$ and $L_2$ metrics alone are not sufficient to avoid spurious adversarial\nsamples. Interestingly, the threshold attack of the proposed assessment is a\nnovel $L_\\infty$ black-box adversarial method which requires even less\nperturbation than the One-Pixel Attack (only $12\\%$ of One-Pixel Attack's\namount of perturbation) to achieve similar results.\n  Code is available at http://bit.ly/DualQualityAssessment.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 05:11:12 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 08:30:06 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 13:44:38 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Kotyan", "Shashank", ""], ["Vargas", "Danilo Vasconcellos", ""]]}, {"id": "1906.06037", "submitter": "Kensuke Ito", "authors": "Makiko Mita, Kensuke Ito, Shohei Ohsawa, Hideyuki Tanaka", "title": "What is Stablecoin?: A Survey on Its Mechanism and Potential as\n  Decentralized Payment Systems", "comments": "15 pages, IIAI AAI 2019 accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Our study provides a survey on how existing stablecoins-- cryptocurrencies\naiming at price stabilization-- peg their value to other assets, from the\nperspective of Decentralized Payment Systems (DPSs). This attempt is important\nbecause there has been no preceding surveys focusing on the stablecoin as DPSs,\ni.e., the one aiming at not only price stabilization but also decentralization.\nSpecifically, we first classified existing stablecoins into four types\naccording to their collaterals (fiat, commodity, crypto, and\nnon-collateralized) and pointed out the high potential of non-collateralized\nstablecoins as DPSs; then, we further classified existing non-collateralized\nstablecoins into two types according to their intervention layers (protocol,\napplication) and confirmed details of their representative mechanisms.\nUtilizing concepts such as Quantity Theory of Money (QTM), Tobin tax, and\nspeculative attack, our survey revealed the status quo where, despite the high\npotential of non-collateralized stablecoins, they have no standard mechanism to\nachieve the stablecoin for practical DPSs.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 06:07:48 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 07:40:24 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Mita", "Makiko", ""], ["Ito", "Kensuke", ""], ["Ohsawa", "Shohei", ""], ["Tanaka", "Hideyuki", ""]]}, {"id": "1906.06046", "submitter": "Ziqi Yang", "authors": "Ziqi Yang, Hung Dang, Ee-Chien Chang", "title": "Effectiveness of Distillation Attack and Countermeasure on Neural\n  Network Watermarking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of machine learning as a service and model sharing platforms has\nraised the need of traitor-tracing the models and proof of authorship.\nWatermarking technique is the main component of existing methods for protecting\ncopyright of models. In this paper, we show that distillation, a widely used\ntransformation technique, is a quite effective attack to remove watermark\nembedded by existing algorithms. The fragility is due to the fact that\ndistillation does not retain the watermark embedded in the model that is\nredundant and independent to the main learning task. We design ingrain in\nresponse to the destructive distillation. It regularizes a neural network with\nan ingrainer model, which contains the watermark, and forces the model to also\nrepresent the knowledge of the ingrainer. Our extensive evaluations show that\ningrain is more robust to distillation attack and its robustness against other\nwidely used transformation techniques is comparable to existing methods.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 06:46:32 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Yang", "Ziqi", ""], ["Dang", "Hung", ""], ["Chang", "Ee-Chien", ""]]}, {"id": "1906.06086", "submitter": "Thomas Brunner", "authors": "Thomas Brunner, Frederik Diehl, Alois Knoll", "title": "Copy and Paste: A Simple But Effective Initialization Method for\n  Black-Box Adversarial Attacks", "comments": "Presented at CVPR 2019 Workshop on Adversarial Machine Learning in\n  Real-World Computer Vision Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many optimization methods for generating black-box adversarial examples have\nbeen proposed, but the aspect of initializing said optimizers has not been\nconsidered in much detail. We show that the choice of starting points is indeed\ncrucial, and that the performance of state-of-the-art attacks depends on it.\nFirst, we discuss desirable properties of starting points for attacking image\nclassifiers, and how they can be chosen to increase query efficiency. Notably,\nwe find that simply copying small patches from other images is a valid\nstrategy. We then present an evaluation on ImageNet that clearly demonstrates\nthe effectiveness of this method: Our initialization scheme reduces the number\nof queries required for a state-of-the-art Boundary Attack by 81%,\nsignificantly outperforming previous results reported for targeted black-box\nadversarial examples.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 09:17:19 GMT"}, {"version": "v2", "created": "Sun, 29 Dec 2019 16:58:39 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Brunner", "Thomas", ""], ["Diehl", "Frederik", ""], ["Knoll", "Alois", ""]]}, {"id": "1906.06262", "submitter": "Lee Friedman", "authors": "Lee Friedman, Hal S. Stern and Oleg V. Komogortsev", "title": "The Linear Relationship between Temporal Persistence, Number of\n  Independent Features and Target EER", "comments": "4 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  If you have a target level of biometric performance (e.g. EER = 5% or 0.1%),\nhow many units of unique information (uncorrelated features) are needed to\nachieve that target? We show, for normally distributed features, that the\nanswer to that question depends on the temporal persistence of the feature set.\nWe address these questions with synthetic features introduced in a prior\nreport. We measure temporal persistence with an intraclass correlation\ncoefficient (ICC). For 5 separate EER targets (5.0%, 2.0%, 1.0%, 0.5% and 0.1%)\nwe provide linear relationships between the temporal persistence of the feature\nset and the log10(number of features). These linear relationships will help\nthose in the planning stage, prior to setting up a new biometric system,\ndetermine the required temporal persistence and number of independent features\nneeded to achieve certain EER targets.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 16:00:37 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Friedman", "Lee", ""], ["Stern", "Hal S.", ""], ["Komogortsev", "Oleg V.", ""]]}, {"id": "1906.06272", "submitter": "Lee Friedman", "authors": "Lee Friedman, Hal S Stern, Vladyslav Prokopenko, Shagen Djanian, Henry\n  K. Griffith, Oleg V. Komogortsev", "title": "Biometric Performance as a Function of Gallery Size", "comments": "19 pages, 9 Figures, 0 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Many developers of biometric systems start with modest samples before general\ndeployment. They are interested in how their systems will work with much larger\nsamples. We evaluated the effect of gallery size on biometric performance.\nIdentification rates describe the performance of biometric identification,\nwhereas ROC-based measures describe the performance of biometric authentication\n(verification). Therefore, we examined how increases in gallery size affected\nidentification rates (i.e., Rank-1 Identification Rate, or Rank-1 IR) and\nROC-based measures such as equal error rate (EER). We studied these phenomena\nwith synthetic data as well as real data from a face recognition study. It is\nwell known that the Rank-1 IR declines with increasing gallery size. We have\nprovided further insight into this decline. We have shown that this\nrelationship is linear in log(Gallery Size). We have also shown that this\ndecline can be counteracted with the inclusion of additional information\n(features) for larger gallery sizes. We have also described the curves which\ncan be used to predict how much additional information is required to stabilize\nthe Rank-1 IR as a function of gallery size. These equations are also linear in\nlog(gallery size). We have also shown that the entire ROC curve is not\nsystematically affected by gallery size, and so ROC-based scalar performance\nmetrics such as EER are also stable across gallery size.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 16:20:48 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 21:35:17 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Friedman", "Lee", ""], ["Stern", "Hal S", ""], ["Prokopenko", "Vladyslav", ""], ["Djanian", "Shagen", ""], ["Griffith", "Henry K.", ""], ["Komogortsev", "Oleg V.", ""]]}, {"id": "1906.06316", "submitter": "Huan Zhang", "authors": "Huan Zhang, Hongge Chen, Chaowei Xiao, Sven Gowal, Robert Stanforth,\n  Bo Li, Duane Boning, Cho-Jui Hsieh", "title": "Towards Stable and Efficient Training of Verifiably Robust Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training neural networks with verifiable robustness guarantees is\nchallenging. Several existing approaches utilize linear relaxation based neural\nnetwork output bounds under perturbation, but they can slow down training by a\nfactor of hundreds depending on the underlying network architectures.\nMeanwhile, interval bound propagation (IBP) based training is efficient and\nsignificantly outperforms linear relaxation based methods on many tasks, yet it\nmay suffer from stability issues since the bounds are much looser especially at\nthe beginning of training. In this paper, we propose a new certified\nadversarial training method, CROWN-IBP, by combining the fast IBP bounds in a\nforward bounding pass and a tight linear relaxation based bound, CROWN, in a\nbackward bounding pass. CROWN-IBP is computationally efficient and consistently\noutperforms IBP baselines on training verifiably robust neural networks. We\nconduct large scale experiments on MNIST and CIFAR datasets, and outperform all\nprevious linear relaxation and bound propagation based certified defenses in\n$\\ell_\\infty$ robustness. Notably, we achieve 7.02% verified test error on\nMNIST at $\\epsilon=0.3$, and 66.94% on CIFAR-10 with $\\epsilon=8/255$. Code is\navailable at https://github.com/deepmind/interval-bound-propagation\n(TensorFlow) and https://github.com/huanzhang12/CROWN-IBP (PyTorch).\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 17:44:40 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 11:03:27 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Zhang", "Huan", ""], ["Chen", "Hongge", ""], ["Xiao", "Chaowei", ""], ["Gowal", "Sven", ""], ["Stanforth", "Robert", ""], ["Li", "Bo", ""], ["Boning", "Duane", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1906.06427", "submitter": "Francisco Messina", "authors": "Mohammadhadi Shateri, Francisco Messina, Pablo Piantanida, Fabrice\n  Labeau", "title": "Real-Time Privacy-Preserving Data Release for Smart Meters", "comments": "Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CR cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart Meters (SMs) are a fundamental component of smart grids, but they carry\nsensitive information about users such as occupancy status of houses and\ntherefore, they have raised serious concerns about leakage of consumers'\nprivate information. In particular, we focus on real-time privacy threats,\ni.e., potential attackers that try to infer sensitive data from SMs reported\ndata in an online fashion. We adopt an information-theoretic privacy measure\nand show that it effectively limits the performance of any real-time attacker.\nUsing this privacy measure, we propose a general formulation to design a\nprivatization mechanism that can provide a target level of privacy by adding a\nminimal amount of distortion to the SMs measurements. On the other hand, to\ncope with different applications, a flexible distortion measure is considered.\nThis formulation leads to a general loss function, which is optimized using a\ndeep learning adversarial framework, where two neural networks $-$ referred to\nas the releaser and the adversary $-$ are trained with opposite goals. An\nexhaustive empirical study is then performed to validate the performances of\nthe proposed approach for the occupancy detection privacy problem, assuming the\nattacker disposes of either limited or full access to the training dataset.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 22:57:20 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 23:51:57 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Shateri", "Mohammadhadi", ""], ["Messina", "Francisco", ""], ["Piantanida", "Pablo", ""], ["Labeau", "Fabrice", ""]]}, {"id": "1906.06475", "submitter": "Jonathan Pan", "authors": "Jonathan Pan", "title": "Physical Integrity Attack Detection of Surveillance Camera with Deep\n  Learning Based Video Frame Interpolation", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surveillance cameras, which is a form of Cyber Physical System, are deployed\nextensively to provide visual surveillance monitoring of activities of interest\nor anomalies. However, these cameras are at risks of physical security attacks\nagainst their physical attributes or configuration like tampering of their\nrecording coverage, camera positions or recording configurations like focus and\nzoom factors. Such adversarial alteration of physical configuration could also\nbe invoked through cyber security attacks against the camera's software\nvulnerabilities to administratively change the camera's physical configuration\nsettings. When such Cyber Physical attacks occur, they affect the integrity of\nthe targeted cameras that would in turn render these cameras ineffective in\nfulfilling the intended security functions. There is a significant measure of\nresearch work in detection mechanisms of cyber-attacks against these Cyber\nPhysical devices, however it is understudied area with such mechanisms against\nintegrity attacks on physical configuration. This research proposes the use of\nthe novel use of deep learning algorithms to detect such physical attacks\noriginating from cyber or physical spaces. Additionally, we proposed the novel\nuse of deep learning-based video frame interpolation for such detection that\nhas comparatively better performance to other anomaly detectors in\nspatiotemporal environments.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 05:48:29 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Pan", "Jonathan", ""]]}, {"id": "1906.06490", "submitter": "Fangyu Gai", "authors": "Fangyu Gai, Cesar Grajales, Jianyu Niu, Mohammad Mussadiq Jalalzai,\n  and Chen Feng", "title": "A Secure Consensus Protocol for Sidechains", "comments": "17 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sidechain technology has been envisioned as a promising solution to\naccelerate today's public blockchains in terms of scalability and\ninteroperability. By relying on the mainchain for security, different\nsidechains can formulate their own rules to reach consensus. Although the\nliterature has considered the possibility of using consensus protocols in the\nsidechain, so far a tailor-made consensus protocol for sidechains with high\nperformance and formal security proof has not been attempted. To fill this gap,\nwe introduce Cumulus, a low overhead, highly efficient, security provable\nsidechain protocol. Cumulus makes use of smart contracts to ensure that only\none block proposed in the sidechain will be enforced on the mainchain in each\nround, thereby achieving consensus in an efficient manner. We give a formal\nspecification of Cumulus which ensures safety and liveness without any online\nrequirements of clients. For security analysis, we provide formal security\ndefinitions and proofs under Universally Composable Security (UCS) model. As a\nproof of concept, we implement Cumulus and evaluate it in an Ethereum testnet.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 07:48:31 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 00:42:08 GMT"}, {"version": "v3", "created": "Sat, 16 Nov 2019 01:31:29 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Gai", "Fangyu", ""], ["Grajales", "Cesar", ""], ["Niu", "Jianyu", ""], ["Jalalzai", "Mohammad Mussadiq", ""], ["Feng", "Chen", ""]]}, {"id": "1906.06500", "submitter": "Donghui Ding", "authors": "Donghui Ding, Xin Jiang, Jiaping Wang, Hao Wang, Xiaobing Zhang, Yi\n  Sun", "title": "Txilm: Lossy Block Compression with Salted Short Hashing", "comments": "5 pages and 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current blockchains are restricted by the low throughput. Aimed at this\nproblem, we propose Txilm, a protocol that compresses the size of transaction\npresentation in each block to save the bandwidth of the network. In this\nprotocol, a block carries short hashes of TXIDs instead of complete\ntransactions. Combined with the sorted transactions based on TXIDs, Txilm\nrealizes 80 times of data size reduction compared with the original\nblockchains. We also evaluate the probability of hash collisions, and provide\nmethods of resolving such collisions. Finally, we design strategies to protect\nagainst potential attacks on Txilm.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 08:53:48 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Ding", "Donghui", ""], ["Jiang", "Xin", ""], ["Wang", "Jiaping", ""], ["Wang", "Hao", ""], ["Zhang", "Xiaobing", ""], ["Sun", "Yi", ""]]}, {"id": "1906.06505", "submitter": "Eman Alashwali", "authors": "Eman Salem Alashwali and Pawel Szalachowski and Andrew Martin", "title": "Does \"www.\" Mean Better Transport Layer Security?", "comments": "update metadata abstract from Latex text to normal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experience shows that most researchers and developers tend to treat\nplain-domains (those that are not prefixed with \"www\" sub-domains, e.g.\n\"example.com\") as synonyms for their equivalent www-domains (those that are\nprefixed with \"www\" sub-domains, e.g. \"www.example.com\"). In this paper, we\nanalyse datasets of nearly two million plain-domains against their equivalent\nwww-domains to answer the following question: Do plain-domains and their\nequivalent www-domains differ in TLS security configurations and certificates?\nIf so, to what extent? Our results provide evidence of an interesting\nphenomenon: plain-domains and their equivalent www-domains differ in TLS\nsecurity configurations and certificates in a non-trivial number of cases.\nFurthermore, www-domains tend to have stronger security configurations than\ntheir equivalent plain-domains. Interestingly, this phenomenon is more\nprevalent in the most-visited domains than in randomly-chosen domains. Further\nanalysis of the top domains dataset shows that 53.35% of the plain-domains that\nshow one or more weakness indicators (e.g. expired certificate) that are not\nshown in their equivalent www-domains perform HTTPS redirection from HTTPS\nplain-domains to their equivalent HTTPS www-domains. Additionally, 24.71% of\nthese redirections contains plain-text HTTP intermediate URLs. In these cases,\nusers see the final www-domains with strong TLS configurations and\ncertificates, but in fact, the HTTPS request has passed through plain-domains\nthat have less secure TLS configurations and certificates. Clearly, such a\nset-up introduces a weak link in the security of the overall interaction.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 09:15:32 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 05:28:04 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Alashwali", "Eman Salem", ""], ["Szalachowski", "Pawel", ""], ["Martin", "Andrew", ""]]}, {"id": "1906.06517", "submitter": "Gautam Srivastava", "authors": "Ashutosh Dhar Dwivedi, Lukas Malina, Petr Dzurenda, Gautam Srivastava", "title": "Optimized Blockchain Model for Internet of Things based Healthcare\n  Applications", "comments": "5 pages, 5 figures. arXiv admin note: text overlap with\n  arXiv:1806.00555 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There continues to be a recent push to taking the cryptocurrency based ledger\nsystem known as Blockchain and applying its techniques to non-financial\napplications. One of the main areas for application remains Internet of Things\n(IoT) as we see many areas of improvement as we move into an age of smart\ncities. In this paper, we examine an initial look at applying the key aspects\nof Blockchain to a health application network where patients health data can be\nused to create alerts important to authenticated healthcare providers in a\nsecure and private manner. This paper also presents the benefits and also\npractical obstacles of the blockchain-based security approaches in IoT.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 10:16:50 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Dwivedi", "Ashutosh Dhar", ""], ["Malina", "Lukas", ""], ["Dzurenda", "Petr", ""], ["Srivastava", "Gautam", ""]]}, {"id": "1906.06540", "submitter": "Stefanos Leonardos Mr.", "authors": "Stefanos Leonardos, Daniel Reijsbergen and Georgios Piliouras", "title": "PREStO: A Systematic Framework for Blockchain Consensus Protocols", "comments": "[Best Paper Award] IEEE-TEM (2020)", "journal-ref": "IEEE Transactions on Engineering Management, vol. 67(4),\n  pp.:1028-1044, (2020)", "doi": "10.1109/TEM.2020.2981286", "report-no": null, "categories": "cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid evolution of blockchain technology has brought together\nstakeholders from fundamentally different backgrounds. The result is a diverse\necosystem, as exemplified by the development of a wide range of different\nblockchain protocols. This raises questions for decision and policy makers: How\ndo different protocols compare? What are their trade-offs? Existing efforts to\nsurvey the area reveal a fragmented terminology and the lack of a unified\nframework to reason about the properties of blockchain protocols. In this\npaper, we work towards bridging this gap. We present a five-dimensional design\nspace with a modular structure in which protocols can be compared and\nunderstood. Based on these five axes -- Optimality, Stability, Efficiency,\nRobustness and Persistence -- we organize the properties of existing protocols\nin subcategories of increasing granularity. The result is a dynamic scheme --\ntermed the PREStO framework -- which aids the interaction between stakeholders\nof different backgrounds, including managers and investors, and which enables\nsystematic reasoning about blockchain protocols. We illustrate its value by\ncomparing existing protocols and identifying research challenges, hence making\na first step towards understanding the blockchain ecosystem through a more\ncomprehensive lens.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 12:09:18 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 10:03:14 GMT"}, {"version": "v3", "created": "Sun, 18 Jul 2021 13:16:43 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Leonardos", "Stefanos", ""], ["Reijsbergen", "Daniel", ""], ["Piliouras", "Georgios", ""]]}, {"id": "1906.06567", "submitter": "Sankarshan Damle", "authors": "Sankarshan Damle, Boi Faltings, and Sujit Gujar", "title": "A Practical Solution to Yao's Millionaires' Problem and Its Application\n  in Designing Secure Combinatorial Auction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of e-commerce and e-voting platforms has resulted in the rise\nin the volume of sensitive information over the Internet. This has resulted in\nan increased demand for secure and private means of information computation.\nTowards this, the Yao's Millionaires' problem, i.e., to determine the richer\namong two millionaires' securely, finds an application. In this work, we\npresent a new solution to the Yao's Millionaires' problem namely, Privacy\nPreserving Comparison (PPC). We show that PPC achieves this comparison in\nconstant time as well as in one execution. PPC uses semi-honest third parties\nfor the comparison who do not learn any information about the values. Further,\nwe show that PPC is collusion-resistance. To demonstrate the significance of\nPPC, we present a secure, approximate single-minded combinatorial auction,\nwhich we call TPACAS, i.e., Truthful, Privacy-preserving Approximate\nCombinatorial Auction for Single-minded bidders. We show that TPACAS, unlike\nprevious works, preserves the following privacies relevant to an auction: agent\nprivacy, the identities of the losing bidders must not be revealed to any other\nagent except the auctioneer (AU), bid privacy, the bid values must be hidden\nfrom the other agents as well as the AU and bid-topology privacy, the items for\nwhich the agents are bidding must be hidden from the other agents as well as\nthe AU. We demonstrate the practicality of TPACAS through simulations. Lastly,\nwe also look at TPACAS' implementation over a publicly distributed ledger, such\nas the Ethereum blockchain.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 14:17:20 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Damle", "Sankarshan", ""], ["Faltings", "Boi", ""], ["Gujar", "Sujit", ""]]}, {"id": "1906.06653", "submitter": "Shijun Zhao", "authors": "Qianying Zhang, Shijun Zhao", "title": "A Comprehensive Formal Security Analysis and Revision of the Two-phase\n  Key Exchange Primitive of TPM 2.0", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Trusted Platform Module (TPM) version 2.0 provides a two-phase key\nexchange primitive which can be used to implement three widely-standardized\nauthenticated key exchange protocols: the Full Unified Model, the Full MQV, and\nthe SM2 key exchange protocols. However, vulnerabilities have been found in all\nof these protocols. Fortunately, it seems that the protections offered by TPM\nchips can mitigate these vulnerabilities. In this paper, we present a security\nmodel which captures TPM's protections on keys and protocols' computation\nenvironments and in which multiple protocols can be analyzed in a unified way.\nBased on the unified security model, we give the first formal security analysis\nof the key exchange primitive of TPM 2.0, and the analysis results show that,\nwith the help of hardware protections of TPM chips, the key exchange primitive\nindeed satisfies the well-defined security property of our security model, but\nunfortunately under some impractical limiting conditions, which would prevent\nthe application of the key exchange primitive in real-world networks. To make\nTPM 2.0 applicable to real-world networks, we present a revision of the key\nexchange primitive of TPM 2.0, which can be secure without the limiting\nconditions. We give a rigorous analysis of our revision, and the results show\nthat our revision achieves not only the basic security property of modern AKE\nsecurity models but also some further security properties.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 06:27:09 GMT"}, {"version": "v2", "created": "Sat, 4 Jul 2020 12:03:04 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Zhang", "Qianying", ""], ["Zhao", "Shijun", ""]]}, {"id": "1906.06765", "submitter": "Yifan Ding", "authors": "Yifan Ding, Liqiang Wang, Huan Zhang, Jinfeng Yi, Deliang Fan and\n  Boqing Gong", "title": "Defending Against Adversarial Attacks Using Random Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As deep neural networks (DNNs) have become increasingly important and\npopular, the robustness of DNNs is the key to the safety of both the Internet\nand the physical world. Unfortunately, some recent studies show that\nadversarial examples, which are hard to be distinguished from real examples,\ncan easily fool DNNs and manipulate their predictions. Upon observing that\nadversarial examples are mostly generated by gradient-based methods, in this\npaper, we first propose to use a simple yet very effective non-differentiable\nhybrid model that combines DNNs and random forests, rather than hide gradients\nfrom attackers, to defend against the attacks. Our experiments show that our\nmodel can successfully and completely defend the white-box attacks, has a lower\ntransferability, and is quite resistant to three representative types of\nblack-box attacks; while at the same time, our model achieves similar\nclassification accuracy as the original DNNs. Finally, we investigate and\nsuggest a criterion to define where to grow random forests in DNNs.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 20:46:44 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Ding", "Yifan", ""], ["Wang", "Liqiang", ""], ["Zhang", "Huan", ""], ["Yi", "Jinfeng", ""], ["Fan", "Deliang", ""], ["Gong", "Boqing", ""]]}, {"id": "1906.06912", "submitter": "Riccardo Longo", "authors": "Riccardo Longo and Massimiliano Sala", "title": "Public Ledger for Sensitive Data", "comments": "21 pages Second version with extended explanations, construction and\n  proofs updated and generalised to asymmetric pairings, compatible with the\n  more secure and efficient type-3 pairings, simplified and streamlined\n  construction of the static ledger", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Satoshi Nakamoto's Blockchain allows to build publicly verifiable and almost\nimmutable ledgers, but sometimes privacy has to be factored in.\n  In this work an original protocol is presented that allows sensitive data to\nbe stored on a ledger where its integrity may be publicly verified, but its\nprivacy is preserved and owners can tightly manage the sharing of their\ninformation with efficient revocation.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 09:25:19 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 13:55:13 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Longo", "Riccardo", ""], ["Sala", "Massimiliano", ""]]}, {"id": "1906.06919", "submitter": "Shuyu Cheng", "authors": "Shuyu Cheng, Yinpeng Dong, Tianyu Pang, Hang Su, Jun Zhu", "title": "Improving Black-box Adversarial Attacks with a Transfer-based Prior", "comments": "NeurIPS 2019; Code available at\n  https://github.com/thu-ml/Prior-Guided-RGF", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the black-box adversarial setting, where the adversary has to\ngenerate adversarial perturbations without access to the target models to\ncompute gradients. Previous methods tried to approximate the gradient either by\nusing a transfer gradient of a surrogate white-box model, or based on the query\nfeedback. However, these methods often suffer from low attack success rates or\npoor query efficiency since it is non-trivial to estimate the gradient in a\nhigh-dimensional space with limited information. To address these problems, we\npropose a prior-guided random gradient-free (P-RGF) method to improve black-box\nadversarial attacks, which takes the advantage of a transfer-based prior and\nthe query information simultaneously. The transfer-based prior given by the\ngradient of a surrogate model is appropriately integrated into our algorithm by\nan optimal coefficient derived by a theoretical analysis. Extensive experiments\ndemonstrate that our method requires much fewer queries to attack black-box\nmodels with higher success rates compared with the alternative state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 09:40:32 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 07:56:53 GMT"}, {"version": "v3", "created": "Sun, 26 Jul 2020 14:00:51 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Cheng", "Shuyu", ""], ["Dong", "Yinpeng", ""], ["Pang", "Tianyu", ""], ["Su", "Hang", ""], ["Zhu", "Jun", ""]]}, {"id": "1906.06921", "submitter": "Md. Helal Ahmed", "authors": "Md. Helal Ahmed, Jagmohan Tanti, Sumant Pushp", "title": "A Public-Key Cryptosystem Using Cyclotomic Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Confidentiality and Integrity are two paramount objectives in the evaluation\nof information and communication technology. In this paper, we propose an\narithmetic approach for designing asymmetric key cryptography. Our method is\nbased on the formulation of cyclotomic matrices correspond to the diophantine\nsystem. The proposed cyclotomic asymmetric cryptosystem (CAC) utilizes the\ncyclotomic matrices, whose entries are cyclotomic numbers of order $2l^{2}$,\n$l$ be prime over a finite field $\\mathbb{F}_{p}$ of $p$ elements. The method\nutilize cyclotomic matrices to design a one-way function. The outcome of a\none-way function that is efficient to compute however difficult to compute its\ninverse unless if secret data about the trapdoor is known. We demonstrate that\nthe encryption and decryption can be efficiently performed with asymptotic\ncomplexity of $\\mathcal{O}(e^{2.373})$. Besides, we study the computational\ncomplexity of the CAC.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 09:44:15 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 07:36:15 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Ahmed", "Md. Helal", ""], ["Tanti", "Jagmohan", ""], ["Pushp", "Sumant", ""]]}, {"id": "1906.06940", "submitter": "James Cheney", "authors": "Ghita Berrada, Sidahmed Benabderrahmane, James Cheney, William\n  Maxwell, Himan Mookherjee, Alec Theriault, and Ryan Wright", "title": "A baseline for unsupervised advanced persistent threat detection in\n  system-level provenance", "comments": null, "journal-ref": "Future Generation Computer Systems 108 (2020) 401-413", "doi": "10.1016/j.future.2020.02.015", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced persistent threats (APT) are stealthy, sophisticated, and\nunpredictable cyberattacks that can steal intellectual property, damage\ncritical infrastructure, or cause millions of dollars in damage. Detecting APTs\nby monitoring system-level activity is difficult because manually inspecting\nthe high volume of normal system activity is overwhelming for security\nanalysts. We evaluate the effectiveness of unsupervised batch and streaming\nanomaly detection algorithms over multiple gigabytes of provenance traces\nrecorded on four different operating systems to determine whether they can\ndetect realistic APT-like attacks reliably and efficiently. This report is the\nfirst detailed study of the effectiveness of generic unsupervised anomaly\ndetection techniques in this setting.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 10:49:28 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 13:56:43 GMT"}, {"version": "v3", "created": "Mon, 23 Sep 2019 13:11:09 GMT"}, {"version": "v4", "created": "Mon, 18 Nov 2019 10:43:30 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Berrada", "Ghita", ""], ["Benabderrahmane", "Sidahmed", ""], ["Cheney", "James", ""], ["Maxwell", "William", ""], ["Mookherjee", "Himan", ""], ["Theriault", "Alec", ""], ["Wright", "Ryan", ""]]}, {"id": "1906.06968", "submitter": "Vijayalakshmi Janakiraman", "authors": "Rashmi Jain, Dinah Samuel Anand, Vijayalakshmi Janakiraman", "title": "Scrubbing Sensitive PHI Data from Medical Records made Easy by SpaCy --\n  A Scalable Model Implementation Comparisons", "comments": "9 Pages, 7 Figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  De-identification of clinical records is an extremely important process which\nenables the use of the wealth of information present in them. There are a lot\nof techniques available for this but none of the method implementation has\nevaluated the scalability, which is an important benchmark. We evaluated\nnumerous deep learning techniques such as BiLSTM-CNN, IDCNN, CRF, BiLSTM-CRF,\nSpaCy, etc. on both the performance and efficiency. We propose that the SpaCy\nmodel implementation for scrubbing sensitive PHI data from medical records is\nboth well performing and extremely efficient compared to other published\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 11:42:22 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Jain", "Rashmi", ""], ["Anand", "Dinah Samuel", ""], ["Janakiraman", "Vijayalakshmi", ""]]}, {"id": "1906.06996", "submitter": "Renjie Lu", "authors": "Renjie Lu, Haihua Shen, Feng Zhang, Huawei Li, Wei Zhao, and Xiaowei\n  Li", "title": "HTDet: A Clustering Method using Information Entropy for Hardware Trojan\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware Trojans (HTs) have drawn more and more attention in both academia\nand industry because of its significant potential threat. In this paper, we\nproposed a novel HT detection method using information entropy based\nclustering, named HTDet. The key insight of HTDet is that the Trojan usually be\ninserted in the regions with low controllability and low observability in order\nto maintain high concealment, which will result in that Trojan logics appear\nextremely low transitions during the simulation. This means that the logical\nregions with the low transitions will provide us with much more abundant and\nmore important information for HT detection. Therefore, HTDet applies\ninformation theory technology and a typical density-based clustering algorithm\ncalled Density-Based Spatial Clustering of Applications with Noise (DBSCAN) to\ndetect all suspicious Trojan logics in circuit under detection (CUD). DBSCAN is\nan unsupervised learning algorithm, which can improve the applicability of\nHTDet. Besides, we develop a heuristic test patterns generation method using\nmutual information to increase the transitions of suspicious Trojan logics.\nExperimental evaluation with benchmarks demenstrates the effectiveness of\nHTDet.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 11:02:56 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Lu", "Renjie", ""], ["Shen", "Haihua", ""], ["Zhang", "Feng", ""], ["Li", "Huawei", ""], ["Zhao", "Wei", ""], ["Li", "Xiaowei", ""]]}, {"id": "1906.07072", "submitter": "Carlos Segarra", "authors": "Carlos Segarra and Ricard Delgado-Gonzalo and Mathieu Lemay and\n  Pierre-Louis Aublin and Peter Pietzuch and Valerio Schiavoni", "title": "Using Trusted Execution Environments for Secure Stream Processing of\n  Medical Data", "comments": "19th International Conference on Distributed Applications and\n  Interoperable Systems", "journal-ref": "In: Pereira J., Ricci L. (eds) Distributed Applications and\n  Interoperable Systems. DAIS 2019. Pages 91-107. Lecture Notes in Computer\n  Science, vol 11534. Springer, Cham", "doi": "10.1007/978-3-030-22496-7_6", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Processing sensitive data, such as those produced by body sensors, on\nthird-party untrusted clouds is particularly challenging without compromising\nthe privacy of the users generating it. Typically, these sensors generate large\nquantities of continuous data in a streaming fashion. Such vast amount of data\nmust be processed efficiently and securely, even under strong adversarial\nmodels. The recent introduction in the mass-market of consumer-grade processors\nwith Trusted Execution Environments (TEEs), such as Intel SGX, paves the way to\nimplement solutions that overcome less flexible approaches, such as those atop\nhomomorphic encryption. We present a secure streaming processing system built\non top of Intel SGX to showcase the viability of this approach with a system\nspecifically fitted for medical data. We design and fully implement a prototype\nsystem that we evaluate with several realistic datasets. Our experimental\nresults show that the proposed system achieves modest overhead compared to\nvanilla Spark while offering additional protection guarantees under powerful\nattackers and threat models.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 14:59:57 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Segarra", "Carlos", ""], ["Delgado-Gonzalo", "Ricard", ""], ["Lemay", "Mathieu", ""], ["Aublin", "Pierre-Louis", ""], ["Pietzuch", "Peter", ""], ["Schiavoni", "Valerio", ""]]}, {"id": "1906.07077", "submitter": "Felix Assion", "authors": "Felix Assion, Peter Schlicht, Florens Gre{\\ss}ner, Wiebke G\\\"unther,\n  Fabian H\\\"uger, Nico Schmidt, Umair Rasheed", "title": "The Attack Generator: A Systematic Approach Towards Constructing\n  Adversarial Attacks", "comments": "CVPR SAIAD - Workshop 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most state-of-the-art machine learning (ML) classification systems are\nvulnerable to adversarial perturbations. As a consequence, adversarial\nrobustness poses a significant challenge for the deployment of ML-based systems\nin safety- and security-critical environments like autonomous driving, disease\ndetection or unmanned aerial vehicles. In the past years we have seen an\nimpressive amount of publications presenting more and more new adversarial\nattacks. However, the attack research seems to be rather unstructured and new\nattacks often appear to be random selections from the unlimited set of possible\nadversarial attacks. With this publication, we present a structured analysis of\nthe adversarial attack creation process. By detecting different building blocks\nof adversarial attacks, we outline the road to new sets of adversarial attacks.\nWe call this the \"attack generator\". In the pursuit of this objective, we\nsummarize and extend existing adversarial perturbation taxonomies. The\nresulting taxonomy is then linked to the application context of computer vision\nsystems for autonomous vehicles, i.e. semantic segmentation and object\ndetection. Finally, in order to prove the usefulness of the attack generator,\nwe investigate existing semantic segmentation attacks with respect to the\ndetected defining components of adversarial attacks.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 15:06:47 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Assion", "Felix", ""], ["Schlicht", "Peter", ""], ["Gre\u00dfner", "Florens", ""], ["G\u00fcnther", "Wiebke", ""], ["H\u00fcger", "Fabian", ""], ["Schmidt", "Nico", ""], ["Rasheed", "Umair", ""]]}, {"id": "1906.07104", "submitter": "Sawood Alam", "authors": "Sawood Alam, Michele C. Weigle, Michael L. Nelson, Martin Klein, and\n  Herbert Van de Sompel", "title": "Supporting Web Archiving via Web Packaging", "comments": "This is a position paper accepted at the ESCAPE Workshop 2019.\n  https://www.iab.org/activities/workshops/escape-workshop/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.CY cs.DL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We describe challenges related to web archiving, replaying archived web\nresources, and verifying their authenticity. We show that Web Packaging has\nsignificant potential to help address these challenges and identify areas in\nwhich changes are needed in order to fully realize that potential.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 16:12:46 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Alam", "Sawood", ""], ["Weigle", "Michele C.", ""], ["Nelson", "Michael L.", ""], ["Klein", "Martin", ""], ["Van de Sompel", "Herbert", ""]]}, {"id": "1906.07127", "submitter": "Zhiniang Peng", "authors": "Zhiniang Peng", "title": "Danger of using fully homomorphic encryption: A look at Microsoft SEAL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully homomorphic encryption is a promising crypto primitive to encrypt your\ndata while allowing others to compute on the encrypted data. But there are many\nwell-known problems with fully homomorphic encryption such as CCA security and\ncircuit privacy problem. Despite these problems, there are still many companies\nare currently using or preparing to use fully homomorphic encryption to build\ndata security applications. It seems that the full homomorphic encryption is\nvery close to practicality and these problems can be easily mitigated in\nimplementation. Although the those problems are well known in theory, there is\nno public discussion of their actual impact on real application. Our research\nshows that there are many security pitfalls in fully homomorphic encryption\nfrom the perspective of practical application. The security problems of a fully\nhomomorphic encryption in a real application is more severe than imagined. In\nthis paper, we will take Microsoft SEAL as an examples to introduce the\nsecurity pitfalls of fully homomorphic encryption from the perspective of\nimplementation and practical application\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 16:56:13 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Peng", "Zhiniang", ""]]}, {"id": "1906.07148", "submitter": "Marcus Comiter", "authors": "Marcus Comiter, Surat Teerapittayanon, H.T. Kung", "title": "CheckNet: Secure Inference on Untrusted Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce CheckNet, a method for secure inference with deep neural\nnetworks on untrusted devices. CheckNet is like a checksum for neural network\ninference: it verifies the integrity of the inference computation performed by\nuntrusted devices to 1) ensure the inference has actually been performed, and\n2) ensure the inference has not been manipulated by an attacker. CheckNet is\ncompletely transparent to the third party running the computation, applicable\nto all types of neural networks, does not require specialized hardware, adds\nlittle overhead, and has negligible impact on model performance. CheckNet can\nbe configured to provide different levels of security depending on application\nneeds and compute/communication budgets. We present both empirical and\ntheoretical validation of CheckNet on multiple popular deep neural network\nmodels, showing excellent attack detection (0.88-0.99 AUC) and attack success\nbounds.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 17:45:25 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Comiter", "Marcus", ""], ["Teerapittayanon", "Surat", ""], ["Kung", "H. T.", ""]]}, {"id": "1906.07153", "submitter": "Tom Goldstein", "authors": "Parsa Saadatpanah, Ali Shafahi, Tom Goldstein", "title": "Adversarial attacks on Copyright Detection Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that many machine learning models are susceptible to\nadversarial attacks, in which an attacker evades a classifier by making small\nperturbations to inputs. This paper discusses how industrial copyright\ndetection tools, which serve a central role on the web, are susceptible to\nadversarial attacks. We discuss a range of copyright detection systems, and why\nthey are particularly vulnerable to attacks. These vulnerabilities are\nespecially apparent for neural network based systems. As a proof of concept, we\ndescribe a well-known music identification method, and implement this system in\nthe form of a neural net. We then attack this system using simple gradient\nmethods. Adversarial music created this way successfully fools industrial\nsystems, including the AudioTag copyright detector and YouTube's Content ID\nsystem. Our goal is to raise awareness of the threats posed by adversarial\nexamples in this space, and to highlight the importance of hardening copyright\ndetection systems to attacks.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 17:57:04 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 17:44:20 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Saadatpanah", "Parsa", ""], ["Shafahi", "Ali", ""], ["Goldstein", "Tom", ""]]}, {"id": "1906.07175", "submitter": "Ayush Kumar", "authors": "Ayush Kumar, Teng Joon Lim", "title": "A Secure Contained Testbed for Analyzing IoT Botnets", "comments": "arXiv admin note: text overlap with arXiv:1901.04805", "journal-ref": "Proceedings of Testbeds and Research Infrastructures for the\n  Development of Networks and Communications (TRIDENTCOM) 2018", "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many security issues have come to the fore with the increasingly widespread\nadoption of Internet-of-Things (IoT) devices. The Mirai attack on Dyn DNS\nservice, in which vulnerable IoT devices such as IP cameras, DVRs and routers\nwere infected and used to propagate large-scale DDoS attacks, is one of the\nmore prominent recent examples. IoT botnets, consisting of\nhundreds-of-thousands of bots, are currently present ``in-the-wild'' at least\nand are only expected to grow in the future, with the potential to cause\nsignificant network downtimes and financial losses to network companies. We\npropose, therefore, to build testbeds for evaluating IoT botnets and design\nsuitable mitigation techniques against them. A DETERlab-based IoT botnet\ntestbed is presented in this work. The testbed is built in a secure contained\nenvironment and includes ancillary services such as DHCP, DNS as well as botnet\ninfrastructure including CnC and scanListen/loading servers. Developing an IoT\nbotnet testbed presented us with some unique challenges which are different\nfrom those encountered in non-IoT botnet testbeds and we highlight them in this\npaper. Further, we point out the important features of our testbed and\nillustrate some of its capabilities through experimental results.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 02:51:58 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Kumar", "Ayush", ""], ["Lim", "Teng Joon", ""]]}, {"id": "1906.07221", "submitter": "Maksym Petkus", "authors": "Maksym Petkus", "title": "Why and How zk-SNARK Works", "comments": "65 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DM math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the existence of multiple great resources on zk-SNARK construction,\nfrom original papers to explainers, due to the sheer number of moving parts the\nsubject remains a black box for many. While some pieces of the puzzle are given\none can not see the full picture without the missing ones. Hence the focus of\nthis work is to shed light onto the topic with a straightforward and clean\napproach based on examples and answering many whys along the way so that more\nindividuals can appreciate the state of the art technology, its innovators and\nultimately the beauty of math. Paper's contribution is a simplistic exposition\nwith a sufficient and gradually increasing level of complexity, necessary to\nunderstand zk-SNARK without any prerequisite knowledge of the subject,\ncryptography or advanced math. The primary goal is not only to explain how it\nworks but why it works and how it came to be this way.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 18:55:12 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Petkus", "Maksym", ""]]}, {"id": "1906.07242", "submitter": "Jack Whitter-Jones", "authors": "Jack Whitter-Jones and Mathew Evans", "title": "The Little Phone That Could Ch-Ch-Chroot", "comments": "Presented At BSides London 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security testing has been a career path that many are beginning to take. In\ndoing so, security testing can hit the realms of many different types of\nengagements, ranging from web, infrastructure and social engineering. With the\nrisk of sabotage, corporate espionage it has been seen that many organisations\nare beginning to develop a tactical capability. In doing so, the term 'Red\nTeam' has been coined to market such engagements. Red Teaming is the method of\nhaving almost free reign towards a target. By doing such an engagement a target\nwill be able to fully understand the breadth of vulnerabilities facing their\norganisation. However, Red Teaming can be an expensive and resource intensive\ntask. Through this paper, it is discussed that it is possible to make a covert\ndisposable phone to help aide Red Teamer's with the reconnaissance phase\nwithout drawing attention to themselves within a day to day task.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 19:50:47 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Whitter-Jones", "Jack", ""], ["Evans", "Mathew", ""]]}, {"id": "1906.07407", "submitter": "Shaosheng Cao", "authors": "Shaosheng Cao, Xinxing Yang, Cen Chen, Jun Zhou, Xiaolong Li, and Yuan\n  Qi", "title": "TitAnt: Online Real-time Transaction Fraud Detection in Ant Financial", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the explosive growth of e-commerce and the booming of e-payment,\ndetecting online transaction fraud in real time has become increasingly\nimportant to Fintech business. To tackle this problem, we introduce the TitAnt,\na transaction fraud detection system deployed in Ant Financial, one of the\nlargest Fintech companies in the world. The system is able to predict online\nreal-time transaction fraud in mere milliseconds. We present the problem\ndefinition, feature extraction, detection methods, implementation and\ndeployment of the system, as well as empirical effectiveness. Extensive\nexperiments have been conducted on large real-world transaction data to show\nthe effectiveness and the efficiency of the proposed system.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 07:05:25 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Cao", "Shaosheng", ""], ["Yang", "Xinxing", ""], ["Chen", "Cen", ""], ["Zhou", "Jun", ""], ["Li", "Xiaolong", ""], ["Qi", "Yuan", ""]]}, {"id": "1906.07460", "submitter": "Alimzhan Sultangazin", "authors": "Alimzhan Sultangazin and Paulo Tabuada", "title": "Symmetries and isomorphisms for privacy in control over the cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing platforms are being increasingly used for closing feedback\ncontrol loops, especially when computationally expensive algorithms, such as\nmodel-predictive control, are used to optimize performance. Outsourcing of\ncontrol algorithms entails an exchange of data between the control system and\nthe cloud, and, naturally, raises concerns about the privacy of the control\nsystem's data (e.g., state trajectory, control objective). Moreover, any\nattempt at enforcing privacy needs to add minimal computational overhead to\navoid degrading control performance. In this paper, we propose several\ntransformation-based methods for enforcing data privacy. We also quantify the\namount of provided privacy and discuss how much privacy is lost when the\nadversary has access to side knowledge. We address three different scenarios:\na) the cloud has no knowledge about the system being controlled; b) the cloud\nknows what sensors and actuators the system employs but not the system\ndynamics; c) the cloud knows the system dynamics, its sensors, and actuators.\nIn all of these three scenarios, the proposed methods allow for the control\nover the cloud without compromising private information (which information is\nconsidered private depends on the considered scenario).\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 09:28:00 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Sultangazin", "Alimzhan", ""], ["Tabuada", "Paulo", ""]]}, {"id": "1906.07532", "submitter": "David Sommer", "authors": "David M. Sommer, Moritz Schneider, Jannik Gut, Srdjan Capkun", "title": "Cyber-Risks in Paper Voting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Paper ballot voting with its fully-reviewable paper-trail is usually\nconsidered as more secure than their e-voting counterparts, given the large\nnumber of recent incidents. In this work, we explore the security of paper\nvoting and show that paper voting, as it is implemented today, is surprisingly\nvulnerable to cyber-attacks. In particular, the aggregation methods of\npreliminary voting results of various countries rely on insecure communication\nchannels like telephone, fax or non-secure e-mail. Furthermore, regulations\ntypically do not mandate the use of secure channels for the transmission of\npreliminary results. We illustrate that preliminary results, despite their\ntemporary nature, may have a severe impact on real-world decisions during the 3\nto 30 days window until the final results are declared. An attacker exploiting\nthis discrepancy can, e.g., benefit from stock market manipulation or call into\nquestion the legitimacy of the elections. This work investigates the\ncyber-risks in paper voting in a systematic manner by reviewing procedures in\nseveral countries (Estonia, France, Germany, the United Kingdom, and the United\nStates of America) and through a comprehensive case-study of Switzerland. We\nexamine the transmission systems currently in use through inquires from\nelection officials. Moreover, we illustrate the feasibility of attacks by\nanalyzing the frequent historical discrepancies between preliminary and final\nresults. Considering our results and recent reports about easily modifiable\npreliminary results in Germany and the Netherlands, we conjecture similar\nweaknesses in other countries as well.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 12:41:23 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 11:39:34 GMT"}, {"version": "v3", "created": "Thu, 26 Nov 2020 17:40:03 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Sommer", "David M.", ""], ["Schneider", "Moritz", ""], ["Gut", "Jannik", ""], ["Capkun", "Srdjan", ""]]}, {"id": "1906.07537", "submitter": "Arielle Moro", "authors": "Arielle Moro, Beno\\^it Garbinato and Val\\'erie Chavez-Demoulin", "title": "Analyzing privacy-aware mobility behavior using the evolution of\n  spatio-temporal entropy", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing mobility behavior of users is extremely useful to create or improve\nexisting services. Several research works have been done in order to study\nmobility behavior of users that mainly use users' significant locations.\nHowever, these existing analysis are extremely intrusive because they require\nthe knowledge of the frequently visited places of users, which thus makes it\nfairly easy to identify them. Consequently, in this paper, we present a\nprivacy-aware methodology to analyze mobility behavior of users. We firstly\npropose a new metric based on the well-known Shannon entropy, called\nspatio-temporal entropy, to quantify the mobility level of a user during a time\nwindow. Then, we compute a sequence of spatio-temporal entropy from the\nlocation history of the user that expresses user's movements as rhythms. We\nsecondly present how to study the effects of several groups of additional\nvariables on the evolution of the spatio-temporal entropy of a user, such as\nspatio-temporal, demographic and mean of transportation variables. For this, we\nuse Generalized Additive Models (GAMs). The results firstly show that the\nspatio-temporal entropy and GAMs are an ideal combination to understand\nmobility behavior of an individual user or a group of users. We also evaluate\nthe prediction accuracy of a global GAM compared to individual GAMs and\nindividual AutoRegressive Integrated Moving Average (ARIMA) models. These last\nresults highlighted that the global GAM gives more accurate predictions of\nspatio-temporal entropy by checking the Mean Absolute Error (MAE). In addition,\nthis research work opens various threads, such as the prediction of demographic\ndata of users or the creation of personalized mobility prediction models by\nusing movement rhythm characteristics of a user.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 12:56:26 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 11:30:19 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Moro", "Arielle", ""], ["Garbinato", "Beno\u00eet", ""], ["Chavez-Demoulin", "Val\u00e9rie", ""]]}, {"id": "1906.07690", "submitter": "S\\'ebastien Lugan PhD", "authors": "Sebastien Lugan, Paul Desbordes, Luis Xavier Ramos Tormo, Axel Legay\n  and Benoit Macq", "title": "Secure Architectures Implementing Trusted Coalitions for Blockchained\n  Distributed Learning (TCLearn)", "comments": null, "journal-ref": "IEEE Access, vol. 7, pp. 181789-181799, 2019", "doi": "10.1109/ACCESS.2019.2959220", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed learning across a coalition of organizations allows the members\nof the coalition to train and share a model without sharing the data used to\noptimize this model. In this paper, we propose new secure architectures that\nguarantee preservation of data privacy, trustworthy sequence of iterative\nlearning and equitable sharing of the learned model among each member of the\ncoalition by using adequate encryption and blockchain mechanisms. We exemplify\nits deployment in the case of the distributed optimization of a deep learning\nconvolutional neural network trained on medical images.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 17:03:28 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Lugan", "Sebastien", ""], ["Desbordes", "Paul", ""], ["Tormo", "Luis Xavier Ramos", ""], ["Legay", "Axel", ""], ["Macq", "Benoit", ""]]}, {"id": "1906.07745", "submitter": "Masoumeh Shafieinejad", "authors": "Masoumeh Shafieinejad, Jiaqi Wang, Nils Lukas, Xinda Li, Florian\n  Kerschbaum", "title": "On the Robustness of the Backdoor-based Watermarking in Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Obtaining the state of the art performance of deep learning models imposes a\nhigh cost to model generators, due to the tedious data preparation and the\nsubstantial processing requirements. To protect the model from unauthorized\nre-distribution, watermarking approaches have been introduced in the past\ncouple of years. We investigate the robustness and reliability of\nstate-of-the-art deep neural network watermarking schemes. We focus on\nbackdoor-based watermarking and propose two -- a black-box and a white-box --\nattacks that remove the watermark. Our black-box attack steals the model and\nremoves the watermark with minimum requirements; it just relies on public\nunlabeled data and a black-box access to the classification label. It does not\nneed classification confidences or access to the model's sensitive information\nsuch as the training data set, the trigger set or the model parameters. The\nwhite-box attack, proposes an efficient watermark removal when the parameters\nof the marked model are available; our white-box attack does not require access\nto the labeled data or the trigger set and improves the runtime of the\nblack-box attack up to seventeen times. We as well prove the security\ninadequacy of the backdoor-based watermarking in keeping the watermark\nundetectable by proposing an attack that detects whether a model contains a\nwatermark. Our attacks show that a recipient of a marked model can remove a\nbackdoor-based watermark with significantly less effort than training a new\nmodel and some other techniques are needed to protect against re-distribution\nby a motivated attacker.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 18:05:35 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 00:56:00 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Shafieinejad", "Masoumeh", ""], ["Wang", "Jiaqi", ""], ["Lukas", "Nils", ""], ["Li", "Xinda", ""], ["Kerschbaum", "Florian", ""]]}, {"id": "1906.07773", "submitter": "Luis Mu\\~noz-Gonz\\'alez", "authors": "Luis Mu\\~noz-Gonz\\'alez, Bjarne Pfitzner, Matteo Russo, Javier\n  Carnerero-Cano, Emil C. Lupu", "title": "Poisoning Attacks with Generative Adversarial Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms are vulnerable to poisoning attacks: An adversary\ncan inject malicious points in the training dataset to influence the learning\nprocess and degrade the algorithm's performance. Optimal poisoning attacks have\nalready been proposed to evaluate worst-case scenarios, modelling attacks as a\nbi-level optimization problem. Solving these problems is computationally\ndemanding and has limited applicability for some models such as deep networks.\nIn this paper we introduce a novel generative model to craft systematic\npoisoning attacks against machine learning classifiers generating adversarial\ntraining examples, i.e. samples that look like genuine data points but that\ndegrade the classifier's accuracy when used for training. We propose a\nGenerative Adversarial Net with three components: generator, discriminator, and\nthe target classifier. This approach allows us to model naturally the\ndetectability constrains that can be expected in realistic attacks and to\nidentify the regions of the underlying data distribution that can be more\nvulnerable to data poisoning. Our experimental evaluation shows the\neffectiveness of our attack to compromise machine learning classifiers,\nincluding deep networks.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 19:14:09 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 16:23:27 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Mu\u00f1oz-Gonz\u00e1lez", "Luis", ""], ["Pfitzner", "Bjarne", ""], ["Russo", "Matteo", ""], ["Carnerero-Cano", "Javier", ""], ["Lupu", "Emil C.", ""]]}, {"id": "1906.07806", "submitter": "Nimisha Limaye", "authors": "Nimisha Limaye, Abhrajit Sengupta, Mohammed Nabeel, and Ozgur\n  Sinanoglu", "title": "Is Robust Design-for-Security Robust Enough? Attack on Locked Circuits\n  with Restricted Scan Chain Access", "comments": "To be published in IEEE/ACM International Conference on\n  Computer-Aided Design (ICCAD) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The security of logic locking has been called into question by various\nattacks, especially a Boolean satisfiability (SAT) based attack, that exploits\nscan access in a working chip. Among other techniques, a robust\ndesign-for-security (DFS) architecture was presented to restrict any\nunauthorized scan access, thereby, thwarting the SAT attack (or any other\nattack that relies on scan access). Nevertheless, in this work, we successfully\nbreak this technique by recovering the secret key despite the lack of scan\naccess. Our security analysis on a few benchmark circuits protected by the\nrobust DFS architecture demonstrates the effectiveness of our attack; on\naverage ~95% of the key bits are correctly recovered, and almost 100% in most\ncases. To overcome this and other prevailing attacks, we propose a defense by\nmaking fundamental changes to the robust DFS technique; the new defense can\nwithstand all logic locking attacks. We observe, on average, lower area\noverhead (~1.65%) than the robust DFS design (~5.15%), and similar test\ncoverage (~99.88%).\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 20:48:10 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Limaye", "Nimisha", ""], ["Sengupta", "Abhrajit", ""], ["Nabeel", "Mohammed", ""], ["Sinanoglu", "Ozgur", ""]]}, {"id": "1906.07841", "submitter": "Lamya Abdullah", "authors": "Lamya Abdullah, Felix Freiling, Juan Quintero and Zinaida Benenson", "title": "Sealed Computation: Abstract Requirements for Mechanisms to Support\n  Trustworthy Cloud Computing", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-12786-2_9", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cloud computing, data processing is delegated to a remote party for\nefficiency and flexibility reasons. A practical user requirement usually is\nthat the confidentiality and integrity of data processing needs to be\nprotected. In the common scenarios of cloud computing today, this can only be\nachieved by assuming that the remote party does not in any form act\nmaliciously. In this paper, we propose an approach that avoids having to trust\na single entity. Our approach is based on two concepts: (1) the technical\nabstraction of sealed computation, i.e., a technical mechanism to confine the\nprocessing of data within a tamper-proof hardware container, and (2) the\nadditional role of an auditing party that itself cannot add functionality to\nthe system but is able to check whether the system (including the mechanism for\nsealed computation) works as expected. We discuss the abstract technical and\nprocedural requirements of these concepts and explain how they can be applied\nin practice.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 23:20:26 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Abdullah", "Lamya", ""], ["Freiling", "Felix", ""], ["Quintero", "Juan", ""], ["Benenson", "Zinaida", ""]]}, {"id": "1906.07852", "submitter": "Cuneyt Gurcan Akcora", "authors": "Cuneyt Gurcan Akcora and Yitao Li and Yulia R. Gel and Murat\n  Kantarcioglu", "title": "BitcoinHeist: Topological Data Analysis for Ransomware Detection on the\n  Bitcoin Blockchain", "comments": "15 pages, 11 tables, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proliferation of cryptocurrencies (e.g., Bitcoin) that allow pseudo-anonymous\ntransactions, has made it easier for ransomware developers to demand ransom by\nencrypting sensitive user data. The recently revealed strikes of ransomware\nattacks have already resulted in significant economic losses and societal harm\nacross different sectors, ranging from local governments to health care.\n  Most modern ransomware use Bitcoin for payments. However, although Bitcoin\ntransactions are permanently recorded and publicly available, current\napproaches for detecting ransomware depend only on a couple of heuristics\nand/or tedious information gathering steps (e.g., running ransomware to collect\nransomware related Bitcoin addresses). To our knowledge, none of the previous\napproaches have employed advanced data analytics techniques to automatically\ndetect ransomware related transactions and malicious Bitcoin addresses.\n  By capitalizing on the recent advances in topological data analysis, we\npropose an efficient and tractable data analytics framework to automatically\ndetect new malicious addresses in a ransomware family, given only a limited\nrecords of previous transactions. Furthermore, our proposed techniques exhibit\nhigh utility to detect the emergence of new ransomware families, that is,\nransomware with no previous records of transactions. Using the existing known\nransomware data sets, we show that our proposed methodology provides\nsignificant improvements in precision and recall for ransomware transaction\ndetection, compared to existing heuristic based approaches, and can be utilized\nto automate ransomware detection.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 00:01:40 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Akcora", "Cuneyt Gurcan", ""], ["Li", "Yitao", ""], ["Gel", "Yulia R.", ""], ["Kantarcioglu", "Murat", ""]]}, {"id": "1906.07858", "submitter": "Rosin Ngueveu", "authors": "Ulrich A\\\"ivodji, Fran\\c{c}ois Bidet, S\\'ebastien Gambs, Rosin Claude\n  Ngueveu, Alain Tapp", "title": "Adversarial training approach for local data debiasing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread use of automated decision processes in many areas of our\nsociety raises serious ethical issues concerning the fairness of the process\nand the possible resulting discriminations. In this work, we propose a novel\napproach called GANsan whose objective is to prevent the possibility of any\ndiscrimination i.e., direct and indirect) based on a sensitive attribute by\nremoving the attribute itself as well as the existing correlations with the\nremaining attributes. Our sanitization algorithm GANsan is partially inspired\nby the powerful framework of generative adversarial networks (in particular the\nCycle-GANs), which offers a flexible way to learn a distribution empirically or\nto translate between two different distributions.\n  In contrast to prior work, one of the strengths of our approach is that the\nsanitization is performed in the same space as the original data by only\nmodifying the other attributes as little as possible and thus preserving the\ninterpretability of the sanitized data. As a consequence, once the sanitizer is\ntrained, it can be applied to new data, such as for instance, locally by an\nindividual on his profile before releasing it. Finally, experiments on a real\ndataset demonstrate the effectiveness of the proposed approach as well as the\nachievable trade-off between fairness and utility.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 00:20:58 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 20:29:19 GMT"}, {"version": "v3", "created": "Thu, 3 Sep 2020 17:54:53 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["A\u00efvodji", "Ulrich", ""], ["Bidet", "Fran\u00e7ois", ""], ["Gambs", "S\u00e9bastien", ""], ["Ngueveu", "Rosin Claude", ""], ["Tapp", "Alain", ""]]}, {"id": "1906.07895", "submitter": "Shihao Yan", "authors": "Shihao Yan, Xiangyun Zhou, Jinsong Hu, and Stephen V. Hanly", "title": "Low Probability of Detection Communication: Opportunities and Challenges", "comments": "7 pages, 5 figures, A slightly different version has been accepted by\n  IEEE Wireless Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.ET math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low probability of detection (LPD) communication has recently emerged as a\nnew transmission technology to address privacy and security in wireless\nnetworks. Recent studies have established the fundamental limits of LPD\ncommunication in terms of the amount of information bits that can be conveyed\nfrom a transmitter to a receiver subject to a constraint on a warden's\ndetection error probability. The established information-theoretic metric\nenables analytical studies on the design and performance of LPD communication\nunder various channel conditions. In this article, we present the key features\nof LPD communication and discuss various important design considerations.\nFirstly, we clarify the differences between LPD communication and the\nwell-known physical-layer security. Then, from an information-theoretic point\nof view, we discuss the optimal signalling strategies for transmitting the\nmessage-carrying signal and artificial-noise signal for LPD communication.\nFinally, we identify the key challenges in the design of practical LPD\ncommunication systems and point out future research directions in this context.\nThis article provides guidelines for designing practical LPD communication\nstrategies in wireless systems and networks.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 03:19:35 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 05:00:44 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Yan", "Shihao", ""], ["Zhou", "Xiangyun", ""], ["Hu", "Jinsong", ""], ["Hanly", "Stephen V.", ""]]}, {"id": "1906.07902", "submitter": "Han Zhao", "authors": "Han Zhao, Jianfeng Chi, Yuan Tian, Geoffrey J. Gordon", "title": "Trade-offs and Guarantees of Adversarial Representation Learning for\n  Information Obfuscation", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdsourced data used in machine learning services might carry sensitive\ninformation about attributes that users do not want to share. Various methods\nhave been proposed to minimize the potential information leakage of sensitive\nattributes while maximizing the task accuracy. However, little is known about\nthe theory behind these methods. In light of this gap, we develop a novel\ntheoretical framework for attribute obfuscation. Under our framework, we\npropose a minimax optimization formulation to protect the given attribute and\nanalyze its inference guarantees against worst-case adversaries. Meanwhile, it\nis clear that in general there is a tension between minimizing information\nleakage and maximizing task accuracy. To understand this, we prove an\ninformation-theoretic lower bound to precisely characterize the fundamental\ntrade-off between accuracy and information leakage. We conduct experiments on\ntwo real-world datasets to corroborate the inference guarantees and validate\nthis trade-off. Our results indicate that, among several alternatives, the\nadversarial learning approach achieves the best trade-off in terms of attribute\nobfuscation and accuracy maximization.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 04:00:38 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 05:08:11 GMT"}, {"version": "v3", "created": "Sun, 25 Oct 2020 05:23:04 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Zhao", "Han", ""], ["Chi", "Jianfeng", ""], ["Tian", "Yuan", ""], ["Gordon", "Geoffrey J.", ""]]}, {"id": "1906.07920", "submitter": "Hanbin Hu", "authors": "Hanbin Hu and Mit Shah and Jianhua Z. Huang and Peng Li", "title": "Global Adversarial Attacks for Assessing Deep Learning Robustness", "comments": "Submitted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that deep neural networks (DNNs) may be vulnerable to\nadversarial attacks, raising the concern on their robustness particularly for\nsafety-critical applications. Recognizing the local nature and limitations of\nexisting adversarial attacks, we present a new type of global adversarial\nattacks for assessing global DNN robustness. More specifically, we propose a\nnovel concept of global adversarial example pairs in which each pair of two\nexamples are close to each other but have different class labels predicted by\nthe DNN. We further propose two families of global attack methods and show that\nour methods are able to generate diverse and intriguing adversarial example\npairs at locations far from the training or testing data. Moreover, we\ndemonstrate that DNNs hardened using the strong projected gradient descent\n(PGD) based (local) adversarial training are vulnerable to the proposed global\nadversarial example pairs, suggesting that global robustness must be considered\nwhile training robust deep learning networks.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 05:16:57 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Hu", "Hanbin", ""], ["Shah", "Mit", ""], ["Huang", "Jianhua Z.", ""], ["Li", "Peng", ""]]}, {"id": "1906.07921", "submitter": "Asaf Shabtai", "authors": "Sefi Akerman, Edan Habler, Asaf Shabtai", "title": "VizADS-B: Analyzing Sequences of ADS-B Images Using Explainable\n  Convolutional LSTM Encoder-Decoder to Detect Cyber Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of the automatic dependent surveillance broadcast (ADS-B)\ntechnology is to serve as a replacement for the current radar-based, air\ntraffic control systems. Despite the considerable time and resources devoted to\ndesigning and developing the system, the ADS-B is well known for its lack of\nsecurity mechanisms. Attempts to address these security vulnerabilities have\nbeen made in previous studies by modifying the protocol's current architecture\nor by using additional hardware components. These solutions, however, are\nconsidered impractical because of 1) the complex regulatory process involving\navionic systems, 2) the high costs of using hardware components, and 3) the\nfact that the ADS-B system itself is already deployed in most aircraft and\nground stations around the world. In this paper, we propose VizADS-B, an\nalternative software-based security solution for detecting anomalous ADS-B\nmessages, which does not require any alteration of the current ADS-B\narchitecture or the addition of sensors. According to the proposed method, the\ninformation obtained from all aircraft within a specific geographical area is\naggregated and represented as a stream of images. Then, a convolutional LSTM\nencoder-decoder model is used for analyzing and detecting anomalies in the\nsequences of images. In addition, we propose an explainability technique,\ndesigned specifically for convolutional LSTM encoder-decoder models, which is\nused for providing operative information to the pilot as a visual indicator of\na detected anomaly, thus allowing the pilot to make relevant decisions. We\nevaluated our proposed method on five datasets by injecting and subsequently\nidentifying five different attacks. Our experiments demonstrate that most of\nthe attacks can be detected based on spatio-temporal anomaly detection\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 05:31:17 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Akerman", "Sefi", ""], ["Habler", "Edan", ""], ["Shabtai", "Asaf", ""]]}, {"id": "1906.07927", "submitter": "Xinchen Yan", "authors": "Haonan Qiu, Chaowei Xiao, Lei Yang, Xinchen Yan, Honglak Lee, Bo Li", "title": "SemanticAdv: Generating Adversarial Examples via Attribute-conditional\n  Image Editing", "comments": "To appear at ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have achieved great success in various\napplications due to their strong expressive power. However, recent studies have\nshown that DNNs are vulnerable to adversarial examples which are manipulated\ninstances targeting to mislead DNNs to make incorrect predictions. Currently,\nmost such adversarial examples try to guarantee \"subtle perturbation\" by\nlimiting the $L_p$ norm of the perturbation. In this paper, we aim to explore\nthe impact of semantic manipulation on DNNs predictions by manipulating the\nsemantic attributes of images and generate \"unrestricted adversarial examples\".\n  In particular, we propose an algorithm \\emph{SemanticAdv} which leverages\ndisentangled semantic factors to generate adversarial perturbation by altering\ncontrolled semantic attributes to fool the learner towards various\n\"adversarial\" targets. We conduct extensive experiments to show that the\nsemantic based adversarial examples can not only fool different learning tasks\nsuch as face verification and landmark detection, but also achieve high\ntargeted attack success rate against \\emph{real-world black-box} services such\nas Azure face verification service based on transferability.\n  To further demonstrate the applicability of \\emph{SemanticAdv} beyond face\nrecognition domain, we also generate semantic perturbations on street-view\nimages. Such adversarial examples with controlled semantic manipulation can\nshed light on further understanding about vulnerabilities of DNNs as well as\npotential defensive approaches.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 05:55:16 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 07:32:08 GMT"}, {"version": "v3", "created": "Mon, 6 Apr 2020 17:34:07 GMT"}, {"version": "v4", "created": "Thu, 2 Jul 2020 19:47:47 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Qiu", "Haonan", ""], ["Xiao", "Chaowei", ""], ["Yang", "Lei", ""], ["Yan", "Xinchen", ""], ["Lee", "Honglak", ""], ["Li", "Bo", ""]]}, {"id": "1906.07982", "submitter": "Rafa\\\"el Pinot", "authors": "Rafael Pinot and Florian Yger and C\\'edric Gouy-Pailler and Jamal Atif", "title": "A unified view on differential privacy and robustness to adversarial\n  examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short note highlights some links between two lines of research within\nthe emerging topic of trustworthy machine learning: differential privacy and\nrobustness to adversarial examples. By abstracting the definitions of both\nnotions, we show that they build upon the same theoretical ground and hence\nresults obtained so far in one domain can be transferred to the other. More\nprecisely, our analysis is based on two key elements: probabilistic mappings\n(also called randomized algorithms in the differential privacy community), and\nthe Renyi divergence which subsumes a large family of divergences. We first\ngeneralize the definition of robustness against adversarial examples to\nencompass probabilistic mappings. Then we observe that Renyi-differential\nprivacy (a generalization of differential privacy recently proposed\nin~\\cite{Mironov2017RenyiDP}) and our definition of robustness share several\nsimilarities. We finally discuss how can both communities benefit from this\nconnection to transfer technical tools from one research field to the other.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 09:12:31 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Pinot", "Rafael", ""], ["Yger", "Florian", ""], ["Gouy-Pailler", "C\u00e9dric", ""], ["Atif", "Jamal", ""]]}, {"id": "1906.07983", "submitter": "Pan Kessel", "authors": "Ann-Kathrin Dombrowski, Maximilian Alber, Christopher J. Anders,\n  Marcel Ackermann, Klaus-Robert M\\\"uller, Pan Kessel", "title": "Explanations can be manipulated and geometry is to blame", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explanation methods aim to make neural networks more trustworthy and\ninterpretable. In this paper, we demonstrate a property of explanation methods\nwhich is disconcerting for both of these purposes. Namely, we show that\nexplanations can be manipulated arbitrarily by applying visually hardly\nperceptible perturbations to the input that keep the network's output\napproximately constant. We establish theoretically that this phenomenon can be\nrelated to certain geometrical properties of neural networks. This allows us to\nderive an upper bound on the susceptibility of explanations to manipulations.\nBased on this result, we propose effective mechanisms to enhance the robustness\nof explanations.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 09:13:23 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 16:12:12 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Dombrowski", "Ann-Kathrin", ""], ["Alber", "Maximilian", ""], ["Anders", "Christopher J.", ""], ["Ackermann", "Marcel", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Kessel", "Pan", ""]]}, {"id": "1906.07997", "submitter": "Dou Goodman", "authors": "Dou Goodman and Tao Wei", "title": "Cloud-based Image Classification Service Is Not Robust To Simple\n  Transformations: A Forgotten Battlefield", "comments": "arXiv admin note: text overlap with arXiv:1901.01223,\n  arXiv:1704.05051, arXiv:1801.02612 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent works demonstrated that Deep Learning models are vulnerable to\nadversarial examples.Fortunately, generating adversarial examples usually\nrequires white-box access to the victim model, and the attacker can only access\nthe APIs opened by cloud platforms. Thus, keeping models in the cloud can\nusually give a (false) sense of security.Unfortunately, cloud-based image\nclassification service is not robust to simple transformations such as Gaussian\nNoise, Salt-and-Pepper Noise, Rotation and Monochromatization. In this\npaper,(1) we propose one novel attack method called Image Fusion(IF) attack,\nwhich achieve a high bypass rate,can be implemented only with OpenCV and is\ndifficult to defend; and (2) we make the first attempt to conduct an extensive\nempirical study of Simple Transformation (ST) attacks against real-world\ncloud-based classification services. Through evaluations on four popular cloud\nplatforms including Amazon, Google, Microsoft, Clarifai, we demonstrate that ST\nattack has a success rate of approximately 100% except Amazon approximately\n50%, IF attack have a success rate over 98% among different classification\nservices. (3) We discuss the possible defenses to address these security\nchallenges.Experiments show that our defense technology can effectively defend\nknown ST attacks.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 09:36:17 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 06:03:09 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Goodman", "Dou", ""], ["Wei", "Tao", ""]]}, {"id": "1906.08139", "submitter": "Chandra Kanth Nagesh", "authors": "Chandra Kanth Nagesh, K N Hemanth Rao, Anjan K Koundinya", "title": "Secure Handshake Mechanism for Autonomous Flying Agents Using Robust\n  Cryptosystem", "comments": "7 pages, 5 figures, Published in the proceedings of 2017 2nd\n  International Conference on Computational Systems and Information Technology\n  for Sustainable Solution (CSITSS) IEEE, December 2017, Bangalore, India", "journal-ref": null, "doi": "10.1109/CSITSS.2017.8447729", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The autonomous flying agents in a Network-centric environment and brings out\nvarious security threats and various techniques of Cryptography. Primary Focus\nis on study and implementation of how cryptographic algorithms can be\neffectively be used in a warfare scenario. The data security is the utmost key\nfactor for the protection of data in such environments. The paper proposes\nmechanisms secured data transmission from the command center (which can be the\nsending flying agent) to shooter target. The command center and shooter target\nhave a unique set of encryption and decryption key which are created randomly\nby calibrating the security level at run time. In the beginning, the encryption\nkey used for encrypting data is received from a shooter target when the\ncommunication is authenticated through UDP sockets. The encrypted data is sent\nto the shooter target with the signed signature and command center's encryption\nkey. The encrypted data and signature are then decrypted and verified\nrespectively at the shooter target. The time analysis is performed and observed\ninputs are provided to the command center.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 15:08:31 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Nagesh", "Chandra Kanth", ""], ["Rao", "K N Hemanth", ""], ["Koundinya", "Anjan K", ""]]}, {"id": "1906.08149", "submitter": "Mahawaga Arachchige Pathum Chamikara", "authors": "M.A.P. Chamikara, P. Bertok, D. Liu, S. Camtepe, I. Khalil", "title": "Efficient privacy preservation of big data for accurate data mining", "comments": "Information Sciences", "journal-ref": null, "doi": "10.1016/j.ins.2019.05.053", "report-no": null, "categories": "cs.DB cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Computing technologies pervade physical spaces and human lives, and produce a\nvast amount of data that is available for analysis. However, there is a growing\nconcern that potentially sensitive data may become public if the collected data\nare not appropriately sanitized before being released for investigation.\nAlthough there are more than a few privacy-preserving methods available, they\nare not efficient, scalable or have problems with data utility, and/or privacy.\nThis paper addresses these issues by proposing an efficient and scalable\nnonreversible perturbation algorithm, PABIDOT, for privacy preservation of big\ndata via optimal geometric transformations. PABIDOT was tested for efficiency,\nscalability, resistance, and accuracy using nine datasets and five\nclassification algorithms. Experiments show that PABIDOT excels in execution\nspeed, scalability, attack resistance and accuracy in large-scale\nprivacy-preserving data classification when compared with two other, related\nprivacy-preserving algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 15:23:41 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Chamikara", "M. A. P.", ""], ["Bertok", "P.", ""], ["Liu", "D.", ""], ["Camtepe", "S.", ""], ["Khalil", "I.", ""]]}, {"id": "1906.08176", "submitter": "Tommy Mckinnon", "authors": "Tommy Mckinnon", "title": "MaGPoS -- A novel decentralized consensus mechanism combining magnetism\n  and proof of stake", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe MaGPoS, a novel consensus mechanism which is well suited to\ndecentralized blockchain based protocols. MaGPoS is based on a combination of\nthe well known physics of nano-scale magnetism, and previous implementations of\nproof of stake. This system has been studied by hundreds of thousands of\nscientists worldwide for over a hundred years, giving it an extreme level of\nreliability that is needed for a consensus mechanism. We start by explaining\nthe physics, and study the properties that make it particularly beneficial for\nuse in a consensus mechanism. We then show how to apply the physical model to a\ndecentralized network of nodes, each with their own copy of a blockchain. After\nthis, we describe some example calculations that a node in the decentralized\nnetwork would make, and provide pseudo code for implementation. Finally, we\ndiscuss the how the model achieves all of the important properties that one\nexpects of a consensus mechanism.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 05:55:18 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Mckinnon", "Tommy", ""]]}, {"id": "1906.08204", "submitter": "Junqi Li", "authors": "Jieren Cheng, Junqi Li, Xiangyan Tang, Victor S. Sheng, Chen Zhang,\n  Mengyang Li", "title": "A Novel DDoS Attack Detection Method Using Optimized Generalized\n  Multiple Kernel Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Denial of Service (DDoS) attack has become one of the most\ndestructive network attacks which can pose a mortal threat to Internet\nsecurity. Existing detection methods can not effectively detect early attacks.\nIn this paper, we propose a detection method of DDoS attacks based on\ngeneralized multiple kernel learning (GMKL) combining with the constructed\nparameter R. The super-fusion feature value (SFV) and comprehensive degree of\nfeature (CDF) are defined to describe the characteristic of attack flow and\nnormal flow. A method for calculating R based on SFV and CDF is proposed to\nselect the combination of kernel function and regularization paradigm. A DDoS\nattack detection classifier is generated by using the trained GMKL model with R\nparameter. The experimental results show that kernel function and\nregularization parameter selection method based on R parameter reduce the\nrandomness of parameter selection and the error of model detection, and the\nproposed method can effectively detect DDoS attacks in complex environments\nwith higher detection rate and lower error rate.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 16:28:09 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Cheng", "Jieren", ""], ["Li", "Junqi", ""], ["Tang", "Xiangyan", ""], ["Sheng", "Victor S.", ""], ["Zhang", "Chen", ""], ["Li", "Mengyang", ""]]}, {"id": "1906.08320", "submitter": "Badih Ghazi", "authors": "Badih Ghazi, Rasmus Pagh, Ameya Velingker", "title": "Scalable and Differentially Private Distributed Aggregation in the\n  Shuffled Model", "comments": "17 pages, 1 figure, 1 table, 2 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning promises to make machine learning feasible on distributed,\nprivate datasets by implementing gradient descent using secure aggregation\nmethods. The idea is to compute a global weight update without revealing the\ncontributions of individual users. Current practical protocols for secure\naggregation work in an \"honest but curious\" setting where a curious adversary\nobserving all communication to and from the server cannot learn any private\ninformation assuming the server is honest and follows the protocol. A more\nscalable and robust primitive for privacy-preserving protocols is shuffling of\nuser data, so as to hide the origin of each data item. Highly scalable and\nsecure protocols for shuffling, so-called mixnets, have been proposed as a\nprimitive for privacy-preserving analytics in the Encode-Shuffle-Analyze\nframework by Bittau et al., which was later analytically studied by Erlingsson\net al. and Cheu et al.. The recent papers by Cheu et al., and Balle et al. have\ngiven protocols for secure aggregation that achieve differential privacy\nguarantees in this \"shuffled model\". Their protocols come at a cost, though:\nEither the expected aggregation error or the amount of communication per user\nscales as a polynomial $n^{\\Omega(1)}$ in the number of users $n$. In this\npaper we propose simple and more efficient protocol for aggregation in the\nshuffled model, where communication as well as error increases only\npolylogarithmically in $n$. Our new technique is a conceptual \"invisibility\ncloak\" that makes users' data almost indistinguishable from random noise while\nintroducing zero distortion on the sum.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 19:30:05 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 17:21:17 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 17:53:21 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Ghazi", "Badih", ""], ["Pagh", "Rasmus", ""], ["Velingker", "Ameya", ""]]}, {"id": "1906.08424", "submitter": "Haleh Amintoosi", "authors": "Mahdi Nikooghadam, Haleh Amintoosi", "title": "Cryptanalysis of Khatoon et al.'s ECC-based Authentication Protocol for\n  Healthcare Systems", "comments": "5 pages, 1 table, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Telecare medical information systems are gaining rapid popularity in terms of\nproviding the delivery of online health-related services such as online remote\nhealth profile access for patients and doctors. Due to being installed entirely\non Internet, these systems are exposed to various security and privacy threats.\nHence, establishing a secure key agreement and authentication process between\nthe patients and the medical servers is an important challenge. Recently,\nKhatoon et.al proposed an ECC-based unlink-able authentication and key\nagreement method for healthcare related application in smart city. In this\narticle, we provide a descriptive analysis on their proposed scheme and prove\nthat Khatoon et al.'s scheme is vulnerable to known-session-specific temporary\ninformation attack and is not able to provide perfect forward secrecy.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 03:08:34 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Nikooghadam", "Mahdi", ""], ["Amintoosi", "Haleh", ""]]}, {"id": "1906.08443", "submitter": "Shihao Yan", "authors": "Riqing Chen, Chunhui Li, Shihao Yan, Robert Malaney, and Jinhong Yuan", "title": "Physical Layer Security for Ultra-Reliable and Low-Latency\n  Communications", "comments": "6 pages, 4 figures; Accepted by IEEE Wireless Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultra-reliable and low-latency communication (URLLC) is one category of\nservice to be provided by next-generation wireless networks. Motivated by\nincreasing security concerns in such networks, this article focuses on physical\nlayer security (PLS) in the context of URLLC. The PLS technique mainly uses\ntransmission designs based on the intrinsic randomness of the wireless medium\nto achieve secrecy. As such, PLS is of lower complexity and incurs less latency\nthan traditional cryptography. In this article, we first introduce appropriate\nperformance metrics for evaluating PLS in URLLC, illustrating the tradeoff\nbetween latency, reliability, and security. We then identify the key\nchallenging problems for achieving PLS for URLLC, and discuss the role that\nchannel state information can have in providing potential solutions to these\nproblems. Finally, we present our recommendations on future research directions\nin this emerging area.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 04:51:15 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Chen", "Riqing", ""], ["Li", "Chunhui", ""], ["Yan", "Shihao", ""], ["Malaney", "Robert", ""], ["Yuan", "Jinhong", ""]]}, {"id": "1906.08507", "submitter": "Jerone Andrews", "authors": "Jerone T. A. Andrews, Thomas Tanay, Lewis D. Griffin", "title": "Multiple-Identity Image Attacks Against Face-based Identity Verification", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facial verification systems are vulnerable to poisoning attacks that make use\nof multiple-identity images (MIIs)---face images stored in a database that\nresemble multiple persons, such that novel images of any of the constituent\npersons are verified as matching the identity of the MII. Research on this mode\nof attack has focused on defence by detection, with no explanation as to why\nthe vulnerability exists. New quantitative results are presented that support\nan explanation in terms of the geometry of the representations spaces used by\nthe verification systems. In the spherical geometry of those spaces, the\nangular distance distributions of matching and non-matching pairs of face\nrepresentations are only modestly separated, approximately centred at 90 and\n40-60 degrees, respectively. This is sufficient for open-set verification on\nnormal data but provides an opportunity for MII attacks. Our analysis considers\nideal MII algorithms, demonstrating that, if realisable, they would deliver\nfaces roughly 45 degrees from their constituent faces, thus classed as matching\nthem. We study the performance of three methods for MII generation---gallery\nsearch, image space morphing, and representation space inversion---and show\nthat the latter two realise the ideal well enough to produce effective attacks,\nwhile the former could succeed but only with an implausibly large gallery to\nsearch. Gallery search and inversion MIIs depend on having access to a facial\ncomparator, for optimisation, but our results show that these attacks can still\nbe effective when attacking disparate comparators, thus securing a deployed\ncomparator is an insufficient defence.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 08:58:22 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Andrews", "Jerone T. A.", ""], ["Tanay", "Thomas", ""], ["Griffin", "Lewis D.", ""]]}, {"id": "1906.08528", "submitter": "Fabio Massimo Zennaro", "authors": "Fabio Massimo Zennaro", "title": "Analyzing and Storing Network Intrusion Detection Data using Bayesian\n  Coresets: A Preliminary Study in Offline and Streaming Settings", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we offer a preliminary study of the application of Bayesian\ncoresets to network security data. Network intrusion detection is a field that\ncould take advantage of Bayesian machine learning in modelling uncertainty and\nmanaging streaming data; however, the large size of the data sets often hinders\nthe use of Bayesian learning methods based on MCMC. Limiting the amount of\nuseful data is a central problem in a field like network traffic analysis,\nwhere large amount of redundant data can be generated very quickly via packet\ncollection. Reducing the number of samples would not only make learning more\nfeasible, but would also contribute to reduce the need for memory and storage.\nWe explore here the use of Bayesian coresets, a technique that reduces the\namount of data samples while guaranteeing the learning of an accurate posterior\ndistribution using Bayesian learning. We analyze how Bayesian coresets affect\nthe accuracy of learned models, and how time-space requirements are traded-off,\nboth in a static scenario and in a streaming scenario.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 09:53:46 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Zennaro", "Fabio Massimo", ""]]}, {"id": "1906.08609", "submitter": "Mayank Raikwar", "authors": "Mayank Raikwar, Danilo Gligoroski, Katina Kralevska", "title": "SoK of Used Cryptography in Blockchain", "comments": null, "journal-ref": "IEEE Access 7 (2019) 148550 - 148575", "doi": "10.1109/ACCESS.2019.2946983", "report-no": null, "categories": "cs.CR cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The underlying fundaments of blockchain are cryptography and cryptographic\nconcepts that provide reliable and secure decentralized solutions. Although\nmany recent papers study the use-cases of blockchain in different industrial\nareas, such as finance, health care, legal relations, IoT, information\nsecurity, and consensus building systems, only few studies scrutinize the\ncryptographic concepts used in blockchain. To the best of our knowledge, there\nis no Systematization of Knowledge (SoK) that gives a complete picture of the\nexisting cryptographic concepts which have been deployed or have the potential\nto be deployed in blockchain. In this paper, we thoroughly review and\nsystematize all cryptographic concepts which are already used in blockchain.\nAdditionally, we give a list of cryptographic concepts which have not yet been\napplied but have big potentials to improve the current blockchain solutions. We\nalso include possible instantiations of these cryptographic concepts in the\nblockchain domain. Last but not least, we explicitly postulate 21 challenging\nproblems that cryptographers interested in blockchain can work on.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 13:38:50 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 10:47:20 GMT"}, {"version": "v3", "created": "Mon, 2 Sep 2019 11:51:57 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Raikwar", "Mayank", ""], ["Gligoroski", "Danilo", ""], ["Kralevska", "Katina", ""]]}, {"id": "1906.08713", "submitter": "Mehmet Yamac", "authors": "Mehmet Yamac, Mete Ahishali, Nikolaos Passalis, Jenni Raitoharju,\n  Bulent Sankur, and Moncef Gabbouj", "title": "Reversible Privacy Preservation using Multi-level Encryption and\n  Compressive Sensing", "comments": "5 pages, submitted/accepted, EUSIPCO 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV eess.IV eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Security monitoring via ubiquitous cameras and their more extended in\nintelligent buildings stand to gain from advances in signal processing and\nmachine learning. While these innovative and ground-breaking applications can\nbe considered as a boon, at the same time they raise significant privacy\nconcerns. In fact, recent GDPR (General Data Protection Regulation) legislation\nhas highlighted and become an incentive for privacy-preserving solutions.\nTypical privacy-preserving video monitoring schemes address these concerns by\neither anonymizing the sensitive data. However, these approaches suffer from\nsome limitations, since they are usually non-reversible, do not provide\nmultiple levels of decryption and computationally costly. In this paper, we\nprovide a novel privacy-preserving method, which is reversible, supports\nde-identification at multiple privacy levels, and can efficiently perform data\nacquisition, encryption and data hiding by combining multi-level encryption\nwith compressive sensing. The effectiveness of the proposed approach in\nprotecting the identity of the users has been validated using the goodness of\nreconstruction quality and strong anonymization of the faces.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 15:58:53 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Yamac", "Mehmet", ""], ["Ahishali", "Mete", ""], ["Passalis", "Nikolaos", ""], ["Raitoharju", "Jenni", ""], ["Sankur", "Bulent", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "1906.08731", "submitter": "Sandro Stucki", "authors": "Sandro Stucki, C\\'esar S\\'anchez, Gerardo Schneider and Borzoo\n  Bonakdarpour", "title": "Gray-box Monitoring of Hyperproperties (Extended Version)", "comments": "This is an extended version of a paper presented at the 23rd\n  International Symposium on Formal Methods (FM '19). This version contains\n  full proofs, a description of the proof-of-concept monitor for DDM, and\n  experimental results that were not included in the original publication", "journal-ref": "ter Beek M., McIver A., Oliveira J. (eds), Formal Methods - The\n  Next 30 Years. FM 2019. Lecture Notes in Computer Science, vol 11800.\n  Springer, Cham", "doi": "10.1007/978-3-030-30942-8_25", "report-no": null, "categories": "cs.LO cs.CR cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many important system properties, particularly in security and privacy,\ncannot be verified statically. Therefore, runtime verification is an appealing\nalternative. Logics for hyperproperties, such as HyperLTL, support a rich set\nof such properties. We first show that black-box monitoring of HyperLTL is in\ngeneral unfeasible, and suggest a gray-box approach. Gray-box monitoring\nimplies performing analysis of the system at run-time, which brings new\nlimitations to monitorabiliy (the feasibility of solving the monitoring\nproblem). Thus, as another contribution of this paper we refine the classic\nnotions of monitorability, both for trace properties and hyperproperties,\ntaking into account the computability of the monitor. We then apply our\napproach to monitor a privacy hyperproperty called distributed data minimality,\nexpressed as a HyperLTL property, by using an SMT-based static verifier at\nruntime.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 16:23:44 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 13:41:38 GMT"}, {"version": "v3", "created": "Fri, 4 Oct 2019 16:32:08 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Stucki", "Sandro", ""], ["S\u00e1nchez", "C\u00e9sar", ""], ["Schneider", "Gerardo", ""], ["Bonakdarpour", "Borzoo", ""]]}, {"id": "1906.08743", "submitter": "David G\\\"uera", "authors": "David G\\\"uera and Sriram Baireddy and Paolo Bestagini and Stefano\n  Tubaro and Edward J. Delp", "title": "We Need No Pixels: Video Manipulation Detection Using Stream Descriptors", "comments": "7 pages, 6 figures, presented at the ICML 2019 Worksop on Synthetic\n  Realities: Deep Learning for Detecting AudioVisual Fakes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manipulating video content is easier than ever. Due to the misuse potential\nof manipulated content, multiple detection techniques that analyze the pixel\ndata from the videos have been proposed. However, clever manipulators should\nalso carefully forge the metadata and auxiliary header information, which is\nharder to do for videos than images. In this paper, we propose to identify\nforged videos by analyzing their multimedia stream descriptors with simple\nbinary classifiers, completely avoiding the pixel space. Using well-known\ndatasets, our results show that this scalable approach can achieve a high\nmanipulation detection score if the manipulators have not done a careful data\nsanitization of the multimedia stream descriptors.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 16:42:06 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["G\u00fcera", "David", ""], ["Baireddy", "Sriram", ""], ["Bestagini", "Paolo", ""], ["Tubaro", "Stefano", ""], ["Delp", "Edward J.", ""]]}, {"id": "1906.08805", "submitter": "Liang Tong", "authors": "Liang Tong, Aron Laszka, Chao Yan, Ning Zhang and Yevgeniy Vorobeychik", "title": "Finding Needles in a Moving Haystack: Prioritizing Alerts with\n  Adversarial Reinforcement Learning", "comments": "v1.0", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detection of malicious behavior is a fundamental problem in security. One of\nthe major challenges in using detection systems in practice is in dealing with\nan overwhelming number of alerts that are triggered by normal behavior (the\nso-called false positives), obscuring alerts resulting from actual malicious\nactivity. While numerous methods for reducing the scope of this issue have been\nproposed, ultimately one must still decide how to prioritize which alerts to\ninvestigate, and most existing prioritization methods are heuristic, for\nexample, based on suspiciousness or priority scores. We introduce a novel\napproach for computing a policy for prioritizing alerts using adversarial\nreinforcement learning. Our approach assumes that the attackers know the full\nstate of the detection system and dynamically choose an optimal attack as a\nfunction of this state, as well as of the alert prioritization policy. The\nfirst step of our approach is to capture the interaction between the defender\nand attacker in a game theoretic model. To tackle the computational complexity\nof solving this game to obtain a dynamic stochastic alert prioritization\npolicy, we propose an adversarial reinforcement learning framework. In this\nframework, we use neural reinforcement learning to compute best response\npolicies for both the defender and the adversary to an arbitrary stochastic\npolicy of the other. We then use these in a double-oracle framework to obtain\nan approximate equilibrium of the game, which in turn yields a robust\nstochastic policy for the defender. Extensive experiments using case studies in\nfraud and intrusion detection demonstrate that our approach is effective in\ncreating robust alert prioritization policies.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 18:47:06 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Tong", "Liang", ""], ["Laszka", "Aron", ""], ["Yan", "Chao", ""], ["Zhang", "Ning", ""], ["Vorobeychik", "Yevgeniy", ""]]}, {"id": "1906.08836", "submitter": "Timothy Trippel", "authors": "Timothy Trippel, Kang G. Shin, Kevin B. Bush, Matthew Hicks", "title": "An Extensible Framework for Quantifying the Coverage of Defenses Against\n  Untrusted Foundries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The transistors used to construct Integrated Circuits (ICs) continue to\nshrink. While this shrinkage improves performance and density, it also reduces\ntrust: the price to build leading-edge fabrication facilities has skyrocketed,\nforcing even nation states to outsource the fabrication of high-performance\nICs. Outsourcing fabrication presents a security threat because the black-box\nnature of a fabricated IC makes comprehensive inspection infeasible. Since\nprior work shows the feasibility of fabrication-time attackers' evasion of\nexisting post-fabrication defenses, IC designers must be able to protect their\nphysical designs before handing them off to an untrusted foundry. To this end,\nrecent work suggests methods to harden IC layouts against attack.\nUnfortunately, no tool exists to assess the effectiveness of the proposed\ndefenses---meaning gaps may exist.\n  This paper presents an extensible IC layout security analysis tool called IC\nAttack Surface (ICAS) that quantifies defensive coverage. For researchers, ICAS\nidentifies gaps for future defenses to target, and enables the quantitative\ncomparison of existing and future defenses. For practitioners, ICAS enables the\nexploration of the impact of design decisions on an IC's resilience to\nfabrication-time attack. ICAS takes a set of metrics that encode the challenge\nof inserting a hardware Trojan into an IC layout, a set of attacks that the\ndefender cares about, and a completed IC layout and reports the number of ways\nan attacker can add each attack to the design. While the ideal score is zero,\npractically, our experience is that lower scores correlate with increased\nattacker effort.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 20:33:31 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Trippel", "Timothy", ""], ["Shin", "Kang G.", ""], ["Bush", "Kevin B.", ""], ["Hicks", "Matthew", ""]]}, {"id": "1906.08842", "submitter": "Timothy Trippel", "authors": "Timothy Trippel, Kang G. Shin, Kevin B. Bush, Matthew Hicks", "title": "T-TER: Defeating A2 Trojans with Targeted Tamper-Evident Routing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the inception of the Integrated Circuit (IC), the size of the\ntransistors used to construct them has continually shrunk. While this\nadvancement significantly improves computing capability, fabrication costs have\nskyrocketed. As a result, most IC designers must now outsource fabrication.\nOutsourcing, however, presents a security threat: comprehensive\npost-fabrication inspection is infeasible given the size of modern ICs, so it\nis nearly impossible to know if the foundry has altered the original design\nduring fabrication (i.e., inserted a hardware Trojan). Defending against a\nfoundry-side adversary is challenging because---even with as few as two\ngates---hardware Trojans can completely undermine software security.\nResearchers have attempted to both detect and prevent foundry-side attacks, but\nall existing defenses are ineffective against Trojans with footprints of a few\ngates or less.\n  We present Targeted Tamper-Evident Routing (T-TER), a preventive layout-level\ndefense against untrusted foundries, capable of thwarting the insertion of even\nthe stealthiest hardware Trojans. T-TER is directed and routing-centric: it\nprevents foundry-side attackers from routing Trojan wires to, or directly\nadjacent to, security-critical wires by shielding them with guard wires. Unlike\nshield wires commonly deployed for cross-talk reduction, T-TER guard wires pose\nan additional technical challenge: they must be tamper-evident in both the\ndigital (deletion attacks) and analog (move and jog attacks) domains. We\naddress this challenge by developing a class of designed-in guard wires, that\nare added to the design specifically to protect security-critical wires.\nT-TER's guard wires incur minimal overhead, scale with design complexity, and\nprovide tamper-evidence against attacks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 20:42:14 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 18:00:30 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Trippel", "Timothy", ""], ["Shin", "Kang G.", ""], ["Bush", "Kevin B.", ""], ["Hicks", "Matthew", ""]]}, {"id": "1906.08935", "submitter": "Ligeng Zhu", "authors": "Ligeng Zhu and Zhijian Liu and Song Han", "title": "Deep Leakage from Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exchanging gradients is a widely used method in modern multi-node machine\nlearning system (e.g., distributed training, collaborative learning). For a\nlong time, people believed that gradients are safe to share: i.e., the training\ndata will not be leaked by gradient exchange. However, we show that it is\npossible to obtain the private training data from the publicly shared\ngradients. We name this leakage as Deep Leakage from Gradient and empirically\nvalidate the effectiveness on both computer vision and natural language\nprocessing tasks. Experimental results show that our attack is much stronger\nthan previous approaches: the recovery is pixel-wise accurate for images and\ntoken-wise matching for texts. We want to raise people's awareness to rethink\nthe gradient's safety. Finally, we discuss several possible strategies to\nprevent such deep leakage. The most effective defense method is gradient\npruning.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 03:46:43 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 05:09:29 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Zhu", "Ligeng", ""], ["Liu", "Zhijian", ""], ["Han", "Song", ""]]}, {"id": "1906.08957", "submitter": "Saeid Tizpaz-Niari", "authors": "Saeid Tizpaz-Niari, Pavol Cerny, Ashutosh Trivedi", "title": "Quantitative Mitigation of Timing Side Channels", "comments": "To Appear in CAV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Timing side channels pose a significant threat to the security and privacy of\nsoftware applications. We propose an approach for mitigating this problem by\ndecreasing the strength of the side channels as measured by entropy-based\nobjectives, such as min-guess entropy. Our goal is to minimize the information\nleaks while guaranteeing a user-specified maximal acceptable performance\noverhead. We dub the decision version of this problem Shannon mitigation, and\nconsider two variants, deterministic and stochastic. First, we show the\ndeterministic variant is NP-hard. However, we give a polynomial algorithm that\nfinds an optimal solution from a restricted set. Second, for the stochastic\nvariant, we develop an algorithm that uses optimization techniques specific to\nthe entropy-based objective used. For instance, for min-guess entropy, we used\nmixed integer-linear programming. We apply the algorithm to a threat model\nwhere the attacker gets to make functional observations, that is, where she\nobserves the running time of the program for the same secret value combined\nwith different public input values. Existing mitigation approaches do not give\nconfidentiality or performance guarantees for this threat model. We evaluate\nour tool SCHMIT on a number of micro-benchmarks and real-world applications\nwith different entropy-based objectives. In contrast to the existing mitigation\napproaches, we show that in the functional-observation threat model, SCHMIT is\nscalable and able to maximize confidentiality under the performance overhead\nbound.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 05:50:51 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Tizpaz-Niari", "Saeid", ""], ["Cerny", "Pavol", ""], ["Trivedi", "Ashutosh", ""]]}, {"id": "1906.09084", "submitter": "Paul Prasse", "authors": "Paul Prasse and Rene Knaebel and Lukas Machlica and Tomas Pevny and\n  Tobias Scheffer", "title": "Joint Detection of Malicious Domains and Infected Clients", "comments": "Mach Learn (2019)", "journal-ref": null, "doi": "10.1007/s10994-019-05789-z", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Detection of malware-infected computers and detection of malicious web\ndomains based on their encrypted HTTPS traffic are challenging problems,\nbecause only addresses, timestamps, and data volumes are observable. The\ndetection problems are coupled, because infected clients tend to interact with\nmalicious domains. Traffic data can be collected at a large scale, and\nantivirus tools can be used to identify infected clients in retrospect.\nDomains, by contrast, have to be labeled individually after forensic analysis.\nWe explore transfer learning based on sluice networks; this allows the\ndetection models to bootstrap each other. In a large-scale experimental study,\nwe find that the model outperforms known reference models and detects\npreviously unknown malware, previously unknown malware families, and previously\nunknown malicious domains.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 11:50:29 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Prasse", "Paul", ""], ["Knaebel", "Rene", ""], ["Machlica", "Lukas", ""], ["Pevny", "Tomas", ""], ["Scheffer", "Tobias", ""]]}, {"id": "1906.09116", "submitter": "Adria Gascon", "authors": "Borja Balle, James Bell, Adria Gascon, Kobbi Nissim", "title": "Differentially Private Summation with Multi-Message Shuffling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent work, Cheu et al. (Eurocrypt 2019) proposed a protocol for\n$n$-party real summation in the shuffle model of differential privacy with\n$O_{\\epsilon, \\delta}(1)$ error and $\\Theta(\\epsilon\\sqrt{n})$ one-bit messages\nper party. In contrast, every local model protocol for real summation must\nincur error $\\Omega(1/\\sqrt{n})$, and there exist protocols matching this lower\nbound which require just one bit of communication per party. Whether this gap\nin number of messages is necessary was left open by Cheu et al.\n  In this note we show a protocol with $O(1/\\epsilon)$ error and\n$O(\\log(n/\\delta))$ messages of size $O(\\log(n))$ per party. This protocol is\nbased on the work of Ishai et al.\\ (FOCS 2006) showing how to implement\ndistributed summation from secure shuffling, and the observation that this\nallows simulating the Laplace mechanism in the shuffle model.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 09:45:21 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 14:32:33 GMT"}, {"version": "v3", "created": "Wed, 21 Aug 2019 18:36:00 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Balle", "Borja", ""], ["Bell", "James", ""], ["Gascon", "Adria", ""], ["Nissim", "Kobbi", ""]]}, {"id": "1906.09181", "submitter": "Nikita Samarin", "authors": "Nikita Samarin, Donald Sannella", "title": "A Key to Your Heart: Biometric Authentication Based on ECG Signals", "comments": "Appears in the \"Who Are You?! Adventures in Authentication\" workshop\n  (WAY 2019) co-located with the Symposium on Usable Privacy and Security\n  (SOUPS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there has been a shift of interest towards the field of\nbiometric authentication, which proves the identity of the user using their\nbiological characteristics. We explore a novel biometric based on the\nelectrical activity of the human heart in the form of electrocardiogram (ECG)\nsignals. In order to explore the stability of ECG as a biometric, we collect\ndata from 55 participants over two sessions with a period of 4 months in\nbetween. We also use a consumer-grade ECG monitor that is more affordable and\nusable than a medical-grade counterpart. Using a standard approach to evaluate\nour classifier, we obtain error rates of 2.4% for data collected within one\nsession and 9.7% for data collected across two sessions. The experimental\nresults suggest that ECG signals collected using a consumer-grade monitor can\nbe successfully used for user authentication.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 15:04:23 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Samarin", "Nikita", ""], ["Sannella", "Donald", ""]]}, {"id": "1906.09314", "submitter": "Christian Cachin", "authors": "Christian Cachin, Bj\\\"orn Tackmann", "title": "Asymmetric Distributed Trust", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quorum systems are a key abstraction in distributed fault-tolerant computing\nfor capturing trust assumptions. They can be found at the core of many\nalgorithms for implementing reliable broadcasts, shared memory, consensus and\nother problems. This paper introduces asymmetric Byzantine quorum systems that\nmodel subjective trust. Every process is free to choose which combinations of\nother processes it trusts and which ones it considers faulty. Asymmetric quorum\nsystems strictly generalize standard Byzantine quorum systems, which have only\none global trust assumption for all processes. This work also presents\nprotocols that implement abstractions of shared memory and broadcast primitives\nwith processes prone to Byzantine faults and asymmetric trust. The model and\nprotocols pave the way for realizing more elaborate algorithms with asymmetric\ntrust.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 20:47:40 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Cachin", "Christian", ""], ["Tackmann", "Bj\u00f6rn", ""]]}, {"id": "1906.09330", "submitter": "Chris Mitchell", "authors": "Chris J Mitchell", "title": "The Saeed-Liu-Tian-Gao-Li authenticated key agreement protocol is\n  insecure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recently proposed authenticated key agreement protocol is shown to be\ninsecure. In particular, one of the two parties is not authenticated, allowing\nan active man in the middle opponent to replay old messages. The protocol is\nessentially an authenticated Diffie-Hellman key agreement scheme, and the lack\nof authentication allows an attacker to replay old messages and have them\naccepted. Moreover, if the ephemeral key used to compute a protocol message is\never compromised, then the key established using the replayed message will also\nbe compromised. Fixing the problem is simple - there are many provably secure\nand standardised protocols which are just as efficient as the flawed scheme.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 21:15:41 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Mitchell", "Chris J", ""]]}, {"id": "1906.09353", "submitter": "Ian Schmutte", "authors": "John M. Abowd and Ian M. Schmutte and William Sexton and Lars Vilhuber", "title": "Suboptimal Provision of Privacy and Statistical Accuracy When They are\n  Public Goods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.TH cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With vast databases at their disposal, private tech companies can compete\nwith public statistical agencies to provide population statistics. However,\nprivate companies face different incentives to provide high-quality statistics\nand to protect the privacy of the people whose data are used. When both privacy\nprotection and statistical accuracy are public goods, private providers tend to\nproduce at least one suboptimally, but it is not clear which. We model a firm\nthat publishes statistics under a guarantee of differential privacy. We prove\nthat provision by the private firm results in inefficiently low data quality in\nthis framework.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 23:42:46 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Abowd", "John M.", ""], ["Schmutte", "Ian M.", ""], ["Sexton", "William", ""], ["Vilhuber", "Lars", ""]]}, {"id": "1906.09423", "submitter": "Behrooz Khadem", "authors": "Behrooz Khadem, Reza Ahmadian", "title": "Comparative study of Joint Image Encryption and Compression Schemes: A\n  Review", "comments": "6 pages, 4 tables. International Journal of Engineering and Applied\n  Sciences (IJEAS), 2019", "journal-ref": "International Journal of Engineering and Applied Sciences (IJEAS)\n  ISSN: 2394-3661, Volume-6, Issue-6, June 2019", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  With the development of imaging methods in wireless communications, enhancing\nthe security and efficiency of image transfer requires image compression and\nencryption schemes. In conventional methods, encryption and compression are two\nseparate processes, therefore an adversary can organize his attack more simply\nbut if these two processes are combined, the output uncertainty increases. As a\nresult, adversaries face more difficulties, and schemes will be more secure.\nThis paper introduces a number of the most important criteria for the\nefficiency and security evaluation of joint image encryption and compression\n(JIEC) schemes. These criteria were then employed to compare the schemes. The\ncomparison results were analysed to propose suggestions and strategies for\nfuture research to develop secure and efficient JIEC schemes.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 10:13:45 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Khadem", "Behrooz", ""], ["Ahmadian", "Reza", ""]]}, {"id": "1906.09456", "submitter": "Huy Kang Kim", "authors": "Hye Min Kim, Hyun Min Song, Jae Woo Seo, Huy Kang Kim", "title": "Andro-Simnet: Android Malware Family Classification Using Social Network\n  Analysis", "comments": "13 pages, 11 figures, dataset link:\n  http://ocslab.hksecurity.net/Datasets/andro-simnet , demo video:\n  https://youtu.be/JmfS-ZtCbg4 , In Proceedings of the 16th Annual Conference\n  on Privacy, Security and Trust (PST), 2018", "journal-ref": "2018 16th Annual Conference on Privacy, Security and Trust (PST),\n  Belfast, 2018, pp. 1-8", "doi": "10.1109/PST.2018.8514216", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the rapid adaptation of mobile devices changes our daily life more\nconveniently, the threat derived from malware is also increased. There are lots\nof research to detect malware to protect mobile devices, but most of them adopt\nonly signature-based malware detection method that can be easily bypassed by\npolymorphic and metamorphic malware. To detect malware and its variants, it is\nessential to adopt behavior-based detection for efficient malware\nclassification. This paper presents a system that classifies malware by using\ncommon behavioral characteristics along with malware families. We measure the\nsimilarity between malware families with carefully chosen features commonly\nappeared in the same family. With the proposed similarity measure, we can\nclassify malware by malware's attack behavior pattern and tactical\ncharacteristics. Also, we apply a community detection algorithm to increase the\nmodularity within each malware family network aggregation. To maintain high\nclassification accuracy, we propose a process to derive the optimal weights of\nthe selected features in the proposed similarity measure. During this process,\nwe find out which features are significant for representing the similarity\nbetween malware samples. Finally, we provide an intuitive graph visualization\nof malware samples which is helpful to understand the distribution and likeness\nof the malware networks. In the experiment, the proposed system achieved 97%\naccuracy for malware classification and 95% accuracy for prediction by K-fold\ncross-validation using the real malware dataset.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 14:48:24 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Kim", "Hye Min", ""], ["Song", "Hyun Min", ""], ["Seo", "Jae Woo", ""], ["Kim", "Huy Kang", ""]]}, {"id": "1906.09525", "submitter": "Chawin Sitawarin", "authors": "Chawin Sitawarin, David Wagner", "title": "Defending Against Adversarial Examples with K-Nearest Neighbor", "comments": "Inadequate experimental evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustness is an increasingly important property of machine learning models\nas they become more and more prevalent. We propose a defense against\nadversarial examples based on a k-nearest neighbor (kNN) on the intermediate\nactivation of neural networks. Our scheme surpasses state-of-the-art defenses\non MNIST and CIFAR-10 against l2-perturbation by a significant margin. With our\nmodels, the mean perturbation norm required to fool our MNIST model is 3.07 and\n2.30 on CIFAR-10. Additionally, we propose a simple certifiable lower bound on\nthe l2-norm of the adversarial perturbation using a more specific version of\nour scheme, a 1-NN on representations learned by a Lipschitz network. Our model\nprovides a nontrivial average lower bound of the perturbation norm, comparable\nto other schemes on MNIST with similar clean accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 00:38:07 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 20:14:50 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Sitawarin", "Chawin", ""], ["Wagner", "David", ""]]}, {"id": "1906.09546", "submitter": "Val\\'erio Rosset", "authors": "Tiago V. Ortiz and Bruno Kimura and J\\'o Ueyama and Val\\'erio Rosset", "title": "Experimental Security Analysis of Controller Software in SDNs: A Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The software defined networking paradigm relies on the programmability of the\nnetwork to automatically perform management and reconfiguration tasks. The\nresult of adopting this programmability feature is twofold: first by designing\nnew solutions and, second, by concurrently making room for the exploitation of\nnew security threats. As a malfunction in the controller software may lead to a\ncollapse of the network, assessing the security of solutions before their\ndeployment, is a major concern in SDNs. In light of this, we have conducted a\ncomprehensive review of the literature on the experimental security analysis of\nthe control plane in SDNs, with an emphasis on vulnerabilities of the\ncontroller software. Additionally, we have introduced a taxonomy of the\ntechniques found in the literature with regard to the experimental security\nanalysis of SDN controller software. Furthermore, a comparative study has been\ncarried out of existing experimental approaches considering the security\nrequirements defined by the Open Network Foundation (ONF). As a result, we\nhighlighted that there is a need for a standardization of the methodologies\nemployed for automated security analysis, that can meet the appropriate\nrequirements, and support the development of reliable and secure software for\nSDNs.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 03:32:11 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Ortiz", "Tiago V.", ""], ["Kimura", "Bruno", ""], ["Ueyama", "J\u00f3", ""], ["Rosset", "Val\u00e9rio", ""]]}, {"id": "1906.09584", "submitter": "Tom Crick", "authors": "Tom Crick and James H. Davenport and Alastair Irons and Tom Prickett", "title": "A UK Case Study on Cybersecurity Education and Accreditation", "comments": "Accepted for the 49th Annual Frontiers in Education Conference (FIE\n  2019); 16 pages, LaTeX", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a national case study-based analysis of the numerous\ndimensions to cybersecurity education and how they are prioritised, implemented\nand accredited; from understanding the interaction of hardware and software,\nmoving from theory to practice (and vice versa), to human factors, policy and\npolitics (as well as various other important facets). A multitude of model\ncurricula and recommendations have been presented and discussed in\ninternational fora in recent years, with varying levels of impact on education,\npolicy and practice. This paper address three key questions: i) what is taught\nand what should be taught for cybersecurity to general computer science\nstudents; ii) should cybersecurity be taught stand-alone or in an integrated\nmanner to general computer science students; and iii) can accreditation by\nnational professional, statutory and regulatory bodies enhance the provision of\ncybersecurity within a body's jurisdiction?\n  Evaluating how cybersecurity is taught in all aspects of computer science is\nclearly a task of considerable size, one that is beyond the scope of this\npaper. Instead a case study-based research approach -- primarily focusing on\nthe UK -- has been adopted to evaluate the evidence of the teaching of\ncybersecurity within general computer science to university-level students.\nThus, in the context of widespread international computer science/engineering\ncurriculum reform, what does this need to embed cybersecurity knowledge and\nskills mean more generally for institutions and educators, and how can we teach\nthis subject more effectively? Through this UK case study, and by contrasting\nwith related initiatives in the US, we demonstrate the positive effect that\nnational accreditation requirements can have, and offer some recommendations\nboth for future research and curriculum developments.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 11:26:13 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 09:44:34 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Crick", "Tom", ""], ["Davenport", "James H.", ""], ["Irons", "Alastair", ""], ["Prickett", "Tom", ""]]}, {"id": "1906.09594", "submitter": "Jason R.C. Nurse Dr", "authors": "Maria Bada and Jason R.C. Nurse", "title": "Developing cybersecurity education and awareness programmes for Small\n  and medium-sized enterprises (SMEs)", "comments": "20 pages, 1 figure", "journal-ref": "Information & Computer Security Journal, Vol. 27 Issue: 3,\n  pp.393-410, 2019", "doi": "10.1108/ICS-07-2018-0080", "report-no": null, "categories": "cs.CR cs.CY cs.GL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: An essential component of an organisation's cybersecurity strategy\nis building awareness and education of online threats, and how to protect\ncorporate data and services. This research article focuses on this topic and\nproposes a high-level programme for cybersecurity education and awareness to be\nused when targeting Small-to-Medium-sized Enterprises/Businesses (SMEs/SMBs) at\na city-level. We ground this programme in existing research as well as unique\ninsight into an ongoing city-based project with similar aims. Findings: We find\nthat whilst literature can be informative at guiding education and awareness\nprogrammes, it may not always reach real-world programmes. On the other hand,\nexisting programmes, such as the one we explored, have great potential but\nthere can also be room for improvement. Knowledge from each of these areas can,\nand should, be combined to the benefit of the academic and practitioner\ncommunities. Originality/value: The study contributes to current research\nthrough the outline of a high-level programme for cybersecurity education and\nawareness targeting SMEs/SMBs. Through this research, we engage in a reflection\nof literature in this space, and present insights into the advances and\nchallenges faced by an on-going programme. These analyses allow us to craft a\nproposal for a core programme that can assist in improving the security\neducation, awareness and training that targets SMEs/SMBs.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 13:13:04 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Bada", "Maria", ""], ["Nurse", "Jason R. C.", ""]]}, {"id": "1906.09613", "submitter": "Daniel Alabi", "authors": "Daniel Alabi", "title": "The Cost of a Reductions Approach to Private Fair Optimization", "comments": "52 Pages, 4 Figures, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Through the lens of information-theoretic reductions, we examine a reductions\napproach to fair optimization and learning where a black-box optimizer is used\nto learn a fair model for classification or regression. Quantifying the\ncomplexity, both statistically and computationally, of making such models\nsatisfy the rigorous definition of differential privacy is our end goal. We\nresolve a few open questions and show applicability to fair machine learning,\nhypothesis testing, and to optimizing non-standard measures of classification\nloss. Furthermore, our sample complexity bounds are tight amongst all\nstrategies that jointly minimize a composition of functions.\n  The reductions approach to fair optimization can be abstracted as the\nconstrained group-objective optimization problem where we aim to optimize an\nobjective that is a function of losses of individual groups, subject to some\nconstraints. We give the first polynomial-time algorithms to solve the problem\nwith $(\\epsilon, 0)$ or $(\\epsilon, \\delta)$ differential privacy guarantees\nwhen defined on a convex decision set (for example, the $\\ell_P$ unit ball)\nwith convex constraints and losses. Accompanying information-theoretic lower\nbounds for the problem are presented. In addition, compared to a previous\nmethod for ensuring differential privacy subject to a relaxed form of the\nequalized odds fairness constraint, the $(\\epsilon, \\delta)$-differentially\nprivate algorithm we present provides asymptotically better sample complexity\nguarantees, resulting in an exponential improvement in certain parameter\nregimes. We introduce a class of bounded divergence linear optimizers, which\ncould be of independent interest, and specialize to pure and approximate\ndifferential privacy.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 17:36:26 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 23:17:07 GMT"}, {"version": "v3", "created": "Mon, 4 Nov 2019 21:49:26 GMT"}, {"version": "v4", "created": "Sun, 23 May 2021 13:29:42 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Alabi", "Daniel", ""]]}, {"id": "1906.09652", "submitter": "Andreea Alexandru", "authors": "Andreea B. Alexandru and George J. Pappas", "title": "Secure Multi-party Computation for Cloud-based Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CR cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this chapter, we will explore the cloud-outsourced privacy-preserving\ncomputation of a controller on encrypted measurements from a (possibly\ndistributed) system, taking into account the challenges introduced by the\ndynamical nature of the data. The privacy notion used in this work is that of\ncryptographic multi-party privacy, i.e., the computation of a functionality\nshould not reveal anything more than what can be inferred only from the inputs\nand outputs of the functionality. The main theoretical concept used towards\nthis goal is Homomorphic Encryption, which allows the evaluation of sums and\nproducts on encrypted data, and, when combined with other cryptographic\ntechniques, such as Secret Sharing, results in a powerful tool for solving a\nwide range of secure multi-party problems. We will rigorously define these\nconcepts and discuss how multi-party privacy can be enforced in the\nimplementation of a Model Predictive Controller, which encompasses computing\nstabilizing control actions by solving an optimization problem on encrypted\ndata.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 21:17:33 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Alexandru", "Andreea B.", ""], ["Pappas", "George J.", ""]]}, {"id": "1906.09679", "submitter": "Farhad Farokhi", "authors": "Nan Wu, Farhad Farokhi, David Smith, Mohamed Ali Kaafar", "title": "The Value of Collaboration in Convex Machine Learning with Differential\n  Privacy", "comments": "Accepted in IEEE S&P 2020", "journal-ref": "IEEE Symposium on Security and Privacy 2020 (IEEE SP 2020)", "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we apply machine learning to distributed private data owned by\nmultiple data owners, entities with access to non-overlapping training\ndatasets. We use noisy, differentially-private gradients to minimize the\nfitness cost of the machine learning model using stochastic gradient descent.\nWe quantify the quality of the trained model, using the fitness cost, as a\nfunction of privacy budget and size of the distributed datasets to capture the\ntrade-off between privacy and utility in machine learning. This way, we can\npredict the outcome of collaboration among privacy-aware data owners prior to\nexecuting potentially computationally-expensive machine learning algorithms.\nParticularly, we show that the difference between the fitness of the trained\nmachine learning model using differentially-private gradient queries and the\nfitness of the trained machine model in the absence of any privacy concerns is\ninversely proportional to the size of the training datasets squared and the\nprivacy budget squared. We successfully validate the performance prediction\nwith the actual performance of the proposed privacy-aware learning algorithms,\napplied to: financial datasets for determining interest rates of loans using\nregression; and detecting credit card frauds using support vector machines.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 00:57:15 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Wu", "Nan", ""], ["Farokhi", "Farhad", ""], ["Smith", "David", ""], ["Kaafar", "Mohamed Ali", ""]]}, {"id": "1906.09682", "submitter": "Sandra Siby", "authors": "Sandra Siby, Marc Juarez, Claudia Diaz, Narseo Vallina-Rodriguez and\n  Carmela Troncoso", "title": "Encrypted DNS --> Privacy? A Traffic Analysis Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtually every connection to an Internet service is preceded by a DNS lookup\nwhich is performed without any traffic-level protection, thus enabling\nmanipulation, redirection, surveillance, and censorship. To address these\nissues, large organizations such as Google and Cloudflare are deploying\nrecently standardized protocols that encrypt DNS traffic between end users and\nrecursive resolvers such as DNS-over-TLS (DoT) and DNS-over-HTTPS (DoH). In\nthis paper, we examine whether encrypting DNS traffic can protect users from\ntraffic analysis-based monitoring and censoring. We propose a novel feature set\nto perform the attacks, as those used to attack HTTPS or Tor traffic are not\nsuitable for DNS' characteristics. We show that traffic analysis enables the\nidentification of domains with high accuracy in closed and open world settings,\nusing 124 times less data than attacks on HTTPS flows. We find that factors\nsuch as location, resolver, platform, or client do mitigate the attacks\nperformance but they are far from completely stopping them. Our results\nindicate that DNS-based censorship is still possible on encrypted DNS traffic.\nIn fact, we demonstrate that the standardized padding schemes are not\neffective. Yet, Tor -- which does not effectively mitigate traffic analysis\nattacks on web traffic -- is a good defense against DoH traffic analysis.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 01:05:29 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 05:32:54 GMT"}, {"version": "v3", "created": "Sun, 6 Oct 2019 21:37:29 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Siby", "Sandra", ""], ["Juarez", "Marc", ""], ["Diaz", "Claudia", ""], ["Vallina-Rodriguez", "Narseo", ""], ["Troncoso", "Carmela", ""]]}, {"id": "1906.09687", "submitter": "Linan Huang", "authors": "Linan Huang, Quanyan Zhu", "title": "A Dynamic Games Approach to Proactive Defense Strategies against\n  Advanced Persistent Threats in Cyber-Physical Systems", "comments": null, "journal-ref": null, "doi": "10.1016/j.cose.2019.101660", "report-no": null, "categories": "cs.GT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced Persistent Threats (APTs) have recently emerged as a significant\nsecurity challenge for a cyber-physical system due to their stealthy, dynamic\nand adaptive nature. Proactive dynamic defenses provide a strategic and\nholistic security mechanism to increase the costs of attacks and mitigate the\nrisks. This work proposes a dynamic game framework to model a long-term\ninteraction between a stealthy attacker and a proactive defender. The stealthy\nand deceptive behaviors are captured by the multi-stage game of incomplete\ninformation, where each player has his own private information unknown to the\nother. Both players act strategically according to their beliefs which are\nformed by the multi-stage observation and learning. The perfect Bayesian Nash\nequilibrium provides a useful prediction of both players' policies because no\nplayers benefit from unilateral deviations from the equilibrium. We propose an\niterative algorithm to compute the perfect Bayesian Nash equilibrium and use\nthe Tennessee Eastman process as a benchmark case study. Our numerical\nexperiment corroborates the analytical results and provides further insights\ninto the design of proactive defense-in-depth strategies.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 01:45:09 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 15:40:47 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Huang", "Linan", ""], ["Zhu", "Quanyan", ""]]}, {"id": "1906.09715", "submitter": "Ayush Kumar", "authors": "Ayush Kumar and Teng Joon Lim", "title": "EDIMA: Early Detection of IoT Malware Network Activity Using Machine\n  Learning Techniques", "comments": null, "journal-ref": "Proceedings of the IEEE 5th World Forum on Internet of Things\n  (WF-IoT) 2019", "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread adoption of Internet of Things has led to many security\nissues. Post the Mirai-based DDoS attack in 2016 which compromised IoT devices,\na host of new malware using Mirai's leaked source code and targeting IoT\ndevices have cropped up, e.g. Satori, Reaper, Amnesia, Masuta etc. These\nmalware exploit software vulnerabilities to infect IoT devices instead of open\nTELNET ports (like Mirai) making them more difficult to block using existing\nsolutions such as firewalls. In this research, we present EDIMA, a distributed\nmodular solution which can be used towards the detection of IoT malware network\nactivity in large-scale networks (e.g. ISP, enterprise networks) during the\nscanning/infecting phase rather than during an attack. EDIMA employs machine\nlearning algorithms for edge devices' traffic classification, a packet traffic\nfeature vector database, a policy module and an optional packet sub-sampling\nmodule. We evaluate the classification performance of EDIMA through testbed\nexperiments and present the results obtained.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 04:18:38 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Kumar", "Ayush", ""], ["Lim", "Teng Joon", ""]]}, {"id": "1906.09721", "submitter": "Farhad Farokhi", "authors": "Farhad Farokhi", "title": "A Game-Theoretic Approach to Adversarial Linear Support Vector\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we employ a game-theoretic model to analyze the interaction\nbetween an adversary and a classifier. There are two classes (i.e., positive\nand negative classes) to which data points can belong. The adversary is\ninterested in maximizing the probability of miss-detection for the positive\nclass (i.e., false negative probability). The adversary however does not want\nto significantly modify the data point so that it still maintains favourable\ntraits of the original class. The classifier, on the other hand, is interested\nin maximizing the probability of correct detection for the positive class\n(i.e., true positive probability) subject to a lower-bound on the probability\nof correct detection for the negative class (i.e., true negative probability).\nFor conditionally Gaussian data points (conditioned on the class) and linear\nsupport vector machine classifiers, we rewrite the optimization problems of the\nadversary and the classifier as convex optimization problems and use best\nresponse dynamics to learn an equilibrium of the game. This results in\ncomputing a linear support vector machine classifier that is robust against\nadversarial input manipulations. We illustrate the framework on a synthetic\ndataset and a public Cardiovascular Disease dataset.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 04:49:09 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Farokhi", "Farhad", ""]]}, {"id": "1906.09765", "submitter": "Dudi Nassi", "authors": "Dudi Nassi, Raz Ben-Netanel, Yuval Elovici, Ben Nassi", "title": "MobilBye: Attacking ADAS with Camera Spoofing", "comments": "Video Demonstration -\n  https://www.youtube.com/watch?v=PP-qTdRugEI&feature=youtu.be", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Advanced driver assistance systems (ADASs) were developed to reduce the\nnumber of car accidents by issuing driver alert or controlling the vehicle. In\nthis paper, we tested the robustness of Mobileye, a popular external ADAS. We\ninjected spoofed traffic signs into Mobileye to assess the influence of\nenvironmental changes (e.g., changes in color, shape, projection speed,\ndiameter and ambient light) on the outcome of an attack. To conduct this\nexperiment in a realistic scenario, we used a drone to carry a portable\nprojector which projected the spoofed traffic sign on a driving car. Our\nexperiments show that it is possible to fool Mobileye so that it interprets the\ndrone carried spoofed traffic sign as a real traffic sign.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 07:49:54 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Nassi", "Dudi", ""], ["Ben-Netanel", "Raz", ""], ["Elovici", "Yuval", ""], ["Nassi", "Ben", ""]]}, {"id": "1906.09786", "submitter": "Asaf Shabtai", "authors": "Orly Stan, Ron Bitton, Michal Ezrets, Moran Dadon, Masaki Inokuchi,\n  Yoshinobu Ohta, Yoshiyuki Yamada, Tomohiko Yagyu, Yuval Elovici, Asaf Shabtai", "title": "Extending Attack Graphs to Represent Cyber-Attacks in Communication\n  Protocols and Modern IT Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An attack graph is a method used to enumerate the possible paths that an\nattacker can execute in the organization network. MulVAL is a known open-source\nframework used to automatically generate attack graphs. MulVAL's default\nmodeling has two main shortcomings. First, it lacks the representation of\nnetwork protocol vulnerabilities, and thus it cannot be used to model common\nnetwork attacks such as ARP poisoning, DNS spoofing, and SYN flooding. Second,\nit does not support advanced types of communication such as wireless and bus\ncommunication, and thus it cannot be used to model cyber-attacks on networks\nthat include IoT devices or industrial components. In this paper, we present an\nextended network security model for MulVAL that: (1) considers the physical\nnetwork topology, (2) supports short-range communication protocols (e.g.,\nBluetooth), (3) models vulnerabilities in the design of network protocols, and\n(4) models specific industrial communication architectures. Using the proposed\nextensions, we were able to model multiple attack techniques including:\nspoofing, man-in-the-middle, and denial of service, as well as attacks on\nadvanced types of communication. We demonstrate the proposed model on a testbed\nimplementing a simplified network architecture comprised of both IT and\nindustrial components.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 08:45:19 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Stan", "Orly", ""], ["Bitton", "Ron", ""], ["Ezrets", "Michal", ""], ["Dadon", "Moran", ""], ["Inokuchi", "Masaki", ""], ["Ohta", "Yoshinobu", ""], ["Yamada", "Yoshiyuki", ""], ["Yagyu", "Tomohiko", ""], ["Elovici", "Yuval", ""], ["Shabtai", "Asaf", ""]]}, {"id": "1906.09791", "submitter": "Mehmet Aydar", "authors": "Mehmet Aydar and Serkan Ayvaz and Salih Cemil Cetin", "title": "Towards a Blockchain based digital identity verification, record\n  attestation and record sharing system", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Covid-19 pandemic has made individuals and organizations to rethink the\nway of handling identity verification and credentials sharing particularly in\nquarantined situations. In this study, we investigate the inefficiencies of\ntraditional identity systems, and discuss how a proper implementation of\nBlockchain technology would result in safer, more secure, privacy respecting\nand remote friendly identity systems. As a result, we propose a Blockchain\nbased framework for digital identity verification, record attestation and\nrecord sharing, and we explain the framework in details with certain use cases.\nOur proposed framework promotes individuals to fully control their identity\ndata and govern the level of the identity data sharing.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 08:52:32 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 13:19:00 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Aydar", "Mehmet", ""], ["Ayvaz", "Serkan", ""], ["Cetin", "Salih Cemil", ""]]}, {"id": "1906.09829", "submitter": "Stefano Braghin", "authors": "Spiros Antonatos, Stefano Braghin, Naoise Holohan, Pol MacAonghusa", "title": "AnonTokens: tracing re-identification attacks through decoy records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy is of the utmost concern when it comes to releasing data to third\nparties. Data owners rely on anonymization approaches to safeguard the released\ndatasets against re-identification attacks. However, even with strict\nanonymization in place, re-identification attacks are still a possibility and\nin many cases a reality. Prior art has focused on providing better\nanonymization algorithms with minimal loss of information and how to prevent\ndata disclosure attacks. Our approach tries to tackle the issue of tracing\nre-identification attacks based on the concept of honeytokens, decoy or \"bait\"\nrecords with the goal to lure malicious users. While the concept of honeytokens\nhas been widely used in the security domain, this is the first approach to\napply the concept on the data privacy domain. Records with high\nre-identification risk, called AnonTokens, are inserted into anonymized\ndatasets. This work demonstrates the feasibility, detectability and usability\nof AnonTokens and provides promising results for data owners who want to apply\nour approach to real use cases. We evaluated our concept with real large-scale\npopulation datasets. The results show that the introduction of decoy tokens is\nfeasible without significant impact on the released dataset.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 10:11:59 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Antonatos", "Spiros", ""], ["Braghin", "Stefano", ""], ["Holohan", "Naoise", ""], ["MacAonghusa", "Pol", ""]]}, {"id": "1906.09968", "submitter": "Mohamed Baza", "authors": "Mohamed Baza, Noureddine Lasla, Mohamed Mahmoud, Gautam Srivastava and\n  Mohamed Abdallah", "title": "B-Ride: Ride Sharing with Privacy-preservation, Trust and Fair Payment\n  atop Public Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ride-sharing is a service that enables drivers to share their trips with\nother riders, contributing to appealing benefits of shared travel costs.\nHowever, the majority of existing platforms rely on a central third party,\nwhich make them subject to a single point of failure and privacy disclosure\nissues. Moreover, they are vulnerable to DDoS and Sybil attacks due to\nmalicious users involvement. Besides, high fees should be paid to the service\nprovider. In this paper, we propose a decentralized ride-sharing service based\non public Blockchain, named B-Ride. Both riders and drivers can find rides\nmatch while preserving their trip data, including pick-up/drop-off location,\nand departure/arrival date. However, under the anonymity of the public\nblockchain, a malicious user may submit multiple ride requests or offers, while\nnot committing to any of them, to discover better offer or to make the system\nunreliable. B-Ride solves this problem by introducing a time-locked deposit\nprotocol for a ride-sharing by leveraging smart contract and zero-knowledge set\nmembership proof. In a nutshell, both a driver and a rider have to show their\ncommitment by sending a deposit to the blockchain. Later, a driver has to prove\nto the blockchain on the agreed departure time that he has arrived at the\npick-up location. To preserve rider/driver location privacy by hiding the exact\npick-up location, the proof is done using zero-knowledge set membership\nprotocol. Moreover, to ensure a fair payment, a pay-as-you-drive methodology is\nintroduced based on the elapsed distance of the driver and the rider. Also, we\nintroduce a reputation-based trust model to rate drivers based on their past\ntrips to allow riders to select them based on their history on the system.\nFinally, we implement B-Ride in a test net of Ethereum. The experiment results\nshow the applicability of our protocol atop the existing real-world blockchain.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 17:40:37 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 21:41:46 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Baza", "Mohamed", ""], ["Lasla", "Noureddine", ""], ["Mahmoud", "Mohamed", ""], ["Srivastava", "Gautam", ""], ["Abdallah", "Mohamed", ""]]}, {"id": "1906.10207", "submitter": "Qi Zhang", "authors": "Qi Zhang, Carla Seatzu, Zhiwu Li, Alessandro Giua", "title": "State estimation under attack in partially-observed discrete event\n  systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of state estimation in the setting of partially-observed discrete\nevent systems subject to cyber attacks is considered. An operator observes a\nplant through a natural projection that hides the occurrence of certain events.\nThe objective of the operator is that of estimating the current state of the\nsystem. The observation is corrupted by an attacker which can insert and erase\nsome sensor readings with the aim of altering the state estimation of the\noperator. Furthermore, the attacker wants to remain stealthy, namely the\noperator should not realize that its observation has been corrupted. An\nautomaton, called attack structure, is defined to describe the set of all\npossible attacks. In more details, first, an unbounded attack structure is\nobtained by concurrent composition of two state observers, the attacker\nobserver and the operator observer. Then, the attack structure is refined to\nobtain a supremal stealthy attack substructure. An attack function may be\nselected from the supremal stealthy attack substructure and it is said harmful\nwhen some malicious goal of the attacker is reached, namely if the set of\nstates consistent with the observation produced by the system and the set of\nstates consistent with the corrupted observation belong to a given relation.\nThe proposed approach can be dually used to verify if there exists a harmful\nattack for the given system: this allows one to establish if the system is safe\nunder attack.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 06:11:57 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 09:58:33 GMT"}, {"version": "v3", "created": "Thu, 14 Jan 2021 12:45:36 GMT"}, {"version": "v4", "created": "Thu, 29 Jul 2021 08:47:05 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Zhang", "Qi", ""], ["Seatzu", "Carla", ""], ["Li", "Zhiwu", ""], ["Giua", "Alessandro", ""]]}, {"id": "1906.10229", "submitter": "Ron Bitton", "authors": "Ron Bitton, Kobi Boymgold, Rami Puzis and Asaf Shabtai", "title": "Evaluating the Information Security Awareness of Smartphone Users", "comments": "Under review in NDSS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information security awareness (ISA) is a practice focused on the set of\nskills, which help a user successfully mitigate a social engineering attack.\nPrevious studies have presented various methods for evaluating the ISA of both\nPC and mobile users. These methods rely primarily on subjective data sources\nsuch as interviews, surveys, and questionnaires that are influenced by human\ninterpretation and sincerity. Furthermore, previous methods for evaluating ISA\ndid not address the differences between classes of social engineering attacks.\nIn this paper, we present a novel framework designed for evaluating the ISA of\nsmartphone users to specific social engineering attack classes. In addition to\nquestionnaires, the proposed framework utilizes objective data sources: a\nmobile agent and a network traffic monitor; both of which are used to analyze\nthe actual behavior of users. We empirically evaluated the ISA scores assessed\nfrom the three data sources (namely, the questionnaires, mobile agent, and\nnetwork traffic monitor) by conducting a long-term user study involving 162\nsmartphone users. All participants were exposed to four different security\nchallenges that resemble real-life social engineering attacks. These challenges\nwere used to assess the ability of the proposed framework to derive a relevant\nISA score. The results of our experiment show that: (1) the self-reported\nbehavior of the users differs significantly from their actual behavior; and (2)\nISA scores derived from data collected by the mobile agent or the network\ntraffic monitor are highly correlated with the users' success in mitigating\nsocial engineering attacks.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 21:01:08 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Bitton", "Ron", ""], ["Boymgold", "Kobi", ""], ["Puzis", "Rami", ""], ["Shabtai", "Asaf", ""]]}, {"id": "1906.10238", "submitter": "Bin Zhao", "authors": "Bin Zhao", "title": "Mapping System Level Behaviors with Android APIs via System Call\n  Dependence Graphs", "comments": "14 pages, 6 figures", "journal-ref": "12th International Conference on Security and its Applications\n  (CNSA 2019), Volume 9, Number 6, May 2019, pp. 139-152, 2019", "doi": "10.5121/csit.2019.90612", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Due to Android's open source feature and low barriers to entry for\ndevelopers, millions of developers and third-party organizations have been\nattracted into the Android ecosystem. However, over 90 percent of mobile\nmalware are found targeted on Android. Though Android provides multiple\nsecurity features and layers to protect user data and system resources, there\nare still some over-privileged applications in Google Play Store or third-party\nAndroid app stores at wild. In this paper, we proposed an approach to map\nsystem level behavior and Android APIs, based on the observation that system\nlevel behaviors cannot be avoided but sensitive Android APIs could be evaded.\nTo the best of our knowledge, our approach provides the first work to map\nsystem level behavior and Android APIs through System Call Dependence Graphs.\nThe study also shows that our approach can effectively identify potential\npermission abusing, with almost negligible performance impact.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 21:20:28 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Zhao", "Bin", ""]]}, {"id": "1906.10272", "submitter": "Ghada Almashaqbeh", "authors": "Ghada Almashaqbeh, Kevin Kelley, Allison Bishop, Justin Cappos", "title": "CAPnet: A Defense Against Cache Accounting Attacks on Content\n  Distribution Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peer-assisted content distribution networks(CDNs) have emerged to improve\nperformance and reduce deployment costs of traditional, infrastructure-based\ncontent delivery networks. This is done by employing peer-to-peer data\ntransfers to supplement the resources of the network infrastructure. However,\nthese hybrid systems are vulnerable to accounting attacks in which the peers,\nor caches, collude with clients in order to report that content was transferred\nwhen it was not. This is a particular issue in systems that incentivize cache\nparticipation, because malicious caches may collect rewards from the content\npublishers operating the CDN without doing any useful work.\n  In this paper, we introduce CAPnet, the first technique that lets untrusted\ncaches join a peer-assisted CDN while providing a bound on the effectiveness of\naccounting attacks. At its heart is a lightweight cache accountability puzzle\nthat clients must solve before caches are given credit. This puzzle requires\ncolocating the data a client has requested, so its solution confirms that the\ncontent (or at least an amount of data within a pre-configured bound) has\nactually been retrieved. We analyze the security and overhead of our scheme in\nrealistic scenarios. The results show that a modest client machine using a\nsingle core can solve puzzles at a rate sufficient to simultaneously watch\ndozens of 1080p videos. The technique is designed to be even more scalable on\nthe server side. In our experiments, one core of a single low-end machine is\nable to generate puzzles for 4.26 Tbps of bandwidth - enabling 870,000 clients\nto concurrently view the same 1080p video. This demonstrates that our scheme\ncan ensure cache accountability without degrading system productivity.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 00:21:05 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Almashaqbeh", "Ghada", ""], ["Kelley", "Kevin", ""], ["Bishop", "Allison", ""], ["Cappos", "Justin", ""]]}, {"id": "1906.10362", "submitter": "Lijin Quan", "authors": "Lijin Quan, Lei Wu, Haoyu Wang", "title": "EVulHunter: Detecting Fake Transfer Vulnerabilities for EOSIO's Smart\n  Contracts at Webassembly-level", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As one of the representative Delegated Proof-of-Stake (DPoS) blockchain\nplatforms, EOSIO's ecosystem grows rapidly in recent years. A number of\nvulnerabilities and corresponding attacks of EOSIO's smart contracts have been\ndiscovered and observed in the wild, which caused a large amount of financial\ndamages. However, the majority of EOSIO's smart contracts are not open-sourced.\nAs a result, the WebAssembly code may become the only available object to be\nanalyzed in most cases. Unfortunately, current tools are web-application\noriented and cannot be applied to EOSIO WebAssembly code directly, which makes\nit more difficult to detect vulnerabilities from those smart contracts. In this\npaper, we propose \\toolname, a static analysis tool that can be used to detect\nvulnerabilities from EOSIO WASM code automatically. We focus on one particular\ntype of vulnerabilities named \\textit{fake-transfer}, and the exploitation of\nsuch vulnerabilities has led to millions of dollars in damages. To the best of\nour knowledge, it is the first attempt to build an automatic tool to detect\nvulnerabilities of EOSIO's smart contracts. The experimental results\ndemonstrate that our tool is able to detect fake transfer vulnerabilities\nquickly and precisely. EVulHunter is available on GitHub\\footnote{Tool and\nbenchmarks: https://github.com/EVulHunter/EVulHunter} and YouTube\\footnote{Demo\nvideo: https://youtu.be/5SJ0ZJKVZvw}.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 07:41:13 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Quan", "Lijin", ""], ["Wu", "Lei", ""], ["Wang", "Haoyu", ""]]}, {"id": "1906.10395", "submitter": "Teodora Baluta", "authors": "Teodora Baluta and Shiqi Shen and Shweta Shinde and Kuldeep S. Meel\n  and Prateek Saxena", "title": "Quantitative Verification of Neural Networks And its Security\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are increasingly employed in safety-critical domains. This\nhas prompted interest in verifying or certifying logically encoded properties\nof neural networks. Prior work has largely focused on checking existential\nproperties, wherein the goal is to check whether there exists any input that\nviolates a given property of interest. However, neural network training is a\nstochastic process, and many questions arising in their analysis require\nprobabilistic and quantitative reasoning, i.e., estimating how many inputs\nsatisfy a given property. To this end, our paper proposes a novel and\nprincipled framework to quantitative verification of logical properties\nspecified over neural networks. Our framework is the first to provide PAC-style\nsoundness guarantees, in that its quantitative estimates are within a\ncontrollable and bounded error from the true count. We instantiate our\nalgorithmic framework by building a prototype tool called NPAQ that enables\nchecking rich properties over binarized neural networks. We show how emerging\nsecurity analyses can utilize our framework in 3 concrete point applications:\nquantifying robustness to adversarial inputs, efficacy of trojan attacks, and\nfairness/bias of given neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 09:08:03 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Baluta", "Teodora", ""], ["Shen", "Shiqi", ""], ["Shinde", "Shweta", ""], ["Meel", "Kuldeep S.", ""], ["Saxena", "Prateek", ""]]}, {"id": "1906.10416", "submitter": "Ralph Ankele", "authors": "Ralph Ankele, Stefan Marksteiner, Kai Nahrgang, Heribert Vallant", "title": "Requirements and Recommendations for IoT/IIoT Models to automate\n  Security Assurance through Threat Modelling, Security Analysis and\n  Penetration Testing", "comments": "8 pages, Proceedings of the 14th International Conference on\n  Availability, Reliability and Security (ARES 2019) (ARES '19), August 26-29,\n  2019, Canterbury, United Kingdom", "journal-ref": null, "doi": "10.1145/3339252.3341482", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The factories of the future require efficient interconnection of their\nphysical machines into the cyber space to cope with the emerging need of an\nincreased uptime of machines, higher performance rates, an improved level of\nproductivity and a collective collaboration along the supply chain. With the\nrapid growth of the Internet of Things (IoT), and its application in industrial\nareas, the so called Industrial Internet of Things (IIoT)/Industry 4.0 emerged.\nHowever, further to the rapid growth of IoT/IIoT systems, cyber attacks are an\nemerging threat and simple manual security testing can often not cope with the\nscale of large IoT/IIoT networks. In this paper, we suggest to extract metadata\nfrom commonly used diagrams and models in a typical software development\nprocess, to automate the process of threat modelling, security analysis and\npenetration testing, without detailed prior security knowledge. In that\ncontext, we present requirements and recommendations for metadata in IoT/IIoT\nmodels that are needed as necessary input parameters of security assurance\ntools.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 09:43:32 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Ankele", "Ralph", ""], ["Marksteiner", "Stefan", ""], ["Nahrgang", "Kai", ""], ["Vallant", "Heribert", ""]]}, {"id": "1906.10478", "submitter": "Amit Klein", "authors": "Amit Klein, Benny Pinkas", "title": "From IP ID to Device ID and KASLR Bypass (Extended Version)", "comments": "This is an extended paper. The original paper will appear in Usenix\n  Security 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IP headers include a 16-bit ID field. Our work examines the generation of\nthis field in Windows (versions 8 and higher), Linux and Android, and shows\nthat the IP ID field enables remote servers to assign a unique ID to each\ndevice and thus be able to identify subsequent transmissions sent from that\ndevice. This identification works across all browsers and over network changes.\nIn modern Linux and Android versions, this field leaks a kernel address, thus\nwe also break KASLR.\n  Our work includes reverse-engineering of the Windows IP ID generation code,\nand a cryptanalysis of this code and of the Linux kernel IP ID generation code.\nIt provides practical techniques to partially extract the key used by each of\nthese algorithms, overcoming different implementation issues, and observing\nthat this key can identify individual devices. We deployed a demo (for Windows)\nshowing that key extraction and machine fingerprinting works in the wild, and\ntested it from networks around the world.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 12:40:28 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 21:04:57 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Klein", "Amit", ""], ["Pinkas", "Benny", ""]]}, {"id": "1906.10493", "submitter": "Laurel McClure", "authors": "Laurel L. McClure", "title": "Partitioning the Primes and Efficient Non-trivial Factor Generation\n  using the Least Odd Partition Identity in Conjunction with Dirichlet Linear\n  Progressions and the Reduced Residue System Modulo 18", "comments": "4 figures and deterministic algorithm for factor generation/primality\n  testing and Goldbach/Dirichlet \"Seesaw\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we introduce the numerical constant, LOPI, N LOPI is congruent\nto LOPI mod 18, equal to the lowest odd partition identity in conjunction with\nthe reduced residue system Modulo 18, a complete disjoint covering residue\nsystem when considered in its whole set of residues from 0 to 17. By\nconvolution of specific LOPI Dirichlet linear progressions for each LOPI\nsuperset, the non-prime elements of the 6 reduced residue congruence classes\nmod 18 are generated sequentially and uniquely. Through set generation and\ncomplete composite number subset generation based on the pattern of sequential\nfactor generation for all composite numbers in each LOPI congruence class,\nmultiplicity becomes a possible tool to define degree of primality. We show\nthat the lowest sum of the digits of an integer, even or odd, is a constant\nunrestricted partition identity contained each natural number and is equal to\none of the residues in Mod 18. We term this constant the lowest odd or even\npartition identity or LOPI or LEPI. When integers are viewed as partitions of\nthe core LOPI-LEPI value, the infinite natural numbers represent the residues\nof Mod 18 as extended each time toward infinity by sequential cycles of 18.\nLOPI mod 18 is a factor generation system that demonstrates why the primes are\nnot generated through convolution of specific Dirichlet linear progressions\ninto the LOPI non-prime subset matrices, revealing the pattern of the primes to\nbe actually six cyclic patterns. In querying the multiplicity in these 3,4\nspecific non prime matrices we suggest another definition of prime and\nnon-prime based on this multiplicity, where 0 is Prime, 1 is a secondary prime\nand so on. An Ox, Ox3 efficient deterministic algorithm is attached describing\nthe process of factor generation and primality testing.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 13:11:52 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 10:50:26 GMT"}, {"version": "v3", "created": "Mon, 9 Dec 2019 15:56:54 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["McClure", "Laurel L.", ""]]}, {"id": "1906.10611", "submitter": "Omri Shmueli", "authors": "Zvika Brakerski, Omri Shmueli", "title": "(Pseudo) Random Quantum States with Binary Phase", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a quantum information-theoretic conjecture due to Ji, Liu and Song\n(CRYPTO 2018) which suggested that a uniform superposition with random\n\\emph{binary} phase is statistically indistinguishable from a Haar random\nstate. That is, any polynomial number of copies of the aforementioned state is\nwithin exponentially small trace distance from the same number of copies of a\nHaar random state.\n  As a consequence, we get a provable elementary construction of\n\\emph{pseudorandom} quantum states from post-quantum pseudorandom functions.\nGenerating pseduorandom quantum states is desirable for physical applications\nas well as for computational tasks such as quantum money. We observe that\nreplacing the pseudorandom function with a $(2t)$-wise independent function\n(either in our construction or in previous work), results in an explicit\nconstruction for \\emph{quantum state $t$-designs} for all $t$. In fact, we show\nthat the circuit complexity (in terms of both circuit size and depth) of\nconstructing $t$-designs is bounded by that of $(2t)$-wise independent\nfunctions. Explicitly, while in prior literature $t$-designs required linear\ndepth (for $t > 2$), this observation shows that polylogarithmic depth suffices\nfor all $t$.\n  We note that our constructions yield pseudorandom states and state designs\nwith only real-valued amplitudes, which was not previously known. Furthermore,\ngenerating these states require quantum circuit of restricted form: applying\none layer of Hadamard gates, followed by a sequence of Toffoli gates. This\nstructure may be useful for efficiency and simplicity of implementation.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 15:40:41 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 10:05:32 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Brakerski", "Zvika", ""], ["Shmueli", "Omri", ""]]}, {"id": "1906.10625", "submitter": "Ivica Stipovic", "authors": "Ivica Stipovic", "title": "Antiforensic techniques deployed by custom developed malware in evading\n  anti-virus detection", "comments": "20 pages, master thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both malware and antivirus detection tools advance in their capabilities.\nMalware aim is to evade the detection while antivirus is to detect the malware.\nOver time, the detection techniques evolved from simple static signature\nmatching over antiheuristic analysis to machine learning assisted algorithms.\nThis thesis describes several layers of anti-virus evasion deployed by the\nmalware and conducts the analysis of the evasion success rate. The scientific\ncontribution of this research is in the following techniques the malware used\n-- the new algorithm for identifying the Windows operating system functions, a\nnew custom developed obfuscation and de-obfuscation routine and the usage of\nUSB and sound devices enumeration in the anti-heuristic detection. The new PE\nmutation engine facilitates the malware static signature variation. In the next\nstage of the assessment, anti-virus engines then test the malware evasion\ncapabilities. The locally installed antivirus applications and the two\nmulti-scanner online engines inspect the submitted malware samples. The thesis\nexamines the results and discusses the strengths and weaknesses of each evasion\ntechnique.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 10:22:12 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Stipovic", "Ivica", ""]]}, {"id": "1906.10668", "submitter": "Benjamin Wesolowski", "authors": "Thorsten Kleinjung and Benjamin Wesolowski", "title": "Discrete logarithms in quasi-polynomial time in finite fields of fixed\n  characteristic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the discrete logarithm problem can be solved in\nquasi-polynomial expected time in the multiplicative group of finite fields of\nfixed characteristic. More generally, we prove that it can be solved in the\nfield of cardinality $p^n$ in expected time $(pn)^{2\\log_2(n) + O(1)}$.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 17:05:06 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 15:41:32 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Kleinjung", "Thorsten", ""], ["Wesolowski", "Benjamin", ""]]}, {"id": "1906.10684", "submitter": "Wei-Ting Chang", "authors": "Wei-Ting Chang, Ravi Tandon", "title": "On the Upload versus Download Cost for Secure and Private Matrix\n  Multiplication", "comments": "To appear at IEEE Information Theory Workshop (ITW) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of secure and private distributed matrix\nmultiplication. Specifically, we focus on a scenario where a user wants to\ncompute the product of a confidential matrix $A$, with a matrix $B_\\theta$,\nwhere $\\theta\\in\\{1,\\dots,M\\}$. The set of candidate matrices\n$\\{B_1,\\dots,B_M\\}$ are public, and available at all the $N$ servers. The goal\nof the user is to distributedly compute $AB_{\\theta}$, such that $(a)$ no\ninformation is leaked about the matrix $A$ to any server; and $(b)$ the index\n$\\theta$ is kept private from each server. Our goal is to understand the\nfundamental tradeoff between the upload vs download cost for this problem. Our\nmain contribution is to show that the lower convex hull of following (upload,\ndownload) pairs: $(U,D)=(N/(K-1),(K/(K-1))(1+(K/N)+\\dots+(K/N)^{M-1}))$ for\n$K=2,\\dots,N$ is achievable. The scheme improves upon state-of-the-art existing\nschemes for this problem, and leverages ideas from secret sharing and coded\nprivate information retrieval.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 17:59:10 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Chang", "Wei-Ting", ""], ["Tandon", "Ravi", ""]]}, {"id": "1906.10762", "submitter": "Lukas Daniel Klausner", "authors": "Tobias Dam and Lukas Daniel Klausner and Damjan Buhov and Sebastian\n  Schrittwieser", "title": "Large-Scale Analysis of Pop-Up Scam on Typosquatting URLs", "comments": "9 pages, 11 figures", "journal-ref": "Proceedings of the 14th International Conference on Availability,\n  Reliability and Security (ARES 2019), 2019, 53:1-53:9", "doi": "10.1145/3339252.3340332", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, many different types of scams can be found on the internet. Online\ncriminals are always finding new creative ways to trick internet users, be it\nin the form of lottery scams, downloading scam apps for smartphones or fake\ngambling websites. This paper presents a large-scale study on one particular\ndelivery method of online scam: pop-up scam on typosquatting domains.\nTyposquatting describes the concept of registering domains which are very\nsimilar to existing ones while deliberately containing common typing errors;\nthese domains are then used to trick online users while under the belief of\nbrowsing the intended website. Pop-up scam uses JavaScript alert boxes to\npresent a message which attracts the user's attention very effectively, as they\nare a blocking user interface element.\n  Our study among typosquatting domains derived from the Alexa Top 1 Million\nlist revealed on 8255 distinct typosquatting URLs a total of 9857 pop-up\nmessages, out of which 8828 were malicious. The vast majority of those distinct\nURLs (7176) were targeted and displayed pop-up messages to one specific HTTP\nuser agent only. Based on our scans, we present an in-depth analysis as well as\na detailed classification of different targeting parameters (user agent and\nlanguage) which triggered varying kinds of pop-up scams.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 21:12:26 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Dam", "Tobias", ""], ["Klausner", "Lukas Daniel", ""], ["Buhov", "Damjan", ""], ["Schrittwieser", "Sebastian", ""]]}, {"id": "1906.10773", "submitter": "Kang Liu", "authors": "Kang Liu, Haoyu Yang, Yuzhe Ma, Benjamin Tan, Bei Yu, Evangeline F. Y.\n  Young, Ramesh Karri, Siddharth Garg", "title": "Are Adversarial Perturbations a Showstopper for ML-Based CAD? A Case\n  Study on CNN-Based Lithographic Hotspot Detection", "comments": null, "journal-ref": "ACM Trans. Des. Autom. Electron. Syst. 25, 5, Article 48 (August\n  2020)", "doi": "10.1145/3408288", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is substantial interest in the use of machine learning (ML) based\ntechniques throughout the electronic computer-aided design (CAD) flow,\nparticularly those based on deep learning. However, while deep learning methods\nhave surpassed state-of-the-art performance in several applications, they have\nexhibited intrinsic susceptibility to adversarial perturbations --- small but\ndeliberate alterations to the input of a neural network, precipitating\nincorrect predictions. In this paper, we seek to investigate whether\nadversarial perturbations pose risks to ML-based CAD tools, and if so, how\nthese risks can be mitigated. To this end, we use a motivating case study of\nlithographic hotspot detection, for which convolutional neural networks (CNN)\nhave shown great promise. In this context, we show the first adversarial\nperturbation attacks on state-of-the-art CNN-based hotspot detectors;\nspecifically, we show that small (on average 0.5% modified area), functionality\npreserving and design-constraint satisfying changes to a layout can nonetheless\ntrick a CNN-based hotspot detector into predicting the modified layout as\nhotspot free (with up to 99.7% success). We propose an adversarial retraining\nstrategy to improve the robustness of CNN-based hotspot detection and show that\nthis strategy significantly improves robustness (by a factor of ~3) against\nadversarial attacks without compromising classification accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 22:37:39 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Liu", "Kang", ""], ["Yang", "Haoyu", ""], ["Ma", "Yuzhe", ""], ["Tan", "Benjamin", ""], ["Yu", "Bei", ""], ["Young", "Evangeline F. Y.", ""], ["Karri", "Ramesh", ""], ["Garg", "Siddharth", ""]]}, {"id": "1906.10775", "submitter": "Laurent Chuat", "authors": "Laurent Chuat, AbdelRahman Abdou, Ralf Sasse, Christoph Sprenger,\n  David Basin, Adrian Perrig", "title": "SoK: Delegation and Revocation, the Missing Links in the Web's Chain of\n  Trust", "comments": "IEEE European Symposium on Security and Privacy (EuroS&P) 2020", "journal-ref": null, "doi": "10.1109/EuroSP48549.2020.00046", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to quickly revoke a compromised key is critical to the security\nof any public-key infrastructure. Regrettably, most traditional certificate\nrevocation schemes suffer from latency, availability, or privacy problems.\nThese problems are exacerbated by the lack of a native delegation mechanism in\nTLS, which increasingly leads domain owners to engage in dangerous practices\nsuch as sharing their private keys with third parties.\n  We analyze solutions that address the long-standing delegation and revocation\nshortcomings of the web PKI, with a focus on approaches that directly affect\nthe chain of trust (i.e., the X.509 certification path). For this purpose, we\npropose a 19-criteria framework for characterizing revocation and delegation\nschemes. We also show that combining short-lived delegated credentials or proxy\ncertificates with an appropriate revocation system would solve several pressing\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 22:45:20 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 09:58:29 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Chuat", "Laurent", ""], ["Abdou", "AbdelRahman", ""], ["Sasse", "Ralf", ""], ["Sprenger", "Christoph", ""], ["Basin", "David", ""], ["Perrig", "Adrian", ""]]}, {"id": "1906.10817", "submitter": "Songze Li", "authors": "Songze Li, Saeid Sahraei, Mingchao Yu, Salman Avestimehr, Sreeram\n  Kannan, Pramod Viswanath", "title": "Coded State Machine -- Scaling State Machine Execution under Byzantine\n  Faults", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an information-theoretic framework, named Coded State Machine\n(CSM), to securely and efficiently execute multiple state machines on untrusted\nnetwork nodes, some of which are Byzantine. The standard method of solving this\nproblem is using State Machine Replication, which achieves high security at the\ncost of low efficiency. We propose CSM, which achieves the optimal linear\nscaling in storage efficiency, throughput, and security simultaneously with the\nsize of the network. The storage efficiency is scaled via the design of\nLagrange coded states and coded input commands that require the same storage\nsize as their origins. The computational efficiency is scaled using a novel\ndelegation algorithm, called INTERMIX, which is an information-theoretically\nverifiable matrix-vector multiplication algorithm of independent interest.\nUsing INTERMIX, the network nodes securely delegate their coding operations to\na single worker node, and a small group of randomly selected auditor nodes\nverify its correctness, so that computational efficiency can scale almost\nlinearly with the network size, without compromising on security.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 02:39:18 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Li", "Songze", ""], ["Sahraei", "Saeid", ""], ["Yu", "Mingchao", ""], ["Avestimehr", "Salman", ""], ["Kannan", "Sreeram", ""], ["Viswanath", "Pramod", ""]]}, {"id": "1906.10861", "submitter": "Meisam Navaki Arefi", "authors": "Meisam Navaki Arefi, Rajkumar Pandi, Michael Carl Tschantz, Jedidiah\n  R. Crandall, King-wa Fu, Dahlia Qiu Shi, Miao Sha", "title": "Assessing Post Deletion in Sina Weibo: Multi-modal Classification of Hot\n  Topics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Widespread Chinese social media applications such as Weibo are widely known\nfor monitoring and deleting posts to conform to Chinese government\nrequirements. In this paper, we focus on analyzing a dataset of censored and\nuncensored posts in Weibo. Despite previous work that only considers text\ncontent of posts, we take a multi-modal approach that takes into account both\ntext and image content. We categorize this dataset into 14 categories that have\nthe potential to be censored on Weibo, and seek to quantify censorship by\ntopic. Specifically, we investigate how different factors interact to affect\ncensorship. We also investigate how consistently and how quickly different\ntopics are censored. To this end, we have assembled an image dataset with\n18,966 images, as well as a text dataset with 994 posts from 14 categories. We\nthen utilized deep learning, CNN localization, and NLP techniques to analyze\nthe target dataset and extract categories, for further analysis to better\nunderstand censorship mechanisms in Weibo. We found that sentiment is the only\nindicator of censorship that is consistent across the variety of topics we\nidentified. Our finding matches with recently leaked logs from Sina Weibo. We\nalso discovered that most categories like those related to anti-government\nactions (e.g. protest) or categories related to politicians (e.g. Xi Jinping)\nare often censored, whereas some categories such as crisis-related categories\n(e.g. rainstorm) are less frequently censored. We also found that censored\nposts across all categories are deleted in three hours on average.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 06:18:00 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 04:33:23 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Arefi", "Meisam Navaki", ""], ["Pandi", "Rajkumar", ""], ["Tschantz", "Michael Carl", ""], ["Crandall", "Jedidiah R.", ""], ["Fu", "King-wa", ""], ["Shi", "Dahlia Qiu", ""], ["Sha", "Miao", ""]]}, {"id": "1906.10873", "submitter": "Amer Chamseddine", "authors": "Amer Chamseddine and George Candea", "title": "Making Smartphone Application Permissions Meaningful for the Average\n  User", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smartphones hold important private information, yet users routinely expose\nthis information to questionable applications written by developers they know\nnothing about. Users may be tempted to think of smartphones as old-style dumb\nphones, not as powerful network-connected computers, and this opens a gap\nbetween the permissions-based security paradigm (offered by platforms like\nAndroid) and what users expect. This makes it easy to fool users into\ninstalling applications that steal their information. Not surprisingly, Android\nis now a more favored target for hackers than Windows.\n  We propose an approach for closing this gap, based on the observation that\nthe current permissions system--rooted in good ol' UNIX-style thinking--is both\ntoo coarse and too fine grained, because it uses the wrong axes for defining\nthe permissions space. We argue for replacing the paradigm in which \"an app\naccesses device resources\" (which is foreign to most non-geeks) with a paradigm\nin which \"an app accesses user-tangible services.\" By using a simple piece of\nmiddleware, we can wrap this view of application control around today's\npermission system, and, by doing so, no conceptual refactoring of applications\nis required.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 07:00:22 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 05:41:01 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Chamseddine", "Amer", ""], ["Candea", "George", ""]]}, {"id": "1906.10877", "submitter": "Volodymyr Sokolov", "authors": "Volodymyr Buriachok and Volodymyr Sokolov and Pavlo Skladannyi", "title": "Security Rating Metrics for Distributed Wireless Systems", "comments": null, "journal-ref": "Mathematics. Information Technologies. Education (MoMLeT&DS), 2019", "doi": "10.5281/zenodo.3256219", "report-no": null, "categories": "cs.CR cs.PF", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The paper examines quantitative assessment of wireless distribution system\nsecurity, as well as an assessment of risks from attacks and security\nviolations. Furthermore, it describes typical security breach and formal attack\nmodels and five methods for assessing security. The proposed normalized method\nfor assessing the degree of security assurance operates with at least three\ncharacteristics, which allows comparatively analyze heterogeneous information\nsystems. The improved calculating formulas have been proposed for two security\nassessment methods, and the elements of functional-cost analysis have been\napplied to calculate the degree of security. To check the results of the\nanalysis, the coefficient of concordance was calculated, which gives\nopportunity to determine the quality of expert assessment. The simultaneous use\nof several models to describe attacks and the effectiveness of countering them\nallows us to create a comprehensive approach to countering modern security\nthreats to information networks at the commercial enterprises and critical\ninfrastructure facilities.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 07:19:23 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Buriachok", "Volodymyr", ""], ["Sokolov", "Volodymyr", ""], ["Skladannyi", "Pavlo", ""]]}, {"id": "1906.10878", "submitter": "Volodymyr Sokolov", "authors": "Mahyar TajDini and Volodymyr Sokolov and Volodymyr Buriachok", "title": "Men-in-the-Middle Attack Simulation on Low Energy Wireless Devices using\n  Software Define Radio", "comments": null, "journal-ref": "Mathematics. Information Technologies. Education (MoMLeT&DS), 2019", "doi": "10.5281/zenodo.3256223", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The article presents a method of organizing men-in-the-middle attack and\npenetration test on Bluetooth Low Energy devices and ZigBee packets using\nsoftware define radio with sniffing and spoofing packets, capture and analysis\ntechniques on wireless waves with the focus on Bluetooth. The paper contains\nthe analysis of the latest scientific work in this area, provides a comparative\nanalysis of SDRs and the rationale for the choice of hardware, gives the\nsequence of actions for collecting wireless data packets and data collection\nfrom ZigBee and BLE devices, and analyzes ways to improve captured wireless\npacket analysis techniques. For the study collected experimental setup, the\nresults of which are analyzed in real time. The collected wireless data packets\nare compared with those sent. The result of the experiment shows the weaknesses\nof local wireless networks.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 07:21:05 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["TajDini", "Mahyar", ""], ["Sokolov", "Volodymyr", ""], ["Buriachok", "Volodymyr", ""]]}, {"id": "1906.10893", "submitter": "Yang Zhao", "authors": "Yang Zhao, Jun Zhao, Linshan Jiang, Rui Tan, Dusit Niyato, Zengxiang\n  Li, Lingjuan Lyu, Yingbo Liu", "title": "Privacy-Preserving Blockchain-Based Federated Learning for IoT Devices", "comments": "This paper appears in IEEE Internet of Things Journal (IoT-J)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC cs.LG cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Home appliance manufacturers strive to obtain feedback from users to improve\ntheir products and services to build a smart home system. To help manufacturers\ndevelop a smart home system, we design a federated learning (FL) system\nleveraging the reputation mechanism to assist home appliance manufacturers to\ntrain a machine learning model based on customers' data. Then, manufacturers\ncan predict customers' requirements and consumption behaviors in the future.\nThe working flow of the system includes two stages: in the first stage,\ncustomers train the initial model provided by the manufacturer using both the\nmobile phone and the mobile edge computing (MEC) server. Customers collect data\nfrom various home appliances using phones, and then they download and train the\ninitial model with their local data. After deriving local models, customers\nsign on their models and send them to the blockchain. In case customers or\nmanufacturers are malicious, we use the blockchain to replace the centralized\naggregator in the traditional FL system. Since records on the blockchain are\nuntampered, malicious customers or manufacturers' activities are traceable. In\nthe second stage, manufacturers select customers or organizations as miners for\ncalculating the averaged model using received models from customers. By the end\nof the crowdsourcing task, one of the miners, who is selected as the temporary\nleader, uploads the model to the blockchain. To protect customers' privacy and\nimprove the test accuracy, we enforce differential privacy on the extracted\nfeatures and propose a new normalization technique. We experimentally\ndemonstrate that our normalization technique outperforms batch normalization\nwhen features are under differential privacy protection. In addition, to\nattract more customers to participate in the crowdsourcing FL task, we design\nan incentive mechanism to award participants.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 07:53:13 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 16:18:12 GMT"}, {"version": "v3", "created": "Wed, 5 Aug 2020 12:44:38 GMT"}, {"version": "v4", "created": "Mon, 1 Feb 2021 11:25:50 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Zhao", "Yang", ""], ["Zhao", "Jun", ""], ["Jiang", "Linshan", ""], ["Tan", "Rui", ""], ["Niyato", "Dusit", ""], ["Li", "Zengxiang", ""], ["Lyu", "Lingjuan", ""], ["Liu", "Yingbo", ""]]}, {"id": "1906.10908", "submitter": "Tribhuvanesh Orekondy", "authors": "Tribhuvanesh Orekondy, Bernt Schiele, Mario Fritz", "title": "Prediction Poisoning: Towards Defenses Against DNN Model Stealing\n  Attacks", "comments": "ICLR 2020, Project page:\n  https://resources.mpi-inf.mpg.de/d2/orekondy/predpoison/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  High-performance Deep Neural Networks (DNNs) are increasingly deployed in\nmany real-world applications e.g., cloud prediction APIs. Recent advances in\nmodel functionality stealing attacks via black-box access (i.e., inputs in,\npredictions out) threaten the business model of such applications, which\nrequire a lot of time, money, and effort to develop. Existing defenses take a\npassive role against stealing attacks, such as by truncating predicted\ninformation. We find such passive defenses ineffective against DNN stealing\nattacks. In this paper, we propose the first defense which actively perturbs\npredictions targeted at poisoning the training objective of the attacker. We\nfind our defense effective across a wide range of challenging datasets and DNN\nmodel stealing attacks, and additionally outperforms existing defenses. Our\ndefense is the first that can withstand highly accurate model stealing attacks\nfor tens of thousands of queries, amplifying the attacker's error rate up to a\nfactor of 85$\\times$ with minimal impact on the utility for benign users.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 08:32:37 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 10:51:12 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Orekondy", "Tribhuvanesh", ""], ["Schiele", "Bernt", ""], ["Fritz", "Mario", ""]]}, {"id": "1906.10922", "submitter": "Yael Mathov", "authors": "Yael Mathov, Noga Agmon, Asaf Shabtai, Rami Puzis, Nils Ole\n  Tippenhauer, Yuval Elovici", "title": "Challenges for Security Assessment of Enterprises in the IoT Era", "comments": "11 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For years, attack graphs have been an important tool for security assessment\nof enterprise networks, but IoT devices, a new player in the IT world, might\nthreat the reliability of this tool. In this paper, we review the challenges\nthat must be addressed when using attack graphs to model and analyze enterprise\nnetworks that include IoT devices. In addition, we propose novel ideas and\ncountermeasures aimed at addressing these challenges.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 09:06:42 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Mathov", "Yael", ""], ["Agmon", "Noga", ""], ["Shabtai", "Asaf", ""], ["Puzis", "Rami", ""], ["Tippenhauer", "Nils Ole", ""], ["Elovici", "Yuval", ""]]}, {"id": "1906.10928", "submitter": "Harel Berger", "authors": "Harel Berger, Amit Z. Dvir, Moti Geva", "title": "A wrinkle in time: A case study in DNS poisoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Domain Name System (DNS) provides a translation between readable domain\nnames and IP addresses. The DNS is a key infrastructure component of the\nInternet and a prime target for a variety of attacks. One of the most\nsignificant threat to the DNS's wellbeing is a DNS poisoning attack, in which\nthe DNS responses are maliciously replaced, or poisoned, by an attacker. To\nidentify this kind of attack, we start by an analysis of different kinds of\nresponse times. We present an analysis of typical and atypical response times,\nwhile differentiating between the different levels of DNS servers' response\ntimes, from root servers down to internal caching servers. We successfully\nidentify empirical DNS poisoning attacks based on a novel method for DNS\nresponse timing analysis. We then present a system we developed to validate our\ntechnique that does not require any changes to the DNS protocol or any existing\nnetwork equipment. Our validation system tested data from different\narchitectures including LAN and cloud environments and real data from an\nInternet Service Provider (ISP). Our method and system differ from most other\nDNS poisoning detection methods and achieved high detection rates exceeding\n99%. These findings suggest that when used in conjunction with other methods,\nthey can considerably enhance the accuracy of these methods.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 09:24:24 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Berger", "Harel", ""], ["Dvir", "Amit Z.", ""], ["Geva", "Moti", ""]]}, {"id": "1906.10943", "submitter": "Asaf Shabtai", "authors": "Orly Stan, Ron Bitton, Michal Ezrets, Moran Dadon, Masaki Inokuchi,\n  Yoshinobu Ohta, Tomohiko Yagyu, Yuval Elovici, Asaf Shabtai", "title": "Heuristic Approach Towards Countermeasure Selection using Attack Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selecting the optimal set of countermeasures is a challenging task that\ninvolves various considerations and tradeoffs such as prioritizing the risks to\nmitigate and costs. The vast majority of studies for selecting a countermeasure\ndeployment are based on a limited risk assessment procedure that utilizes the\ncommon vulnerability scoring system (CVSS). Such a risk assessment procedure\ndoes not necessarily consider the prerequisites and exploitability of a\nspecific asset, cannot distinguish insider from outsider threat actor, and does\nnot express the consequences of exploiting a vulnerability as well as the\nattacker's lateral movements. Other studies applied a more extensive risk\nassessment procedure that relies on manual work and repeated assessment. These\nsolutions however, do not consider the network topology and do not specify the\noptimal position for deploying the countermeasures, and therefore are less\npractical. In this paper we suggest a heuristic search approach for selecting\nthe optimal countermeasure deployment under a given budget limitation. The\nproposed method expresses the risk of the system using an extended attack graph\nmodeling, which considers the prerequisites and consequences of exploiting a\nvulnerability, examines the attacker's potential lateral movements, and express\nthe physical network topology as well as vulnerabilities in network protocols.\nIn addition, unlike previous studies which utilizes attack graph for\ncountermeasure planning, the proposed methods does not require re-generating\nthe attack graph at each stage of the procedure, which is computationally\nheavy, and therefore it provides a more accurate and practical countermeasure\ndeployment planning process.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 09:56:32 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Stan", "Orly", ""], ["Bitton", "Ron", ""], ["Ezrets", "Michal", ""], ["Dadon", "Moran", ""], ["Inokuchi", "Masaki", ""], ["Ohta", "Yoshinobu", ""], ["Yagyu", "Tomohiko", ""], ["Elovici", "Yuval", ""], ["Shabtai", "Asaf", ""]]}, {"id": "1906.10973", "submitter": "Yifeng Li", "authors": "Yifeng Li, Lingxi Xie, Ya Zhang, Rui Zhang, Yanfeng Wang, Qi Tian", "title": "Defending Adversarial Attacks by Correcting logits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating and eliminating adversarial examples has been an intriguing topic\nin the field of deep learning. While previous research verified that\nadversarial attacks are often fragile and can be defended via image-level\nprocessing, it remains unclear how high-level features are perturbed by such\nattacks. We investigate this issue from a new perspective, which purely relies\non logits, the class scores before softmax, to detect and defend adversarial\nattacks. Our defender is a two-layer network trained on a mixed set of clean\nand perturbed logits, with the goal being recovering the original prediction.\nUpon a wide range of adversarial attacks, our simple approach shows promising\nresults with relatively high accuracy in defense, and the defender can transfer\nacross attackers with similar properties. More importantly, our defender can\nwork in the scenarios that image data are unavailable, and enjoys high\ninterpretability especially at the semantic level.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 11:07:29 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Li", "Yifeng", ""], ["Xie", "Lingxi", ""], ["Zhang", "Ya", ""], ["Zhang", "Rui", ""], ["Wang", "Yanfeng", ""], ["Tian", "Qi", ""]]}, {"id": "1906.10991", "submitter": "Yaniv Saar", "authors": "Gil Einziger, Maayan Goldstein, Yaniv Sa'ar, Itai Segall", "title": "Verifying Robustness of Gradient Boosted Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient boosted models are a fundamental machine learning technique.\nRobustness to small perturbations of the input is an important quality measure\nfor machine learning models, but the literature lacks a method to prove the\nrobustness of gradient boosted models. This work introduces VeriGB, a tool for\nquantifying the robustness of gradient boosted models. VeriGB encodes the model\nand the robustness property as an SMT formula, which enables state of the art\nverification tools to prove the model's robustness. We extensively evaluate\nVeriGB on publicly available datasets and demonstrate a capability for\nverifying large models. Finally, we show that some model configurations tend to\nbe inherently more robust than others.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 11:48:58 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Einziger", "Gil", ""], ["Goldstein", "Maayan", ""], ["Sa'ar", "Yaniv", ""], ["Segall", "Itai", ""]]}, {"id": "1906.11011", "submitter": "Peter Mell", "authors": "Peter Mell, John Kelsey, James Shook", "title": "Cryptocurrency Smart Contracts for Distributed Consensus of Public\n  Randomness", "comments": "16 pages, International Symposium on Stabilization, Safety, and\n  Security of Distributed Systems", "journal-ref": null, "doi": "10.1007/978-3-319-69084-1_31", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most modern electronic devices can produce a random number. However, it is\ndifficult to see how a group of mutually distrusting entities can have\nconfidence in any such hardware-produced stream of random numbers, since the\nproducer could control the output to their gain. In this work, we use public\nand immutable cryptocurrency smart contracts, along with a set of potentially\nmalicious randomness providers, to produce a trustworthy stream of timestamped\npublic random numbers. Our contract eliminates the ability of a producer to\npredict or control the generated random numbers, including the stored history\nof random numbers. We consider and mitigate the threat of collusion between the\nrandomness providers and miners in a second, more complex contract.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 12:10:51 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Mell", "Peter", ""], ["Kelsey", "John", ""], ["Shook", "James", ""]]}, {"id": "1906.11042", "submitter": "Peter Mell", "authors": "Peter Mell", "title": "Managed Blockchain Based Cryptocurrencies with Consensus Enforced Rules\n  and Transparency", "comments": "10 pages, 17th IEEE International Conference On Trust, Security And\n  Privacy In Computing And Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain based cryptocurrencies are usually unmanaged, distributed,\nconsensus-based systems in which no single entity has control. Managed\ncryptocurrencies can be implemented using private blockchains but are\nfundamentally different as the owners have complete control to do arbitrary\nactivity without transparency (since they control the mining). In this work we\nexplore a hybrid approach where a managed cryptocurrency is maintained through\ndistributed consensus based methods. The currency administrator can perform\nongoing management functions while the consensus methods enforce the rules of\nthe cryptocurrency and provide transparency for all management actions. This\nenables the introduction of money management features common in fiat currencies\nbut where the managing entity cannot perform arbitrary actions and transparency\nis enforced. We thus eliminate the need for users to trust the currency\nadministrator but also to enable the administrator to manage the\ncryptocurrency. We demonstrate how to implement our approach through modest\nmodifications to the implicit Bitcoin specification, however, our approach can\nbe applied to most any blockchain based cryptocurrency using a variety of\nconsensus methods.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 12:44:51 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Mell", "Peter", ""]]}, {"id": "1906.11057", "submitter": "Peter Mell", "authors": "Peter Mell, Jim Dray, James Shook", "title": "Smart Contract Federated Identity Management without Third Party\n  Authentication Services", "comments": "12 pages, Open Identity Summit 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated identity management enables users to access multiple systems using\na single login credential. However, to achieve this a complex privacy\ncompromising authentication has to occur between the user, relying party (RP)\n(e.g., a business), and a credential service provider (CSP) that performs the\nauthentication. In this work, we use a smart contract on a blockchain to enable\nan architecture where authentication no longer involves the CSP. Authentication\nis performed solely through user to RP communications (eliminating fees and\nenhancing privacy). No third party needs to be contacted, not even the smart\ncontract. No public key infrastructure (PKI) needs to be maintained. And no\nrevocation lists need to be checked. In contrast to competing smart contract\napproaches, ours is hierarchically managed (like a PKI) enabling better\nvalidation of attribute providers and making it more useful for large entities\nto provide identity services for their constituents (e.g., a government) while\nstill enabling users to maintain a level of self-sovereignty.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 12:55:17 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Mell", "Peter", ""], ["Dray", "Jim", ""], ["Shook", "James", ""]]}, {"id": "1906.11061", "submitter": "Peter Mell", "authors": "Peter Mell, Assane Gueye, Christopher Schanzle", "title": "Quantifying Information Exposure in Internet Routing", "comments": "5 pages, 17th IEEE International Conference On Trust, Security And\n  Privacy In Computing And Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data sent over the Internet can be monitored and manipulated by intermediate\nentities in the data path from the source to the destination. For unencrypted\ncommunications (and some encrypted communications with known weaknesses),\neavesdropping and man-in-the-middle attacks are possible. For encrypted\ncommunication, the identification of the communicating endpoints is still\nrevealed. In addition, encrypted communications may be stored until such time\nas newly discovered weaknesses in the encryption algorithm or advances in\ncomputer hardware render them readable by attackers.\n  In this work, we use public data to evaluate both advertised and observed\nroutes through the Internet and measure the extent to which communications\nbetween pairs of countries are exposed to other countries. We use both physical\nrouter geolocation as well as the country of registration of the companies\nowning each router. We find a high level of information exposure; even\nphysically adjacent countries use routes that involve many other countries. We\nalso found that countries that are well `connected' tend to be more exposed.\nOur analysis indicates that there exists a tradeoff between robustness and\ninformation exposure in the current Internet.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 13:00:21 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Mell", "Peter", ""], ["Gueye", "Assane", ""], ["Schanzle", "Christopher", ""]]}, {"id": "1906.11078", "submitter": "Peter Mell", "authors": "Dylan Yaga, Peter Mell, Nik Roby, Karen Scarfone", "title": "Blockchain Technology Overview", "comments": "68 pages, National Institute of Standards and Technology Internal\n  Report", "journal-ref": null, "doi": "10.6028/NIST.IR.8202", "report-no": null, "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchains are tamper evident and tamper resistant digital ledgers\nimplemented in a distributed fashion (i.e., without a central repository) and\nusually without a central authority (i.e., a bank, company, or government). At\ntheir basic level, they enable a community of users to record transactions in a\nshared ledger within that community, such that under normal operation of the\nblockchain network no transaction can be changed once published. This document\nprovides a high-level technical overview of blockchain technology. The purpose\nis to help readers understand how blockchain technology works.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 13:20:44 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Yaga", "Dylan", ""], ["Mell", "Peter", ""], ["Roby", "Nik", ""], ["Scarfone", "Karen", ""]]}, {"id": "1906.11094", "submitter": "Philipp Morgner", "authors": "Philipp Morgner, Christoph Mai, Nicole Koschate-Fischer, Felix\n  Freiling, Zinaida Benenson", "title": "Security Update Labels: Establishing Economic Incentives for Security\n  Patching of IoT Consumer Products", "comments": "To appear in the Proceedings of the IEEE Symposium on Security and\n  Privacy (S&P) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the expansion of the Internet of Things (IoT), the number of security\nincidents due to insecure and misconfigured IoT devices is increasing.\nEspecially on the consumer market, manufacturers focus on new features and\nearly releases at the expense of a comprehensive security strategy. Hence,\nexperts have started calling for regulation of the IoT consumer market, while\npolicymakers are seeking for suitable regulatory approaches. We investigate how\nmanufacturers can be incentivized to increase sustainable security efforts for\nIoT products. We propose mandatory security update labels that inform consumers\nduring buying decisions about the willingness of the manufacturer to provide\nsecurity updates in the future. Mandatory means that the labels explicitly\nstate when security updates are not guaranteed. We conducted a user study with\nmore than 1,400 participants to assess the importance of security update labels\nfor the consumer choice by means of a conjoint analysis. The results show that\nthe availability of security updates (until which date the updates are\nguaranteed) accounts for 8% to 35% impact on overall consumers' choice,\ndepending on the perceived security risk of the product category. For products\nwith a high perceived security risk, this availability is twice as important as\nother high-ranked product attributes. Moreover, provisioning time for security\nupdates (how quickly the product will be patched after a vulnerability is\ndiscovered) additionally accounts for 7% to 25% impact on consumers' choices.\nThe proposed labels are intuitively understood by consumers, do not require\nproduct assessments by third parties before release, and have a potential to\nincentivize manufacturers to provide sustainable security support.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 13:43:57 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Morgner", "Philipp", ""], ["Mai", "Christoph", ""], ["Koschate-Fischer", "Nicole", ""], ["Freiling", "Felix", ""], ["Benenson", "Zinaida", ""]]}, {"id": "1906.11117", "submitter": "Nikolay Matyunin", "authors": "Nikolay Matyunin, Yujue Wang, Tolga Arul, Kristian Kullmann, Jakub\n  Szefer, Stefan Katzenbeisser", "title": "MagneticSpy: Exploiting Magnetometer in Mobile Devices for Website and\n  Application Fingerprinting", "comments": "Accepted at the Workshop on Privacy in the Electronic Society (WPES),\n  2019", "journal-ref": null, "doi": "10.1145/3338498.3358650", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that aggregate CPU usage and power consumption\ntraces on smartphones can leak information about applications running on the\nsystem or websites visited. In response, access to such data has been blocked\nfor mobile applications starting from Android 8. In this work, we explore a new\nsource of side-channel leakage for this class of attacks. Our method is based\non the fact that electromagnetic activity caused by mobile processors leads to\nnoticeable disturbances in magnetic sensor measurements on mobile devices, with\nthe amplitude being proportional to the CPU workload. Therefore, recorded\nsensor data can be analyzed to reveal information about ongoing activities. The\nattack works on a number of devices: we evaluated 80 models of modern\nsmartphones and tablets and observed the reaction of the magnetometer to the\nCPU activity on 56 of them. On selected devices we were able to successfully\nidentify which application has been opened (with up to 90% accuracy) or which\nweb page has been loaded (up to 91% accuracy). The presented side channel poses\na significant risk to end users' privacy, as the sensor data can be recorded\nfrom native apps or even from web pages without user permissions. Finally, we\ndiscuss possible countermeasures to prevent the presented information leakage.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 14:23:10 GMT"}, {"version": "v2", "created": "Sat, 7 Sep 2019 11:32:33 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Matyunin", "Nikolay", ""], ["Wang", "Yujue", ""], ["Arul", "Tolga", ""], ["Kullmann", "Kristian", ""], ["Szefer", "Jakub", ""], ["Katzenbeisser", "Stefan", ""]]}, {"id": "1906.11133", "submitter": "Gary Saavedra", "authors": "Gary J Saavedra, Kathryn N Rodhouse, Daniel M Dunlavy, Philip W\n  Kegelmeyer", "title": "A Review of Machine Learning Applications in Fuzzing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzing has played an important role in improving software development and\ntesting over the course of several decades. Recent research in fuzzing has\nfocused on applications of machine learning (ML), offering useful tools to\novercome challenges in the fuzzing process. This review surveys the current\nresearch in applying ML to fuzzing. Specifically, this review discusses\nsuccessful applications of ML to fuzzing, briefly explores challenges\nencountered, and motivates future research to address fuzzing bottlenecks.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 20:02:49 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 20:19:14 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Saavedra", "Gary J", ""], ["Rodhouse", "Kathryn N", ""], ["Dunlavy", "Daniel M", ""], ["Kegelmeyer", "Philip W", ""]]}, {"id": "1906.11246", "submitter": "Andreas Berg", "authors": "Andreas Berg and Daniel Forsberg", "title": "Identifying DNS-tunneled traffic with predictive models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DNS is a distributed, fault tolerant system that avoids a single point of\nfailure. As such it is an integral part of the internet as we use it today and\nhence deemed a safe protocol which is let through firewalls and proxies with no\nor little checks. This can be exploited by malicious agents. Network forensics\nis effective but struggles due to size of data and manual labour. This paper\nexplores to what extent predictive models can be used to predict network\ntraffic, what protocols are tunneled in the DNS protocol and more specifically\nwhether the predictive performance is enhanced when analyzing DNS-queries and\nresponses together and which feature set that can be used for DNS-tunneled\nnetwork prediction. The tested protocols are SSH, SFTP and Telnet and the\nmachine learning models used are Multi Layered Perceptron and Random Forests.\nTo train the models we extract the IP Packet length, Name length and Name\nentropy of both the queries and responses in the DNS traffic. With an\nexperimental research strategy it is empirically shown that the performance of\nthe models increases when training the models on the query and respose pairs\nrather than using only queries or responses. The accuracy of the models is >83%\nand reduction in data size when features are extracted is roughly 95%. Our\nresults provides evidence that machine learning is a valuable tool in detecting\nnetwork protocols in a DNS tunnel and that only an small subset of network\ntraffic is needed to detect this anomaly.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 12:58:57 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Berg", "Andreas", ""], ["Forsberg", "Daniel", ""]]}, {"id": "1906.11288", "submitter": "AbdelRahman Abdou", "authors": "AbdelRahman Abdou and Paul C. van Oorschot", "title": "Secure Client and Server Geolocation Over the Internet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we provide a summary of recent efforts towards achieving\nInternet geolocation securely, \\ie without allowing the entity being geolocated\nto cheat about its own geographic location. Cheating motivations arise from\nmany factors, including impersonation (in the case locations are used to\nreinforce authentication), and gaining location-dependent benefits. In\nparticular, we provide a technical overview of Client Presence Verification\n(CPV) and Server Location Verification (SLV)---two recently proposed techniques\ndesigned to verify the geographic locations of clients and servers in realtime\nover the Internet. Each technique addresses a wide range of adversarial tactics\nto manipulate geolocation, including the use of IP-hiding technologies like\nVPNs and anonymizers, as we now explain.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 18:27:28 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Abdou", "AbdelRahman", ""], ["van Oorschot", "Paul C.", ""]]}, {"id": "1906.11327", "submitter": "Omri Ben-Eliezer", "authors": "Omri Ben-Eliezer and Eylon Yogev", "title": "The Adversarial Robustness of Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.CR cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random sampling is a fundamental primitive in modern algorithms, statistics,\nand machine learning, used as a generic method to obtain a small yet\n\"representative\" subset of the data. In this work, we investigate the\nrobustness of sampling against adaptive adversarial attacks in a streaming\nsetting: An adversary sends a stream of elements from a universe $U$ to a\nsampling algorithm (e.g., Bernoulli sampling or reservoir sampling), with the\ngoal of making the sample \"very unrepresentative\" of the underlying data\nstream. The adversary is fully adaptive in the sense that it knows the exact\ncontent of the sample at any given point along the stream, and can choose which\nelement to send next accordingly, in an online manner.\n  Well-known results in the static setting indicate that if the full stream is\nchosen in advance (non-adaptively), then a random sample of size $\\Omega(d /\n\\varepsilon^2)$ is an $\\varepsilon$-approximation of the full data with good\nprobability, where $d$ is the VC-dimension of the underlying set system\n$(U,R)$. Does this sample size suffice for robustness against an adaptive\nadversary? The simplistic answer is \\emph{negative}: We demonstrate a set\nsystem where a constant sample size (corresponding to VC-dimension $1$)\nsuffices in the static setting, yet an adaptive adversary can make the sample\nvery unrepresentative, as long as the sample size is (strongly) sublinear in\nthe stream length, using a simple and easy-to-implement attack.\n  However, this attack is \"theoretical only\", requiring the set system size to\n(essentially) be exponential in the stream length. This is not a coincidence:\nWe show that to make Bernoulli or reservoir sampling robust against adaptive\nadversaries, the modification required is solely to replace the VC-dimension\nterm $d$ in the sample size with the cardinality term $\\log |R|$. This nearly\nmatches the bound imposed by the attack.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 20:15:54 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Ben-Eliezer", "Omri", ""], ["Yogev", "Eylon", ""]]}, {"id": "1906.11328", "submitter": "Tian Liu", "authors": "Tian Liu and Tao Shu", "title": "Adversarial FDI Attack against AC State Estimation with ANN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural network (ANN) provides superior accuracy for nonlinear\nalternating current (AC) state estimation (SE) in smart grid over traditional\nmethods. However, research has discovered that ANN could be easily fooled by\nadversarial examples. In this paper, we initiate a new study of adversarial\nfalse data injection (FDI) attack against AC SE with ANN: by injecting a\ndeliberate attack vector into measurements, the attacker can degrade the\naccuracy of ANN SE while remaining undetected. We propose a population-based\nalgorithm and a gradient-based algorithm to generate attack vectors. The\nperformance of these algorithms is evaluated through simulations on IEEE 9-bus,\n14-bus and 30-bus systems under various attack scenarios. Simulation results\nshow that DE is more effective than SLSQP on all simulation cases. The attack\nexamples generated by DE algorithm successfully degrade the ANN SE accuracy\nwith high probability.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 20:16:17 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Liu", "Tian", ""], ["Shu", "Tao", ""]]}, {"id": "1906.11427", "submitter": "Vishal Sharma", "authors": "Gaurav Choudhary, Jiyoon Kim, Vishal Sharma", "title": "Security of 5G-Mobile Backhaul Networks: A Survey", "comments": "30 pages, 6 figures, 6 tables, Journal of Wireless Mobile Networks,\n  Ubiquitous Computing, and Dependable Applications (JoWUA)", "journal-ref": "Journal of Wireless Mobile Networks, Ubiquitous Computing, and\n  Dependable Applications (JoWUA), 9:4 (Dec. 2018), pp. 41-70", "doi": "10.22667/JOWUA.2018.12.31.041", "report-no": null, "categories": "cs.NI cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid involution of the mobile generation with incipient data networking\ncapabilities and utilization has exponentially increased the data traffic\nvolumes. Such traffic drains various key issues in 5G mobile backhaul networks.\nSecurity of mobile backhaul is of utmost importance; however, there are a\nlimited number of articles, which have explored such a requirement. This paper\ndiscusses the potential design issues and key challenges of the secure 5G\nmobile backhaul architecture. The comparisons of the existing state-of-the-art\nsolutions for secure mobile backhaul, together with their major contributions\nhave been explored. Furthermore, the paper discussed various key issues related\nto Quality of Service (QoS), routing and scheduling, resource management,\ncapacity enhancement, latency, security-management, and handovers using\nmechanisms like Software Defined Networking and millimeter Wave technologies.\nMoreover, the trails of research challenges and future directions are\nadditionally presented.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 03:55:36 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Choudhary", "Gaurav", ""], ["Kim", "Jiyoon", ""], ["Sharma", "Vishal", ""]]}, {"id": "1906.11441", "submitter": "Lin Sun", "authors": "Lin Sun, Jun Zhao, Xiaojun Ye", "title": "Distributed Clustering in the Anonymized Space with Local Differential\n  Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering and analyzing on collected data can improve user experiences and\nquality of services in big data, IoT applications. However, directly releasing\noriginal data brings potential privacy concerns, which raises challenges and\nopportunities for privacy-preserving clustering. In this paper, we study the\nproblem of non-interactive clustering in distributed setting under the\nframework of local differential privacy. We first extend the Bit Vector, a\nnovel anonymization mechanism to be functionality-capable and\nprivacy-preserving. Based on the modified encoding mechanism, we propose\nkCluster algorithm that can be used for clustering in the anonymized space. We\nshow the modified encoding mechanism can be easily implemented in existing\nclustering algorithms that only rely on distance information, such as DBSCAN.\nTheoretical analysis and experimental results validate the effectiveness of the\nproposed schemes.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 05:38:40 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Sun", "Lin", ""], ["Zhao", "Jun", ""], ["Ye", "Xiaojun", ""]]}, {"id": "1906.11461", "submitter": "Volkan Dedeoglu", "authors": "Volkan Dedeoglu, Raja Jurdak, Guntur D. Putra, Ali Dorri, Salil S.\n  Kanhere", "title": "A Trust Architecture for Blockchain in IoT", "comments": "Submitted to MobiQuitous2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain is a promising technology for establishing trust in IoT networks,\nwhere network nodes do not necessarily trust each other. Cryptographic hash\nlinks and distributed consensus mechanisms ensure that the data stored on an\nimmutable blockchain can not be altered or deleted. However, blockchain\nmechanisms do not guarantee the trustworthiness of data at the origin. We\npropose a layered architecture for improving the end-to-end trust that can be\napplied to a diverse range of blockchain-based IoT applications. Our\narchitecture evaluates the trustworthiness of sensor observations at the data\nlayer and adapts block verification at the blockchain layer through the\nproposed data trust and gateway reputation modules. We present the performance\nevaluation of the data trust module using a simulated indoor target\nlocalization and the gateway reputation module using an end-to-end blockchain\nimplementation, together with a qualitative security analysis for the\narchitecture.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 07:11:43 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Dedeoglu", "Volkan", ""], ["Jurdak", "Raja", ""], ["Putra", "Guntur D.", ""], ["Dorri", "Ali", ""], ["Kanhere", "Salil S.", ""]]}, {"id": "1906.11488", "submitter": "Omar Alhawi", "authors": "Omar M. Alhawi, Mustafa A. Mustafa and Lucas C. Cordeiro", "title": "Finding Security Vulnerabilities in Unmanned Aerial Vehicles Using\n  Software Verification", "comments": "16 pages, 7 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of Unmanned Aerial Vehicles (UAVs) embedded with vulnerable\nmonolithic software has recently raised serious concerns about their security\ndue to concurrency aspects and fragile communication links. However, verifying\nsecurity in UAV software based on traditional testing remains an open challenge\nmainly due to scalability and deployment issues. Here we investigate software\nverification techniques to detect security vulnerabilities in typical UAVs. In\nparticular, we investigate existing software analyzers and verifiers, which\nimplement fuzzing and bounded model checking (BMC) techniques, to detect memory\nsafety and concurrency errors. We also investigate fragility aspects related to\nthe UAV communication link. All UAV components (e.g., position, velocity, and\nattitude control) heavily depend on the communication link. Our preliminary\nresults show that fuzzing and BMC techniques can detect various software\nvulnerabilities, which are of particular interest to ensure security in UAVs.\nWe were able to perform successful cyber-attacks via penetration testing\nagainst the UAV both connection and software system. As a result, we\ndemonstrate real cyber-threats with the possibility of exploiting further\nsecurity vulnerabilities in real-world UAV software in the foreseeable future.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 08:15:39 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 11:57:57 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Alhawi", "Omar M.", ""], ["Mustafa", "Mustafa A.", ""], ["Cordeiro", "Lucas C.", ""]]}, {"id": "1906.11507", "submitter": "Cristian-Alexandru Staicu", "authors": "Cristian-Alexandru Staicu, Daniel Schoepe, Musard Balliu, Michael\n  Pradel, Andrei Sabelfeld", "title": "An Empirical Study of Information Flows in Real-World JavaScript", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information flow analysis prevents secret or untrusted data from flowing into\npublic or trusted sinks. Existing mechanisms cover a wide array of options,\nranging from lightweight taint analysis to heavyweight information flow control\nthat also considers implicit flows. Dynamic analysis, which is particularly\npopular for languages such as JavaScript, faces the question whether to invest\nin analyzing flows caused by not executing a particular branch, so-called\nhidden implicit flows. This paper addresses the questions how common different\nkinds of flows are in real-world programs, how important these flows are to\nenforce security policies, and how costly it is to consider these flows. We\naddress these questions in an empirical study that analyzes 56 real-world\nJavaScript programs that suffer from various security problems, such as code\ninjection vulnerabilities, denial of service vulnerabilities, memory leaks, and\nprivacy leaks. The study is based on a state-of-the-art dynamic information\nflow analysis and a formalization of its core. We find that implicit flows are\nexpensive to track in terms of permissiveness, label creep, and runtime\noverhead. We find a lightweight taint analysis to be sufficient for most of the\nstudied security problems, while for some privacy-related code, observable\ntracking is sometimes required. In contrast, we do not find any evidence that\ntracking hidden implicit flows reveals otherwise missed security problems. Our\nresults help security analysts and analysis designers to understand the\ncost-benefit tradeoffs of information flow analysis and provide empirical\nevidence that analyzing implicit flows in a cost-effective way is a relevant\nproblem.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 08:53:59 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Staicu", "Cristian-Alexandru", ""], ["Schoepe", "Daniel", ""], ["Balliu", "Musard", ""], ["Pradel", "Michael", ""], ["Sabelfeld", "Andrei", ""]]}, {"id": "1906.11520", "submitter": "Florentin Rochet", "authors": "Florentin Rochet, Olivier Bonaventure, Olivier Pereira", "title": "Flexible Anonymous Network", "comments": null, "journal-ref": "12th Workshop on Hot Topics in Privacy Enhancing Technologies\n  (HotPETs 2019)", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet technologies have been designed from guidelines like the robustness\nprinciple also known as Postel's law. Jon Postel's law is described as: \"Be\nconservative in what you do, be liberal in what you accept from others.\"\nFundamentally, it advises protocol designs to be tolerant with what they accept\nfrom the other peers. We propose to take a step back and wonder how the\nrobustness principle could be revisited to support security requirements as\nwell as unifying flexibility from specifications, protocol design and software\nimplementations. Our goal would be to define a software architecture that\noffers the benefits of the robustness principle (i.e., efficient network\nservices despite the presence of various software versions), while also\nguaranteeing that this robustness cannot be exploited by making sure that it is\nonly used to support authentic evolution of the protocol specification.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 09:44:32 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Rochet", "Florentin", ""], ["Bonaventure", "Olivier", ""], ["Pereira", "Olivier", ""]]}, {"id": "1906.11525", "submitter": "Marc Chaumont", "authors": "Ahmad Zakaria, Marc Chaumont and G\\'erard Subsol", "title": "Pooled Steganalysis in JPEG: how to deal with the spreading strategy?", "comments": "Ahmad Zakaria, Marc Chaumont, Gerard Subsol, \" Pooled Steganalysis in\n  JPEG: how to deal with the spreading strategy? \", WIFS'2019, IEEE\n  International Workshop on Information Forensics and Security, December 9-12,\n  2019, Delft, The Netherlands, 6 pages, Acceptance rate = 30%", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In image pooled steganalysis, a steganalyst, Eve, aims to detect if a set of\nimages sent by a steganographer, Alice, to a receiver, Bob, contains a hidden\nmessage. We can reasonably assess that the steganalyst does not know the\nstrategy used to spread the payload across images. To the best of our\nknowledge, in this case, the most appropriate solution for pooled steganalysis\nis to use a Single-Image Detector (SID) to estimate/quantify if an image is\ncover or stego, and to average the scores obtained on the set of images.\n  In such a scenario, where Eve does not know the spreading strategies, we\nexperimentally show that if Eve can discriminate among few well-known spreading\nstrategies, she can improve her steganalysis performances compared to a simple\naveraging or maximum pooled approach. Our discriminative approach allows\nobtaining steganalysis efficiencies comparable to those obtained by a\nclairvoyant, Eve, who knows the Alice spreading strategy. Another interesting\nobservation is that DeLS spreading strategy behaves really better than all the\nother spreading strategies.\n  Those observations results in the experimentation with six different\nspreading strategies made on Jpeg images with J-UNIWARD, a state-of-the-art\nSingle-Image-Detector, and a discriminative architecture that is invariant to\nthe individual payload in each image, invariant to the size of the analyzed set\nof images, and build on a binary detector (for the pooling) that is able to\ndeal with various spreading strategies.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 09:55:05 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 13:51:44 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Zakaria", "Ahmad", ""], ["Chaumont", "Marc", ""], ["Subsol", "G\u00e9rard", ""]]}, {"id": "1906.11598", "submitter": "Peter Ligeti", "authors": "Mate Gyarmati and Peter Ligeti", "title": "Smallest graphs achieving the Stinson bound", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perfect secret sharing scheme is a method of distribute a secret information\n$s$ among participants such that only predefined coalitions, called qualified\nsubsets of the participants can recover the secret, whereas any other\ncoalitions, the unqualified subsets cannot determine anything about the secret.\nThe most important property is the efficiency of the system, which is measured\nby the information ratio. It can be shown that for graphs the information ratio\nis at most $(\\delta+1)/2$ where $\\delta$ is the maximal degree of the graph.\nBlundo et al. constructed a family of $\\delta$-regular graphs with information\nratio $(\\delta+1)/2$ on at least $c\\cdot 6^\\delta$ vertices. We improve this\nresult by constructing a significantly smaller graph family on $c\\cdot\n2^\\delta$ vertices achieving the same upper bound both in the worst and the\naverage case.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 13:01:57 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Gyarmati", "Mate", ""], ["Ligeti", "Peter", ""]]}, {"id": "1906.11667", "submitter": "Shashank Kotyan", "authors": "Shashank Kotyan and Danilo Vasconcellos Vargas", "title": "Evolving Robust Neural Architectures to Defend from Adversarial Attacks", "comments": "Pre-print of the published article in Proceedings of the Workshop on\n  Artificial Intelligence Safety 2020, co-located with the 29th International\n  Joint Conference on Artificial Intelligence and the 17th Pacific Rim\n  International Conference on Artificial Intelligence (IJCAI-PRICAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CR cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural networks are prone to misclassify slightly modified input images.\nRecently, many defences have been proposed, but none have improved the\nrobustness of neural networks consistently. Here, we propose to use adversarial\nattacks as a function evaluation to search for neural architectures that can\nresist such attacks automatically. Experiments on neural architecture search\nalgorithms from the literature show that although accurate, they are not able\nto find robust architectures. A significant reason for this lies in their\nlimited search space. By creating a novel neural architecture search with\noptions for dense layers to connect with convolution layers and vice-versa as\nwell as the addition of concatenation layers in the search, we were able to\nevolve an architecture that is inherently accurate on adversarial samples.\nInterestingly, this inherent robustness of the evolved architecture rivals\nstate-of-the-art defences such as adversarial training while being trained only\non the non-adversarial samples. Moreover, the evolved architecture makes use of\nsome peculiar traits which might be useful for developing even more robust\nones. Thus, the results here confirm that more robust architectures exist as\nwell as opens up a new realm of feasibilities for the development and\nexploration of neural networks.\n  Code available at http://bit.ly/RobustArchitectureSearch.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 14:12:52 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 20:46:26 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 13:34:50 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Kotyan", "Shashank", ""], ["Vargas", "Danilo Vasconcellos", ""]]}, {"id": "1906.11729", "submitter": "Guanxiong Liu", "authors": "Guanxiong Liu, Issa Khalil, Abdallah Khreishah", "title": "Using Intuition from Empirical Properties to Simplify Adversarial\n  Training Defense", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the surprisingly good representation power of complex distributions,\nneural network (NN) classifiers are widely used in many tasks which include\nnatural language processing, computer vision and cyber security. In recent\nworks, people noticed the existence of adversarial examples. These adversarial\nexamples break the NN classifiers' underlying assumption that the environment\nis attack free and can easily mislead fully trained NN classifier without\nnoticeable changes. Among defensive methods, adversarial training is a popular\nchoice. However, original adversarial training with single-step adversarial\nexamples (Single-Adv) can not defend against iterative adversarial examples.\nAlthough adversarial training with iterative adversarial examples (Iter-Adv)\ncan defend against iterative adversarial examples, it consumes too much\ncomputational power and hence is not scalable. In this paper, we analyze\nIter-Adv techniques and identify two of their empirical properties. Based on\nthese properties, we propose modifications which enhance Single-Adv to perform\ncompetitively as Iter-Adv. Through preliminary evaluation, we show that the\nproposed method enhances the test accuracy of state-of-the-art (SOTA)\nSingle-Adv defensive method against iterative adversarial examples by up to\n16.93% while reducing its training cost by 28.75%.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 15:22:56 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Liu", "Guanxiong", ""], ["Khalil", "Issa", ""], ["Khreishah", "Abdallah", ""]]}, {"id": "1906.11782", "submitter": "Mazharul Islam", "authors": "Mazharul Islam, MD. Nazmuddoha Ansary, Novia Nurain, Salauddin Parvez\n  Shams, and A. B. M. Alim Al Islam", "title": "A Sweet Recipe for Consolidated Vulnerabilities: Attacking a Live\n  Website by Harnessing a Killer Combination of Vulnerabilities", "comments": "Accepted at 5th International Conference on Networking, Systems and\n  Security (5th NSysS 2018)", "journal-ref": null, "doi": "10.1109/NSysS.2018.8631373", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recent emergence of new vulnerabilities is an epoch-making problem in the\ncomplex world of website security. Most of the websites are failing to keep\nupdating to tackle their websites from these new vulnerabilities leaving\nwithout realizing the weakness of the websites. As a result, when\ncyber-criminals scour such vulnerable old version websites, the scanner will\nrepresent a set of vulnerabilities. Once found, these vulnerabilities are then\nexploited to steal data, distribute malicious content, or inject defacement and\nspam content into the vulnerable websites. Furthermore, a combination of\ndifferent vulnerabilities is able to cause more damages than anticipation.\nTherefore, in this paper, we endeavor to find connections among various\nvulnerabilities such as cross-site scripting, local file inclusion, remote file\ninclusion, buffer overflow CSRF, etc. To do so, we develop a Finite State\nMachine (FSM) attacking model, which analyzes a set of vulnerabilities towards\nthe road to finding connections. We demonstrate the efficacy of our model by\napplying it to the set of vulnerabilities found on two live websites.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 16:41:18 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Islam", "Mazharul", ""], ["Ansary", "MD. Nazmuddoha", ""], ["Nurain", "Novia", ""], ["Shams", "Salauddin Parvez", ""], ["Islam", "A. B. M. Alim Al", ""]]}, {"id": "1906.11798", "submitter": "Klas Leino", "authors": "Klas Leino, Matt Fredrikson", "title": "Stolen Memories: Leveraging Model Memorization for Calibrated White-Box\n  Membership Inference", "comments": "appearing in USENIX 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Membership inference (MI) attacks exploit the fact that machine learning\nalgorithms sometimes leak information about their training data through the\nlearned model. In this work, we study membership inference in the white-box\nsetting in order to exploit the internals of a model, which have not been\neffectively utilized by previous work. Leveraging new insights about how\noverfitting occurs in deep neural networks, we show how a model's idiosyncratic\nuse of features can provide evidence for membership to white-box\nattackers---even when the model's black-box behavior appears to generalize\nwell---and demonstrate that this attack outperforms prior black-box methods.\nTaking the position that an effective attack should have the ability to provide\nconfident positive inferences, we find that previous attacks do not often\nprovide a meaningful basis for confidently inferring membership, whereas our\nattack can be effectively calibrated for high precision. Finally, we examine\npopular defenses against MI attacks, finding that (1) smaller generalization\nerror is not sufficient to prevent attacks on real models, and (2) while\nsmall-$\\epsilon$-differential privacy reduces the attack's effectiveness, this\noften comes at a significant cost to the model's accuracy; and for larger\n$\\epsilon$ that are sometimes used in practice (e.g., $\\epsilon=16$), the\nattack can achieve nearly the same accuracy as on the unprotected model.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 17:07:51 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 21:06:44 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Leino", "Klas", ""], ["Fredrikson", "Matt", ""]]}, {"id": "1906.11897", "submitter": "Mark Lee", "authors": "Mark Lee, Zico Kolter", "title": "On Physical Adversarial Patches for Object Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we demonstrate a physical adversarial patch attack against\nobject detectors, notably the YOLOv3 detector. Unlike previous work on physical\nobject detection attacks, which required the patch to overlap with the objects\nbeing misclassified or avoiding detection, we show that a properly designed\npatch can suppress virtually all the detected objects in the image. That is, we\ncan place the patch anywhere in the image, causing all existing objects in the\nimage to be missed entirely by the detector, even those far away from the patch\nitself. This in turn opens up new lines of physical attacks against object\ndetection systems, which require no modification of the objects in a scene. A\ndemo of the system can be found at https://youtu.be/WXnQjbZ1e7Y.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 11:04:57 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Lee", "Mark", ""], ["Kolter", "Zico", ""]]}, {"id": "1906.11938", "submitter": "Lisa Oakley", "authors": "Lisa Oakley, Alina Oprea", "title": "QFlip: An Adaptive Reinforcement Learning Strategy for the FlipIt\n  Security Game", "comments": "Outstanding Student Paper award", "journal-ref": "Decision and Game Theory for Security. GameSec 2019. Lecture Notes\n  in Computer Science, vol 11836. Springer, Cham. pp 364-384", "doi": "10.1007/978-3-030-32430-8_22", "report-no": null, "categories": "cs.CR cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A rise in Advanced Persistent Threats (APTs) has introduced a need for\nrobustness against long-running, stealthy attacks which circumvent existing\ncryptographic security guarantees. FlipIt is a security game that models\nattacker-defender interactions in advanced scenarios such as APTs. Previous\nwork analyzed extensively non-adaptive strategies in FlipIt, but adaptive\nstrategies rise naturally in practical interactions as players receive feedback\nduring the game. We model the FlipIt game as a Markov Decision Process and\nintroduce QFlip, an adaptive strategy for FlipIt based on temporal difference\nreinforcement learning. We prove theoretical results on the convergence of our\nnew strategy against an opponent playing with a Periodic strategy. We confirm\nour analysis experimentally by extensive evaluation of QFlip against specific\nopponents. QFlip converges to the optimal adaptive strategy for Periodic and\nExponential opponents using associated state spaces. Finally, we introduce a\ngeneralized QFlip strategy with composite state space that outperforms a Greedy\nstrategy for several distributions including Periodic and Uniform, without\nprior knowledge of the opponent's strategy. We also release an OpenAI Gym\nenvironment for FlipIt to facilitate future research.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 20:08:56 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 19:19:31 GMT"}, {"version": "v3", "created": "Sat, 21 Dec 2019 01:13:27 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Oakley", "Lisa", ""], ["Oprea", "Alina", ""]]}, {"id": "1906.11946", "submitter": "Mahdi Miraz", "authors": "Mahdi H. Miraz and David C. Donald", "title": "LApps: Technological, Legal and Market Potentials of Blockchain\n  Lightning Network Applications", "comments": "ICISDM 2019, published by ACM", "journal-ref": null, "doi": "10.1145/3325917.3325942", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following in the footsteps of pioneer Bitcoin, many altcoins as well as\ncoloured coins have been being developed and merchandised adopting blockchain\nas the core enabling technology. However, since interoperability and\nscalability, due to high and capped (in particular cases) transaction latency\nare deep-rooted in the architecture of blockchain technology, they are by\ndefault inherited in any blockchain based applications. Lightning Network (LN)\nis one of the supporting technologies developed to eliminate this impediment of\nblockchain technology by facilitating instantaneous transfers of cryptos. Since\nthe potentials of LN is still relatively unknown, this paper investigates the\ncurrent states of development along with possible non-monetary usage of LN,\nespecially in settlement coloured coins such as securities, as well as creation\nof new business models based on Lightning Applications (LApps) and microchannel\npayments as well as micro-trades. The legal challenges that may act as\nimpediment to the adoption of LN is also discussed.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 09:54:14 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Miraz", "Mahdi H.", ""], ["Donald", "David C.", ""]]}, {"id": "1906.11976", "submitter": "Jos\\'e Camacho", "authors": "Jos\\'e Camacho, Jos\\'e Manuel Garc\\'ia-Gim\\'enez, Noem\\'i Marta\n  Fuentes-Garc\\'ia, Gabriel Maci\\'a-Fern\\'andez", "title": "Multivariate Big Data Analysis for Intrusion Detection: 5 steps from the\n  haystack to the needle", "comments": null, "journal-ref": "Computers & Security, Volume 87, November 2019, 101603", "doi": "10.1016/j.cose.2019.101603", "report-no": null, "categories": "cs.NI cs.CR cs.LG stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research literature on cybersecurity incident detection & response is\nvery rich in automatic detection methodologies, in particular those based on\nthe anomaly detection paradigm. However, very little attention has been devoted\nto the diagnosis ability of the methods, aimed to provide useful information on\nthe causes of a given detected anomaly. This information is of utmost\nimportance for the security team to reduce the time from detection to response.\nIn this paper, we present Multivariate Big Data Analysis (MBDA), a complete\nintrusion detection approach based on 5 steps to effectively handle massive\namounts of disparate data sources. The approach has been designed to deal with\nthe main characteristics of Big Data, that is, the high volume, velocity and\nvariety. The core of the approach is the Multivariate Statistical Network\nMonitoring (MSNM) technique proposed in a recent paper. Unlike in state of the\nart machine learning methodologies applied to the intrusion detection problem,\nwhen an anomaly is identified in MBDA the output of the system includes the\ndetail of the logs of raw information associated to this anomaly, so that the\nsecurity team can use this information to elucidate its root causes. MBDA is\nbased in two open software packages available in Github: the MEDA Toolbox and\nthe FCParser. We illustrate our approach with two case studies. The first one\ndemonstrates the application of MBDA to semistructured sources of information,\nusing the data from the VAST 2012 mini challenge 2. This complete case study is\nsupplied in a virtual machine available for download. In the second case study\nwe show the Big Data capabilities of the approach in data collected from a real\nnetwork with labeled attacks.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 21:36:13 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Camacho", "Jos\u00e9", ""], ["Garc\u00eda-Gim\u00e9nez", "Jos\u00e9 Manuel", ""], ["Fuentes-Garc\u00eda", "Noem\u00ed Marta", ""], ["Maci\u00e1-Fern\u00e1ndez", "Gabriel", ""]]}, {"id": "1906.11979", "submitter": "Hanxiang Hao", "authors": "Hanxiang Hao, David G\\\"uera, Amy R. Reibman and Edward J. Delp", "title": "A Utility-Preserving GAN for Face Obscuration", "comments": "6 pages, 5 figures, presented at the ICML 2019 Worksop on Synthetic\n  Realities: Deep Learning for Detecting AudioVisual Fakes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From TV news to Google StreetView, face obscuration has been used for privacy\nprotection. Due to recent advances in the field of deep learning, obscuration\nmethods such as Gaussian blurring and pixelation are not guaranteed to conceal\nidentity. In this paper, we propose a utility-preserving generative model,\nUP-GAN, that is able to provide an effective face obscuration, while preserving\nfacial utility. By utility-preserving we mean preserving facial features that\ndo not reveal identity, such as age, gender, skin tone, pose, and expression.\nWe show that the proposed method achieves the best performance in terms of\nobscuration and utility preservation.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 22:01:27 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Hao", "Hanxiang", ""], ["G\u00fcera", "David", ""], ["Reibman", "Amy R.", ""], ["Delp", "Edward J.", ""]]}, {"id": "1906.11993", "submitter": "Valentin Hartmann", "authors": "Valentin Hartmann, Robert West", "title": "Privacy-Preserving Distributed Learning with Secret Gradient Descent", "comments": "13 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many important application domains of machine learning, data is a\nprivacy-sensitive resource. In addition, due to the growing complexity of the\nmodels, single actors typically do not have sufficient data to train a model on\ntheir own. Motivated by these challenges, we propose Secret Gradient Descent\n(SecGD), a method for training machine learning models on data that is spread\nover different clients while preserving the privacy of the training data. We\nachieve this by letting each client add temporary noise to the information they\nsend to the server during the training process. They also share this noise in\nseparate messages with the server, which can then subtract it from the\npreviously received values. By routing all data through an anonymization\nnetwork such as Tor, we prevent the server from knowing which messages\noriginate from the same client, which in turn allows us to show that breaking a\nclient's privacy is computationally intractable as it would require solving a\nhard instance of the subset sum problem. This setup allows SecGD to work in the\npresence of only two honest clients and a malicious server, and without the\nneed for peer-to-peer connections.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 23:27:16 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Hartmann", "Valentin", ""], ["West", "Robert", ""]]}, {"id": "1906.12056", "submitter": "Bao Wang", "authors": "Bao Wang, Quanquan Gu, March Boedihardjo, Farzin Barekat, Stanley J.\n  Osher", "title": "DP-LSSGD: A Stochastic Optimization Method to Lift the Utility in\n  Privacy-Preserving ERM", "comments": "21 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) models trained by differentially private stochastic\ngradient descent (DP-SGD) have much lower utility than the non-private ones. To\nmitigate this degradation, we propose a DP Laplacian smoothing SGD (DP-LSSGD)\nto train ML models with differential privacy (DP) guarantees. At the core of\nDP-LSSGD is the Laplacian smoothing, which smooths out the Gaussian noise used\nin the Gaussian mechanism. Under the same amount of noise used in the Gaussian\nmechanism, DP-LSSGD attains the same DP guarantee, but in practice, DP-LSSGD\nmakes training both convex and nonconvex ML models more stable and enables the\ntrained models to generalize better. The proposed algorithm is simple to\nimplement and the extra computational complexity and memory overhead compared\nwith DP-SGD are negligible. DP-LSSGD is applicable to train a large variety of\nML models, including DNNs. The code is available at\n\\url{https://github.com/BaoWangMath/DP-LSSGD}.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 06:25:41 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 07:49:42 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Wang", "Bao", ""], ["Gu", "Quanquan", ""], ["Boedihardjo", "March", ""], ["Barekat", "Farzin", ""], ["Osher", "Stanley J.", ""]]}, {"id": "1906.12061", "submitter": "Xian Yeow Lee", "authors": "Xian Yeow Lee, Aaron Havens, Girish Chowdhary, Soumik Sarkar", "title": "Learning to Cope with Adversarial Attacks", "comments": "arXiv paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The security of Deep Reinforcement Learning (Deep RL) algorithms deployed in\nreal life applications are of a primary concern. In particular, the robustness\nof RL agents in cyber-physical systems against adversarial attacks are\nespecially vital since the cost of a malevolent intrusions can be extremely\nhigh. Studies have shown Deep Neural Networks (DNN), which forms the core\ndecision-making unit in most modern RL algorithms, are easily subjected to\nadversarial attacks. Hence, it is imperative that RL agents deployed in\nreal-life applications have the capability to detect and mitigate adversarial\nattacks in an online fashion. An example of such a framework is the\nMeta-Learned Advantage Hierarchy (MLAH) agent that utilizes a meta-learning\nframework to learn policies robustly online. Since the mechanism of this\nframework are still not fully explored, we conducted multiple experiments to\nbetter understand the framework's capabilities and limitations. Our results\nshows that the MLAH agent exhibits interesting coping behaviors when subjected\nto different adversarial attacks to maintain a nominal reward. Additionally,\nthe framework exhibits a hierarchical coping capability, based on the\nadaptability of the Master policy and sub-policies themselves. From empirical\nresults, we also observed that as the interval of adversarial attacks increase,\nthe MLAH agent can maintain a higher distribution of rewards, though at the\ncost of higher instabilities.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 07:10:30 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Lee", "Xian Yeow", ""], ["Havens", "Aaron", ""], ["Chowdhary", "Girish", ""], ["Sarkar", "Soumik", ""]]}, {"id": "1906.12140", "submitter": "Swanand Kadhe", "authors": "Swanand Kadhe, Jichan Chung, and Kannan Ramchandran", "title": "SeF: A Secure Fountain Architecture for Slashing Storage Costs in\n  Blockchains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.IT math.IT", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Full nodes, which synchronize the entire blockchain history and independently\nvalidate all the blocks, form the backbone of any blockchain network by playing\na vital role in ensuring security properties. On the other hand, a user running\na full node needs to pay a heavy price in terms of storage costs. E.g., the\nBitcoin blockchain size has grown over 215GB, in spite of its low throughput.\nThe ledger size for a high throughput blockchain Ripple has already reached\n9TB, and it is growing at an astonishing rate of 12GB per day!\n  In this paper, we propose an architecture based on 'fountain codes', a class\nof erasure codes, that enables any full node to 'encode' validated blocks into\na small number of 'coded blocks', thereby reducing its storage costs by orders\nof magnitude. In particular, our proposed \"Secure Fountain (SeF)\" architecture\ncan achieve a near-optimal trade-off between the storage savings per node and\nthe 'bootstrap cost' in terms of the number of (honest) storage-constrained\nnodes a new node needs to contact to recover the blockchain. A key technical\ninnovation in SeF codes is to make fountain codes secure against adversarial\nnodes that can provide maliciously formed coded blocks. Our idea is to use the\nheader-chain as a 'side-information' to check whether a coded block is\nmaliciously formed while it is getting decoded. Further, the 'rateless\nproperty' of fountain codes helps in achieving high decentralization and\nscalability. Our experiments demonstrate that SeF codes tuned to achieve 1000x\nstorage savings enable full nodes to encode the 191GB Bitcoin blockchain into\n195MB on average. A new node can recover the blockchain from an arbitrary set\nof storage-constrained nodes as long as the set contains ~1100 honest nodes on\naverage. Note that for a 1000x storage savings, the fundamental bound on the\nnumber of honest nodes to contact is 1000: we need about 10% more in practice.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 11:32:33 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Kadhe", "Swanand", ""], ["Chung", "Jichan", ""], ["Ramchandran", "Kannan", ""]]}, {"id": "1906.12147", "submitter": "Catuscia Palamidessi", "authors": "Natasha Fernandes and Kacem Lefki and Catuscia Palamidessi", "title": "Utility-Preserving Privacy Mechanisms for Counting Queries", "comments": null, "journal-ref": "Models, Languages and Tools for Concurrent and Distributed\n  Programming, LNCS 11665, Springer, 2019", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy (DP) and local differential privacy (LPD) are frameworks\nto protect sensitive information in data collections. They are both based on\nobfuscation. In DP the noise is added to the result of queries on the dataset,\nwhereas in LPD the noise is added directly on the individual records, before\nbeing collected. The main advantage of LPD with respect to DP is that it does\nnot need to assume a trusted third party. The main disadvantage is that the\ntrade-off between privacy and utility is usually worse than in DP, and\ntypically to retrieve reasonably good statistics from the locally sanitized\ndata it is necessary to have a huge collection of them. In this paper, we focus\non the problem of estimating counting queries from collections of noisy\nanswers, and we propose a variant of LDP based on the addition of geometric\nnoise. Our main result is that the geometric noise has a better statistical\nutility than other LPD mechanisms from the literature.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 11:46:32 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Fernandes", "Natasha", ""], ["Lefki", "Kacem", ""], ["Palamidessi", "Catuscia", ""]]}, {"id": "1906.12182", "submitter": "Linan Huang", "authors": "Linan Huang, Quanyan Zhu", "title": "Adaptive Honeypot Engagement through Reinforcement Learning of\n  Semi-Markov Decision Processes", "comments": "The presentation can be found at https://youtu.be/GPKT3uJtXqk. arXiv\n  admin note: text overlap with arXiv:1907.01396", "journal-ref": null, "doi": "10.1007/978-3-030-32430-8_13", "report-no": null, "categories": "cs.CR cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A honeynet is a promising active cyber defense mechanism. It reveals the\nfundamental Indicators of Compromise (IoCs) by luring attackers to conduct\nadversarial behaviors in a controlled and monitored environment. The active\ninteraction at the honeynet brings a high reward but also introduces high\nimplementation costs and risks of adversarial honeynet exploitation. In this\nwork, we apply infinite-horizon Semi-Markov Decision Process (SMDP) to\ncharacterize a stochastic transition and sojourn time of attackers in the\nhoneynet and quantify the reward-risk trade-off. In particular, we design\nadaptive long-term engagement policies shown to be risk-averse, cost-effective,\nand time-efficient. Numerical results have demonstrated that our adaptive\nengagement policies can quickly attract attackers to the target honeypot and\nengage them for a sufficiently long period to obtain worthy threat information.\nMeanwhile, the penetration probability is kept at a low level. The results show\nthat the expected utility is robust against attackers of a large range of\npersistence and intelligence. Finally, we apply reinforcement learning to the\nSMDP to solve the curse of modeling. Under a prudent choice of the learning\nrate and exploration policy, we achieve a quick and robust convergence of the\noptimal policy and value.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 02:23:11 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 02:10:44 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Huang", "Linan", ""], ["Zhu", "Quanyan", ""]]}, {"id": "1906.12198", "submitter": "Shahab Shamshirband", "authors": "Shahab Shamshirband, Anthony T. Chronopoulos", "title": "A New Malware Detection System Using a High Performance-ELM method", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A vital element of a cyberspace infrastructure is cybersecurity. Many\nprotocols proposed for security issues, which leads to anomalies that affect\nthe related infrastructure of cyberspace. Machine learning (ML) methods used to\nmitigate anomalies behavior in mobile devices. This paper aims to apply a High\nPerformance Extreme Learning Machine (HP-ELM) to detect possible anomalies in\ntwo malware datasets. Two widely used datasets (the CTU-13 and Malware) are\nused to test the effectiveness of HP-ELM. Extensive comparisons are carried out\nin order to validate the effectiveness of the HP-ELM learning method. The\nexperiment results demonstrate that the HP-ELM was the highest accuracy of\nperformance of 0.9592 for the top 3 features with one activation function.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 12:36:02 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Shamshirband", "Shahab", ""], ["Chronopoulos", "Anthony T.", ""]]}, {"id": "1906.12237", "submitter": "Alberto Sonnino", "authors": "Alberto Sonnino and George Danezis", "title": "SybilQuorum: Open Distributed Ledgers Through Trust Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Sybil attack plagues all peer-to-peer systems, and modern open\ndistributed ledgers employ a number of tactics to prevent it from proof of\nwork, or other resources such as space, stake or memory, to traditional\nadmission control in permissioned settings. With SybilQuorum we propose an\nalternative approach to securing an open distributed ledger against Sybil\nattacks, and ensuring consensus amongst honest participants, leveraging social\nnetwork based Sybil defences. We show how nodes expressing their trust\nrelationships through the ledger can bootstrap and operate a value system, and\ngeneral transaction system, and how Sybil attacks are thwarted. We empirically\nevaluate our system as a secure Federated Byzantine Agreement System, and\nextend the theory of those systems to do so.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 14:21:39 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Sonnino", "Alberto", ""], ["Danezis", "George", ""]]}, {"id": "1906.12269", "submitter": "Daniel Z\\\"ugner", "authors": "Daniel Z\\\"ugner and Stephan G\\\"unnemann", "title": "Certifiable Robustness and Robust Training for Graph Convolutional\n  Networks", "comments": "Published as a Conference Paper at ACM SIGKDD 2019", "journal-ref": null, "doi": "10.1145/3292500.3330905", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works show that Graph Neural Networks (GNNs) are highly non-robust\nwith respect to adversarial attacks on both the graph structure and the node\nattributes, making their outcomes unreliable. We propose the first method for\ncertifiable (non-)robustness of graph convolutional networks with respect to\nperturbations of the node attributes. We consider the case of binary node\nattributes (e.g. bag-of-words) and perturbations that are L_0-bounded. If a\nnode has been certified with our method, it is guaranteed to be robust under\nany possible perturbation given the attack model. Likewise, we can certify\nnon-robustness. Finally, we propose a robust semi-supervised training procedure\nthat treats the labeled and unlabeled nodes jointly. As shown in our\nexperimental evaluation, our method significantly improves the robustness of\nthe GNN with only minimal effect on the predictive accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 15:40:10 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Z\u00fcgner", "Daniel", ""], ["G\u00fcnnemann", "Stephan", ""]]}]