[{"id": "1511.00050", "submitter": "Victor Solovyev", "authors": "Victor Solovyev and Ramzan Umarov", "title": "FendOff encryption software to secure personal information on computers\n  and mobile devices", "comments": "7 pages, 9 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper describes several original cryptographic cipher modules (VSEM) that\nare based on using one time pseudorandom pad and pseudorandom transpositions.\nThe VSEM includes 4 modules of encryption that can be applied in combinations.\nWe studied ability of these modules to secure the private data against attacks\nand their speed of encryption. The VSEM encryption was implemented in Fendoff\napplications for mobile devices on iOS and Android platforms as well as in\ncomputer application running Window or Mac OS. We describe these applications\ndesigned to encrypt/decrypt various personal data such as passwords, credit\ncard or bank information as well as to secure content of any text or image\nfiles.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2015 00:22:00 GMT"}], "update_date": "2015-11-03", "authors_parsed": [["Solovyev", "Victor", ""], ["Umarov", "Ramzan", ""]]}, {"id": "1511.00104", "submitter": "Daoyuan Wu", "authors": "Daoyuan Wu and Rocky K. C. Chang", "title": "Cross-Platform Analysis of Indirect File Leaks in Android and iOS\n  Applications", "comments": "This paper was published in IEEE Mobile Security Technologies (MoST)\n  2015 with the original title of \"Indirect File Leaks in Mobile Applications\".\n  (see http://ieee-security.org/TC/SPW2015/MoST/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, much of our sensitive information is stored inside mobile applications\n(apps), such as the browsing histories and chatting logs. To safeguard these\nprivacy files, modern mobile systems, notably Android and iOS, use sandboxes to\nisolate apps' file zones from one another. However, we show in this paper that\nthese private files can still be leaked by indirectly exploiting components\nthat are trusted by the victim apps. In particular, we devise new indirect file\nleak (IFL) attacks that exploit browser interfaces, command interpreters, and\nembedded app servers to leak data from very popular apps, such as Evernote and\nQQ. Unlike the previous attacks, we demonstrate that these IFLs can affect both\nAndroid and iOS. Moreover, our IFL methods allow an adversary to launch the\nattacks remotely, without implanting malicious apps in victim's smartphones. We\nfinally compare the impacts of four different types of IFL attacks on Android\nand iOS, and propose several mitigation methods.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2015 09:29:30 GMT"}, {"version": "v2", "created": "Thu, 9 Feb 2017 13:31:58 GMT"}], "update_date": "2017-02-10", "authors_parsed": [["Wu", "Daoyuan", ""], ["Chang", "Rocky K. C.", ""]]}, {"id": "1511.00117", "submitter": "Christophe Guyeux", "authors": "Christophe Guyeux and Jacques M. Bahi", "title": "Topological chaos and chaotic iterations. Application to Hash functions", "comments": "IJCNN 2010, Int. Joint Conf. on Neural Networks, joint to WCCI'10,\n  IEEE World Congress on Computational Intelligence", "journal-ref": null, "doi": "10.1109/IJCNN.2010.5596512", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new notion of chaotic algorithms. These algorithms\nare iterative and are based on so-called chaotic iterations. Contrary to all\nexisting studies on chaotic iterations, we are not interested in stable states\nof such iterations but in their possible unpredictable behaviors. By\nestablishing a link between chaotic iterations and the notion of Devaney's\ntopological chaos, we give conditions ensuring that these kind of algorithms\nproduce topological chaos. This leads to algorithms that are highly\nunpredictable. After presenting the theoretical foundations of our approach, we\nare interested in its practical aspects. We show how the theoretical algorithms\ngive rise to computer programs that produce true topological chaos, then we\npropose applications in the area of information security.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2015 12:18:27 GMT"}], "update_date": "2015-11-03", "authors_parsed": [["Guyeux", "Christophe", ""], ["Bahi", "Jacques M.", ""]]}, {"id": "1511.00150", "submitter": "Wenhao Wang", "authors": "Wenhao Wang, Zhi Sun, Kui Ren, Bocheng Zhu", "title": "User Capacity of Wireless Physical-layer Identification: An\n  Information-theoretic Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless Physical Layer Identification (WPLI) system aims at identifying or\nclassifying authorized devices based on the unique Radio Frequency Fingerprints\n(RFFs) extracted from their radio frequency signals at the physical layer.\nCurrent works of WPLI focus on demonstrating system feasibility based on\nexperimental error performance of WPLI with a fixed number of users. While an\nimportant question remains to be answered: what's the user number that WPLI can\naccommodate using different RFFs and receiving equipment. The user capacity of\nthe WPLI can be a major concern for practical system designers and can also be\na key metric to evaluate the classification performance of WPLI. In this work,\nwe establish a theoretical understanding on user capacity of WPLI in an\ninformation-theoretic perspective. We apply information-theoretic modeling on\nRFF features of WPLI. An information-theoretic approach is consequently\nproposed based on mutual information between RFF and user identity to\ncharacterize the user capacity of WPLI. Based on this theoretical tool, the\nachievable user capacity of WPLI is characterized under practical constrains of\noff-the-shelf receiving devices. Field experiments on classification error\nperformance are conducted for the validation of the information-theoretic user\ncapacity characterization.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2015 16:54:09 GMT"}, {"version": "v2", "created": "Wed, 2 Mar 2016 15:18:21 GMT"}], "update_date": "2016-03-03", "authors_parsed": [["Wang", "Wenhao", ""], ["Sun", "Zhi", ""], ["Ren", "Kui", ""], ["Zhu", "Bocheng", ""]]}, {"id": "1511.00329", "submitter": "Yuan Hong", "authors": "Nicholas Rizzo, Ethan Sprissler, Yuan Hong, Sanjay Goel", "title": "Privacy Preserving Driving Style Recognition", "comments": "International Conference on Connected Vehicles and Expo 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to better manage the premiums and encourage safe driving, many\ncommercial insurance companies (e.g., Geico, Progressive) are providing options\nfor their customers to install sensors on their vehicles which collect\nindividual vehicle's traveling data. The driver's insurance is linked to\nhis/her driving behavior. At the other end, through analyzing the historical\ntraveling data from a large number of vehicles, the insurance company could\nbuild a classifier to predict a new driver's driving style: aggressive or\ndefensive. However, collection of such vehicle traveling data explicitly\nbreaches the drivers' personal privacy. To tackle such privacy concerns, this\npaper presents a privacy-preserving driving style recognition technique to\nsecurely predict aggressive and defensive drivers for the insurance company\nwithout compromising the privacy of all the participating parties. The\ninsurance company cannot learn any private information from the vehicles, and\nvice-versa. Finally, the effectiveness and efficiency of the privacy-preserving\ndriving style recognition technique are validated with experimental results.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2015 23:07:29 GMT"}], "update_date": "2015-11-03", "authors_parsed": [["Rizzo", "Nicholas", ""], ["Sprissler", "Ethan", ""], ["Hong", "Yuan", ""], ["Goel", "Sanjay", ""]]}, {"id": "1511.00341", "submitter": "Ralph Holz", "authors": "Ralph Holz and Johanna Amann and Olivier Mehani and Matthias Wachs and\n  Mohamed Ali Kaafar", "title": "TLS in the wild: an Internet-wide analysis of TLS-based protocols for\n  electronic communication", "comments": "NDSS 2016", "journal-ref": null, "doi": "10.14722/ndss.2016.23055", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of electronic communication today happens either via email or\nchat. Thanks to the use of standardised protocols electronic mail (SMTP, IMAP,\nPOP3) and instant chat (XMPP, IRC) servers can be deployed in a decentralised\nbut interoperable fashion. These protocols can be secured by providing\nencryption with the use of TLS---directly or via the STARTTLS extension---and\nleverage X.509 PKIs or ad hoc methods to authenticate communication peers.\nHowever, many combination of these mechanisms lead to insecure deployments.\n  We present the largest study to date that investigates the security of the\nemail and chat infrastructures. We used active Internet-wide scans to determine\nthe amount of secure service deployments, and passive monitoring to investigate\nif user agents actually use this opportunity to secure their communications. We\naddressed both the client-to-server interactions as well as server-to-server\nforwarding mechanisms that these protocols offer, and the use of encryption and\nauthentication methods in the process.\n  Our findings shed light on an insofar unexplored area of the Internet. The\ntruly frightening result is that most of our communication is poorly secured in\ntransit.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2015 00:16:56 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2016 00:23:58 GMT"}], "update_date": "2016-01-26", "authors_parsed": [["Holz", "Ralph", ""], ["Amann", "Johanna", ""], ["Mehani", "Olivier", ""], ["Wachs", "Matthias", ""], ["Kaafar", "Mohamed Ali", ""]]}, {"id": "1511.00444", "submitter": "Paul Brussee", "authors": "Paul Brussee, Johan Pouwelse", "title": "Autonomous smartphone apps: self-compilation, mutation, and viral\n  spreading", "comments": "7 pages, 5 figures; addition section 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first smart phone tool that is capable of self-compilation,\nmutation and viral spreading. Our autonomous app does not require a host\ncomputer to alter its functionality, change its appearance and lacks the normal\nnecessity of a central app store to spread among hosts. We pioneered survival\nskills for mobile software in order to overcome disrupted Internet access due\nto natural disasters and human made interference, like Internet kill switches\nor censored networks. Internet kill switches have proven to be an effective\ntool to eradicate open Internet access and all forms of digital communication\nwithin an hour on a country-wide basis. We present the first operational tool\nthat is capable of surviving such digital eradication.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2015 11:10:42 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2015 19:52:16 GMT"}], "update_date": "2015-11-05", "authors_parsed": [["Brussee", "Paul", ""], ["Pouwelse", "Johan", ""]]}, {"id": "1511.00509", "submitter": "Alexander Kott", "authors": "Alexander Kott, Ananthram Swami, Patrick McDaniel", "title": "Six Potential Game-Changers in Cyber Security: Towards Priorities in\n  Cyber Science and Engineering", "comments": "A version of this paper was presented as a keynote talk at the NATO\n  Symposium on Cyber Security Science and Engineering, 13-14 October 2014,\n  Tallinn, Estonia. A much shorter version was published in IEEE Computer\n  (Kott, Alexander, Ananthram Swami, and Patrick McDaniel. \"Security Outlook:\n  Six Cyber Game Changers for the Next 15 Years.\" Computer 47.12 (2014):\n  104-106)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fields of study encompassed by cyber science and engineering are broad\nand poorly defined at this time. As national governments and research\ncommunities increase their recognition of the importance, urgency and technical\nrichness of these disciplines, a question of priorities arises: what specific\nsub-areas of research should be the foci of attention and funding? In this\npaper we point to an approach to answering this question. We explore results of\na recent workshop that postulated possible game-changers or disruptive changes\nthat might occur in cyber security within the next 15 years. We suggest that\nsuch game-changers may be useful in focusing attention of research communities\non high-priority topics. Indeed, if a drastic, important change is likely to\noccur, should we not focus our research efforts on the nature and ramifications\nof the phenomena pertaining to that change? We illustrate each of the\ngame-changers examples of related current research, and then offer\nrecommendations for advancement of cyber science and engineering with respect\nto each of the six game-changers.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2015 14:13:24 GMT"}], "update_date": "2015-11-03", "authors_parsed": [["Kott", "Alexander", ""], ["Swami", "Ananthram", ""], ["McDaniel", "Patrick", ""]]}, {"id": "1511.00568", "submitter": "Santosh Malhotra", "authors": "Amit Kumar and Santosh Malhotra", "title": "Network Security Threats and Protection Models", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": "CSE-101507", "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a brave new age of global connectivity and e-commerce, interconnections\nvia networks have heightened, creating for both individuals and organizations,\na state of complete dependence upon vulnerable systems for storage and transfer\nof information. Never before, have so many people had power in their own hands.\nThe power to deface websites, access personal mail accounts, and worse more the\npotential to bring down entire governments, and financial corporations through\nopenly documented software codes. This paper discusses the possible exploits on\ntypical network components, it will cite real life scenarios, and propose\npractical measures that can be taken as safeguard. Then, it describes some of\nthe key efforts done by the research community to prevent such attacks, mainly\nby using Firewall and Intrusion Detection Systems.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2015 16:14:10 GMT"}], "update_date": "2015-11-03", "authors_parsed": [["Kumar", "Amit", ""], ["Malhotra", "Santosh", ""]]}, {"id": "1511.00619", "submitter": "Tim Libert", "authors": "Timothy Libert", "title": "Exposing the Hidden Web: An Analysis of Third-Party HTTP Requests on 1\n  Million Websites", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This article provides a quantitative analysis of privacy-compromising\nmechanisms on 1 million popular websites. Findings indicate that nearly 9 in 10\nwebsites leak user data to parties of which the user is likely unaware; more\nthan 6 in 10 websites spawn third- party cookies; and more than 8 in 10\nwebsites load Javascript code from external parties onto users' computers.\nSites that leak user data contact an average of nine external domains,\nindicating that users may be tracked by multiple entities in tandem. By tracing\nthe unintended disclosure of personal browsing histories on the Web, it is\nrevealed that a handful of U.S. companies receive the vast bulk of user data.\nFinally, roughly 1 in 5 websites are potentially vulnerable to known National\nSecurity Agency spying techniques at the time of analysis.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2015 18:01:32 GMT"}], "update_date": "2015-11-03", "authors_parsed": [["Libert", "Timothy", ""]]}, {"id": "1511.00905", "submitter": "Hien Truong", "authors": "Babins Shrestha, Nitesh Saxena, Hien Thi Thu Truong, N. Asokan", "title": "Sensor-based Proximity Detection in the Face of Active Adversaries", "comments": null, "journal-ref": "IEEE Transactions on Mobile Computing ( Volume: 18, Issue: 2, Feb.\n  1 2019)", "doi": "10.1109/TMC.2018.2839604", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual proximity detection (or, co-presence detection) is a promising\napproach to defend against relay attacks in many mobile authentication systems.\nWe present a systematic assessment of co-presence detection in the presence of\na context-manipulating attacker. First, we show that it is feasible to\nmanipulate, consistently control and stabilize the readings of different\nacoustic and physical environment sensors (and even multiple sensors\nsimultaneously) using low-cost, off-the-shelf equipment. Second, based on these\ncapabilities, we show that an attacker who can manipulate the context gains a\nsignificant advantage in defeating context-based co-presence detection. For\nsystems that use multiple sensors, we investigate two sensor fusion approaches\nbased on machine learning techniques: features-fusion and decisions-fusion, and\nshow that both are vulnerable to contextual attacks but the latter approach can\nbe more resistant in some cases.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2015 13:31:55 GMT"}, {"version": "v2", "created": "Mon, 5 Apr 2021 01:13:11 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Shrestha", "Babins", ""], ["Saxena", "Nitesh", ""], ["Truong", "Hien Thi Thu", ""], ["Asokan", "N.", ""]]}, {"id": "1511.01047", "submitter": "George Kesidis", "authors": "Zhicong Qiu, David J. Miller, George Kesidis", "title": "Detecting Clusters of Anomalies on Low-Dimensional Feature Subsets with\n  Application to Network Traffic Flow Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a variety of applications, one desires to detect groups of anomalous data\nsamples, with a group potentially manifesting its atypicality (relative to a\nreference model) on a low-dimensional subset of the full measured set of\nfeatures. Samples may only be weakly atypical individually, whereas they may be\nstrongly atypical when considered jointly. What makes this group anomaly\ndetection problem quite challenging is that it is a priori unknown which subset\nof features jointly manifests a particular group of anomalies. Moreover, it is\nunknown how many anomalous groups are present in a given data batch. In this\nwork, we develop a group anomaly detection (GAD) scheme to identify the subset\nof samples and subset of features that jointly specify an anomalous cluster. We\napply our approach to network intrusion detection to detect BotNet and\npeer-to-peer flow clusters. Unlike previous studies, our approach captures and\nexploits statistical dependencies that may exist between the measured features.\nExperiments on real world network traffic data demonstrate the advantage of our\nproposed system, and highlight the importance of exploiting feature dependency\nstructure, compared to the feature (or test) independence assumption made in\nprevious studies.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2015 15:13:59 GMT"}], "update_date": "2015-11-04", "authors_parsed": [["Qiu", "Zhicong", ""], ["Miller", "David J.", ""], ["Kesidis", "George", ""]]}, {"id": "1511.01249", "submitter": "Vinh Thong Ta", "authors": "Vinh Thong Ta", "title": "Privacy by Design: On the Formal Design and Conformance Check of\n  Personal Data Protection Policies and Architectures", "comments": "41 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The new General Data Protection Regulation (GDPR) will take effect in May\n2018, and hence, designing compliant data protection policies and system\narchitectures became crucial for organizations to avoid penalties.\nUnfortunately, the regulations given in a textual format can be easily\nmisinterpreted by the policy and system designers, which also making the\nconformance check error-prone for auditors. In this paper, we apply formal\napproach to facilitate systematic design of policies and architectures in an\nunambiguous way, and provide a framework for mathematically sound conformance\nchecks against the current data protection regulations. We propose a\n(semi-)formal approach for specifying and reasoning about data protection\npolicies and architectures as well as defining conformance relations between\narchitectures and policies. The usability of our proposed approach is\ndemonstrated on a smart metering service case study.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2015 09:20:20 GMT"}, {"version": "v2", "created": "Mon, 14 May 2018 15:48:18 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Ta", "Vinh Thong", ""]]}, {"id": "1511.01363", "submitter": "Sevag Gharibian", "authors": "Anne Broadbent, Sevag Gharibian, Hong-Sheng Zhou", "title": "Quantum One-Time Memories from Stateless Hardware", "comments": "22 pages. Superseded by arXiv:1810.05226. The current paper was\n  withdrawn due to an error in the main security proof (Lemma B.2,\n  specifically); thank you to an anonymous referee for catching it. The\n  superseding paper gives different security claims and proof techniques", "journal-ref": "In Proceedings of TQC 2020", "doi": "10.4230/LIPIcs.TQC.2020.6", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central tenet of theoretical cryptography is the study of the minimal\nassumptions required to implement a given cryptographic primitive. One such\nprimitive is the one-time memory (OTM), introduced by Goldwasser, Kalai, and\nRothblum [CRYPTO 2008], which is a classical functionality modeled after a\nnon-interactive 1-out-of-2 oblivious transfer, and which is complete for\none-time classical and quantum programs. It is known that secure OTMs do not\nexist in the standard model in both the classical and quantum settings. Here,\nwe show how to use quantum information, together with the assumption of\nstateless (i.e., reusable) hardware tokens, to build statistically secure OTMs.\nThis is in sharp contrast with the classical case, where stateless hardware\ntokens alone cannot yield OTMs. In addition, our scheme is technologically\nsimple. We prove security in the quantum universal composability framework,\nemploying semi-definite programming results of Molina, Vidick and Watrous [TQC\n2013] and combinatorial techniques of Pastawski et al. [Proc. Natl. Acad. Sci.\n2012].\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2015 15:05:15 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 10:24:58 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Broadbent", "Anne", ""], ["Gharibian", "Sevag", ""], ["Zhou", "Hong-Sheng", ""]]}, {"id": "1511.01514", "submitter": "Laurent Chuat", "authors": "Laurent Chuat, Pawel Szalachowski, Adrian Perrig, Ben Laurie, Eran\n  Messeri", "title": "Efficient Gossip Protocols for Verifying the Consistency of Certificate\n  Logs", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": "10.1109/CNS.2015.7346853", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The level of trust accorded to certification authorities has been decreasing\nover the last few years as several cases of misbehavior and compromise have\nbeen observed. Log-based approaches, such as Certificate Transparency, ensure\nthat fraudulent TLS certificates become publicly visible. However, a key\nelement that log-based approaches still lack is a way for clients to verify\nthat the log behaves in a consistent and honest manner. This task is\nchallenging due to privacy, efficiency, and deployability reasons. In this\npaper, we propose the first (to the best of our knowledge) gossip protocols\nthat enable the detection of log inconsistencies. We analyze these protocols\nand present the results of a simulation based on real Internet traffic traces.\nWe also give a deployment plan, discuss technical issues, and present an\nimplementation.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2015 21:10:22 GMT"}], "update_date": "2016-01-06", "authors_parsed": [["Chuat", "Laurent", ""], ["Szalachowski", "Pawel", ""], ["Perrig", "Adrian", ""], ["Laurie", "Ben", ""], ["Messeri", "Eran", ""]]}, {"id": "1511.01549", "submitter": "Kyle Marshall", "authors": "Anna-Lena Horlemann-Trautmann, Kyle Marshall, Joachim Rosenthal", "title": "Extension of Overbeck's Attack for Gabidulin Based Cryptosystems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new attack against cryptosystems based on the rank metric. Our\nattack allows us to cryptanalyze two variants of the GPT cryptosystem which\nwere designed to resist the attack of Overbeck.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2015 23:18:13 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2016 16:00:39 GMT"}], "update_date": "2016-01-05", "authors_parsed": [["Horlemann-Trautmann", "Anna-Lena", ""], ["Marshall", "Kyle", ""], ["Rosenthal", "Joachim", ""]]}, {"id": "1511.01568", "submitter": "EPTCS", "authors": "Jaap Boender (Middlesex University), Florian Kamm\\\"uller (Middlesex\n  University), Rajagopal Nagarajan (Middlesex University)", "title": "Formalization of Quantum Protocols using Coq", "comments": "In Proceedings QPL 2015, arXiv:1511.01181", "journal-ref": "EPTCS 195, 2015, pp. 71-83", "doi": "10.4204/EPTCS.195.6", "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum Information Processing, which is an exciting area of research at the\nintersection of physics and computer science, has great potential for\ninfluencing the future development of information processing systems. The\nbuilding of practical, general purpose Quantum Computers may be some years into\nthe future. However, Quantum Communication and Quantum Cryptography are well\ndeveloped. Commercial Quantum Key Distribution systems are easily available and\nseveral QKD networks have been built in various parts of the world. The\nsecurity of the protocols used in these implementations rely on\ninformation-theoretic proofs, which may or may not reflect actual system\nbehaviour. Moreover, testing of implementations cannot guarantee the absence of\nbugs and errors. This paper presents a novel framework for modelling and\nverifying quantum protocols and their implementations using the proof assistant\nCoq. We provide a Coq library for quantum bits (qubits), quantum gates, and\nquantum measurement. As a step towards verifying practical quantum\ncommunication and security protocols such as Quantum Key Distribution, we\nsupport multiple qubits, communication and entanglement. We illustrate these\nconcepts by modelling the Quantum Teleportation Protocol, which communicates\nthe state of an unknown quantum bit using only a classical channel.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2015 01:42:01 GMT"}], "update_date": "2015-11-06", "authors_parsed": [["Boender", "Jaap", "", "Middlesex University"], ["Kamm\u00fcller", "Florian", "", "Middlesex\n  University"], ["Nagarajan", "Rajagopal", "", "Middlesex University"]]}, {"id": "1511.01622", "submitter": "Nalin Asanka Gamagedara Arachchilage", "authors": "Nalin Asanka Gamagedara Arachchilage, Steve Love, Carsten Maple", "title": "Can a Mobile Game Teach Computer Users to Thwart Phishing Attacks?", "comments": "11 pages", "journal-ref": "International Journal for Infonomics (IJI), Volume 6, Issues 3/4,\n  ISSN: 1742 4712, pp. 720-730 (2013)", "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phishing is an online fraudulent technique, which aims to steal sensitive\ninformation such as usernames, passwords and online banking details from its\nvictims. To prevent this, anti-phishing education needs to be considered. This\nresearch focuses on examining the effectiveness of mobile game based learning\ncompared to traditional online learning to thwart phishing threats. Therefore,\na mobile game prototype was developed based on the design introduced by\nArachchilage and Cole [3]. The game design aimed to enhance avoidance behaviour\nthrough motivation to thwart phishing threats. A website developed by\nAnti-Phishing Work Group (APWG) for the public Anti-phishing education\ninitiative was used as a traditional web based learning source. A think-aloud\nexperiment along with a pre- and post-test was conducted through a user study.\nThe study findings revealed that the participants who played the mobile game\nwere better able to identify fraudulent web sites compared to the participants\nwho read the website without any training.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2015 06:28:57 GMT"}], "update_date": "2015-11-06", "authors_parsed": [["Arachchilage", "Nalin Asanka Gamagedara", ""], ["Love", "Steve", ""], ["Maple", "Carsten", ""]]}, {"id": "1511.01808", "submitter": "Shuaiqi Hu", "authors": "Shuaiqi Hu", "title": "A Hierarchical Key Management Scheme for Wireless Sensor Networks Based\n  on Identity-based Encryption", "comments": "ICCC 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Limited resources (such as energy, computing power, storage, and so on) make\nit impractical for wireless sensor networks (WSNs) to deploy traditional\nsecurity schemes. In this paper, a hierarchical key management scheme is\nproposed on the basis of identity-based encryption (IBE).This proposed scheme\nnot only converts the distributed flat architecture of the WSNs to a\nhierarchical architecture for better network management but also ensures the\nindependence and security of the sub-networks. This paper firstly reviews the\nidentity-based encryption, particularly, the Boneh-Franklin algorithm. Then a\nnovel hierarchical key management scheme based on the basic Boneh-Franklin and\nDiffie-Hellman (DH) algorithms is proposed. At last, the security and\nefficiency of our scheme is discussed by comparing with other identity-based\nschemes for flat architecture of WSNs.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2015 16:46:58 GMT"}, {"version": "v2", "created": "Sat, 12 Dec 2015 10:16:26 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2015 09:34:27 GMT"}], "update_date": "2015-12-16", "authors_parsed": [["Hu", "Shuaiqi", ""]]}, {"id": "1511.02119", "submitter": "Andrew Paverd", "authors": "Andrew Paverd, Sandeep Tamrakar, Hoang Long Nguyen, Praveen Kumar\n  Pendyala, Thien Duc Nguyen, Elizabeth Stobert, Tommi Gr\\\"ondahl, N. Asokan,\n  Ahmad-Reza Sadeghi", "title": "OmniShare: Securely Accessing Encrypted Cloud Storage from Multiple\n  Authorized Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud storage services like Dropbox and Google Drive are widely used by\nindividuals and businesses. Two attractive features of these services are 1)\nthe automatic synchronization of files between multiple client devices and 2)\nthe possibility to share files with other users. However, privacy of cloud data\nis a growing concern for both individuals and businesses. Encrypting data on\nthe client-side before uploading it is an effective privacy safeguard, but it\nrequires all client devices to have the decryption key. Current solutions\nderive these keys solely from user-chosen passwords, which have low entropy and\nare easily guessed.\n  We present OmniShare, the first scheme to allow client-side encryption with\nhigh-entropy keys whilst providing an intuitive key distribution mechanism to\nenable access from multiple client devices. Instead of passwords, we use low\nbandwidth uni-directional out-of-band (OOB) channels, such as QR codes, to\nauthenticate new devices. To complement these OOB channels, the cloud storage\nitself is used as a communication channel between devices in our protocols. We\nrely on a directory-based key hierarchy with individual file keys to limit the\nconsequences of key compromise and allow efficient sharing of files without\nrequiring re-encryption. OmniShare is open source software and currently\navailable for Android and Windows with other platforms in development. We\ndescribe the design and implementation of OmniShare, and explain how we\nevaluated its security using formal methods, its performance via real-world\nbenchmarks, and its usability through a cognitive walkthrough.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2015 15:37:27 GMT"}, {"version": "v2", "created": "Fri, 30 Sep 2016 15:35:10 GMT"}, {"version": "v3", "created": "Thu, 29 Dec 2016 12:18:01 GMT"}], "update_date": "2016-12-30", "authors_parsed": [["Paverd", "Andrew", ""], ["Tamrakar", "Sandeep", ""], ["Nguyen", "Hoang Long", ""], ["Pendyala", "Praveen Kumar", ""], ["Nguyen", "Thien Duc", ""], ["Stobert", "Elizabeth", ""], ["Gr\u00f6ndahl", "Tommi", ""], ["Asokan", "N.", ""], ["Sadeghi", "Ahmad-Reza", ""]]}, {"id": "1511.02338", "submitter": "Osamu Hirota", "authors": "Osamu Hirota", "title": "Towards Quantum Enigma Cipher II-A protocol based on quantum\n  illumination-", "comments": "Submitted to Quantum ICT Research Institute Bulletin", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research note II introduces a way to understand a basic concept of the\nquantum enigma cipher. The conventional cipher is designed by a mathematical\nalgorithm and its security is evaluated by the complexity of the algorithm in\nsecurity analysis and ability of computers. This kind of cipher can be\ndecrypted with probability one in principle by the Brute force attack in which\nan eavesdropper tries all the possible keys based on the correct ciphertext and\nsome known plaintext. A cipher with quantum effects in physical layer may\nprotect the system from the Brute force attack by means of the quantum no\ncloning theorem and randomizations based on quantum noise effect. The\nrandomizations for the ciphertext which is the output from the mathematical\nencryption box is crucial to realize a quantum enigma cipher. Especially, by\nrandomizations, it is necessary to make a substantial difference in accuracy of\nciphertext in eavesdropper's observation and legitimate user's observation. The\nquantum illumination protocol can make a difference in error performance of the\nlegitimate's receiver and the eavesdropper's receiver. This difference is due\nto differences in ability of the legitimate's receiver with entanglement and\nthe eavesdropper's receiver without entanglement. It is shown in this note that\nthe quantum illumination can be employed as an element of the most simple\nquantum enigma cipher.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2015 11:09:09 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Hirota", "Osamu", ""]]}, {"id": "1511.02375", "submitter": "Jian Ren", "authors": "Kai Zhou and Jian Ren", "title": "CASO: Cost-Aware Secure Outsourcing of General Computational Problems", "comments": "32 pages, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computation outsourcing is an integral part of cloud computing. It enables\nend-users to outsource their computational tasks to the cloud and utilize the\nshared cloud resources in a pay-per-use manner. However, once the tasks are\noutsourced, the end-users will lose control of their data, which may result in\nsevere security issues especially when the data is sensitive. To address this\nproblem, secure outsourcing mechanisms have been proposed to ensure security of\nthe end-users' outsourced data. In this paper, we investigate outsourcing of\ngeneral computational problems which constitute the mathematical basics for\nproblems emerged from various fields such as engineering and finance. To be\nspecific, we propose affine mapping based schemes for the problem\ntransformation and outsourcing so that the cloud is unable to learn any key\ninformation from the transformed problem. Meanwhile, the overhead for the\ntransformation is limited to an acceptable level compared to the computational\nsavings introduced by the outsourcing itself. Furthermore, we develop\ncost-aware schemes to balance the trade-offs between end-users' various\nsecurity demands and computational overhead. We also propose a verification\nscheme to ensure that the end-users will always receive a valid solution from\nthe cloud. Our extensive complexity and security analysis show that our\nproposed Cost-Aware Secure Outsourcing (CASO) scheme is both practical and\neffective.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2015 16:45:38 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Zhou", "Kai", ""], ["Ren", "Jian", ""]]}, {"id": "1511.02378", "submitter": "Jian Ren", "authors": "Jian Li, Tongtong Li and Jian Ren", "title": "Optimal Construction of Regenerating Code through Rate-matching in\n  Hostile Networks", "comments": "31 pages, 7 figures, journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regenerating code is a class of code very suitable for distributed storage\nsystems, which can maintain optimal bandwidth and storage space. Two types of\nimportant regenerating code have been constructed: the minimum storage\nregeneration (MSR) code and the minimum bandwidth regeneration (MBR) code.\nHowever, in hostile networks where adversaries can compromise storage nodes,\nthe storage capacity of the network can be significantly affected. In this\npaper, we propose two optimal constructions of regenerating codes through\nrate-matching that can combat against this kind of adversaries in hostile\nnetworks: 2-layer rate-matched regenerating code and $m$-layer rate-matched\nregenerating code. For the 2-layer code, we can achieve the optimal storage\nefficiency for given system requirements. Our comprehensive analysis shows that\nour code can detect and correct malicious nodes with higher storage efficiency\ncompared to the universally resilient regenerating code which is a\nstraightforward extension of regenerating code with error detection and\ncorrection capability. Then we propose the $m$-layer code by extending the\n2-layer code and achieve the optimal error correction efficiency by matching\nthe code rate of each layer's regenerating code. We also demonstrate that the\noptimized parameter can achieve the maximum storage capacity under the same\nconstraint. Compared to the universally resilient regenerating code, our code\ncan achieve much higher error correction efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2015 17:02:11 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Li", "Jian", ""], ["Li", "Tongtong", ""], ["Ren", "Jian", ""]]}, {"id": "1511.02511", "submitter": "Gerald Cleaver", "authors": "Jeffrey S. Lee and Gerald B. Cleaver", "title": "The Cosmic Microwave Background Radiation Power Spectrum as a Random Bit\n  Generator for Symmetric and Asymmetric-Key Cryptography", "comments": "9 pages, 1 figure", "journal-ref": "Heliyon Volume 3, Issue 10, October 2017, Article e00422", "doi": "10.1016/j.heliyon.2017.e00422", "report-no": null, "categories": "cs.CR hep-th", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, the Cosmic Microwave Background (CMB) Radiation is shown to be\ncapable of functioning as a Random Bit Generator, and constitutes an\neffectively infinite supply of truly random one-time pad values of arbitrary\nlength. It is further argued that the CMB power spectrum potentially conforms\nto the FIPS 140-2 standard. Additionally, its applicability to the generation\nof a (n x n) random key matrix for a Vernam cipher is established.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2015 18:07:33 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2015 17:29:41 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Lee", "Jeffrey S.", ""], ["Cleaver", "Gerald B.", ""]]}, {"id": "1511.02513", "submitter": "Thomas Steinke", "authors": "Raef Bassily, Kobbi Nissim, Adam Smith, Thomas Steinke, Uri Stemmer,\n  Jonathan Ullman", "title": "Algorithmic Stability for Adaptive Data Analysis", "comments": "This work unifies and subsumes the two arXiv manuscripts\n  arXiv:1503.04843 and arXiv:1504.05800", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptivity is an important feature of data analysis---the choice of questions\nto ask about a dataset often depends on previous interactions with the same\ndataset. However, statistical validity is typically studied in a nonadaptive\nmodel, where all questions are specified before the dataset is drawn. Recent\nwork by Dwork et al. (STOC, 2015) and Hardt and Ullman (FOCS, 2014) initiated\nthe formal study of this problem, and gave the first upper and lower bounds on\nthe achievable generalization error for adaptive data analysis.\n  Specifically, suppose there is an unknown distribution $\\mathbf{P}$ and a set\nof $n$ independent samples $\\mathbf{x}$ is drawn from $\\mathbf{P}$. We seek an\nalgorithm that, given $\\mathbf{x}$ as input, accurately answers a sequence of\nadaptively chosen queries about the unknown distribution $\\mathbf{P}$. How many\nsamples $n$ must we draw from the distribution, as a function of the type of\nqueries, the number of queries, and the desired level of accuracy?\n  In this work we make two new contributions:\n  (i) We give upper bounds on the number of samples $n$ that are needed to\nanswer statistical queries. The bounds improve and simplify the work of Dwork\net al. (STOC, 2015), and have been applied in subsequent work by those authors\n(Science, 2015, NIPS, 2015).\n  (ii) We prove the first upper bounds on the number of samples required to\nanswer more general families of queries. These include arbitrary\nlow-sensitivity queries and an important class of optimization queries.\n  As in Dwork et al., our algorithms are based on a connection with algorithmic\nstability in the form of differential privacy. We extend their work by giving a\nquantitatively optimal, more general, and simpler proof of their main theorem\nthat stability implies low generalization error. We also study weaker stability\nguarantees such as bounded KL divergence and total variation distance.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2015 18:26:50 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Bassily", "Raef", ""], ["Nissim", "Kobbi", ""], ["Smith", "Adam", ""], ["Steinke", "Thomas", ""], ["Stemmer", "Uri", ""], ["Ullman", "Jonathan", ""]]}, {"id": "1511.02528", "submitter": "EPTCS", "authors": "Rob van Glabbeek, Jan Friso Groote, Peter H\\\"ofner", "title": "Proceedings Workshop on Models for Formal Analysis of Real Systems", "comments": null, "journal-ref": "EPTCS 196, 2015", "doi": "10.4204/EPTCS.196", "report-no": null, "categories": "cs.LO cs.CR cs.OS cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of MARS 2015, the first workshop on\nModels for Formal Analysis of Real Systems, held on November 23, 2015 in Suva,\nFiji, as an affiliated workshop of LPAR 2015, the 20th International Conference\non Logic for Programming, Artificial Intelligence and Reasoning.\n  The workshop emphasises modelling over verification. It aims at discussing\nthe lessons learned from making formal methods for the verification and\nanalysis of realistic systems. Examples are:\n  (1) Which formalism is chosen, and why?\n  (2) Which abstractions have to be made and why?\n  (3) How are important characteristics of the system modelled?\n  (4) Were there any complications while modelling the system?\n  (5) Which measures were taken to guarantee the accuracy of the model?\n  We invited papers that present full models of real systems, which may lay the\nbasis for future comparison and analysis. An aim of the workshop is to present\ndifferent modelling approaches and discuss pros and cons for each of them.\nAlternative formal descriptions of the systems presented at this workshop are\nencouraged, which should foster the development of improved specification\nformalisms.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2015 21:12:17 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["van Glabbeek", "Rob", ""], ["Groote", "Jan Friso", ""], ["H\u00f6fner", "Peter", ""]]}, {"id": "1511.02564", "submitter": "Dennis Gamayunov", "authors": "George Noseevich and Dennis Gamayunov", "title": "Towards automated web application logic reconstruction for application\n  level security", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern overlay security mechanisms like Web Application Firewalls (WAF)\nsuffer from inability to recognize custom high-level application logic and data\nobjects, which results in low accuracy, high false positives rates, and\noverhelming manual effort for fine tuning. In this paper we propose an approach\nto web application modeling for security purposes that could help\nnext-generation WAFs to adapt to specific web applications, and do it\nautomatically whenever possible. We aim at creating multi-layer models that\nadequately simulate various aspects of web application functionality that are\nsignificant for intrusion detection and prevention, including request parsing\nand routing, reconstruction of actions and data objects, and action\ninterdependencies.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2015 04:30:47 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Noseevich", "George", ""], ["Gamayunov", "Dennis", ""]]}, {"id": "1511.02903", "submitter": "Antonio Goncalves", "authors": "Rui Shantilau, Antonio Goncalves, Anacleto Correia", "title": "A Socio-Technical approach to address the Information security: Using\n  the 27001 Manager Artefact", "comments": "16 PAGES, 10 FIGURES", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In general, the perspective customer / supplier followed by organizations,\nregarding information security management, is based mainly on management\ncontrols based on standards such as ISO / IEC 27001: 2015, resulting in the\nproduction of especially technical analysis reports, rather than a\nsocio-technical approach. This leads to the perception by the customer of the\ndelivery of a product instead of a service.The product concerned is reduced to\na set of prescriptions, sometimes unrelated, which materialize in a descriptive\nand static view of client security management. As a result, the client can\nhardly use the product continuously, following the dynamics of changes in their\norganization, therefore recognizing value in the provision made by the\nsupplier. The use of the paradigm Service Dominant Logic (LDS), in the\ndevelopment of a range of security management information, helps to change the\nfocus of tangible resources to the intangible assets. The aspects of\ntangibility, materialized in a document that describes the client's\nvulnerabilities and attack vectors are referred to a secondary level, given the\nimportance of the intangible aspects, such as the interaction that is\nestablished between the customer specialists and supplier. In this article we\npropose to analyze in the perspective of a socio-technical theory, the Activity\nTheory, the service provided by an artifact called 27001 Manager, designed to\nassist the entire cycle of analysis, development and maintenance of an\ninformation security management system (ISMS). The analysis aims at observing\nthe existing interaction between customer / supplier, considering that the\nservice is inherently dynamic and inter-subjective, ie the result of a\ncompromise between the customer and the supplier.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2015 11:27:58 GMT"}], "update_date": "2015-11-11", "authors_parsed": [["Shantilau", "Rui", ""], ["Goncalves", "Antonio", ""], ["Correia", "Anacleto", ""]]}, {"id": "1511.02930", "submitter": "Vishesh Karwa", "authors": "Vishesh Karwa and Pavel N. Krivitsky and Aleksandra B. Slavkovi\\'c", "title": "Sharing Social Network Data: Differentially Private Estimation of\n  Exponential-Family Random Graph Models", "comments": "Updated, 39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.CR cs.SI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by a real-life problem of sharing social network data that contain\nsensitive personal information, we propose a novel approach to release and\nanalyze synthetic graphs in order to protect privacy of individual\nrelationships captured by the social network while maintaining the validity of\nstatistical results. A case study using a version of the Enron e-mail corpus\ndataset demonstrates the application and usefulness of the proposed techniques\nin solving the challenging problem of maintaining privacy \\emph{and} supporting\nopen access to network data to ensure reproducibility of existing studies and\ndiscovering new scientific insights that can be obtained by analyzing such\ndata. We use a simple yet effective randomized response mechanism to generate\nsynthetic networks under $\\epsilon$-edge differential privacy, and then use\nlikelihood based inference for missing data and Markov chain Monte Carlo\ntechniques to fit exponential-family random graph models to the generated\nsynthetic networks.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2015 23:36:30 GMT"}, {"version": "v2", "created": "Fri, 23 Sep 2016 16:48:20 GMT"}], "update_date": "2016-09-26", "authors_parsed": [["Karwa", "Vishesh", ""], ["Krivitsky", "Pavel N.", ""], ["Slavkovi\u0107", "Aleksandra B.", ""]]}, {"id": "1511.03005", "submitter": "Zhiwei Xu", "authors": "Zhiwei Xu, Bo Chen, Ninghan Wang, Yujun Zhang, Zhongcheng Li", "title": "ELDA: Towards Efficient and Lightweight Detection of Cache Pollution\n  Attacks in NDN", "comments": "A regular paper published in LCN 2015,9 pages,which includes a novel\n  lightweight FM sketch for estimating the number of distinct items in data\n  streams", "journal-ref": null, "doi": "10.1109/LCN.2015.7366286", "report-no": null, "categories": "cs.CR cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a promising architectural design for future Internet, named data\nnetworking (NDN) relies on in-network caching to efficiently deliver name-based\ncontent. However, the in-network caching is vulnerable to cache pollution\nattacks (CPA), which can reduce cache hits by violating cache locality and\nsignificantly degrade the overall performance of NDN. To defend against CPA\nattacks, the most effective way is to first detect the attacks and then\nthrottle them. Since the CPA attack itself has already imposed a huge burden on\nvictims, to avoid exhausting the remaining resources on the victims for\ndetection purpose, we expect a lightweight detection solution. We thus propose\nELDA, an Efficient and Lightweight Detection scheme against cache pollution\nAttacks, in which we design a Lightweight Flajolet-Martin (LFM) sketch to\nmonitor the interest traffic. Our analysis and simulations demonstrate that, by\nconsuming a few computation and memory resources, ELDA can effectively and\nefficiently detect CPA attacks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2015 07:15:53 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Xu", "Zhiwei", ""], ["Chen", "Bo", ""], ["Wang", "Ninghan", ""], ["Zhang", "Yujun", ""], ["Li", "Zhongcheng", ""]]}, {"id": "1511.03351", "submitter": "Changsha Ma", "authors": "Changsha Ma and Chang Wen Chen", "title": "Attribute-Based Multi-Dimensional Scalable Access Control For Social\n  Media Sharing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Media sharing is an extremely popular paradigm of social interaction in\nonline social networks (OSNs) nowadays. The scalable media access control is\nessential to perform information sharing among users with various access\nprivileges. In this paper, we present a multi-dimensional scalable media access\ncontrol (MD-SMAC) system based on the proposed scalable ciphertext policy\nattribute-based encryption (SCP-ABE) algorithm. In the proposed MD-SMAC system,\nfine-grained access control can be performed on the media contents encoded in a\nmulti-dimensional scalable manner based on data consumers' diverse attributes.\nThrough security analysis, we show that the proposed MC-SMAC system is able to\nresist collusion attacks. Additionally, we conduct experiments to evaluate the\nefficiency performance of the proposed system, especially on mobile devices.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2015 01:32:47 GMT"}], "update_date": "2015-11-12", "authors_parsed": [["Ma", "Changsha", ""], ["Chen", "Chang Wen", ""]]}, {"id": "1511.03376", "submitter": "Yue Wang", "authors": "Yue Wang and Jaewoo Lee and Daniel Kifer", "title": "Revisiting Differentially Private Hypothesis Tests for Categorical Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider methods for performing hypothesis tests on data\nprotected by a statistical disclosure control technology known as differential\nprivacy. Previous approaches to differentially private hypothesis testing\neither perturbed the test statistic with random noise having large variance\n(and resulted in a significant loss of power) or added smaller amounts of noise\ndirectly to the data but failed to adjust the test in response to the added\nnoise (resulting in biased, unreliable $p$-values). In this paper, we develop a\nvariety of practical hypothesis tests that address these problems. Using a\ndifferent asymptotic regime that is more suited to hypothesis testing with\nprivacy, we show a modified equivalence between chi-squared tests and\nlikelihood ratio tests. We then develop differentially private likelihood ratio\nand chi-squared tests for a variety of applications on tabular data (i.e.,\nindependence, sample proportions, and goodness-of-fit tests). Experimental\nevaluations on small and large datasets using a wide variety of privacy\nsettings demonstrate the practicality and reliability of our methods.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2015 03:36:38 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2016 03:19:19 GMT"}, {"version": "v3", "created": "Fri, 2 Dec 2016 04:09:27 GMT"}, {"version": "v4", "created": "Sat, 18 Mar 2017 06:55:30 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Wang", "Yue", ""], ["Lee", "Jaewoo", ""], ["Kifer", "Daniel", ""]]}, {"id": "1511.03451", "submitter": "Emanuele Bellini", "authors": "Emanuele Bellini, Nadir Murru", "title": "An efficient and secure RSA--like cryptosystem exploiting R\\'edei\n  rational functions over conics", "comments": "18 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define an isomorphism between the group of points of a conic and the set\nof integers modulo a prime equipped with a non-standard product. This product\ncan be efficiently evaluated through the use of R\\'edei rational functions. We\nthen exploit the isomorphism to construct a novel RSA-like scheme. We compare\nour scheme with classic RSA and with RSA-like schemes based on the cubic or\nconic equation. The decryption operation of the proposed scheme turns to be two\ntimes faster than RSA, and involves the lowest number of modular inversions\nwith respect to other RSA-like schemes based on curves. Our solution offers the\nsame security as RSA in a one-to-one communication and more security in\nbroadcast applications.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2015 11:05:13 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2016 10:19:47 GMT"}], "update_date": "2016-01-28", "authors_parsed": [["Bellini", "Emanuele", ""], ["Murru", "Nadir", ""]]}, {"id": "1511.03609", "submitter": "Andrei Costin", "authors": "Andrei Costin and Apostolis Zarras and Aur\\'elien Francillon", "title": "Automated Dynamic Firmware Analysis at Scale: A Case Study on Embedded\n  Web Interfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedded devices are becoming more widespread, interconnected, and\nweb-enabled than ever. However, recent studies showed that these devices are\nfar from being secure. Moreover, many embedded systems rely on web interfaces\nfor user interaction or administration. Unfortunately, web security is known to\nbe difficult, and therefore the web interfaces of embedded systems represent a\nconsiderable attack surface.\n  In this paper, we present the first fully automated framework that applies\ndynamic firmware analysis techniques to achieve, in a scalable manner,\nautomated vulnerability discovery within embedded firmware images. We apply our\nframework to study the security of embedded web interfaces running in\nCommercial Off-The-Shelf (COTS) embedded devices, such as routers, DSL/cable\nmodems, VoIP phones, IP/CCTV cameras. We introduce a methodology and implement\na scalable framework for discovery of vulnerabilities in embedded web\ninterfaces regardless of the vendor, device, or architecture. To achieve this\ngoal, our framework performs full system emulation to achieve the execution of\nfirmware images in a software-only environment, i.e., without involving any\nphysical embedded devices. Then, we analyze the web interfaces within the\nfirmware using both static and dynamic tools. We also present some interesting\ncase-studies, and discuss the main challenges associated with the dynamic\nanalysis of firmware images and their web interfaces and network services. The\nobservations we make in this paper shed light on an important aspect of\nembedded devices which was not previously studied at a large scale.\n  We validate our framework by testing it on 1925 firmware images from 54\ndifferent vendors. We discover important vulnerabilities in 185 firmware\nimages, affecting nearly a quarter of vendors in our dataset. These\nexperimental results demonstrate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2015 19:17:38 GMT"}], "update_date": "2015-11-12", "authors_parsed": [["Costin", "Andrei", ""], ["Zarras", "Apostolis", ""], ["Francillon", "Aur\u00e9lien", ""]]}, {"id": "1511.03829", "submitter": "Johannes Schneider", "authors": "Johannes Schneider, Bin Lu", "title": "Secure Numerical and Logical Multi Party Operations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive algorithms for efficient secure numerical and logical operations\nusing a recently introduced scheme for secure multi-party\ncomputation~\\cite{sch15} in the semi-honest model ensuring statistical or\nperfect security. To derive our algorithms for trigonometric functions, we use\nbasic mathematical laws in combination with properties of the additive\nencryption scheme in a novel way. For division and logarithm we use a new\napproach to compute a Taylor series at a fixed point for all numbers. All our\nlogical operations such as comparisons and large fan-in AND gates are perfectly\nsecure. Our empirical evaluation yields speed-ups of more than a factor of 100\nfor the evaluated operations compared to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2015 09:45:41 GMT"}, {"version": "v2", "created": "Sun, 31 Jan 2016 00:17:07 GMT"}, {"version": "v3", "created": "Wed, 19 Jul 2017 22:56:18 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Schneider", "Johannes", ""], ["Lu", "Bin", ""]]}, {"id": "1511.03870", "submitter": "Simon Blackburn", "authors": "Adi Ben-Zvi, Simon R. Blackburn, Boaz Tsaban", "title": "A Practical Cryptanalysis of the Algebraic Eraser", "comments": "15 pages. Updated references, with brief comments added. Minor typos\n  corrected. Final version, accepted for CRYPTO 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anshel, Anshel, Goldfeld and Lemieaux introduced the Colored Burau Key\nAgreement Protocol (CBKAP) as the concrete instantiation of their Algebraic\nEraser scheme. This scheme, based on techniques from permutation groups, matrix\ngroups and braid groups, is designed for lightweight environments such as RFID\ntags and other IoT applications. It is proposed as an underlying technology for\nISO/IEC 29167-20. SecureRF, the company owning the trademark Algebraic Eraser,\nhas presented the scheme to the IRTF with a view towards standardisation.\n  We present a novel cryptanalysis of this scheme. For parameter sizes\ncorresponding to claimed 128-bit security, our implementation recovers the\nshared key using less than 8 CPU hours, and less than 64MB of memory.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2015 11:58:06 GMT"}, {"version": "v2", "created": "Thu, 2 Jun 2016 13:18:57 GMT"}], "update_date": "2016-06-03", "authors_parsed": [["Ben-Zvi", "Adi", ""], ["Blackburn", "Simon R.", ""], ["Tsaban", "Boaz", ""]]}, {"id": "1511.03894", "submitter": "Joseph Kilcullen", "authors": "Joseph Kilcullen", "title": "The Game of Phishing", "comments": "Published in International Journal on Cryptography and Information\n  Security (IJCIS)", "journal-ref": "International Journal on Cryptography and Information Security\n  (IJCIS), Vol. 8, No.1, March 2018", "doi": "10.5121/ijcis.2018.8102", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current implementation of TLS involves your browser displaying a padlock,\nand a green bar, after successfully verifying the digital signature on the TLS\ncertificate. Proposed is a solution where your browser's response to successful\nverification of a TLS certificate is to display a login window. That login\nwindow displays the identity credentials from the TLS certificate, to allow the\nuser to authenticate Bob. It also displays a 'user-browser' shared secret i.e.\na specific picture from your hard disk. This is not SiteKey, the image is\nshared between the computer user and their browser. It is never transmitted\nover the internet. Since sandboxed websites cannot access your hard disk this\nimage cannot be counterfeited by phishing websites. Basically if you view the\ninstalled software component of your browser as an actor in the cryptography\nprotocol, then the solution to phishing attacks is classic cryptography, as\ndocumented in any cryptography textbook.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2015 13:45:28 GMT"}, {"version": "v2", "created": "Thu, 9 Jun 2016 08:33:23 GMT"}, {"version": "v3", "created": "Thu, 4 Aug 2016 17:30:40 GMT"}, {"version": "v4", "created": "Mon, 3 Oct 2016 15:42:35 GMT"}, {"version": "v5", "created": "Thu, 10 Aug 2017 09:37:42 GMT"}, {"version": "v6", "created": "Wed, 11 Apr 2018 21:57:30 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Kilcullen", "Joseph", ""]]}, {"id": "1511.04012", "submitter": "Zhixiong Chen", "authors": "Zhixiong Chen", "title": "Linear complexity and trace representation of quaternary sequences over\n  $\\mathbb{Z}_4$ based on generalized cyclotomic classes modulo $pq$", "comments": "16 pages", "journal-ref": null, "doi": "10.1007/s12095-016-0185-6", "report-no": null, "categories": "math.NT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a family of quaternary sequences over the residue class ring modulo\n$4$ of length $pq$, a product of two distinct odd primes, using the generalized\ncyclotomic classes modulo $pq$ and calculate the discrete Fourier transform\n(DFT) of the sequences. The DFT helps us to determine the exact values of\nlinear complexity and the trace representation of the sequences.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2015 14:19:06 GMT"}], "update_date": "2016-03-15", "authors_parsed": [["Chen", "Zhixiong", ""]]}, {"id": "1511.04158", "submitter": "Sankalp Bagaria", "authors": "Sankalp Bagaria", "title": "Aadhaar-Based Unified Payment Solution", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose to build an Aadhaar Based Unified Payment Solution.\nThe key idea is that a virtual wallet will be linked to the Aadhaar card number\nof the customer. After that, any identification unique to the person and linked\nwith the Aadhaar card, be it something the person knows like secret\nInternet-banking password, be it something s/he carries like debit card/ credit\ncard, something s/he owns like fingerprints, voice, email-id or somewhere s/he\nis like house or office address, can be used for money transfer from the\nsender's Aadhaar card linked virtual wallet to the receiver's Aadhaar card\nlinked virtual wallet, whose any unique ID is known to the sender. If the\nsender knows the receiver's email-id, s/he can transfer money to his/ her\nAadhaar card linked virtual wallet using the email-id. And, if the sender knows\nreceiver's mobile number but not email-id, s/he can use the mobile number to\ntransfer the money to his/ her Aadhaar card linked virtual wallet. And so on.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2015 04:48:36 GMT"}], "update_date": "2015-11-16", "authors_parsed": [["Bagaria", "Sankalp", ""]]}, {"id": "1511.04173", "submitter": "EPTCS", "authors": "Kaylash Chaudhary (University of the South Pacific), Ansgar Fehnker\n  (University of the South Pacific), Jaco van de Pol (University of Twente),\n  Marielle Stoelinga (University of Twente)", "title": "Modeling and Verification of the Bitcoin Protocol", "comments": "In Proceedings MARS 2015, arXiv:1511.02528", "journal-ref": "EPTCS 196, 2015, pp. 46-60", "doi": "10.4204/EPTCS.196.5", "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin is a popular digital currency for online payments, realized as a\ndecentralized peer-to-peer electronic cash system. Bitcoin keeps a ledger of\nall transactions; the majority of the participants decides on the correct\nledger. Since there is no trusted third party to guard against double spending,\nand inspired by its popularity, we would like to investigate the correctness of\nthe Bitcoin protocol. Double spending is an important threat to electronic\npayment systems. Double spending would happen if one user could force a\nmajority to believe that a ledger without his previous payment is the correct\none. We are interested in the probability of success of such a double spending\nattack, which is linked to the computational power of the attacker. This paper\nexamines the Bitcoin protocol and provides its formalization as an UPPAAL\nmodel. The model will be used to show how double spending can be done if the\nparties in the Bitcoin protocol behave maliciously, and with what probability\ndouble spending occurs.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2015 06:28:19 GMT"}], "update_date": "2015-11-16", "authors_parsed": [["Chaudhary", "Kaylash", "", "University of the South Pacific"], ["Fehnker", "Ansgar", "", "University of the South Pacific"], ["van de Pol", "Jaco", "", "University of Twente"], ["Stoelinga", "Marielle", "", "University of Twente"]]}, {"id": "1511.04174", "submitter": "EPTCS", "authors": "Wendelin Serwe (Inria)", "title": "Formal Specification and Verification of Fully Asynchronous\n  Implementations of the Data Encryption Standard", "comments": "In Proceedings MARS 2015, arXiv:1511.02528", "journal-ref": "EPTCS 196, 2015, pp. 61-147", "doi": "10.4204/EPTCS.196.6", "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents two formal models of the Data Encryption Standard (DES),\na first using the international standard LOTOS, and a second using the more\nrecent process calculus LNT. Both models encode the DES in the style of\nasynchronous circuits, i.e., the data-flow blocks of the DES algorithm are\nrepresented by processes communicating via rendezvous. To ensure correctness of\nthe models, several techniques have been applied, including model checking,\nequivalence checking, and comparing the results produced by a prototype\nautomatically generated from the formal model with those of existing\nimplementations of the DES. The complete code of the models is provided as\nappendices and also available on the website of the CADP verification toolbox.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2015 06:28:28 GMT"}], "update_date": "2015-11-16", "authors_parsed": [["Serwe", "Wendelin", "", "Inria"]]}, {"id": "1511.04317", "submitter": "Mansour Ahmadi", "authors": "Mansour Ahmadi, Dmitry Ulyanov, Stanislav Semenov, Mikhail Trofimov,\n  Giorgio Giacinto", "title": "Novel Feature Extraction, Selection and Fusion for Effective Malware\n  Family Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern malware is designed with mutation characteristics, namely polymorphism\nand metamorphism, which causes an enormous growth in the number of variants of\nmalware samples. Categorization of malware samples on the basis of their\nbehaviors is essential for the computer security community, because they\nreceive huge number of malware everyday, and the signature extraction process\nis usually based on malicious parts characterizing malware families. Microsoft\nreleased a malware classification challenge in 2015 with a huge dataset of near\n0.5 terabytes of data, containing more than 20K malware samples. The analysis\nof this dataset inspired the development of a novel paradigm that is effective\nin categorizing malware variants into their actual family groups. This paradigm\nis presented and discussed in the present paper, where emphasis has been given\nto the phases related to the extraction, and selection of a set of novel\nfeatures for the effective representation of malware samples. Features can be\ngrouped according to different characteristics of malware behavior, and their\nfusion is performed according to a per-class weighting paradigm. The proposed\nmethod achieved a very high accuracy ($\\approx$ 0.998) on the Microsoft Malware\nChallenge dataset.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2015 15:33:02 GMT"}, {"version": "v2", "created": "Thu, 10 Mar 2016 10:21:15 GMT"}], "update_date": "2016-03-11", "authors_parsed": [["Ahmadi", "Mansour", ""], ["Ulyanov", "Dmitry", ""], ["Semenov", "Stanislav", ""], ["Trofimov", "Mikhail", ""], ["Giacinto", "Giorgio", ""]]}, {"id": "1511.04389", "submitter": "Erik Ferragut", "authors": "Erik M. Ferragut, Andrew C. Brady, Ethan J. Brady, Jacob M. Ferragut,\n  Nathan M. Ferragut, Max C. Wildgruber", "title": "HackAttack: Game-Theoretic Analysis of Realistic Cyber Conflicts", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Game theory is appropriate for studying cyber conflict because it allows for\nan intelligent and goal-driven adversary. Applications of game theory have led\nto a number of results regarding optimal attack and defense strategies.\nHowever, the overwhelming majority of applications explore overly simplistic\ngames, often ones in which each participant's actions are visible to every\nother participant. These simplifications strip away the fundamental properties\nof real cyber conflicts: probabilistic alerting, hidden actions, unknown\nopponent capabilities.\n  In this paper, we demonstrate that it is possible to analyze a more realistic\ngame, one in which different resources have different weaknesses, players have\ndifferent exploits, and moves occur in secrecy, but they can be detected.\nCertainly, more advanced and complex games are possible, but the game presented\nhere is more realistic than any other game we know of in the scientific\nliterature. While optimal strategies can be found for simpler games using\ncalculus, case-by-case analysis, or, for stochastic games, Q-learning, our more\ncomplex game is more naturally analyzed using the same methods used to study\nother complex games, such as checkers and chess. We define a simple evaluation\nfunction and ploy multi-step searches to create strategies. We show that such\nscenarios can be analyzed, and find that in cases of extreme uncertainty, it is\noften better to ignore one's opponent's possible moves. Furthermore, we show\nthat a simple evaluation function in a complex game can lead to interesting and\nnuanced strategies.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2015 18:18:49 GMT"}], "update_date": "2015-11-16", "authors_parsed": [["Ferragut", "Erik M.", ""], ["Brady", "Andrew C.", ""], ["Brady", "Ethan J.", ""], ["Ferragut", "Jacob M.", ""], ["Ferragut", "Nathan M.", ""], ["Wildgruber", "Max C.", ""]]}, {"id": "1511.04493", "submitter": "Huijing Zhang", "authors": "Huijing Zhang and David Choffnes", "title": "Client-Side Web Proxy Detection from Unprivileged Mobile Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile devices that connect to the Internet via cellular networks are rapidly\nbecoming the primary medium for accessing Web content. Cellular service\nproviders (CSPs) commonly deploy Web proxies and other middleboxes for\nsecurity, performance optimization and traffic engineering reasons. However,\nthe prevalence and policies of these Web proxies are generally opaque to users\nand difficult to measure without privileged access to devices and servers. In\nthis paper, we present a methodology to detect the presence of Web proxies\nwithout requiring access to low-level packet traces on a device, nor access to\nservers being contacted. We demonstrate the viability of this technique using\ncontrolled experiments, and present the results of running our approach on\nseveral production networks and popular Web sites. Next, we characterize the\nbehaviors of these Web proxies, including caching, redirecting, and content\nrewriting. Our analysis can identify how Web proxies impact network\nperformance, and inform policies for future deployments. Last, we release an\nAndroid app called Proxy Detector on the Google Play Store, allowing average\nusers with unprivileged (non-rooted) devices to understand Web proxy\ndeployments and contribute to our IRB-approved study. We report on results of\nusing this app on 11 popular carriers from the US, Canada, Austria, and China.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2015 02:26:24 GMT"}], "update_date": "2015-11-17", "authors_parsed": [["Zhang", "Huijing", ""], ["Choffnes", "David", ""]]}, {"id": "1511.04508", "submitter": "Nicolas Papernot", "authors": "Nicolas Papernot and Patrick McDaniel and Xi Wu and Somesh Jha and\n  Ananthram Swami", "title": "Distillation as a Defense to Adversarial Perturbations against Deep\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning algorithms have been shown to perform extremely well on many\nclassical machine learning problems. However, recent studies have shown that\ndeep learning, like other machine learning techniques, is vulnerable to\nadversarial samples: inputs crafted to force a deep neural network (DNN) to\nprovide adversary-selected outputs. Such attacks can seriously undermine the\nsecurity of the system supported by the DNN, sometimes with devastating\nconsequences. For example, autonomous vehicles can be crashed, illicit or\nillegal content can bypass content filters, or biometric authentication systems\ncan be manipulated to allow improper access. In this work, we introduce a\ndefensive mechanism called defensive distillation to reduce the effectiveness\nof adversarial samples on DNNs. We analytically investigate the\ngeneralizability and robustness properties granted by the use of defensive\ndistillation when training DNNs. We also empirically study the effectiveness of\nour defense mechanisms on two DNNs placed in adversarial settings. The study\nshows that defensive distillation can reduce effectiveness of sample creation\nfrom 95% to less than 0.5% on a studied DNN. Such dramatic gains can be\nexplained by the fact that distillation leads gradients used in adversarial\nsample creation to be reduced by a factor of 10^30. We also find that\ndistillation increases the average minimum number of features that need to be\nmodified to create adversarial samples by about 800% on one of the DNNs we\ntested.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2015 04:51:04 GMT"}, {"version": "v2", "created": "Mon, 14 Mar 2016 13:08:09 GMT"}], "update_date": "2016-03-15", "authors_parsed": [["Papernot", "Nicolas", ""], ["McDaniel", "Patrick", ""], ["Wu", "Xi", ""], ["Jha", "Somesh", ""], ["Swami", "Ananthram", ""]]}, {"id": "1511.04541", "submitter": "Nalin Asanka Gamagedara Arachchilage", "authors": "Nalin Asanka Gamagedara Arachchilage, Andrew Martin", "title": "A Trust Domains Taxonomy for Securely Sharing Information: A Preliminary\n  Investigation", "comments": "16, Eighth International Symposium on Human Aspects of Information\n  Security & Assurance (HAISA 2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information sharing has become a vital part in our day-to-day life due to the\npervasiveness of Internet technology. In any given collaboration, information\nneeds to flow from one participant to another. While participants may be\ninterested in sharing information with one another, it is often necessary for\nthem to establish the impact of sharing certain kinds of information. This is\nbecause certain information could have detrimental effects when it ends up in\nwrong hands. For this reason, any would-be participant in a given collaboration\nmay need to establish the guarantees that the collaboration provides, in terms\nof protecting sensitive information, before joining the collaboration as well\nas evaluating the impact of sharing a given piece of information with a given\nset of entities. In order to address this issue, earlier work introduced a\ntrust domains taxonomy that aims at managing trust-related issues in\ninformation sharing. This paper attempts to empirically investigate the\nproposed taxonomy through a possible scenario (e.g. the ConfiChair system). The\nstudy results determined that Role, Policy, Action, Control, Evidence and Asset\nelements should be incorporated into the taxonomy for securely sharing\ninformation among others. Additionally, the study results showed that the\nConfiChair, a novel cloud-based conference management system, offers strong\nprivacy and confidentiality guarantees.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2015 11:08:23 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2015 02:45:36 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2016 23:50:46 GMT"}], "update_date": "2016-01-11", "authors_parsed": [["Arachchilage", "Nalin Asanka Gamagedara", ""], ["Martin", "Andrew", ""]]}, {"id": "1511.04594", "submitter": "Daniel Gruss", "authors": "Daniel Gruss, Cl\\'ementine Maurice, Klaus Wagner, Stefan Mangard", "title": "Flush+Flush: A Fast and Stealthy Cache Attack", "comments": "This paper has been accepted at the 13th Conference on Detection of\n  Intrusions and Malware & Vulnerability Assessment (DIMVA) 2016. The final\n  publication is available at link.springer.com", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on cache attacks has shown that CPU caches leak significant\ninformation. Proposed detection mechanisms assume that all cache attacks cause\nmore cache hits and cache misses than benign applications and use hardware\nperformance counters for detection.\n  In this article, we show that this assumption does not hold by developing a\nnovel attack technique: the Flush+Flush attack. The Flush+Flush attack only\nrelies on the execution time of the flush instruction, which depends on whether\ndata is cached or not. Flush+Flush does not make any memory accesses, contrary\nto any other cache attack. Thus, it causes no cache misses at all and the\nnumber of cache hits is reduced to a minimum due to the constant cache flushes.\nTherefore, Flush+Flush attacks are stealthy, i.e., the spy process cannot be\ndetected based on cache hits and misses, or state-of-the-art detection\nmechanisms. The Flush+Flush attack runs in a higher frequency and thus is\nfaster than any existing cache attack. With 496 KB/s in a cross-core covert\nchannel it is 6.7 times faster than any previously published cache covert\nchannel.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2015 18:40:20 GMT"}, {"version": "v2", "created": "Fri, 1 Apr 2016 11:32:03 GMT"}, {"version": "v3", "created": "Tue, 5 Apr 2016 09:23:47 GMT"}], "update_date": "2016-04-06", "authors_parsed": [["Gruss", "Daniel", ""], ["Maurice", "Cl\u00e9mentine", ""], ["Wagner", "Klaus", ""], ["Mangard", "Stefan", ""]]}, {"id": "1511.04631", "submitter": "Adam Sealfon", "authors": "Adam Sealfon", "title": "Shortest Paths and Distances with Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a model for differentially private analysis of weighted graphs\nin which the graph topology $(V,E)$ is assumed to be public and the private\ninformation consists only of the edge weights $w:E\\to\\mathbb{R}^+$. This can\nexpress hiding congestion patterns in a known system of roads. Differential\nprivacy requires that the output of an algorithm provides little advantage,\nmeasured by privacy parameters $\\epsilon$ and $\\delta$, for distinguishing\nbetween neighboring inputs, which are thought of as inputs that differ on the\ncontribution of one individual. In our model, two weight functions $w,w'$ are\nconsidered to be neighboring if they have $\\ell_1$ distance at most one.\n  We study the problems of privately releasing a short path between a pair of\nvertices and of privately releasing approximate distances between all pairs of\nvertices. We are concerned with the approximation error, the difference between\nthe length of the released path or released distance and the length of the\nshortest path or actual distance.\n  For privately releasing a short path between a pair of vertices, we prove a\nlower bound of $\\Omega(|V|)$ on the additive approximation error for fixed\n$\\epsilon,\\delta$. We provide a differentially private algorithm that matches\nthis error bound up to a logarithmic factor and releases paths between all\npairs of vertices. The approximation error of our algorithm can be bounded by\nthe number of edges on the shortest path, so we achieve better accuracy than\nthe worst-case bound for vertex pairs that are connected by a low-weight path\nwith $o(|V|)$ vertices.\n  For privately releasing all-pairs distances, we show that for trees we can\nrelease all distances with approximation error $O(\\log^{2.5}|V|)$ for fixed\nprivacy parameters. For arbitrary bounded-weight graphs with edge weights in\n$[0,M]$ we can release all distances with approximation error\n$\\tilde{O}(\\sqrt{|V|M})$.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2015 22:43:31 GMT"}, {"version": "v2", "created": "Wed, 20 Apr 2016 05:43:42 GMT"}], "update_date": "2016-04-21", "authors_parsed": [["Sealfon", "Adam", ""]]}, {"id": "1511.04785", "submitter": "Ferdo Cem", "authors": "Jonathan Webb, Fernando Docemmilli, Mikhail Bonin", "title": "Graph Theory Applications in Network Security", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph theory has become a very critical component in many applications in the\ncomputing field including networking and security. Unfortunately, it is also\namongst the most complex topics to understand and apply.\n  In this paper, we review some of the key applications of graph theory in\nnetwork security. We first cover some algorithmic aspects, then present network\ncoding and its relation to routing.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2015 23:52:00 GMT"}], "update_date": "2015-11-17", "authors_parsed": [["Webb", "Jonathan", ""], ["Docemmilli", "Fernando", ""], ["Bonin", "Mikhail", ""]]}, {"id": "1511.04897", "submitter": "Daniel Gruss", "authors": "Moritz Lipp, Daniel Gruss, Raphael Spreitzer, Cl\\'ementine Maurice,\n  Stefan Mangard", "title": "ARMageddon: Cache Attacks on Mobile Devices", "comments": "Original publication in the Proceedings of the 25th Annual USENIX\n  Security Symposium (USENIX Security 2016).\n  https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/lipp", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last 10 years, cache attacks on Intel x86 CPUs have gained increasing\nattention among the scientific community and powerful techniques to exploit\ncache side channels have been developed. However, modern smartphones use one or\nmore multi-core ARM CPUs that have a different cache organization and\ninstruction set than Intel x86 CPUs. So far, no cross-core cache attacks have\nbeen demonstrated on non-rooted Android smartphones. In this work, we\ndemonstrate how to solve key challenges to perform the most powerful cross-core\ncache attacks Prime+Probe, Flush+Reload, Evict+Reload, and Flush+Flush on\nnon-rooted ARM-based devices without any privileges. Based on our techniques,\nwe demonstrate covert channels that outperform state-of-the-art covert channels\non Android by several orders of magnitude. Moreover, we present attacks to\nmonitor tap and swipe events as well as keystrokes, and even derive the lengths\nof words entered on the touchscreen. Eventually, we are the first to attack\ncryptographic primitives implemented in Java. Our attacks work across CPUs and\ncan even monitor cache activity in the ARM TrustZone from the normal world. The\ntechniques we present can be used to attack hundreds of millions of Android\ndevices.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2015 10:24:33 GMT"}, {"version": "v2", "created": "Sun, 19 Jun 2016 18:37:47 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Lipp", "Moritz", ""], ["Gruss", "Daniel", ""], ["Spreitzer", "Raphael", ""], ["Maurice", "Cl\u00e9mentine", ""], ["Mangard", "Stefan", ""]]}, {"id": "1511.05180", "submitter": "Bo Chen", "authors": "Bo Chen and Radu Sion", "title": "HiFlash: A History Independent Flash Device", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retention regulations require timely and irrecoverable disposal of data, a\nchallenging task, as data and its side effects are stored and maintained at all\nlayers of a computing system. Those side effects can be used as an oracle to\nderive the past existence of deleted data.\n  Fortunately, history independence can be utilized to eliminate such\nhistory-related oracles. HIFS can provide history independence for file storage\nover mechanical disk drives. However, HIFS cannot provide history independence\nwhen deployed on top of flash devices, as flash memory manages its own internal\nblock placement, which is often inherently history dependent.\n  In this work, we initiate research on history independent flash devices. We\ndesign HiFlash, which achieves a strong notion of history independence by\ndefending against an adversary allowed access to the flash at multiple\ndifferent points in time. In addition, we design a simple, yet history\nindependence friendly wear-leveling mechanism that allows HiFlash to smartly\nand advantageously trade off a tunable small amount of history leakage for a\nsignificant increase in the device's lifetime. Our prototype built in an actual\nflash device as well as extensive simulations validate the effectiveness of\nHiFlash.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2015 21:12:23 GMT"}], "update_date": "2015-11-18", "authors_parsed": [["Chen", "Bo", ""], ["Sion", "Radu", ""]]}, {"id": "1511.05341", "submitter": "Zhengjun Cao", "authors": "Zhengjun Cao and Lihua Liu", "title": "On the Weakness of Fully Homomorphic Encryption", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully homomorphic encryption (FHE) allows anyone to perform computations on\nencrypted data, despite not having the secret decryption key. Since the\nGentry's work in 2009, the primitive has interested many researchers. In this\npaper, we stress that any computations performed on encrypted data are\nconstrained to the encrypted domain (finite fields or rings). This restriction\nmakes the primitive useless for most computations involving common arithmetic\nexpressions and relational expressions. It is only applicable to the\ncomputations related to modular arithmetic. We want to reaffirm that\ncryptography uses modular arithmetic a lot in order to obscure and dissipate\nthe redundancies in a plaintext message, not to perform any numerical\ncalculations. We think it might be an overstated claim that FHE is of great\nimportance to client-server computing or cloud computing.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2015 10:39:26 GMT"}], "update_date": "2015-11-18", "authors_parsed": [["Cao", "Zhengjun", ""], ["Liu", "Lihua", ""]]}, {"id": "1511.05357", "submitter": "Xiaofu Wu Dr", "authors": "Xiaofu Wu and Zhen Yang and Cong Ling and Xiang-Gen Xia", "title": "Artificial-Noise-Aided Message Authentication Codes with\n  Information-Theoretic Security", "comments": "12 pages, 4 figures, submitted for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past, two main approaches for the purpose of authentication, including\ninformation-theoretic authentication codes and complexity-theoretic message\nauthentication codes (MACs), were almost independently developed. In this\npaper, we propose a new cryptographic primitive, namely, artificial-noise-aided\nMACs (ANA-MACs), which can be considered as both computationally secure and\ninformation-theoretically secure. For ANA-MACs, we introduce artificial noise\nto interfere with the complexity-theoretic MACs and quantization is further\nemployed to facilitate packet-based transmission. With a channel coding\nformulation of key recovery in the MACs, the generation of standard\nauthentication tags can be seen as an encoding process for the ensemble of\ncodes, where the shared key between Alice and Bob is considered as the input\nand the message is used to specify a code from the ensemble of codes. Then, we\nshow that the introduction of artificial noise in ANA-MACs can be well employed\nto resist the key recovery attack even if the opponent has an unlimited\ncomputing power. Finally, a pragmatic approach for the analysis of ANA-MACs is\nprovided, and we show how to balance the three performance metrics, including\nthe completeness error, the false acceptance probability, and the conditional\nequivocation about the key. The analysis can be well applied to a class of\nANA-MACs, where MACs with Rijndael cipher are employed.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2015 11:48:43 GMT"}], "update_date": "2015-11-18", "authors_parsed": [["Wu", "Xiaofu", ""], ["Yang", "Zhen", ""], ["Ling", "Cong", ""], ["Xia", "Xiang-Gen", ""]]}, {"id": "1511.05453", "submitter": "Aaron Johnson", "authors": "Aaron Johnson, Rob Jansen, Aaron D. Jaggard, Joan Feigenbaum, Paul\n  Syverson", "title": "Avoiding The Man on the Wire: Improving Tor's Security with Trust-Aware\n  Path Selection", "comments": "A conference version of this paper appears in Proceedings of the 24th\n  Network and Distributed System Security Symposium (NDSS 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tor users are vulnerable to deanonymization by an adversary that can observe\nsome Tor relays or some parts of the network. We demonstrate that previous\nnetwork-aware path-selection algorithms that propose to solve this problem are\nvulnerable to attacks across multiple Tor connections. We suggest that users\nuse trust to choose the paths through Tor that are less likely to be observed,\nwhere trust is flexibly modeled as a probability distribution on the location\nof the user's adversaries, and we present the Trust-Aware Path Selection\nalgorithm for Tor that helps users avoid traffic-analysis attacks while still\nchoosing paths that could have been selected by many other users. We evaluate\nthis algorithm in two settings using a high-level map of Internet routing: (i)\nusers try to avoid a single global adversary that has an independent chance to\ncontrol each Autonomous System organization, Internet Exchange Point\norganization, and Tor relay family, and (ii) users try to avoid deanonymization\nby any single country. We also examine the performance of Trust-Aware Path\nselection using the Shadow network simulator.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2015 16:11:25 GMT"}, {"version": "v2", "created": "Mon, 19 Dec 2016 21:03:02 GMT"}, {"version": "v3", "created": "Fri, 27 Jan 2017 15:33:32 GMT"}], "update_date": "2017-01-30", "authors_parsed": [["Johnson", "Aaron", ""], ["Jansen", "Rob", ""], ["Jaggard", "Aaron D.", ""], ["Feigenbaum", "Joan", ""], ["Syverson", "Paul", ""]]}, {"id": "1511.05680", "submitter": "Wuxuan Jiang", "authors": "Wuxuan Jiang, Cong Xie, Zhihua Zhang", "title": "Wishart Mechanism for Differentially Private Principal Components\n  Analysis", "comments": "A full version with technical proofs. Accepted to AAAI-16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new input perturbation mechanism for publishing a covariance\nmatrix to achieve $(\\epsilon,0)$-differential privacy. Our mechanism uses a\nWishart distribution to generate matrix noise. In particular, We apply this\nmechanism to principal component analysis. Our mechanism is able to keep the\npositive semi-definiteness of the published covariance matrix. Thus, our\napproach gives rise to a general publishing framework for input perturbation of\na symmetric positive semidefinite matrix. Moreover, compared with the classic\nLaplace mechanism, our method has better utility guarantee. To the best of our\nknowledge, Wishart mechanism is the best input perturbation approach for\n$(\\epsilon,0)$-differentially private PCA. We also compare our work with\nprevious exponential mechanism algorithms in the literature and provide near\noptimal bound while having more flexibility and less computational\nintractability.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 07:34:23 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2015 06:41:29 GMT"}], "update_date": "2015-11-20", "authors_parsed": [["Jiang", "Wuxuan", ""], ["Xie", "Cong", ""], ["Zhang", "Zhihua", ""]]}, {"id": "1511.05682", "submitter": "Kemal Bicakci", "authors": "Yusuf Uzunay and Kemal Bicakci", "title": "Trust-in-the-Middle: Towards Establishing Trustworthiness of\n  Authentication Proxies using Trusted Computing", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Authentication proxies, which store users' secret credentials and submit them\nto servers on their behalf, offer benefits with respect to security of the\nauthentication and usability of credential management. However, as being a\nservice that is not in control of users, one important problem they suffer is\nthe trust problem; how users trust that their secrets are handled securely in\nthe proxy and not revealed to third parties. In this paper, we present a\nsolution called Trust-in-the-Middle, a TPM based proxy system which ensures\nthat user credentials are securely stored and submitted without disclosing them\neven if the proxy is compromised. We build our architecture on a trust chain\nbootstrapped by TPM DRTM and prevent access to credentials if any entity in the\nchain is maliciously modified. We use remote attestation to guarantee that all\ncritical operations on the proxy are performed securely and credentials are\ncryptographically protected when they are not in DRTM-supported isolation.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 07:49:11 GMT"}, {"version": "v2", "created": "Sun, 27 Dec 2015 20:04:56 GMT"}], "update_date": "2015-12-29", "authors_parsed": [["Uzunay", "Yusuf", ""], ["Bicakci", "Kemal", ""]]}, {"id": "1511.05740", "submitter": "Efstathios Panayi", "authors": "Gareth William Peters and Efstathios Panayi", "title": "Understanding Modern Banking Ledgers through Blockchain Technologies:\n  Future of Transaction Processing and Smart Contracts on the Internet of Money", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this chapter we provide an overview of the concept of blockchain\ntechnology and its potential to disrupt the world of banking through\nfacilitating global money remittance, smart contracts, automated banking\nledgers and digital assets. In this regard, we first provide a brief overview\nof the core aspects of this technology, as well as the second-generation\ncontract-based developments. From there we discuss key issues that must be\nconsidered in developing such ledger based technologies in a banking context.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 11:32:53 GMT"}], "update_date": "2015-11-19", "authors_parsed": [["Peters", "Gareth William", ""], ["Panayi", "Efstathios", ""]]}, {"id": "1511.05787", "submitter": "Zhengjun Cao", "authors": "Zhengjun Cao and Lihua Liu", "title": "The Paillier's Cryptosystem and Some Variants Revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At Eurocrypt'99, Paillier presented a public-key cryptosystem based on a\nnovel computational problem. It has interested many researchers because it was\nadditively homomorphic. In this paper, we show that there is a big difference\nbetween the original Paillier's encryption and some variants. The Paillier's\nencryption can be naturally transformed into a signature scheme but these\nvariants miss the feature. In particular, we simplify the alternative\ndecryption procedure of Bresson-Catalano-Pointcheval encryption scheme proposed\nat Asiacrypt'03. The new version is more applicable to cloud computing because\nof its double trapdoor decryption mechanism and its flexibility to be\nintegrated into other cryptographic schemes. It captures a new feature that its\ntwo groups of secret keys can be distributed to different users so as to\nenhance the robustness of key management.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 14:02:28 GMT"}], "update_date": "2015-11-19", "authors_parsed": [["Cao", "Zhengjun", ""], ["Liu", "Lihua", ""]]}, {"id": "1511.05957", "submitter": "Josep Domingo-Ferrer", "authors": "David S\\'anchez, Sergio Mart\\'inez and Josep Domingo-Ferrer", "title": "Supplementary Materials for \"How to Avoid Reidentification with Proper\n  Anonymization\"- Comment on \"Unique in the shopping mall: on the\n  reidentifiability of credit card metadata\"", "comments": null, "journal-ref": "Supplementary materials to \"Comment on \"Unique in the shopping\n  mall: on the reidentifiability of credit card metadata\"\", Science, Vol. 351,\n  Issue 6279, p. 1274, 18 Mar. 2016.\n  http://science.sciencemag.org/content/351/6279/1274.1.full", "doi": "10.1126/science.aad9295", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study by De Montjoye et al. (\"Science\", 30 January 2015, p. 536) claimed\nthat most individuals can be reidentified from a deidentified credit card\ntransaction database and that anonymization mechanisms are not effective\nagainst reidentification. Such claims deserve detailed quantitative scrutiny,\nas they might seriously undermine the willingness of data owners and subjects\nto share data for research. In a recent Technical Comment published in\n\"Science\" (18 March 2016, p. 1274), we demonstrate that the reidentification\nrisk reported by De Montjoye et al. was significantly overestimated (due to a\nmisunderstanding of the reidentification attack) and that the alleged\nineffectiveness of anonymization is due to the choice of poor and undocumented\nmethods and to a general disregard of 40 years of anonymization literature. The\ntechnical comment also shows how to properly anonymize data, in order to reduce\nunequivocal reidentifications to zero while retaining even more analytical\nutility than with the poor anonymization mechanisms employed by De Montjoye et\nal. In conclusion, data owners, subjects and users can be reassured that sound\nprivacy models and anonymization methods exist to produce safe and useful\nanonymized data.\n  Supplementary materials detailing the data sets, algorithms and extended\nresults of our study are available here. Moreover, unlike the De Montjoye et\nal.'s data set, which was never made available, our data, anonymized results,\nand anonymization algorithms can be freely downloaded from\nhttp://crises-deim.urv.cat/opendata/SPD_Science.zip\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 09:34:11 GMT"}, {"version": "v2", "created": "Fri, 18 Mar 2016 19:04:25 GMT"}], "update_date": "2016-03-21", "authors_parsed": [["S\u00e1nchez", "David", ""], ["Mart\u00ednez", "Sergio", ""], ["Domingo-Ferrer", "Josep", ""]]}, {"id": "1511.06090", "submitter": "Gianluca Stringhini", "authors": "Genki Saito and Gianluca Stringhini", "title": "Master of Puppets: Analyzing And Attacking A Botnet For Fun And Profit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A botnet is a network of compromised machines (bots), under the control of an\nattacker. Many of these machines are infected without their owners' knowledge,\nand botnets are the driving force behind several misuses and criminal\nactivities on the Internet (for example spam emails). Depending on its\ntopology, a botnet can have zero or more command and control (C&C) servers,\nwhich are centralized machines controlled by the cybercriminal that issue\ncommands and receive reports back from the co-opted bots.\n  In this paper, we present a comprehensive analysis of the command and control\ninfrastructure of one of the world's largest proprietary spamming botnets\nbetween 2007 and 2012: Cutwail/Pushdo. We identify the key functionalities\nneeded by a spamming botnet to operate effectively. We then develop a number of\nattacks against the command and control logic of Cutwail that target those\nfunctionalities, and make the spamming operations of the botnet less effective.\nThis analysis was made possible by having access to the source code of the C&C\nsoftware, as well as setting up our own Cutwail C&C server, and by implementing\na clone of the Cutwail bot. With the help of this tool, we were able to\nenumerate the number of bots currently registered with the C&C server,\nimpersonate an existing bot to report false information to the C&C server, and\nmanipulate spamming statistics of an arbitrary bot stored in the C&C database.\nFurthermore, we were able to make the control server inaccessible by conducting\na distributed denial of service (DDoS) attack. Our results may be used by law\nenforcement and practitioners to develop better techniques to mitigate and\ncripple other botnets, since many of findings are generic and are due to the\nworkflow of C&C communication in general.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 08:52:47 GMT"}], "update_date": "2015-11-20", "authors_parsed": [["Saito", "Genki", ""], ["Stringhini", "Gianluca", ""]]}, {"id": "1511.06253", "submitter": "Fragkiskos Koufogiannis", "authors": "Fragkiskos Koufogiannis and George Pappas", "title": "Diffusing Private Data over Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of social and technological networks has enabled rapid sharing\nof data and information. This has resulted in significant privacy concerns\nwhere private information can be either leaked or inferred from public data.\nThe problem is significantly harder for social networks where we may reveal\nmore information to our friends than to strangers. Nonetheless, our private\ninformation can still leak to strangers as our friends are their friends and so\non. In order to address this important challenge, in this paper, we present a\nprivacy-preserving mechanism that enables private data to be diffused over a\nnetwork. In particular, whenever a user wants to access another users' data,\nthe proposed mechanism returns a differentially private response that ensures\nthat the amount of private data leaked depends on the distance between the two\nusers in the network. While allowing global statistics to be inferred by users\nacting as analysts, our mechanism guarantees that no individual user, or a\ngroup of users, can harm the privacy guarantees of any other user. We\nillustrate our mechanism with two examples: one on synthetic data where the\nusers share their GPS coordinates; and one on a Facebook ego-network where a\nuser shares her infection status.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 16:55:03 GMT"}], "update_date": "2015-11-20", "authors_parsed": [["Koufogiannis", "Fragkiskos", ""], ["Pappas", "George", ""]]}, {"id": "1511.06470", "submitter": "Zhengjun Cao", "authors": "Zhengjun Cao and Lihua Liu", "title": "Comment on Two schemes for Secure Outsourcing of Linear Programming", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Wang et al. [IEEE INFOCOM 2011, 820-828], and Nie et al. [IEEE AINA\n2014, 591-596] have proposed two schemes for secure outsourcing of large-scale\nlinear programming (LP). They did not consider the standard form: minimize\nc^{T}x, subject to Ax=b, x>0. Instead, they studied a peculiar form: minimize\nc^{T}x, subject to Ax = b, Bx>0, where B is a non-singular matrix. In this\nnote, we stress that the proposed peculiar form is unsolvable and meaningless.\nThe two schemes have confused the functional inequality constraints Bx>0 with\nthe nonnegativity constraints x>0 in the linear programming model. But the\ncondition x>0 is indispensable to the simplex method. Therefore, both two\nschemes failed.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 01:28:15 GMT"}], "update_date": "2015-11-23", "authors_parsed": [["Cao", "Zhengjun", ""], ["Liu", "Lihua", ""]]}, {"id": "1511.06795", "submitter": "Elias Gonzalez", "authors": "Elias Gonzalez and Laszlo B. Kish", "title": "Key Exchange Trust Evaluation in Peer-to-Peer Sensor Networks with\n  Unconditionally Secure Key Exchange", "comments": "17 pages, 2 figures, submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the utilization of sensor networks continue to increase, the importance of\nsecurity becomes more profound. Many industries depend on sensor networks for\ncritical tasks, and a malicious entity can potentially cause catastrophic\ndamage. We propose a new key exchange trust evaluation for peer-to-peer sensor\nnetworks, where part of the network has unconditionally secure key exchange.\nFor a given sensor, the higher the portion of channels with unconditionally\nsecure key exchange the higher the trust value. We give a brief introduction to\nunconditionally secured key exchange concepts and mention current trust\nmeasures in sensor networks. We demonstrate the new key exchange trust measure\non a hypothetical sensor network using both wired and wireless communication\nchannels.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 23:04:29 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Gonzalez", "Elias", ""], ["Kish", "Laszlo B.", ""]]}, {"id": "1511.06915", "submitter": "Maumita Bhattacharya", "authors": "H. Wilcox and Maumita Bhattacharya", "title": "Countering Social Engineering through Social Media: An Enterprise\n  Security Perspective", "comments": "Proceedings of The 7th International Conference on Computational\n  Collective Intelligence Technologies and Applications (ICCCI 2015), LNAI,\n  Springer, Vol. 9330, pp. 54-64", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing threat of social engineers targeting social media channels to\nadvance their attack effectiveness on company data has seen many organizations\nintroducing initiatives to better understand these vulnerabilities. This paper\nexamines concerns of social engineering through social media within the\nenterprise and explores countermeasures undertaken to stem ensuing risk. Also\nincluded is an analysis of existing social media security policies and\nguidelines within the public and private sectors.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2015 18:40:20 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Wilcox", "H.", ""], ["Bhattacharya", "Maumita", ""]]}, {"id": "1511.07093", "submitter": "Nalin Asanka Gamagedara Arachchilage", "authors": "Nalin Asanka Gamagedara Arachchilage, Ali Tarhini, Steve Love", "title": "Designing a mobile game to thwarts malicious IT threats: A phishing\n  threat avoidance perspective", "comments": "9, International Journal for Infonomics (IJI), Volume 8 Issues 3/4,\n  September/December 2015. arXiv admin note: text overlap with arXiv:1511.01622", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phishing is an online identity theft, which aims to steal sensitive\ninformation such as username, password and online banking details from victims.\nTo prevent this, phishing education needs to be considered. Game based\neducation is becoming more and more popular. This paper introduces a mobile\ngame prototype for the android platform based on a story, which simplifies and\nexaggerates real life. The elements of a game design framework for avoiding\nphishing attacks were used to address the game design issues and game design\nprinciples were used as a set of guidelines for structuring and presenting\ninformation. The overall mobile game design was aimed to enhance the user's\navoidance behaviour through motivation to protect themselves against phishing\nthreats. The prototype mobile game design was presented on MIT App Inventor\nEmulator.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2015 01:32:59 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Arachchilage", "Nalin Asanka Gamagedara", ""], ["Tarhini", "Ali", ""], ["Love", "Steve", ""]]}, {"id": "1511.07528", "submitter": "Nicolas Papernot", "authors": "Nicolas Papernot and Patrick McDaniel and Somesh Jha and Matt\n  Fredrikson and Z. Berkay Celik and Ananthram Swami", "title": "The Limitations of Deep Learning in Adversarial Settings", "comments": "Accepted to the 1st IEEE European Symposium on Security & Privacy,\n  IEEE 2016. Saarbrucken, Germany", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning takes advantage of large datasets and computationally efficient\ntraining algorithms to outperform other approaches at various machine learning\ntasks. However, imperfections in the training phase of deep neural networks\nmake them vulnerable to adversarial samples: inputs crafted by adversaries with\nthe intent of causing deep neural networks to misclassify. In this work, we\nformalize the space of adversaries against deep neural networks (DNNs) and\nintroduce a novel class of algorithms to craft adversarial samples based on a\nprecise understanding of the mapping between inputs and outputs of DNNs. In an\napplication to computer vision, we show that our algorithms can reliably\nproduce samples correctly classified by human subjects but misclassified in\nspecific targets by a DNN with a 97% adversarial success rate while only\nmodifying on average 4.02% of the input features per sample. We then evaluate\nthe vulnerability of different sample classes to adversarial perturbations by\ndefining a hardness measure. Finally, we describe preliminary work outlining\ndefenses against adversarial samples by defining a predictive measure of\ndistance between a benign input and a target classification.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2015 01:07:08 GMT"}], "update_date": "2015-11-25", "authors_parsed": [["Papernot", "Nicolas", ""], ["McDaniel", "Patrick", ""], ["Jha", "Somesh", ""], ["Fredrikson", "Matt", ""], ["Celik", "Z. Berkay", ""], ["Swami", "Ananthram", ""]]}, {"id": "1511.07536", "submitter": "Shayak Sen Shayak Sen", "authors": "Anupam Datta, Joseph Y. Halpern, John C. Mitchell, Arnab Roy, Shayak\n  Sen", "title": "A Symbolic Logic with Concrete Bounds for Cryptographic Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a formal logic for quantitative reasoning about security\nproperties of network protocols. The system allows us to derive concrete\nsecurity bounds that can be used to choose key lengths and other security\nparameters. We provide axioms for reasoning about digital signatures and random\nnonces, with security properties based on the concrete security of signature\nschemes and pseudorandom number generators (PRG). The formal logic supports\nfirst-order reasoning and reasoning about protocol invariants, taking concrete\nsecurity bounds into account. Proofs constructed in our logic also provide\nconventional asymptotic security guarantees because of the way that concrete\nbounds accumulate in proofs. As an illustrative example, we use the formal\nlogic to prove an authentication property with concrete bounds of a\nsignature-based challenge-response protocol.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2015 01:52:04 GMT"}], "update_date": "2015-11-25", "authors_parsed": [["Datta", "Anupam", ""], ["Halpern", "Joseph Y.", ""], ["Mitchell", "John C.", ""], ["Roy", "Arnab", ""], ["Sen", "Shayak", ""]]}, {"id": "1511.07792", "submitter": "Elena Dubrova", "authors": "Elena Dubrova and Mats N\\\"aslund and Gunnar Carlsson and John Fornehed\n  and Ben Smeets", "title": "Two Countermeasures Against Hardware Trojans Exploiting Non-Zero\n  Aliasing Probability of BIST", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The threat of hardware Trojans has been widely recognized by academia,\nindustry, and government agencies. A Trojan can compromise security of a system\nin spite of cryptographic protection. The damage caused by a Trojan may not be\nlimited to a business or reputation, but could have a severe impact on public\nsafety, national economy, or national security. An extremely stealthy way of\nimplementing hardware Trojans has been presented by Becker et al. at CHES'2012.\nTheir work have shown that it is possible to inject a Trojan in a random number\ngenerator compliant with FIPS 140-2 and NIST SP800-90 standards by exploiting\nnon-zero aliasing probability of Logic Built-In-Self-Test (LBIST). In this\npaper, we present two methods for modifying LBIST to prevent such an attack.\nThe first method makes test patterns dependent on a configurable key which is\nprogramed into a chip after the manufacturing stage. The second method uses a\nremote test management system which can execute LBIST using a different set of\ntest patterns at each test cycle.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2015 16:40:08 GMT"}], "update_date": "2015-11-25", "authors_parsed": [["Dubrova", "Elena", ""], ["N\u00e4slund", "Mats", ""], ["Carlsson", "Gunnar", ""], ["Fornehed", "John", ""], ["Smeets", "Ben", ""]]}, {"id": "1511.07896", "submitter": "Vishesh Karwa", "authors": "Vishesh Karwa and Dan Kifer and Aleksandra B. Slavkovi\\'c", "title": "Private Posterior distributions from Variational approximations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy preserving mechanisms such as differential privacy inject additional\nrandomness in the form of noise in the data, beyond the sampling mechanism.\nIgnoring this additional noise can lead to inaccurate and invalid inferences.\nIn this paper, we incorporate the privacy mechanism explicitly into the\nlikelihood function by treating the original data as missing, with an end goal\nof estimating posterior distributions over model parameters. This leads to a\nprincipled way of performing valid statistical inference using private data,\nhowever, the corresponding likelihoods are intractable. In this paper, we\nderive fast and accurate variational approximations to tackle such intractable\nlikelihoods that arise due to privacy. We focus on estimating posterior\ndistributions of parameters of the naive Bayes log-linear model, where the\nsufficient statistics of this model are shared using a differentially private\ninterface. Using a simulation study, we show that the posterior approximations\noutperform the naive method of ignoring the noise addition mechanism.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2015 21:49:02 GMT"}], "update_date": "2015-11-26", "authors_parsed": [["Karwa", "Vishesh", ""], ["Kifer", "Dan", ""], ["Slavkovi\u0107", "Aleksandra B.", ""]]}, {"id": "1511.08101", "submitter": "Marco Calderini", "authors": "Marco Calderini, Massimilano Sala, Irene Villa", "title": "A note on APN permutations in even dimension", "comments": null, "journal-ref": "Finite Fields and Their Applications, 46:1 - 16, 2017", "doi": "10.1016/j.ffa.2017.02.001", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  APN permutations in even dimension are vectorial Boolean functions that play\na special role in the design of block ciphers. We study their properties,\nproviding some general results and some applications to the low-dimension\ncases. In particular, we prove that none of their components can be quadratic.\nFor an APN vectorial Boolean function (in even dimension) with all cubic\ncomponents we prove the existence of a component having a large number of\nbalanced derivatives. Using these restrictions, we obtain the first theoretical\nproof of the non-existence of APN permutations in dimension 4. Moreover, we\nderive some contraints on APN permutations in dimension 6.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2015 15:59:31 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2016 10:19:17 GMT"}, {"version": "v3", "created": "Mon, 22 Aug 2016 10:14:23 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Calderini", "Marco", ""], ["Sala", "Massimilano", ""], ["Villa", "Irene", ""]]}, {"id": "1511.08324", "submitter": "Xiujia Guo", "authors": "Xiujia Guo, Haibo Chen, Xuqin Liu, Xiangyu Xu, Zhong Chen", "title": "The Scale-free Network of Passwords : Visualization and Estimation of\n  Empirical Passwords", "comments": "9 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel vision of large scale of empirical password\nsets available and improve the understanding of passwords by revealing their\ninterconnections and considering the security on a level of the whole password\nset instead of one single password level. Through the visualization of Yahoo,\nPhpbb, 12306, etc. we, for the first time, show what the spatial structure of\nempirical password sets are like and take the community and clustering patterns\nof the passwords into account to shed lights on the definition of popularity of\na password based on their frequency and degree separately. Furthermore, we\npropose a model of statistical guessing attack from the perspective of the\ndata's topological space, which provide an explanation of the \"cracking curve\".\nWe also give a lower bound of the minimum size of the dictionary needed to\ncompromise arbitrary ratio of any given password set by proving that it is\nequivalent to the minimum dominating set problem, which is a NP-complete\nproblem. Hence the minimal dictionary problem is also NP-complete.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2015 08:54:48 GMT"}], "update_date": "2015-11-30", "authors_parsed": [["Guo", "Xiujia", ""], ["Chen", "Haibo", ""], ["Liu", "Xuqin", ""], ["Xu", "Xiangyu", ""], ["Chen", "Zhong", ""]]}, {"id": "1511.08413", "submitter": "Sven Puchinger", "authors": "Sven Puchinger, Sven M\\\"uelich, Karim Ishak, Martin Bossert", "title": "Code-Based Cryptosystems Using Generalized Concatenated Codes", "comments": "Submitted to Springer Proceedings in Mathematics & Statistics,\n  special issue devoted to the conference Application of Computer Algebra (ACA)\n  2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The security of public-key cryptosystems is mostly based on number theoretic\nproblems like factorization and the discrete logarithm. There exists an\nalgorithm which solves these problems in polynomial time using a quantum\ncomputer. Hence, these cryptosystems will be broken as soon as quantum\ncomputers emerge. Code-based cryptography is an alternative which resists\nquantum computers since its security is based on an NP-complete problem, namely\ndecoding of random linear codes. The McEliece cryptosystem is the most\nprominent scheme to realize code-based cryptography. Many codeclasses were\nproposed for the McEliece cryptosystem, but most of them are broken by now.\nSendrier suggested to use ordinary concatenated codes, however, he also\npresented an attack on such codes. This work investigates generalized\nconcatenated codes to be used in the McEliece cryptosystem. We examine the\napplication of Sendrier's attack on generalized concatenated codes and present\nalternative methods for both partly finding the code structure and recovering\nthe plaintext from a cryptogram. Further, we discuss modifications of the\ncryptosystem making it resistant against these attacks.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2015 15:14:56 GMT"}], "update_date": "2015-11-30", "authors_parsed": [["Puchinger", "Sven", ""], ["M\u00fcelich", "Sven", ""], ["Ishak", "Karim", ""], ["Bossert", "Martin", ""]]}, {"id": "1511.08507", "submitter": "Steffen Wendzel", "authors": "Steffen Wendzel, Carolin Palmer", "title": "Creativity in Mind: Evaluating and Maintaining Advances in Network\n  Steganographic Research", "comments": "to appear in Journal of Universal Computer Science (J.UCS)", "journal-ref": "Journal of Universal Computer Science, Vol. 21(12), 2015", "doi": "10.3217/jucs-021-12-1684", "report-no": null, "categories": "cs.MM cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research discipline of network steganography deals with the hiding of\ninformation within network transmissions, e.g. to transfer illicit information\nin networks with Internet censorship. The last decades of research on network\nsteganography led to more than hundred techniques for hiding data in network\ntransmissions. However, previous research has shown that most of these hiding\ntechniques are either based on the same idea or introduce limited novelty,\nenabling the application of existing countermeasures. In this paper, we provide\na link between the field of creativity and network steganographic research. We\npropose a framework and a metric to help evaluating the creativity bound to a\ngiven hiding technique. This way, we support two sides of the scientific peer\nreview process as both authors and reviewers can use our framework to analyze\nthe novelty and applicability of hiding techniques. At the same time, we\ncontribute to a uniform terminology in network steganography.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2015 21:07:05 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Wendzel", "Steffen", ""], ["Palmer", "Carolin", ""]]}, {"id": "1511.08552", "submitter": "Mark Bun", "authors": "Mark Bun and Kobbi Nissim and Uri Stemmer", "title": "Simultaneous Private Learning of Multiple Concepts", "comments": "29 pages. To appear in ITCS '16", "journal-ref": null, "doi": "10.1145/2840728.2840747", "report-no": null, "categories": "cs.DS cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the direct-sum problem in the context of differentially\nprivate PAC learning: What is the sample complexity of solving $k$ learning\ntasks simultaneously under differential privacy, and how does this cost compare\nto that of solving $k$ learning tasks without privacy? In our setting, an\nindividual example consists of a domain element $x$ labeled by $k$ unknown\nconcepts $(c_1,\\ldots,c_k)$. The goal of a multi-learner is to output $k$\nhypotheses $(h_1,\\ldots,h_k)$ that generalize the input examples.\n  Without concern for privacy, the sample complexity needed to simultaneously\nlearn $k$ concepts is essentially the same as needed for learning a single\nconcept. Under differential privacy, the basic strategy of learning each\nhypothesis independently yields sample complexity that grows polynomially with\n$k$. For some concept classes, we give multi-learners that require fewer\nsamples than the basic strategy. Unfortunately, however, we also give lower\nbounds showing that even for very simple concept classes, the sample cost of\nprivate multi-learning must grow polynomially in $k$.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2015 03:57:22 GMT"}], "update_date": "2015-11-30", "authors_parsed": [["Bun", "Mark", ""], ["Nissim", "Kobbi", ""], ["Stemmer", "Uri", ""]]}, {"id": "1511.08681", "submitter": "Christos Dimitrakakis", "authors": "Aristide Tossou, Christos Dimitrakakis", "title": "Algorithms for Differentially Private Multi-Armed Bandits", "comments": null, "journal-ref": "AAAI 2016, Feb 2016, Phoenix, Arizona, United States", "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present differentially private algorithms for the stochastic Multi-Armed\nBandit (MAB) problem. This is a problem for applications such as adaptive\nclinical trials, experiment design, and user-targeted advertising where private\ninformation is connected to individual rewards. Our major contribution is to\nshow that there exist $(\\epsilon, \\delta)$ differentially private variants of\nUpper Confidence Bound algorithms which have optimal regret, $O(\\epsilon^{-1} +\n\\log T)$. This is a significant improvement over previous results, which only\nachieve poly-log regret $O(\\epsilon^{-2} \\log^{2} T)$, because of our use of a\nnovel interval-based mechanism. We also substantially improve the bounds of\nprevious family of algorithms which use a continual release mechanism.\nExperiments clearly validate our theoretical bounds.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2015 14:16:00 GMT"}], "update_date": "2015-11-30", "authors_parsed": [["Tossou", "Aristide", ""], ["Dimitrakakis", "Christos", ""]]}, {"id": "1511.08756", "submitter": "Daniel Gruss", "authors": "Peter Pessl, Daniel Gruss, Cl\\'ementine Maurice, Michael Schwarz,\n  Stefan Mangard", "title": "DRAMA: Exploiting DRAM Addressing for Cross-CPU Attacks", "comments": "Original publication in the Proceedings of the 25th Annual USENIX\n  Security Symposium (USENIX Security 2016).\n  https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/pessl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cloud computing environments, multiple tenants are often co-located on the\nsame multi-processor system. Thus, preventing information leakage between\ntenants is crucial. While the hypervisor enforces software isolation, shared\nhardware, such as the CPU cache or memory bus, can leak sensitive information.\nFor security reasons, shared memory between tenants is typically disabled.\nFurthermore, tenants often do not share a physical CPU. In this setting, cache\nattacks do not work and only a slow cross-CPU covert channel over the memory\nbus is known. In contrast, we demonstrate a high-speed covert channel as well\nas the first side-channel attack working across processors and without any\nshared memory. To build these attacks, we use the undocumented DRAM address\nmappings.\n  We present two methods to reverse engineer the mapping of memory addresses to\nDRAM channels, ranks, and banks. One uses physical probing of the memory bus,\nthe other runs entirely in software and is fully automated. Using this mapping,\nwe introduce DRAMA attacks, a novel class of attacks that exploit the DRAM row\nbuffer that is shared, even in multi-processor systems. Thus, our attacks work\nin the most restrictive environments. First, we build a covert channel with a\ncapacity of up to 2 Mbps, which is three to four orders of magnitude faster\nthan memory-bus-based channels. Second, we build a side-channel template attack\nthat can automatically locate and monitor memory accesses. Third, we show how\nusing the DRAM mappings improves existing attacks and in particular enables\npractical Rowhammer attacks on DDR4.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2015 17:45:57 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2015 09:29:06 GMT"}, {"version": "v3", "created": "Sun, 19 Jun 2016 19:40:38 GMT"}, {"version": "v4", "created": "Tue, 28 Jun 2016 13:18:23 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["Pessl", "Peter", ""], ["Gruss", "Daniel", ""], ["Maurice", "Cl\u00e9mentine", ""], ["Schwarz", "Michael", ""], ["Mangard", "Stefan", ""]]}, {"id": "1511.08800", "submitter": "Li Yang", "authors": "Hong-Wei Li, Li Yang", "title": "Quantum differential cryptanalysis to the block ciphers", "comments": "11 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential cryptanalysis is one of the most popular methods in attacking\nblock ciphers. However, there still some limitations in traditional\ndifferential cryptanalysis. On the other hand, researches of quantum algorithms\nhave made great progress nowadays. This paper proposes two methods to apply\nquantum algorithms in differential cryptanalysis, and analysis their\nefficiencies and success probabilities. One method is using quantum algorithm\nin the high probability differential finding period for every S-Box. The second\nmethod is taking the encryption as a whole, using quantum algorithm in this\nprocess.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2015 06:07:23 GMT"}], "update_date": "2015-12-01", "authors_parsed": [["Li", "Hong-Wei", ""], ["Yang", "Li", ""]]}, {"id": "1511.08839", "submitter": "Luiz Capretz Dr.", "authors": "Marwan Darwish, Abdelkader Ouda, Luiz Fernando Capretz", "title": "Cloud-based DDoS Attacks and Defenses", "comments": null, "journal-ref": "IEEE International Conference on Information Society (i-Society\n  2013), pp. 67-71, 2013", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safety and reliability are important in the cloud computing environment. This\nis especially true today as distributed denial-of-service (DDoS) attacks\nconstitute one of the largest threats faced by Internet users and cloud\ncomputing services. DDoS attacks target the resources of these services,\nlowering their ability to provide optimum usage of the network infrastructure.\nDue to the nature of cloud computing, the methodologies for preventing or\nstopping DDoS attacks are quite different compared to those used in traditional\nnetworks. In this paper, we investigate the effect of DDoS attacks on cloud\nresources and recommend practical defense mechanisms against different types of\nDDoS attacks in the cloud environment.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2015 22:18:44 GMT"}], "update_date": "2015-12-01", "authors_parsed": [["Darwish", "Marwan", ""], ["Ouda", "Abdelkader", ""], ["Capretz", "Luiz Fernando", ""]]}, {"id": "1511.09116", "submitter": "Bridger Hahn", "authors": "Nolan Donoghue, Bridger Hahn, Helen Xu, Thomas Kroeger, David Zage and\n  Rob Johnson", "title": "Tracking Network Events with Write Optimized Data Structures: The Design\n  and Implementation of TWIAD: The Write-Optimized IP Address Database", "comments": "7 pages, 2 figures, 6 tables. Submitted and accepted to BADGERS 2015\n  at RAID 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Access to network traffic records is an integral part of recognizing and\naddressing network security breaches. Even with the increasing sophistication\nof network attacks, basic network events such as connections between two IP\naddresses play an important role in any network defense. Given the duration of\ncurrent attacks, long-term data archival is critical but typically very little\nof the data is ever accessed. Previous work has provided tools and identified\nthe need to trace connections. However, traditional databases raise performance\nconcerns as they are optimized for querying rather than ingestion.\n  The study of write-optimized data structures (WODS) is a new and growing\nfield that provides a novel approach to traditional storage structures (e.g.,\nB-trees). WODS trade minor degradations in query performance for significant\ngains in the ability to quickly insert more data elements, typically on the\norder of 10 to 100 times more inserts per second. These efficient,\nout-of-memory data structures can play a critical role in enabling robust,\nlong-term tracking of network events.\n  In this paper, we present TWIAD, the Write-optimized IP Address Database.\nTWIAD uses a write-optimized B-tree known as a B {\\epsilon} tree to track all\nIP address connections in a network traffic stream. Our initial implementation\nfocuses on utilizing lower cost hardware, demonstrating that basic long-term\ntracking can be done without advanced equipment. We tested TWIAD on a modest\ndesktop system and showed a sustained ingestion rate of about 20,000 inserts\nper second.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2015 00:23:34 GMT"}], "update_date": "2015-12-01", "authors_parsed": [["Donoghue", "Nolan", ""], ["Hahn", "Bridger", ""], ["Xu", "Helen", ""], ["Kroeger", "Thomas", ""], ["Zage", "David", ""], ["Johnson", "Rob", ""]]}, {"id": "1511.09199", "submitter": "Bernd Roellgen", "authors": "G. Brands, C.B. Roellgen, K.U. Vogel", "title": "QRKE: Extensions", "comments": "Algorithm has been broken", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Permutable Chebyshev polynomials (T polynomials) defined over the field of\nreal numbers are suitable for creating a Diffie-Hellman-like key exchange\nalgorithm that is able to withstand attacks using quantum computers. The\nalgorithm takes advantage of the commutative properties of Chebyshev\npolynomials of the first kind. We show how T polynomial values can be computed\nfaster and how the underlying principle can further be used to create public\nkey encryption methods, as well as certificate-like authentication-, and\nsignature schemes.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2015 08:43:36 GMT"}, {"version": "v2", "created": "Fri, 19 Jan 2018 13:33:20 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Brands", "G.", ""], ["Roellgen", "C. B.", ""], ["Vogel", "K. U.", ""]]}]