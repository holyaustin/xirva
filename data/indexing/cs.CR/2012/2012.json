[{"id": "2012.00136", "submitter": "Harry Halpin", "authors": "Harry Halpin", "title": "A Critique of Immunity Passports and W3C Decentralized Identifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Due to the widespread COVID-19 pandemic, there has been a push for `immunity\npassports' and even technical proposals. Although the debate about the medical\nand ethical problems of immunity passports has been widespread, there has been\nless inspection of the technical foundations of immunity passport schemes.\nThese schemes are envisaged to be used for sharing COVID-19 test and\nvaccination results in general. The most prominent immunity passport schemes\nhave involved a stack of little-known standards, such as Decentralized\nIdentifiers (DIDs) and Verifiable Credentials (VCs) from the World Wide Web\nConsortium (W3C). Our analysis shows that this group of technical identity\nstandards are based on under-specified and often non-standardized documents\nthat have substantial security and privacy issues, due in part to the\nquestionable use of blockchain technology. One concrete proposal for immunity\npassports is even susceptible to dictionary attacks. The use of `cryptography\ntheater' in efforts like immunity passports, where cryptography is used to\nallay the privacy concerns of users, should be discouraged in standardization.\nDeployment of these W3C standards for `self-sovereign identity' in use-cases\nlike immunity passports could just as well lead to a dangerous form identity\ntotalitarianism.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 22:10:43 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Halpin", "Harry", ""]]}, {"id": "2012.00193", "submitter": "Muhammad Usman", "authors": "Muhammad Usman", "title": "Lightweight Encryption for the Low Powered IoT Devices", "comments": "This is a short survey of lightweight encryption algorithms used in\n  IoT, submitted as an assignment for the graduate course titled \"Internet of\n  Things\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The internet of things refers to the network of devices connected to the\ninternet and can communicate with each other. The term things is to refer\nnon-conventional devices that are usually not connected to the internet. The\nnetwork of such devices or things is growing at an enormous rate. The security\nand privacy of the data flowing through these things is a major concern. The\ndevices are low powered and the conventional encryption algorithms are not\nsuitable to be employed on these devices. In this correspondence a survey of\nthe contemporary lightweight encryption algorithms suitable for use in the IoT\nenvironment has been presented.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 00:59:33 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 05:15:27 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Usman", "Muhammad", ""]]}, {"id": "2012.00283", "submitter": "Ayan Mahalanobis", "authors": "Chris Monico and Ayan Mahalanobis", "title": "A remark on MAKE -- a Matrix Action Key Exchange", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In a recent paper [arXiv:2009.00716], Rahman and Shpilrain proposed a new\nkey-exchange protocol MAKE based on external semidirect product of groups. The\npurpose of this paper is to show that the key exchange protocol is insecure. We\nwere able to break their challenge problem in under a second.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 05:55:52 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Monico", "Chris", ""], ["Mahalanobis", "Ayan", ""]]}, {"id": "2012.00463", "submitter": "Faisal Hussain", "authors": "Faisal Hussain, Syed Ghazanfar Abbas, Ubaid U. Fayyaz, Ghalib A. Shah,\n  Abdullah Toqeer, Ahmad Ali", "title": "Towards a Universal Features Set for IoT Botnet Attacks Detection", "comments": "Accepted in 2020 IEEE 23rd International Multitopic Conference\n  (INMIC), 7 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The security pitfalls of IoT devices make it easy for the attackers to\nexploit the IoT devices and make them a part of a botnet. Once hundreds of\nthousands of IoT devices are compromised and become the part of a botnet, the\nattackers use this botnet to launch the large and complex distributed denial of\nservice (DDoS) attacks which take down the target websites or services and make\nthem unable to respond the legitimate users. So far, many botnet detection\ntechniques have been proposed but their performance is limited to a specific\ndataset on which they are trained. This is because the features used to train a\nmachine learning model on one botnet dataset, do not perform well on other\ndatasets due to the diversity of attack patterns. Therefore, in this paper, we\npropose a universal features set to better detect the botnet attacks regardless\nof the underlying dataset. The proposed features set manifest preeminent\nresults for detecting the botnet attacks when tested the trained machine\nlearning models over three different botnet attack datasets.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 13:15:57 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Hussain", "Faisal", ""], ["Abbas", "Syed Ghazanfar", ""], ["Fayyaz", "Ubaid U.", ""], ["Shah", "Ghalib A.", ""], ["Toqeer", "Abdullah", ""], ["Ali", "Ahmad", ""]]}, {"id": "2012.00472", "submitter": "Martin Kleppmann", "authors": "Martin Kleppmann, Heidi Howard", "title": "Byzantine Eventual Consistency and the Fundamental Limits of\n  Peer-to-Peer Databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sybil attacks, in which a large number of adversary-controlled nodes join a\nnetwork, are a concern for many peer-to-peer database systems, necessitating\nexpensive countermeasures such as proof-of-work. However, there is a category\nof database applications that are, by design, immune to Sybil attacks because\nthey can tolerate arbitrary numbers of Byzantine-faulty nodes. In this paper,\nwe characterize this category of applications using a consistency model we call\nByzantine Eventual Consistency (BEC). We introduce an algorithm that guarantees\nBEC based on Byzantine causal broadcast, prove its correctness, and demonstrate\nnear-optimal performance in a prototype implementation.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 13:24:09 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Kleppmann", "Martin", ""], ["Howard", "Heidi", ""]]}, {"id": "2012.00517", "submitter": "Tuomo Sipola", "authors": "Joni Korpihalkola, Tuomo Sipola, Samir Puuska, Tero Kokkonen", "title": "One-Pixel Attack Deceives Computer-Assisted Diagnosis of Cancer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer vision and machine learning can be used to automate various tasks in\ncancer diagnostic and detection. If an attacker can manipulate the automated\nprocessing, the results can be devastating and in the worst case lead to wrong\ndiagnosis and treatment. In this research, the goal is to demonstrate the use\nof one-pixel attacks in a real-life scenario with a real pathology dataset,\nTUPAC16, which consists of digitized whole-slide images. We attack against the\nIBM CODAIT's MAX breast cancer detector using adversarial images. These\nadversarial examples are found using differential evolution to perform the\none-pixel modification to the images in the dataset. The results indicate that\na minor one-pixel modification of a whole slide image under analysis can affect\nthe diagnosis by reversing the automatic diagnosis result. The attack poses a\nthreat from the cyber security perspective: the one-pixel method can be used as\nan attack vector by a motivated attacker.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 14:27:28 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 09:42:34 GMT"}, {"version": "v3", "created": "Wed, 2 Jun 2021 12:06:48 GMT"}, {"version": "v4", "created": "Wed, 16 Jun 2021 12:59:02 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Korpihalkola", "Joni", ""], ["Sipola", "Tuomo", ""], ["Puuska", "Samir", ""], ["Kokkonen", "Tero", ""]]}, {"id": "2012.00648", "submitter": "Prerit Datta", "authors": "Prerit Datta, Natalie Lodinger, Akbar Siami Namin, Keith S. Jones", "title": "Cyber-Attack Consequence Prediction", "comments": "9 pages. The pre-print of a paper to appear in the proceedings of the\n  3rd Workshop on Big Data Engineering and Analytics in Cyber-Physical Systems\n  (BigEACPS'20), IEEE BigData Conference 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cyber-physical systems posit a complex number of security challenges due to\ninterconnection of heterogeneous devices having limited processing,\ncommunication, and power capabilities. Additionally, the conglomeration of both\nphysical and cyber-space further makes it difficult to devise a single security\nplan spanning both these spaces. Cyber-security researchers are often\noverloaded with a variety of cyber-alerts on a daily basis many of which turn\nout to be false positives. In this paper, we use machine learning and natural\nlanguage processing techniques to predict the consequences of cyberattacks. The\nidea is to enable security researchers to have tools at their disposal that\nmakes it easier to communicate the attack consequences with various\nstakeholders who may have little to no cybersecurity expertise. Additionally,\nwith the proposed approach researchers' cognitive load can be reduced by\nautomatically predicting the consequences of attacks in case new attacks are\ndiscovered. We compare the performance through various machine learning models\nemploying word vectors obtained using both tf-idf and Doc2Vec models. In our\nexperiments, an accuracy of 60% was obtained using tf-idf features and 57%\nusing Doc2Vec method for models based on LinearSVC model.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 17:18:47 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 18:57:49 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Datta", "Prerit", ""], ["Lodinger", "Natalie", ""], ["Namin", "Akbar Siami", ""], ["Jones", "Keith S.", ""]]}, {"id": "2012.00687", "submitter": "Ilia Shumailov", "authors": "Almos Zarandy, Ilia Shumailov, Ross Anderson", "title": "Hey Alexa what did I just type? Decoding smartphone sounds with a voice\n  assistant", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Voice assistants are now ubiquitous and listen in on our everyday lives. Ever\nsince they became commercially available, privacy advocates worried that the\ndata they collect can be abused: might private conversations be extracted by\nthird parties? In this paper we show that privacy threats go beyond spoken\nconversations and include sensitive data typed on nearby smartphones. Using two\ndifferent smartphones and a tablet we demonstrate that the attacker can extract\nPIN codes and text messages from recordings collected by a voice assistant\nlocated up to half a meter away. This shows that remote keyboard-inference\nattacks are not limited to physical keyboards but extend to virtual keyboards\ntoo. As our homes become full of always-on microphones, we need to work through\nthe implications.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 17:48:25 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Zarandy", "Almos", ""], ["Shumailov", "Ilia", ""], ["Anderson", "Ross", ""]]}, {"id": "2012.00740", "submitter": "K. R. Jayaram", "authors": "K. R. Jayaram, Archit Verma, Ashish Verma, Gegi Thomas and Colin\n  Sutcher-Shepard", "title": "MYSTIKO : : Cloud-Mediated, Private, Federated Gradient Descent", "comments": "IEEE CLOUD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning enables multiple, distributed participants (potentially on\ndifferent clouds) to collaborate and train machine/deep learning models by\nsharing parameters/gradients. However, sharing gradients, instead of\ncentralizing data, may not be as private as one would expect. Reverse\nengineering attacks on plaintext gradients have been demonstrated to be\npractically feasible. Existing solutions for differentially private federated\nlearning, while promising, lead to less accurate models and require nontrivial\nhyperparameter tuning. In this paper, we examine the use of additive\nhomomorphic encryption (specifically the Paillier cipher) to design secure\nfederated gradient descent techniques that (i) do not require addition of\nstatistical noise or hyperparameter tuning, (ii) does not alter the final\naccuracy or utility of the final model, (iii) ensure that the plaintext model\nparameters/gradients of a participant are never revealed to any other\nparticipant or third party coordinator involved in the federated learning job,\n(iv) minimize the trust placed in any third party coordinator and (v) are\nefficient, with minimal overhead, and cost effective.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 18:58:51 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Jayaram", "K. R.", ""], ["Verma", "Archit", ""], ["Verma", "Ashish", ""], ["Thomas", "Gegi", ""], ["Sutcher-Shepard", "Colin", ""]]}, {"id": "2012.00817", "submitter": "Revan MacQueen", "authors": "Revan MacQueen, Nicholas Bombardieri, James R. Wright, Karim Ali", "title": "Game Theoretic Malware Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large software platforms (e.g., mobile app stores, social media, email\nservice providers) must ensure that files on their platform do not contain\nmalicious code. Platform hosts use security tools to analyze those files for\npotential malware. However, given the expensive runtimes of tools coupled with\nthe large number of exchanged files, platforms are not able to run all tools on\nevery incoming file. Moreover, malicious parties look to find gaps in the\ncoverage of the analysis tools, and exchange files containing malware that\nexploits these vulnerabilities.\n  To address this problem, we present a novel approach that models the\nrelationship between malicious parties and the security analyst as a\nleader-follower Stackelberg security game. To estimate the parameters of our\nmodel, we have combined the information from the VirusTotal dataset with the\nmore detailed reports from the National Vulnerability Database. Compared to a\nset of natural baselines, we show that our model computes an optimal\nrandomization over sets of available security analysis tools.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 20:37:31 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["MacQueen", "Revan", ""], ["Bombardieri", "Nicholas", ""], ["Wright", "James R.", ""], ["Ali", "Karim", ""]]}, {"id": "2012.00826", "submitter": "Taoufik Yeferny", "authors": "Sofian Hamad, Taoufik Yeferny", "title": "A Chatbot for Information Security", "comments": null, "journal-ref": "IJCSNS International Journal of Computer Science and Network\n  Security, VOL.20 No.4, April 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Advancements in artificial intelligence (AI), speech recognition systems\n(ASR), and machine learning have enabled the development of intelligent\ncomputer programs called chatbots. Many chatbots have been proposed to provide\ndifferent services in many areas such as customer service, sales and marketing.\nHowever, the use of chatbot as advisers in the field of information security is\nnot yet considered. Furthermore, people, especially normal users who have no\ntechnical background, are unaware about many of aspects in information\nsecurity. Therefore, in this paper we proposed a chatbot that acts as an\nadviser in information security. The proposed adviser uses a knowledge base\nwith json file. Having such chatbot provides many features including raising\nthe awareness in field of information security by offering accurate advice,\nbased on different opinions from information security expertise, for many users\non different. Furthermore, this chatbot is currently deployed through Telegram\nplatform, which is one of widely used social network platforms. The deployment\nof the proposed chatbot over different platforms is considered as the future\nwork.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 21:20:35 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Hamad", "Sofian", ""], ["Yeferny", "Taoufik", ""]]}, {"id": "2012.00845", "submitter": "Farid Ghareh Mohammadi", "authors": "Farid Ghareh Mohammadi, Farzan Shenavarmasouleh, M. Hadi Amini and\n  Hamid R. Arabnia", "title": "Malware Detection using Artificial Bee Colony Algorithm", "comments": null, "journal-ref": null, "doi": "10.1145/3410530.3414598", "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware detection has become a challenging task due to the increase in the\nnumber of malware families. Universal malware detection algorithms that can\ndetect all the malware families are needed to make the whole process feasible.\nHowever, the more universal an algorithm is, the higher number of feature\ndimensions it needs to work with, and that inevitably causes the emerging\nproblem of Curse of Dimensionality (CoD). Besides, it is also difficult to make\nthis solution work due to the real-time behavior of malware analysis. In this\npaper, we address this problem and aim to propose a feature selection based\nmalware detection algorithm using an evolutionary algorithm that is referred to\nas Artificial Bee Colony (ABC). The proposed algorithm enables researchers to\ndecrease the feature dimension and as a result, boost the process of malware\ndetection. The experimental results reveal that the proposed method outperforms\nthe state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 21:32:09 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Mohammadi", "Farid Ghareh", ""], ["Shenavarmasouleh", "Farzan", ""], ["Amini", "M. Hadi", ""], ["Arabnia", "Hamid R.", ""]]}, {"id": "2012.00870", "submitter": "Gohar Kyureghyan M.", "authors": "Lukas K\\\"olsch, Bj\\\"orn Kriepke and Gohar M. Kyureghyan", "title": "Image sets of perfectly nonlinear maps", "comments": "Minor revision with new references; Theorems 18, 19 are added", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CR cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a lower bound on the image size of a $d$-uniform map, $d\\geq 1$,\nof finite fields, by extending the methods used for planar maps. In the\nparticularly interesting case of APN maps on binary fields, our bound coincides\nwith the one obtained by Ingo Czerwinski, using a linear programming method.\n  We study properties of APN maps of $\\mathbb{F}_{2^n}$ with minimal image set.\nIn particular, we observe that for even $n$, a Dembowski-Ostrom polynomial of\nform $f(x) =f'(x^3)$ is APN if and only if $f$ is almost-3-to-1, that is when\nits image set is minimal. We show that any almost-3-to-1 quadratic map is APN,\nif $n$ is even. For $n$ odd, we present APN Dembowski-Ostrom polynomials on\n$\\mathbb{F}_{2^n}$ with image sizes $ 2^{n-1}$ and $5\\cdot 2^{n-3}$.\n  We present several results connecting the image sets of special APN maps with\ntheir Walsh spectrum. Especially, we show that a large class of APN maps has\nthe classical Walsh spectrum. Finally, we prove that the image size of a\nnon-bijective almost bent map contains at most $2^n-2^{(n-1)/2}$ elements.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 22:21:32 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 20:04:11 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["K\u00f6lsch", "Lukas", ""], ["Kriepke", "Bj\u00f6rn", ""], ["Kyureghyan", "Gohar M.", ""]]}, {"id": "2012.01032", "submitter": "Shuyu Zheng", "authors": "Shuyu Zheng, Haoyu Wang, Lei Wu, Gang Huang, Xuanzhe Liu", "title": "VM Matters: A Comparison of WASM VMs and EVMs in the Performance of\n  Blockchain Smart Contracts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  WebAssemly is an emerging runtime for Web applications and has been supported\nin almost all browsers. Recently, WebAssembly is further regarded to be a the\nnext-generation environment for blockchain applications, and has been adopted\nby Ethereum, namely eWASM, to replace the state-of-the-art EVM. However,\nwhether and how well current eWASM outperforms EVM on blockchain clients is\nstill unknown. This paper conducts the first measurement study, to measure the\nperformance on WASM VM and EVM for executing smart contracts on blockchain. To\nour surprise, the current WASM VM does not perform in expected performance. The\noverhead introduced by WASM is really non-trivial. Our results highlight the\nchallenges when deploying WASM in practice, and provide insightful implications\nfor improvement space.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 09:01:13 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 07:41:41 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Zheng", "Shuyu", ""], ["Wang", "Haoyu", ""], ["Wu", "Lei", ""], ["Huang", "Gang", ""], ["Liu", "Xuanzhe", ""]]}, {"id": "2012.01046", "submitter": "Lutan Zhao", "authors": "Fengkai Yuan and Kai Wang and Rui Hou and Xiaoxin Li and Peinan Li and\n  Lutan Zhao and Jiameng Ying and Amro Awad and Dan Meng", "title": "PiPoMonitor: Mitigating Cross-core Cache Attacks Using the Auto-Cuckoo\n  Filter", "comments": "This paper is going to appear in 2021 Design, Automation and Test in\n  Europe Conference (DATE)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cache side channel attacks obtain victim cache line access footprint to infer\nsecurity-critical information. Among them, cross-core attacks exploiting the\nshared last level cache are more threatening as their simplicity to set up and\nhigh capacity. Stateful approaches of detection-based mitigation observe\nprecise cache behaviors and protect specific cache lines that are suspected of\nbeing attacked. However, their recording structures incur large storage\noverhead and are vulnerable to reverse engineering attacks. Exploring the\nintrinsic non-determinate layout of a traditional Cuckoo filter, this paper\nproposes a space efficient Auto-Cuckoo filter to record access footprints,\nwhich succeed to decrease storage overhead and resist reverse engineering\nattacks at the same time. With Auto-Cuckoo filter, we propose PiPoMonitor to\ndetect \\textit{Ping-Pong patterns} and prefetch specific cache line to\ninterfere with adversaries' cache probes. Security analysis shows the\nPiPoMonitor can effectively mitigate cross-core attacks and the Auto-Cuckoo\nfilter is immune to reverse engineering attacks. Evaluation results indicate\nPiPoMonitor has negligible impact on performance and the storage overhead is\nonly 0.37$\\%$, an order of magnitude lower than previous stateful approaches.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 09:30:03 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 08:13:39 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Yuan", "Fengkai", ""], ["Wang", "Kai", ""], ["Hou", "Rui", ""], ["Li", "Xiaoxin", ""], ["Li", "Peinan", ""], ["Zhao", "Lutan", ""], ["Ying", "Jiameng", ""], ["Awad", "Amro", ""], ["Meng", "Dan", ""]]}, {"id": "2012.01107", "submitter": "Mark Scanlon", "authors": "Samuel Todd Bromley and John Sheppard and Mark Scanlon and Nhien-An\n  Le-Khac", "title": "Retracing the Flow of the Stream: Investigating Kodi Streaming Services", "comments": null, "journal-ref": "Digital Forensics and Cyber Crime: 11th EAI International\n  Conference on Digital Forensics and Cybercrime (ICDF2C), Boston, USA,\n  September 2020", "doi": null, "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kodi is of one of the world's largest open-source streaming platforms for\nviewing video content. Easily installed Kodi add-ons facilitate access to\nonline pirated videos and streaming content by facilitating the user to search\nand view copyrighted videos with a basic level of technical knowledge. In some\ncountries, there have been paid child sexual abuse organizations\npublishing/streaming child abuse material to an international paying clientele.\nOpen source software used for viewing videos from the Internet, such as Kodi,\nis being exploited by criminals to conduct their activities. In this paper, we\ndescribe a new method to quickly locate Kodi artifacts and gather information\nfor a successful prosecution. We also evaluate our approach on different\nplatforms; Windows, Android and Linux. Our experiments show the file location,\nartifacts and a history of viewed content including their locations from the\nInternet. Our approach will serve as a resource to forensic investigators to\nexamine Kodi or similar streaming platforms.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 11:47:20 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Bromley", "Samuel Todd", ""], ["Sheppard", "John", ""], ["Scanlon", "Mark", ""], ["Le-Khac", "Nhien-An", ""]]}, {"id": "2012.01119", "submitter": "Gamal Elkoumy", "authors": "Gamal Elkoumy, Alisa Pankova and Marlon Dumas", "title": "Privacy-Preserving Directly-Follows Graphs: Balancing Risk and Utility\n  in Process Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process mining techniques enable organizations to analyze business process\nexecution traces in order to identify opportunities for improving their\noperational performance. Oftentimes, such execution traces contain private\ninformation. For example, the execution traces of a healthcare process are\nlikely to be privacy-sensitive. In such cases, organizations need to deploy\nPrivacy-Enhancing Technologies (PETs) to strike a balance between the benefits\nthey get from analyzing these data and the requirements imposed onto them by\nprivacy regulations, particularly that of minimizing re-identification risks\nwhen data are disclosed to a process analyst. Among many available PETs,\ndifferential privacy stands out for its ability to prevent predicate singling\nout attacks and its composable privacy guarantees. A drawback of differential\nprivacy is the lack of interpretability of the main privacy parameter it relies\nupon, namely epsilon. This leads to the recurrent question of how much epsilon\nis enough? This article proposes a method to determine the epsilon value to be\nused when disclosing the output of a process mining technique in terms of two\nbusiness-relevant metrics, namely absolute percentage error metrics capturing\nthe loss of accuracy (a.k.a. utility loss) resulting from adding noise to the\ndisclosed data, and guessing advantage, which captures the increase in the\nprobability that an adversary may guess information about an individual as a\nresult of a disclosure. The article specifically studies the problem of\nprotecting the disclosure of the so-called Directly-Follows Graph (DFGs), which\nis a process mining artifact produced by most process mining tools. The article\nreports on an empirical evaluation of the utility-risk trade-offs that the\nproposed approach achieves on a collection of 13 real-life event logs.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 12:24:00 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 06:02:03 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Elkoumy", "Gamal", ""], ["Pankova", "Alisa", ""], ["Dumas", "Marlon", ""]]}, {"id": "2012.01159", "submitter": "Mark Scanlon", "authors": "Aikaterini Kanta, Iwen Coisel and Mark Scanlon", "title": "Smarter Password Guessing Techniques Leveraging Contextual Information\n  and OSINT", "comments": null, "journal-ref": "The 6th IEEE International Conference on Cyber Security and\n  Protection of Digital Services (Cyber Security 2020)", "doi": "10.1109/CyberSecurity49315.2020.9138870", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent decades, criminals have increasingly used the web to research,\nassist and perpetrate criminal behaviour. One of the most important ways in\nwhich law enforcement can battle this growing trend is through accessing\npertinent information about suspects in a timely manner. A significant\nhindrance to this is the difficulty of accessing any system a suspect uses that\nrequires authentication via password. Password guessing techniques generally\nconsider common user behaviour while generating their passwords, as well as the\npassword policy in place. Such techniques can offer a modest success rate\nconsidering a large/average population. However, they tend to fail when\nfocusing on a single target -- especially when the latter is an educated user\ntaking precautions as a savvy criminal would be expected to do. Open Source\nIntelligence is being increasingly leveraged by Law Enforcement in order to\ngain useful information about a suspect, but very little is currently being\ndone to integrate this knowledge in an automated way within password cracking.\nThe purpose of this research is to delve into the techniques that enable the\ngathering of the necessary context about a suspect and find ways to leverage\nthis information within password guessing techniques.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 12:58:04 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Kanta", "Aikaterini", ""], ["Coisel", "Iwen", ""], ["Scanlon", "Mark", ""]]}, {"id": "2012.01174", "submitter": "Francesca Cuomo", "authors": "Pietro Spadaccino and Francesca Cuomo", "title": "Intrusion Detection Systems for IoT: opportunities and challenges\n  offered by Edge Computing", "comments": "Paper submitted for publication in the IEEE Communications Surveys &\n  Tutorials", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Key components of current cybersecurity methods are the Intrusion Detection\nSystems (IDSs) were different techniques and architectures are applied to\ndetect intrusions. IDSs can be based either on cross-checking monitored events\nwith a database of known intrusion experiences, known as signature-based, or on\nlearning the normal behavior of the system and reporting whether some anomalous\nevents occur, named anomaly-based. This work is dedicated to the application to\nthe Internet of Things (IoT) network where edge computing is used to support\nthe IDS implementation. New challenges that arise when deploying an IDS in an\nedge scenario are identified and remedies are proposed. We focus on\nanomaly-based IDSs, showing the main techniques that can be leveraged to detect\nanomalies and we present machine learning techniques and their application in\nthe context of an IDS, describing the expected advantages and disadvantages\nthat a specific technique could cause.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 13:07:27 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Spadaccino", "Pietro", ""], ["Cuomo", "Francesca", ""]]}, {"id": "2012.01370", "submitter": "Xiaoqi Li", "authors": "Xiaoqi Li, Ting Chen, Xiapu Luo, Chenxu Wang", "title": "CLUE: Towards Discovering Locked Cryptocurrencies in Ethereum", "comments": "In Proceedings of the 36th ACM/SIGAPP Symposium on Applied Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As the most popular blockchain that supports smart contracts, there are\nalready more than 296 thousand kinds of cryptocurrencies built on Ethereum.\nHowever, not all cryptocurrencies can be controlled by users. For example, some\nmoney is permanently locked in wallets' accounts due to attacks. In this paper,\nwe conduct the first systematic investigation on locked cryptocurrencies in\nEthereum. In particular, we define three categories of accounts with locked\ncryptocurrencies and develop a novel tool named CLUE to discover them. Results\nshow that there are more than 216 million dollars value of cryptocurrencies\nlocked in Ethereum. We also analyze the reasons (i.e., attacks/behaviors) why\ncryptocurrencies are locked. Because the locked cryptocurrencies can never be\ncontrolled by users, avoid interacting with the accounts discovered by CLUE and\nrepeating the same mistakes again can help users to save money.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 18:11:11 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Li", "Xiaoqi", ""], ["Chen", "Ting", ""], ["Luo", "Xiapu", ""], ["Wang", "Chenxu", ""]]}, {"id": "2012.01382", "submitter": "Geoffrey Goodell", "authors": "Oscar King and Geoffrey Goodell", "title": "Analysis of a Decentralised Digital Token Architecture for Public\n  Transport", "comments": "23 pages, 7 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digitisation is often viewed as beneficial to a user. Where originally people\nwould physically have to identify to a service, pay for a ticket in cash, or go\ninto a library to access a book, people can now achieve all of this through a\nclick of a button. While these actions may seem functionally identical to their\nanalogue counterparts, they come with one important difference. Namely, in the\ndigital case, a user's actions are automatically recorded. The recording of\nuser's interactions presents a problem because this information can be used\noutside the control of the person whom it concerns. This issue is only\nexacerbated by the centralisation of these aforementioned services'\nauthentication mechanisms permitting the collection of even more data.\n  This work aims to motivate the need and establish the feasibility for the\napplication of a privacy-enhancing digital token management service to public\ntransit. A proof-of-concept implementation of the Decentralised Digital\nIdentity Architecture proposed by Goodell and Aste is developed. This\nimplementation was optimised for the public transport use case. Finally, its\nperformance is tested in a local environment to better understand the technical\nchallenges and assess such a system's technical feasibility in a production\nsetting. It was observed that for loads between 1 and 5 requests per second the\nproof-of-concept performs within acceptable limits with a maximum median\nresponse time of 334 milliseconds. Above 5 requests per second response times\ndrastically increase due to hardware bottlenecks.\n  It was concluded that the demonstrated throughput and latency shows that the\nsystem can feasibly compete with solutions currently in use. Yet, further work\nis needed to demonstrate these performance characteristics in an environment\nsimilar to that experienced in production.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 18:24:43 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["King", "Oscar", ""], ["Goodell", "Geoffrey", ""]]}, {"id": "2012.01553", "submitter": "Lucy Simko", "authors": "Lucy Simko, Jack Lucas Chang, Maggie Jiang, Ryan Calo, Franziska\n  Roesner, Tadayoshi Kohno", "title": "COVID-19 Contact Tracing and Privacy: A Longitudinal Study of Public\n  Opinion", "comments": "37 pages, 11 figures. Supercedes arXiv:2005.06056", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is growing use of technology-enabled contact tracing, the process of\nidentifying potentially infected COVID-19 patients by notifying all recent\ncontacts of an infected person. Governments, technology companies, and research\ngroups alike have been working towards releasing smartphone apps, using IoT\ndevices, and distributing wearable technology to automatically track \"close\ncontacts\" and identify prior contacts in the event an individual tests\npositive. However, there has been significant public discussion about the\ntensions between effective technology-based contact tracing and the privacy of\nindividuals. To inform this discussion, we present the results of seven months\nof online surveys focused on contact tracing and privacy, each with 100\nparticipants. Our first surveys were on April 1 and 3, before the first peak of\nthe virus in the US, and we continued to conduct the surveys weekly for 10\nweeks (through June), and then fortnightly through November, adding topical\nquestions to reflect current discussions about contact tracing and COVID-19.\nOur results present the diversity of public opinion and can inform policy\nmakers, technologists, researchers, and public health experts on whether and\nhow to leverage technology to reduce the spread of COVID-19, while considering\npotential privacy concerns. We are continuing to conduct longitudinal\nmeasurements and will update this report over time; citations to this version\nof the report should reference Report Version 2.0, December 4, 2020.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 21:50:42 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 19:07:10 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Simko", "Lucy", ""], ["Chang", "Jack Lucas", ""], ["Jiang", "Maggie", ""], ["Calo", "Ryan", ""], ["Roesner", "Franziska", ""], ["Kohno", "Tadayoshi", ""]]}, {"id": "2012.01592", "submitter": "Zeyu Ding", "authors": "Zeyu Ding, Yuxin Wang, Yingtai Xiao, Guanhong Wang, Danfeng Zhang,\n  Daniel Kifer", "title": "Free Gap Estimates from the Exponential Mechanism, Sparse Vector, Noisy\n  Max and Related Algorithms", "comments": "arXiv admin note: substantial text overlap with arXiv:1904.12773", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Private selection algorithms, such as the Exponential Mechanism, Noisy Max\nand Sparse Vector, are used to select items (such as queries with large\nanswers) from a set of candidates, while controlling privacy leakage in the\nunderlying data. Such algorithms serve as building blocks for more complex\ndifferentially private algorithms. In this paper we show that these algorithms\ncan release additional information related to the gaps between the selected\nitems and the other candidates for free (i.e., at no additional privacy cost).\nThis free gap information can improve the accuracy of certain follow-up\ncounting queries by up to 66%. We obtain these results from a careful privacy\nanalysis of these algorithms. Based on this analysis, we further propose novel\nhybrid algorithms that can dynamically save additional privacy budget.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 23:28:27 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Ding", "Zeyu", ""], ["Wang", "Yuxin", ""], ["Xiao", "Yingtai", ""], ["Wang", "Guanhong", ""], ["Zhang", "Danfeng", ""], ["Kifer", "Daniel", ""]]}, {"id": "2012.01699", "submitter": "Ryan Feng", "authors": "Ryan Feng, Wu-chi Feng, Atul Prakash", "title": "Essential Features: Reducing the Attack Surface of Adversarial\n  Perturbations with Robust Content-Aware Image Preprocessing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversaries are capable of adding perturbations to an image to fool machine\nlearning models into incorrect predictions. One approach to defending against\nsuch perturbations is to apply image preprocessing functions to remove the\neffects of the perturbation. Existing approaches tend to be designed\northogonally to the content of the image and can be beaten by adaptive attacks.\nWe propose a novel image preprocessing technique called Essential Features that\ntransforms the image into a robust feature space that preserves the main\ncontent of the image while significantly reducing the effects of the\nperturbations. Specifically, an adaptive blurring strategy that preserves the\nmain edge features of the original object along with a k-means color reduction\napproach is employed to simplify the image to its k most representative colors.\nThis approach significantly limits the attack surface for adversaries by\nlimiting the ability to adjust colors while preserving pertinent features of\nthe original image. We additionally design several adaptive attacks and find\nthat our approach remains more robust than previous baselines. On CIFAR-10 we\nachieve 64% robustness and 58.13% robustness on RESISC45, raising robustness by\nover 10% versus state-of-the-art adversarial training techniques against\nadaptive white-box and black-box attacks. The results suggest that strategies\nthat retain essential features in images by adaptive processing of the content\nhold promise as a complement to adversarial training for boosting robustness\nagainst adversarial inputs.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 04:40:51 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Feng", "Ryan", ""], ["Feng", "Wu-chi", ""], ["Prakash", "Atul", ""]]}, {"id": "2012.01701", "submitter": "Yi Zeng", "authors": "Han Qiu, Yi Zeng, Tianwei Zhang, Yong Jiang, and Meikang Qiu", "title": "FenceBox: A Platform for Defeating Adversarial Examples with Data\n  Augmentation Techniques", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is extensively studied that Deep Neural Networks (DNNs) are vulnerable to\nAdversarial Examples (AEs). With more and more advanced adversarial attack\nmethods have been developed, a quantity of corresponding defense solutions were\ndesigned to enhance the robustness of DNN models. It has become a popularity to\nleverage data augmentation techniques to preprocess input samples before\ninference to remove adversarial perturbations. By obfuscating the gradients of\nDNN models, these approaches can defeat a considerable number of conventional\nattacks. Unfortunately, advanced gradient-based attack techniques (e.g., BPDA\nand EOT) were introduced to invalidate these preprocessing effects.\n  In this paper, we present FenceBox, a comprehensive framework to defeat\nvarious kinds of adversarial attacks. FenceBox is equipped with 15 data\naugmentation methods from three different categories. We comprehensively\nevaluated that these methods can effectively mitigate various adversarial\nattacks. FenceBox also provides APIs for users to easily deploy the defense\nover their models in different modes: they can either select an arbitrary\npreprocessing method, or a combination of functions for a better robustness\nguarantee, even under advanced adversarial attacks. We open-source FenceBox,\nand expect it can be used as a standard toolkit to facilitate the research of\nadversarial attacks and defenses.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 04:56:06 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Qiu", "Han", ""], ["Zeng", "Yi", ""], ["Zhang", "Tianwei", ""], ["Jiang", "Yong", ""], ["Qiu", "Meikang", ""]]}, {"id": "2012.01765", "submitter": "Md Sadek Ferdous", "authors": "Adil Ahmed Chowdhury, Farida Chowdhury, Md Sadek Ferdous", "title": "A Study of Password Security Factors among Bangladeshi Government\n  Websites", "comments": "Accepted for publication in the 23rd International Conference on\n  Computer and Information Technology (ICCIT), 19-21 December, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Government of Bangladesh is aggressively transforming its public service\nlandscape by transforming public services into online services via a number of\nwebsites. The motivation is that this would be a catalyst for a transformative\nchange in every aspect of citizen life. Some web services must be protected\nfrom any unauthorised usages and passwords remain the most widely used\ncredential mechanism for this purpose. However, if passwords are not adopted\nproperly, they can be a cause for security breach. That is why it is important\nto study different aspects of password security on different websites. In this\npaper, we present a study of password security among 36 different Bangladeshi\ngovernment websites against six carefully chosen password security heuristics.\nThis study is the first of its kind in this domain and offers interesting\ninsights. For example, many websites have not adopted proper security measures\nwith respect to security. There is no password construction guideline adopted\nby many websites, thus creating a barrier for users to select a strong\npassword. Some of them allow supposedly weak passwords and still do not utilise\na secure HTTPS channel to transmit information over the Internet.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 08:52:49 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Chowdhury", "Adil Ahmed", ""], ["Chowdhury", "Farida", ""], ["Ferdous", "Md Sadek", ""]]}, {"id": "2012.01791", "submitter": "Giulio Zizzo", "authors": "Giulio Zizzo, Ambrish Rawat, Mathieu Sinn, Beat Buesser", "title": "FAT: Federated Adversarial Training", "comments": "NeurIPS 2020 Workshop on Scalability, Privacy, and Security in\n  Federated Learning (SpicyFL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning (FL) is one of the most important paradigms addressing\nprivacy and data governance issues in machine learning (ML). Adversarial\ntraining has emerged, so far, as the most promising approach against evasion\nthreats on ML models. In this paper, we take the first known steps towards\nfederated adversarial training (FAT) combining both methods to reduce the\nthreat of evasion during inference while preserving the data privacy during\ntraining. We investigate the effectiveness of the FAT protocol for idealised\nfederated settings using MNIST, Fashion-MNIST, and CIFAR10, and provide first\ninsights on stabilising the training on the LEAF benchmark dataset which\nspecifically emulates a federated learning environment. We identify challenges\nwith this natural extension of adversarial training with regards to achieved\nadversarial robustness and further examine the idealised settings in the\npresence of clients undermining model convergence. We find that Trimmed Mean\nand Bulyan defences can be compromised and we were able to subvert Krum with a\nnovel distillation based attack which presents an apparently \"robust\" model to\nthe defender while in fact the model fails to provide robustness against simple\nattack modifications.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 09:47:47 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Zizzo", "Giulio", ""], ["Rawat", "Ambrish", ""], ["Sinn", "Mathieu", ""], ["Buesser", "Beat", ""]]}, {"id": "2012.01812", "submitter": "Raphael Bialon", "authors": "Raphael Bialon", "title": "On Root Detection Strategies for Android Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Android operating system runs on the majority of smartphones nowadays.\nIts success is driven by its availability to a variety of smartphone hardware\nvendors on the one hand, and the customization possibilities given to its users\non the other hand. While other big smartphone operating systems restrict user\nconfiguration to a given set of functionality, Android users can leverage the\nwhole potential of their devices. This high degree of customization enabled by\na process called rooting, where the users escalate their privileges to those of\nthe operating system, introduces security, data integrity and privacy concerns.\nSeveral rooting detection mechanisms for Android devices already exist, aimed\nat different levels of detection. This paper introduces further strategies\nderived from the Linux ecosystem and outlines their usage on the Android\nplatform. In addition, we present a novel remote rooting detection approach\naimed at trust and integrity checks between devices in wireless networks.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 10:40:15 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Bialon", "Raphael", ""]]}, {"id": "2012.01813", "submitter": "Johanna Johansen Ms", "authors": "Johanna Johansen, Tore Pedersen, Simone Fischer-H\\\"ubner, Christian\n  Johansen, Gerardo Schneider, Arnold Roosendaal, Harald Zwingelberg, Anders\n  Jakob Sivesind, Josef Noll", "title": "A Multidisciplinary Definition of Privacy Labels: The Story of Princess\n  Privacy and the Seven Helpers", "comments": "29 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Privacy is currently in distress and in need of rescue, much like princesses\nin the all-familiar fairytales. We employ storytelling and metaphors from\nfairytales to make reader-friendly and streamline our arguments about how a\ncomplex concept of Privacy Labeling (the 'knight in shining armor') can be a\nsolution to the current state of Privacy (the 'princess in distress'). We give\na precise definition of Privacy Labeling (PL), painting a panoptic portrait\nfrom seven different perspectives (the 'seven helpers'): Business, Legal,\nRegulatory, Usability and Human Factors, Educative, Technological, and\nMultidisciplinary. We describe a common vision, proposing several important\n'traits of character' of PL as well as identifying 'undeveloped\npotentialities', i.e., open problems on which the community can focus. More\nspecifically, this position paper identifies the stakeholders of the PL and\ntheir needs with regard to privacy, describing how PL should be and look like\nin order to address these needs. Throughout the paper, we highlight goals,\ncharacteristics, open problems, and starting points for creating, what we\nconsider to be, the ideal PL. In the end we present three approaches to\nestablish and manage PL, through: self-evaluations, certifications, or\ncommunity endeavors. Based on these, we sketch a roadmap for future\ndevelopments.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 10:42:30 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 10:57:17 GMT"}, {"version": "v3", "created": "Sun, 9 May 2021 16:54:58 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Johansen", "Johanna", ""], ["Pedersen", "Tore", ""], ["Fischer-H\u00fcbner", "Simone", ""], ["Johansen", "Christian", ""], ["Schneider", "Gerardo", ""], ["Roosendaal", "Arnold", ""], ["Zwingelberg", "Harald", ""], ["Sivesind", "Anders Jakob", ""], ["Noll", "Josef", ""]]}, {"id": "2012.01939", "submitter": "Thomas Dalton", "authors": "Thomas Dalton, Mauritius Schmidtler, Alireza Hadj Khodabakhshi", "title": "Classifying Malware Using Function Representations in a Static Call\n  Graph", "comments": "12 pages, 6 figures, accepted to CSoNet 2020 Dallas, to be published\n  in Springer's Lecture Notes in Computer Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a deep learning approach for identifying malware families using\nthe function call graphs of x86 assembly instructions. Though prior work on\nstatic call graph analysis exists, very little involves the application of\nmodern, principled feature learning techniques to the problem. In this paper,\nwe introduce a system utilizing an executable's function call graph where\nfunction representations are obtained by way of a recurrent neural network\n(RNN) autoencoder which maps sequences of x86 instructions into dense, latent\nvectors. These function embeddings are then modeled as vertices in a graph with\nedges indicating call dependencies. Capturing rich, node-level representations\nas well as global, topological properties of an executable file greatly\nimproves malware family detection rates and contributes to a more principled\napproach to the problem in a way that deliberately avoids tedious feature\nengineering and domain expertise. We test our approach by performing several\nexperiments on a Microsoft malware classification data set and achieve\nexcellent separation between malware families with a classification accuracy of\n99.41%.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 20:36:19 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Dalton", "Thomas", ""], ["Schmidtler", "Mauritius", ""], ["Khodabakhshi", "Alireza Hadj", ""]]}, {"id": "2012.01946", "submitter": "Marco Squarcina", "authors": "Marco Squarcina, Mauro Tempesta, Lorenzo Veronese, Stefano Calzavara,\n  Matteo Maffei", "title": "Can I Take Your Subdomain? Exploring Related-Domain Attacks in the\n  Modern Web", "comments": "Submitted to USENIX Security '21 on 16 Oct 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Related-domain attackers control a sibling domain of their target web\napplication, e.g., as the result of a subdomain takeover. Despite their\nadditional power over traditional web attackers, related-domain attackers\nreceived only limited attention by the research community. In this paper we\ndefine and quantify for the first time the threats that related-domain\nattackers pose to web application security. In particular, we first clarify the\ncapabilities that related-domain attackers can acquire through different attack\nvectors, showing that different instances of the related-domain attacker\nconcept are worth attention. We then study how these capabilities can be abused\nto compromise web application security by focusing on different angles,\nincluding: cookies, CSP, CORS, postMessage and domain relaxation. By building\non this framework, we report on a large-scale security measurement on the top\n50k domains from the Tranco list that led to the discovery of vulnerabilities\nin 887 sites, where we quantified the threats posed by related-domain attackers\nto popular web applications.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 14:21:38 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Squarcina", "Marco", ""], ["Tempesta", "Mauro", ""], ["Veronese", "Lorenzo", ""], ["Calzavara", "Stefano", ""], ["Maffei", "Matteo", ""]]}, {"id": "2012.01964", "submitter": "Vaishali Kansal", "authors": "Vaishali Kansal and Mayank Dave", "title": "Proactive DDoS Attack Mitigation in Cloud-Fog Environment using Moving\n  Target Defense", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Distributed Denial of Service (DDoS) attacks are serious cyber attacks and\nmitigating DDoS attacks in cloud is a topic of ongoing research interest which\nremains a major security challenge. Fog computing is an extension of cloud\ncomputing which has been used to secure cloud. Moving Target Defense (MTD) is a\nnewly recognized, proactive security defense that can be used to mitigate DDoS\nattacks on cloud. MTD intends to make a system dynamic in nature and uncertain\nby changing attack surface continuously to confuse attackers. In this paper, a\nnovel DDoS mitigation framework is presented to support Cloud-Fog Platform\nusing MTD technique (CFPM). CFPM applies migration MTD technique at fog layer\nto mitigate DDoS attacks in cloud. It detects attacker among all the legitimate\nclients proactively at the fog layer and isolate it from innocent clients. CFPM\nuses an effective request handling procedure for load balancing and attacker\nisolation procedure which aims to minimize disruption to cloud server as well\nas serving fog servers. In addition, effectiveness of CFPM is evaluated by\nanalyzing the behavior of the system before and after attack, considering\ndifferent possible scenarios. This approach is effective as it uses the\nadvantage of both MTD technique and Fog computing paradigm supporting cloud\nenvironment.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 14:37:12 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Kansal", "Vaishali", ""], ["Dave", "Mayank", ""]]}, {"id": "2012.01968", "submitter": "Jung Ho Ahn", "authors": "Sangpyo Kim and Wonkyung Jung and Jaiyoung Park and Jung Ho Ahn", "title": "Accelerating Number Theoretic Transformations for Bootstrappable\n  Homomorphic Encryption on GPUs", "comments": "12 pages, 13 figures, to appear in IISWC 2020", "journal-ref": null, "doi": "10.1109/IISWC50251.2020.00033", "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Homomorphic encryption (HE) draws huge attention as it provides a way of\nprivacy-preserving computations on encrypted messages. Number Theoretic\nTransform (NTT), a specialized form of Discrete Fourier Transform (DFT) in the\nfinite field of integers, is the key algorithm that enables fast computation on\nencrypted ciphertexts in HE. Prior works have accelerated NTT and its inverse\ntransformation on a popular parallel processing platform, GPU, by leveraging\nDFT optimization techniques. However, these GPU-based studies lack a\ncomprehensive analysis of the primary differences between NTT and DFT or only\nconsider small HE parameters that have tight constraints in the number of\narithmetic operations that can be performed without decryption. In this paper,\nwe analyze the algorithmic characteristics of NTT and DFT and assess the\nperformance of NTT when we apply the optimizations that are commonly applicable\nto both DFT and NTT on modern GPUs. From the analysis, we identify that NTT\nsuffers from severe main-memory bandwidth bottleneck on large HE parameter\nsets. To tackle the main-memory bandwidth issue, we propose a novel\nNTT-specific on-the-fly root generation scheme dubbed on-the-fly twiddling\n(OT). Compared to the baseline radix-2 NTT implementation, after applying all\nthe optimizations, including OT, we achieve 4.2x speedup on a modern GPU.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 14:47:03 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Kim", "Sangpyo", ""], ["Jung", "Wonkyung", ""], ["Park", "Jaiyoung", ""], ["Ahn", "Jung Ho", ""]]}, {"id": "2012.01971", "submitter": "Faisal Hussain", "authors": "Faisal Hussain, Syed Ghazanfar Abbas, Muhammad Husnain, Ubaid Ullah\n  Fayyaz, Farrukh Shahzad, Ghalib A. Shah", "title": "IoT DoS and DDoS Attack Detection using ResNet", "comments": "Accepted in 2020 IEEE 23rd International Multitopic Conference\n  (INMIC), 7 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The network attacks are increasing both in frequency and intensity with the\nrapid growth of internet of things (IoT) devices. Recently, denial of service\n(DoS) and distributed denial of service (DDoS) attacks are reported as the most\nfrequent attacks in IoT networks. The traditional security solutions like\nfirewalls, intrusion detection systems, etc., are unable to detect the complex\nDoS and DDoS attacks since most of them filter the normal and attack traffic\nbased upon the static predefined rules. However, these solutions can become\nreliable and effective when integrated with artificial intelligence (AI) based\ntechniques. During the last few years, deep learning models especially\nconvolutional neural networks achieved high significance due to their\noutstanding performance in the image processing field. The potential of these\nconvolutional neural network (CNN) models can be used to efficiently detect the\ncomplex DoS and DDoS by converting the network traffic dataset into images.\nTherefore, in this work, we proposed a methodology to convert the network\ntraffic data into image form and trained a state-of-the-art CNN model, i.e.,\nResNet over the converted data. The proposed methodology accomplished 99.99\\%\naccuracy for detecting the DoS and DDoS in case of binary classification.\nFurthermore, the proposed methodology achieved 87\\% average precision for\nrecognizing eleven types of DoS and DDoS attack patterns which is 9\\% higher as\ncompared to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 13:33:27 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Hussain", "Faisal", ""], ["Abbas", "Syed Ghazanfar", ""], ["Husnain", "Muhammad", ""], ["Fayyaz", "Ubaid Ullah", ""], ["Shahzad", "Farrukh", ""], ["Shah", "Ghalib A.", ""]]}, {"id": "2012.01972", "submitter": "Mark Scanlon", "authors": "Xiaoyu Du, Quan Le and Mark Scanlon", "title": "Automated Artefact Relevancy Determination from Artefact Metadata and\n  Associated Timeline Events", "comments": null, "journal-ref": "The 6th IEEE International Conference on Cyber Security and\n  Protection of Digital Services (Cyber Security), Dublin, Ireland, June 2020", "doi": "10.1109/CyberSecurity49315.2020.9138874", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Case-hindering, multi-year digital forensic evidence backlogs have become\ncommonplace in law enforcement agencies throughout the world. This is due to an\never-growing number of cases requiring digital forensic investigation coupled\nwith the growing volume of data to be processed per case. Leveraging previously\nprocessed digital forensic cases and their component artefact relevancy\nclassifications can facilitate an opportunity for training automated artificial\nintelligence based evidence processing systems. These can significantly aid\ninvestigators in the discovery and prioritisation of evidence. This paper\npresents one approach for file artefact relevancy determination building on the\ngrowing trend towards a centralised, Digital Forensics as a Service (DFaaS)\nparadigm. This approach enables the use of previously encountered pertinent\nfiles to classify newly discovered files in an investigation. Trained models\ncan aid in the detection of these files during the acquisition stage, i.e.,\nduring their upload to a DFaaS system. The technique generates a relevancy\nscore for file similarity using each artefact's filesystem metadata and\nassociated timeline events. The approach presented is validated against three\nexperimental usage scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 14:14:26 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Du", "Xiaoyu", ""], ["Le", "Quan", ""], ["Scanlon", "Mark", ""]]}, {"id": "2012.01973", "submitter": "Ning Ge", "authors": "Yi Liu, Li Zhang, Ning Ge, Guanghao Li", "title": "A Systematic Literature Review on Federated Learning: From A Model\n  Quality Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  As an emerging technique, Federated Learning (FL) can jointly train a global\nmodel with the data remaining locally, which effectively solves the problem of\ndata privacy protection through the encryption mechanism. The clients train\ntheir local model, and the server aggregates models until convergence. In this\nprocess, the server uses an incentive mechanism to encourage clients to\ncontribute high-quality and large-volume data to improve the global model.\nAlthough some works have applied FL to the Internet of Things (IoT), medicine,\nmanufacturing, etc., the application of FL is still in its infancy, and many\nrelated issues need to be solved. Improving the quality of FL models is one of\nthe current research hotspots and challenging tasks. This paper systematically\nreviews and objectively analyzes the approaches to improving the quality of FL\nmodels. We are also interested in the research and application trends of FL and\nthe effect comparison between FL and non-FL because the practitioners usually\nworry that achieving privacy protection needs compromising learning quality. We\nuse a systematic review method to analyze 147 latest articles related to FL.\nThis review provides useful information and insights to both academia and\npractitioners from the industry. We investigate research questions about\nacademic research and industrial application trends of FL, essential factors\naffecting the quality of FL models, and compare FL and non-FL algorithms in\nterms of learning quality. Based on our review's conclusion, we give some\nsuggestions for improving the FL model quality. Finally, we propose an FL\napplication framework for practitioners.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 05:48:36 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Liu", "Yi", ""], ["Zhang", "Li", ""], ["Ge", "Ning", ""], ["Li", "Guanghao", ""]]}, {"id": "2012.01983", "submitter": "Mahmoud Badr", "authors": "Mahmoud M. Badr, Mohamed I. Ibrahem, Mohamed Mahmoud, Mostafa M.\n  Fouda, Waleed Alasmary", "title": "Detection of False-Reading Attacks in the AMI Net-Metering System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In smart grid, malicious customers may compromise their smart meters (SMs) to\nreport false readings to achieve financial gains illegally. Reporting false\nreadings not only causes hefty financial losses to the utility but may also\ndegrade the grid performance because the reported readings are used for energy\nmanagement. This paper is the first work that investigates this problem in the\nnet-metering system, in which one SM is used to report the difference between\nthe power consumed and the power generated. First, we prepare a benign dataset\nfor the net-metering system by processing a real power consumption and\ngeneration dataset. Then, we propose a new set of attacks tailored for the\nnet-metering system to create malicious dataset. After that, we analyze the\ndata and we found time correlations between the net meter readings and\ncorrelations between the readings and relevant data obtained from trustworthy\nsources such as the solar irradiance and temperature. Based on the data\nanalysis, we propose a general multi-data-source deep hybrid learning-based\ndetector to identify the false-reading attacks. Our detector is trained on net\nmeter readings of all customers besides data from the trustworthy sources to\nenhance the detector performance by learning the correlations between them. The\nrationale here is that although an attacker can report false readings, he\ncannot manipulate the solar irradiance and temperature values because they are\nbeyond his control. Extensive experiments have been conducted, and the results\nindicate that our detector can identify the false-reading attacks with high\ndetection rate and low false alarm.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 07:40:02 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Badr", "Mahmoud M.", ""], ["Ibrahem", "Mohamed I.", ""], ["Mahmoud", "Mohamed", ""], ["Fouda", "Mostafa M.", ""], ["Alasmary", "Waleed", ""]]}, {"id": "2012.01987", "submitter": "Mark Scanlon", "authors": "Xiaoyu Du, Chris Hargreaves, John Sheppard, Felix Anda, Asanka\n  Sayakkara, Nhien-An Le-Khac, Mark Scanlon", "title": "SoK: Exploring the State of the Art and the Future Potential of\n  Artificial Intelligence in Digital Forensic Investigation", "comments": null, "journal-ref": "The 15th International ARES Conference on Availability,\n  Reliability and Security, August 25--28, 2020", "doi": "10.1145/3407023.3407068", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-year digital forensic backlogs have become commonplace in law\nenforcement agencies throughout the globe. Digital forensic investigators are\noverloaded with the volume of cases requiring their expertise compounded by the\nvolume of data to be processed. Artificial intelligence is often seen as the\nsolution to many big data problems. This paper summarises existing artificial\nintelligence based tools and approaches in digital forensics. Automated\nevidence processing leveraging artificial intelligence based techniques shows\ngreat promise in expediting the digital forensic analysis process while\nincreasing case processing capacities. For each application of artificial\nintelligence highlighted, a number of current challenges and future potential\nimpact is discussed.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 12:07:21 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Du", "Xiaoyu", ""], ["Hargreaves", "Chris", ""], ["Sheppard", "John", ""], ["Anda", "Felix", ""], ["Sayakkara", "Asanka", ""], ["Le-Khac", "Nhien-An", ""], ["Scanlon", "Mark", ""]]}, {"id": "2012.02009", "submitter": "Song Fang", "authors": "Song Fang and Quanyan Zhu", "title": "Fundamental Stealthiness-Distortion Tradeoffs in Dynamical Systems under\n  Injection Attacks: A Power Spectral Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CR cs.IT cs.SY eess.SP math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze the fundamental stealthiness-distortion tradeoffs\nof linear Gaussian dynamical systems under data injection attacks using a power\nspectral analysis, whereas the Kullback-Leibler (KL) divergence is employed as\nthe stealthiness measure. Particularly, we obtain explicit formulas in terms of\npower spectra that characterize analytically the stealthiness-distortion\ntradeoffs as well as the properties of the worst-case attacks. Furthermore, it\nis seen in general that the attacker only needs to know the input-output\nbehaviors of the systems in order to carry out the worst-case attacks.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 15:45:12 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 15:42:24 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Fang", "Song", ""], ["Zhu", "Quanyan", ""]]}, {"id": "2012.02076", "submitter": "Jinyan Wang", "authors": "Jinhuan Duan, Xianxian Li, Shiqi Gao, Jinyan Wang and Zili Zhong", "title": "SSGD: A safe and efficient method of gradient descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the vigorous development of artificial intelligence technology, various\nengineering technology applications have been implemented one after another.\nThe gradient descent method plays an important role in solving various\noptimization problems, due to its simple structure, good stability and easy\nimplementation. In multi-node machine learning system, the gradients usually\nneed to be shared. Shared gradients are generally unsafe. Attackers can obtain\ntraining data simply by knowing the gradient information. In this paper, to\nprevent gradient leakage while keeping the accuracy of model, we propose the\nsuper stochastic gradient descent approach to update parameters by concealing\nthe modulus length of gradient vectors and converting it or them into a unit\nvector. Furthermore, we analyze the security of super stochastic gradient\ndescent approach. Our algorithm can defend against attacks on the gradient.\nExperiment results show that our approach is obviously superior to prevalent\ngradient descent approaches in terms of accuracy, robustness, and adaptability\nto large-scale batches.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 17:09:20 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 04:33:08 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Duan", "Jinhuan", ""], ["Li", "Xianxian", ""], ["Gao", "Shiqi", ""], ["Wang", "Jinyan", ""], ["Zhong", "Zili", ""]]}, {"id": "2012.02081", "submitter": "Zhongzheng Xiong", "authors": "Zhongzheng Xiong, Zengfeng Huang, Xiaojun Mao, Jian Wang, Shan Ying", "title": "Compressive Privatization: Sparse Distribution Estimation under Locally\n  Differentially Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of discrete distribution estimation under locally\ndifferential privacy. Distribution estimation is one of the most fundamental\nestimation problems, which is widely studied in both non-private and private\nsettings. In the local model, private mechanisms with provably optimal sample\ncomplexity are known. However, they are optimal only in the worst-case sense;\ntheir sample complexity is proportional to the size of the entire universe,\nwhich could be huge in practice (e.g., all IP addresses). We show that as long\nas the target distribution is sparse or approximately sparse (e.g., highly\nskewed), the number of samples needed could be significantly reduced. The\nsample complexity of our new mechanism is characterized by the sparsity of the\ntarget distribution and only weakly depends on the size the universe. Our\nmechanism does privatization and dimensionality reduction simultaneously, and\nthe sample complexity will only depend on the reduced dimensionality. The\noriginal distribution is then recovered using tools from compressive sensing.\nTo complement our theoretical results, we conduct experimental studies, the\nresults of which clearly demonstrate the advantages of our method and confirm\nour theoretical findings.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 17:14:23 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Xiong", "Zhongzheng", ""], ["Huang", "Zengfeng", ""], ["Mao", "Xiaojun", ""], ["Wang", "Jian", ""], ["Ying", "Shan", ""]]}, {"id": "2012.02127", "submitter": "Rotem Liss", "authors": "Walter O. Krawec, Rotem Liss, Tal Mor", "title": "Security Proof Against Collective Attacks for an Experimentally Feasible\n  Semi-Quantum Key Distribution Protocol", "comments": "16 pages; 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-quantum key distribution (SQKD) allows two parties (Alice and Bob) to\ncreate a shared secret key, even if one of those parties (say, Alice) is\nclassical. However, most SQKD protocols suffer from practical security\nproblems. The recently developed \"Classical Alice with a Controllable Mirror\"\nprotocol [Boyer, Katz, Liss, and Mor, Phys. Rev. A 96, 062335 (2017)] is an\nexperimentally feasible SQKD protocol, and it was proven robust, but not yet\nproved secure. Here we prove the security of the Mirror protocol against a wide\nclass of quantum attacks (the \"collective attacks\") and evaluate the resulting\nkey rate.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 18:05:36 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Krawec", "Walter O.", ""], ["Liss", "Rotem", ""], ["Mor", "Tal", ""]]}, {"id": "2012.02147", "submitter": "Hesam Hamledari", "authors": "Hesam Hamledari and Martin Fischer", "title": "The Application of Blockchain-Based Crypto Assets for Integrating the\n  Physical and Financial Supply Chains in the Construction & Engineering\n  Industry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supply chain integration remains an elusive goal for the construction and\nengineering industry. The high degree of fragmentation and the reliance on\nthird-party financial institutions has pushed the physical and financial supply\nchains apart. The paper demonstrates how blockchain-based crypto assets (crypto\ncurrencies and crypto tokens) can address this limitation when used for\nconditioning the flow of funds based on the flow of products. The paper\ncontrasts the integration between cash and product flows in supply chains that\nrely on fiat currencies and crypto assets for their payment settlement. Two\nfacets of crypto asset-enabled integration, atomicity and granularity, are\nfurther introduced. The thesis is validated in the context of construction\nprogress payments. The as-built data captured by unmanned aerial and ground\nvehicles was passed to an autonomous smart contract-based method that utilizes\ncrypto-currencies and crypto tokens for payment settlement; the resulting\npayment datasets, written to the Ethereum blockchain, were analyzed in terms of\ntheir integration of product and cash flow. The work is concluded with a\ndiscussion of findings and their implications for the industry.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 18:27:16 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Hamledari", "Hesam", ""], ["Fischer", "Martin", ""]]}, {"id": "2012.02242", "submitter": "Fateme Sarkohaki", "authors": "Mina Zaminkar, Fateme Sarkohaki, Reza Fotohi", "title": "A method based on encryption and node rating for securing the RPL\n  protocol communications in the IoT ecosystem", "comments": "24 pages, 11 figures, 6 tables", "journal-ref": "Int J Commun Syst. 2020;e4693", "doi": "10.1002/dac.4693", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Internet of Things (IoT) provides the possibility for milliards of devices\nthroughout the world to communicate with each other, and data is collected\nautonomously. The big data generated by the devices should be managed securely.\nDue to security challenges, like malicious nodes, many approaches cannot\nrespond to these concerns. In this paper, a robust hybrid method, including\nencryption, is used as an efficient approach for resolving the RPL protocol\nconcerns so that the devices are connected securely. Therefore, the proposed\nDSH-RPL method for securing the RPL protocol comprises the four following\nphases: The first phase creates a reliable RPL. The second phase detects the\nsinkhole attack. The third phase quarantines the detected malicious node, and\nthe fourth phase transmits data through encryption. The simulation results show\nthat the DSH-RPL reduces the false-positive rate more than 18.2% and 23.1%, and\nreduces the false-negative rate more than 16.1% and 22.78%, it also increases\nthe packet delivery rate more than 19.68% and 25.32% and increases the\ndetection rate more than 26% and 31% compared to SecTrust-RPL and IBOOS-RPL.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 09:27:38 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Zaminkar", "Mina", ""], ["Sarkohaki", "Fateme", ""], ["Fotohi", "Reza", ""]]}, {"id": "2012.02256", "submitter": "Alexander Ivchenko Vladimirovich", "authors": "Raoul Nigmatullin, Semyon Dorokhin, Alexander Ivchenko", "title": "A Novel Approach to Radiometric Identification", "comments": "7 pages, 3 figures, 2 tables", "journal-ref": null, "doi": "10.3233/FAIA200806", "report-no": null, "categories": "eess.SP cs.CR cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper demonstrates that highly accurate radiometric identification is\npossible using CAPoNeF feature engineering method. We tested basic ML\nclassification algorithms on experimental data gathered by SDR. The statistical\nand correlational properties of suggested features were analyzed first with the\nhelp of Point Biserial and Pearson Correlation Coefficients and then using\nP-values. The most relevant features were highlighted. Random Forest provided\n99% accuracy. We give LIME description of model behavior. It turns out that\neven if the dimension of the feature space is reduced to 3, it is still\npossible to classify devices with 99% accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 10:54:44 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Nigmatullin", "Raoul", ""], ["Dorokhin", "Semyon", ""], ["Ivchenko", "Alexander", ""]]}, {"id": "2012.02384", "submitter": "Yunhan Huang", "authors": "Yunhan Huang, Zehui Xiong, Quanyan Zhu", "title": "Cross-Layer Coordinated Attacks on Cyber-Physical Systems: A LQG Game\n  Framework with Controlled Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CR cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work establishes a game-theoretic framework to study cross-layer\ncoordinated attacks on cyber-physical systems (CPSs). The attacker can\ninterfere with the physical process and launch jamming attacks on the\ncommunication channels simultaneously. At the same time, the defender can dodge\nthe jamming by dispensing with observations. The generic framework captures a\nwide variety of classic attack models on CPSs. Leveraging dynamic programming\ntechniques, we fully characterize the Subgame Perfect Equilibrium (SPE) control\nstrategies. We also derive the SPE observation and jamming strategies and\nprovide efficient computational methods to compute them. The results\ndemonstrate that the physical and cyber attacks are coordinated and depend on\neach other.\n  On the one hand, the control strategies are linear in the state estimate, and\nthe estimate error caused by jamming attacks will induce performance\ndegradation. On the other hand, the interactions between the attacker and the\ndefender in the physical layer significantly impact the observation and jamming\nstrategies. Numerical examples illustrate the interactions between the defender\nand the attacker through their observation and jamming strategies.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 03:31:57 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 04:38:55 GMT"}, {"version": "v3", "created": "Wed, 7 Apr 2021 14:55:59 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Huang", "Yunhan", ""], ["Xiong", "Zehui", ""], ["Zhu", "Quanyan", ""]]}, {"id": "2012.02494", "submitter": "Sahil Gangurde", "authors": "Sahil Gangurde, Krishnakant Tiwari", "title": "LSB Steganography Using Pixel Locator Sequence with AES", "comments": "5 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Image steganography is the art of hiding data into images. Secret data such\nas messages, audio, images can be hidden inside the cover image. This is mainly\nachieved by hiding the data into the LSB(Least Significant Bit) of the image\npixels. To improve the security of steganography, this paper studied data\nencryption with AES(Advanced Encryption Standard) and LSB based data hiding\ntechnique with advanced user-defined encrypted data distribution in pixels\nother than the common linear computational method of storing data in a linear\nform. This data distribution file will contain the location of the data(in form\nof pixel numbers) to be encrypted/decrypted which is further encrypted with AES\nthus providing double encryption for data and its location stored over pixels.\nSteganography has many applications such as medical, military, copyright\ninformation, etc.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 09:53:52 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Gangurde", "Sahil", ""], ["Tiwari", "Krishnakant", ""]]}, {"id": "2012.02511", "submitter": "Aleksey Novokhrestov", "authors": "Valeria Ageeva, Aleksey Novokhrestov, Maria Kholodova", "title": "Threats to the information system in the physical environment and\n  cyberspace", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of the study is to supplement and update the list of threats to\nthe confidentiality and integrity of the system. The article focuses on the\nalready compiled list of threats and a model of system, but also considers new\nthreats and types of threats. Scientific novelty is in the interdisciplinary\nconsideration of the issue with the involvement of the works of modern Russian\nand Western scientists. As a result of the study, new threats to the\nconfidentiality and integrity of the system were described, the type of these\nthreats was determined and classified by channels of communication.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 10:42:31 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Ageeva", "Valeria", ""], ["Novokhrestov", "Aleksey", ""], ["Kholodova", "Maria", ""]]}, {"id": "2012.02554", "submitter": "Claudio Canella", "authors": "Claudio Canella, Mario Werner, Daniel Gruss, Michael Schwarz", "title": "Automating Seccomp Filter Generation for Linux Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software vulnerabilities in applications undermine the security of\napplications. By blocking unused functionality, the impact of potential\nexploits can be reduced. While seccomp provides a solution for filtering\nsyscalls, it requires manual implementation of filter rules for each individual\napplication. Recent work has investigated automated approaches for detecting\nand installing the necessary filter rules. However, as we show, these\napproaches make assumptions that are not necessary or require overly\ntime-consuming analysis.\n  In this paper, we propose Chestnut, an automated approach for generating\nstrict syscall filters for Linux userspace applications with lower requirements\nand limitations. Chestnut comprises two phases, with the first phase consisting\nof two static components, i.e., a compiler and a binary analyzer, that extract\nthe used syscalls during compilation or in an analysis of the binary. The\ncompiler-based approach of Chestnut is up to factor 73 faster than previous\napproaches without affecting the accuracy adversely. On the binary analysis\nlevel, we demonstrate that the requirement of position-independent binaries of\nrelated work is not needed, enlarging the set of applications for which\nChestnut is usable. In an optional second phase, Chestnut provides a dynamic\nrefinement tool that allows restricting the set of allowed syscalls further. We\ndemonstrate that Chestnut on average blocks 302 syscalls (86.5%) via the\ncompiler and 288 (82.5%) using the binary-level analysis on a set of 18 widely\nused applications. We found that Chestnut blocks the dangerous exec syscall in\n50% and 77.7% of the tested applications using the compiler- and binary-based\napproach, respectively. For the tested applications, Chestnut prevents\nexploitation of more than 62% of the 175 CVEs that target the kernel via\nsyscalls. Finally, we perform a 6 month long-term study of a sandboxed Nginx\nserver.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 12:30:36 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Canella", "Claudio", ""], ["Werner", "Mario", ""], ["Gruss", "Daniel", ""], ["Schwarz", "Michael", ""]]}, {"id": "2012.02586", "submitter": "Filipo Sharevski", "authors": "Peter Jachim and Filipo Sharevski and Paige Treebridge", "title": "TrollHunter [Evader]: Automated Detection [Evasion] of Twitter Trolls\n  During the COVID-19 Pandemic", "comments": "Accepted for publication at NSPW 2020", "journal-ref": "New Security Paradigms Workshop (NSPW) 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents TrollHunter, an automated reasoning mechanism we used to\nhunt for trolls on Twitter during the COVID-19 pandemic in 2020. Trolls, poised\nto disrupt the online discourse and spread disinformation, quickly seized the\nabsence of a credible response to COVID-19 and created a COVID-19 infodemic by\npromulgating dubious content on Twitter. To counter the COVID-19 infodemic, the\nTrollHunter leverages a unique linguistic analysis of a multi-dimensional set\nof Twitter content features to detect whether or not a tweet was meant to\ntroll. TrollHunter achieved 98.5% accuracy, 75.4% precision and 69.8% recall\nover a dataset of 1.3 million tweets. Without a final resolution of the\npandemic in sight, it is unlikely that the trolls will go away, although they\nmight be forced to evade automated hunting. To explore the plausibility of this\nstrategy, we developed and tested an adversarial machine learning mechanism\ncalled TrollHunter-Evader. TrollHunter-Evader employs a Test Time Evasion (TTE)\napproach in a combination with a Markov chain-based mechanism to recycle\noriginally trolling tweets. The recycled tweets were able to achieve a\nremarkable 40% decrease in the TrollHunter's ability to correctly identify\ntrolling tweets. Because the COVID-19 infodemic could have a harmful impact on\nthe COVID-19 pandemic, we provide an elaborate discussion about the\nimplications of employing adversarial machine learning to evade Twitter troll\nhunts.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 13:46:42 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 03:00:54 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Jachim", "Peter", ""], ["Sharevski", "Filipo", ""], ["Treebridge", "Paige", ""]]}, {"id": "2012.02606", "submitter": "Filipo Sharevski", "authors": "Peter Jachim and Filipo Sharevski and Emma Pieroni", "title": "TrollHunter2020: Real-Time Detection of Trolling Narratives on Twitter\n  During the 2020 US Elections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents TrollHunter2020, a real-time detection mechanism we used\nto hunt for trolling narratives on Twitter during the 2020 U.S. elections.\nTrolling narratives form on Twitter as alternative explanations of polarizing\nevents like the 2020 U.S. elections with the goal to conduct information\noperations or provoke emotional response. Detecting trolling narratives thus is\nan imperative step to preserve constructive discourse on Twitter and remove an\ninflux of misinformation. Using existing techniques, this takes time and a\nwealth of data, which, in a rapidly changing election cycle with high stakes,\nmight not be available. To overcome this limitation, we developed\nTrollHunter2020 to hunt for trolls in real-time with several dozens of trending\nTwitter topics and hashtags corresponding to the candidates' debates, the\nelection night, and the election aftermath. TrollHunter2020 collects trending\ndata and utilizes a correspondence analysis to detect meaningful relationships\nbetween the top nouns and verbs used in constructing trolling narratives while\nthey emerge on Twitter. Our results suggest that the TrollHunter2020 indeed\ncaptures the emerging trolling narratives in a very early stage of an unfolding\npolarizing event. We discuss the utility of TrollHunter2020 for early detection\nof information operations or trolling and the implications of its use in\nsupporting a constrictive discourse on the platform around polarizing topics.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 14:03:06 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 02:59:24 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Jachim", "Peter", ""], ["Sharevski", "Filipo", ""], ["Pieroni", "Emma", ""]]}, {"id": "2012.02644", "submitter": "Md Sadek Ferdous", "authors": "Soumik Sarker, Arnob Kumar Saha, Md Sadek Ferdous", "title": "A Survey on Blockchain & Cloud Integration", "comments": "Accepted for publication in the 23rd International Conference on\n  Computer and Information Technology (ICCIT), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain is one of the emerging technologies with the potential to disrupt\nmany application domains. Cloud is an on-demand service paradigm facilitating\nthe availability of shared resources for data storage and computation. In\nrecent years, the integration of blockchain and cloud has received significant\nattention for ensuring efficiency, transparency, security and even for offering\nbetter cloud services in the form of novel service models. In order to exploit\nthe full potential of blockchain-cloud integration, it is essential to have a\nclear understanding on the existing works within this domain. To facilitate\nthis, there have been several survey papers, however, none of them covers the\naspect of blockchain-cloud integration from a service-oriented perspective.\nThis paper aims to fulfil this gap by providing a service oriented review of\nblockchain-cloud integration. Indeed, in this survey, we explore different\nservice models into which blockchain has been integrated. For each service\nmodel, we review the existing works and present a comparative analysis so as to\noffer a clear and concise view in each category.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 15:04:27 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Sarker", "Soumik", ""], ["Saha", "Arnob Kumar", ""], ["Ferdous", "Md Sadek", ""]]}, {"id": "2012.02670", "submitter": "Dario Pasquini", "authors": "Dario Pasquini, Giuseppe Ateniese and Massimo Bernaschi", "title": "Unleashing the Tiger: Inference Attacks on Split Learning", "comments": "To appear in the proceedings of: ACM Conference on Computer and\n  Communications Security 2021 (CCS21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the security of Split Learning -- a novel collaborative\nmachine learning framework that enables peak performance by requiring minimal\nresources consumption. In the present paper, we expose vulnerabilities of the\nprotocol and demonstrate its inherent insecurity by introducing general attack\nstrategies targeting the reconstruction of clients' private training sets. More\nprominently, we show that a malicious server can actively hijack the learning\nprocess of the distributed model and bring it into an insecure state that\nenables inference attacks on clients' data. We implement different adaptations\nof the attack and test them on various datasets as well as within realistic\nthreat scenarios. We demonstrate that our attack is able to overcome recently\nproposed defensive techniques aimed at enhancing the security of the split\nlearning protocol. Finally, we also illustrate the protocol's insecurity\nagainst malicious clients by extending previously devised attacks for Federated\nLearning. To make our results reproducible, we made our code available at\nhttps://github.com/pasquini-dario/SplitNN_FSHA.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 15:41:00 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 12:58:49 GMT"}, {"version": "v3", "created": "Fri, 14 May 2021 19:08:20 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Pasquini", "Dario", ""], ["Ateniese", "Giuseppe", ""], ["Bernaschi", "Massimo", ""]]}, {"id": "2012.02675", "submitter": "Ranwa Al Mallah", "authors": "Ranwa Al Mallah, Talal Halabi, Bilal Farooq", "title": "A Minimax Game for Resilient-by-design Adaptive Traffic Control Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connected and Autonomous Vehicles (CAVs) with their evolving data gathering\ncapabilities will play a significant role in road safety and efficiency\napplications supported by Intelligent Transport Systems (ITS), such as Adaptive\nTraffic Signal Control (ATSC) for urban traffic congestion management. However,\ntheir involvement will expand the space of security vulnerabilities and create\nlarger threat vectors. We perform the first detailed security analysis and\nimplementation of a new cyber-physical attack category carried out by the\nnetwork of CAVs on ITS, namely, coordinated Sybil attacks, where vehicles with\nforged or fake identities try to alter the data collected by the ATSC\nalgorithms to sabotage their decisions. Consequently, a novel, game-theoretic\nmitigation approach at the application layer is proposed to minimize the impact\nof Sybil attacks. The devised minimax game model enables the ATSC algorithm to\ngenerate optimal decisions under a suspected attack, improving its resilience.\nExtensive experimentation is performed on a traffic dataset provided by the\nCity of Montreal under real-world intersection settings to evaluate the attack\nimpact. Our results improved time loss on attacked intersections by\napproximately 48.9%. Substantial benefits can be gained from the mitigation,\nyielding more robust control of traffic across networked intersections.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 15:45:05 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 13:43:35 GMT"}, {"version": "v3", "created": "Sat, 26 Dec 2020 15:20:35 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Mallah", "Ranwa Al", ""], ["Halabi", "Talal", ""], ["Farooq", "Bilal", ""]]}, {"id": "2012.02688", "submitter": "Ali Burak \\\"Unal", "authors": "Ali Burak \\\"Unal, Mete Akg\\\"un, Nico Pfeifer", "title": "ESCAPED: Efficient Secure and Private Dot Product Framework for\n  Kernel-based Machine Learning Algorithms with Applications in Healthcare", "comments": "AAAI 2021, Preprint version of the full paper with supplementary\n  material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To train sophisticated machine learning models one usually needs many\ntraining samples. Especially in healthcare settings these samples can be very\nexpensive, meaning that one institution alone usually does not have enough on\nits own. Merging privacy-sensitive data from different sources is usually\nrestricted by data security and data protection measures. This can lead to\napproaches that reduce data quality by putting noise onto the variables (e.g.,\nin $\\epsilon$-differential privacy) or omitting certain values (e.g., for\n$k$-anonymity). Other measures based on cryptographic methods can lead to very\ntime-consuming computations, which is especially problematic for larger\nmulti-omics data. We address this problem by introducing ESCAPED, which stands\nfor Efficient SeCure And PrivatE Dot product framework, enabling the\ncomputation of the dot product of vectors from multiple sources on a\nthird-party, which later trains kernel-based machine learning algorithms, while\nneither sacrificing privacy nor adding noise. We evaluated our framework on\ndrug resistance prediction for HIV-infected people and multi-omics\ndimensionality reduction and clustering problems in precision medicine. In\nterms of execution time, our framework significantly outperforms the\nbest-fitting existing approaches without sacrificing the performance of the\nalgorithm. Even though we only show the benefit for kernel-based algorithms,\nour framework can open up new research opportunities for further machine\nlearning models that require the dot product of vectors from multiple sources.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 15:57:20 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["\u00dcnal", "Ali Burak", ""], ["Akg\u00fcn", "Mete", ""], ["Pfeifer", "Nico", ""]]}, {"id": "2012.02715", "submitter": "Leila Delshadtehrani", "authors": "Leila Delshadtehrani, Sadullah Canakci, Manuel Egele, Ajay Joshi", "title": "Efficient Sealable Protection Keys for RISC-V", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the continuous increase in the number of software-based attacks, there\nhas been a growing effort towards isolating sensitive data and trusted software\ncomponents from untrusted third-party components. A hardware-assisted\nintra-process isolation mechanism enables software developers to partition a\nprocess into isolated components and in turn secure sensitive data from\nuntrusted components. However, most of the existing hardware-assisted\nintra-process isolation mechanisms in modern processors, such as ARM and IBM\nPower, rely on costly kernel operations for switching between trusted and\nuntrusted domains. Recently, Intel introduced a new hardware feature for\nintra-process memory isolation, called Memory Protection Keys (MPK), which\nenables a user-space process to switch the domains in an efficient way. While\nthe efficiency of Intel MPK enables developers to leverage it for common use\ncases such as Code-Pointer Integrity, the limited number of unique domains (16)\nprohibits its use in cases such as OpenSSL where a large number of domains are\nrequired. Moreover, Intel MPK suffers from the protection key use-after-free\nvulnerability. To address these shortcomings, in this paper, we propose an\nefficient intra-process isolation technique for the RISC-V open ISA, called\nSealPK, which supports up to 1024 unique domains. SealPK prevents the\nprotection key use-after-free problem by leveraging a lazy de-allocation\napproach. To further strengthen SealPK, we devise three novel sealing features\nto protect the allocated domains, their associated pages, and their permissions\nfrom modifications or tampering by an attacker. To demonstrate the feasibility\nof our design, we implement SealPK on a RISC-V Rocket processor, provide the OS\nsupport for it, and prototype our design on an FPGA. We demonstrate the\nefficiency of SealPK by leveraging it to implement an isolated shadow stack on\nour FPGA prototype.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 16:58:09 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Delshadtehrani", "Leila", ""], ["Canakci", "Sadullah", ""], ["Egele", "Manuel", ""], ["Joshi", "Ajay", ""]]}, {"id": "2012.02745", "submitter": "Daniel De Almeida Braga", "authors": "Daniel De Almeida Braga, Pierre-Alain Fouque, Mohamed Sabt", "title": "Dragonblood is Still Leaking: Practical Cache-based Side-Channel in the\n  Wild", "comments": "Accepted at Annual Computer Security Applications Conference (ACSAC\n  2020), December 7-11, 2020, Austin, USA. ACM, New York, NY, USA, 13 pages,\n  ACM ISBN 978-1-4503-8858-0/20/12 Artifact available:\n  https://gitlab.inria.fr/ddealmei/poc-iwd-acsac2020/-/tree/master/", "journal-ref": null, "doi": "10.1145/3427228.3427295", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recently, the Dragonblood attacks have attracted new interests on the\nsecurity of WPA-3 implementation and in particular on the Dragonfly code\ndeployed on many open-source libraries. One attack concerns the protection of\nusers passwords during authentication. In the Password Authentication Key\nExchange (PAKE) protocol called Dragonfly, the secret, namely the password, is\nmapped to an elliptic curve point. This operation is sensitive, as it involves\nthe secret password, and therefore its resistance against side-channel attacks\nis of utmost importance. Following the initial disclosure of Dragonblood, we\nnotice that this particular attack has been partially patched by only a few\nimplementations.\n  In this work, we show that the patches implemented after the disclosure of\nDragonblood are insufficient. We took advantage of state-of-the-art techniques\nto extend the original attack, demonstrating that we are able to recover the\npassword with only a third of the measurements needed in Dragonblood attack. We\nmainly apply our attack on two open-source projects: iwd (iNet Wireless Daemon)\nand FreeRADIUS, in order underline the practicability of our attack. Indeed,\nthe iwd package, written by Intel, is already deployed in the Arch Linux\ndistribution, which is well-known among security experts, and aims to offer an\nalternative to wpa\\_supplicant. As for FreeRADIUS, it is widely deployed and\nwell-maintained upstream open-source project. We publish a full Proof of\nConcept of our attack, and actively participated in the process of patching the\nvulnerable code. Here, in a backward compatibility perspective, we advise the\nuse of a branch-free implementation as a mitigation technique, as what was used\nin hostapd, due to its quite simplicity and its negligible incurred overhead.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 17:55:19 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 21:19:24 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Braga", "Daniel De Almeida", ""], ["Fouque", "Pierre-Alain", ""], ["Sabt", "Mohamed", ""]]}, {"id": "2012.02848", "submitter": "Christiana Chamon", "authors": "Christiana Chamon, Shahriar Ferdous, and Laszlo Kish", "title": "Deterministic Random Number Generator Attack against the\n  Kirchhoff-Law-Johnson-Noise Secure Key Exchange Protocol", "comments": "arXiv admin note: substantial text overlap with arXiv:2005.10429", "journal-ref": null, "doi": "10.1142/S0219477521500462", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper demonstrates the vulnerability of the Kirchhoff-Law-Johnson-Noise\n(KLJN) secure key exchanger to compromised random number generator(s) even if\nthese random numbers are used solely to generate the noises emulating the\nJohnson noise of Alice's and Bob's resistors. The attacks shown are\ndeterministic in the sense that Eve's knowledge of Alice's and/or Bob's random\nnumbers is basically deterministic. Moreover, no statistical evaluation is\nneeded, except for rarely occurring events of negligible, random waiting time\nand verification time. We explore two situations. In the first case, Eve knows\nboth Alice's and Bob's random noises. We show that, in this situation, Eve can\nquickly crack the secure key bit by using Ohm's Law. In the other situation,\nEve knows only Bob's random noise. Then Eve first can learn Bob's resistance\nvalue by using Ohm's Law. Therefore, she will have the same knowledge as Bob,\nthus at the end of the bit exchange period, she will know Alice's bit.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 20:56:40 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 16:02:53 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Chamon", "Christiana", ""], ["Ferdous", "Shahriar", ""], ["Kish", "Laszlo", ""]]}, {"id": "2012.02865", "submitter": "Seham Ebrahim", "authors": "Seham Muawadh Ali Ebrahim", "title": "Hybrid Chaotic Method for Medical Images Ciphering", "comments": null, "journal-ref": "International Journal of Network Security & Its Applications\n  (IJNSA) Vol.12, No.6, November 2020", "doi": "10.5121/ijnsa.2020.12601", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Healthcare is an essential application of e-services, where for diagnostic\ntesting, medical imaging acquiring, processing, analysis, storage, and\nprotection are used. Image ciphering during storage and transmission over the\nnetworks used has seen implemented using many types of ciphering algorithms for\nsecurity purpose. Current cyphering algorithms are classified into two types:\ntraditional classical cryptography using standard algorithms (DES, AES, IDEA,\nRC5, RSA, ...) and chaos cryptography using continuous (Chau, Rossler, Lorenz,\n...) or discreet (Logistics, Henon, ...) algorithms. The traditional algorithms\nhave struggled to combat image data as compared to regular textual data.\nWhereas, the chaotic algorithms are more efficient for image ciphering. The\nSignificance characteristics of chaos are its extreme sensitivity to initial\nconditions and algorithm parameters. In this paper, medical image security\nbased on hybrid/mixed chaotic algorithms is proposed. The proposed method is\nimplemented using MATLAB. Where the image of the Retina of the Eye to detect\nBlood Vessels is ciphered. The Pseudo-Random Numbers Generators (PRNGs) from\nthe different chaotic algorithms are implemented, and their statistical\nproperties are evaluated using the National Institute of Standards and\nTechnology NIST and other statistical test-suits. Then, these algorithms are\nused to secure the data, where the statistical properties of the cipher-text\nare also tested. We propose two PRNGs to increase the complexity of the PRNGs\nand to allow many of the NIST statistical tests to be passed: one based on\ntwo-hybrid mixed chaotic logistic maps and one based on two-hybrid mixed\nchaotic Henon maps, where each chaotic algorithm runs side-by-side and starts\nwith random initial conditions and parameters (encryption keys). The resulting\nhybrid PRNGs passed many of the NIST statistical test suits.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 21:52:21 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Ebrahim", "Seham Muawadh Ali", ""]]}, {"id": "2012.02885", "submitter": "Abhishek Singh", "authors": "Abhishek Singh, Ramesh Raskar", "title": "Verifiable Proof of Health using Public Key Cryptography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the current pandemic, testing continues to be the most important tool for\nmonitoring and curbing the disease spread and early identification of the\ndisease to perform health-related interventions like quarantine, contact\ntracing and etc. Therefore, the ability to verify the testing status is\npertinent as public places prepare to safely open. Recent advances in\ncryptographic tools have made it possible to build a secure and resilient\ndigital-id system. In this work, we propose to build an end to end COVID-19\nresults verification protocol that takes privacy, computation, and other\npractical concerns into account for designing an inter-operable layer of\ntesting results verification system that could potentially enable less\nstringent and more selective lockdowns. We also discuss various concerns\nencompassing the security, privacy, ethics and equity aspect of the proposed\nsystem.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 22:54:33 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Singh", "Abhishek", ""], ["Raskar", "Ramesh", ""]]}, {"id": "2012.02891", "submitter": "Mayra Macas", "authors": "Mayra Macas, Chunming Wu", "title": "Review: Deep Learning Methods for Cybersecurity and Intrusion Detection\n  Systems", "comments": "IEEE Latin-American Conference on Communications (LATINCOM) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As the number of cyber-attacks is increasing, cybersecurity is evolving to a\nkey concern for any business. Artificial Intelligence (AI) and Machine Learning\n(ML) (in particular Deep Learning - DL) can be leveraged as key enabling\ntechnologies for cyber-defense, since they can contribute in threat detection\nand can even provide recommended actions to cyber analysts. A partnership of\nindustry, academia, and government on a global scale is necessary in order to\nadvance the adoption of AI/ML to cybersecurity and create efficient cyber\ndefense systems. In this paper, we are concerned with the investigation of the\nvarious deep learning techniques employed for network intrusion detection and\nwe introduce a DL framework for cybersecurity applications.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 23:09:35 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Macas", "Mayra", ""], ["Wu", "Chunming", ""]]}, {"id": "2012.03141", "submitter": "Marino Miculan", "authors": "Marino Miculan, Nicola Vitacolonna", "title": "Automated Symbolic Verification of Telegram's MTProto 2.0", "comments": "19 pages", "journal-ref": "In \"Proceedings of the 18th International Conference on Security\n  and Cryptography, SECRYPT 2021\". ISBN 978-989-758-524-1, pages 185-197", "doi": "10.5220/0010549601850197", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  MTProto 2.0 is a suite of cryptographic protocols for instant messaging at\nthe core of the popular Telegram messenger application. In this paper we\nanalyse MTProto 2.0 using the symbolic verifier ProVerif. We provide fully\nautomated proofs of the soundness of MTProto 2.0's authentication, normal chat,\nend-to-end encrypted chat, and rekeying mechanisms with respect to several\nsecurity properties, including authentication, integrity, secrecy and perfect\nforward secrecy; at the same time, we discover that the rekeying protocol is\nvulnerable to an unknown key-share (UKS) attack. We proceed in an incremental\nway: each protocol is examined in isolation, relying only on the guarantees\nprovided by the previous ones and the robustness of the basic cryptographic\nprimitives. Our research proves the formal correctness of MTProto 2.0 w.r.t.\nmost relevant security properties, and it can serve as a reference for\nimplementation and analysis of clients and servers.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 23:21:11 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 20:14:11 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Miculan", "Marino", ""], ["Vitacolonna", "Nicola", ""]]}, {"id": "2012.03154", "submitter": "Yuanjun Zhao", "authors": "Yuanjun Zhao, Roberto Togneri, Victor Sreeram", "title": "Multi-task Learning Based Spoofing-Robust Automatic Speaker Verification\n  System", "comments": "12 pages, 6 figures, codes used in the experimental section can be\n  found at https://github.com/zhaoyj1122/SRASV", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CR cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spoofing attacks posed by generating artificial speech can severely degrade\nthe performance of a speaker verification system. Recently, many anti-spoofing\ncountermeasures have been proposed for detecting varying types of attacks from\nsynthetic speech to replay presentations. While there are numerous effective\ndefenses reported on standalone anti-spoofing solutions, the integration for\nspeaker verification and spoofing detection systems has obvious benefits. In\nthis paper, we propose a spoofing-robust automatic speaker verification\n(SR-ASV) system for diverse attacks based on a multi-task learning\narchitecture. This deep learning based model is jointly trained with\ntime-frequency representations from utterances to provide recognition decisions\nfor both tasks simultaneously. Compared with other state-of-the-art systems on\nthe ASVspoof 2017 and 2019 corpora, a substantial improvement of the combined\nsystem under different spoofing conditions can be obtained.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 01:03:35 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Zhao", "Yuanjun", ""], ["Togneri", "Roberto", ""], ["Sreeram", "Victor", ""]]}, {"id": "2012.03162", "submitter": "Christopher Vega", "authors": "Christopher Vega, Patanjali SLPSK, Shubhra Deb Paul, Swarup Bhunia", "title": "MeLPUF: Memory in Logic PUF", "comments": "5 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical Unclonable Functions (PUFs) are used for securing electronic designs\nacross the implementation spectrum ranging from lightweight FPGA to\nserver-class ASIC designs. However, current PUF implementations are vulnerable\nto model-building attacks; they often incur significant design overheads and\nare challenging to configure based on application-specific requirements. These\nfactors limit their application, primarily in the case of the system on chip\n(SoC) designs used in diverse applications. In this work, we propose MeL-PUF -\nMemory-in-Logic PUF, a low-overhead, distributed, and synthesizable PUF that\ntakes advantage of existing logic gates in a design and transforms them to\ncreate cross-coupled inverters (i.e. memory cells) controlled by a PUF control\nsignal. The power-up states of these memory cells are used as the source of\nentropy in the proposed PUF architecture. These on-demand memory cells can be\ndistributed across the combinational logic of various intellectual property\n(IP) blocks in a system on chip (SoC) design. They can also be synthesized with\na standard logic synthesis tool to meet the area,power, or performance\nconstraints of a design. By aggregating the power-up states from multiple such\nmemory cells, we can create a PUF signature or digital fingerprint of varying\nsize. We evaluate the MeL-PUF signature quality with both circuit-level\nsimulations as well as with measurements in FPGA devices. We show that MeL-PUF\nprovides high-quality signatures in terms of uniqueness, randomness, and\nrobustness, without incurring large overheads. We also suggest additional\noptimizations that can be leveraged to improve the performance of MeL-PUF.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 02:18:52 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 21:06:27 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Vega", "Christopher", ""], ["SLPSK", "Patanjali", ""], ["Paul", "Shubhra Deb", ""], ["Bhunia", "Swarup", ""]]}, {"id": "2012.03165", "submitter": "Jianbing Ni", "authors": "Jianbing Ni and Kuan Zhang and Athanasios V. Vasilakos", "title": "Security and Privacy for Mobile Edge Caching: Challenges and Solutions", "comments": "This article has been accepted by IEEE Wireless Communications\n  Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mobile edge caching is a promising technology for the next-generation mobile\nnetworks to effectively offer service environment and cloud-storage\ncapabilities at the edge of networks. By exploiting the storage and computing\nresources at the network edge, mobile edge caching can significantly reduce\nservice latency, decrease network load, and improve user experience. On the\nother hand, edge caching is subject to a number of threats regarding privacy\nviolation and security breach. In this article, we first introduce the\narchitecture of mobile edge caching, and address the key problems regarding\nwhy, where, what, and how to cache. Then, we examine the potential cyber\nthreats, including cache poisoning attacks, cache pollution attacks, cache\nside-channel attacks, and cache deception attacks, which result in huge\nconcerns about privacy, security, and trust in content placement, content\ndelivery, and content usage for mobile users, respectively. After that, we\npropose a service-oriented and location-based efficient key distribution\nprotocol (SOLEK) as an example in response to efficient and secure content\ndelivery in mobile edge caching. Finally, we discuss the potential techniques\nfor privacy-preserving content placement, efficient and secure content\ndelivery, and trustful content usage, which are expected to draw more attention\nand efforts into secure edge caching.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 02:53:22 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Ni", "Jianbing", ""], ["Zhang", "Kuan", ""], ["Vasilakos", "Athanasios V.", ""]]}, {"id": "2012.03283", "submitter": "Jianwei Huang", "authors": "Jianwei Huang, Vinod Yegneswaran, Phillip Porras, and Guofei Gu", "title": "On the Privacy and Integrity Risks of Contact-Tracing Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smartphone-based contact-tracing applications are at the epicenter of the\nglobal fight against the Covid-19 pandemic. While governments and healthcare\nagencies are eager to mandate the deployment of such applications en-masse,\nthey face increasing scrutiny from the popular press, security companies, and\nhuman rights watch agencies that fear the exploitation of these technologies as\nsurveillance tools. Finding the optimal balance between community safety and\nprivacy has been a challenge, and strategies to address these concerns have\nvaried among countries. This paper describes two important attacks that affect\na broad swath of contact-tracing applications. The first, referred to as\ncontact-isolation attack, is a user-privacy attack that can be used to identify\npotentially infected patients in your neighborhood. The second is a\ncontact-pollution attack that affects the integrity of contact tracing\napplications by causing them to produce a high volume of false-positive alerts.\nWe developed prototype implementations and evaluated both attacks in the\ncontext of the DP-3T application framework, but these vulnerabilities affect a\nmuch broader class of applications. We found that both attacks are feasible and\nrealizable with a minimal attacker work factor. We further conducted an impact\nassessment of these attacks by using a simulation study and measurements from\nthe SafeGraph database. Our results indicate that attacks launched from a\nmodest number (on the order of 10,000) of monitoring points can effectively\ndecloak between 5-40\\% of infected users in a major metropolis, such as\nHouston.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 15:05:02 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 19:04:31 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Huang", "Jianwei", ""], ["Yegneswaran", "Vinod", ""], ["Porras", "Phillip", ""], ["Gu", "Guofei", ""]]}, {"id": "2012.03371", "submitter": "Jacob Spertus", "authors": "Amanda K. Glazer and Jacob V. Spertus and Philip B. Stark", "title": "More style, less work: card-style data decrease risk-limiting audit\n  sample sizes", "comments": "19 pages, 9 figures. In submission at Digital Threats: Research and\n  Practice", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.ME", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  U.S. elections rely heavily on computers such as voter registration\ndatabases, electronic pollbooks, voting machines, scanners, tabulators, and\nresults reporting websites. These introduce digital threats to election\noutcomes. Risk-limiting audits (RLAs) mitigate threats to some of these systems\nby manually inspecting random samples of ballot cards. RLAs have a large chance\nof correcting wrong outcomes (by conducting a full manual tabulation of a\ntrustworthy record of the votes), but can save labor when reported outcomes are\ncorrect. This efficiency is eroded when sampling cannot be targeted to ballot\ncards that contain the contest(s) under audit. If the sample is drawn from all\ncast cards, RLA sample sizes scale like the reciprocal of the fraction of\nballot cards that contain the contest(s) under audit. That fraction shrinks as\nthe number of cards per ballot grows (i.e., when elections contain more\ncontests) and as the fraction of ballots that contain the contest decreases\n(i.e., when a smaller percentage of voters are eligible to vote in the\ncontest). States that conduct RLAs of contests on multi-card ballots or of\nsmall contests can dramatically reduce sample sizes by using information about\nwhich ballot cards contain which contests -- by keeping track of card-style\ndata (CSD). For instance, CSD reduces the expected number of draws needed to\naudit a single countywide contest on a 4-card ballot by 75%. Similarly, CSD\nreduces the expected number of draws by 95% or more for an audit of two\ncontests with the same margin on a 4-card ballot if one contest is on every\nballot and the other is on 10% of ballots. In realistic examples, the savings\ncan be several orders of magnitude.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 20:35:12 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Glazer", "Amanda K.", ""], ["Spertus", "Jacob V.", ""], ["Stark", "Philip B.", ""]]}, {"id": "2012.03386", "submitter": "Weili Han Prof.", "authors": "Lushan Song, Haoqi Wu, Wenqiang Ruan, Weili Han", "title": "SoK: Training Machine Learning Models over Multiple Sources with Privacy\n  Preservation", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, gathering high-quality training data from multiple data controllers\nwith privacy preservation is a key challenge to train high-quality machine\nlearning models. The potential solutions could dramatically break the barriers\namong isolated data corpus, and consequently enlarge the range of data\navailable for processing. To this end, both academia researchers and industrial\nvendors are recently strongly motivated to propose two main-stream folders of\nsolutions: 1) Secure Multi-party Learning (MPL for short); and 2) Federated\nLearning (FL for short). These two solutions have their advantages and\nlimitations when we evaluate them from privacy preservation, ways of\ncommunication, communication overhead, format of data, the accuracy of trained\nmodels, and application scenarios.\n  Motivated to demonstrate the research progress and discuss the insights on\nthe future directions, we thoroughly investigate these protocols and frameworks\nof both MPL and FL. At first, we define the problem of training machine\nlearning models over multiple data sources with privacy-preserving (TMMPP for\nshort). Then, we compare the recent studies of TMMPP from the aspects of the\ntechnical routes, parties supported, data partitioning, threat model, and\nsupported machine learning models, to show the advantages and limitations.\nNext, we introduce the state-of-the-art platforms which support online training\nover multiple data sources. Finally, we discuss the potential directions to\nresolve the problem of TMMPP.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 22:24:28 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Song", "Lushan", ""], ["Wu", "Haoqi", ""], ["Ruan", "Wenqiang", ""], ["Han", "Weili", ""]]}, {"id": "2012.03404", "submitter": "Shagufta Mehnaz", "authors": "Shagufta Mehnaz, Ninghui Li, Elisa Bertino", "title": "Black-box Model Inversion Attribute Inference Attacks on Classification\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Increasing use of ML technologies in privacy-sensitive domains such as\nmedical diagnoses, lifestyle predictions, and business decisions highlights the\nneed to better understand if these ML technologies are introducing leakages of\nsensitive and proprietary training data. In this paper, we focus on one kind of\nmodel inversion attacks, where the adversary knows non-sensitive attributes\nabout instances in the training data and aims to infer the value of a sensitive\nattribute unknown to the adversary, using oracle access to the target\nclassification model. We devise two novel model inversion attribute inference\nattacks -- confidence modeling-based attack and confidence score-based attack,\nand also extend our attack to the case where some of the other (non-sensitive)\nattributes are unknown to the adversary. Furthermore, while previous work uses\naccuracy as the metric to evaluate the effectiveness of attribute inference\nattacks, we find that accuracy is not informative when the sensitive attribute\ndistribution is unbalanced. We identify two metrics that are better for\nevaluating attribute inference attacks, namely G-mean and Matthews correlation\ncoefficient (MCC). We evaluate our attacks on two types of machine learning\nmodels, decision tree and deep neural network, trained with two real datasets.\nExperimental results show that our newly proposed attacks significantly\noutperform the state-of-the-art attacks. Moreover, we empirically show that\nspecific groups in the training dataset (grouped by attributes, e.g., gender,\nrace) could be more vulnerable to model inversion attacks. We also demonstrate\nthat our attacks' performances are not impacted significantly when some of the\nother (non-sensitive) attributes are also unknown to the adversary.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 01:14:19 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Mehnaz", "Shagufta", ""], ["Li", "Ninghui", ""], ["Bertino", "Elisa", ""]]}, {"id": "2012.03407", "submitter": "Mar\\'ia \\'Angeles V\\'azquez-Castro", "authors": "A. Vazquez-Castro, D. Rusca and H. Zbinden", "title": "Quantum Keyless Privacy vs. Quantum Key Distribution for Space Links", "comments": null, "journal-ref": "Phys. Rev. Applied 16, 014006 (2021)", "doi": "10.1103/PhysRevApplied.16.014006", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study information theoretical security for space links between a satellite\nand a ground-station. Quantum key distribution (QKD) is a well established\nmethod for information theoretical secure communication, giving the\neavesdropper unlimited access to the channel and technological resources only\nlimited by the laws of quantum physics. But QKD for space links is extremely\nchallenging, the achieved key rates are extremely low, and day-time operating\nimpossible. However, eavesdropping on a channel in free-space without being\nnoticed seems complicated, given the constraints imposed by orbital mechanics.\nIf we also exclude eavesdropper's presence in a given area around the emitter\nand receiver, we can guarantee that he has only access to a fraction of the\noptical signal. In this setting, quantum keyless private (direct) communication\nbased on the wiretap channel model is a valid alternative to provide\ninformation theoretical security. Like for QKD, we assume the legitimate users\nto be limited by state-of-the-art technology, while the potential eavesdropper\nis only limited by physical laws: physical measurement (Helstrom detector) and\nquantum electrodynamics (Holevo bound). Nevertheless, we demonstrate\ninformation theoretical secure communication rates (positive keyless private\ncapacity) over a classical-quantum wiretap channel using on-off-keying of\ncoherent states. We present numerical results for a setting equivalent to the\nrecent experiments with the Micius satellite and compare them to the\nfundamental limit for the secret key rate of QKD. We obtain much higher rates\ncompared with QKD with exclusion area of less than 13 meters for Low Earth\nOrbit (LEO) satellites. Moreover, we show that the wiretap channel quantum\nkeyless privacy is much less sensitive to noise and signal dynamics and daytime\noperation is possible.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 01:33:40 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Vazquez-Castro", "A.", ""], ["Rusca", "D.", ""], ["Zbinden", "H.", ""]]}, {"id": "2012.03461", "submitter": "Lei Wang", "authors": "Lei Wang, Xin Liu, and Yin Zhang", "title": "A Distributed and Secure Algorithm for Computing Dominant SVD Based on\n  Projection Splitting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose and study a distributed and secure algorithm for\ncomputing dominant (or truncated) singular value decompositions (SVD) of large\nand distributed data matrices. We consider the scenario where each node\nprivately holds a subset of columns and only exchanges ''safe'' information\nwith other nodes in a collaborative effort to calculate a dominant SVD for the\nwhole matrix. In the framework of alternating direction methods of multipliers\n(ADMM), we propose a novel formulation for building consensus by equalizing\nsubspaces spanned by splitting variables instead of equalizing themselves. This\ntechnique greatly relaxes feasibility restrictions and accelerates convergence\nsignificantly, while at the same time yielding simple subproblems. We design\nseveral algorithmic features, including a low-rank multiplier formula and\nmechanisms for controlling subproblem solution accuracies, to increase the\nalgorithm's computational efficiency and reduce its communication overhead.\nMore importantly, the possibility appears remote, if possible at all, for a\nmalicious node to uncover the data stored in another node through shared\nquantities available in our algorithm, which is not the case in existing\ndistributed or parallelized algorithms. We present the convergence analysis\nresults, including a worst-case complexity estimate, and extensive experimental\nresults indicating that the proposed algorithm, while safely guarding data\nprivacy, has a strong potential to deliver a cutting-edge performance,\nespecially when communication costs are high.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 05:52:18 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 12:34:07 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 13:34:05 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Wang", "Lei", ""], ["Liu", "Xin", ""], ["Zhang", "Yin", ""]]}, {"id": "2012.03483", "submitter": "Byunggill Joe", "authors": "Byunggill Joe, Jihun Hamm, Sung Ju Hwang, Sooel Son, Insik Shin", "title": "Learning to Separate Clusters of Adversarial Representations for Robust\n  Adversarial Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although deep neural networks have shown promising performances on various\ntasks, they are susceptible to incorrect predictions induced by imperceptibly\nsmall perturbations in inputs. A large number of previous works proposed to\ndetect adversarial attacks. Yet, most of them cannot effectively detect them\nagainst adaptive whitebox attacks where an adversary has the knowledge of the\nmodel and the defense method. In this paper, we propose a new probabilistic\nadversarial detector motivated by a recently introduced non-robust feature. We\nconsider the non-robust features as a common property of adversarial examples,\nand we deduce it is possible to find a cluster in representation space\ncorresponding to the property. This idea leads us to probability estimate\ndistribution of adversarial representations in a separate cluster, and leverage\nthe distribution for a likelihood based adversarial detector.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 07:21:18 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Joe", "Byunggill", ""], ["Hamm", "Jihun", ""], ["Hwang", "Sung Ju", ""], ["Son", "Sooel", ""], ["Shin", "Insik", ""]]}, {"id": "2012.03528", "submitter": "Qizhang Li", "authors": "Yiwen Guo, Qizhang Li, Hao Chen", "title": "Backpropagating Linearly Improves Transferability of Adversarial\n  Examples", "comments": "Accepted by NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vulnerability of deep neural networks (DNNs) to adversarial examples has\ndrawn great attention from the community. In this paper, we study the\ntransferability of such examples, which lays the foundation of many black-box\nattacks on DNNs. We revisit a not so new but definitely noteworthy hypothesis\nof Goodfellow et al.'s and disclose that the transferability can be enhanced by\nimproving the linearity of DNNs in an appropriate manner. We introduce linear\nbackpropagation (LinBP), a method that performs backpropagation in a more\nlinear fashion using off-the-shelf attacks that exploit gradients. More\nspecifically, it calculates forward as normal but backpropagates loss as if\nsome nonlinear activations are not encountered in the forward pass.\nExperimental results demonstrate that this simple yet effective method\nobviously outperforms current state-of-the-arts in crafting transferable\nadversarial examples on CIFAR-10 and ImageNet, leading to more effective\nattacks on a variety of DNNs.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 08:40:56 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Guo", "Yiwen", ""], ["Li", "Qizhang", ""], ["Chen", "Hao", ""]]}, {"id": "2012.03577", "submitter": "Ievgeniia Kuzminykh", "authors": "Ievgeniia Kuzminykh, Bogdan Ghita, and Alexandr Silonosov", "title": "Impact of Network and Host Characteristics on the Keystroke Pattern in\n  Remote Desktop Sessions", "comments": "Copy draft with 10 pages, 4 figures,35 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Authentication based on keystroke dynamics is a convenient biometric\napproach, easy in use, transparent, and cheap as it does not require a\ndedicated sensor. Keystroke authentication, as part of multi factor\nauthentication, can be used in remote display access to guarantee the security\nof use of remote connectivity systems during the access control phase or\nthroughout the session. This paper investigates how network conditions and\nadditional host interaction may impact the behavioural pattern of keystrokes\nwhen used in a remote desktop application scenario. We focus on the timing of\nadjacent keys and investigate this impact by calculating the variations of the\nEuclidean distance between a reference profile and resulting profiles following\nsuch impairments. The experimental results indicate that variations of\ncongestion latency, whether produced by adjacent traffic sources or by\nadditional remote desktop interactions, have a substantive impact on the\nEuclidian distance, which in turn may affect the effectiveness of the biometric\nauthentication algorithm. Results also indicate that data flows within remote\ndesktop protocol are not prioritized and therefore additional traffic will have\na significant impact on the keystroke timings, which renders continuous\nauthentication less effective for remote access and more appropriate for\none-time login.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 10:34:53 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Kuzminykh", "Ievgeniia", ""], ["Ghita", "Bogdan", ""], ["Silonosov", "Alexandr", ""]]}, {"id": "2012.03586", "submitter": "Alessandro Erba", "authors": "Alessandro Erba, Nils Ole Tippenhauer", "title": "No Need to Know Physics: Resilience of Process-based Model-free Anomaly\n  Detection for Industrial Control Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, a number of process-based anomaly detection schemes for\nIndustrial Control Systems were proposed. In this work, we provide the first\nsystematic analysis of such schemes, and introduce a taxonomy of properties\nthat are verified by those detection systems. We then present a novel general\nframework to generate adversarial spoofing signals that violate physical\nproperties of the system, and use the framework to analyze four anomaly\ndetectors published at top security conferences. We find that three of those\ndetectors are susceptible to a number of adversarial manipulations (e.g.,\nspoofing with precomputed patterns), which we call Synthetic Sensor Spoofing\nand one is resilient against our attacks. We investigate the root of its\nresilience and demonstrate that it comes from the properties that we\nintroduced. Our attacks reduce the Recall (True Positive Rate) of the attacked\nschemes making them not able to correctly detect anomalies. Thus, the\nvulnerabilities we discovered in the anomaly detectors show that (despite an\noriginal good detection performance), those detectors are not able to reliably\nlearn physical properties of the system. Even attacks that prior work was\nexpected to be resilient against (based on verified properties) were found to\nbe successful. We argue that our findings demonstrate the need for both more\ncomplete attacks in datasets, and more critical analysis of process-based\nanomaly detectors. We plan to release our implementation as open-source,\ntogether with an extension of two public datasets with a set of Synthetic\nSensor Spoofing attacks as generated by our framework.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 11:02:44 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Erba", "Alessandro", ""], ["Tippenhauer", "Nils Ole", ""]]}, {"id": "2012.03589", "submitter": "Ievgeniia Kuzminykh", "authors": "Ievgeniia Kuzminykh, Bogdan Ghita, and Jose M. Such", "title": "The Challenges with Internet of Things for Business", "comments": "9 pages, 42 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many companies consider IoT as a central element for increasing\ncompetitiveness. Despite the growing number of cyberattacks on IoT devices and\nthe importance of IoT security, no study has yet primarily focused on the\nimpact of IoT security measures on the security challenges. This paper presents\na review of the current state of security of IoT in companies that produce IoT\nproducts and have begun a transformation towards the digitalization of their\nproducts and the associated production processes. The analysis of challenges in\nIoT security was conducted based on the review of resources and reports on IoT\nsecurity, while mapping the relevant solutions/measures for strengthening\nsecurity to the existing challenges. This mapping assists stakeholders in\nunderstanding the IoT security initiatives regarding their business needs and\nissues. Based on the analysis, we conclude that almost all companies have an\nunderstanding of basic security measures as encryption, but do not understand\nthreat surface and not aware of advanced methods of protecting data and\ndevices. The analysis shows that most companies do not have internal experts in\nIoT security and prefer to outsource security operations to security providers.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 11:12:28 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Kuzminykh", "Ievgeniia", ""], ["Ghita", "Bogdan", ""], ["Such", "Jose M.", ""]]}, {"id": "2012.03622", "submitter": "Richard Adeyemi Ikuesan Dr.", "authors": "Victor R. Kebande, Nickson M. Karie and Richard A. Ikuesan", "title": "Real-time monitoring as a supplementary security component of\n  vigilantism in modern network environments", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The phenomenon of network vigilantism is autonomously attributed to how\nanomalies and obscure activities from adversaries can be tracked in realtime.\nNeedless to say, in today dynamic, virtualized, and complex network\nenvironments, it has become undeniably necessary for network administrators,\nanalysts as well as engineers to practice network vigilantism, on traffic as\nwell as other network events in real-time. The reason is to understand the\nexact security posture of an organization network environment at any given\ntime. This is driven by the fact that modern network environments do, not only\npresent new opportunities to organizations but also a different set of new and\ncomplex cybersecurity challenges that need to be resolved daily. The growing\nsize, scope, complexity, and volume of networked devices in our modern network\nenvironments also makes it hard even for the most experienced network\nadministrators to independently provide the breadth and depth of knowledge\nneeded to oversee or diagnose complex network problems. Besides, with the\ngrowing number of Cyber Security Threats in the world today, many organizations\nhave been forced to change the way they plan, develop and implement\ncybersecurity strategies as a way to reinforce their ability to respond to\ncybersecurity incidents. This paper, therefore, examines the relevance of\nRealTime Monitoring (RTM) as a supplementary security component of vigilantism\nin modern network environments, more especially for proper planning,\npreparedness, and mitigation in case of a cybersecurity incident. Additionally,\nthis paper also investigates some of the key issues and challenges surrounding\nthe implementation of RTM for security vigilantism in our modern network\nenvironments.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 12:12:51 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Kebande", "Victor R.", ""], ["Karie", "Nickson M.", ""], ["Ikuesan", "Richard A.", ""]]}, {"id": "2012.03669", "submitter": "Challiz Omorog", "authors": "C. D. Omorog, R. P. Medina", "title": "Internet Security Awareness of Filipinos: A Survey Paper", "comments": "13 pages", "journal-ref": "IJCSR. Vol 1 No. 4 (2018) 14-26", "doi": "10.25147/ijcsr.2017.001.1.18", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose. This paper examines the Internet security perception of Filipinos to\nestablish a need and sense of urgency on the part of the government to create a\nculture of cybersecurity for every Filipino. Method. A quantitative survey was\nconducted through traditional, online, and phone interviews among 252\nrespondents using a two-page questionnaire that covers basic demographic\ninformation and two key elements (1) Internet usage and (2) security practices.\nResults. Based on findings, there is a sharp increase in Internet users for the\nlast three years (50%), and most access to the Internet through mobile (94.4%).\nAlthough at home is the most frequent location for Internet access (94.4%), a\ngood percentage still use free WiFi access points available in malls (22.2%),\nrestaurants (11.1%), and other public areas (38.9%) doing Internet services\n(email and downloading) that are vulnerable to cyberattacks. The study also\nrevealed that although respondents may have good knowledge of Internet security\nsoftware, proper implementation is very limited. Conclusion. Filipinos are\nsusceptible to cyberattacks, particularly to phishing and malware attacks.\nAlso, the majority of the respondents' Internet security perception is\nderivative: they practice online measures but with a limited understanding of\nthe purpose. Therefore proper education, through training and awareness, is an\neffective approach to remedy the situation. Recommendations. The Philippine\ngovernment must now take actions and tap industries to educate Filipinos about\nInternet security before any negative consequences happen in the future.\nResearch Implications. The information collected sets a clear picture of the\nimportance of cybersecurity awareness from a regional to a global perspective.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 02:56:27 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Omorog", "C. D.", ""], ["Medina", "R. P.", ""]]}, {"id": "2012.03670", "submitter": "Umut Can Cabuk", "authors": "Umut Can Cabuk", "title": "Non-Repudiation for VoIP Communication in UMTS and LTE Networks", "comments": "Master's Thesis. Prepared in Fraunhofer SIT; defended in Aarhus\n  University, in 2015", "journal-ref": null, "doi": "10.13140/RG.2.2.14059.95526", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This thesis work presents an architectural design of a system to bring\nnon-repudiation concept into the IP based digital voice conversations (VoIP) in\nLTE and UMTS networks, using electronic signatures, by considering a\ncentralized approach. Moreover, functionalities and technical methods to\nsupport such a system are researched. Last but not least, ways to introduce\nthis system as a public and commercial service are discussed. Non-repudiation\nconcept provided by electronic signatures and related cryptographic functions,\nas introduced in this study, allow using digital records of these voice\nconversations as legally binding statements or proofs likewise and even instead\nof traditional wet signatures. The system is designed as a subsystem to IMS\nbased 3G and 4G networks and maximum compatibility with current configurations,\ncomponents and interfaces of these networks is intended. On the other hand\nnon-repudiation is achieved by special signature, storage and verification\nunits located in the IMS core network. Voice data is proposed to be processed\nin MRF unit of the IMS. Additionally, a USSD/USSI based special solution to\ninitiate these signed calls is developed. According to the proposed scheme;\nduring a signed call, two unidirectional voice streams originating from two\nparties of the call, which are transferred in IP and UDP encapsulated RTP\npackages, are received by the signature unit and interweaved using their\narrival times, so that they become a unified stream. Signature unit generates\nhashes of groups of received packages and signs them using PKI algorithms and\napplying hash/signature chaining to increase integrity protection and to\nempower non-repudiation. Then, it forwards packages and signature information\nto the storage unit. Storage unit keeps all the call records, signature data\nand metadata of these calls. Verification unit later gathers relevant data from\nthe storage unit...\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 23:40:26 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Cabuk", "Umut Can", ""]]}, {"id": "2012.03706", "submitter": "George Bissias", "authors": "George Bissias, Rainer B\\\"ohme, David Thibodeau, Brian N. Levine", "title": "Pricing Security in Proof-of-Work Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key component of security in decentralized blockchains is proof of\nopportunity cost among block producers. In the case of proof-of-work (PoW),\ncurrently used by the most prominent systems, the cost is due to spent\ncomputation. In this paper, we characterize the security investment of miners\nin terms of its cost in fiat money. This enables comparison of security\nallocations across PoW blockchains that generally use different PoW algorithms\nand reward miners in different cryptocurrency units. We prove that there exists\na unique allocation equilibrium, depending on market prices only, that is\nachieved by both strategic miners (who contemplate the actions of others) and\nby miners seeking only short-term profit. In fact, the latter will unknowingly\ncompensate for any attempt to deliberately shift security allocation away from\nequilibrium.\n  Our conclusions are supported analytically through the development of a\nMarkov decision process, game theoretical analysis, and derivation of no\narbitrage conditions. We corroborate those results with empirical evidence from\nmore than two years of blockchain and price data. Overall agreement is strong.\nWe show that between January 1, 2018 and August 1, 2020, market prices\npredicted security allocation between Bitcoin and Bitcoin Cash with error less\nthan 0.6%. And from the beginning of October 2019, until August 1, 2020, market\nprices predicted security allocation between Bitcoin and Litecoin with error of\n0.45%. These results are further corroborated by our establishment of\nGranger-causality between change in market prices and change in security\nallocation.\n  To demonstrate the practicality of our results, we describe a trustless\noracle that leverages the equilibrium to estimate the price ratios of PoW\ncryptocurrencies from on-chain information only.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 14:05:11 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Bissias", "George", ""], ["B\u00f6hme", "Rainer", ""], ["Thibodeau", "David", ""], ["Levine", "Brian N.", ""]]}, {"id": "2012.03750", "submitter": "Paul Maxwell", "authors": "Paul Maxwell, David Niblick, and Daniel C. Ruiz", "title": "Using Side Channel Information and Artificial Intelligence for Malware\n  Detection", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Cybersecurity continues to be a difficult issue for society especially as the\nnumber of networked systems grows. Techniques to protect these systems range\nfrom rules-based to artificial intelligence-based intrusion detection systems\nand anti-virus tools. These systems rely upon the information contained in the\nnetwork packets and download executables to function. Side channel information\nleaked from hardware has been shown to reveal secret information in systems\nsuch as encryption keys. This work demonstrates that side channel information\ncan be used to detect malware running on a computing platform without access to\nthe code involved.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 18:38:53 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Maxwell", "Paul", ""], ["Niblick", "David", ""], ["Ruiz", "Daniel C.", ""]]}, {"id": "2012.03754", "submitter": "Thanh Thi Nguyen", "authors": "Thanh Thi Nguyen, Hammad Tahir, Mohamed Abdelrazek, Ali Babar", "title": "Deep Learning Methods for Credit Card Fraud Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Credit card frauds are at an ever-increasing rate and have become a major\nproblem in the financial sector. Because of these frauds, card users are\nhesitant in making purchases and both the merchants and financial institutions\nbear heavy losses. Some major challenges in credit card frauds involve the\navailability of public data, high class imbalance in data, changing nature of\nfrauds and the high number of false alarms. Machine learning techniques have\nbeen used to detect credit card frauds but no fraud detection systems have been\nable to offer great efficiency to date. Recent development of deep learning has\nbeen applied to solve complex problems in various areas. This paper presents a\nthorough study of deep learning methods for the credit card fraud detection\nproblem and compare their performance with various machine learning algorithms\non three different financial datasets. Experimental results show great\nperformance of the proposed deep learning methods against traditional machine\nlearning models and imply that the proposed approaches can be implemented\neffectively for real-world credit card fraud detection systems.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 14:48:58 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Nguyen", "Thanh Thi", ""], ["Tahir", "Hammad", ""], ["Abdelrazek", "Mohamed", ""], ["Babar", "Ali", ""]]}, {"id": "2012.03765", "submitter": "Jinyuan Jia", "authors": "Jinyuan Jia and Xiaoyu Cao and Neil Zhenqiang Gong", "title": "Certified Robustness of Nearest Neighbors against Data Poisoning Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data poisoning attacks aim to corrupt a machine learning model via modifying,\nadding, and/or removing some carefully selected training examples, such that\nthe corrupted model predicts any or attacker-chosen incorrect labels for\ntesting examples. The key idea of state-of-the-art certified defenses against\ndata poisoning attacks is to create a \\emph{majority vote} mechanism to predict\nthe label of a testing example. Moreover, each voter is a base classifier\ntrained on a subset of the training dataset. Classical simple learning\nalgorithms such as $k$ nearest neighbors (kNN) and radius nearest neighbors\n(rNN) have intrinsic majority vote mechanisms. In this work, we show that the\nintrinsic majority vote mechanisms in kNN and rNN already provide certified\nrobustness guarantees against general data poisoning attacks. Moreover, our\nevaluation results on MNIST and CIFAR10 show that the intrinsic certified\nrobustness guarantees of kNN and rNN outperform those provided by\nstate-of-the-art certified defenses. Our results serve as standard baselines\nfor future certified defenses against data poisoning attacks.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 15:04:48 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 02:20:42 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Jia", "Jinyuan", ""], ["Cao", "Xiaoyu", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "2012.03782", "submitter": "Fumiyuki Kato", "authors": "Fumiyuki Kato, Yang Cao, and Yoshikawa Masatoshi", "title": "PCT-TEE: Trajectory-based Private Contact Tracing System with Trusted\n  Execution Environment", "comments": "arXiv admin note: substantial text overlap with arXiv:2010.13381.\n  text overlap with arXiv:2010.13381", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing Bluetooth-based Private Contact Tracing (PCT) systems can privately\ndetect whether people have come into direct contact with COVID-19 patients.\nHowever, we find that the existing systems lack functionality and flexibility,\nwhich may hurt the success of the contact tracing. Specifically, they cannot\ndetect indirect contact (e.g., people may be exposed to coronavirus because of\nused the same elevator even without direct contact); they also cannot flexibly\nchange the rules of \"risky contact\", such as how many hours of exposure or how\nclose to a COVID-19 patient that is considered as risk exposure, which may be\nchanged with the environmental situation. In this paper, we propose an\nefficient and secure contact tracing system that enables both direct contact\nand indirect contact. To address the above problems, we need to utilize users'\ntrajectory data for private contact tracing, which we call trajectory-based\nPCT. We formalize this problem as Spatiotemporal Private Set Intersection. By\nanalyzing different approaches such as homomorphic encryption that could be\nextended to solve this problem, we identify that Trusted Execution Environment\n(TEE) is a proposing method to achieve our requirements. The major challenge is\nhow to design algorithms for spatiotemporal private set intersection under\nlimited secure memory of TEE. To this end, we design a TEE-based system with\nflexible trajectory data encoding algorithms. Our experiments on real-world\ndata show that the proposed system can process thousands of queries on tens of\nmillion records of trajectory data in a few seconds.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 15:22:19 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 09:03:46 GMT"}, {"version": "v3", "created": "Wed, 24 Feb 2021 11:32:55 GMT"}, {"version": "v4", "created": "Sun, 27 Jun 2021 14:25:28 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Kato", "Fumiyuki", ""], ["Cao", "Yang", ""], ["Masatoshi", "Yoshikawa", ""]]}, {"id": "2012.03814", "submitter": "Matilda Rhode", "authors": "\\'Eireann Leverett, Matilda Rhode, Adam Wedgbury", "title": "Vulnerability Forecasting: In theory and practice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Why wait for zero-days when you could predict them in advance? It is possible\nto predict the volume of CVEs released in the NVD as much as a year in advance.\nThis can be done within 3 percent of the actual value, and different predictive\nalgorithms perform well at different lookahead values. It is also possible to\nestimate the proportions of that total volumn belonging to specific vendors,\nsoftware, CVSS scores, or vulnerability types. Strategic patch management\nshould become much easier, with this uncertainty reduction.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 15:57:12 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Leverett", "\u00c9ireann", ""], ["Rhode", "Matilda", ""], ["Wedgbury", "Adam", ""]]}, {"id": "2012.03816", "submitter": "Yuezun Li", "authors": "Yuezun Li, Yiming Li, Baoyuan Wu, Longkang Li, Ran He, and Siwei Lyu", "title": "Backdoor Attack with Sample-Specific Triggers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, backdoor attacks pose a new security threat to the training process\nof deep neural networks (DNNs). Attackers intend to inject hidden backdoor into\nDNNs, such that the attacked model performs well on benign samples, whereas its\nprediction will be maliciously changed if the hidden backdoor is activated by\nan attacker-defined trigger. Existing backdoor attacks usually adopt the\nsetting that the trigger is sample-agnostic, $i.e.,$ different poisoned samples\ncontain the same trigger, resulting in that the attacks could be easily\nmitigated by current backdoor defenses. In this work, we explore a novel attack\nparadigm that the backdoor trigger is sample-specific. Specifically, inspired\nby the recent advance in DNN-based image steganography, we generate\nsample-specific invisible additive noises as backdoor triggers by encoding an\nattacker-specified string into benign images through an encoder-decoder\nnetwork. The mapping from the string to the target label will be generated when\nDNNs are trained on the poisoned dataset. Extensive experiments on benchmark\ndatasets verify the effectiveness of our method in attacking models with or\nwithout defenses.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 16:02:08 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Li", "Yuezun", ""], ["Li", "Yiming", ""], ["Wu", "Baoyuan", ""], ["Li", "Longkang", ""], ["He", "Ran", ""], ["Lyu", "Siwei", ""]]}, {"id": "2012.03817", "submitter": "Yuval Dagan", "authors": "Yuval Dagan, Gil Kur", "title": "A bounded-noise mechanism for differential privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Answering multiple counting queries is one of the best-studied problems in\ndifferential privacy. Its goal is to output an approximation of the average\n$\\frac{1}{n}\\sum_{i=1}^n \\vec{x}^{(i)}$ of vectors $\\vec{x}^{(i)} \\in [0,1]^k$,\nwhile preserving the privacy with respect to any $\\vec{x}^{(i)}$. We present an\n$(\\epsilon,\\delta)$-private mechanism with optimal $\\ell_\\infty$ error for most\nvalues of $\\delta$. This result settles the conjecture of Steinke and Ullman\n[2020] for the these values of $\\delta$. Our algorithm adds independent noise\nof bounded magnitude to each of the $k$ coordinates, while prior solutions\nrelied on unbounded noise such as the Laplace and Gaussian mechanisms.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 16:03:21 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Dagan", "Yuval", ""], ["Kur", "Gil", ""]]}, {"id": "2012.03893", "submitter": "Noah Golowich", "authors": "Badih Ghazi, Noah Golowich, Ravi Kumar, Pasin Manurangsi", "title": "Sample-efficient proper PAC learning with approximate differential\n  privacy", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we prove that the sample complexity of properly learning a\nclass of Littlestone dimension $d$ with approximate differential privacy is\n$\\tilde O(d^6)$, ignoring privacy and accuracy parameters. This result answers\na question of Bun et al. (FOCS 2020) by improving upon their upper bound of\n$2^{O(d)}$ on the sample complexity. Prior to our work, finiteness of the\nsample complexity for privately learning a class of finite Littlestone\ndimension was only known for improper private learners, and the fact that our\nlearner is proper answers another question of Bun et al., which was also asked\nby Bousquet et al. (NeurIPS 2020). Using machinery developed by Bousquet et\nal., we then show that the sample complexity of sanitizing a binary hypothesis\nclass is at most polynomial in its Littlestone dimension and dual Littlestone\ndimension. This implies that a class is sanitizable if and only if it has\nfinite Littlestone dimension. An important ingredient of our proofs is a new\nproperty of binary hypothesis classes that we call irreducibility, which may be\nof independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 18:17:46 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Ghazi", "Badih", ""], ["Golowich", "Noah", ""], ["Kumar", "Ravi", ""], ["Manurangsi", "Pasin", ""]]}, {"id": "2012.04117", "submitter": "Victor Aguiar Evangelista De Farias", "authors": "Victor A. E. Farias, Felipe T. Brito, Cheryl Flynn, Javam C. Machado,\n  Subhabrata Majumdar and Divesh Srivastava", "title": "Local Dampening: Differential Privacy for Non-numeric Queries via Local\n  Sensitivity", "comments": null, "journal-ref": "PVLDB,14(4),2021, 521 - 533", "doi": "10.14778/3436905.3436912", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy is the state-of-the-art formal definition for data\nrelease under strong privacy guarantees. A variety of mechanisms have been\nproposed in the literature for releasing the noisy output of numeric queries\n(e.g., using the Laplace mechanism), based on the notions of global sensitivity\nand local sensitivity. However, although there has been some work on generic\nmechanisms for releasing the output of non-numeric queries using global\nsensitivity (e.g., the Exponential mechanism), the literature lacks generic\nmechanisms for releasing the output of non-numeric queries using local\nsensitivity to reduce the noise in the query output.\n  In this work, we remedy this shortcoming and present the local dampening\nmechanism. We adapt the notion of local sensitivity for the non-numeric setting\nand leverage it to design a generic non-numeric mechanism. We illustrate the\neffectiveness of the local dampening mechanism by applying it to two diverse\nproblems: (i) Influential node analysis. Given an influence metric, we release\nthe top-k most central nodes while preserving the privacy of the relationship\nbetween nodes in the network; (ii) Decision tree induction. We provide a\nprivate adaptation to the ID3 algorithm to build decision trees from a given\ntabular dataset. Experimental results show that we could reduce the use of\nprivacy budget by 3 to 4 orders of magnitude for Influential node analysis and\nincrease accuracy up to 12% for Decision tree induction when compared to global\nsensitivity based approaches.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 23:51:19 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 19:22:31 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Farias", "Victor A. E.", ""], ["Brito", "Felipe T.", ""], ["Flynn", "Cheryl", ""], ["Machado", "Javam C.", ""], ["Majumdar", "Subhabrata", ""], ["Srivastava", "Divesh", ""]]}, {"id": "2012.04156", "submitter": "Aditya Jyoti Paul", "authors": "Joan S. Muthu, Aditya Jyoti Paul, P. Murali", "title": "An Efficient Analyses of the Behavior of One Dimensional Chaotic Maps\n  using 0-1 Test and Three State Test", "comments": "6 pages, Published in IEEE RAICS 2020, see https://www.raics.in", "journal-ref": "2020 IEEE Recent Advances in Intelligent Computational Systems\n  (RAICS), 2020, pp. 125-130", "doi": "10.1109/RAICS51191.2020.9332470", "report-no": null, "categories": "math.NA cs.CR cs.NA eess.SP math.DS math.FA nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a rigorous analysis of the behavior of the standard logistic\nmap, Logistic Tent system (LTS), Logistic-Sine system (LSS) and Tent-Sine\nsystem (TSS) is performed using 0-1 test and three state test (3ST). In this\nwork, it has been proved that the strength of the chaotic behavior is not\nuniform. Through extensive experiment and analysis, the strong and weak chaotic\nregions of LTS, LSS and TSS have been identified. This would enable researchers\nusing these maps, to have better choices of control parameters as key values,\nfor stronger encryption. In addition, this paper serves as a precursor to\nstronger testing practices in cryptosystem research, as Lyapunov exponent alone\nhas been shown to fail as a true representation of the chaotic nature of a map.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 01:41:37 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 10:22:56 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Muthu", "Joan S.", ""], ["Paul", "Aditya Jyoti", ""], ["Murali", "P.", ""]]}, {"id": "2012.04163", "submitter": "Suranga Seneviratne", "authors": "Sicong Wang, Naveen Karunanayake, Tham Nguyen, Suranga Seneviratne", "title": "Privacy-Preserving Spam Filtering using Functional Encryption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional spam classification requires the end-user to reveal the content\nof its received email to the spam classifier which violates the privacy. Spam\nclassification over encrypted emails enables the classifier to classify spam\nemail without accessing the email, hence protects the privacy of email content.\nIn this paper, we construct a spam classification framework that enables the\nclassification of encrypted emails. Our classification model is based on a\nneural network with a quadratic network part and a multi-layer perception\nnetwork part. The quadratic network architecture is compatible with the\noperation of an existing quadratic functional encryption scheme that enables\nour classification to predict the label of encrypted emails without revealing\nthe associated plain-text email. The evaluation results on real-world spam\ndatasets indicate that our proposed spam classification model achieves an\naccuracy of over 96%.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 02:14:28 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Wang", "Sicong", ""], ["Karunanayake", "Naveen", ""], ["Nguyen", "Tham", ""], ["Seneviratne", "Suranga", ""]]}, {"id": "2012.04172", "submitter": "Hong-Ning Dai Prof.", "authors": "Xiaoyun Li, Zibin Zheng, Hong-Ning Dai", "title": "When Services Computing Meets Blockchain: Challenges and Opportunities", "comments": "15 pages, 5 figures", "journal-ref": "Journal of Parallel and Distributed Computing, 2021", "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Services computing can offer a high-level abstraction to support diverse\napplications via encapsulating various computing infrastructures. Though\nservices computing has greatly boosted the productivity of developers, it is\nfaced with three main challenges: privacy and security risks, information silo,\nand pricing mechanisms and incentives. The recent advances of blockchain bring\nopportunities to address the challenges of services computing due to its\nbuild-in encryption as well as digital signature schemes, decentralization\nfeature, and intrinsic incentive mechanisms. In this paper, we present a survey\nto investigate the integration of blockchain with services computing. The\nintegration of blockchain with services computing mainly exhibits merits in two\naspects: i) blockchain can potentially address key challenges of services\ncomputing and ii) services computing can also promote blockchain development.\nIn particular, we categorize the current literature of services computing based\non blockchain into five types: services creation, services discovery, services\nrecommendation, services composition, and services arbitration. Moreover, we\ngeneralize Blockchain as a Service (BaaS) architecture and summarize the\nrepresentative BaaS platforms. In addition, we also outline open issues of\nblockchain-based services computing and BaaS.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 02:27:43 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Li", "Xiaoyun", ""], ["Zheng", "Zibin", ""], ["Dai", "Hong-Ning", ""]]}, {"id": "2012.04211", "submitter": "Guangsheng Ma", "authors": "Guangsheng Ma and Hongbo Li", "title": "Quantum Fully Homomorphic Encryption with neither Clifford Gate\n  Decomposition nor Real Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel quantum fully homomorphic encryption (QFHE) scheme, which\nallows to perform conditional rotations with the control bit in encrypted form.\nIn our scheme, any quantum circuit can be directly evaluated with no need to\ndecompose into Clifford/non-Clifford gates, nor to be transformed into real\nrepresentation. Our scheme is able to evaluate quantum Fourier transform\nalgorithm faster than previous QFHE schemes in the worst case.\n  The security of our scheme relies on the hardness of the underlying quantum\ncapable FHE scheme, and the latter sets its security on the learning with\nerrors problem and the circular security assumption.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 04:54:02 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 13:57:41 GMT"}, {"version": "v3", "created": "Wed, 7 Apr 2021 10:52:17 GMT"}, {"version": "v4", "created": "Sun, 11 Apr 2021 10:43:30 GMT"}, {"version": "v5", "created": "Tue, 18 May 2021 04:49:30 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Ma", "Guangsheng", ""], ["Li", "Hongbo", ""]]}, {"id": "2012.04215", "submitter": "Manik Lal Das", "authors": "Yash Mehta, Dev Patel, and Manik Lal Das", "title": "On Aadhaar Identity Management System", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A unique identification for citizens can lead to effective governance to\nmanage and provide citizen-centric services. While ensuring this service,\nprivacy of the citizens needs to be preserved. Aadhaar, the identification\nsystem by UIDAI has faced some critics regarding its privacy preserving\nfeature. This paper discusses those concerns in Aadhaar system and proposed a\nnew model for the Aadhaar system. The proposed solution is aimed to address the\nissue of collusion of third party service providers and profiling of Aadhaar\nusers. The proposed solution uses a distributed model capturing the Aadhaar\nsystem, in which data of users is decentralized and stored in zonal office's\ndatabases as well as the CIDR. The proposed solution provides the functioning\nof the authentication process of the Aadhaar system more effective, as it\nreduces the number of requests being handled directly by the CIDR and also\ntackles the concern of correlation of data.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 05:00:18 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Mehta", "Yash", ""], ["Patel", "Dev", ""], ["Das", "Manik Lal", ""]]}, {"id": "2012.04254", "submitter": "Junmo Lee", "authors": "Junmo Lee, Seongjun Kim, Sanghyeon Park, Soo-Mook Moon", "title": "RouTEE: A Secure Payment Network Routing Hub using Trusted Execution\n  Environments", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptocurrencies such as Bitcoin and Ethereum have made payment transactions\npossible without a trusted third party, but they have a scalability issue due\nto their consensus mechanisms. Payment networks have emerged to overcome this\nlimitation by executing transactions outside of the blockchain, which is why\nthese are referred to as off-chain transactions. In order to establish a\npayment channel between two users, the users lock their deposits in the\nblockchain, and then they can pay each other through the channel. Furthermore,\npayment networks support multi-hop payments that allow users to transfer their\nbalances to other users who are connected to them via multiple channels.\nHowever, multi-hop payments are hard to be accomplished, as they are heavily\ndependent on routing users on a payment path from a sender to a receiver.\nAlthough routing hubs can make multi-hop payments more practical and efficient,\nthey need a lot of collateral locked for a long period and have privacy issues\nin terms of payment history.\n  We propose RouTEE, a secure payment routing hub that is fully feasible\nwithout the hub's deposit. Unlike existing payment networks, RouTEE provides\nhigh balance liquidity, and details about payments are concealed from hosts by\nleveraging trusted execution environments (TEEs). RouTEE is designed to make\nrational hosts behave honestly, by introducing a new routing fee scheme and a\nsecure settlement method. Moreover, users do not need to monitor the blockchain\nin real-time or run full nodes. They can participate in RouTEE by simply\nverifying block headers through light clients; furthermore, having only one\nchannel with RouTEE is sufficient to interact with other users. Our\nimplementation demonstrates that RouTEE is highly efficient and outperforms\nLightning Network that is the state-of-the-art payment network.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 07:34:39 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Lee", "Junmo", ""], ["Kim", "Seongjun", ""], ["Park", "Sanghyeon", ""], ["Moon", "Soo-Mook", ""]]}, {"id": "2012.04405", "submitter": "Ryan K. L. Ko", "authors": "Ryan K L Ko", "title": "Cyber Autonomy: Automating the Hacker- Self-healing, self-adaptive,\n  automatic cyber defense systems and their impact to the industry, society and\n  national security", "comments": "15 pages, 5 figures, preprint of chapter in edited book \"Emerging\n  Technologies and International Security: Machines, the State, and War\" edited\n  By Reuben Steff, Joe Burton, Simona R. Soare", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper sets the context for the urgency for cyber autonomy, and the\ncurrent gaps of the cyber security industry. A novel framework proposing four\nphases of maturity for full cyber autonomy will be discussed. The paper also\nreviews new and emerging cyber security automation techniques and tools, and\ndiscusses their impact on society, the perceived cyber security skills\ngap/shortage and national security. We will also be discussing the delicate\nbalance between national security, human rights and ethics, and the potential\ndemise of the manual penetration testing industry in the face of automation.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 12:50:09 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Ko", "Ryan K L", ""]]}, {"id": "2012.04432", "submitter": "Yi Liu", "authors": "Yi Liu, Xingliang Yuan, Ruihui Zhao, Yifeng Zheng, Yefeng Zheng", "title": "RC-SSFL: Towards Robust and Communication-efficient Semi-supervised\n  Federated Learning System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) is an emerging decentralized artificial intelligence\nparadigm, which promises to train a shared global model in high-quality while\nprotecting user data privacy. However, the current systems rely heavily on a\nstrong assumption: all clients have a wealth of ground truth labeled data,\nwhich may not be always feasible in the real life. In this paper, we present a\npractical Robust, and Communication-efficient Semi-supervised FL (RC-SSFL)\nsystem design that can enable the clients to jointly learn a high-quality model\nthat is comparable to typical FL's performance. In this setting, we assume that\nthe client has only unlabeled data and the server has a limited amount of\nlabeled data. Besides, we consider malicious clients can launch poisoning\nattacks to harm the performance of the global model. To solve this issue,\nRC-SSFL employs a minimax optimization-based client selection strategy to\nselect the clients who hold high-quality updates and uses geometric median\naggregation to robustly aggregate model updates. Furthermore, RC-SSFL\nimplements a novel symmetric quantization method to greatly improve\ncommunication efficiency. Extensive case studies on two real-world datasets\ndemonstrate that RC-SSFL can maintain the performance comparable to typical FL\nin the presence of poisoning attacks and reduce communication overhead by $2\n\\times \\sim 4 \\times $.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 14:02:56 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Liu", "Yi", ""], ["Yuan", "Xingliang", ""], ["Zhao", "Ruihui", ""], ["Zheng", "Yifeng", ""], ["Zheng", "Yefeng", ""]]}, {"id": "2012.04436", "submitter": "Yi Liu", "authors": "Yi Liu, Ruihui Zhao, Jiawen Kang, Abdulsalam Yassine, Dusit Niyato,\n  Jialiang Peng", "title": "Towards Communication-efficient and Attack-Resistant Federated Edge\n  Learning for Industrial Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Edge Learning (FEL) allows edge nodes to train a global deep\nlearning model collaboratively for edge computing in the Industrial Internet of\nThings (IIoT), which significantly promotes the development of Industrial 4.0.\nHowever, FEL faces two critical challenges: communication overhead and data\nprivacy. FEL suffers from expensive communication overhead when training\nlarge-scale multi-node models. Furthermore, due to the vulnerability of FEL to\ngradient leakage and label-flipping attacks, the training process of the global\nmodel is easily compromised by adversaries. To address these challenges, we\npropose a communication-efficient and privacy-enhanced asynchronous FEL\nframework for edge computing in IIoT. First, we introduce an asynchronous model\nupdate scheme to reduce the computation time that edge nodes wait for global\nmodel aggregation. Second, we propose an asynchronous local differential\nprivacy mechanism, which improves communication efficiency and mitigates\ngradient leakage attacks by adding well-designed noise to the gradients of edge\nnodes. Third, we design a cloud-side malicious node detection mechanism to\ndetect malicious nodes by testing the local model quality. Such a mechanism can\navoid malicious nodes participating in training to mitigate label-flipping\nattacks. Extensive experimental studies on two real-world datasets demonstrate\nthat the proposed framework can not only improve communication efficiency but\nalso mitigate malicious attacks while its accuracy is comparable to traditional\nFEL frameworks.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 14:11:32 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Liu", "Yi", ""], ["Zhao", "Ruihui", ""], ["Kang", "Jiawen", ""], ["Yassine", "Abdulsalam", ""], ["Niyato", "Dusit", ""], ["Peng", "Jialiang", ""]]}, {"id": "2012.04454", "submitter": "Paul-Gauthier No\\'e", "authors": "Paul-Gauthier No\\'e, Mohammad Mohammadamini, Driss Matrouf, Titouan\n  Parcollet, Andreas Nautsch, Jean-Fran\\c{c}ois Bonastre", "title": "Adversarial Disentanglement of Speaker Representation for\n  Attribute-Driven Privacy Preservation", "comments": "Accepted to Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In speech technologies, speaker's voice representation is used in many\napplications such as speech recognition, voice conversion, speech synthesis\nand, obviously, user authentication. Modern vocal representations of the\nspeaker are based on neural embeddings. In addition to the targeted\ninformation, these representations usually contain sensitive information about\nthe speaker, like the age, sex, physical state, education level or ethnicity.\nIn order to allow the user to choose which information to protect, we introduce\nin this paper the concept of attribute-driven privacy preservation in speaker\nvoice representation. It allows a person to hide one or more personal aspects\nto a potential malicious interceptor and to the application provider. As a\nfirst solution to this concept, we propose to use an adversarial autoencoding\nmethod that disentangles in the voice representation a given speaker attribute\nthus allowing its concealment. We focus here on the sex attribute for an\nAutomatic Speaker Verification (ASV) task. Experiments carried out using the\nVoxCeleb datasets have shown that the proposed method enables the concealment\nof this attribute while preserving ASV ability.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 14:47:23 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 09:26:53 GMT"}, {"version": "v3", "created": "Wed, 16 Jun 2021 08:40:07 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["No\u00e9", "Paul-Gauthier", ""], ["Mohammadamini", "Mohammad", ""], ["Matrouf", "Driss", ""], ["Parcollet", "Titouan", ""], ["Nautsch", "Andreas", ""], ["Bonastre", "Jean-Fran\u00e7ois", ""]]}, {"id": "2012.04473", "submitter": "Isaiah Hull", "authors": "Isaiah Hull, Or Sattath, Eleni Diamanti, G\\\"oran Wendin", "title": "Quantum Technology for Economists", "comments": "106 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.CR q-fin.EC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on quantum technology spans multiple disciplines: physics, computer\nscience, engineering, and mathematics. The objective of this manuscript is to\nprovide an accessible introduction to this emerging field for economists that\nis centered around quantum computing and quantum money. We proceed in three\nsteps. First, we discuss basic concepts in quantum computing and quantum\ncommunication, assuming knowledge of linear algebra and statistics, but not of\ncomputer science or physics. This covers fundamental topics, such as qubits,\nsuperposition, entanglement, quantum circuits, oracles, and the no-cloning\ntheorem. Second, we provide an overview of quantum money, an early invention of\nthe quantum communication literature that has recently been partially\nimplemented in an experimental setting. One form of quantum money offers the\nprivacy and anonymity of physical cash, the option to transact without the\ninvolvement of a third party, and the efficiency and convenience of a debit\ncard payment. Such features cannot be achieved in combination with any other\nform of money. Finally, we review all existing quantum speedups that have been\nidentified for algorithms used to solve and estimate economic models. This\nincludes function approximation, linear systems analysis, Monte Carlo\nsimulation, matrix inversion, principal component analysis, linear regression,\ninterpolation, numerical differentiation, and true random number generation. We\nalso discuss the difficulty of achieving quantum speedups and comment on common\nmisconceptions about what is achievable with quantum computing.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 15:14:24 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 09:26:09 GMT"}, {"version": "v3", "created": "Sat, 9 Jan 2021 23:59:26 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Hull", "Isaiah", ""], ["Sattath", "Or", ""], ["Diamanti", "Eleni", ""], ["Wendin", "G\u00f6ran", ""]]}, {"id": "2012.04699", "submitter": "David Saranchak", "authors": "Daniel L. Felps, Amelia D. Schwickerath, Joyce D. Williams, Trung N.\n  Vuong, Alan Briggs, Matthew Hunt, Evan Sakmar, David D. Saranchak, Tyler\n  Shumaker", "title": "Class Clown: Data Redaction in Machine Unlearning at Enterprise Scale", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Individuals are gaining more control of their personal data through recent\ndata privacy laws such the General Data Protection Regulation and the\nCalifornia Consumer Privacy Act. One aspect of these laws is the ability to\nrequest a business to delete private information, the so called \"right to be\nforgotten\" or \"right to erasure\". These laws have serious financial\nimplications for companies and organizations that train large, highly accurate\ndeep neural networks (DNNs) using these valuable consumer data sets. However, a\nreceived redaction request poses complex technical challenges on how to comply\nwith the law while fulfilling core business operations. We introduce a DNN\nmodel lifecycle maintenance process that establishes how to handle specific\ndata redaction requests and minimize the need to completely retrain the model.\nOur process is based upon the membership inference attack as a compliance tool\nfor every point in the training set. These attack models quantify the privacy\nrisk of all training data points and form the basis of follow-on data redaction\nfrom an accurate deployed model; excision is implemented through incorrect\nlabel assignment within incremental model updates.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 19:35:09 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Felps", "Daniel L.", ""], ["Schwickerath", "Amelia D.", ""], ["Williams", "Joyce D.", ""], ["Vuong", "Trung N.", ""], ["Briggs", "Alan", ""], ["Hunt", "Matthew", ""], ["Sakmar", "Evan", ""], ["Saranchak", "David D.", ""], ["Shumaker", "Tyler", ""]]}, {"id": "2012.04734", "submitter": "Mohammed Hassanin", "authors": "Mohammed Hassanin, Nour Moustafa, Murat Tahtali", "title": "A Deep Marginal-Contrastive Defense against Adversarial Attacks on 1D\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning algorithms have been recently targeted by attackers due to\ntheir vulnerability. Several research studies have been conducted to address\nthis issue and build more robust deep learning models. Non-continuous deep\nmodels are still not robust against adversarial, where most of the recent\nstudies have focused on developing attack techniques to evade the learning\nprocess of the models. One of the main reasons behind the vulnerability of such\nmodels is that a learning classifier is unable to slightly predict perturbed\nsamples. To address this issue, we propose a novel objective/loss function, the\nso-called marginal contrastive, which enforces the features to lie under a\nspecified margin to facilitate their prediction using deep convolutional\nnetworks (i.e., Char-CNN). Extensive experiments have been conducted on\ncontinuous cases (e.g., UNSW NB15 dataset) and discrete ones (i.e,\neight-large-scale datasets [32]) to prove the effectiveness of the proposed\nmethod. The results revealed that the regularization of the learning process\nbased on the proposed loss function can improve the performance of Char-CNN.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 20:51:43 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Hassanin", "Mohammed", ""], ["Moustafa", "Nour", ""], ["Tahtali", "Murat", ""]]}, {"id": "2012.04770", "submitter": "Michael Specter", "authors": "John Meklenburg, Michael Specter, Michael Wentz, Hari Balakrishnan,\n  Anantha Chandrakasan, John Cohn, Gary Hatke, Louise Ivers, Ronald Rivest,\n  Gerald Jay Sussman, Daniel Weitzner", "title": "SonicPACT: An Ultrasonic Ranging Method for the Private Automated\n  Contact Tracing (PACT) Protocol", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Throughout the course of the COVID-19 pandemic, several countries have\ndeveloped and released contact tracing and exposure notification smartphone\napplications (apps) to help slow the spread of the disease. To support such\napps, Apple and Google have released Exposure Notification Application\nProgramming Interfaces (APIs) to infer device (user) proximity using Bluetooth\nLow Energy (BLE) beacons. The Private Automated Contact Tracing (PACT) team has\nshown that accurately estimating the distance between devices using only BLE\nradio signals is challenging. This paper describes the design and\nimplementation of the SonicPACT protocol to use near-ultrasonic signals on\ncommodity iOS and Android smartphones to estimate distances using\ntime-of-flight measurements. The protocol allows Android and iOS devices to\ninteroperate, augmenting and improving the current exposure notification APIs.\nOur initial experimental results are promising, suggesting that SonicPACT\nshould be considered for implementation by Apple and Google.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 22:33:39 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Meklenburg", "John", ""], ["Specter", "Michael", ""], ["Wentz", "Michael", ""], ["Balakrishnan", "Hari", ""], ["Chandrakasan", "Anantha", ""], ["Cohn", "John", ""], ["Hatke", "Gary", ""], ["Ivers", "Louise", ""], ["Rivest", "Ronald", ""], ["Sussman", "Gerald Jay", ""], ["Weitzner", "Daniel", ""]]}, {"id": "2012.04848", "submitter": "Xiaodi Wu", "authors": "Kai-Min Chung, Yi Lee, Han-Hsuan Lin, and Xiaodi Wu", "title": "Constant-round Blind Classical Verification of Quantum Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent breakthrough, Mahadev constructed a classical verification of\nquantum computation (CVQC) protocol for a classical client to delegate decision\nproblems in BQP to an untrusted quantum prover under computational assumptions.\nIn this work, we explore further the feasibility of CVQC with the more general\nsampling problems in BQP and with the desirable blindness property. We\ncontribute affirmative solutions to both as follows.\n  (1) Motivated by the sampling nature of many quantum applications (e.g.,\nquantum algorithms for machine learning and quantum supremacy tasks), we\ninitiate the study of CVQC for quantum sampling problems (denoted by SampBQP).\nMore precisely, in a CVQC protocol for a SampBQP problem, the prover and the\nverifier are given an input $x\\in \\{0,1\\}^n$ and a quantum circuit $C$, and the\ngoal of the classical client is to learn a sample from the output $z \\leftarrow\nC(x)$ up to a small error, from its interaction with an untrusted prover. We\ndemonstrate its feasibility by constructing a four-message CVQC protocol for\nSampBQP based on the quantum Learning With Error assumption.\n  (2) The blindness of CVQC protocols refers to a property of the protocol\nwhere the prover learns nothing, and hence is blind, about the client's input.\nIt is a highly desirable property that has been intensively studied for the\ndelegation of quantum computation. We provide a simple yet powerful generic\ncompiler that transforms any CVQC protocol to a blind one while preserving its\ncompleteness and soundness errors as well as the number of rounds.\n  Applying our compiler to (a parallel repetition of) Mahadev's CVQC protocol\nfor BQP and our CVQC protocol for SampBQP yields the first constant-round blind\nCVQC protocol for BQP and SampBQP respectively, with negligible completeness\nand soundness errors.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 03:39:13 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Chung", "Kai-Min", ""], ["Lee", "Yi", ""], ["Lin", "Han-Hsuan", ""], ["Wu", "Xiaodi", ""]]}, {"id": "2012.04864", "submitter": "Haipeng Chen", "authors": "Qi Zhou, Haipeng Chen, Yitao Zheng, Zhen Wang", "title": "EvaLDA: Efficient Evasion Attacks Towards Latent Dirichlet Allocation", "comments": "Accepted for publication at AAAI'2021. 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As one of the most powerful topic models, Latent Dirichlet Allocation (LDA)\nhas been used in a vast range of tasks, including document understanding,\ninformation retrieval and peer-reviewer assignment. Despite its tremendous\npopularity, the security of LDA has rarely been studied. This poses severe\nrisks to security-critical tasks such as sentiment analysis and peer-reviewer\nassignment that are based on LDA. In this paper, we are interested in knowing\nwhether LDA models are vulnerable to adversarial perturbations of benign\ndocument examples during inference time. We formalize the evasion attack to LDA\nmodels as an optimization problem and prove it to be NP-hard. We then propose a\nnovel and efficient algorithm, EvaLDA to solve it. We show the effectiveness of\nEvaLDA via extensive empirical evaluations. For instance, in the NIPS dataset,\nEvaLDA can averagely promote the rank of a target topic from 10 to around 7 by\nonly replacing 1% of the words with similar words in a victim document. Our\nwork provides significant insights into the power and limitations of evasion\nattacks to LDA models.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 04:57:20 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 03:12:53 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Zhou", "Qi", ""], ["Chen", "Haipeng", ""], ["Zheng", "Yitao", ""], ["Wang", "Zhen", ""]]}, {"id": "2012.04884", "submitter": "Jakub Breier", "authors": "Jakub Breier and Adrian Baldwin and Helen Balinsky and Yang Liu", "title": "Risk Management Framework for Machine Learning Security", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks for machine learning models have become a highly studied\ntopic both in academia and industry. These attacks, along with traditional\nsecurity threats, can compromise confidentiality, integrity, and availability\nof organization's assets that are dependent on the usage of machine learning\nmodels. While it is not easy to predict the types of new attacks that might be\ndeveloped over time, it is possible to evaluate the risks connected to using\nmachine learning models and design measures that help in minimizing these\nrisks.\n  In this paper, we outline a novel framework to guide the risk management\nprocess for organizations reliant on machine learning models. First, we define\nsets of evaluation factors (EFs) in the data domain, model domain, and security\ncontrols domain. We develop a method that takes the asset and task importance,\nsets the weights of EFs' contribution to confidentiality, integrity, and\navailability, and based on implementation scores of EFs, it determines the\noverall security state in the organization. Based on this information, it is\npossible to identify weak links in the implemented security measures and find\nout which measures might be missing completely. We believe our framework can\nhelp in addressing the security issues related to usage of machine learning\nmodels in organizations and guide them in focusing on the adequate security\nmeasures to protect their assets.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 06:21:34 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Breier", "Jakub", ""], ["Baldwin", "Adrian", ""], ["Balinsky", "Helen", ""], ["Liu", "Yang", ""]]}, {"id": "2012.05003", "submitter": "Carlos Cilleruelo", "authors": "Carlos Cilleruelo, Luis de-Marcos, Javier Junquera-S\\'anchez and\n  Jos\\'e-Javier Mart\\'inez-Herr\\'aiz", "title": "Interconnection between darknets", "comments": null, "journal-ref": null, "doi": "10.1109/MIC.2020.3037723", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tor and i2p networks are two of the most popular darknets. Both darknets have\nbecome an area of illegal activities highlighting the necessity to study and\nanalyze them to identify and report illegal content to Law Enforcement Agencies\n(LEAs). This paper analyzes the connections between the Tor network and the i2p\nnetwork. We created the first dataset that combines information from Tor and\ni2p networks. The dataset contains more than 49k darknet services. The process\nof building and analyzing the dataset shows that it is not possible to explore\none of the networks without considering the other. Both networks work as an\necosystem and there are clear paths between them. Using graph analysis, we also\nidentified the most relevant domains, the prominent types of services in each\nnetwork, and their relations. Findings are relevant to LEAs and researchers\naiming to crawl and investigate i2p and Tor networks.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 12:30:23 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Cilleruelo", "Carlos", ""], ["de-Marcos", "Luis", ""], ["Junquera-S\u00e1nchez", "Javier", ""], ["Mart\u00ednez-Herr\u00e1iz", "Jos\u00e9-Javier", ""]]}, {"id": "2012.05064", "submitter": "Mayank Rathee", "authors": "Javier Alvarez-Valle, Pratik Bhatu, Nishanth Chandran, Divya Gupta,\n  Aditya Nori, Aseem Rastogi, Mayank Rathee, Rahul Sharma, Shubham Ugare", "title": "Secure Medical Image Analysis with CrypTFlow", "comments": "6 pages. PPML NeurIPS 2020 Workshop, Vancouver, Canada. arXiv admin\n  note: substantial text overlap with arXiv:1909.07814", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present CRYPTFLOW, a system that converts TensorFlow inference code into\nSecure Multi-party Computation (MPC) protocols at the push of a button. To do\nthis, we build two components. Our first component is an end-to-end compiler\nfrom TensorFlow to a variety of MPC protocols. The second component is an\nimproved semi-honest 3-party protocol that provides significant speedups for\ninference. We empirically demonstrate the power of our system by showing the\nsecure inference of real-world neural networks such as DENSENET121 for\ndetection of lung diseases from chest X-ray images and 3D-UNet for segmentation\nin radiotherapy planning using CT images. In particular, this paper provides\nthe first evaluation of secure segmentation of 3D images, a task that requires\nmuch more powerful models than classification and is the largest secure\ninference task run till date.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 14:11:39 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Alvarez-Valle", "Javier", ""], ["Bhatu", "Pratik", ""], ["Chandran", "Nishanth", ""], ["Gupta", "Divya", ""], ["Nori", "Aditya", ""], ["Rastogi", "Aseem", ""], ["Rathee", "Mayank", ""], ["Sharma", "Rahul", ""], ["Ugare", "Shubham", ""]]}, {"id": "2012.05141", "submitter": "Saptarshi Majumder", "authors": "Sanket Shevkar and Parthit Patel and Saptarshi Majumder and Harshita\n  Singh and Kshitijaa Jaglan and Hrithwik Shalu", "title": "EMRs with Blockchain : A distributed democratised Electronic Medical\n  Record sharing platform", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical data sharing needs to be done with the utmost respect for privacy and\nsecurity. It contains intimate data of the patient and any access to it must be\nhighly regulated. With the emergence of vertical solutions in healthcare\ninstitutions, interoperability across organisations has been hindered. The\nauthors of this paper propose a blockchain based medical-data sharing solution,\nutilising Hyperledger Fabric to regulate access to medical data, and using the\nInterPlanatory File System for its storage. We believe that the combination of\nthese two distributed solutions can enable patients to access their medical\nrecords across healthcare institutions while ensuring non-repudiation,\nimmutability and providing data-ownership. It would enable healthcare\npractitioners to access all previous medical records in a single location,\nempowering them with the data required for the effective diagnosis and\ntreatment of patients. Making it safe and straightforward, it would also enable\npatients to share medical data with research institutions, leading to the\ncreation of reliable data sets, laying the groundwork required for the creation\nof personalised medicine.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 16:27:54 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Shevkar", "Sanket", ""], ["Patel", "Parthit", ""], ["Majumder", "Saptarshi", ""], ["Singh", "Harshita", ""], ["Jaglan", "Kshitijaa", ""], ["Shalu", "Hrithwik", ""]]}, {"id": "2012.05291", "submitter": "Usmann Khan", "authors": "Usmann Khan, Lun Wang, Jithendaraa Subramanian, Joseph P. Near, Dawn\n  Song", "title": "PrivFramework: A System for Configurable and Automated Privacy Policy\n  Compliance", "comments": null, "journal-ref": "NeurIPS 2020 Workshop on Dataset Security and Curation", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's massive scale of data collection coupled with recent surges of\nconsumer data leaks has led to increased attention towards data privacy and\nrelated risks. Conventional data privacy protection systems focus on reducing\ncustodial risk and lack features empowering data owners. As an end user there\nare limited options available to specify and enforce one's own privacy\npreferences over their data. To address these concerns we present\nPrivFramework, a user-configurable frame-work for automated privacy policy\ncompliance. PrivFramework allows data owners to write powerful privacy policies\nto protect their data and automatically enforces these policies against\nanalysis programs written in Python. Using static-analysis PrivFramework\nautomatically checks authorized analysis programs for compliance to\nuser-defined policies.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 20:00:48 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Khan", "Usmann", ""], ["Wang", "Lun", ""], ["Subramanian", "Jithendaraa", ""], ["Near", "Joseph P.", ""], ["Song", "Dawn", ""]]}, {"id": "2012.05326", "submitter": "Aur\\'elien Bellet", "authors": "Edwige Cyffers, Aur\\'elien Bellet", "title": "Privacy Amplification by Decentralization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Analyzing data owned by several parties while achieving a good trade-off\nbetween utility and privacy is a key challenge in federated learning and\nanalytics. In this work, we introduce a novel relaxation of local differential\nprivacy (LDP) that naturally arises in fully decentralized protocols, i.e.,\nwhen participants exchange information by communicating along the edges of a\nnetwork graph. This relaxation, that we call network DP, captures the fact that\nusers have only a local view of the decentralized system. To show the relevance\nof network DP, we study a decentralized model of computation where a token\nperforms a walk on the network graph and is updated sequentially by the party\nwho receives it. For tasks such as real summation, histogram computation and\noptimization with gradient descent, we propose simple algorithms on ring and\ncomplete topologies. We prove that the privacy-utility trade-offs of our\nalgorithms significantly improve upon LDP, and in some cases even match what\ncan be achieved with methods based on trusted/secure aggregation and shuffling.\nOur experiments illustrate the superior utility of our approach when training a\nmachine learning model with stochastic gradient descent.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 21:33:33 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 14:33:33 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Cyffers", "Edwige", ""], ["Bellet", "Aur\u00e9lien", ""]]}, {"id": "2012.05403", "submitter": "Abhinav Aggarwal", "authors": "Oluwaseyi Feyisetan, Abhinav Aggarwal, Zekun Xu, Nathanael Teissier", "title": "Research Challenges in Designing Differentially Private Text Generation\n  Mechanisms", "comments": "14 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Accurately learning from user data while ensuring quantifiable privacy\nguarantees provides an opportunity to build better Machine Learning (ML) models\nwhile maintaining user trust. Recent literature has demonstrated the\napplicability of a generalized form of Differential Privacy to provide\nguarantees over text queries. Such mechanisms add privacy preserving noise to\nvectorial representations of text in high dimension and return a text based\nprojection of the noisy vectors. However, these mechanisms are sub-optimal in\ntheir trade-off between privacy and utility. This is due to factors such as a\nfixed global sensitivity which leads to too much noise added in dense spaces\nwhile simultaneously guaranteeing protection for sensitive outliers. In this\nproposal paper, we describe some challenges in balancing the tradeoff between\nprivacy and utility for these differentially private text mechanisms. At a high\nlevel, we provide two proposals: (1) a framework called LAC which defers some\nof the noise to a privacy amplification step and (2), an additional suite of\nthree different techniques for calibrating the noise based on the local region\naround a word. Our objective in this paper is not to evaluate a single solution\nbut to further the conversation on these challenges and chart pathways for\nbuilding better mechanisms.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 01:44:50 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Feyisetan", "Oluwaseyi", ""], ["Aggarwal", "Abhinav", ""], ["Xu", "Zekun", ""], ["Teissier", "Nathanael", ""]]}, {"id": "2012.05433", "submitter": "Beongjun Choi", "authors": "Beongjun Choi, Jy-yong Sohn, Dong-Jun Han and Jaekyun Moon", "title": "Communication-Computation Efficient Secure Aggregation for Federated\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning has been spotlighted as a way to train neural networks\nusing distributed data with no need for individual nodes to share data.\nUnfortunately, it has also been shown that adversaries may be able to extract\nlocal data contents off model parameters transmitted during federated learning.\nA recent solution based on the secure aggregation primitive enabled\nprivacy-preserving federated learning, but at the expense of significant extra\ncommunication/computational resources. In this paper, we propose a\nlow-complexity scheme that provides data privacy using substantially reduced\ncommunication/computational resources relative to the existing secure solution.\nThe key idea behind the suggested scheme is to design the topology of\nsecret-sharing nodes as a sparse random graph instead of the complete graph\ncorresponding to the existing solution. We first obtain the necessary and\nsufficient condition on the graph to guarantee both reliability and privacy. We\nthen suggest using the Erd\\H{o}s-R\\'enyi graph in particular and provide\ntheoretical guarantees on the reliability/privacy of the proposed scheme.\nThrough extensive real-world experiments, we demonstrate that our scheme, using\nonly $20 \\sim 30\\%$ of the resources required in the conventional scheme,\nmaintains virtually the same levels of reliability and data privacy in\npractical federated learning systems.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 03:17:50 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 03:15:44 GMT"}, {"version": "v3", "created": "Mon, 12 Jul 2021 14:08:24 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Choi", "Beongjun", ""], ["Sohn", "Jy-yong", ""], ["Han", "Dong-Jun", ""], ["Moon", "Jaekyun", ""]]}, {"id": "2012.05434", "submitter": "YueFeng Chen", "authors": "Xiaofeng Mao, Yuefeng Chen, Shuhui Wang, Hang Su, Yuan He, Hui Xue", "title": "Composite Adversarial Attacks", "comments": "To appear in AAAI 2021, code will be released later", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attack is a technique for deceiving Machine Learning (ML) models,\nwhich provides a way to evaluate the adversarial robustness. In practice,\nattack algorithms are artificially selected and tuned by human experts to break\na ML system. However, manual selection of attackers tends to be sub-optimal,\nleading to a mistakenly assessment of model security. In this paper, a new\nprocedure called Composite Adversarial Attack (CAA) is proposed for\nautomatically searching the best combination of attack algorithms and their\nhyper-parameters from a candidate pool of \\textbf{32 base attackers}. We design\na search space where attack policy is represented as an attacking sequence,\ni.e., the output of the previous attacker is used as the initialization input\nfor successors. Multi-objective NSGA-II genetic algorithm is adopted for\nfinding the strongest attack policy with minimum complexity. The experimental\nresult shows CAA beats 10 top attackers on 11 diverse defenses with less\nelapsed time (\\textbf{6 $\\times$ faster than AutoAttack}), and achieves the new\nstate-of-the-art on $l_{\\infty}$, $l_{2}$ and unrestricted adversarial attacks.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 03:21:16 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Mao", "Xiaofeng", ""], ["Chen", "Yuefeng", ""], ["Wang", "Shuhui", ""], ["Su", "Hang", ""], ["He", "Yuan", ""], ["Xue", "Hui", ""]]}, {"id": "2012.05471", "submitter": "Vitaly Cheptsov", "authors": "Marvin H\\\"auser, Vitaly Cheptsov", "title": "Securing the EDK II Image Loader", "comments": "10 pages, 2 tables", "journal-ref": "2020 Ivannikov Ispras Open Conference (ISPRAS), 2020, pp. 16-25", "doi": "10.1109/ISPRAS51486.2020.00010", "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Unified Extensible Firmware Interface (UEFI) is a standardised interface\nbetween the firmware and the operating system used in all x86-based platforms\nover the past ten years, which continues to spread to other architectures such\nas ARM and RISC-V. The UEFI incorporates a modular design based on images\ncontaining a driver or an application in a Common Object File Format (COFF)\neither as a Portable Executable (PE) or as a Terse Executable (TE). The\nde-facto standard generic UEFI services implementation, including the image\nloading functionality, is TianoCore EDK II. Its track of security issues shows\nnumerous design and implementation flaws some of which are yet to be addressed.\nIn this paper we outline both the requirements for a secure UEFI Image Loader\nand the issues of the existing implementation. As an alternative we propose a\nformally verified Image Loader supporting both PE and TE images with\nfine-grained hardening enabling a seamless integration with EDK II and\nsubsequently with the other firmwares.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 06:21:44 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 10:57:49 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["H\u00e4user", "Marvin", ""], ["Cheptsov", "Vitaly", ""]]}, {"id": "2012.05516", "submitter": "Balaji Ganesan", "authors": "Balaji Ganesan, Hima Patel, Sameep Mehta", "title": "Explainable Link Prediction for Privacy-Preserving Contact Tracing", "comments": "8 pages, 7 figures, SpicyFL 2020 Workshop at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contact Tracing has been used to identify people who were in close proximity\nto those infected with SARS-Cov2 coronavirus. A number of digital contract\ntracing applications have been introduced to facilitate or complement physical\ncontact tracing. However, there are a number of privacy issues in the\nimplementation of contract tracing applications, which make people reluctant to\ninstall or update their infection status on these applications. In this concept\npaper, we present ideas from Graph Neural Networks and explainability, that\ncould improve trust in these applications, and encourage adoption by people.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 08:58:24 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Ganesan", "Balaji", ""], ["Patel", "Hima", ""], ["Mehta", "Sameep", ""]]}, {"id": "2012.05685", "submitter": "Bogdan Georgiev", "authors": "David Biesner, Kostadin Cvejoski, Bogdan Georgiev, Rafet Sifa, Erik\n  Krupicka", "title": "Generative Deep Learning Techniques for Password Generation", "comments": "25 pages, 13 figures. Comments welcome!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Password guessing approaches via deep learning have recently been\ninvestigated with significant breakthroughs in their ability to generate novel,\nrealistic password candidates. In the present work we study a broad collection\nof deep learning and probabilistic based models in the light of password\nguessing: attention-based deep neural networks, autoencoding mechanisms and\ngenerative adversarial networks. We provide novel generative deep-learning\nmodels in terms of variational autoencoders exhibiting state-of-art sampling\nperformance, yielding additional latent-space features such as interpolations\nand targeted sampling. Lastly, we perform a thorough empirical analysis in a\nunified controlled framework over well-known datasets (RockYou, LinkedIn,\nYouku, Zomato, Pwnd). Our results not only identify the most promising schemes\ndriven by deep neural networks, but also illustrate the strengths of each\napproach in terms of generation variability and sample uniqueness.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 14:11:45 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 20:43:19 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Biesner", "David", ""], ["Cvejoski", "Kostadin", ""], ["Georgiev", "Bogdan", ""], ["Sifa", "Rafet", ""], ["Krupicka", "Erik", ""]]}, {"id": "2012.05749", "submitter": "Yunang Chen", "authors": "Yunang Chen, Amrita Roy Chowdhury, Ruizhe Wang, Andrei Sabelfeld,\n  Rahul Chatterjee, Earlence Fernandes", "title": "Data Privacy in Trigger-Action Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Trigger-action platforms (TAPs) allow users to connect independent web-based\nor IoT services to achieve useful automation. They provide a simple interface\nthat helps end-users create trigger-compute-action rules that pass data between\ndisparate Internet services. Unfortunately, TAPs introduce a large-scale\nsecurity risk: if they are compromised, attackers will gain access to sensitive\ndata for millions of users. To avoid this risk, we propose eTAP, a\nprivacy-enhancing trigger-action platform that executes trigger-compute-action\nrules without accessing users' private data in plaintext or learning anything\nabout the results of the computation. We use garbled circuits as a primitive,\nand leverage the unique structure of trigger-compute-action rules to make them\npractical. We formally state and prove the security guarantees of our\nprotocols. We prototyped eTAP, which supports the most commonly used operations\non popular commercial TAPs like IFTTT and Zapier. Specifically, it supports\nBoolean, arithmetic, and string operations on private trigger data and can run\n100% of the top-500 rules of IFTTT users and 93.4% of all publicly-available\nrules on Zapier. Based on ten existing rules that exercise a wide variety of\noperations, we show that eTAP has a modest performance impact: on average rule\nexecution latency increases by 70 ms (55%) and throughput reduces by 59%.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 15:35:03 GMT"}, {"version": "v2", "created": "Sun, 28 Mar 2021 11:58:37 GMT"}, {"version": "v3", "created": "Mon, 24 May 2021 21:33:24 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Chen", "Yunang", ""], ["Chowdhury", "Amrita Roy", ""], ["Wang", "Ruizhe", ""], ["Sabelfeld", "Andrei", ""], ["Chatterjee", "Rahul", ""], ["Fernandes", "Earlence", ""]]}, {"id": "2012.05867", "submitter": "Shaanan Cohney", "authors": "Shaanan Cohney, Ross Teixeira, Anne Kohlbrenner, Arvind Narayanan,\n  Mihir Kshirsagar, Yan Shvartzshnaider, Madelyn Sanfilippo", "title": "Virtual Classrooms and Real Harms: Remote Learning at U.S. Universities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Universities have been forced to rely on remote educational technology to\nfacilitate the rapid shift to online learning. In doing so, they acquire new\nrisks of security vulnerabilities and privacy violations. To help universities\nnavigate this landscape, we develop a model that describes the actors,\nincentives, and risks, informed by surveying 49 educators and 14 administrators\nat U.S. universities. Next, we develop a methodology for administrators to\nassess security and privacy risks of these products. We then conduct a privacy\nand security analysis of 23 popular platforms using a combination of\nsociological analyses of privacy policies and 129 state laws, alongside a\ntechnical assessment of platform software. Based on our findings, we develop\nrecommendations for universities to mitigate the risks to their stakeholders.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 18:25:09 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2021 10:31:47 GMT"}, {"version": "v3", "created": "Wed, 16 Jun 2021 01:56:02 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Cohney", "Shaanan", ""], ["Teixeira", "Ross", ""], ["Kohlbrenner", "Anne", ""], ["Narayanan", "Arvind", ""], ["Kshirsagar", "Mihir", ""], ["Shvartzshnaider", "Yan", ""], ["Sanfilippo", "Madelyn", ""]]}, {"id": "2012.05948", "submitter": "Lilas Alrahis", "authors": "Lilas Alrahis, Satwik Patnaik, Faiq Khalid, Muhammad Abdullah Hanif,\n  Hani Saleh, Muhammad Shafique, and Ozgur Sinanoglu", "title": "GNNUnlock: Graph Neural Networks-based Oracle-less Unlocking Scheme for\n  Provably Secure Logic Locking", "comments": "6 pages, 4 figures, 6 tables, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose GNNUnlock, the first-of-its-kind oracle-less\nmachine learning-based attack on provably secure logic locking that can\nidentify any desired protection logic without focusing on a specific syntactic\ntopology. The key is to leverage a well-trained graph neural network (GNN) to\nidentify all the gates in a given locked netlist that belong to the targeted\nprotection logic, without requiring an oracle. This approach fits perfectly\nwith the targeted problem since a circuit is a graph with an inherent structure\nand the protection logic is a sub-graph of nodes (gates) with specific and\ncommon characteristics. GNNs are powerful in capturing the nodes' neighborhood\nproperties, facilitating the detection of the protection logic. To rectify any\nmisclassifications induced by the GNN, we additionally propose a connectivity\nanalysis-based post-processing algorithm to successfully remove the predicted\nprotection logic, thereby retrieving the original design. Our extensive\nexperimental evaluation demonstrates that GNNUnlock is 99.24%-100% successful\nin breaking various benchmarks locked using stripped-functionality logic\nlocking, tenacious and traceless logic locking, and Anti-SAT. Our proposed\npost-processing enhances the detection accuracy, reaching 100% for all of our\ntested locked benchmarks. Analysis of the results corroborates that GNNUnlock\nis powerful enough to break the considered schemes under different parameters,\nsynthesis settings, and technology nodes. The evaluation further shows that\nGNNUnlock successfully breaks corner cases where even the most advanced\nstate-of-the-art attacks fail.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 20:07:28 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Alrahis", "Lilas", ""], ["Patnaik", "Satwik", ""], ["Khalid", "Faiq", ""], ["Hanif", "Muhammad Abdullah", ""], ["Saleh", "Hani", ""], ["Shafique", "Muhammad", ""], ["Sinanoglu", "Ozgur", ""]]}, {"id": "2012.06024", "submitter": "Kenneth Co", "authors": "Alberto G. Matachana, Kenneth T. Co, Luis Mu\\~noz-Gonz\\'alez, David\n  Martinez, Emil C. Lupu", "title": "Robustness and Transferability of Universal Attacks on Compressed Models", "comments": "Accepted to AAAI 2021 Workshop: Towards Robust, Secure and Efficient\n  Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural network compression methods like pruning and quantization are very\neffective at efficiently deploying Deep Neural Networks (DNNs) on edge devices.\nHowever, DNNs remain vulnerable to adversarial examples-inconspicuous inputs\nthat are specifically designed to fool these models. In particular, Universal\nAdversarial Perturbations (UAPs), are a powerful class of adversarial attacks\nwhich create adversarial perturbations that can generalize across a large set\nof inputs. In this work, we analyze the effect of various compression\ntechniques to UAP attacks, including different forms of pruning and\nquantization. We test the robustness of compressed models to white-box and\ntransfer attacks, comparing them with their uncompressed counterparts on\nCIFAR-10 and SVHN datasets. Our evaluations reveal clear differences between\npruning methods, including Soft Filter and Post-training Pruning. We observe\nthat UAP transfer attacks between pruned and full models are limited,\nsuggesting that the systemic vulnerabilities across these models are different.\nThis finding has practical implications as using different compression\ntechniques can blunt the effectiveness of black-box transfer attacks. We show\nthat, in some scenarios, quantization can produce gradient-masking, giving a\nfalse sense of security. Finally, our results suggest that conclusions about\nthe robustness of compressed models to UAP attacks is application dependent,\nobserving different phenomena in the two datasets used in our experiments.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 23:40:23 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Matachana", "Alberto G.", ""], ["Co", "Kenneth T.", ""], ["Mu\u00f1oz-Gonz\u00e1lez", "Luis", ""], ["Martinez", "David", ""], ["Lupu", "Emil C.", ""]]}, {"id": "2012.06122", "submitter": "Ramtin Hosseini", "authors": "Ramtin Hosseini, Xingyi Yang and Pengtao Xie", "title": "DSRNA: Differentiable Search of Robust Neural Architectures", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In deep learning applications, the architectures of deep neural networks are\ncrucial in achieving high accuracy. Many methods have been proposed to search\nfor high-performance neural architectures automatically. However, these\nsearched architectures are prone to adversarial attacks. A small perturbation\nof the input data can render the architecture to change prediction outcomes\nsignificantly. To address this problem, we propose methods to perform\ndifferentiable search of robust neural architectures. In our methods, two\ndifferentiable metrics are defined to measure architectures' robustness, based\non certified lower bound and Jacobian norm bound. Then we search for robust\narchitectures by maximizing the robustness metrics. Different from previous\napproaches which aim to improve architectures' robustness in an implicit way:\nperforming adversarial training and injecting random noise, our methods\nexplicitly and directly maximize robustness metrics to harvest robust\narchitectures. On CIFAR-10, ImageNet, and MNIST, we perform game-based\nevaluation and verification-based evaluation on the robustness of our methods.\nThe experimental results show that our methods 1) are more robust to various\nnorm-bound attacks than several robust NAS baselines; 2) are more accurate than\nbaselines when there are no attacks; 3) have significantly higher certified\nlower bounds than baselines.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 04:52:54 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Hosseini", "Ramtin", ""], ["Yang", "Xingyi", ""], ["Xie", "Pengtao", ""]]}, {"id": "2012.06128", "submitter": "Qin Wang", "authors": "Qin Wang, Jiangshan Yu, Shiping Chen, Yang Xiang", "title": "SoK: Diving into DAG-based Blockchain Systems", "comments": "Full version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blockchain plays an important role in cryptocurrency markets and technology\nservices. However, limitations on high latency and low scalability retard their\nadoptions and applications in classic designs. Reconstructed blockchain systems\nhave been proposed to avoid the consumption of competitive transactions caused\nby linear sequenced blocks. These systems, instead, structure\ntransactions/blocks in the form of Directed Acyclic Graph (DAG) and\nconsequently re-build upper layer components including consensus, incentives,\n\\textit{etc.} The promise of DAG-based blockchain systems is to enable fast\nconfirmation (complete transactions within million seconds) and high\nscalability (attach transactions in parallel) without significantly\ncompromising security. However, this field still lacks systematic work that\nsummarises the DAG technique. To bridge the gap, this Systematization of\nKnowledge (SoK) provides a comprehensive analysis of DAG-based blockchain\nsystems. Through deconstructing open-sourced systems and reviewing academic\nresearches, we conclude the main components and featured properties of systems,\nand provide the approach to establish a DAG. With this in hand, we analyze the\nsecurity and performance of several leading systems, followed by discussions\nand comparisons with concurrent (scaling blockchain) techniques. We further\nidentify open challenges to highlight the potentiality of DAG-based solutions\nand indicate their promising directions for future research.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 05:13:18 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 02:11:31 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Wang", "Qin", ""], ["Yu", "Jiangshan", ""], ["Chen", "Shiping", ""], ["Xiang", "Yang", ""]]}, {"id": "2012.06150", "submitter": "Jack Li", "authors": "J. Li, L. Lyu, X. Liu, X. Zhang, and X. Lyu", "title": "FLEAM: A Federated Learning Empowered Architecture to Mitigate DDoS in\n  Industrial IoT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The distributed denial of service (DDoS) attack is detrimental to the\nindustrial Internet of things (IIoT) as it triggers severe resource starvation\non networked objects. Recent dynamics demonstrate that it is a highly\nprofitable business for attackers using botnets. Current centralized mitigation\nsolutions concentrate on detection and mitigation at a victim's side, paying\ninadequate attention to hacking costs and the collaboration of defenders. Thus,\nwe propose the federated learning empowered mitigation architecture (FLEAM) to\nadvocate joint defense, incurring a higher hacking expense. FLEAM combines FL\nand fog computing to reduce mitigation time and improve detection accuracy,\nenabling defenders to jointly combatting botnets. Our comprehensive evaluations\nshowcase that the attacking expense incurred is 2.5 times higher, the\nmitigation delay is about 72% lower, and the accuracy is 47% greater on average\nthan classic solutions.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 06:22:15 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Li", "J.", ""], ["Lyu", "L.", ""], ["Liu", "X.", ""], ["Zhang", "X.", ""], ["Lyu", "X.", ""]]}, {"id": "2012.06300", "submitter": "Lo\\\"ic Miller", "authors": "Lo\\\"ic Miller, Pascal M\\'erindol, Antoine Gallais, Cristel Pelsser", "title": "Towards Secure and Leak-Free Workflows Using Microservice Isolation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data leaks and breaches are on the rise. They result in huge losses of money\nfor businesses like the movie industry, as well as a loss of user privacy for\nbusinesses dealing with user data like the pharmaceutical industry. Preventing\ndata exposures is challenging, because the causes for such events are various,\nranging from hacking to misconfigured databases. Alongside the surge in data\nexposures, the recent rise of microservices as a paradigm brings the need to\nnot only secure traffic at the border of the network, but also internally,\npressing the adoption of new security models such as zero-trust to secure\nbusiness processes.\n  Business processes can be modeled as workflows, where the owner of the data\nat risk interacts with contractors to realize a sequence of tasks on this data.\nIn this paper, we show how those workflows can be enforced while preventing\ndata exposure. Following the principles of zero-trust, we develop an\ninfrastructure using the isolation provided by a microservice architecture, to\nenforce owner policy. We show that our infrastructure is resilient to the set\nof attacks considered in our security model. We implement a simple, yet\nrealistic, workflow with our infrastructure in a publicly available proof of\nconcept. We then verify that the specified policy is correctly enforced by\ntesting the deployment for policy violations, and estimate the overhead cost of\nauthorization.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 13:11:20 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Miller", "Lo\u00efc", ""], ["M\u00e9rindol", "Pascal", ""], ["Gallais", "Antoine", ""], ["Pelsser", "Cristel", ""]]}, {"id": "2012.06330", "submitter": "Yi Xiang Marcus Tan", "authors": "Yi Xiang Marcus Tan, Penny Chong, Jiamei Sun, Ngai-Man Cheung, Yuval\n  Elovici, Alexander Binder", "title": "Detection of Adversarial Supports in Few-shot Classifiers Using\n  Self-Similarity and Filtering", "comments": "Accepted in the International Workshop on Safety and Security of Deep\n  Learning 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot classifiers excel under limited training samples, making them useful\nin applications with sparsely user-provided labels. Their unique relative\nprediction setup offers opportunities for novel attacks, such as targeting\nsupport sets required to categorise unseen test samples, which are not\navailable in other machine learning setups. In this work, we propose a\ndetection strategy to identify adversarial support sets, aimed at destroying\nthe understanding of a few-shot classifier for a certain class. We achieve this\nby introducing the concept of self-similarity of a support set and by employing\nfiltering of supports. Our method is attack-agnostic, and we are the first to\nexplore adversarial detection for support sets of few-shot classifiers to the\nbest of our knowledge. Our evaluation of the miniImagenet (MI) and CUB datasets\nexhibits good attack detection performance despite conceptual simplicity,\nshowing high AUROC scores. We show that self-similarity and filtering for\nadversarial detection can be paired with other filtering functions,\nconstituting a generalisable concept.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 14:13:41 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 14:52:14 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Tan", "Yi Xiang Marcus", ""], ["Chong", "Penny", ""], ["Sun", "Jiamei", ""], ["Cheung", "Ngai-Man", ""], ["Elovici", "Yuval", ""], ["Binder", "Alexander", ""]]}, {"id": "2012.06332", "submitter": "Ayush Goel", "authors": "Ayush Goel", "title": "An Empirical Review of Adversarial Defenses", "comments": "19 pages, 8 Figures, Report Reviewed by Vivek Menon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  From face recognition systems installed in phones to self-driving cars, the\nfield of AI is witnessing rapid transformations and is being integrated into\nour everyday lives at an incredible pace. Any major failure in these system's\npredictions could be devastating, leaking sensitive information or even costing\nlives (as in the case of self-driving cars). However, deep neural networks,\nwhich form the basis of such systems, are highly susceptible to a specific type\nof attack, called adversarial attacks. A hacker can, even with bare minimum\ncomputation, generate adversarial examples (images or data points that belong\nto another class, but consistently fool the model to get misclassified as\ngenuine) and crumble the basis of such algorithms. In this paper, we compile\nand test numerous approaches to defend against such adversarial attacks. Out of\nthe ones explored, we found two effective techniques, namely Dropout and\nDenoising Autoencoders, and show their success in preventing such attacks from\nfooling the model. We demonstrate that these techniques are also resistant to\nboth higher noise levels as well as different kinds of adversarial attacks\n(although not tested against all). We also develop a framework for deciding the\nsuitable defense technique to use against attacks, based on the nature of the\napplication and resource constraints of the Deep Neural Network.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 09:34:41 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Goel", "Ayush", ""]]}, {"id": "2012.06337", "submitter": "Han Yu", "authors": "Lingjuan Lyu, Han Yu, Xingjun Ma, Lichao Sun, Jun Zhao, Qiang Yang,\n  Philip S. Yu", "title": "Privacy and Robustness in Federated Learning: Attacks and Defenses", "comments": "arXiv admin note: text overlap with arXiv:2003.02133; text overlap\n  with arXiv:1911.11815 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As data are increasingly being stored in different silos and societies\nbecoming more aware of data privacy issues, the traditional centralized\ntraining of artificial intelligence (AI) models is facing efficiency and\nprivacy challenges. Recently, federated learning (FL) has emerged as an\nalternative solution and continue to thrive in this new reality. Existing FL\nprotocol design has been shown to be vulnerable to adversaries within or\noutside of the system, compromising data privacy and system robustness. Besides\ntraining powerful global models, it is of paramount importance to design FL\nsystems that have privacy guarantees and are resistant to different types of\nadversaries. In this paper, we conduct the first comprehensive survey on this\ntopic. Through a concise introduction to the concept of FL, and a unique\ntaxonomy covering: 1) threat models; 2) poisoning attacks and defenses against\nrobustness; 3) inference attacks and defenses against privacy, we provide an\naccessible review of this important topic. We highlight the intuitions, key\ntechniques as well as fundamental assumptions adopted by various attacks and\ndefenses. Finally, we discuss promising future research directions towards\nrobust and privacy-preserving federated learning.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 12:11:45 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Lyu", "Lingjuan", ""], ["Yu", "Han", ""], ["Ma", "Xingjun", ""], ["Sun", "Lichao", ""], ["Zhao", "Jun", ""], ["Yang", "Qiang", ""], ["Yu", "Philip S.", ""]]}, {"id": "2012.06340", "submitter": "Kenny Zhuo Ming Lu", "authors": "Kenny Zhuo Ming Lu", "title": "Control Flow Obfuscation for FJ using Continuation Passing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Control flow obfuscation deters software reverse engineering attempts by\naltering the program's control flow transfer. The alternation should not affect\nthe software's run-time behaviour. In this paper, we propose a control flow\nobfuscation approach for FJ with exception handling. The approach is based on a\nsource to source transformation using continuation passing style (CPS). We\nargue that the proposed CPS transformation causes malicious attacks using\ncontext insensitive static analysis and context sensitive analysis with fixed\ncall string to lose precision.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 06:41:52 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 04:34:52 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Lu", "Kenny Zhuo Ming", ""]]}, {"id": "2012.06354", "submitter": "Alexander Ziller", "authors": "Alexander Ziller, Jonathan Passerat-Palmbach, Th\\'eo Ryffel, Dmitrii\n  Usynin, Andrew Trask, Ion\\'esio Da Lima Costa Junior, Jason Mancuso, Marcus\n  Makowski, Daniel Rueckert, Rickmer Braren, Georgios Kaissis", "title": "Privacy-preserving medical image analysis", "comments": "Accepted at the workshop for Medical Imaging meets NeurIPS, 34th\n  Conference on Neural Information Processing Systems (NeurIPS) December 11,\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The utilisation of artificial intelligence in medicine and healthcare has led\nto successful clinical applications in several domains. The conflict between\ndata usage and privacy protection requirements in such systems must be resolved\nfor optimal results as well as ethical and legal compliance. This calls for\ninnovative solutions such as privacy-preserving machine learning (PPML). We\npresent PriMIA (Privacy-preserving Medical Image Analysis), a software\nframework designed for PPML in medical imaging. In a real-life case study we\ndemonstrate significantly better classification performance of a securely\naggregated federated learning model compared to human experts on unseen\ndatasets. Furthermore, we show an inference-as-a-service scenario for\nend-to-end encrypted diagnosis, where neither the data nor the model are\nrevealed. Lastly, we empirically evaluate the framework's security against a\ngradient-based model inversion attack and demonstrate that no usable\ninformation can be recovered from the model.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 13:56:00 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Ziller", "Alexander", ""], ["Passerat-Palmbach", "Jonathan", ""], ["Ryffel", "Th\u00e9o", ""], ["Usynin", "Dmitrii", ""], ["Trask", "Andrew", ""], ["Junior", "Ion\u00e9sio Da Lima Costa", ""], ["Mancuso", "Jason", ""], ["Makowski", "Marcus", ""], ["Rueckert", "Daniel", ""], ["Braren", "Rickmer", ""], ["Kaissis", "Georgios", ""]]}, {"id": "2012.06405", "submitter": "Nathan Drenkow", "authors": "Nathan Drenkow, Neil Fendley, Philippe Burlina", "title": "Random Projections for Adversarial Attack Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whilst adversarial attack detection has received considerable attention, it\nremains a fundamentally challenging problem from two perspectives. First, while\nthreat models can be well-defined, attacker strategies may still vary widely\nwithin those constraints. Therefore, detection should be considered as an\nopen-set problem, standing in contrast to most current detection strategies.\nThese methods take a closed-set view and train binary detectors, thus biasing\ndetection toward attacks seen during detector training. Second, information is\nlimited at test time and confounded by nuisance factors including the label and\nunderlying content of the image. Many of the current high-performing techniques\nuse training sets for dealing with some of these issues, but can be limited by\nthe overall size and diversity of those sets during the detection step. We\naddress these challenges via a novel strategy based on random subspace\nanalysis. We present a technique that makes use of special properties of random\nprojections, whereby we can characterize the behavior of clean and adversarial\nexamples across a diverse set of subspaces. We then leverage the\nself-consistency (or inconsistency) of model activations to discern clean from\nadversarial examples. Performance evaluation demonstrates that our technique\noutperforms ($>0.92$ AUC) competing state of the art (SOTA) attack strategies,\nwhile remaining truly agnostic to the attack method itself. It also requires\nsignificantly less training data, composed only of clean examples, when\ncompared to competing SOTA methods, which achieve only chance performance, when\nevaluated in a more rigorous testing scenario.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 15:02:28 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Drenkow", "Nathan", ""], ["Fendley", "Neil", ""], ["Burlina", "Philippe", ""]]}, {"id": "2012.06502", "submitter": "Mohammad Mannan", "authors": "S. Ali, M. Elgharabawy, Q. Duchaussoy, M. Mannan, A. Youssef", "title": "Betrayed by the Guardian: Security and Privacy Risks of Parental Control\n  Solutions", "comments": null, "journal-ref": "Published at ACSAC 2020", "doi": "10.1145/3427228.3427287", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For parents of young children and adolescents, the digital age has introduced\nmany new challenges, including excessive screen time, inappropriate online\ncontent, cyber predators, and cyberbullying. To address these challenges, many\nparents rely on numerous parental control solutions on different platforms,\nincluding parental control network devices (e.g., WiFi routers) and software\napplications on mobile devices and laptops. While these parental control\nsolutions may help digital parenting, they may also introduce serious security\nand privacy risks to children and parents, due to their elevated privileges and\nhaving access to a significant amount of privacy-sensitive data. In this paper,\nwe present an experimental framework for systematically evaluating security and\nprivacy issues in parental control software and hardware solutions. Using the\ndeveloped framework, we provide the first comprehensive study of parental\ncontrol tools on multiple platforms including network devices, Windows\napplications, Chrome extensions and Android apps. Our analysis uncovers\npervasive security and privacy issues that can lead to leakage of private\ninformation, and/or allow an adversary to fully control the parental control\nsolution, and thereby may directly aid cyberbullying and cyber predators.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 17:06:00 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Ali", "S.", ""], ["Elgharabawy", "M.", ""], ["Duchaussoy", "Q.", ""], ["Mannan", "M.", ""], ["Youssef", "A.", ""]]}, {"id": "2012.06554", "submitter": "Do Le Quoc", "authors": "Robert Krahn and Donald Dragoti and Franz Gregor and Do Le Quoc and\n  Valerio Schiavoni and Pascal Felber and Clenimar Souza and Andrey Brito and\n  Christof Fetzer", "title": "TEEMon: A continuous performance monitoring framework for TEEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Trusted Execution Environments (TEEs), such as Intel Software Guard\neXtensions (SGX), are considered as a promising approach to resolve security\nchallenges in clouds. TEEs protect the confidentiality and integrity of\napplication code and data even against privileged attackers with root and\nphysical access by providing an isolated secure memory area, i.e., enclaves.\nThe security guarantees are provided by the CPU, thus even if system software\nis compromised, the attacker can never access the enclave's content. While this\napproach ensures strong security guarantees for applications, it also\nintroduces a considerable runtime overhead in part by the limited availability\nof protected memory (enclave page cache). Currently, only a limited number of\nperformance measurement tools for TEE-based applications exist and none offer\nperformance monitoring and analysis during runtime.\n  This paper presents TEEMon, the first continuous performance monitoring and\nanalysis tool for TEE-based applications. TEEMon provides not only fine-grained\nperformance metrics during runtime, but also assists the analysis of\nidentifying causes of performance bottlenecks, e.g., excessive system calls.\nOur approach smoothly integrates with existing open-source tools (e.g.,\nPrometheus or Grafana) towards a holistic monitoring solution, particularly\noptimized for systems deployed through Docker containers or Kubernetes and\noffers several dedicated metrics and visualizations. Our evaluation shows that\nTEEMon's overhead ranges from 5% to 17%.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 18:33:23 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Krahn", "Robert", ""], ["Dragoti", "Donald", ""], ["Gregor", "Franz", ""], ["Quoc", "Do Le", ""], ["Schiavoni", "Valerio", ""], ["Felber", "Pascal", ""], ["Souza", "Clenimar", ""], ["Brito", "Andrey", ""], ["Fetzer", "Christof", ""]]}, {"id": "2012.06609", "submitter": "James Holland", "authors": "James K Holland and Nicholas Hopper", "title": "RegulaTor: A Straightforward Website Fingerprinting Defense", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Website Fingerprinting (WF) attacks are used by local passive attackers to\ndetermine the destination of encrypted internet traffic by comparing the\nsequences of packets sent to and received by the user to a previously recorded\ndata set. As a result, WF attacks are of particular concern to\nprivacy-enhancing technologies such as Tor. In response, a variety of WF\ndefenses have been developed, though they tend to incur high bandwidth and\nlatency overhead or require additional infrastructure, thus making them\ndifficult to implement in practice. Some lighter-weight defenses have been\npresented as well; still, they attain only moderate effectiveness against\nrecently published WF attacks. In this paper, we aim to present a realistic and\nnovel defense, RegulaTor, which takes advantage of common patterns in web\nbrowsing traffic to reduce both defense overhead and the accuracy of current WF\nattacks. In the closed-world setting, RegulaTor reduces the accuracy of the\nstate-of-the-art attack, Tik-Tok, against comparable defenses from 66% to\n25.4%. To achieve this performance, it requires limited added latency and a\nbandwidth overhead 39.1% less than the leading moderate-overhead defense. In\nthe open-world setting, RegulaTor limits a precision-tuned Tik-Tok attack to an\nF-score of .135, compared to .625 for the best comparable defense.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 19:31:22 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 01:02:31 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Holland", "James K", ""], ["Hopper", "Nicholas", ""]]}, {"id": "2012.06658", "submitter": "Pietro Borrello", "authors": "Pietro Borrello, Emilio Coppa, Daniele Cono D'Elia", "title": "Hiding in the Particles: When Return-Oriented Programming Meets Program\n  Obfuscation", "comments": "Published in the proceedings of DSN'21 (51st IEEE/IFIP Int. Conf. on\n  Dependable Systems and Networks). Code and BibTeX entry available at\n  https://github.com/pietroborrello/raindrop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Largely known for attack scenarios, code reuse techniques at a closer look\nreveal properties that are appealing also for program obfuscation. We explore\nthe popular return-oriented programming paradigm under this light, transforming\nprogram functions into ROP chains that coexist seamlessly with the surrounding\nsoftware stack. We show how to build chains that can withstand popular static\nand dynamic deobfuscation approaches, evaluating the robustness and overheads\nof the design over common programs. The results suggest a significant amount of\ncomputational resources would be required to carry a deobfuscation attack for\nsecret finding and code coverage goals.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 22:01:23 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 15:28:37 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Borrello", "Pietro", ""], ["Coppa", "Emilio", ""], ["D'Elia", "Daniele Cono", ""]]}, {"id": "2012.06666", "submitter": "Mohammad Khodaei", "authors": "Mohammad Khodaei and Panos Papadimitratos", "title": "Cooperative Location Privacy in Vehicular Networks: Why Simple Mix-zones\n  are not Enough", "comments": "19 pages, 15 Figures, IEEE Internet of Things Journal", "journal-ref": "IEEE Internet of Things Journal, 2021", "doi": "10.1109/JIOT.2020.3043640", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicular communications disclose rich information about the vehicles and\ntheir whereabouts. Pseudonymous authentication secures communication while\nenhancing user privacy. To enhance location privacy, cryptographic mix-zones\nwere proposed to facilitate vehicles covertly transition to new ephemeral\ncredentials. The resilience to (syntactic and semantic) pseudonym linking\n(attacks) highly depends on the geometry of the mix-zones, mobility patterns,\nvehicle density, and arrival rates. We introduce a tracking algorithm for\nlinking pseudonyms before and after a cryptographically protected mix-zone. Our\nexperimental results show that an eavesdropper, leveraging standardized\nvehicular communication messages and road layout, could successfully link 73%\nof pseudonyms during non-rush hours and 62% of pseudonyms during rush hours\nafter vehicles change their pseudonyms in a mix-zone. To mitigate such\ninference attacks, we present a novel cooperative mix-zone scheme that enhances\nuser privacy regardless of the vehicle mobility patterns, vehicle density, and\narrival rate to the mix-zone. A subset of vehicles, termed relaying vehicles,\nare selected to be responsible for emulating non-existing vehicles. Such\nvehicles cooperatively disseminate decoy traffic without affecting\nsafety-critical operations: with 50% of vehicles as relaying vehicles, the\nprobability of linking pseudonyms (for the entire interval) drops from 68% to\n18%. On average, this imposes 28 ms extra computation overhead, per second, on\nthe Roadside Units (RSUs) and 4.67 ms extra computation overhead, per second,\non the (relaying) vehicle side; it also introduces 1.46 KB/sec extra\ncommunication overhead by (relaying) vehicles and 45 KB/sec by RSUs for the\ndissemination of decoy traffic. Thus, user privacy is enhanced at the cost of\nlow computation and communication overhead.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 22:37:22 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Khodaei", "Mohammad", ""], ["Papadimitratos", "Panos", ""]]}, {"id": "2012.06761", "submitter": "Pascal Nasahl", "authors": "Pascal Nasahl, Robert Schilling, Mario Werner, Jan Hoogerbrugge,\n  Marcel Medwed, Stefan Mangard", "title": "CrypTag: Thwarting Physical and Logical Memory Vulnerabilities using\n  Cryptographically Colored Memory", "comments": null, "journal-ref": null, "doi": "10.1145/3433210.3453684", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory vulnerabilities are a major threat to many computing systems. To\neffectively thwart spatial and temporal memory vulnerabilities, full logical\nmemory safety is required. However, current mitigation techniques for memory\nsafety are either too expensive or trade security against efficiency. One\npromising attempt to detect memory safety vulnerabilities in hardware is memory\ncoloring, a security policy deployed on top of tagged memory architectures.\nHowever, due to the memory storage and bandwidth overhead of large tags,\ncommodity tagged memory architectures usually only provide small tag sizes,\nthus limiting their use for security applications. Irrespective of logical\nmemory safety, physical memory safety is a necessity in hostile environments\nprevalent for modern cloud computing and IoT devices. Architectures from Intel\nand AMD already implement transparent memory encryption to maintain\nconfidentiality and integrity of all off-chip data. Surprisingly, the\ncombination of both, logical and physical memory safety, has not yet been\nextensively studied in previous research, and a naive combination of both\nsecurity strategies would accumulate both overheads. In this paper, we propose\nCrypTag, an efficient hardware/software co-design mitigating a large class of\nlogical memory safety issues and providing full physical memory safety. At its\ncore, CrypTag utilizes a transparent memory encryption engine not only for\nphysical memory safety, but also for memory coloring at hardly any additional\ncosts. The design avoids any overhead for tag storage by embedding memory\ncolors in the upper bits of a pointer and using these bits as an additional\ninput for the memory encryption. A custom compiler extension automatically\nleverages CrypTag to detect logical memory safety issues for commodity programs\nand is fully backward compatible.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 09:13:14 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 10:39:11 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Nasahl", "Pascal", ""], ["Schilling", "Robert", ""], ["Werner", "Mario", ""], ["Hoogerbrugge", "Jan", ""], ["Medwed", "Marcel", ""], ["Mangard", "Stefan", ""]]}, {"id": "2012.06805", "submitter": "Wesley Joon-Wie Tann", "authors": "Wesley Joon-Wie Tann, Jackie Tan Jin Wei, Joanna Purba, Ee-Chien Chang", "title": "Filtering DDoS Attacks from Unlabeled Network Traffic Data Using Online\n  Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DDoS attacks are simple, effective, and still pose a significant threat even\nafter more than two decades. Given the recent success in machine learning, it\nis interesting to investigate how we can leverage deep learning to filter out\napplication layer attack requests. There are challenges in adopting deep\nlearning solutions due to the ever-changing profiles, the lack of labeled data,\nand constraints in the online setting. Offline unsupervised learning methods\ncan sidestep these hurdles by learning an anomaly detector $N$ from the\nnormal-day traffic ${\\mathcal N}$. However, anomaly detection does not exploit\ninformation acquired during attacks, and their performance typically is not\nsatisfactory. In this paper, we propose two frameworks that utilize both the\nhistoric ${\\mathcal N}$ and the mixture ${\\mathcal M}$ traffic obtained during\nattacks, consisting of unlabeled requests. We also introduce a machine learning\noptimization problem that aims to sift out the attacks using ${\\mathcal N}$ and\n${\\mathcal M}$. First, our proposed approach, inspired by statistical methods,\nextends an unsupervised anomaly detector $N$ to solve the problem using\nestimated conditional probability distributions. We adopt transfer learning to\napply $N$ on ${\\mathcal N}$ and ${\\mathcal M}$ separately and efficiently,\ncombining the results to obtain an online learner. Second, we formulate a\nspecific loss function more suited for deep learning and use iterative training\nto solve it in the online setting. On publicly available datasets, our online\nlearners achieve a $99.3\\%$ improvement on false-positive rates compared to the\nbaseline detection methods. In the offline setting, our approaches are\ncompetitive with classifiers trained on labeled data.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 12:39:05 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Tann", "Wesley Joon-Wie", ""], ["Wei", "Jackie Tan Jin", ""], ["Purba", "Joanna", ""], ["Chang", "Ee-Chien", ""]]}, {"id": "2012.06809", "submitter": "Laijin Meng", "authors": "Laijin Meng, Xinghao Jiang, Zhenzhen Zhang, Zhaohong Li, and Tanfeng\n  Sun", "title": "Coverless Video Steganography based on Maximum DC Coefficients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coverless steganography has been a great interest in recent years, since it\nis a technology that can absolutely resist the detection of steganalysis by not\nmodifying the carriers. However, most existing coverless steganography\nalgorithms select images as carriers, and few studies are reported on coverless\nvideo steganography. In fact, video is a securer and more informative carrier.\nIn this paper, a novel coverless video steganography algorithm based on maximum\nDirect Current (DC) coefficients is proposed. Firstly, a Gaussian distribution\nmodel of DC coefficients considering video coding process is built, which\nindicates that the distribution of changes for maximum DC coefficients in a\nblock is more stable than the adjacent DC coefficients. Then, a novel hash\nsequence generation method based on the maximum DC coefficients is proposed.\nAfter that, the video index structure is established to speed up the efficiency\nof searching videos. In the process of information hiding, the secret\ninformation is converted into binary segments, and the video whose hash\nsequence equals to secret information segment is selected as the carrier\naccording to the video index structure. Finally, all of the selected videos and\nauxiliary information are sent to the receiver. Especially, the subjective\nsecurity of video carriers, the cost of auxiliary information and the\nrobustness to video compression are considered for the first time in this\npaper. Experimental results and analysis show that the proposed algorithm\nperforms better in terms of capacity, robustness, and security, compared with\nthe state-of-the-art coverless steganography algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 13:21:30 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Meng", "Laijin", ""], ["Jiang", "Xinghao", ""], ["Zhang", "Zhenzhen", ""], ["Li", "Zhaohong", ""], ["Sun", "Tanfeng", ""]]}, {"id": "2012.06810", "submitter": "David Sanchez", "authors": "Alberto Blanco-Justicia, Josep Domingo-Ferrer, Sergio Mart\\'inez,\n  David S\\'anchez, Adrian Flanagan and Kuan Eeik Tan", "title": "Achieving Security and Privacy in Federated Learning Systems: Survey,\n  Research Challenges and Future Directions", "comments": "40 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) allows a server to learn a machine learning (ML)\nmodel across multiple decentralized clients that privately store their own\ntraining data. In contrast with centralized ML approaches, FL saves computation\nto the server and does not require the clients to outsource their private data\nto the server. However, FL is not free of issues. On the one hand, the model\nupdates sent by the clients at each training epoch might leak information on\nthe clients' private data. On the other hand, the model learnt by the server\nmay be subjected to attacks by malicious clients; these security attacks might\npoison the model or prevent it from converging. In this paper, we first examine\nsecurity and privacy attacks to FL and critically survey solutions proposed in\nthe literature to mitigate each attack. Afterwards, we discuss the difficulty\nof simultaneously achieving security and privacy protection. Finally, we sketch\nways to tackle this open problem and attain both security and privacy.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 13:23:56 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Blanco-Justicia", "Alberto", ""], ["Domingo-Ferrer", "Josep", ""], ["Mart\u00ednez", "Sergio", ""], ["S\u00e1nchez", "David", ""], ["Flanagan", "Adrian", ""], ["Tan", "Kuan Eeik", ""]]}, {"id": "2012.06876", "submitter": "Utkarsh Uppal", "authors": "Utkarsh Uppal, Bharat Giddwani", "title": "Normalized Label Distribution: Towards Learning Calibrated, Adaptable\n  and Efficient Activation Maps", "comments": "Accepted in AAAI 2021 Workshop on \"Towards Robust, Secure and\n  Efficient Machine Learning\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vulnerability of models to data aberrations and adversarial attacks\ninfluences their ability to demarcate distinct class boundaries efficiently.\nThe network's confidence and uncertainty play a pivotal role in weight\nadjustments and the extent of acknowledging such attacks. In this paper, we\naddress the trade-off between the accuracy and calibration potential of a\nclassification network. We study the significance of ground-truth distribution\nchanges on the performance and generalizability of various state-of-the-art\nnetworks and compare the proposed method's response to unanticipated attacks.\nFurthermore, we demonstrate the role of label-smoothing regularization and\nnormalization in yielding better generalizability and calibrated probability\ndistribution by proposing normalized soft labels to enhance the calibration of\nfeature maps. Subsequently, we substantiate our inference by translating\nconventional convolutions to padding based partial convolution to establish the\ntangible impact of corrections in reinforcing the performance and convergence\nrate. We graphically elucidate the implication of such variations with the\ncritical purpose of corroborating the reliability and reproducibility for\nmultiple datasets.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 17:54:01 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Uppal", "Utkarsh", ""], ["Giddwani", "Bharat", ""]]}, {"id": "2012.06884", "submitter": "Mordechai Guri", "authors": "Mordechai Guri", "title": "AIR-FI: Generating Covert Wi-Fi Signals from Air-Gapped Computers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show that attackers can exfiltrate data from air-gapped\ncomputers via Wi-Fi signals. Malware in a compromised air-gapped computer can\ngenerate signals in the Wi-Fi frequency bands. The signals are generated\nthrough the memory buses - no special hardware is required. Sensitive data can\nbe modulated and secretly exfiltrated on top of the signals. We show that\nnearby Wi-Fi capable devices (e.g., smartphones, laptops, IoT devices) can\nintercept these signals, decode them, and send them to the attacker over the\nInternet. To extract the signals, we utilize the physical layer information\nexposed by the Wi-Fi chips. We implement the transmitter and receiver and\ndiscuss design considerations and implementation details. We evaluate this\ncovert channel in terms of bandwidth and distance and present a set of\ncountermeasures. Our evaluation shows that data can be exfiltrated from\nair-gapped computers to nearby Wi-Fi receivers located a distance of several\nmeters away.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 18:36:21 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Guri", "Mordechai", ""]]}, {"id": "2012.07006", "submitter": "Yi Zeng", "authors": "Han Qiu, Yi Zeng, Shangwei Guo, Tianwei Zhang, Meikang Qiu, Bhavani\n  Thuraisingham", "title": "DeepSweep: An Evaluation Framework for Mitigating DNN Backdoor Attacks\n  using Data Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public resources and services (e.g., datasets, training platforms,\npre-trained models) have been widely adopted to ease the development of Deep\nLearning-based applications. However, if the third-party providers are\nuntrusted, they can inject poisoned samples into the datasets or embed\nbackdoors in those models. Such an integrity breach can cause severe\nconsequences, especially in safety- and security-critical applications. Various\nbackdoor attack techniques have been proposed for higher effectiveness and\nstealthiness. Unfortunately, existing defense solutions are not practical to\nthwart those attacks in a comprehensive way.\n  In this paper, we investigate the effectiveness of data augmentation\ntechniques in mitigating backdoor attacks and enhancing DL models' robustness.\nAn evaluation framework is introduced to achieve this goal. Specifically, we\nconsider a unified defense solution, which (1) adopts a data augmentation\npolicy to fine-tune the infected model and eliminate the effects of the\nembedded backdoor; (2) uses another augmentation policy to preprocess input\nsamples and invalidate the triggers during inference. We propose a systematic\napproach to discover the optimal policies for defending against different\nbackdoor attacks by comprehensively evaluating 71 state-of-the-art data\naugmentation functions. Extensive experiments show that our identified policy\ncan effectively mitigate eight different kinds of backdoor attacks and\noutperform five existing defense methods. We envision this framework can be a\ngood benchmark tool to advance future DNN backdoor studies.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 08:51:37 GMT"}, {"version": "v2", "created": "Sun, 11 Apr 2021 17:09:10 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Qiu", "Han", ""], ["Zeng", "Yi", ""], ["Guo", "Shangwei", ""], ["Zhang", "Tianwei", ""], ["Qiu", "Meikang", ""], ["Thuraisingham", "Bhavani", ""]]}, {"id": "2012.07110", "submitter": "Marco Schreyer", "authors": "Marco Schreyer, Chistian Schulze, Damian Borth", "title": "Leaking Sensitive Financial Accounting Data in Plain Sight using Deep\n  Autoencoder Neural Networks", "comments": "8 pages (excl. appendix), 4 Figures, 2 Tables, AAAI-21 Workshop on\n  Knowledge Discovery from Unstructured Data in Financial Services, this paper\n  is the initial accepted version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Nowadays, organizations collect vast quantities of sensitive information in\n`Enterprise Resource Planning' (ERP) systems, such as accounting relevant\ntransactions, customer master data, or strategic sales price information. The\nleakage of such information poses a severe threat for companies as the number\nof incidents and the reputational damage to those experiencing them continue to\nincrease. At the same time, discoveries in deep learning research revealed that\nmachine learning models could be maliciously misused to create new attack\nvectors. Understanding the nature of such attacks becomes increasingly\nimportant for the (internal) audit and fraud examination practice. The creation\nof such an awareness holds in particular for the fraudulent data leakage using\ndeep learning-based steganographic techniques that might remain undetected by\nstate-of-the-art `Computer Assisted Audit Techniques' (CAATs). In this work, we\nintroduce a real-world `threat model' designed to leak sensitive accounting\ndata. In addition, we show that a deep steganographic process, constituted by\nthree neural networks, can be trained to hide such data in unobtrusive\n`day-to-day' images. Finally, we provide qualitative and quantitative\nevaluations on two publicly available real-world payment datasets.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 17:29:53 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Schreyer", "Marco", ""], ["Schulze", "Chistian", ""], ["Borth", "Damian", ""]]}, {"id": "2012.07173", "submitter": "Song Tian", "authors": "Song Tian", "title": "Cover attacks for elliptic curves with prime order", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new approach to the elliptic curve discrete logarithm problem over\ncubic extension fields $\\mathbb{F}_{q^3}$. It is based on a transfer: First an\n$\\mathbb{F}_q$-rational $(\\ell,\\ell,\\ell)$-isogeny from the Weil restriction of\nthe elliptic curve under consideration with respect to\n$\\mathbb{F}_{q^3}/\\mathbb{F}_q$ to the Jacobian variety of a genus three curve\nover $\\mathbb{F}_q$ is applied and then the problem is solved in the Jacobian\nvia the index-calculus attacks. Although using no covering maps in the\nconstruction of the desired homomorphism, this method is, in a sense, a kind of\ncover attack. As a result, it is possible to solve the discrete logarithm\nproblem in some elliptic curve groups of prime order over $\\mathbb{F}_{q^3}$ in\na time of $\\tilde{O}(q)$.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 22:41:08 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Tian", "Song", ""]]}, {"id": "2012.07196", "submitter": "Mohannad Alhanahnah", "authors": "Mohannad Alhanahnah", "title": "Software Quality Assessment for Robot Operating System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Robot Operating System (ROS) is widely used in academia and industry, and\nimportantly is leveraged in safety-critical robotic systems. The quality of ROS\nsoftware can affect the safety and security properties of robotics systems;\ntherefore, reliability and quality are imperative to guarantee. Source code\nstatic analysis is a key approach to formally perform software verification. We\naddress two concerns in this paper: (1) conducting a systematic literature\nreview study to provide a complete picture of the existing methods that analyze\ndifferent aspects of ROS software, (2) performing empirical study to evaluate\nsoftware properties that can influence the functionality of ROS. We leverage\nPMD1, an off-the-shelf static analysis tool, to conduct our empirical study\nover a set of ROS repositories implemented using Java. The survey analysis\nshows a significant shortcoming in the body of research by the lack of tailored\nanalysis mechanisms for assessing ROS2 code and reveals that the majority of\nresearch efforts are centered around ROS1. Our empirical study shows that the\nJava code of ROS2 does not suffer from serious issues and the majority of the\ndetected alerts are code style issues.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 01:11:56 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Alhanahnah", "Mohannad", ""]]}, {"id": "2012.07242", "submitter": "Andrew Boutros", "authors": "Andrew Boutros, Mathew Hall, Nicolas Papernot, Vaughn Betz", "title": "Neighbors From Hell: Voltage Attacks Against Deep Learning Accelerators\n  on Multi-Tenant FPGAs", "comments": "Published in the 2020 proceedings of the International Conference of\n  Field-Programmable Technology (ICFPT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Field-programmable gate arrays (FPGAs) are becoming widely used accelerators\nfor a myriad of datacenter applications due to their flexibility and energy\nefficiency. Among these applications, FPGAs have shown promising results in\naccelerating low-latency real-time deep learning (DL) inference, which is\nbecoming an indispensable component of many end-user applications. With the\nemerging research direction towards virtualized cloud FPGAs that can be shared\nby multiple users, the security aspect of FPGA-based DL accelerators requires\ncareful consideration. In this work, we evaluate the security of DL\naccelerators against voltage-based integrity attacks in a multitenant FPGA\nscenario. We first demonstrate the feasibility of such attacks on a\nstate-of-the-art Stratix 10 card using different attacker circuits that are\nlogically and physically isolated in a separate attacker role, and cannot be\nflagged as malicious circuits by conventional bitstream checkers. We show that\naggressive clock gating, an effective power-saving technique, can also be a\npotential security threat in modern FPGAs. Then, we carry out the attack on a\nDL accelerator running ImageNet classification in the victim role to evaluate\nthe inherent resilience of DL models against timing faults induced by the\nadversary. We find that even when using the strongest attacker circuit, the\nprediction accuracy of the DL accelerator is not compromised when running at\nits safe operating frequency. Furthermore, we can achieve 1.18-1.31x higher\ninference performance by over-clocking the DL accelerator without affecting its\nprediction accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 03:59:08 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Boutros", "Andrew", ""], ["Hall", "Mathew", ""], ["Papernot", "Nicolas", ""], ["Betz", "Vaughn", ""]]}, {"id": "2012.07339", "submitter": "Jiangshan Yu Dr", "authors": "Ermyas Abebe, Yining Hu, Allison Irvin, Dileban Karunamoorthy,\n  Vinayaka Pandit, Venkatraman Ramakrishna, Jiangshan Yu", "title": "Verifiable Observation of Permissioned Ledgers", "comments": "Full report of ICBC'21 version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Permissioned ledger technologies have gained significant traction over the\nlast few years. For practical reasons, their applications have focused on\ntransforming narrowly scoped use-cases in isolation. This has led to a\nproliferation of niche, isolated networks that are quickly becoming data and\nvalue silos. To increase value across the broader ecosystem, these networks\nmust seamlessly integrate with existing systems and interoperate with one\nanother. A fundamental requirement for enabling crosschain communication is the\nability to prove the validity of the internal state of a ledger to an external\nparty. However, due to the closed nature of permissioned ledgers, their\ninternal state is opaque to an external observer. This makes consuming and\nverifying states from these networks a non-trivial problem.\n  This paper addresses this fundamental requirement for state sharing across\npermissioned ledgers. In particular, we address two key problems for external\nclients: (i) assurances on the validity of state in a permissioned ledger and\n(ii) the ability to reason about the currency of state. We assume an\nadversarial model where the members of the committee managing the permissioned\nledger can be malicious in the absence of detectability and accountability. We\npresent a formalization of the problem for state sharing and examine its\nsecurity properties under different adversarial conditions. We propose the\ndesign of a protocol that uses a secure public ledger for providing guarantees\non safety and the ability to reason about time, with at least one honest member\nin the committee. We then provide a formal security analysis of our design and\na proof of concept implementation based on Hyperledger Fabric demonstrating the\neffectiveness of the proposed protocol.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 08:43:19 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 08:38:17 GMT"}, {"version": "v3", "created": "Fri, 12 Mar 2021 11:53:05 GMT"}, {"version": "v4", "created": "Mon, 10 May 2021 00:46:06 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Abebe", "Ermyas", ""], ["Hu", "Yining", ""], ["Irvin", "Allison", ""], ["Karunamoorthy", "Dileban", ""], ["Pandit", "Vinayaka", ""], ["Ramakrishna", "Venkatraman", ""], ["Yu", "Jiangshan", ""]]}, {"id": "2012.07432", "submitter": "Amit Klein", "authors": "Amit Klein", "title": "Cross Layer Attacks and How to Use Them (for DNS Cache Poisoning, Device\n  Tracking and More)", "comments": "To be published in 2021 IEEE Symposium on Security and Privacy (SP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We analyze the prandom pseudo random number generator (PRNG) in use in the\nLinux kernel (which is the kernel of the Linux operating system, as well as of\nAndroid) and demonstrate that this PRNG is weak. The prandom PRNG is in use by\nmany \"consumers\" in the Linux kernel. We focused on three consumers at the\nnetwork level -- the UDP source port generation algorithm, the IPv6 flow label\ngeneration algorithm and the IPv4 ID generation algorithm. The flawed prandom\nPRNG is shared by all these consumers, which enables us to mount \"cross layer\nattacks\" against the Linux kernel. In these attacks, we infer the internal\nstate of the prandom PRNG from one OSI layer, and use it to either predict the\nvalues of the PRNG employed by the other OSI layer, or to correlate it to an\ninternal state of the PRNG inferred from the other protocol.\n  Using this approach we can mount a very efficient DNS cache poisoning attack\nagainst Linux. We collect TCP/IPv6 flow label values, or UDP source ports, or\nTCP/IPv4 IP ID values, reconstruct the internal PRNG state, then predict an\noutbound DNS query UDP source port, which speeds up the attack by a factor of\nx3000 to x6000. This attack works remotely, but can also be mounted locally,\nacross Linux users and across containers, and (depending on the stub resolver)\ncan poison the cache with an arbitrary DNS record. Additionally, we can\nidentify and track Linux and Android devices -- we collect TCP/IPv6 flow label\nvalues and/or UDP source port values and/or TCP/IPv4 ID fields, reconstruct the\nPRNG internal state and correlate this new state to previously extracted PRNG\nstates to identify the same device.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 11:37:39 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Klein", "Amit", ""]]}, {"id": "2012.07474", "submitter": "Hassan Ali", "authors": "Hassan Ali, Surya Nepal, Salil S. Kanhere and Sanjay Jha", "title": "HaS-Nets: A Heal and Select Mechanism to Defend DNNs Against Backdoor\n  Attacks for Data Collection Scenarios", "comments": "21 pages, 36 figures, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have witnessed the continuing arms race between backdoor attacks and the\ncorresponding defense strategies on Deep Neural Networks (DNNs). Most\nstate-of-the-art defenses rely on the statistical sanitization of the \"inputs\"\nor \"latent DNN representations\" to capture trojan behaviour. In this paper, we\nfirst challenge the robustness of such recently reported defenses by\nintroducing a novel variant of targeted backdoor attack, called \"low-confidence\nbackdoor attack\". We also propose a novel defense technique, called \"HaS-Nets\".\n  \"Low-confidence backdoor attack\" exploits the confidence labels assigned to\npoisoned training samples by giving low values to hide their presence from the\ndefender, both during training and inference. We evaluate the attack against\nfour state-of-the-art defense methods, viz., STRIP, Gradient-Shaping, Februus\nand ULP-defense, and achieve Attack Success Rate (ASR) of 99%, 63.73%, 91.2%\nand 80%, respectively.\n  We next present \"HaS-Nets\" to resist backdoor insertion in the network during\ntraining, using a reasonably small healing dataset, approximately 2% to 15% of\nfull training data, to heal the network at each iteration. We evaluate it for\ndifferent datasets - Fashion-MNIST, CIFAR-10, Consumer Complaint and Urban\nSound - and network architectures - MLPs, 2D-CNNs, 1D-CNNs. Our experiments\nshow that \"HaS-Nets\" can decrease ASRs from over 90% to less than 15%,\nindependent of the dataset, attack configuration and network architecture.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 12:47:41 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Ali", "Hassan", ""], ["Nepal", "Surya", ""], ["Kanhere", "Salil S.", ""], ["Jha", "Sanjay", ""]]}, {"id": "2012.07626", "submitter": "Linshan Jiang", "authors": "Linshan Jiang, Rui Tan, Xin Lou, Guosheng Lin", "title": "On Lightweight Privacy-Preserving Collaborative Learning for Internet of\n  Things by Independent Random Projections", "comments": "arXiv admin note: substantial text overlap with arXiv:1902.05197", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The Internet of Things (IoT) will be a main data generation infrastructure\nfor achieving better system intelligence. This paper considers the design and\nimplementation of a practical privacy-preserving collaborative learning scheme,\nin which a curious learning coordinator trains a better machine learning model\nbased on the data samples contributed by a number of IoT objects, while the\nconfidentiality of the raw forms of the training data is protected against the\ncoordinator. Existing distributed machine learning and data encryption\napproaches incur significant computation and communication overhead, rendering\nthem ill-suited for resource-constrained IoT objects. We study an approach that\napplies independent random projection at each IoT object to obfuscate data and\ntrains a deep neural network at the coordinator based on the projected data\nfrom the IoT objects. This approach introduces light computation overhead to\nthe IoT objects and moves most workload to the coordinator that can have\nsufficient computing resources. Although the independent projections performed\nby the IoT objects address the potential collusion between the curious\ncoordinator and some compromised IoT objects, they significantly increase the\ncomplexity of the projected data. In this paper, we leverage the superior\nlearning capability of deep learning in capturing sophisticated patterns to\nmaintain good learning performance. The extensive comparative evaluation shows\nthat this approach outperforms other lightweight approaches that apply additive\nnoisification for differential privacy and/or support vector machines for\nlearning in the applications with light to moderate data pattern complexities.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 12:44:37 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Jiang", "Linshan", ""], ["Tan", "Rui", ""], ["Lou", "Xin", ""], ["Lin", "Guosheng", ""]]}, {"id": "2012.07634", "submitter": "Richard Harang", "authors": "Richard Harang and Ethan M. Rudd", "title": "SOREL-20M: A Large Scale Benchmark Dataset for Malicious PE Detection", "comments": "Associated code available at: https://github.com/sophos-ai/SOREL-20M", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe the SOREL-20M (Sophos/ReversingLabs-20 Million)\ndataset: a large-scale dataset consisting of nearly 20 million files with\npre-extracted features and metadata, high-quality labels derived from multiple\nsources, information about vendor detections of the malware samples at the time\nof collection, and additional ``tags'' related to each malware sample to serve\nas additional targets. In addition to features and metadata, we also provide\napproximately 10 million ``disarmed'' malware samples -- samples with both the\noptional\\_headers.subsystem and file\\_header.machine flags set to zero -- that\nmay be used for further exploration of features and detection strategies. We\nalso provide Python code to interact with the data and features, as well as\nbaseline neural network and gradient boosted decision tree models and their\nresults, with full training and evaluation code, to serve as a starting point\nfor further experimentation.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 15:22:37 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Harang", "Richard", ""], ["Rudd", "Ethan M.", ""]]}, {"id": "2012.07727", "submitter": "Stefan Roth", "authors": "Stefan Roth, Stefano Tomasin, Marco Maso, and Aydin Sezgin", "title": "Localization Attack by Precoder Feedback Overhearing in 5G Networks and\n  Countermeasures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR eess.SP math.IT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In fifth-generation (5G) cellular networks, users feed back to the base\nstation the index of the precoder (from a codebook) to be used for downlink\ntransmission. The precoder is strongly related to the user channel and in turn\nto the user position within the cell. We propose a method by which an external\nattacker determines the user position by passively overhearing this unencrypted\nlayer-2 feedback signal. The attacker first builds a map of fed back precoder\nindices in the cell. Then, by overhearing the precoder index fed back by the\nvictim user, the attacker finds its position on the map. We focus on the type-I\nsingle-panel codebook, which today is the only mandatory solution in the 3GPP\nstandard. We analyze the attack and assess the obtained localization accuracy\nagainst various parameters. We analyze the localization error of a simplified\nprecoder feedback model and describe its asymptotic localization precision. We\nalso propose a mitigation against our attack, wherein the user randomly selects\nthe precoder among those providing the highest rate. Simulations confirm that\nthe attack can achieve a high localization accuracy, which is significantly\nreduced when the mitigation solution is adopted, at the cost of a negligible\nrate degradation.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 17:22:55 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Roth", "Stefan", ""], ["Tomasin", "Stefano", ""], ["Maso", "Marco", ""], ["Sezgin", "Aydin", ""]]}, {"id": "2012.07805", "submitter": "Nicholas Carlini", "authors": "Nicholas Carlini, Florian Tramer, Eric Wallace, Matthew Jagielski,\n  Ariel Herbert-Voss, Katherine Lee, Adam Roberts, Tom Brown, Dawn Song, Ulfar\n  Erlingsson, Alina Oprea, Colin Raffel", "title": "Extracting Training Data from Large Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has become common to publish large (billion parameter) language models\nthat have been trained on private datasets. This paper demonstrates that in\nsuch settings, an adversary can perform a training data extraction attack to\nrecover individual training examples by querying the language model.\n  We demonstrate our attack on GPT-2, a language model trained on scrapes of\nthe public Internet, and are able to extract hundreds of verbatim text\nsequences from the model's training data. These extracted examples include\n(public) personally identifiable information (names, phone numbers, and email\naddresses), IRC conversations, code, and 128-bit UUIDs. Our attack is possible\neven though each of the above sequences are included in just one document in\nthe training data.\n  We comprehensively evaluate our extraction attack to understand the factors\nthat contribute to its success. Worryingly, we find that larger models are more\nvulnerable than smaller models. We conclude by drawing lessons and discussing\npossible safeguards for training large language models.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 18:39:09 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 17:45:26 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Carlini", "Nicholas", ""], ["Tramer", "Florian", ""], ["Wallace", "Eric", ""], ["Jagielski", "Matthew", ""], ["Herbert-Voss", "Ariel", ""], ["Lee", "Katherine", ""], ["Roberts", "Adam", ""], ["Brown", "Tom", ""], ["Song", "Dawn", ""], ["Erlingsson", "Ulfar", ""], ["Oprea", "Alina", ""], ["Raffel", "Colin", ""]]}, {"id": "2012.07916", "submitter": "Nima Karimian", "authors": "Kavya Dayananda and Nima Karimian", "title": "When Physical Unclonable Function Meets Biometrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As the Covid-19 pandemic grips the world, healthcare systems are being\nreshaped, where the e-health concepts become more likely to be accepted.\nWearable devices often carry sensitive information from users which are exposed\nto security and privacy risks. Moreover, users have always had the concern of\nbeing counterfeited between the fabrication process and vendors' storage.\nHence, not only securing personal data is becoming a crucial obligation, but\nalso device verification is another challenge. To address biometrics\nauthentication and physically unclonable functions (PUFs) need to be put in\nplace to mitigate the security and privacy of the users. Among biometrics\nmodalities, Electrocardiogram (ECG) based biometric has become popular as it\ncan authenticate patients and monitor the patient's vital signs. However,\nresearchers have recently started to study the vulnerabilities of the ECG\nbiometric systems and tried to address the issues of spoofing. Moreover, most\nof the wearable is enabled with CPU and memories. Thus, volatile memory-based\n(NVM) PUF can be easily placed in the device to avoid counterfeit. However,\nmany research challenged the unclonability characteristics of PUFs. Thus, a\ncareful study on these attacks should be sufficient to address the need. In\nthis paper, our aim is to provide a comprehensive study on the state-of-the-art\ndevelopments papers based on biometrics enabled hardware security.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 20:00:40 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Dayananda", "Kavya", ""], ["Karimian", "Nima", ""]]}, {"id": "2012.07917", "submitter": "Dan Wallach", "authors": "Daniel W. Song, Konstantinos Mamouras, Ang Chen, Nathan Dautenhahn,\n  and Dan S. Wallach", "title": "The Design and Implementation of a Verified File System with End-to-End\n  Data Integrity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite significant research and engineering efforts, many of today's\nimportant computer systems suffer from bugs. To increase the reliability of\nsoftware systems, recent work has applied formal verification to certify the\ncorrectness of such systems, with recent successes including certified file\nsystems and certified cryptographic protocols, albeit using quite different\nproof tactics and toolchains. Unifying these concepts, we present the first\ncertified file system that uses cryptographic primitives to protect itself\nagainst tampering. Our certified file system defends against adversaries that\nmight wish to tamper with the raw disk. Such an \"untrusted storage\" threat\nmodel captures the behavior of storage devices that might silently return\nerroneous bits as well as adversaries who might have limited access to a disk,\nperhaps while in transit. In this paper, we present IFSCQ, a certified\ncryptographic file system with strong integrity guarantees. IFSCQ combines and\nextends work on cryptographic file systems and formally certified file systems\nto prove that our design is correct. It is the first certified file system that\nis secure against strong adversaries that can maliciously corrupt on-disk data\nand metadata, including attempting to roll back the disk to earlier versions of\nvalid data. IFSCQ achieves this by constructing a Merkle hash tree of the whole\ndisk, and by proving that tampered disk blocks will always be detected if they\never occur. We demonstrate that IFSCQ runs with reasonable overhead while\ndetecting several kinds of attacks.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 20:02:26 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Song", "Daniel W.", ""], ["Mamouras", "Konstantinos", ""], ["Chen", "Ang", ""], ["Dautenhahn", "Nathan", ""], ["Wallach", "Dan S.", ""]]}, {"id": "2012.07944", "submitter": "Micah Sherr", "authors": "Rahel A. Fainchtein and Adam J. Aviv and Micah Sherr and Stephen\n  Ribaudo and Armaan Khullar", "title": "Holes in the Geofence: Privacy Vulnerabilities in \"Smart\" DNS Services", "comments": "To appear at: Rahel A. Fainchtein, Adam A. Aviv, Micah Sherr, Stephen\n  Ribaudo, and Armaan Khullar. Holes in the Geofence: Privacy Vulnerabilities\n  in \"Smart\" DNS Services. Proceedings on Privacy Enhancing Technologies\n  (PoPETS), July 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Smart DNS (SDNS) services advertise access to \"geofenced\" content (typically,\nvideo streaming sites such as Netflix or Hulu) that is normally inaccessible\nunless the client is within a prescribed geographic region. SDNS is simple to\nuse and involves no software installation. Instead, it requires only that users\nmodify their DNS settings to point to an SDNS resolver. The SDNS resolver\n\"smartly\" identifies geofenced domains and, in lieu of their proper DNS\nresolutions, returns IP addresses of proxy servers located within the geofence.\nThese servers then transparently proxy traffic between the users and their\nintended destinations, allowing for the bypass of these geographic\nrestrictions.\n  This paper presents the first academic study of SDNS services. We identify a\nnumber of serious and pervasive privacy vulnerabilities that expose information\nabout the users of these systems. These include architectural weaknesses that\nenable content providers to identify which requesting clients use SDNS. Worse,\nwe identify flaws in the design of some SDNS services that allow {\\em any}\narbitrary third party to enumerate these services' users (by IP address), even\nif said users are currently offline. We present mitigation strategies to these\nattacks that have been adopted by at least one SDNS provider in response to our\nfindings.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 21:19:37 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Fainchtein", "Rahel A.", ""], ["Aviv", "Adam J.", ""], ["Sherr", "Micah", ""], ["Ribaudo", "Stephen", ""], ["Khullar", "Armaan", ""]]}, {"id": "2012.07989", "submitter": "Shadrack Awah Buo", "authors": "Shadrack Awah Buo", "title": "The Emerging Threats of Deepfake Attacks and Countermeasures", "comments": "5", "journal-ref": null, "doi": "10.13140/RG.2.2.23089.81762", "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deepfake technology (DT) has taken a new level of sophistication.\nCybercriminals now can manipulate sounds, images, and videos to defraud and\nmisinform individuals and businesses. This represents a growing threat to\ninternational institutions and individuals which needs to be addressed. This\npaper provides an overview of deepfakes, their benefits to society, and how DT\nworks. Highlights the threats that are presented by deepfakes to businesses,\npolitics, and judicial systems worldwide. Additionally, the paper will explore\npotential solutions to deepfakes and conclude with future research direction.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 22:40:49 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Buo", "Shadrack Awah", ""]]}, {"id": "2012.07994", "submitter": "Mohammadreza Ebrahimi", "authors": "Mohammadreza Ebrahimi, Ning Zhang, James Hu, Muhammad Taqi Raza,\n  Hsinchun Chen", "title": "Binary Black-box Evasion Attacks Against Deep Learning-based Static\n  Malware Detectors with Adversarial Byte-Level Language Model", "comments": "Accepted in 35th AAAI Conference on Artificial Intelligence, Workshop\n  on Robust, Secure, and Efficient Machine Learning (RSEML)", "journal-ref": "AAAI Conference on Artificial Intelligence, Workshop on Robust,\n  Secure, and Efficient Machine Learning (RSEML), February 2-9, 2021", "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Anti-malware engines are the first line of defense against malicious\nsoftware. While widely used, feature engineering-based anti-malware engines are\nvulnerable to unseen (zero-day) attacks. Recently, deep learning-based static\nanti-malware detectors have achieved success in identifying unseen attacks\nwithout requiring feature engineering and dynamic analysis. However, these\ndetectors are susceptible to malware variants with slight perturbations, known\nas adversarial examples. Generating effective adversarial examples is useful to\nreveal the vulnerabilities of such systems. Current methods for launching such\nattacks require accessing either the specifications of the targeted\nanti-malware model, the confidence score of the anti-malware response, or\ndynamic malware analysis, which are either unrealistic or expensive. We propose\nMalRNN, a novel deep learning-based approach to automatically generate evasive\nmalware variants without any of these restrictions. Our approach features an\nadversarial example generation process, which learns a language model via a\ngenerative sequence-to-sequence recurrent neural network to augment malware\nbinaries. MalRNN effectively evades three recent deep learning-based malware\ndetectors and outperforms current benchmark methods. Findings from applying our\nMalRNN on a real dataset with eight malware categories are discussed.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 22:54:53 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Ebrahimi", "Mohammadreza", ""], ["Zhang", "Ning", ""], ["Hu", "James", ""], ["Raza", "Muhammad Taqi", ""], ["Chen", "Hsinchun", ""]]}, {"id": "2012.08003", "submitter": "Mahdi Zamani", "authors": "Mihai Christodorescu, Wanyun Catherine Gu, Ranjit Kumaresan, Mohsen\n  Minaei, Mustafa Ozdayi, Benjamin Price, Srinivasan Raghuraman, Muhammad Saad,\n  Cuy Sheffield, Minghua Xu, Mahdi Zamani", "title": "Towards a Two-Tier Hierarchical Infrastructure: An Offline Payment\n  System for Central Bank Digital Currencies", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Digital payments traditionally rely on online communications with several\nintermediaries such as banks, payment networks, and payment processors in order\nto authorize and process payment transactions. While these communication\nnetworks are designed to be highly available with continuous uptime, there may\nbe times when an end-user experiences little or no access to network\nconnectivity.\n  The growing interest in digital forms of payments has led central banks\naround the world to explore the possibility of issuing a new type of\ncentral-bank money, known as central bank digital currency (CBDC). To\nfacilitate the secure issuance and transfer of CBDC, we envision a CBDC design\nunder a two-tier hierarchical trust infrastructure, which is implemented using\npublic-key cryptography with the central bank as the root certificate authority\nfor generating digital signatures, and other financial institutions as\nintermediate certificate authorities. One important design feature for CBDC\nthat can be developed under this hierarchical trust infrastructure is an\noffline capability to create secure point-to-point offline payments through the\nuse of authorized hardware. An offline capability for CBDC as digital cash can\ncreate a resilient payment system for consumers and businesses to transact in\nany situation.\n  We propose an offline payment system (OPS) protocol for CBDC that allows a\nuser to make digital payments to another user while both users are temporarily\noffline and unable to connect to payment intermediaries (or even the Internet).\nOPS can be used to instantly complete a transaction involving any form of\ndigital currency over a point-to-point channel without communicating with any\npayment intermediary, achieving virtually unbounded throughput and real-time\ntransaction latency.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 23:22:56 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Christodorescu", "Mihai", ""], ["Gu", "Wanyun Catherine", ""], ["Kumaresan", "Ranjit", ""], ["Minaei", "Mohsen", ""], ["Ozdayi", "Mustafa", ""], ["Price", "Benjamin", ""], ["Raghuraman", "Srinivasan", ""], ["Saad", "Muhammad", ""], ["Sheffield", "Cuy", ""], ["Xu", "Minghua", ""], ["Zamani", "Mahdi", ""]]}, {"id": "2012.08042", "submitter": "Stephen MacDonell", "authors": "Noah Oghenfego Ogwara, Krassie Petrova, Mee Loong (Bobby) Yang,\n  Stephen G. MacDonell", "title": "Enhancing Data Security in the User Layer of Mobile Cloud Computing\n  Environment: A Novel Approach", "comments": "9 pages, 1 figure, 1 table, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reviews existing Intrusion Detection Systems (IDS) that target the\nMobile Cloud Computing (MCC), Cloud Computing (CC), and Mobile Device (MD)\nenvironment. The review identifies the drawbacks in existing solutions and\nproposes a novel approach towards enhancing the security of the User Layer (UL)\nin the MCC environment. The approach named MINDPRES (Mobile- Cloud Intrusion\nDetection and Prevention System) combines a host-based IDS and network-based\nIDS using Machine Learning (ML) techniques. It applies dynamic analysis of both\ndevice resources and network traffic in order to detect malicious activities at\nthe UL in the MCC environment. Preliminary investigations show that our\napproach will enhance the security of the UL in the MCC environment. Our future\nwork will include the development and the evaluation of the proposed model\nacross the various mobile platforms in the MCC environment.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 02:06:00 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Ogwara", "Noah Oghenfego", "", "Bobby"], ["Petrova", "Krassie", "", "Bobby"], ["Loong", "Mee", "", "Bobby"], ["Yang", "", ""], ["MacDonell", "Stephen G.", ""]]}, {"id": "2012.08096", "submitter": "Lu Chen", "authors": "Lu Chen, Jiao Sun, Wei Xu", "title": "FAWA: Fast Adversarial Watermark Attack on Optical Character Recognition\n  (OCR) Systems", "comments": "16 pages, ECML/PKDD 2020 research trace", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) significantly improved the accuracy of optical\ncharacter recognition (OCR) and inspired many important applications.\nUnfortunately, OCRs also inherit the vulnerabilities of DNNs under adversarial\nexamples. Different from colorful vanilla images, text images usually have\nclear backgrounds. Adversarial examples generated by most existing adversarial\nattacks are unnatural and pollute the background severely. To address this\nissue, we propose the Fast Adversarial Watermark Attack (FAWA) against\nsequence-based OCR models in the white-box manner. By disguising the\nperturbations as watermarks, we can make the resulting adversarial images\nappear natural to human eyes and achieve a perfect attack success rate. FAWA\nworks with either gradient-based or optimization-based perturbation generation.\nIn both letter-level and word-level attacks, our experiments show that in\naddition to natural appearance, FAWA achieves a 100% attack success rate with\n60% less perturbations and 78% fewer iterations on average. In addition, we\nfurther extend FAWA to support full-color watermarks, other languages, and even\nthe OCR accuracy-enhancing mechanism.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 05:19:54 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Chen", "Lu", ""], ["Sun", "Jiao", ""], ["Xu", "Wei", ""]]}, {"id": "2012.08156", "submitter": "Sagar Sharma", "authors": "Sagar Sharma, Keke Chen", "title": "Confidential Machine Learning on Untrusted Platforms: A Survey", "comments": "To appear in Cybersecurity Journal, Springer, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the ever-growing data and the need for developing powerful machine\nlearning models, data owners increasingly depend on various untrusted platforms\n(e.g., public clouds, edges, and machine learning service providers) for\nscalable processing or collaborative learning. Thus, sensitive data and models\nare in danger of unauthorized access, misuse, and privacy compromises. A\nrelatively new body of research confidentially trains machine learning models\non protected data to address these concerns. In this survey, we summarize\nnotable studies in this emerging area of research. With a unified framework, we\nhighlight the critical challenges and innovations in outsourcing machine\nlearning confidentially. We focus on the cryptographic approaches for\nconfidential machine learning (CML), primarily on model training, while also\ncovering other directions such as perturbation-based approaches and CML in the\nhardware-assisted computing environment. The discussion will take a holistic\nway to consider a rich context of the related threat models, security\nassumptions, design principles, and associated trade-offs amongst data utility,\ncost, and confidentiality.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 08:57:02 GMT"}, {"version": "v2", "created": "Sat, 12 Jun 2021 22:58:24 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Sharma", "Sagar", ""], ["Chen", "Keke", ""]]}, {"id": "2012.08318", "submitter": "Jafar Majidpour", "authors": "Jafar Majidpour and Hiwa Hasanzadeh", "title": "Application of deep learning to enhance the accuracy of intrusion\n  detection in modern computer networks", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Application of deep learning to enhance the accuracy of intrusion detection\nin modern computer networks were studied in this paper. The identification of\nattacks in computer networks is divided in to two categories of intrusion\ndetection and anomaly detection in terms of the information used in the\nlearning phase. Intrusion detection uses both routine traffic and attack\ntraffic. Abnormal detection methods attempt to model the normal behavior of the\nsystem, and any incident that violates this model is considered to be a\nsuspicious behavior. For example, if the web server, which is usually passive,\ntries to There are many addresses that are likely to be infected with the worm.\nThe abnormal diagnostic methods are Statistical models, Secure system approach,\nReview protocol, Check files, Create White list, Neural Networks, Genetic\nAlgorithm, Vector Machines, decision tree. Our results have demonstrated that\nour approach offers high levels of accuracy, precision and recall together with\nreduced training time. In our future work, the first avenue of exploration for\nimprovement will be to assess and extend the capability of our model to handle\nzero-day attacks.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 07:21:43 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Majidpour", "Jafar", ""], ["Hasanzadeh", "Hiwa", ""]]}, {"id": "2012.08347", "submitter": "Andrew Trask", "authors": "Andrew Trask and Emma Bluemke and Ben Garfinkel and Claudia Ghezzou\n  Cuervas-Mons and Allan Dafoe", "title": "Beyond Privacy Trade-offs with Structured Transparency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many socially valuable activities depend on sensitive information, such as\nmedical research, public health policies, political coordination, and\npersonalized digital services. This is often posed as an inherent privacy\ntrade-off: we can benefit from data analysis or retain data privacy, but not\nboth. Across several disciplines, a vast amount of effort has been directed\ntoward overcoming this trade-off to enable productive uses of information\nwithout also enabling undesired misuse, a goal we term `structured\ntransparency'. In this paper, we provide an overview of the frontier of\nresearch seeking to develop structured transparency. We offer a general\ntheoretical framework and vocabulary, including characterizing the fundamental\ncomponents -- input privacy, output privacy, input verification, output\nverification, and flow governance -- and fundamental problems of copying,\nbundling, and recursive oversight. We argue that these barriers are less\nfundamental than they often appear. Recent progress in developing\n`privacy-enhancing technologies' (PETs), such as secure computation and\nfederated learning, may substantially reduce lingering use-misuse trade-offs in\na number of domains. We conclude with several illustrations of structured\ntransparency -- in open research, energy management, and credit scoring systems\n-- and a discussion of the risks of misuse of these tools.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 15:03:25 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Trask", "Andrew", ""], ["Bluemke", "Emma", ""], ["Garfinkel", "Ben", ""], ["Cuervas-Mons", "Claudia Ghezzou", ""], ["Dafoe", "Allan", ""]]}, {"id": "2012.08356", "submitter": "Alexander Ivchenko Vladimirovich", "authors": "Raoul Nigmatullin, Alexander Ivchenko, Semyon Dorokhin", "title": "Differentiation of Sliding Rescaled Ranges: New Approach to Encrypted\n  and VPN Traffic Detection", "comments": "5 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new approach to traffic preprocessing called Differentiation of\nSliding Rescaled Ranges (DSRR) expanding the ideas laid down by H.E. Hurst. We\napply proposed approach on the characterizing encrypted and unencrypted traffic\non the well-known ISCXVPN2016 dataset. We deploy DSRR for flow-base features\nand then solve the task VPN vs nonVPN with basic machine learning models. With\nDSRR and Random Forest, we obtain 0.971 Precision, 0.969 Recall and improve\nthis result to 0.976 using statistical analysis of features in comparison with\nNeural Network approach that gives 0.93 Precision via 2D-CNN. The proposed\nmethod and the results can be found at\nhttps://github.com/AleksandrIvchenko/dsrr_vpn_nonvpn.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 13:19:45 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Nigmatullin", "Raoul", ""], ["Ivchenko", "Alexander", ""], ["Dorokhin", "Semyon", ""]]}, {"id": "2012.08460", "submitter": "Joab Kose", "authors": "Joab Kose, Oscar Bautista Chia, Vashish Baboolal", "title": "Review and Test of Steganography Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Steganography is the art of concealing a secret message within an\nappropriate-multimedia carrier such as images, audio, video files, and even\nnetwork packets. Steganographic techniques have been used since ancient times\nto hide the message from third-parties deemed to be enemies. On one hand,\nSteganography is a useful technique that has been applied in various useful\napplications. On the other hand, however, the same technique has been applied\nand used for the wrong purposes by people who have ill intentions. The increase\nin computational power and increase in security-awareness over the past few\nyears have propelled the application of steganography in computational\nsecurity-techniques. Being robust, undetectable, and having a good capacity of\nhidden-data, steganography has been preferred for hiding data than watermarking\nand cryptographic-techniques. This paper clarifies the application of\nsteganography on different multimedia-carriers by using various potential\ntools, methods, and principles to either apply or detect steganography\ntechniques.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 17:56:08 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Kose", "Joab", ""], ["Chia", "Oscar Bautista", ""], ["Baboolal", "Vashish", ""]]}, {"id": "2012.08487", "submitter": "Simon Davies", "authors": "Simon R. Davies, Richard Macfarlane, William J. Buchanan", "title": "Evaluation of Live Forensic Techniques in Ransomware Attack Mitigation", "comments": "11 pages, 10 figures", "journal-ref": "Forensic Science International: Digital Investigation. Volume 33,\n  June 2020, 300979", "doi": "10.1016/j.fsidi.2020.300979", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Memory was captured from a system infected by ransomware and its contents was\nexamined using live forensic tools, with the intent of identifying the\nsymmetric encryption keys being used. NotPetya, Bad Rabbit and Phobos hybrid\nransomware samples were tested during the investigation. If keys were\ndiscovered, the following two steps were also performed. Firstly, a timeline\nwas manually created by combining data from multiple sources to illustrate the\nransomware's behaviour as well as showing when the encryption keys were present\nin memory and how long they remained there. Secondly, an attempt was made to\ndecrypt the files encrypted by the ransomware using the found keys. In all\ncases, the investigation was able to confirm that it was possible to identify\nthe encryption keys used. A description of how these found keys were then used\nto successfully decrypt files that had been encrypted during the execution of\nthe ransomware is also given. The resulting generated timelines provided a\nexcellent way to visualise the behaviour of the ransomware and the encryption\nkey management practices it employed, and from a forensic investigation and\npossible mitigation point of view, when the encryption keys are in memory.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 18:33:02 GMT"}, {"version": "v2", "created": "Sat, 19 Dec 2020 19:46:45 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Davies", "Simon R.", ""], ["Macfarlane", "Richard", ""], ["Buchanan", "William J.", ""]]}, {"id": "2012.08559", "submitter": "Sergio Hidalgo-Espinoza", "authors": "Sergio Hidalgo-Espinoza and Kevin Chamorro-Cupueran and Oscar\n  Chang-Tortolero", "title": "Intrusion detection in computer systems by using artificial neural\n  networks with Deep Learning approaches", "comments": null, "journal-ref": "10th International Conference on Advances in Computing and\n  Information Technology (ACITY 2020), November 28~29, 2020, London, United\n  Kingdom Volume Editors : David C. Wyld, Dhinaharan Nagamalai (Eds) ISBN :\n  978-1-925953-29-9", "doi": "10.5121/csit.2020.101501", "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Intrusion detection into computer networks has become one of the most\nimportant issues in cybersecurity. Attackers keep on researching and coding to\ndiscover new vulnerabilities to penetrate information security system. In\nconsequence computer systems must be daily upgraded using up-to-date techniques\nto keep hackers at bay. This paper focuses on the design and implementation of\nan intrusion detection system based on Deep Learning architectures. As a first\nstep, a shallow network is trained with labelled log-in [into a computer\nnetwork] data taken from the Dataset CICIDS2017. The internal behaviour of this\nnetwork is carefully tracked and tuned by using plotting and exploring codes\nuntil it reaches a functional peak in intrusion prediction accuracy. As a\nsecond step, an autoencoder, trained with big unlabelled data, is used as a\nmiddle processor which feeds compressed information and abstract representation\nto the original shallow network. It is proven that the resultant deep\narchitecture has a better performance than any version of the shallow network\nalone. The resultant functional code scripts, written in MATLAB, represent a\nre-trainable system which has been proved using real data, producing good\nprecision and fast response.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 19:12:23 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Hidalgo-Espinoza", "Sergio", ""], ["Chamorro-Cupueran", "Kevin", ""], ["Chang-Tortolero", "Oscar", ""]]}, {"id": "2012.08588", "submitter": "Ivan Evtimov", "authors": "Ivan Evtimov, Pascal Sturmfels, Tadayoshi Kohno", "title": "FoggySight: A Scheme for Facial Lookup Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in deep learning algorithms have enabled better-than-human\nperformance on face recognition tasks. In parallel, private companies have been\nscraping social media and other public websites that tie photos to identities\nand have built up large databases of labeled face images. Searches in these\ndatabases are now being offered as a service to law enforcement and others and\ncarry a multitude of privacy risks for social media users. In this work, we\ntackle the problem of providing privacy from such face recognition systems. We\npropose and evaluate FoggySight, a solution that applies lessons learned from\nthe adversarial examples literature to modify facial photos in a\nprivacy-preserving manner before they are uploaded to social media.\nFoggySight's core feature is a community protection strategy where users acting\nas protectors of privacy for others upload decoy photos generated by\nadversarial machine learning algorithms. We explore different settings for this\nscheme and find that it does enable protection of facial privacy -- including\nagainst a facial recognition service with unknown internals.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 19:57:18 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Evtimov", "Ivan", ""], ["Sturmfels", "Pascal", ""], ["Kohno", "Tadayoshi", ""]]}, {"id": "2012.08604", "submitter": "Qi Chang", "authors": "Qi Chang, Zhennan Yan, Lohendran Baskaran, Hui Qu, Yikai Zhang, Tong\n  Zhang, Shaoting Zhang, and Dimitris N. Metaxas", "title": "Multi-modal AsynDGAN: Learn From Distributed Medical Image Data without\n  Sharing Private Information", "comments": "arXiv admin note: text overlap with arXiv:2006.00080", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As deep learning technologies advance, increasingly more data is necessary to\ngenerate general and robust models for various tasks. In the medical domain,\nhowever, large-scale and multi-parties data training and analyses are\ninfeasible due to the privacy and data security concerns. In this paper, we\npropose an extendable and elastic learning framework to preserve privacy and\nsecurity while enabling collaborative learning with efficient communication.\nThe proposed framework is named distributed Asynchronized Discriminator\nGenerative Adversarial Networks (AsynDGAN), which consists of a centralized\ngenerator and multiple distributed discriminators. The advantages of our\nproposed framework are five-fold: 1) the central generator could learn the real\ndata distribution from multiple datasets implicitly without sharing the image\ndata; 2) the framework is applicable for single-modality or multi-modality\ndata; 3) the learned generator can be used to synthesize samples for\ndown-stream learning tasks to achieve close-to-real performance as using actual\nsamples collected from multiple data centers; 4) the synthetic samples can also\nbe used to augment data or complete missing modalities for one single data\ncenter; 5) the learning process is more efficient and requires lower bandwidth\nthan other distributed deep learning methods.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 20:41:24 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Chang", "Qi", ""], ["Yan", "Zhennan", ""], ["Baskaran", "Lohendran", ""], ["Qu", "Hui", ""], ["Zhang", "Yikai", ""], ["Zhang", "Tong", ""], ["Zhang", "Shaoting", ""], ["Metaxas", "Dimitris N.", ""]]}, {"id": "2012.08680", "submitter": "Kexin Pei", "authors": "Kexin Pei, Zhou Xuan, Junfeng Yang, Suman Jana, Baishakhi Ray", "title": "Trex: Learning Execution Semantics from Micro-Traces for Binary\n  Similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting semantically similar functions -- a crucial analysis capability\nwith broad real-world security usages including vulnerability detection,\nmalware lineage, and forensics -- requires understanding function behaviors and\nintentions. This task is challenging as semantically similar functions can be\nimplemented differently, run on different architectures, and compiled with\ndiverse compiler optimizations or obfuscations. Most existing approaches match\nfunctions based on syntactic features without understanding the functions'\nexecution semantics.\n  We present Trex, a transfer-learning-based framework, to automate learning\nexecution semantics explicitly from functions' micro-traces and transfer the\nlearned knowledge to match semantically similar functions. Our key insight is\nthat these traces can be used to teach an ML model the execution semantics of\ndifferent sequences of instructions. We thus train the model to learn execution\nsemantics from the functions' micro-traces, without any manual labeling effort.\nWe then develop a novel neural architecture to learn execution semantics from\nmicro-traces, and we finetune the pretrained model to match semantically\nsimilar functions.\n  We evaluate Trex on 1,472,066 function binaries from 13 popular software\nprojects. These functions are from different architectures and compiled with\nvarious optimizations and obfuscations. Trex outperforms the state-of-the-art\nsystems by 7.8%, 7.2%, and 14.3% in cross-architecture, optimization, and\nobfuscation function matching, respectively. Ablation studies show that the\npretraining significantly boosts the function matching performance,\nunderscoring the importance of learning execution semantics.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 00:24:51 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2020 04:14:44 GMT"}, {"version": "v3", "created": "Mon, 26 Apr 2021 22:04:43 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Pei", "Kexin", ""], ["Xuan", "Zhou", ""], ["Yang", "Junfeng", ""], ["Jana", "Suman", ""], ["Ray", "Baishakhi", ""]]}, {"id": "2012.08723", "submitter": "Ninareh Mehrabi", "authors": "Ninareh Mehrabi, Muhammad Naveed, Fred Morstatter, Aram Galstyan", "title": "Exacerbating Algorithmic Bias through Fairness Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic fairness has attracted significant attention in recent years,\nwith many quantitative measures suggested for characterizing the fairness of\ndifferent machine learning algorithms. Despite this interest, the robustness of\nthose fairness measures with respect to an intentional adversarial attack has\nnot been properly addressed. Indeed, most adversarial machine learning has\nfocused on the impact of malicious attacks on the accuracy of the system,\nwithout any regard to the system's fairness. We propose new types of data\npoisoning attacks where an adversary intentionally targets the fairness of a\nsystem. Specifically, we propose two families of attacks that target fairness\nmeasures. In the anchoring attack, we skew the decision boundary by placing\npoisoned points near specific target points to bias the outcome. In the\ninfluence attack on fairness, we aim to maximize the covariance between the\nsensitive attributes and the decision outcome and affect the fairness of the\nmodel. We conduct extensive experiments that indicate the effectiveness of our\nproposed attacks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 03:44:17 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Mehrabi", "Ninareh", ""], ["Naveed", "Muhammad", ""], ["Morstatter", "Fred", ""], ["Galstyan", "Aram", ""]]}, {"id": "2012.08726", "submitter": "Ning Yu", "authors": "Ning Yu, Vladislav Skripniuk, Dingfan Chen, Larry Davis, Mario Fritz", "title": "Responsible Disclosure of Generative Models Using Scalable\n  Fingerprinting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.CY cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past six years, deep generative models have achieved a qualitatively\nnew level of performance. Generated data has become difficult, if not\nimpossible, to be distinguished from real data. While there are plenty of use\ncases that benefit from this technology, there are also strong concerns on how\nthis new technology can be misused to spoof sensors, generate deep fakes, and\nenable misinformation at scale. Unfortunately, current deep fake detection\nmethods are not sustainable, as the gap between real and fake continues to\nclose. In contrast, our work enables a responsible disclosure of such\nstate-of-the-art generative models, that allows researchers and companies to\nfingerprint their models, so that the generated samples containing a\nfingerprint can be accurately detected and attributed to a source. Our\ntechnique achieves this by an efficient and scalable ad-hoc generation of a\nlarge population of models with distinct fingerprints. Our recommended\noperation point uses a 128-bit fingerprint which in principle results in more\nthan $10^{36}$ identifiable models. Experiments show that our method fulfills\nkey properties of a fingerprinting mechanism and achieves effectiveness in deep\nfake detection and attribution.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 03:51:54 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 04:19:56 GMT"}, {"version": "v3", "created": "Tue, 23 Feb 2021 08:17:25 GMT"}, {"version": "v4", "created": "Tue, 30 Mar 2021 23:51:15 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Yu", "Ning", ""], ["Skripniuk", "Vladislav", ""], ["Chen", "Dingfan", ""], ["Davis", "Larry", ""], ["Fritz", "Mario", ""]]}, {"id": "2012.08742", "submitter": "Anna Melman", "authors": "Anna Melman, Pavel Petrov, Alexander Shelupanov", "title": "An adaptive algorithm for embedding information into compressed JPEG\n  images using the QIM method", "comments": "4 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread use of JPEG images makes them good covers for secret messages\nstoring and transmitting. This paper proposes a new algorithm for embedding\ninformation in JPEG images based on the steganographic QIM method. The main\nproblem of such embedding is the vulnerability to statistical steganalysis. To\nsolve this problem, it is proposed to use a variable quantization step, which\nis adaptively selected for each block of the JPEG cover image. Experimental\nresults show that the proposed approach successfully increases the security of\nembedding.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 04:37:28 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Melman", "Anna", ""], ["Petrov", "Pavel", ""], ["Shelupanov", "Alexander", ""]]}, {"id": "2012.08782", "submitter": "Leandros Maglaras A", "authors": "Vassilis Papaspirou, Leandros Maglaras, Mohamed Amine Ferrag, Ioanna\n  Kantzavelou, Helge Janicke, Christos Douligeris", "title": "A novel Two-Factor HoneyToken Authentication Mechanism", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The majority of systems rely on user authentication on passwords, but\npasswords have so many weaknesses and widespread use that easily raise\nsignificant security concerns, regardless of their encrypted form. Users hold\nthe same password for different accounts, administrators never check password\nfiles for flaws that might lead to a successful cracking, and the lack of a\ntight security policy regarding regular password replacement are a few problems\nthat need to be addressed. The proposed research work aims at enhancing this\nsecurity mechanism, prevent penetrations, password theft, and attempted\nbreak-ins towards securing computing systems. The selected solution approach is\ntwo-folded; it implements a two-factor authentication scheme to prevent\nunauthorized access, accompanied by Honeyword principles to detect corrupted or\nstolen tokens. Both can be integrated into any platform or web application with\nthe use of QR codes and a mobile phone.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 07:59:47 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 18:23:40 GMT"}, {"version": "v3", "created": "Wed, 20 Jan 2021 20:00:18 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Papaspirou", "Vassilis", ""], ["Maglaras", "Leandros", ""], ["Ferrag", "Mohamed Amine", ""], ["Kantzavelou", "Ioanna", ""], ["Janicke", "Helge", ""], ["Douligeris", "Christos", ""]]}, {"id": "2012.08811", "submitter": "Simon Duque Anton", "authors": "Simon D Duque Anton, Daniel Fraunholz, Daniel Schneider", "title": "Investigating the Ecosystem of Offensive Information Security Tools", "comments": "Six pages, one figure, this work is a preprint of a paper accepted at\n  the 1st Workshop on Next Generation Networks and Applications (NGNA-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The internet landscape is growing and at the same time becoming more\nheterogeneous. Services are performed via computers and networks, critical data\nis stored digitally. This enables freedom for the user, and flexibility for\noperators. Data is easier to manage and distribute. However, every device\nconnected to a network is potentially susceptible to cyber attacks. Security\nsolutions, such as antivirus software or firewalls, are widely established.\nHowever, certain types of attacks cannot be prevented with defensive measures\nalone. Offensive security describes the practice of security professionals\nusing methods and tools of cyber criminals. This allows them to find\nvulnerabilities before they become the point of entry in a real attack.\nFurthermore, following the methods of cyber criminals enables security\nprofessionals to adapt to a criminal's point of view and potentially discover\nattack angles formerly ignored. As cyber criminals often employ freely\navailable security tools, having knowledge about these provides additional\ninsight for professionals. This work categorises and compares tools regarding\nmetrics concerning maintainability, usability and technical details. Generally,\nseveral well-established tools are available for the first phases, while phases\nafter the initial breach lack a variety of tools.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 09:19:34 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Anton", "Simon D Duque", ""], ["Fraunholz", "Daniel", ""], ["Schneider", "Daniel", ""]]}, {"id": "2012.08835", "submitter": "Sergio Maffeis", "authors": "Rishi Rabheru, Hazim Hanif, Sergio Maffeis", "title": "A Hybrid Graph Neural Network Approach for Detecting PHP Vulnerabilities", "comments": "A poster version of this paper appeared as\n  https://doi.org/10.1145/3412841.3442132", "journal-ref": null, "doi": "10.1145/3412841.3442132", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents DeepTective, a deep learning approach to detect\nvulnerabilities in PHP source code. Our approach implements a novel hybrid\ntechnique that combines Gated Recurrent Units and Graph Convolutional Networks\nto detect SQLi, XSS and OSCI vulnerabilities leveraging both syntactic and\nsemantic information. We evaluate DeepTective and compare it to the state of\nthe art on an established synthetic dataset and on a novel real-world dataset\ncollected from GitHub. Experimental results show that DeepTective achieves near\nperfect classification on the synthetic dataset, and an F1 score of 88.12% on\nthe realistic dataset, outperforming related approaches. We validate\nDeepTective in the wild by discovering 4 novel vulnerabilities in established\nWordPress plugins.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 10:17:53 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Rabheru", "Rishi", ""], ["Hanif", "Hazim", ""], ["Maffeis", "Sergio", ""]]}, {"id": "2012.08870", "submitter": "Carolin Hannusch", "authors": "Giovanni Falcone, \\'Agota Figula, Carolin Hannusch", "title": "Explicit bases of the Riemann-Roch spaces on divisors on hyperelliptic\n  curves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  For an (imaginary) hyperelliptic curve $\\mathcal{H}$ of genus $g$, we\ndetermine a basis of the Riemann-Roch space $\\mathcal{L}(D)$, where $D$ is a\ndivisor with positive degree $n$, linearly equivalent to $P_1+\\cdots+\nP_j+(n-j)\\Omega$, with $0 \\le j \\le g$, where $\\Omega$ is a Weierstrass point,\ntaken as the point at infinity. As an application, we determine a generator\nmatrix of a Goppa code for $j=g=3$ and $n=4.$\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 11:24:05 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Falcone", "Giovanni", ""], ["Figula", "\u00c1gota", ""], ["Hannusch", "Carolin", ""]]}, {"id": "2012.08924", "submitter": "Onur G\\\"unl\\\"u Dr.-Ing.", "authors": "Onur G\\\"unl\\\"u and Rafael F. Schaefer", "title": "Secret Key Agreement with Physical Unclonable Functions: An Optimality\n  Summary", "comments": "To appear in MDPI Entropy Journal. arXiv admin note: text overlap\n  with arXiv:2002.11687", "journal-ref": null, "doi": "10.3390/e23010016", "report-no": null, "categories": "eess.SP cs.CR cs.CV cs.IT cs.MM math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address security and privacy problems for digital devices and biometrics\nfrom an information-theoretic optimality perspective, where a secret key is\ngenerated for authentication, identification, message encryption/decryption, or\nsecure computations. A physical unclonable function (PUF) is a promising\nsolution for local security in digital devices and this review gives the most\nrelevant summary for information theorists, coding theorists, and signal\nprocessing community members who are interested in optimal PUF constructions.\nLow-complexity signal processing methods such as transform coding that are\ndeveloped to make the information-theoretic analysis tractable are discussed.\nThe optimal trade-offs between the secret-key, privacy-leakage, and storage\nrates for multiple PUF measurements are given. Proposed optimal code\nconstructions that jointly design the vector quantizer and error-correction\ncode parameters are listed. These constructions include modern and algebraic\ncodes such as polar codes and convolutional codes, both of which can achieve\nsmall block-error probabilities at short block lengths, corresponding to a\nsmall number of PUF circuits. Open problems in the PUF literature from a signal\nprocessing, information theory, coding theory, and hardware complexity\nperspectives and their combinations are listed to stimulate further\nadvancements in the research on local privacy and security.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 13:21:20 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["G\u00fcnl\u00fc", "Onur", ""], ["Schaefer", "Rafael F.", ""]]}, {"id": "2012.08968", "submitter": "Nicholas Stedmon BA(Hons)", "authors": "Nicholas Stedmon", "title": "The Impact of Cyber Security Threats on the 2020 US Elections", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper will investigate the literature surrounding cyber security threats\nin the 2020 US Elections. It begins with a brief overview of cyber security and\nthe current state of cyber security regarding elections. In the main body of\nthe paper, the focus will be on the literature review of three main areas:\nvoter suppression, voter fraud, and disinformation, considering their impacts\non the outcome of the election and on the voting public. Having evaluated\nsources on each this paper concludes by summarising the areas which have had\nthe greatest impact on the 2020 US elections.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 14:06:32 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Stedmon", "Nicholas", ""]]}, {"id": "2012.08980", "submitter": "Tong Zhang", "authors": "Tong Zhang and Rui Wang", "title": "Secure Degrees-of-Freedom of the MIMO X Channel with Delayed CSIT", "comments": "Accepted by IEEE WCL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the secure degrees-of-freedom (SDoF) characterization\nfor the multiple-input multiple-output (MIMO) X channel with confidential\nmessages and delayed CSIT. In particular, we propose a transmission scheme,\nwhich can be regarded as a generalization of the state-of-the-art scheme\nwithout security and with delayed CSIT. The key of this generalization is\nperforming the security analysis, by which we derive the optimal duration of\nthe artificial noise transmission phase. As a result, we derive the sum-SDoF\nlower bound. Furthermore, we reveal that if the number of receive antennas,\ndenoted by N, is fixed, the minimum number of transmit antennas achieving the\nmaximum of the lower bound is $\\frac{7+\\sqrt{33}}{8}N$.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 14:20:07 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 04:54:59 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Zhang", "Tong", ""], ["Wang", "Rui", ""]]}, {"id": "2012.09013", "submitter": "Sean Oesch", "authors": "Sean Oesch, Robert Bridges, Jared Smith, Justin Beaver, John Goodall,\n  Kelly Huffer, Craig Miles, Dan Scofield", "title": "An Assessment of the Usability of Machine Learning Based Tools for the\n  Security Operations Center", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Gartner, a large research and advisory company, anticipates that by 2024 80%\nof security operation centers (SOCs) will use machine learning (ML) based\nsolutions to enhance their operations. In light of such widespread adoption, it\nis vital for the research community to identify and address usability concerns.\nThis work presents the results of the first in situ usability assessment of\nML-based tools. With the support of the US Navy, we leveraged the national\ncyber range, a large, air-gapped cyber testbed equipped with state-of-the-art\nnetwork and user emulation capabilities, to study six US Naval SOC analysts'\nusage of two tools. Our analysis identified several serious usability issues,\nincluding multiple violations of established usability heuristics form user\ninterface design. We also discovered that analysts lacked a clear mental model\nof how these tools generate scores, resulting in mistrust and/or misuse of the\ntools themselves. Surprisingly, we found no correlation between analysts' level\nof education or years of experience and their performance with either tool,\nsuggesting that other factors such as prior background knowledge or personality\nplay a significant role in ML-based tool usage. Our findings demonstrate that\nML-based security tool vendors must put a renewed focus on working with\nanalysts, both experienced and inexperienced, to ensure that their systems are\nusable and useful in real-world security operations settings.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 15:17:18 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Oesch", "Sean", ""], ["Bridges", "Robert", ""], ["Smith", "Jared", ""], ["Beaver", "Justin", ""], ["Goodall", "John", ""], ["Huffer", "Kelly", ""], ["Miles", "Craig", ""], ["Scofield", "Dan", ""]]}, {"id": "2012.09116", "submitter": "Pasin Manurangsi", "authors": "Badih Ghazi, Ravi Kumar, Pasin Manurangsi", "title": "On Avoiding the Union Bound When Answering Multiple Differentially\n  Private Queries", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study the problem of answering $k$ queries with $(\\epsilon,\n\\delta)$-differential privacy, where each query has sensitivity one. We give an\nalgorithm for this task that achieves an expected $\\ell_\\infty$ error bound of\n$O(\\frac{1}{\\epsilon}\\sqrt{k \\log \\frac{1}{\\delta}})$, which is known to be\ntight (Steinke and Ullman, 2016).\n  A very recent work by Dagan and Kur (2020) provides a similar result, albeit\nvia a completely different approach. One difference between our work and theirs\nis that our guarantee holds even when $\\delta < 2^{-\\Omega(k/(\\log k)^8)}$\nwhereas theirs does not apply in this case. On the other hand, the algorithm of\nDagan and Kur has a remarkable advantage that the $\\ell_{\\infty}$ error bound\nof $O(\\frac{1}{\\epsilon}\\sqrt{k \\log \\frac{1}{\\delta}})$ holds not only in\nexpectation but always (i.e., with probability one) while we can only get a\nhigh probability (or expected) guarantee on the error.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 17:58:45 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Ghazi", "Badih", ""], ["Kumar", "Ravi", ""], ["Manurangsi", "Pasin", ""]]}, {"id": "2012.09155", "submitter": "Maverick Woo", "authors": "Kaiyuan Li and Maverick Woo and Limin Jia", "title": "On the Generation of Disassembly Ground Truth and the Evaluation of\n  Disassemblers", "comments": "Revised and extended version of our publication that first appeared\n  in the 2020 Workshop on Forming an Ecosystem Around Software Transformation\n  (FEAST '20), November 13, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a software transformation or software security task needs to analyze a\ngiven program binary, the first step is often disassembly. Since many modern\ndisassemblers have become highly accurate on many binaries, we believe reliable\ndisassembler benchmarking requires standardizing the set of binaries used and\nthe disassembly ground truth about these binaries. This paper presents (i) a\nfirst version of our work-in-progress disassembly benchmark suite, which\ncomprises 879 binaries from diverse projects compiled with multiple compilers\nand optimization settings, and (ii) a novel disassembly ground truth generator\nleveraging the notion of \"listing files\", which has broad support by Clang,\nGCC, ICC, and MSVC. In additional, it presents our evaluation of four prominent\nopen-source disassemblers using this benchmark suite and a custom evaluation\nsystem. Our entire system and all generated data are maintained openly on\nGitHub to encourage community adoption.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 20:03:40 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Li", "Kaiyuan", ""], ["Woo", "Maverick", ""], ["Jia", "Limin", ""]]}, {"id": "2012.09163", "submitter": "Fukutomo Nakanishi", "authors": "Fukutomo Nakanishi, Giulio De Pasquale, Daniele Ferla, Lorenzo\n  Cavallaro", "title": "Intertwining ROP Gadgets and Opaque Predicates for Robust Obfuscation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software obfuscation plays a crucial role in protecting intellectual property\nin software from reverse engineering attempts. While some obfuscation\ntechniques originate from the obfuscation-reverse engineering arms race, others\nstem from different research areas, such as binary software exploitation.\n  Return-oriented programming (ROP) gained popularity as one of the most\neffective exploitation techniques for memory error vulnerabilities. ROP\ninterferes with our natural perception of a process control flow, which\nnaturally inspires us to repurpose ROP as a robust and effective form of\nsoftware obfuscation. Although previous work already explores ROP's\neffectiveness as an obfuscation technique, evolving reverse engineering\nresearch raises the need for principled reasoning to understand the strengths\nand limitations of ROP-based mechanisms against man-at-the-end (MATE) attacks.\n  To this end, we propose ROPFuscator, a fine-grained obfuscation framework for\nC/C++ programs using ROP. We incorporate opaque predicates and constants and a\nnovel instruction hiding technique to withstand sophisticated MATE attacks.\nMore importantly, we introduce a realistic and unified threat model to\nthoroughly evaluate ROPFuscator and provide principled reasoning on ROP-based\nobfuscation techniques that answer to code coverage, incurred overhead,\ncorrectness, robustness, and practicality challenges.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 18:58:52 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Nakanishi", "Fukutomo", ""], ["De Pasquale", "Giulio", ""], ["Ferla", "Daniele", ""], ["Cavallaro", "Lorenzo", ""]]}, {"id": "2012.09214", "submitter": "Sean Oesch", "authors": "Robert A. Bridges, Sean Oesch, Miki E. Verma, Michael D. Iannacone,\n  Kelly M.T. Huffer, Brian Jewell, Jeff A. Nichols, Brian Weber, Justin M.\n  Beaver, Jared M. Smith, Daniel Scofield, Craig Miles, Thomas Plummer, Mark\n  Daniell, Anne M. Tall", "title": "Beyond the Hype: A Real-World Evaluation of the Impact and Cost of\n  Machine Learning-Based Malware Detection", "comments": "Includes Actionable Takeaways for SOCs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  There is a lack of scientific testing of commercially available malware\ndetectors, especially those that boast accurate classification of\nnever-before-seen (i.e., zero-day) files using machine learning (ML). The\nresult is that the efficacy and gaps among the available approaches are opaque,\ninhibiting end users from making informed network security decisions and\nresearchers from targeting gaps in current detectors. In this paper, we present\na scientific evaluation of four market-leading malware detection tools to\nassist an organization with two primary questions: (Q1) To what extent do\nML-based tools accurately classify never-before-seen files without sacrificing\ndetection ability on known files? (Q2) Is it worth purchasing a network-level\nmalware detector to complement host-based detection? We tested each tool\nagainst 3,536 total files (2,554 or 72% malicious, 982 or 28% benign) including\nover 400 zero-day malware, and tested with a variety of file types and\nprotocols for delivery. We present statistical results on detection time and\naccuracy, consider complementary analysis (using multiple tools together), and\nprovide two novel applications of a recent cost-benefit evaluation procedure by\nIannaconne & Bridges that incorporates all the above metrics into a single\nquantifiable cost. While the ML-based tools are more effective at detecting\nzero-day files and executables, the signature-based tool may still be an\noverall better option. Both network-based tools provide substantial (simulated)\nsavings when paired with either host tool, yet both show poor detection rates\non protocols other than HTTP or SMTP. Our results show that all four tools have\nnear-perfect precision but alarmingly low recall, especially on file types\nother than executables and office files -- 37% of malware tested, including all\npolyglot files, were undetected.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 19:10:00 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 17:37:15 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Bridges", "Robert A.", ""], ["Oesch", "Sean", ""], ["Verma", "Miki E.", ""], ["Iannacone", "Michael D.", ""], ["Huffer", "Kelly M. T.", ""], ["Jewell", "Brian", ""], ["Nichols", "Jeff A.", ""], ["Weber", "Brian", ""], ["Beaver", "Justin M.", ""], ["Smith", "Jared M.", ""], ["Scofield", "Daniel", ""], ["Miles", "Craig", ""], ["Plummer", "Thomas", ""], ["Daniell", "Mark", ""], ["Tall", "Anne M.", ""]]}, {"id": "2012.09221", "submitter": "Yucel Aydin", "authors": "Yucel Aydin, Gunes Karabulut Kurt, Enver Ozdemir, Halim Yanikomeroglu", "title": "Group Handover for Drone-Mounted Base Stations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread use of new technologies such as the Internet of things (IoT)\nand machine type communication(MTC) forces an increase on the number of user\nequipments(UEs) and MTC devices that are connecting to mobile networks.\nInherently, as the number of UEs inside a base station's (BS) coverage area\nsurges, the quality of service (QoS) tends to decline. The use of drone-mounted\nBS (UxNB) is a solution in places where UEs are densely populated, such as\nstadiums. UxNB emerges as a promising technology that can be used for capacity\ninjection purposes in the future due to its fast deployment. However, this\nemerging technology introduces a new security issue. Mutual authentication,\ncreating a communication channel between terrestrial BS and UxNB, and fast\nhandover operations may cause security issues in the use of UxNB for capacity\ninjection. This new protocol also suggests performing UE handover from\nterrestrial to UxNB as a group. To the best of the authors' knowledge, there is\nno authentication solution between BSs according to LTE and 5G standards. The\nproposed scheme provides a solution for the authentication of UxNB by the\nterrestrial BS. Additionally, a credential sharing phase for each UE in\nhandover is not required in the proposed method. The absence of a credential\nsharing step saves resources by reducing the number of communications between\nBSs. Moreover, many UE handover operations are completed in concise time within\nthe proposed group handover method.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 19:28:48 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 18:07:13 GMT"}, {"version": "v3", "created": "Sun, 21 Mar 2021 09:42:13 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Aydin", "Yucel", ""], ["Kurt", "Gunes Karabulut", ""], ["Ozdemir", "Enver", ""], ["Yanikomeroglu", "Halim", ""]]}, {"id": "2012.09292", "submitter": "Alessio Merlo Prof.", "authors": "Alessio Merlo, Antonio Ruggia, Luigi Sciolla, Luca Verderame", "title": "ARMAND: Anti-Repackaging through Multi-pattern Anti-tampering based on\n  Native Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  App repackaging refers to the practice of customizing an existing mobile app\nand redistributing it in the wild to fool the final user into installing the\nrepackaged app instead of the original one. In this way, an attacker can embed\nmalicious payload into a legitimate app for different aims, such as access to\npremium features, redirect revenue, or access to user's private data. In the\nAndroid ecosystem, apps are available on public stores, and the only\nrequirement for an app to execute properly is to be digitally signed. Due to\nthis, the repackaging threat is widely spread. Anti-repackaging techniques aim\nto make harder the repackaging process for an attack adding logical controls -\ncalled detection node - in the app at compile-time. Such controls check the app\nintegrity at runtime to detect tampering. If tampering is recognized, the\ndetection nodes lead the repackaged app to fail (e.g., throwing an exception).\nFrom an attacker's standpoint, she must detect and bypass all controls to\nrepackage safely. In this work, we propose a novel anti-repackaging scheme -\ncalled ARMAND - which aims to overcome the limitations of the current\nprotection schemes. We have implemented this scheme into a prototype - named\nARMANDroid - which leverages multiple protection patterns and relies on native\ncode. The evaluation phase of ARMANDroid on 30.000 real-world Android apps\nshowed that the scheme is robust against the common attack vectors and\nefficient in terms of time and space overhead.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 22:14:35 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 09:49:19 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Merlo", "Alessio", ""], ["Ruggia", "Antonio", ""], ["Sciolla", "Luigi", ""], ["Verderame", "Luca", ""]]}, {"id": "2012.09344", "submitter": "Bushra Sabir", "authors": "Bushra Sabir, Faheem Ullah, M. Ali Babar and Raj Gaire", "title": "Machine Learning for Detecting Data Exfiltration: A Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Context: Research at the intersection of cybersecurity, Machine Learning\n(ML), and Software Engineering (SE) has recently taken significant steps in\nproposing countermeasures for detecting sophisticated data exfiltration\nattacks. It is important to systematically review and synthesize the ML-based\ndata exfiltration countermeasures for building a body of knowledge on this\nimportant topic. Objective: This paper aims at systematically reviewing\nML-based data exfiltration countermeasures to identify and classify ML\napproaches, feature engineering techniques, evaluation datasets, and\nperformance metrics used for these countermeasures. This review also aims at\nidentifying gaps in research on ML-based data exfiltration countermeasures.\nMethod: We used a Systematic Literature Review (SLR) method to select and\nreview {92} papers. Results: The review has enabled us to (a) classify the ML\napproaches used in the countermeasures into data-driven, and behaviour-driven\napproaches, (b) categorize features into six types: behavioural, content-based,\nstatistical, syntactical, spatial and temporal, (c) classify the evaluation\ndatasets into simulated, synthesized, and real datasets and (d) identify 11\nperformance measures used by these studies. Conclusion: We conclude that: (i)\nthe integration of data-driven and behaviour-driven approaches should be\nexplored; (ii) There is a need of developing high quality and large size\nevaluation datasets; (iii) Incremental ML model training should be incorporated\nin countermeasures; (iv) resilience to adversarial learning should be\nconsidered and explored during the development of countermeasures to avoid\npoisoning attacks; and (v) the use of automated feature engineering should be\nencouraged for efficiently detecting data exfiltration attacks.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 01:05:50 GMT"}, {"version": "v2", "created": "Sun, 21 Mar 2021 23:23:14 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Sabir", "Bushra", ""], ["Ullah", "Faheem", ""], ["Babar", "M. Ali", ""], ["Gaire", "Raj", ""]]}, {"id": "2012.09364", "submitter": "Chaochao Chen", "authors": "Chaochao Chen, Jun Zhou, Longfei Zheng, Yan Wang, Xiaolin Zheng,\n  Bingzhe Wu, Cen Chen, Li Wang, and Jianwei Yin", "title": "Towards Scalable and Privacy-Preserving Deep Neural Network via\n  Algorithmic-Cryptographic Co-design", "comments": "12 pages. arXiv admin note: text overlap with arXiv:2003.05198", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have achieved remarkable progress in various\nreal-world applications, especially when abundant training data are provided.\nHowever, data isolation has become a serious problem currently. Existing works\nbuild privacy preserving DNN models from either algorithmic perspective or\ncryptographic perspective. The former mainly splits the DNN computation graph\nbetween data holders or between data holders and server, which demonstrates\ngood scalability but suffers from accuracy loss and potential privacy risks. In\ncontrast, the latter leverages time-consuming cryptographic techniques, which\nhas strong privacy guarantee but poor scalability. In this paper, we propose\nSPNN - a Scalable and Privacy-preserving deep Neural Network learning\nframework, from algorithmic-cryptographic co-perspective. From algorithmic\nperspective, we split the computation graph of DNN models into two parts, i.e.,\nthe private data related computations that are performed by data holders and\nthe rest heavy computations that are delegated to a server with high\ncomputation ability. From cryptographic perspective, we propose using two types\nof cryptographic techniques, i.e., secret sharing and homomorphic encryption,\nfor the isolated data holders to conduct private data related computations\nprivately and cooperatively. Furthermore, we implement SPNN in a decentralized\nsetting and introduce user-friendly APIs. Experimental results conducted on\nreal-world datasets demonstrate the superiority of SPNN.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 02:26:16 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Chen", "Chaochao", ""], ["Zhou", "Jun", ""], ["Zheng", "Longfei", ""], ["Wang", "Yan", ""], ["Zheng", "Xiaolin", ""], ["Wu", "Bingzhe", ""], ["Chen", "Cen", ""], ["Wang", "Li", ""], ["Yin", "Jianwei", ""]]}, {"id": "2012.09375", "submitter": "Xiang Cheng", "authors": "Xiang Cheng, Hanchao Yang, Archanaa S Krishnan, Patrick Schaumont and\n  Yaling Yang", "title": "KHOVID: Interoperable Privacy Preserving Digital Contact Tracing", "comments": "14 pages, 7 figures. Submitted to a conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During a pandemic, contact tracing is an essential tool to drive down the\ninfection rate within a population. To accelerate the laborious manual contact\ntracing process, digital contact tracing (DCT) tools can track contact events\ntransparently and privately by using the sensing and signaling capabilities of\nthe ubiquitous cell phone. However, an effective DCT must not only preserve\nuser privacy but also augment the existing manual contact tracing process.\nIndeed, not every member of a population may own a cell phone or have a DCT app\ninstalled and enabled. We present KHOVID to fulfill the combined goal of manual\ncontact-tracing interoperability and DCT user privacy. At KHOVID's core is a\nprivacy-friendly mechanism to encode user trajectories using geolocation data.\nManual contact tracing data can be integrated through the same geolocation\nformat. The accuracy of the geolocation data from DCT is improved using\nBluetooth proximity detection, and we propose a novel method to encode\nBluetooth ephemeral IDs. This contribution describes the detailed design of\nKHOVID; presents a prototype implementation including an app and server\nsoftware; and presents a validation based on simulation and field experiments.\nWe also compare the strengths of KHOVID with other, earlier proposals of DCT.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 03:00:53 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Cheng", "Xiang", ""], ["Yang", "Hanchao", ""], ["Krishnan", "Archanaa S", ""], ["Schaumont", "Patrick", ""], ["Yang", "Yaling", ""]]}, {"id": "2012.09593", "submitter": "Chaoqing Tang", "authors": "Chaoqing Tang", "title": "Concurrent Encryption and Authentication for Wireless Networks using\n  Compressed Sensing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Authentication and encryption are traditionally treated as two separate\nprocesses in wireless networks, this paper integrates user authentication into\nthe process of solving eavesdropping attacks. A compressed sensing (CS)-based\nframework is proposed which manipulates the measurement matrix of CS to\nsafeguard secure computationally. The framework is also capable of continuous\nauthentication and transmission error correction and is robust to data loss. In\ndetail, this paper first proposes an algorithm to generate a 2D key which\ndepends on the physical property of communication channels. The 2D key is\nfurther used to generate authentication information and signal structure as\nwell as encrypt original data. Then an encrypted message which contains both\ndata and authentication information is formed for anonymous transmission. The\nlegal receiver can split authentication information and data, and performing a\ndata loss-robust and transmission error-robust authentication and recovery\nstrategy. The framework is evaluated quantitatively using Monte Carlo\nsimulation with simulated sparse signal. The secure transmission performance\nand authentication performance as well as data loss robustness are\ninvestigated. This framework provides an integrated security solution that\nefficiently safeguards the confidential, privacy and robust communication in\ncyber-physical systems, especially in resource-limited and safety-critical\nwireless networks.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 14:06:54 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Tang", "Chaoqing", ""]]}, {"id": "2012.09707", "submitter": "Gursel Serpen", "authors": "Ahsan Al Zaki Khan and Gursel Serpen", "title": "Intrusion Detection and identification System Design and Performance\n  Evaluation for Industrial SCADA Networks", "comments": "24 single-column, double-spaced pages; 1 Figure; and 21 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we present a study that proposes a three-stage classifier\nmodel which employs a machine learning algorithm to develop an intrusion\ndetection and identification system for tens of different types of attacks\nagainst industrial SCADA networks. The machine learning classifier is trained\nand tested on the data generated using the laboratory prototype of a gas\npipeline SCADA network. The dataset consists of three attack groups and seven\ndifferent attack classes or categories. The same dataset further provides\nsignatures of 35 different types of sub-attacks which are related to those\nseven attack classes. The study entailed the design of three-stage machine\nlearning classifier as a misuse intrusion detection system to detect and\nidentify specifically each of the 35 attack subclasses. The first stage of the\nclassifier decides if a record is associated with normal operation or an attack\nsignature. If the record is found to belong to an attack signature, then in the\nsecond stage, it is classified into one of seven attack classes. Based on the\nidentified attack class as determined by the output from the second stage\nclassifier, the attack record is provided for a third stage sub-attack\nclassification, where seven different classifiers are employed. The output from\nthe third stage classifier identifies the sub-attack type to which the record\nbelongs. Simulation results indicate that designs exploring specialization to\ndomains or executing the classification in multiple stages versus single-stage\ndesigns are promising for problems where there are tens of classes. Comparison\nwith studies in the literature also indicated that the multi-stage classifier\nperformed markedly better.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 16:24:09 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Khan", "Ahsan Al Zaki", ""], ["Serpen", "Gursel", ""]]}, {"id": "2012.09775", "submitter": "Fabian Bach", "authors": "Fabian Bach", "title": "Differential privacy and noisy confidentiality concepts for European\n  population statistics", "comments": "37 pages, 7 figures, extended abstract accepted for NTTS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper aims to give an overview of various approaches to statistical\ndisclosure control based on random noise that are currently being discussed for\nofficial population statistics and censuses. A particular focus is on a\nstringent delineation between different concepts influencing the discussion: we\nseparate clearly between risk measures, noise distributions and output\nmechanisms - putting these concepts into scope and into relation with each\nother.\n  After recapitulating differential privacy as a risk measure, the paper also\nremarks on utility and risk aspects of some specific output mechanisms and\nparameter setups, with special attention on static outputs that are rather\ntypical in official population statistics. In particular, it is argued that\nunbounded noise distributions, such as plain Laplace, may jeopardise key unique\ncensus features without a clear need from a risk perspective. On the other\nhand, bounded noise distributions, such as the truncated Laplace or the cell\nkey method, can be set up to keep unique census features while controlling\ndisclosure risks in census-like outputs.\n  Finally, the paper analyses some typical attack scenarios to constrain\ngeneric noise parameter ranges that suggest a good risk/utility compromise for\nthe 2021 EU census output scenario. The analysis also shows that strictly\ndifferentially private mechanisms would be severely constrained in this\nscenario.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 17:34:53 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Bach", "Fabian", ""]]}, {"id": "2012.09919", "submitter": "Marc Schoolderman", "authors": "Marc Schoolderman, Jonathan Moerman, Sjaak Smetsers, Marko van Eekelen", "title": "Efficient Verification of Optimized Code: Correct High-speed X25519", "comments": "19 pages, 5 figures. accepted at NFM 2021 (without appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code that is highly optimized poses a problem for program-level verification:\nprogrammers can employ various clever tricks that are non-trivial to reason\nabout. For cryptography on low-power devices, it is nonetheless crucial that\nimplementations be functionally correct, secure, and efficient. These are\nusually crafted in hand-optimized machine code that eschew conventional control\nflow as much as possible.\n  We have formally verified such code: a library which implements elliptic\ncurve cryptography on 8-bit AVR microcontrollers. The chosen implementation is\nthe most efficient currently known for this microarchitecture. It consists of\nover 3000 lines of assembly instructions. Building on earlier work, we use the\nWhy3 platform to model the code and prove verification conditions, using\nautomated provers. We expect the approach to be re-usable and adaptable, and it\nallows for validation. Furthermore, an error in the original implementation was\nfound and corrected, at the same time reducing its memory footprint. This shows\nthat practical verification of cutting-edge code is not only possible, but can\nin fact add to its efficiency -- and is clearly necessary.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 20:25:58 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 11:07:36 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Schoolderman", "Marc", ""], ["Moerman", "Jonathan", ""], ["Smetsers", "Sjaak", ""], ["van Eekelen", "Marko", ""]]}, {"id": "2012.09950", "submitter": "Rajesh Kumar", "authors": "Rajesh Kumar and Can Isik and Vir V Phoha", "title": "Treadmill Assisted Gait Spoofing (TAGS): An Emerging Threat to wearable\n  Sensor-based Gait Authentication", "comments": "17 pages", "journal-ref": "ACM Journal of Digital Threats: Research and Practice, June 2021", "doi": "10.1145/3442151", "report-no": null, "categories": "cs.CR cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we examine the impact of Treadmill Assisted Gait Spoofing\n(TAGS) on Wearable Sensor-based Gait Authentication (WSGait). We consider more\nrealistic implementation and deployment scenarios than the previous study,\nwhich focused only on the accelerometer sensor and a fixed set of features.\nSpecifically, we consider the situations in which the implementation of WSGait\ncould be using one or more sensors embedded into modern smartphones. Besides,\nit could be using different sets of features or different classification\nalgorithms, or both. Despite the use of a variety of sensors, feature sets\n(ranked by mutual information), and six different classification algorithms,\nTAGS was able to increase the average False Accept Rate (FAR) from 4% to 26%.\nSuch a considerable increase in the average FAR, especially under the stringent\nimplementation and deployment scenarios considered in this study, calls for a\nfurther investigation into the design of evaluations of WSGait before its\ndeployment for public use.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 21:58:41 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Kumar", "Rajesh", ""], ["Isik", "Can", ""], ["Phoha", "Vir V", ""]]}, {"id": "2012.09960", "submitter": "Matthew Bach-Nutman", "authors": "Matthew Bach-Nutman", "title": "Understanding The Top 10 OWASP Vulnerabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Understanding the common vulnerabilities in web applications help businesses\nbe better prepared in protecting their data against such attacks. With the\nknowledge gained from research users and developers can be better equipped to\ndeal with the most common attacks and form solutions to prevent future attacks\nagainst their web applications. Vulnerabilities exist in many forms within\nmodern web applications which can be easily mitigated with investment of time\nand research.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 22:40:04 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Bach-Nutman", "Matthew", ""]]}, {"id": "2012.09987", "submitter": "Ziaur Rahman", "authors": "Anichur Rahman, Md. Jahidul Islam, Ziaur Rahman, Md. Mahfuz Reza,\n  Adnan Anwar, M. A. Parvez Mahmud, Mostofa Kamal Nasir and Rafidah Md Noor", "title": "DistB-Condo: Distributed Blockchain-based IoT-SDN Model for Smart\n  Condominium", "comments": "17 Pages, 12 Tables, 17 Figures", "journal-ref": "EEE Access, vol. 8, pp. 209594-209609, 2020", "doi": "10.1109/ACCESS.2020.3039113", "report-no": null, "categories": "cs.CR cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Condominium network refers to intra-organization networks, where smart\nbuildings or apartments are connected and share resources over the network.\nSecured communication platform or channel has been highlighted as a key\nrequirement for a reliable condominium which can be ensured by the utilization\nof the advanced techniques and platforms like Software-Defined Network (SDN),\nNetwork Function Virtualization (NFV) and Blockchain (BC). These technologies\nprovide a robust, and secured platform to meet all kinds of challenges, such as\nsafety, confidentiality, flexibility, efficiency, and availability. This work\nsuggests a distributed, scalable IoT-SDN with Blockchain-based NFV framework\nfor a smart condominium (DistB-Condo) that can act as an efficient secured\nplatform for a small community. Moreover, the Blockchain-based IoT-SDN with NFV\nframework provides the combined benefits of leading technologies. It also\npresents an optimized Cluster Head Selection (CHS) algorithm for selecting a\nCluster Head (CH) among the clusters that efficiently saves energy. Besides, a\ndecentralized and secured Blockchain approach has been introduced that allows\nmore prominent security and privacy to the desired condominium network. Our\nproposed approach has also the ability to detect attacks in an IoT environment.\nEventually, this article evaluates the performance of the proposed architecture\nusing different parameters (e.g., throughput, packet arrival rate, and response\ntime). The proposed approach outperforms the existing OF-Based SDN. DistB-Condo\nhas better throughput on average, and the bandwidth (Mbps) much higher than the\nOF-Based SDN approach in the presence of attacks. Also, the proposed model has\nan average response time of 5% less than the core model.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 00:32:18 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Rahman", "Anichur", ""], ["Islam", "Md. Jahidul", ""], ["Rahman", "Ziaur", ""], ["Reza", "Md. Mahfuz", ""], ["Anwar", "Adnan", ""], ["Mahmud", "M. A. Parvez", ""], ["Nasir", "Mostofa Kamal", ""], ["Noor", "Rafidah Md", ""]]}, {"id": "2012.10011", "submitter": "Ziaur Rahman", "authors": "Anichur Rahman, Umme Sara, Dipanjali Kundu, Saiful Islam, Md. Jahidul\n  Islam, Mahedi Hasan, Ziaur Rahman and Mostofa Kamal Nasir", "title": "DistB-SDoIndustry: Enhancing Security in Industry 4.0 Services based on\n  Distributed Blockchain through Software Defined Networking-IoT Enabled\n  Architecture", "comments": "8 Pages, 6 Figures", "journal-ref": "IJACSA, 11(9), 2020", "doi": "10.14569/IJACSA.2020.0110980", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The concept of Industry 4.0 is a newly emerging focus of research throughout\nthe world. However, it has lots of challenges to control data, and it can be\naddressed with various technologies like Internet of Things (IoT), Big Data,\nArtificial Intelligence (AI), Software Defined Networking (SDN), and Blockchain\n(BC) for managing data securely. Further, the complexity of sensors,\nappliances, sensor networks connecting to the internet and the model of\nIndustry 4.0 has created the challenge of designing systems, infrastructure and\nsmart applications capable of continuously analyzing the data produced.\nRegarding these, the authors present a distributed Blockchain-based security to\nindustry 4.0 applications with SDN-IoT enabled environment. Where the\nBlockchain can be capable of leading the robust, privacy and confidentiality to\nour desired system. In addition, the SDN-IoT incorporates the different\nservices of industry 4.0 with more security as well as flexibility.\nFurthermore, the authors offer an excellent combination among the technologies\nlike IoT, SDN and Blockchain to improve the security and privacy of Industry\n4.0 services properly. Finally , the authors evaluate performance and security\nin a variety of ways in the presented architecture.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 01:56:54 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Rahman", "Anichur", ""], ["Sara", "Umme", ""], ["Kundu", "Dipanjali", ""], ["Islam", "Saiful", ""], ["Islam", "Md. Jahidul", ""], ["Hasan", "Mahedi", ""], ["Rahman", "Ziaur", ""], ["Nasir", "Mostofa Kamal", ""]]}, {"id": "2012.10049", "submitter": "Puneet Bakshi", "authors": "Puneet Bakshi, Sukumar Nandi", "title": "Privacy Enhanced DigiLocker using Ciphertext-Policy Attribute-Based\n  Encryption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, Government of India has taken several initiatives to make India\ndigitally strong such as to provide each resident a unique digital identity,\nreferred to as Aadhaar, and to provide several online e-Governance services\nbased on Aadhaar such as DigiLocker. DigiLocker is an online service which\nprovides a shareable private storage space on public cloud to its subscribers.\nAlthough DigiLocker ensures traditional security such as data integrity and\nsecure data access, privacy of e-documents are yet to addressed.\nCiphertext-Policy Attribute-Based Encryption (CP-ABE) can improve data privacy\nbut the right implementation of it has always been a challenge. This paper\npresents a scheme to implement privacy enhanced DigiLocker using CP-ABE.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 04:34:42 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Bakshi", "Puneet", ""], ["Nandi", "Sukumar", ""]]}, {"id": "2012.10253", "submitter": "Enis Karaarslan Dr.", "authors": "E. Karaarslan, E.Konacakl{\\i}", "title": "Data Storage in the Decentralized World: Blockchain and Derivatives", "comments": "33 pages, 10 figures", "journal-ref": "In Gulsecen S., Sharma S., Akadal E.(Eds.), Who Runs The World:\n  DATA (pp. 37-69). Istanbul, Istanbul University Press (2020)", "doi": "10.26650/B/ET06.2020.011.03", "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We have entered an era where the importance of decentralized solutions has\nbecome more obvious. Blockchain technology and its derivatives are distributed\nledger technologies that keep the registry of data between peers of a network.\nThis ledger is secured within a successive over looping cryptographic chain.\nThe accomplishment of the Bitcoin cryptocurrency proved that blockchain\ntechnology and its derivatives could be used to eliminate intermediaries and\nprovide security for cyberspace. However, there are some challenges in the\nimplementation of blockchain technology. This chapter first explains the\nconcept of blockchain technology and the data that we can store therein. The\nmain advantage of blockchain is the security services that it provides. This\nsection continues by describing these services.. The challenges of blockchain;\nblockchain anomalies, energy consumption, speed, scalability, interoperability,\nprivacy and cryptology in the age of quantum computing are described. Selected\nsolutions for these challenges are given. Remarkable derivatives of blockchain,\nwhich use different solutions (directed acyclic graph, distributed hash table,\ngossip consensus protocol) to solve some of these challenges are described.\nThen the data storage in blockchain and evolving data solutions are explained.\nThe comparison of decentralized solutions with the lcentralized database\nsystems is given. A multi-platform interoperable scalable architecture (MPISA)\nis proposed. In the conclusion we include the evolution assumptions of data\nstorage in a decentralized world.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 14:09:43 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Karaarslan", "E.", ""], ["Konacakl\u0131", "E.", ""]]}, {"id": "2012.10313", "submitter": "Chris Chhak", "authors": "CHR Chhak, Andrew Tolmach, Sean Anderson", "title": "Towards Formally Verified Compilation of Tag-Based Policy Enforcement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Hardware-assisted reference monitoring is receiving increasing attention as a\nway to improve the security of existing software. One example is the PIPE\narchitecture extension, which attaches metadata tags to register and memory\nvalues and executes tag-based rules at each machine instruction to enforce a\nsoftware-defined security policy. To use PIPE effectively, engineers should be\nable to write security policies in terms of source-level concepts like\nfunctions, local variables, and structured control operators, which are not\nvisible at machine level. It is the job of the compiler to generate PIPE-aware\nmachine code that enforces these source-level policies. The compiler thus\nbecomes part of the monitored system's trusted computing base -- and hence a\nprime candidate for verification.\n  To formalize compiler correctness in this setting, we extend the source\nlanguage semantics with its own form of user-specified tag-based monitoring,\nand show that the compiler preserves that monitoring behavior. The challenges\nof compilation include mapping source-level monitoring policies to\ninstruction-level tag rules, preserving fail-stop behaviors, and satisfying the\nsurprisingly complex preconditions for conventional optimizations. In this\npaper, we describe the design and verification of Tagine, a small prototype\ncompiler that translates a simple tagged WHILE language to a tagged register\ntransfer language and performs simple optimizations. Tagine is based on the\nRTLgen and Deadcode phases of the CompCert compiler, and hence is written and\nverified in Coq. This work is a first step toward verification of a full-scale\ncompiler for a realistic tagged source language.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 15:57:10 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Chhak", "CHR", ""], ["Tolmach", "Andrew", ""], ["Anderson", "Sean", ""]]}, {"id": "2012.10376", "submitter": "Paul Ledger", "authors": "P.D. Ledger and B.A. Wilson and A.A.S. Amad and W.R.B. Lionheart", "title": "Identification of Metallic Objects using Spectral MPT Signatures: Object\n  Characterisation and Invariants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NA math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The early detection of terrorist threats, such as guns and knives, through\nimproved metal detection, has the potential to reduce the number of attacks and\nimprove public safety and security. To achieve this, there is considerable\npotential to use the fields applied and measured by a metal detector to\ndiscriminate between different shapes and different metals since, hidden within\nthe field perturbation, is object characterisation information. The magnetic\npolarizability tensor (MPT) offers an economical characterisation of metallic\nobjects that can be computed for different threat and non-threat objects and\nhas an established theoretical background, which shows that the induced voltage\nis a function of the hidden object's MPT coefficients. In this paper, we\ndescribe the additional characterisation information that measurements of the\ninduced voltage over a range of frequencies offer compared to measurements at a\nsingle frequency. We call such object characterisations its MPT spectral\nsignature. Then, we present a series of alternative rotational invariants for\nthe purpose of classifying hidden objects using MPT spectral signatures.\nFinally, we include examples of computed MPT spectral signature\ncharacterisations of realistic threat and non-threat objects that can be used\nto train machine learning algorithms for classification purposes.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 17:37:54 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Ledger", "P. D.", ""], ["Wilson", "B. A.", ""], ["Amad", "A. A. S.", ""], ["Lionheart", "W. R. B.", ""]]}, {"id": "2012.10431", "submitter": "Elias Gr\\\"unewald", "authors": "Elias Gr\\\"unewald and Frank Pallas", "title": "TILT: A GDPR-Aligned Transparency Information Language and Toolkit for\n  Practical Privacy Engineering", "comments": "Accepted for publication at the ACM Conference on Fairness,\n  Accountability, and Transparency 2021 (ACM FAccT'21). This is a preprint\n  manuscript (authors' own version before final copy-editing)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.FL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present TILT, a transparency information language and\ntoolkit explicitly designed to represent and process transparency information\nin line with the requirements of the GDPR and allowing for a more automated and\nadaptive use of such information than established, legalese data protection\npolicies do.\n  We provide a detailed analysis of transparency obligations from the GDPR to\nidentify the expressiveness required for a formal transparency language\nintended to meet respective legal requirements. In addition, we identify a set\nof further, non-functional requirements that need to be met to foster practical\nadoption in real-world (web) information systems engineering. On this basis, we\nspecify our formal language and present a respective, fully implemented toolkit\naround it. We then evaluate the practical applicability of our language and\ntoolkit and demonstrate the additional prospects it unlocks through two\ndifferent use cases: a) the inter-organizational analysis of personal\ndata-related practices allowing, for instance, to uncover data sharing networks\nbased on explicitly announced transparency information and b) the presentation\nof formally represented transparency information to users through novel, more\ncomprehensible, and potentially adaptive user interfaces, heightening data\nsubjects' actual informedness about data-related practices and, thus, their\nsovereignty.\n  Altogether, our transparency information language and toolkit allow -\ndifferently from previous work - to express transparency information in line\nwith actual legal requirements and practices of modern (web) information\nsystems engineering and thereby pave the way for a multitude of novel\npossibilities to heighten transparency and user sovereignty in practice.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 18:45:04 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Gr\u00fcnewald", "Elias", ""], ["Pallas", "Frank", ""]]}, {"id": "2012.10452", "submitter": "S\\'ebastien Designolle", "authors": "Pouriya Alikhani, Nicolas Brunner, Claude Cr\\'epeau, S\\'ebastien\n  Designolle, Rapha\\\"el Houlmann, Weixu Shi, Hugo Zbinden", "title": "Experimental relativistic zero-knowledge proofs", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Protecting secrets is a key challenge in our contemporary information-based\nera. In common situations, however, revealing secrets appears unavoidable, for\ninstance, when identifying oneself in a bank to retrieve money. In turn, this\nmay have highly undesirable consequences in the unlikely, yet not unrealistic,\ncase where the bank's security gets compromised. This naturally raises the\nquestion of whether disclosing secrets is fundamentally necessary for\nidentifying oneself, or more generally for proving a statement to be correct.\nDevelopments in computer science provide an elegant solution via the concept of\nzero-knowledge proofs: a prover can convince a verifier of the validity of a\ncertain statement without facilitating the elaboration of a proof at all. In\nthis work, we report the experimental realisation of such a zero-knowledge\nprotocol involving two separated verifier-prover pairs. Security is enforced\nvia the physical principle of special relativity, and no computational\nassumption (such as the existence of one-way functions) is required. Our\nimplementation exclusively relies on off-the-shelf equipment and works at both\nshort (60 m) and long distances (400 m) in about one second. This demonstrates\nthe practical potential of multi-prover zero-knowledge protocols, promising for\nidentification tasks and blockchain-based applications such as cryptocurrencies\nor smart contracts.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 19:00:01 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Alikhani", "Pouriya", ""], ["Brunner", "Nicolas", ""], ["Cr\u00e9peau", "Claude", ""], ["Designolle", "S\u00e9bastien", ""], ["Houlmann", "Rapha\u00ebl", ""], ["Shi", "Weixu", ""], ["Zbinden", "Hugo", ""]]}, {"id": "2012.10511", "submitter": "Adam Petz", "authors": "Adam Petz and Perry Alexander", "title": "An Infrastructure for Faithful Execution of Remote Attestation Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Remote attestation is an emerging technology for establishing trust in a\nremote computing system. Copland is a domain-specific language for specifying\nlayered attestation protocols, characterizing attestation-relevant system\nevents, and describing evidence bundling. In this work we formally define and\nverify a Copland Compiler and Copland Virtual Machine for executing Copland\nprotocols. The compiler translates Copland into instructions that are executed\non the virtual machine. The compiler and virtual machine are implemented as\nmonadic, functional programs in the Coq proof assistant and verified with\nrespect to the Copland event and evidence semantics. In addition we introduce\nthe Attestation Manager Monad as an environment for managing Copland term\nexecution providing support for managing nonces, binding results of Copland\nprotocols to variables, and appraising evidence results.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 20:57:34 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Petz", "Adam", ""], ["Alexander", "Perry", ""]]}, {"id": "2012.10523", "submitter": "Staal Vinterbo PhD", "authors": "Staal A. Vinterbo", "title": "A closed form scale bound for the $(\\epsilon, \\delta)$-differentially\n  private Gaussian Mechanism valid for all privacy regimes", "comments": "11 pages. Version 2 improves on the bound", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard closed form lower bound on $\\sigma$ for providing $(\\epsilon,\n\\delta)$-differential privacy by adding zero mean Gaussian noise with variance\n$\\sigma^2$ is $\\sigma > \\Delta\\sqrt {2}(\\epsilon^{-1}) \\sqrt {\\log \\left(\n5/4\\delta^{-1} \\right)}$ for $\\epsilon \\in (0,1)$. We present a similar closed\nform bound $\\sigma \\geq \\Delta (\\epsilon\\sqrt{2})^{-1} \\left(\\sqrt{az+\\epsilon}\n+ s\\sqrt{az}\\right)$ for $z=-\\log(4\\delta(1-\\delta))$ and $(a,s)=(1,1)$ if\n$\\delta \\leq 1/2$ and $(a,s)=(\\pi/4,-1)$ otherwise. Our bound is valid for all\n$\\epsilon > 0$ and is always lower (better). We also present a sufficient\ncondition for $(\\epsilon, \\delta)$-differential privacy when adding noise\ndistributed according to even and log-concave densities supported everywhere.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 21:35:26 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 14:01:55 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Vinterbo", "Staal A.", ""]]}, {"id": "2012.10534", "submitter": "Md. Monowar Anjum", "authors": "Md. Monowar Anjum, Noman Mohammed", "title": "PAARS: Privacy Aware Access Regulation System", "comments": "Published in 11th IEEE UEMCON 2020, NY, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  During pandemics, health officials usually recommend access monitoring and\nregulation protocols/systems in places that are major activity centres. As\norganizations adhere to those recommendations, they often fail to implement\nproper privacy requirements to prevent privacy loss of the users of those\nprotocols or systems. This is a very timely issue as health authorities across\nthe world are increasingly putting these regulations in place to mitigate the\nspread of the current pandemic. A number of solutions have been proposed to\nmitigate these privacy issues existing in current models of contact tracing or\naccess regulations systems. However, a prevalent pattern among these solutions\nare they mainly focus on protecting users privacy from server side and involve\nBluetooth based ephemeral identifier exchange between users. Another pattern is\nall the current solutions try to solve the problem in city-wide or nation-wide\nlevel. In this paper, we propose a system, PAARS, which approaches the privacy\nissues in access monitoring/regulation systems from a micro level. We solve the\nprivacy issues in access monitoring/regulation systems without any exchange of\nany ephemeral identifiers between users. Moreover, our proposed system provides\nprivacy on both server side and the user side by using secure hashing and\ndifferential privacy mechanism.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 21:54:58 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Anjum", "Md. Monowar", ""], ["Mohammed", "Noman", ""]]}, {"id": "2012.10544", "submitter": "Micah Goldblum", "authors": "Micah Goldblum, Dimitris Tsipras, Chulin Xie, Xinyun Chen, Avi\n  Schwarzschild, Dawn Song, Aleksander Madry, Bo Li, Tom Goldstein", "title": "Dataset Security for Machine Learning: Data Poisoning, Backdoor Attacks,\n  and Defenses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As machine learning systems grow in scale, so do their training data\nrequirements, forcing practitioners to automate and outsource the curation of\ntraining data in order to achieve state-of-the-art performance. The absence of\ntrustworthy human supervision over the data collection process exposes\norganizations to security vulnerabilities; training data can be manipulated to\ncontrol and degrade the downstream behaviors of learned models. The goal of\nthis work is to systematically categorize and discuss a wide range of dataset\nvulnerabilities and exploits, approaches for defending against these threats,\nand an array of open problems in this space. In addition to describing various\npoisoning and backdoor threat models and the relationships among them, we\ndevelop their unified taxonomy.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 22:38:47 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 03:03:30 GMT"}, {"version": "v3", "created": "Sun, 28 Mar 2021 19:01:07 GMT"}, {"version": "v4", "created": "Wed, 31 Mar 2021 22:21:34 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Goldblum", "Micah", ""], ["Tsipras", "Dimitris", ""], ["Xie", "Chulin", ""], ["Chen", "Xinyun", ""], ["Schwarzschild", "Avi", ""], ["Song", "Dawn", ""], ["Madry", "Aleksander", ""], ["Li", "Bo", ""], ["Goldstein", "Tom", ""]]}, {"id": "2012.10547", "submitter": "Runhua Xu", "authors": "Runhua Xu, James Joshi and Chao Li", "title": "NN-EMD: Efficiently Training Neural Networks using Encrypted\n  Multi-Sourced Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Training a machine learning model over an encrypted dataset is an existing\npromising approach to address the privacy-preserving machine learning task,\nhowever, it is extremely challenging to efficiently train a deep neural network\n(DNN) model over encrypted data for two reasons: first, it requires large-scale\ncomputation over huge datasets; second, the existing solutions for computation\nover encrypted data, such as homomorphic encryption, is inefficient. Further,\nfor an enhanced performance of a DNN model, we also need to use huge training\ndatasets composed of data from multiple data sources that may not have\npre-established trust relationships among each other. We propose a novel\nframework, NN-EMD, to train DNN over multiple encrypted datasets collected from\nmultiple sources. Toward this, we propose a set of secure computation protocols\nusing hybrid functional encryption schemes. We evaluate our framework for\nperformance with regards to the training time and model accuracy on the MNIST\ndatasets. Compared to other existing frameworks, our proposed NN-EMD framework\ncan significantly reduce the training time, while providing comparable model\naccuracy and privacy guarantees as well as supporting multiple data sources.\nFurthermore, the depth and complexity of neural networks do not affect the\ntraining time despite introducing a privacy-preserving NN-EMD setting.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 23:01:20 GMT"}, {"version": "v2", "created": "Sun, 18 Apr 2021 00:49:07 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Xu", "Runhua", ""], ["Joshi", "James", ""], ["Li", "Chao", ""]]}, {"id": "2012.10563", "submitter": "Takeshi Miyamae", "authors": "Takeshi Miyamae, Kanta Matsuura", "title": "Privacy Analysis and Evaluation Policy of Blockchain-based Anonymous\n  Cryptocurrencies", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In blockchain-based anonymous cryptocurrencies, due to their\ntamper-resistance and transparency characteristics, transaction data are\ninitially required to be anonymous, with the help of various cryptographic\ntechniques, e.g., commitment schemes and zero-knowledge proofs. Also,\ncryptocurrencies are different from existing anonymous messaging protocols\nregarding the software architecture and the underlying security model. Due to\nthese differences, the sense of anonymity must be specifically defined for\nanonymous cryptocurrencies, and the anonymity in each anonymous cryptocurrency\nmust be analyzed and evaluated based on the specific architecture model. In\nthis paper, we first propose a specific architecture model with three software\nlayers to anonymous cryptocurrencies. Next, we introduce definitions of\nfundamental privacy properties (Pfitzmann's anonymity, unlinkability, and\npseudonymity) and comprehensively analyze each privacy property for each\narchitecture layer of anonymous cryptocurrencies to establish a privacy\nevaluation policy for anonymous cryptocurrencies. Finally, we fairly compare\nthe privacy of current leading anonymous cryptocurrencies (e.g., Zerocash,\nCryptoNote, and Mimblewimble) using the privacy evaluation policy.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 01:00:38 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Miyamae", "Takeshi", ""], ["Matsuura", "Kanta", ""]]}, {"id": "2012.10566", "submitter": "Jiasi Weng", "authors": "Jiasi Weng, Jian Weng, Hongwei Huang, Chengjun Cai, and Cong Wang", "title": "FedServing: A Federated Prediction Serving Framework Based on Incentive\n  Mechanism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data holders, such as mobile apps, hospitals and banks, are capable of\ntraining machine learning (ML) models and enjoy many intelligence services. To\nbenefit more individuals lacking data and models, a convenient approach is\nneeded which enables the trained models from various sources for prediction\nserving, but it has yet to truly take off considering three issues: (i)\nincentivizing prediction truthfulness; (ii) boosting prediction accuracy; (iii)\nprotecting model privacy.\n  We design FedServing, a federated prediction serving framework, achieving the\nthree issues. First, we customize an incentive mechanism based on Bayesian game\ntheory which ensures that joining providers at a Bayesian Nash Equilibrium will\nprovide truthful (not meaningless) predictions. Second, working jointly with\nthe incentive mechanism, we employ truth discovery algorithms to aggregate\ntruthful but possibly inaccurate predictions for boosting prediction accuracy.\nThird, providers can locally deploy their models and their predictions are\nsecurely aggregated inside TEEs. Attractively, our design supports popular\nprediction formats, including top-1 label, ranked labels and posterior\nprobability. Besides, blockchain is employed as a complementary component to\nenforce exchange fairness. By conducting extensive experiments, we validate the\nexpected properties of our design. We also empirically demonstrate that\nFedServing reduces the risk of certain membership inference attack.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 01:06:11 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Weng", "Jiasi", ""], ["Weng", "Jian", ""], ["Huang", "Hongwei", ""], ["Cai", "Chengjun", ""], ["Wang", "Cong", ""]]}, {"id": "2012.10576", "submitter": "Ahmet Kurt", "authors": "Ahmet Kurt, Suat Mercan, Enes Erdin, Kemal Akkaya", "title": "Enabling Micro-payments on IoT Devices using Bitcoin Lightning Network", "comments": "To be published at 2021 IEEE ICBC in Poster Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Lightning Network (LN) addresses the scalability problem of Bitcoin by\nleveraging off-chain transactions. Nevertheless, it is not possible to run LN\non resource-constrained IoT devices due to its storage, memory, and processing\nrequirements. Therefore, in this paper, we propose an efficient and secure\nprotocol that enables an IoT device to use LN's functions through a gateway LN\nnode. The idea is to involve the IoT device in LN operations with its digital\nsignature by replacing original 2-of-2 multisignature channels with 3-of-3\nmultisignature channels. Our protocol enforces the LN gateway to request the\nIoT device's cryptographic signature for all operations on the channel. We\nevaluated the proposed protocol by implementing it on a Raspberry Pi for a toll\npayment scenario and demonstrated its feasibility and security.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 02:15:06 GMT"}, {"version": "v2", "created": "Sat, 13 Mar 2021 04:43:23 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Kurt", "Ahmet", ""], ["Mercan", "Suat", ""], ["Erdin", "Enes", ""], ["Akkaya", "Kemal", ""]]}, {"id": "2012.10602", "submitter": "Kaiwen Wang", "authors": "Kaiwen Wang, Travis Dick, Maria-Florina Balcan", "title": "Scalable and Provably Accurate Algorithms for Differentially Private\n  Distributed Decision Tree Learning", "comments": "In AAAI Workshop on Privacy-Preserving Artificial Intelligence, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces the first provably accurate algorithms for\ndifferentially private, top-down decision tree learning in the distributed\nsetting (Balcan et al., 2012). We propose DP-TopDown, a general privacy\npreserving decision tree learning algorithm, and present two distributed\nimplementations. Our first method NoisyCounts naturally extends the single\nmachine algorithm by using the Laplace mechanism. Our second method LocalRNM\nsignificantly reduces communication and added noise by performing local\noptimization at each data holder. We provide the first utility guarantees for\ndifferentially private top-down decision tree learning in both the single\nmachine and distributed settings. These guarantees show that the error of the\nprivately-learned decision tree quickly goes to zero provided that the dataset\nis sufficiently large. Our extensive experiments on real datasets illustrate\nthe trade-offs of privacy, accuracy and generalization when learning private\ndecision trees in the distributed setting.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 06:09:36 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 00:43:22 GMT"}, {"version": "v3", "created": "Tue, 23 Feb 2021 03:24:20 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Wang", "Kaiwen", ""], ["Dick", "Travis", ""], ["Balcan", "Maria-Florina", ""]]}, {"id": "2012.10681", "submitter": "Jun Zhao", "authors": "Feng Li, Kwok-Yan Lam, Min Jia, Jun Zhao, Xiuhua Li, Li Wang", "title": "Blockchain-Based Approach for Securing Spectrum Trading in Multibeam\n  Satellite Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a blockchain-based approach for securing spectrum sharing\nin multi-beam satellite systems. Satellite spectrum is a scarce resource that\nrequires highly efficient management schemes for optimized sharing by network\nusers. However, spectrum sharing is vulnerable to attacks by malicious protocol\nparticipants. In order to ensure efficient spectrum management in the face of\ndishonest satellite users or cyber attackers, it is important for spectrum\nsharing mechanism to provide transparency and traceability of the trading\nprocess so as to enable the system to detect, and hence eliminate, unauthorized\naccess by malicious users. We address these requirements by proposing the use\nof blockchain which, apart from its ability to provide transparency and\ntraceability, ensures an immutable means for keeping track of user trading\nreputation. Besides, in order to address the practical constraints of\nheterogeneous user nodes, we also propose the use of edge computing to support\nusers with limited computing power. In this paper, we propose a\nblockchain-based spectrum trading framework and, based on which, a multibeam\nsatellite spectrum sharing algorithm for interference pricing and heterogeneous\nspectrum demands is devised to improve the efficiency of satellite spectrum. By\nleveraging on the system characteristics of blockchain, a dynamic spectrum\nsharing mechanism with traceability, openness and transparency for whole\ntrading process is presented. Numerical results are also provided to evaluate\nthe system benefits and spectrum pricing of the proposed mechanism.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 13:12:08 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Li", "Feng", ""], ["Lam", "Kwok-Yan", ""], ["Jia", "Min", ""], ["Zhao", "Jun", ""], ["Li", "Xiuhua", ""], ["Wang", "Li", ""]]}, {"id": "2012.10692", "submitter": "Xin Jin", "authors": "Xin Jin, Hongyu Zhang, Xiaodong Li, Haoyang Yu, Beisheng Liu, Shujiang\n  Xie, Amit Kumar Singh and Yujie Li", "title": "Confused Modulo Projection based Somewhat Homomorphic Encryption --\n  Cryptosystem, Library and Applications on Secure Smart Cities", "comments": "IEEE Internet of Things Journal (IOTJ), Published Online: 7 August\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the development of cloud computing, the storage and processing of\nmassive visual media data has gradually transferred to the cloud server. For\nexample, if the intelligent video monitoring system cannot process a large\namount of data locally, the data will be uploaded to the cloud. Therefore, how\nto process data in the cloud without exposing the original data has become an\nimportant research topic. We propose a single-server version of somewhat\nhomomorphic encryption cryptosystem based on confused modulo projection theorem\nnamed CMP-SWHE, which allows the server to complete blind data processing\nwithout \\emph{seeing} the effective information of user data. On the client\nside, the original data is encrypted by amplification, randomization, and\nsetting confusing redundancy. Operating on the encrypted data on the server\nside is equivalent to operating on the original data. As an extension, we\ndesigned and implemented a blind computing scheme of accelerated version based\non batch processing technology to improve efficiency. To make this algorithm\neasy to use, we also designed and implemented an efficient general blind\ncomputing library based on CMP-SWHE. We have applied this library to foreground\nextraction, optical flow tracking and object detection with satisfactory\nresults, which are helpful for building smart cities. We also discuss how to\nextend the algorithm to deep learning applications. Compared with other\nhomomorphic encryption cryptosystems and libraries, the results show that our\nmethod has obvious advantages in computing efficiency. Although our algorithm\nhas some tiny errors ($10^{-6}$) when the data is too large, it is very\nefficient and practical, especially suitable for blind image and video\nprocessing.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 14:20:56 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Jin", "Xin", ""], ["Zhang", "Hongyu", ""], ["Li", "Xiaodong", ""], ["Yu", "Haoyang", ""], ["Liu", "Beisheng", ""], ["Xie", "Shujiang", ""], ["Singh", "Amit Kumar", ""], ["Li", "Yujie", ""]]}, {"id": "2012.10825", "submitter": "Majid Khabbazian", "authors": "Sonbol Rahimpour and Majid Khabbazian", "title": "Hashcashed Reputation with Application in Designing Watchtowers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel reputation system to stimulate well-behaviour, and\ncompetition in online markets. Our reputation system is suited for markets\nwhere a publicly-verifiable \"proof-of-misbehaviour\" can be generated when one\nparty misbehaves. Such markets include those that provide blockchain services,\nsuch as monitoring services by watchtowers. Watchtowers are entities that watch\nthe blockchain on behalf of their offline clients to protect the clients'\ninterests in applications such as payment networks (e.g., the Lightning\nnetwork). In practice, there is no trust between clients and watchtowers, and\nit is challenging to incentivize watchtowers to well-behave (e.g., to refuse\nbribery). To showcase our reputation system, in this work, we create an open\nmarket of watchtowers, where watchtowers are motivated to not only deliver\ntheir promised service but also reduce their service fees in competition with\neach other.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2020 01:46:29 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Rahimpour", "Sonbol", ""], ["Khabbazian", "Majid", ""]]}, {"id": "2012.10831", "submitter": "Susie Xi Rao", "authors": "Susie Xi Rao, Shuai Zhang, Zhichao Han, Zitao Zhang, Wei Min, Mo\n  Cheng, Yinan Shan, Yang Zhao, Ce Zhang", "title": "Suspicious Massive Registration Detection via Dynamic Heterogeneous\n  Graph Neural Networks", "comments": "8 pages, 1 figure, accepted in the AAAI Workshop on Deep Learning on\n  Graphs 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Massive account registration has raised concerns on risk management in\ne-commerce companies, especially when registration increases rapidly within a\nshort time frame. To monitor these registrations constantly and minimize the\npotential loss they might incur, detecting massive registration and predicting\ntheir riskiness are necessary. In this paper, we propose a Dynamic\nHeterogeneous Graph Neural Network framework to capture suspicious massive\nregistrations (DHGReg). We first construct a dynamic heterogeneous graph from\nthe registration data, which is composed of a structural subgraph and a\ntemporal subgraph. Then, we design an efficient architecture to predict\nsuspicious/benign accounts. Our proposed model outperforms the baseline models\nand is computationally efficient in processing a dynamic heterogeneous graph\nconstructed from a real-world dataset. In practice, the DHGReg framework would\nbenefit the detection of suspicious registration behaviors at an early stage.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2020 02:39:32 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Rao", "Susie Xi", ""], ["Zhang", "Shuai", ""], ["Han", "Zhichao", ""], ["Zhang", "Zitao", ""], ["Min", "Wei", ""], ["Cheng", "Mo", ""], ["Shan", "Yinan", ""], ["Zhao", "Yang", ""], ["Zhang", "Ce", ""]]}, {"id": "2012.10832", "submitter": "AmirMahdi Sadeghzadeh", "authors": "Amir Mahdi Sadeghzadeh, Behrad Tajali, and Rasool Jalili", "title": "AWA: Adversarial Website Adaptation", "comments": "15 pages, 7 figures, and 2 tables. Accepted in IEEE Transactions on\n  Information Forensics and Security (TIFS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most important obligations of privacy-enhancing technologies is to\nbring confidentiality and privacy to users' browsing activities on the\nInternet. The website fingerprinting attack enables a local passive\neavesdropper to predict the target user's browsing activities even she uses\nanonymous technologies, such as VPNs, IPsec, and Tor. Recently, the growth of\ndeep learning empowers adversaries to conduct the website fingerprinting attack\nwith higher accuracy. In this paper, we propose a new defense against website\nfingerprinting attack using adversarial deep learning approaches called\nAdversarial Website Adaptation (AWA). AWA creates a transformer set in each run\nso that each website has a unique transformer. Each transformer generates\nadversarial traces to evade the adversary's classifier. AWA has two versions,\nincluding Universal AWA (UAWA) and Non-Universal AWA (NUAWA). Unlike NUAWA,\nthere is no need to access the entire trace of a website in order to generate\nan adversarial trace in UAWA. We accommodate secret random elements in the\ntraining phase of transformers in order for AWA to generate various sets of\ntransformers in each run. We run AWA several times and create multiple sets of\ntransformers. If an adversary and a target user select different sets of\ntransformers, the accuracy of adversary's classifier is almost 19.52% and\n31.94% with almost 22.28% and 26.28% bandwidth overhead in UAWA and NUAWA,\nrespectively. If a more powerful adversary generates adversarial traces through\nmultiple sets of transformers and trains a classifier on them, the accuracy of\nadversary's classifier is almost 49.10% and 25.93% with almost 62.52% and\n64.33% bandwidth overhead in UAWA and NUAW, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2020 03:00:10 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 16:20:20 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Sadeghzadeh", "Amir Mahdi", ""], ["Tajali", "Behrad", ""], ["Jalili", "Rasool", ""]]}, {"id": "2012.10876", "submitter": "Vahid Jahandideh", "authors": "Vahid Jahandideh, Amir Daneshgar, Mahmoud Salmasizadeh", "title": "Concrete Evaluation of the Random Probing Security", "comments": "V. Jahandideh had an issue with his affiliation, and the other two\n  did not want to be part of the project", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study masked implementation's security when an adversary randomly probes\neach of its internal variables, intending to recover non-trivial knowledge\nabout its secrets. We introduce a novel metric called Secret Recovery\nProbability (SRP) for assessing the informativeness of the probing leakages\nabout the masked secrets. To evaluate SRP, our starting point is to describe\nthe relations of the intermediate variables with a parity equation system where\nthe target secret is an unknown of this system ...\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2020 09:30:56 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 09:05:30 GMT"}, {"version": "v3", "created": "Fri, 21 May 2021 19:19:23 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Jahandideh", "Vahid", ""], ["Daneshgar", "Amir", ""], ["Salmasizadeh", "Mahmoud", ""]]}, {"id": "2012.11035", "submitter": "Shahab Asoodeh", "authors": "Shahab Asoodeh, Mario Diaz, and Flavio P. Calmon", "title": "Privacy Analysis of Online Learning Algorithms via Contraction\n  Coefficients", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.LG math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose an information-theoretic technique for analyzing privacy\nguarantees of online algorithms. Specifically, we demonstrate that differential\nprivacy guarantees of iterative algorithms can be determined by a direct\napplication of contraction coefficients derived from strong data processing\ninequalities for $f$-divergences. Our technique relies on generalizing the\nDobrushin's contraction coefficient for total variation distance to an\n$f$-divergence known as $E_\\gamma$-divergence. $E_\\gamma$-divergence, in turn,\nis equivalent to approximate differential privacy. As an example, we apply our\ntechnique to derive the differential privacy parameters of gradient descent.\nMoreover, we also show that this framework can be tailored to batch learning\nalgorithms that can be implemented with one pass over the training dataset.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2020 22:02:15 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Asoodeh", "Shahab", ""], ["Diaz", "Mario", ""], ["Calmon", "Flavio P.", ""]]}, {"id": "2012.11072", "submitter": "Ryan Jahnige", "authors": "Ananth Vishnu Bhaskar, Ankit Baingane, Ryan Jahnige, Qingquan Zhang,\n  Ting Zhu", "title": "A Secured Protocol for IoT Networks", "comments": "Implementation was never carrier out with the proposed algorithms.\n  The implementation discussed is based on earlier algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers in the past have shown that Symmetric key cryptography is\ngenerally considered infeasible and public key cryptography, at times, fails to\nprovide sufficient security and integrity to data. In contrast to this\nprejudice, our paper presents a novel approach that establishes security to\ndata through encryption techniques like RSA and more importantly it identifies\na randomized path to route messages from source to the destination and ensures\nthat packets are delivered safely even when intermediate nodes are attacked by\nidentifying alternate paths between source and the destination.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 01:25:42 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 22:20:21 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Bhaskar", "Ananth Vishnu", ""], ["Baingane", "Ankit", ""], ["Jahnige", "Ryan", ""], ["Zhang", "Qingquan", ""], ["Zhu", "Ting", ""]]}, {"id": "2012.11097", "submitter": "Yi Ding", "authors": "Yi Ding, Fuyuan Tan, Zhen Qin, Mingsheng Cao, Kim-Kwang Raymond Choo\n  and Zhiguang Qin", "title": "DeepKeyGen: A Deep Learning-based Stream Cipher Generator for Medical\n  Image Encryption and Decryption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for medical image encryption is increasingly pronounced, for example\nto safeguard the privacy of the patients' medical imaging data. In this paper,\na novel deep learning-based key generation network (DeepKeyGen) is proposed as\na stream cipher generator to generate the private key, which can then be used\nfor encrypting and decrypting of medical images. In DeepKeyGen, the generative\nadversarial network (GAN) is adopted as the learning network to generate the\nprivate key. Furthermore, the transformation domain (that represents the\n\"style\" of the private key to be generated) is designed to guide the learning\nnetwork to realize the private key generation process. The goal of DeepKeyGen\nis to learn the mapping relationship of how to transfer the initial image to\nthe private key. We evaluate DeepKeyGen using three datasets, namely: the\nMontgomery County chest X-ray dataset, the Ultrasonic Brachial Plexus dataset,\nand the BraTS18 dataset. The evaluation findings and security analysis show\nthat the proposed key generation network can achieve a high-level security in\ngenerating the private key.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 03:21:59 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Ding", "Yi", ""], ["Tan", "Fuyuan", ""], ["Qin", "Zhen", ""], ["Cao", "Mingsheng", ""], ["Choo", "Kim-Kwang Raymond", ""], ["Qin", "Zhiguang", ""]]}, {"id": "2012.11182", "submitter": "Andrea Fioraldi", "authors": "Andrea Fioraldi", "title": "Program State Abstraction for Feedback-Driven Fuzz Testing using Likely\n  Invariants", "comments": "This is a Master Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fuzz testing proved its great effectiveness in finding software bugs in the\nlatest years, however, there are still open challenges. Coverage-guided fuzzers\nsuffer from the fact that covering a program point does not ensure the trigger\nof a fault. Other more sensitive techniques that in theory should cope with\nthis problem, such as the coverage of the memory values, easily lead to path\nexplosion. In this thesis, we propose a new feedback for Feedback-driven Fuzz\ntesting that combines code coverage with the \"shape\" of the data. We learn\nlikely invariants for each basic block in order to divide into regions the\nspace described by the variables used in the block. The goal is to distinguish\nin the feedback when a block is executed with values that fall in different\nregions of the space. This better approximates the program state coverage and,\non some targets, improves the ability of the fuzzer in finding faults. We\ndeveloped a prototype using LLVM and AFL++ called InvsCov.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 08:49:25 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Fioraldi", "Andrea", ""]]}, {"id": "2012.11206", "submitter": "Reza Malekian Ph.D.", "authors": "Nikheel Soni, Reza Malekian, Arnav Thakur", "title": "Edge Computing in Transportation: Security Issues and Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As the amount of data that needs to be processed in real-time due to recent\napplication developments increase, the need for a new computing paradigm is\nrequired. Edge computing resolves this issue by offloading computing resources\nrequired by intelligent transportation systems such as the Internet of Vehicles\nfrom the cloud closer to the end devices to improve performance however, it is\nsusceptible to security issues that make the transportation systems vulnerable\nto attackers. In addition to this, there are security issues in transportation\ntechnologies that impact the edge computing paradigm as well. This paper\npresents some of the main security issues and challenges that are present in\nedge computing, which are Distributed Denial of Service attacks, side channel\nattacks, malware injection attacks and authentication and authorization\nattacks, how these impact intelligent transportation systems and research being\ndone to help realize and mitigate these issues.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 09:41:05 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Soni", "Nikheel", ""], ["Malekian", "Reza", ""], ["Thakur", "Arnav", ""]]}, {"id": "2012.11207", "submitter": "Zhengyu Zhao", "authors": "Zhengyu Zhao, Zhuoran Liu, Martha Larson", "title": "On Success and Simplicity: A Second Look at Transferable Targeted\n  Attacks", "comments": "Code available at https://github.com/ZhengyuZhao/Targeted-Tansfer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Achieving transferability of targeted attacks is reputed to be remarkably\ndifficult. Currently, state-of-the-art approaches are resource-intensive\nbecause they necessitate training model(s) for each target class with\nadditional data. In our investigation, we find, however, that simple\ntransferable attacks which require neither additional data nor model training\ncan achieve surprisingly high targeted transferability. This insight has been\noverlooked until now, mainly due to the widespread practice of unreasonably\nrestricting attack optimization to a limited number of iterations. In\nparticular, we, for the first time, identify that a simple logit loss can yield\ncompetitive results with the state of the arts. Our analysis spans a variety of\ntransfer settings, especially including three new, realistic settings: an\nensemble transfer setting with little model similarity, a worse-case setting\nwith low-ranked target classes, and also a real-world attack against the Google\nCloud Vision API. Results in these new settings demonstrate that the commonly\nadopted, easy settings cannot fully reveal the actual properties of different\nattacks and may cause misleading comparisons. We also show the usefulness of\nthe simple logit loss for generating targeted universal adversarial\nperturbations in a data-free and training-free manner. Overall, the aim of our\nanalysis is to inspire a more meaningful evaluation on targeted\ntransferability.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 09:41:29 GMT"}, {"version": "v2", "created": "Sat, 6 Feb 2021 15:18:35 GMT"}, {"version": "v3", "created": "Fri, 28 May 2021 20:50:00 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Zhao", "Zhengyu", ""], ["Liu", "Zhuoran", ""], ["Larson", "Martha", ""]]}, {"id": "2012.11223", "submitter": "Lucas Carvalho Cordeiro", "authors": "Kaled M. Alshmrany, Rafael S. Menezes, Mikhail R. Gadelha, and Lucas\n  C. Cordeiro", "title": "FuSeBMC: A White-Box Fuzzer for Finding Security Vulnerabilities in C\n  Programs", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe and evaluate a novel white-box fuzzer for C programs named\nFuSeBMC, which combines fuzzing and symbolic execution, and applies Bounded\nModel Checking (BMC) to find security vulnerabilities in C programs. FuSeBMC\nexplores and analyzes C programs (1) to find execution paths that lead to\nproperty violations and (2) to incrementally inject labels to guide the fuzzer\nand the BMC engine to produce test-cases for code coverage. FuSeBMC\nsuccessfully participates in Test-Comp'21 and achieves first place in the\nCover-Error category and second place in the Overall category.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 10:07:20 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Alshmrany", "Kaled M.", ""], ["Menezes", "Rafael S.", ""], ["Gadelha", "Mikhail R.", ""], ["Cordeiro", "Lucas C.", ""]]}, {"id": "2012.11325", "submitter": "Abdallah Moubayed", "authors": "MohammadNoor Injadat and Abdallah Moubayed and Abdallah Shami", "title": "Detecting Botnet Attacks in IoT Environments: An Optimized Machine\n  Learning Approach", "comments": "4 pages, 2 figures, 1 table, Accepted and presented at IEEE 32nd\n  International Conference on Microelectronics (IEEE-ICM2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increased reliance on the Internet and the corresponding surge in\nconnectivity demand has led to a significant growth in Internet-of-Things (IoT)\ndevices. The continued deployment of IoT devices has in turn led to an increase\nin network attacks due to the larger number of potential attack surfaces as\nillustrated by the recent reports that IoT malware attacks increased by 215.7%\nfrom 10.3 million in 2017 to 32.7 million in 2018. This illustrates the\nincreased vulnerability and susceptibility of IoT devices and networks.\nTherefore, there is a need for proper effective and efficient attack detection\nand mitigation techniques in such environments. Machine learning (ML) has\nemerged as one potential solution due to the abundance of data generated and\navailable for IoT devices and networks. Hence, they have significant potential\nto be adopted for intrusion detection for IoT environments. To that end, this\npaper proposes an optimized ML-based framework consisting of a combination of\nBayesian optimization Gaussian Process (BO-GP) algorithm and decision tree (DT)\nclassification model to detect attacks on IoT devices in an effective and\nefficient manner. The performance of the proposed framework is evaluated using\nthe Bot-IoT-2018 dataset. Experimental results show that the proposed optimized\nframework has a high detection accuracy, precision, recall, and F-score,\nhighlighting its effectiveness and robustness for the detection of botnet\nattacks in IoT environments.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 16:39:55 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Injadat", "MohammadNoor", ""], ["Moubayed", "Abdallah", ""], ["Shami", "Abdallah", ""]]}, {"id": "2012.11326", "submitter": "Abdallah Moubayed", "authors": "Abdallah Moubayed and MohammadNoor Injadat and Abdallah Shami", "title": "Optimized Random Forest Model for Botnet Detection Based on DNS Queries", "comments": "4 pages, 3 figures, 1 table, Accepted and presented in IEEE 32nd\n  International Conference on Microelectronics (IEEE-ICM2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Domain Name System (DNS) protocol plays a major role in today's Internet\nas it translates between website names and corresponding IP addresses. However,\ndue to the lack of processes for data integrity and origin authentication, the\nDNS protocol has several security vulnerabilities. This often leads to a\nvariety of cyber-attacks, including botnet network attacks. One promising\nsolution to detect DNS-based botnet attacks is adopting machine learning (ML)\nbased solutions. To that end, this paper proposes a novel optimized ML-based\nframework to detect botnets based on their corresponding DNS queries. More\nspecifically, the framework consists of using information gain as a feature\nselection method and genetic algorithm (GA) as a hyper-parameter optimization\nmodel to tune the parameters of a random forest (RF) classifier. The proposed\nframework is evaluated using a state-of-the-art TI-2016 DNS dataset.\nExperimental results show that the proposed optimized framework reduced the\nfeature set size by up to 60%. Moreover, it achieved a high detection accuracy,\nprecision, recall, and F-score compared to the default classifier. This\nhighlights the effectiveness and robustness of the proposed framework in\ndetecting botnet attacks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 16:34:11 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Moubayed", "Abdallah", ""], ["Injadat", "MohammadNoor", ""], ["Shami", "Abdallah", ""]]}, {"id": "2012.11354", "submitter": "Tommaso Zoppi Dr", "authors": "Tommaso Zoppi, Andrea ceccarelli, Tommaso Capecchi, Andrea Bondavalli", "title": "Unsupervised Anomaly Detectors to Detect Intrusions in the Current\n  Threat Landscape", "comments": "Will be published on ACM Transactions Data Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection aims at identifying unexpected fluctuations in the expected\nbehavior of a given system. It is acknowledged as a reliable answer to the\nidentification of zero-day attacks to such extent, several ML algorithms that\nsuit for binary classification have been proposed throughout years. However,\nthe experimental comparison of a wide pool of unsupervised algorithms for\nanomaly-based intrusion detection against a comprehensive set of attacks\ndatasets was not investigated yet. To fill such gap, we exercise seventeen\nunsupervised anomaly detection algorithms on eleven attack datasets. Results\nallow elaborating on a wide range of arguments, from the behavior of the\nindividual algorithm to the suitability of the datasets to anomaly detection.\nWe conclude that algorithms as Isolation Forests, One-Class Support Vector\nMachines and Self-Organizing Maps are more effective than their counterparts\nfor intrusion detection, while clustering algorithms represent a good\nalternative due to their low computational complexity. Further, we detail how\nattacks with unstable, distributed or non-repeatable behavior as Fuzzing, Worms\nand Botnets are more difficult to detect. Ultimately, we digress on\ncapabilities of algorithms in detecting anomalies generated by a wide pool of\nunknown attacks, showing that achieved metric scores do not vary with respect\nto identifying single attacks.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 14:06:58 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Zoppi", "Tommaso", ""], ["ceccarelli", "Andrea", ""], ["Capecchi", "Tommaso", ""], ["Bondavalli", "Andrea", ""]]}, {"id": "2012.11358", "submitter": "H Jacinto", "authors": "A. Matthew Smith and H S. Jacinto", "title": "Reconfigurable Integrated Optical Interferometer Network-Based\n  Physically Unclonable Function", "comments": null, "journal-ref": "Journal of Lightwave Technology, vol. 38, no. 17, pp. 4599-4606, 1\n  Sept.1, 2020", "doi": "10.1109/JLT.2020.2996015", "report-no": null, "categories": "cs.CR physics.optics quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we describe the characteristics of a large integrated linear\noptical device containing Mach-Zehnder interferometers and describe its\npotential use as a physically unclonable function. We propose that any tunable\ninterferometric device of practical scale will be intrinsically unclonable and\nwill possess an inherent randomness that can be useful for many practical\napplications. The device under test has the additional use-case as a\ngeneral-purpose photonic manipulation tool, with various applications based on\nthe experimental results of our prototype. Once our tunable interferometric\ndevice is set to work as a physically unclonable function, we find that there\nare approximately 6.85x10E35 challenge-response pairs, where each challenge can\nbe quickly reconfigured by tuning the interferometer array for subsequent\nchallenges.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 15:59:55 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Smith", "A. Matthew", ""], ["Jacinto", "H S.", ""]]}, {"id": "2012.11375", "submitter": "Joshua Taylor", "authors": "Joshua Taylor", "title": "Effectiveness of SCADA System Security Used Within Critical\n  Infrastructure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since the 1960s Supervisory Control and Data Acquisition (SCADA) systems have\nbeen used within industry. Referred to as critical infrastructure (CI), key\ninstallations such as power stations, water treatment and energy grids are\ncontrolled using SCADA. Existing literature reveals inherent security risks to\nCI and suggests this stems from the rise of interconnected networks, leading to\nthe hypothesis that the rise of interconnectivity between corporate networks\nand SCADA system networks pose security risks to CI. The results from studies\ninto previous global attacks involving SCADA and CI, with focus on two highly\nserious incidents in Iran and Ukraine, reveal that although interconnectivity\nis a major factor, isolated CIs are still highly vulnerable to attack due to\nrisks within the SCADA controllers and protocols.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 00:31:01 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Taylor", "Joshua", ""]]}, {"id": "2012.11424", "submitter": "Brian Coyle", "authors": "Brian Coyle, Mina Doosti, Elham Kashefi, Niraj Kumar", "title": "Variational Quantum Cloning: Improving Practicality for Quantum\n  Cryptanalysis", "comments": "16 pages main text, 25 pages supplementary material, 20 figures.\n  Comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptanalysis on standard quantum cryptographic systems generally involves\nfinding optimal adversarial attack strategies on the underlying protocols. The\ncore principle of modelling quantum attacks in many cases reduces to the\nadversary's ability to clone unknown quantum states which facilitates the\nextraction of some meaningful secret information. Explicit optimal attack\nstrategies typically require high computational resources due to large circuit\ndepths or, in many cases, are unknown. In this work, we propose variational\nquantum cloning (VQC), a quantum machine learning based cryptanalysis algorithm\nwhich allows an adversary to obtain optimal (approximate) cloning strategies\nwith short depth quantum circuits, trained using hybrid classical-quantum\ntechniques. The algorithm contains operationally meaningful cost functions with\ntheoretical guarantees, quantum circuit structure learning and gradient descent\nbased optimisation. Our approach enables the end-to-end discovery of hardware\nefficient quantum circuits to clone specific families of quantum states, which\nin turn leads to an improvement in cloning fidelites when implemented on\nquantum hardware: the Rigetti Aspen chip. Finally, we connect these results to\nquantum cryptographic primitives, in particular quantum coin flipping. We\nderive attacks on two protocols as examples, based on quantum cloning and\nfacilitated by VQC. As a result, our algorithm can improve near term attacks on\nthese protocols, using approximate quantum cloning as a resource.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 15:28:09 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Coyle", "Brian", ""], ["Doosti", "Mina", ""], ["Kashefi", "Elham", ""], ["Kumar", "Niraj", ""]]}, {"id": "2012.11541", "submitter": "Muhammad Imran Khan", "authors": "Muhammad Imran Khan and Simon Foley and Barry O'Sullivan", "title": "Privacy Interpretation of Behavioural-based Anomaly Detection Approaches", "comments": "19 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the notion of 'Privacy-Anomaly Detection' and considers\nthe question of whether behavioural-based anomaly detection approaches can have\na privacy semantic interpretation and whether the detected anomalies can be\nrelated to the conventional (formal) definitions of privacy semantics such as\nk-anonymity. The idea is to learn the user's past querying behaviour in terms\nof privacy and then identifying deviations from past behaviour in order to\ndetect privacy violations. Privacy attacks, violations of formal privacy\ndefinition, based on a sequence of SQL queries (query correlations) are also\nconsidered in the paper and it is shown that interactive querying settings are\nvulnerable to privacy attacks based on query sequences. Investigation on\nwhether these types of privacy attacks can potentially manifest themselves as\nanomalies, specifically as privacy-anomalies was carried out. It is shown that\nin this paper that behavioural-based anomaly detection approaches have the\npotential to detect privacy attacks based on query sequences (violation of\nformal privacy definition) as privacy-anomalies.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 18:21:09 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Khan", "Muhammad Imran", ""], ["Foley", "Simon", ""], ["O'Sullivan", "Barry", ""]]}, {"id": "2012.11699", "submitter": "Asier Guti\\'errez-Fandi\\~no", "authors": "Asier Guti\\'errez-Fandi\\~no, Jordi Armengol-Estap\\'e, Marta Villegas", "title": "A Vulnerability Study on Academic Collaboration Networks Based on\n  Network Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Researchers that work for the same institution use their email as the main\ncommunication tool. Email can be one of the most fruitful attack vectors of\nresearch institutions as they also contain access to all accounts and thus to\nall private information. We propose an approach for analyzing in terms of\nsecurity research institutions' communication networks. We first obtained\ninstitutions' communication networks as well as a method to analyze possible\nbreaches of collected emails. We downloaded the network of 4 different research\ncenters, three from Spain and one from Portugal. We then ran simulations of\nSusceptible-Exposed-Infected-Recovered (SEIR) complex network dynamics model\nfor analyzing the vulnerability of the network. More than half of the nodes\nhave more than one security breach, and our simulation results show that more\nthan 90\\% of the networks' nodes are vulnerable. This method can be employed\nfor enhancing security of research centers and can make email accounts' use\nsecurity-aware. It may additionally open new research lines in communication\nsecurity. Finally, we manifest that, due to confidentiality reasons, the\nsources we utilized for obtaining communication networks should not be\nproviding the information that we were able to gather.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 21:51:54 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 10:41:28 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Guti\u00e9rrez-Fandi\u00f1o", "Asier", ""], ["Armengol-Estap\u00e9", "Jordi", ""], ["Villegas", "Marta", ""]]}, {"id": "2012.11701", "submitter": "Aayush Garg", "authors": "Aayush Garg, Renzo Degiovanni, Matthieu Jimenez, Maxime Cordy, Mike\n  Papadakis and Yves Le Traon", "title": "Learning To Predict Vulnerabilities From Vulnerability-Fixes: A Machine\n  Translation Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Vulnerability prediction refers to the problem of identifying the system\ncomponents that are most likely to be vulnerable based on the information\ngained from historical data. Typically, vulnerability prediction is performed\nusing manually identified features that are potentially linked with vulnerable\ncode. Unfortunately, recent studies have shown that existing approaches are\nineffective when evaluated in realistic settings due to some unavoidable noise\nincluded in the historical data. To deal with this issue, we develop a\nprediction method using the encoder-decoder framework of machine translation\nthat automatically learns the latent features (context, patterns, etc.) of code\nthat are linked with vulnerabilities. The key idea of our approach is to learn\nfrom things we know, the past vulnerability fixes and their context. We\nevaluate our approach by comparing it with existing techniques on available\nreleases of the three security-critical open source systems (Linux Kernel,\nOpenSSL, and Wireshark) with historical vulnerabilities that have been reported\nin the National Vulnerability Database (NVD). Our evaluation demonstrates that\nthe prediction capability of our approach significantly outperforms the\nstate-of-the-art vulnerability prediction techniques (Software Metrics,\nImports, Function Calls, and Text Mining) in both recall and precision values\n(yielding 4.7 times higher MCC values) under realistic training setting.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 21:59:12 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Garg", "Aayush", ""], ["Degiovanni", "Renzo", ""], ["Jimenez", "Matthieu", ""], ["Cordy", "Maxime", ""], ["Papadakis", "Mike", ""], ["Traon", "Yves Le", ""]]}, {"id": "2012.11775", "submitter": "Hugues Nelson Iradukunda", "authors": "Wei Wang, Emily Sallenback, Zeyu Ning, Hugues Nelson Iradukunda, Wenxi\n  Lu, Qingquan Zhang, Ting Zhu", "title": "MailLeak: Obfuscation-Robust Character Extraction Using Transfer\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The following work presents a new algorithm for character recognition from\nobfuscated images. The presented method is an example of a potential threat to\ncurrent postal services. This paper both analyzes the efficiency of the given\nalgorithm and suggests countermeasures to prevent such threats from occurring.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 01:14:28 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Wang", "Wei", ""], ["Sallenback", "Emily", ""], ["Ning", "Zeyu", ""], ["Iradukunda", "Hugues Nelson", ""], ["Lu", "Wenxi", ""], ["Zhang", "Qingquan", ""], ["Zhu", "Ting", ""]]}, {"id": "2012.11803", "submitter": "Bingyao Huang", "authors": "Bingyao Huang and Ruyi Lian and Dimitris Samaras and Haibin Ling", "title": "Modeling Deep Learning Based Privacy Attacks on Physical Mail", "comments": "Source code: https://github.com/BingyaoHuang/Neural-STE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mail privacy protection aims to prevent unauthorized access to hidden content\nwithin an envelope since normal paper envelopes are not as safe as we think. In\nthis paper, for the first time, we show that with a well designed deep learning\nmodel, the hidden content may be largely recovered without opening the\nenvelope. We start by modeling deep learning-based privacy attacks on physical\nmail content as learning the mapping from the camera-captured envelope front\nface image to the hidden content, then we explicitly model the mapping as a\ncombination of perspective transformation, image dehazing and denoising using a\ndeep convolutional neural network, named Neural-STE (See-Through-Envelope). We\nshow experimentally that hidden content details, such as texture and image\nstructure, can be clearly recovered. Finally, our formulation and model allow\nus to design envelopes that can counter deep learning-based privacy attacks on\nphysical mail.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 02:54:00 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 21:02:54 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Huang", "Bingyao", ""], ["Lian", "Ruyi", ""], ["Samaras", "Dimitris", ""], ["Ling", "Haibin", ""]]}, {"id": "2012.12031", "submitter": "Majid Rafiei", "authors": "Majid Rafiei and Wil M.P. van der Aalst", "title": "Towards Quantifying Privacy in Process Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Process mining employs event logs to provide insights into the actual\nprocesses. Event logs are recorded by information systems and contain valuable\ninformation helping organizations to improve their processes. However, these\ndata also include highly sensitive private information which is a major concern\nwhen applying process mining. Therefore, privacy preservation in process mining\nis growing in importance, and new techniques are being introduced. The\neffectiveness of the proposed privacy preservation techniques needs to be\nevaluated. It is important to measure both sensitive data protection and data\nutility preservation. In this paper, we propose an approach to quantify the\neffectiveness of privacy preservation techniques. We introduce two measures for\nquantifying disclosure risks to evaluate the sensitive data protection aspect.\nMoreover, a measure is proposed to quantify data utility preservation for the\nmain process mining activities. The proposed measures have been tested using\nvarious real-life event logs.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 10:04:54 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Rafiei", "Majid", ""], ["van der Aalst", "Wil M. P.", ""]]}, {"id": "2012.12060", "submitter": "Yusuke Kawamoto", "authors": "M\\'ario S. Alvim, Konstantinos Chatzikokolakis, Yusuke Kawamoto,\n  Catuscia Palamidessi", "title": "Information Leakage Games: Exploring Information as a Utility Function", "comments": "Journal version of GameSec'17 paper (arXiv:1705.05030)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.GT cs.IT math.IT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A common goal in the areas of secure information flow and privacy is to build\neffective defenses against unwanted leakage of information. To this end, one\nmust be able to reason about potential attacks and their interplay with\npossible defenses. In this paper, we propose a game-theoretic framework to\nformalize strategies of attacker and defender in the context of information\nleakage, and provide a basis for developing optimal defense methods. A novelty\nof our games is that their utility is given by information leakage, which in\nsome cases may behave in a non-linear way. This causes a significant deviation\nfrom classic game theory, in which utility functions are linear with respect to\nplayers' strategies. Hence, a key contribution of this paper is the\nestablishment of the foundations of information leakage games. We consider two\nkinds of games, depending on the notion of leakage considered. The first kind,\nthe QIF-games, is tailored for the theory of quantitative information flow\n(QIF). The second one, the DP-games, corresponds to differential privacy (DP).\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 14:51:30 GMT"}, {"version": "v2", "created": "Sun, 18 Jul 2021 09:56:24 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Alvim", "M\u00e1rio S.", ""], ["Chatzikokolakis", "Konstantinos", ""], ["Kawamoto", "Yusuke", ""], ["Palamidessi", "Catuscia", ""]]}, {"id": "2012.12138", "submitter": "Adrian Vladu", "authors": "Alina Ene, Huy L. Nguyen, Adrian Vladu", "title": "Projection-Free Bandit Optimization with Privacy Guarantees", "comments": "Appears in AAAI-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design differentially private algorithms for the bandit convex\noptimization problem in the projection-free setting. This setting is important\nwhenever the decision set has a complex geometry, and access to it is done\nefficiently only through a linear optimization oracle, hence Euclidean\nprojections are unavailable (e.g. matroid polytope, submodular base polytope).\nThis is the first differentially-private algorithm for projection-free bandit\noptimization, and in fact our bound of $\\widetilde{O}(T^{3/4})$ matches the\nbest known non-private projection-free algorithm (Garber-Kretzu, AISTATS `20)\nand the best known private algorithm, even for the weaker setting when\nprojections are available (Smith-Thakurta, NeurIPS `13).\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 16:19:29 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Ene", "Alina", ""], ["Nguyen", "Huy L.", ""], ["Vladu", "Adrian", ""]]}, {"id": "2012.12518", "submitter": "Mahsa Saeidi", "authors": "Mahsa Saeidi, McKenzie Calvert, Audrey W. Au, Anita Sarma, Rakesh B.\n  Bobba", "title": "If This Context Then That Concern: Exploring users' concerns with IFTTT\n  applets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  End users are increasingly using trigger-action platforms like,\nIf-This-Then-That (IFTTT) to create applets to connect smart home devices and\nservices. However, there are inherent risks in using such applets -- even\nnon-malicious ones -- as sensitive information may leak through their use in\ncertain contexts (e.g., where the device is located, who can observe the\nresultant action). This work aims to understand how well end users can assess\nthis risk. We do so by exploring users' concerns with using IFTTT applets and\nmore importantly if and how those concerns change based on different contextual\nfactors. Through a Mechanical Turk survey of 386 participants on 49 smart-home\nIFTTT applets, we found that nudging the participants to think about different\nusage contexts led them to think deeper about the associated risks and raise\ntheir concerns. Qualitative analysis reveals that participants had a nuanced\nunderstanding of contextual factors and how these factors could lead to leakage\nof sensitive data and allow unauthorized access to applets and data.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 07:11:47 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Saeidi", "Mahsa", ""], ["Calvert", "McKenzie", ""], ["Au", "Audrey W.", ""], ["Sarma", "Anita", ""], ["Bobba", "Rakesh B.", ""]]}, {"id": "2012.12528", "submitter": "Asaf Shabtai", "authors": "Alon Zolfi and Moshe Kravchik and Yuval Elovici and Asaf Shabtai", "title": "The Translucent Patch: A Physical and Universal Attack on Object\n  Detectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical adversarial attacks against object detectors have seen increasing\nsuccess in recent years. However, these attacks require direct access to the\nobject of interest in order to apply a physical patch. Furthermore, to hide\nmultiple objects, an adversarial patch must be applied to each object. In this\npaper, we propose a contactless translucent physical patch containing a\ncarefully constructed pattern, which is placed on the camera's lens, to fool\nstate-of-the-art object detectors. The primary goal of our patch is to hide all\ninstances of a selected target class. In addition, the optimization method used\nto construct the patch aims to ensure that the detection of other (untargeted)\nclasses remains unharmed. Therefore, in our experiments, which are conducted on\nstate-of-the-art object detection models used in autonomous driving, we study\nthe effect of the patch on the detection of both the selected target class and\nthe other classes. We show that our patch was able to prevent the detection of\n42.27% of all stop sign instances while maintaining high (nearly 80%) detection\nof the other classes.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 07:47:13 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Zolfi", "Alon", ""], ["Kravchik", "Moshe", ""], ["Elovici", "Yuval", ""], ["Shabtai", "Asaf", ""]]}, {"id": "2012.12529", "submitter": "Eyasu Getahun Chekole Dr", "authors": "Eyasu Getahun Chekole, Martin Ochoa, Sudipta Chattopadhyay", "title": "SCOPE CPS: Secure Compiling of PLCs in Cyber-Physical Systems", "comments": "Writing errors are corrected and presentation of the paper is\n  improved for better readability", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cyber-Physical Systems (CPS) are being widely adopted in critical\ninfrastructures, such as smart grids, nuclear plants, water systems,\ntransportation systems, manufacturing and healthcare services, among others.\nHowever, the increasing prevalence of cyberattacks targeting them raises a\ngrowing security concern in the domain. In particular, memory-safety attacks,\nthat exploit memory-safety vulnerabilities, constitute a major attack vector\nagainst real-time control devices in CPS. Traditional IT countermeasures\nagainst such attacks have limitations when applied to the CPS context: they\ntypically incur in high runtime overheads; which conflicts with real-time\nconstraints in CPS and they often abort the program when an attack is detected,\nthus harming availability of the system, which in turn can potentially result\nin damage to the physical world. In this work, we propose to enforce a\nfull-stack memory-safety (covering user-space and kernel-space attack surfaces)\nbased on secure compiling of PLCs to detect memory-safety attacks in CPS.\nFurthermore, to ensure availability, we enforce a resilient mitigation\ntechnique that bypasses illegal memory access instructions at runtime by\ndynamically instrumenting low-level code. We empirically measure the\ncomputational overhead caused by our approach on two experimental settings\nbased on real CPS. The experimental results show that our approach effectively\nand efficiently detects and mitigates memory-safety attacks in realistic CPS.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 07:48:22 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 16:06:37 GMT"}, {"version": "v3", "created": "Thu, 18 Mar 2021 18:49:40 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Chekole", "Eyasu Getahun", ""], ["Ochoa", "Martin", ""], ["Chattopadhyay", "Sudipta", ""]]}, {"id": "2012.12591", "submitter": "Viraj Kulkarni", "authors": "Manish Gawali, Arvind C S, Shriya Suryavanshi, Harshit Madaan, Ashrika\n  Gaikwad, Bhanu Prakash KN, Viraj Kulkarni, Aniruddha Pant", "title": "Comparison of Privacy-Preserving Distributed Deep Learning Methods in\n  Healthcare", "comments": "10 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we compare three privacy-preserving distributed learning\ntechniques: federated learning, split learning, and SplitFed. We use these\ntechniques to develop binary classification models for detecting tuberculosis\nfrom chest X-rays and compare them in terms of classification performance,\ncommunication and computational costs, and training time. We propose a novel\ndistributed learning architecture called SplitFedv3, which performs better than\nsplit learning and SplitFedv2 in our experiments. We also propose alternate\nmini-batch training, a new training technique for split learning, that performs\nbetter than alternate client training, where clients take turns to train a\nmodel.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 10:45:52 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Gawali", "Manish", ""], ["S", "Arvind C", ""], ["Suryavanshi", "Shriya", ""], ["Madaan", "Harshit", ""], ["Gaikwad", "Ashrika", ""], ["KN", "Bhanu Prakash", ""], ["Kulkarni", "Viraj", ""], ["Pant", "Aniruddha", ""]]}, {"id": "2012.12603", "submitter": "Jens Van den Broeck", "authors": "Jens Van den Broeck, Bart Coppens, Bjorn De Sutter", "title": "Flexible Software Protection", "comments": "Submitted to ACM Transactions on Privacy and Security", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To counter software reverse engineering or tampering, software obfuscation\ntools can be used. However, such tools to a large degree hard-code how the\nobfuscations are deployed. They hence lack resilience and stealth in the face\nof many attacks. To counter this problem, we propose the novel concept of\nflexible obfuscators, which implement protections in terms of data structures\nand APIs already present in the application to be protected. The protections\nare hence tailored to the application in which they are deployed, making them\nless learnable and less distinguishable. In our research, we concretized the\nflexible protection concept for opaque predicates. We designed an interface to\nenable the reuse of existing data structures and APIs in injected opaque\npredicates, we analyzed their resilience and stealth, we implemented a\nproof-of-concept flexible obfuscator, and we evaluated it on a number of\nreal-world use cases. This paper presents an in-depth motivation for our work,\nthe design of the interface, an in-depth security analysis, and a feasibility\nreport based on our experimental evaluation. The findings are that flexible\nopaque predicates indeed provide strong resilience and improved stealth, but\nalso that their deployment is costly, and that they should hence be used\nsparsely to protect only the most security-sensitive code fragments that do not\ndominate performance. Flexible obfuscation therefor delivers an expensive but\nalso more durable new weapon in the ever ongoing software protection arms race.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 11:06:49 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Broeck", "Jens Van den", ""], ["Coppens", "Bart", ""], ["De Sutter", "Bjorn", ""]]}, {"id": "2012.12640", "submitter": "Matthew Wicker", "authors": "Matthew Yuan, Matthew Wicker, Luca Laurenti", "title": "Gradient-Free Adversarial Attacks for Bayesian Neural Networks", "comments": "6 Pages, 2 Figures, AABI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The existence of adversarial examples underscores the importance of\nunderstanding the robustness of machine learning models. Bayesian neural\nnetworks (BNNs), due to their calibrated uncertainty, have been shown to posses\nfavorable adversarial robustness properties. However, when approximate Bayesian\ninference methods are employed, the adversarial robustness of BNNs is still not\nwell understood. In this work, we employ gradient-free optimization methods in\norder to find adversarial examples for BNNs. In particular, we consider genetic\nalgorithms, surrogate models, as well as zeroth order optimization methods and\nadapt them to the goal of finding adversarial examples for BNNs. In an\nempirical evaluation on the MNIST and Fashion MNIST datasets, we show that for\nvarious approximate Bayesian inference methods the usage of gradient-free\nalgorithms can greatly improve the rate of finding adversarial examples\ncompared to state-of-the-art gradient-based methods.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 13:19:11 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Yuan", "Matthew", ""], ["Wicker", "Matthew", ""], ["Laurenti", "Luca", ""]]}, {"id": "2012.12743", "submitter": "Qingtian Zou", "authors": "Qingtian Zou (1), Anoop Singhal (2), Xiaoyan Sun (3), Peng Liu (1)\n  ((1) The Pennsylvania State University, (2) National Institute of Standards\n  and Technology, (3) California State University, Sacramento)", "title": "Generating Comprehensive Data with Protocol Fuzzing for Applying Deep\n  Learning to Detect Network Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network attacks have become a major security concern for organizations\nworldwide and have also drawn attention in the academics. Recently, researchers\nhave applied neural networks to detect network attacks with network logs.\nHowever, public network data sets have major drawbacks such as limited data\nsample variations and unbalanced data with respect to malicious and benign\nsamples. In this paper, we present a new approach, protocol fuzzing, to\nautomatically generate high-quality network data, on which deep learning models\ncan be trained. Our findings show that fuzzing generates data samples that\ncover real-world data and deep learning models trained with fuzzed data can\nsuccessfully detect real network attacks.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 15:24:45 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Zou", "Qingtian", ""], ["Singhal", "Anoop", ""], ["Sun", "Xiaoyan", ""], ["Liu", "Peng", ""]]}, {"id": "2012.12803", "submitter": "Vitaly Feldman", "authors": "Vitaly Feldman, Audra McMillan, Kunal Talwar", "title": "Hiding Among the Clones: A Simple and Nearly Optimal Analysis of Privacy\n  Amplification by Shuffling", "comments": "Minor revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work of Erlingsson, Feldman, Mironov, Raghunathan, Talwar, and\nThakurta [EFMRTT19] demonstrates that random shuffling amplifies differential\nprivacy guarantees of locally randomized data. Such amplification implies\nsubstantially stronger privacy guarantees for systems in which data is\ncontributed anonymously [BEMMRLRKTS17] and has lead to significant interest in\nthe shuffle model of privacy [CSUZZ19,EFMRTT19].\n  We show that random shuffling of $n$ data records that are input to\n$\\varepsilon_0$-differentially private local randomizers results in an\n$(O((1-e^{-\\varepsilon_0})\\sqrt{\\frac{e^{\\varepsilon_0}\\log(1/\\delta)}{n}}),\n\\delta)$-differentially private algorithm. This significantly improves over\nprevious work and achieves the asymptotically optimal dependence in\n$\\varepsilon_0$. Our result is based on a new approach that is simpler than\nprevious work and extends to approximate differential privacy with nearly the\nsame guarantees. Our work also yields an empirical method to derive tighter\nbounds the resulting $\\varepsilon$ and we show that it gets to within a small\nconstant factor of the optimal bound. As a direct corollary of our analysis, we\nderive a simple and asymptotically optimal algorithm for discrete distribution\nestimation in the shuffle model of privacy. We also observe that our result\nimplies the first asymptotically optimal privacy analysis of noisy stochastic\ngradient descent that applies to sampling without replacement.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 17:07:26 GMT"}, {"version": "v2", "created": "Fri, 25 Dec 2020 06:55:45 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Feldman", "Vitaly", ""], ["McMillan", "Audra", ""], ["Talwar", "Kunal", ""]]}, {"id": "2012.12835", "submitter": "Saptarshi Purkayastha", "authors": "Shreya Goyal, Saptarshi Purkayastha, Tyler Phillips, Rob Quick, Alexis\n  Britt", "title": "Enabling Secure and Effective Biomedical Data Sharing through\n  Cyberinfrastructure Gateways", "comments": "Presented at Gateways 2020, Online, USA, October 2020, see\n  https://osf.io/meetings/gateways2020/", "journal-ref": null, "doi": "10.17605/OSF.IO/6Y8WG", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Dynaswap project reports on developing a coherently integrated and\ntrustworthy holistic secure workflow protection architecture for\ncyberinfrastructures which can be used on virtual machines deployed through\ncyberinfrastructure (CI) services such as JetStream. This service creates a\nuser-friendly cloud environment designed to give researchers access to\ninteractive computing and data analysis resources on demand. The Dynaswap\ncybersecurity architecture supports roles, role hierarchies, and data\nhierarchies, as well as dynamic changes of roles and hierarchical relations\nwithin the scientific infrastructure. Dynaswap combines existing cutting-edge\nsecurity frameworks (including an Authentication Authorization-Accounting\nframework, Multi-Factor Authentication, Secure Digital Provenance, and\nBlockchain) with advanced security tools (e.g., Biometric-Capsule,\nCryptography-based Hierarchical Access Control, and Dual-level Key Management).\nThe CI is being validated in life-science research environments and in the\neducation settings of Health Informatics.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 17:54:30 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Goyal", "Shreya", ""], ["Purkayastha", "Saptarshi", ""], ["Phillips", "Tyler", ""], ["Quick", "Rob", ""], ["Britt", "Alexis", ""]]}, {"id": "2012.12958", "submitter": "Yasmine Saleh", "authors": "Yasmine N. M. Saleh, Claude C. Chibelushi, Ayman A. Abdel-Hamid and\n  Abdel-Hamid Soliman", "title": "Privacy Preservation for Wireless Sensor Networks in Healthcare: State\n  of the Art, and Open Research Challenges", "comments": "42 pages, 15 figures and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of miniature biosensors has generated numerous opportunities for\ndeploying wireless sensor networks in healthcare. However, an important barrier\nis that acceptance by healthcare stakeholders is influenced by the\neffectiveness of privacy safeguards for personal and intimate information which\nis collected and transmitted over the air, within and beyond these networks. In\nparticular, these networks are progressing beyond traditional sensors, towards\nalso using multimedia sensors, which raise further privacy concerns.\nParadoxically, less research has addressed privacy protection, compared to\nsecurity. Nevertheless, privacy protection has gradually evolved from being\nassumed an implicit by-product of security measures, and it is maturing into a\nresearch concern in its own right. However, further technical and\nsocio-technical advances are needed. As a contribution towards galvanising\nfurther research, the hallmarks of this paper include: (i) a literature survey\nexplicitly anchored on privacy preservation, it is underpinned by untangling\nprivacy goals from security goals, to avoid mixing privacy and security\nconcerns, as is often the case in other papers; (ii) a critical survey of\nprivacy preservation services for wireless sensor networks in healthcare,\nincluding threat analysis and assessment methodologies; it also offers\nclassification trees for the multifaceted challenge of privacy protection in\nhealthcare, and for privacy threats, attacks and countermeasures; (iii) a\ndiscussion of technical advances complemented by reflection over the\nimplications of regulatory frameworks; (iv) a discussion of open research\nchallenges, leading onto offers of directions for future research towards\nunlocking the door onto privacy protection which is appropriate for healthcare\nin the twenty-first century.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 20:36:58 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Saleh", "Yasmine N. M.", ""], ["Chibelushi", "Claude C.", ""], ["Abdel-Hamid", "Ayman A.", ""], ["Soliman", "Abdel-Hamid", ""]]}, {"id": "2012.13028", "submitter": "Mohammad J. Hashemi", "authors": "Mohammad J. Hashemi, Eric Keller", "title": "General Domain Adaptation Through Proportional Progressive Pseudo\n  Labeling", "comments": "Published at 2020 IEEE International Conference on Big Data (Big\n  Data)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation helps transfer the knowledge gained from a labeled source\ndomain to an unlabeled target domain. During the past few years, different\ndomain adaptation techniques have been published. One common flaw of these\napproaches is that while they might work well on one input type, such as\nimages, their performance drops when applied to others, such as text or\ntime-series. In this paper, we introduce Proportional Progressive Pseudo\nLabeling (PPPL), a simple, yet effective technique that can be implemented in a\nfew lines of code to build a more general domain adaptation technique that can\nbe applied on several different input types. At the beginning of the training\nphase, PPPL progressively reduces target domain classification error, by\ntraining the model directly with pseudo-labeled target domain samples, while\nexcluding samples with more likely wrong pseudo-labels from the training set\nand also postponing training on such samples. Experiments on 6 different\ndatasets that include tasks such as anomaly detection, text sentiment analysis\nand image classification demonstrate that PPPL can beat other baselines and\ngeneralize better.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 23:57:00 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Hashemi", "Mohammad J.", ""], ["Keller", "Eric", ""]]}, {"id": "2012.13053", "submitter": "Steve Lu", "authors": "Samuel Dittmer and Yuval Ishai and Steve Lu and Rafail Ostrovsky and\n  Mohamed Elsabagh and Nikolaos Kiourtis and Brian Schulte and Angelos Stavrou", "title": "Function Secret Sharing for PSI-CA:With Applications to Private Contact\n  Tracing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we describe a token-based solution to Contact Tracing via\nDistributed Point Functions (DPF) and, more generally, Function Secret Sharing\n(FSS). The key idea behind the solution is that FSS natively supports secure\nkeyword search on raw sets of keywords without a need for processing the\nkeyword sets via a data structure for set membership. Furthermore, the FSS\nfunctionality enables adding up numerical payloads associated with multiple\nmatches without additional interaction. These features make FSS an attractive\ntool for lightweight privacy-preserving searching on a database of tokens\nbelonging to infected individuals.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 01:13:59 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Dittmer", "Samuel", ""], ["Ishai", "Yuval", ""], ["Lu", "Steve", ""], ["Ostrovsky", "Rafail", ""], ["Elsabagh", "Mohamed", ""], ["Kiourtis", "Nikolaos", ""], ["Schulte", "Brian", ""], ["Stavrou", "Angelos", ""]]}, {"id": "2012.13061", "submitter": "Patrick Ocheja", "authors": "Patrick Ocheja, Yang Cao, Shiyao Ding, and Masatoshi Yoshikawa", "title": "Quantifying the Privacy-Utility Trade-offs in COVID-19 Contact Tracing\n  Apps", "comments": "12 pages, 11 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  How to contain the spread of the COVID-19 virus is a major concern for most\ncountries. As the situation continues to change, various countries are making\nefforts to reopen their economies by lifting some restrictions and enforcing\nnew measures to prevent the spread. In this work, we review some approaches\nthat have been adopted to contain the COVID-19 virus such as contact tracing,\nclusters identification, movement restrictions, and status validation.\nSpecifically, we classify available techniques based on some characteristics\nsuch as technology, architecture, trade-offs (privacy vs utility), and the\nphase of adoption. We present a novel approach for evaluating privacy using\nboth qualitative and quantitative measures of privacy-utility assessment of\ncontact tracing applications. In this new method, we classify utility at three\n(3) distinct levels: no privacy, 100% privacy, and at k where k is set by the\nsystem providing the utility or privacy.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 01:37:07 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Ocheja", "Patrick", ""], ["Cao", "Yang", ""], ["Ding", "Shiyao", ""], ["Yoshikawa", "Masatoshi", ""]]}, {"id": "2012.13111", "submitter": "Saurabh Bagchi", "authors": "Ruqi Bai and Saurabh Bagchi and David I. Inouye", "title": "Exploring Adversarial Examples via Invertible Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples (AEs) are images that can mislead deep neural network\n(DNN) classifiers via introducing slight perturbations into original images.\nThis security vulnerability has led to vast research in recent years because it\ncan introduce real-world threats into systems that rely on neural networks.\nYet, a deep understanding of the characteristics of adversarial examples has\nremained elusive. We propose a new way of achieving such understanding through\na recent development, namely, invertible neural models with Lipschitz\ncontinuous mapping functions from the input to the output. With the ability to\ninvert any latent representation back to its corresponding input image, we can\ninvestigate adversarial examples at a deeper level and disentangle the\nadversarial example's latent representation. Given this new perspective, we\npropose a fast latent space adversarial example generation method that could\naccelerate adversarial training. Moreover, this new perspective could\ncontribute to new ways of adversarial example detection.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 05:17:21 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Bai", "Ruqi", ""], ["Bagchi", "Saurabh", ""], ["Inouye", "David I.", ""]]}, {"id": "2012.13225", "submitter": "Unai Rioja", "authors": "Unai Rioja and Lejla Batina and Jose Luis Flores and Igor Armendariz", "title": "Auto-tune POIs: Estimation of distribution algorithms for efficient\n  side-channel analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Due to the constant increase and versatility of IoT devices that should keep\nsensitive information private, Side-Channel Analysis (SCA) attacks on embedded\ndevices are gaining visibility in the industrial field. The integration and\nvalidation of countermeasures against SCA can be an expensive and cumbersome\nprocess, especially for the less experienced ones, and current certification\nprocedures require to attack the devices under test using multiple SCA\ntechniques and attack vectors, often implying a high degree of complexity. The\ngoal of this paper is to ease one of the most crucial and tedious steps of\nprofiling attacks i.e. the points of interest (POI) selection and hence assist\nthe SCA evaluation process. To this end, we introduce the usage of Estimation\nof Distribution Algorithms (EDAs) in the SCA field in order to automatically\ntune the point of interest selection. We showcase our approach on several\nexperimental use cases, including attacks on unprotected and protected AES\nimplementations over distinct copies of the same device, dismissing in this way\nthe portability issue.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 12:47:15 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2021 15:37:43 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Rioja", "Unai", ""], ["Batina", "Lejla", ""], ["Flores", "Jose Luis", ""], ["Armendariz", "Igor", ""]]}, {"id": "2012.13230", "submitter": "James Chiang", "authors": "Massimo Bartoletti, James Hsin-yu Chiang, Alberto Lluch-Lafuente", "title": "SoK: Lending Pools in Decentralized Finance", "comments": "20 pages. Under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lending pools are decentralized applications which allow mutually untrusted\nusers to lend and borrow crypto-assets. These applications feature complex,\nhighly parametric incentive mechanisms to equilibrate the loan market. This\ncomplexity makes the behaviour of lending pools difficult to understand and to\npredict: indeed, ineffective incentives and attacks could potentially lead to\nemergent unwanted behaviours. Reasoning about lending pools is made even harder\nby the lack of executable models of their behaviour: to precisely understand\nhow users interact with lending pools, eventually one has to inspect their\nimplementations, where the incentive mechanisms are intertwined with low-level\nimplementation details. Further, the variety of existing implementations makes\nit difficult to distill the common aspects of lending pools. We systematize the\nexisting knowledge about lending pools, leveraging a new formal model of\ninteractions with users, which reflects the archetypal features of mainstream\nimplementations. This enables us to prove some general properties of lending\npools, such as the correct handling of funds, and to precisely describe\nvulnerabilities and attacks. We also discuss the role of lending pools in the\nbroader context of decentralized finance.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 12:53:38 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Bartoletti", "Massimo", ""], ["Chiang", "James Hsin-yu", ""], ["Lluch-Lafuente", "Alberto", ""]]}, {"id": "2012.13293", "submitter": "Margarita Osadchy", "authors": "Danny Keller, Margarita Osadchy, and Orr Dunkelman", "title": "Fuzzy Commitments Offer Insufficient Protection to Biometric Templates\n  Produced by Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we study the protection that fuzzy commitments offer when they\nare applied to facial images, processed by the state of the art deep learning\nfacial recognition systems. We show that while these systems are capable of\nproducing great accuracy, they produce templates of too little entropy. As a\nresult, we present a reconstruction attack that takes a protected template, and\nreconstructs a facial image. The reconstructed facial images greatly resemble\nthe original ones. In the simplest attack scenario, more than 78% of these\nreconstructed templates succeed in unlocking an account (when the system is\nconfigured to 0.1% FAR). Even in the \"hardest\" settings (in which we take a\nreconstructed image from one system and use it in a different system, with\ndifferent feature extraction process) the reconstructed image offers 50 to 120\ntimes higher success rates than the system's FAR.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 15:28:33 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Keller", "Danny", ""], ["Osadchy", "Margarita", ""], ["Dunkelman", "Orr", ""]]}, {"id": "2012.13366", "submitter": "AKM Bahalul Haque", "authors": "AKM Bahalul Haque, Mahbubur Rahman", "title": "Blockchain Technology: Methodology, Application and Security Issues", "comments": "10 pages, 14 Figures and 4 Tables", "journal-ref": "IJCSNS International Journal of Computer Science and Network\n  Security, VOL.20 No.2, February 2020", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Blockchain technology is an interlinked systematic chain of blocks that\ncontains transaction history and other user data. It works under the principle\nof decentralized distributed digital ledger. This technology enables\ncryptographically secure and anonymous financial transactions among the user\nnodes of the network enabling the transactions to be validated and approved by\nall the users in a transparent environment. It is a revolutionary technology\nthat earned its emerging popularity through the usage of digital\ncryptocurrencies. Even though Blockchain holds a promising scope of development\nin the online transaction system, it is prone to several security and\nvulnerability issues. In this paper, blockchain methodology, its applications,\nand security issues are discussed which might shed some light on blockchain\nenthusiasts and researchers.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 17:48:45 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Haque", "AKM Bahalul", ""], ["Rahman", "Mahbubur", ""]]}, {"id": "2012.13423", "submitter": "Vilc Rufino", "authors": "Vilc Rufino, Mateus Nogueira, Alberto Avritzer, Daniel Menasch\\'e,\n  Barbara Russo, Andrea Janes, Vincenzo Ferme, Andr\\'e Van Hoorn, Henning\n  Schulz, Cabral Lima", "title": "Improving Predictability of User-Affecting Metrics to Support Anomaly\n  Detection in Cloud Services", "comments": null, "journal-ref": "IEEE Access, vol. 8, p.198152-198167, 2020", "doi": "10.1109/ACCESS.2020.3028571", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Anomaly detection systems aim to detect and report attacks or unexpected\nbehavior in networked systems. Previous work has shown that anomalies have an\nimpact on system performance, and that performance signatures can be\neffectively used for implementing an IDS. In this paper, we present an\nanalytical and an experimental study on the trade-off between anomaly detection\nbased on performance signatures and system scalability. The proposed approach\ncombines analytical modeling and load testing to find optimal configurations\nfor the signature-based IDS. We apply a heavy-tail bi-modal modeling approach,\nwhere \"long\" jobs represent large resource consuming transactions, e.g.,\ngenerated by DDoS attacks; the model was parametrized using results obtained\nfrom controlled experiments. For performance purposes, mean response time is\nthe key metric to be minimized, whereas for security purposes, response time\nvariance and classification accuracy must be taken into account. The key\ninsights from our analysis are: (i) there is an optimal number of servers which\nminimizes the response time variance, (ii) the sweet-spot number of servers\nthat minimizes response time variance and maximizes classification accuracy is\ntypically smaller than or equal to the one that minimizes mean response time.\nTherefore, for security purposes, it may be worth slightly sacrificing\nperformance to increase classification accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 19:08:32 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Rufino", "Vilc", ""], ["Nogueira", "Mateus", ""], ["Avritzer", "Alberto", ""], ["Menasch\u00e9", "Daniel", ""], ["Russo", "Barbara", ""], ["Janes", "Andrea", ""], ["Ferme", "Vincenzo", ""], ["Van Hoorn", "Andr\u00e9", ""], ["Schulz", "Henning", ""], ["Lima", "Cabral", ""]]}, {"id": "2012.13464", "submitter": "MD Zadid Khan", "authors": "Mashrur Chowdhury, Mhafuzul Islam and Zadid Khan", "title": "Security of Connected and Automated Vehicles", "comments": "11 pages, 4 figures, published in the 2019 fall issue of the \"Bridge\"\n  article of NAE on Cybersecurity", "journal-ref": "The Bridge, National Academy of Engineering, 49(3), pp. 46-56\n  (2019)", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The transportation system is rapidly evolving with new connected and\nautomated vehicle (CAV) technologies that integrate CAVs with other vehicles\nand roadside infrastructure in a cyberphysical system (CPS). Through\nconnectivity, CAVs affect their environments and vice versa, increasing the\nsize of the cyberattack surface and the risk of exploitation of security\nvulnerabilities by malicious actors. Thus, greater understanding of potential\nCAV-CPS cyberattacks and of ways to prevent them is a high priority. In this\narticle we describe CAV-CPS cyberattack surfaces and security vulnerabilities,\nand outline potential cyberattack detection and mitigation strategies. We\nexamine emerging technologies - artificial intelligence, software-defined\nnetworks, network function virtualization, edge computing, information-centric\nand virtual dispersive networking, fifth generation (5G) cellular networks,\nblockchain technology, and quantum and postquantum cryptography - as potential\nsolutions aiding in securing CAVs and transportation infrastructure against\nexisting and future cyberattacks.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 23:43:29 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Chowdhury", "Mashrur", ""], ["Islam", "Mhafuzul", ""], ["Khan", "Zadid", ""]]}, {"id": "2012.13552", "submitter": "Kentaro Mihara", "authors": "Kentaro Mihara, Ryohei Yamaguchi, Miguel Mitsuishi, Yusuke Maruyama", "title": "Neural Network Training With Homomorphic Encryption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a novel method and implementation architecture to train neural\nnetworks which preserves the confidentiality of both the model and the data.\nOur method relies on homomorphic capability of lattice based encryption scheme.\nOur procedure is optimized for operations on packed ciphertexts in order to\nachieve efficient updates of the model parameters. Our method achieves a\nsignificant reduction of computations due to our way to perform multiplications\nand rotations on packed ciphertexts from a feedforward network to a\nback-propagation network. To verify the accuracy of the training model as well\nas the implementation feasibility, we tested our method on the Iris data set by\nusing the CKKS scheme with Microsoft SEAL as a back end. Although our test\nimplementation is for simple neural network training, we believe our basic\nimplementation block can help the further applications for more complex neural\nnetwork based use cases.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 10:03:31 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Mihara", "Kentaro", ""], ["Yamaguchi", "Ryohei", ""], ["Mitsuishi", "Miguel", ""], ["Maruyama", "Yusuke", ""]]}, {"id": "2012.13573", "submitter": "Fengxiang He", "authors": "Fengxiang He, Shaopeng Fu, Bohan Wang, Dacheng Tao", "title": "Robustness, Privacy, and Generalization of Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training can considerably robustify deep neural networks to\nresist adversarial attacks. However, some works suggested that adversarial\ntraining might comprise the privacy-preserving and generalization abilities.\nThis paper establishes and quantifies the privacy-robustness trade-off and\ngeneralization-robustness trade-off in adversarial training from both\ntheoretical and empirical aspects. We first define a notion, {\\it robustified\nintensity} to measure the robustness of an adversarial training algorithm. This\nmeasure can be approximate empirically by an asymptotically consistent\nempirical estimator, {\\it empirical robustified intensity}. Based on the\nrobustified intensity, we prove that (1) adversarial training is $(\\varepsilon,\n\\delta)$-differentially private, where the magnitude of the differential\nprivacy has a positive correlation with the robustified intensity; and (2) the\ngeneralization error of adversarial training can be upper bounded by an\n$\\mathcal O(\\sqrt{\\log N}/N)$ on-average bound and an $\\mathcal O(1/\\sqrt{N})$\nhigh-probability bound, both of which have positive correlations with the\nrobustified intensity. Additionally, our generalization bounds do not\nexplicitly rely on the parameter size which would be prohibitively large in\ndeep learning. Systematic experiments on standard datasets, CIFAR-10 and\nCIFAR-100, are in full agreement with our theories. The source code package is\navailable at \\url{https://github.com/fshp971/RPG}.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 13:35:02 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["He", "Fengxiang", ""], ["Fu", "Shaopeng", ""], ["Wang", "Bohan", ""], ["Tao", "Dacheng", ""]]}, {"id": "2012.13718", "submitter": "Anna Georgiadou Mrs", "authors": "Anna Georgiadou, Spiros Mouzakitis and Dimitrios Askounis", "title": "Towards Assessing Critical Infrastructures Cyber-Security Culture During\n  Covid-19 Crisis: A Tailor-Made Survey", "comments": "4th International Conference on Networks and Security (NSEC 2020)", "journal-ref": null, "doi": "10.5121/csit.2020.101806", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper outlines the design and development of a survey targeting the\ncyber-security culture assessment of critical infrastructures during the\nCOVID-19 crisis, when living routine was seriously disturbed and working\nreality fundamentally affected. Its foundations lie on a security culture\nframework consisted of 10 different security dimensions analysed into 52\ndomains examined under two different pillars: organizational and individual. In\nthis paper, a detailed questionnaire building analysis is being presented while\nrevealing the aims, goals and expected outcomes of each question. It concludes\nwith the survey implementation and delivery plan following a number of\npre-survey stages each serving a specific methodological purpose.\n", "versions": [{"version": "v1", "created": "Sat, 26 Dec 2020 11:15:09 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Georgiadou", "Anna", ""], ["Mouzakitis", "Spiros", ""], ["Askounis", "Dimitrios", ""]]}, {"id": "2012.13807", "submitter": "Jun Zhao", "authors": "Mengmeng Yang, Ivan Tjuawinata, Kwok Yan Lam, Jun Zhao, Lin Sun", "title": "Secure Hot Path Crowdsourcing with Local Differential Privacy under Fog\n  Computing Architecture", "comments": "This paper appears in IEEE Transactions on Services Computing.\n  https://doi.org/10.1109/TSC.2020.3039336", "journal-ref": null, "doi": "10.1109/TSC.2020.3039336", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Crowdsourcing plays an essential role in the Internet of Things (IoT) for\ndata collection, where a group of workers is equipped with Internet-connected\ngeolocated devices to collect sensor data for marketing or research purpose. In\nthis paper, we consider crowdsourcing these worker's hot travel path. Each\nworker is required to report his real-time location information, which is\nsensitive and has to be protected. Encryption-based methods are the most direct\nway to protect the location, but not suitable for resource-limited devices.\nBesides, local differential privacy is a strong privacy concept and has been\ndeployed in many software systems. However, the local differential privacy\ntechnology needs a large number of participants to ensure the accuracy of the\nestimation, which is not always the case for crowdsourcing. To solve this\nproblem, we proposed a trie-based iterative statistic method, which combines\nadditive secret sharing and local differential privacy technologies. The\nproposed method has excellent performance even with a limited number of\nparticipants without the need of complex computation. Specifically, the\nproposed method contains three main components: iterative statistics, adaptive\nsampling, and secure reporting. We theoretically analyze the effectiveness of\nthe proposed method and perform extensive experiments to show that the proposed\nmethod not only provides a strict privacy guarantee, but also significantly\nimproves the performance from the previous existing solutions.\n", "versions": [{"version": "v1", "created": "Sat, 26 Dec 2020 20:26:43 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Yang", "Mengmeng", ""], ["Tjuawinata", "Ivan", ""], ["Lam", "Kwok Yan", ""], ["Zhao", "Jun", ""], ["Sun", "Lin", ""]]}, {"id": "2012.13971", "submitter": "Lun-Pin Yuan", "authors": "Lun-Pin Yuan, Euijin Choo, Ting Yu, Issa Khalil, Sencun Zhu", "title": "Time-Window Group-Correlation Support vs. Individual Features: A\n  Detection of Abnormal Users", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Autoencoder-based anomaly detection methods have been used in identifying\nanomalous users from large-scale enterprise logs with the assumption that\nadversarial activities do not follow past habitual patterns. Most existing\napproaches typically build models by reconstructing single-day and\nindividual-user behaviors. However, without capturing long-term signals and\ngroup-correlation signals, the models cannot identify low-signal yet\nlong-lasting threats, and will wrongly report many normal users as anomalies on\nbusy days, which, in turn, lead to high false positive rate. In this paper, we\npropose ACOBE, an Anomaly detection method based on COmpound BEhavior, which\ntakes into consideration long-term patterns and group behaviors. ACOBE\nleverages a novel behavior representation and an ensemble of deep autoencoders\nand produces an ordered investigation list. Our evaluation shows that ACOBE\noutperforms prior work by a large margin in terms of precision and recall, and\nour case study demonstrates that ACOBE is applicable in practice for\ncyberattack detection.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2020 16:30:31 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Yuan", "Lun-Pin", ""], ["Choo", "Euijin", ""], ["Yu", "Ting", ""], ["Khalil", "Issa", ""], ["Zhu", "Sencun", ""]]}, {"id": "2012.13995", "submitter": "Xiaoyu Cao", "authors": "Xiaoyu Cao, Minghong Fang, Jia Liu, Neil Zhenqiang Gong", "title": "FLTrust: Byzantine-robust Federated Learning via Trust Bootstrapping", "comments": "To appear in NDSS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Byzantine-robust federated learning aims to enable a service provider to\nlearn an accurate global model when a bounded number of clients are malicious.\nThe key idea of existing Byzantine-robust federated learning methods is that\nthe service provider performs statistical analysis among the clients' local\nmodel updates and removes suspicious ones, before aggregating them to update\nthe global model. However, malicious clients can still corrupt the global\nmodels in these methods via sending carefully crafted local model updates to\nthe service provider. The fundamental reason is that there is no root of trust\nin existing federated learning methods.\n  In this work, we bridge the gap via proposing FLTrust, a new federated\nlearning method in which the service provider itself bootstraps trust. In\nparticular, the service provider itself collects a clean small training dataset\n(called root dataset) for the learning task and the service provider maintains\na model (called server model) based on it to bootstrap trust. In each\niteration, the service provider first assigns a trust score to each local model\nupdate from the clients, where a local model update has a lower trust score if\nits direction deviates more from the direction of the server model update.\nThen, the service provider normalizes the magnitudes of the local model updates\nsuch that they lie in the same hyper-sphere as the server model update in the\nvector space. Our normalization limits the impact of malicious local model\nupdates with large magnitudes. Finally, the service provider computes the\naverage of the normalized local model updates weighted by their trust scores as\na global model update, which is used to update the global model. Our extensive\nevaluations on six datasets from different domains show that our FLTrust is\nsecure against both existing attacks and strong adaptive attacks.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2020 18:43:39 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Cao", "Xiaoyu", ""], ["Fang", "Minghong", ""], ["Liu", "Jia", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "2012.14095", "submitter": "J\\'an Pich", "authors": "J\\'an Pich", "title": "Learning algorithms from circuit lower bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit known constructions of efficient learning algorithms from various\nnotions of constructive circuit lower bounds such as distinguishers breaking\npseudorandom generators or efficient witnessing algorithms which find errors of\nsmall circuits attempting to compute hard functions. As our main result we\nprove that if it is possible to find efficiently, in a particular interactive\nway, errors of many p-size circuits attempting to solve hard problems, then\np-size circuits can be PAC learned over the uniform distribution with\nmembership queries by circuits of subexponential size. The opposite implication\nholds as well. This provides a new characterisation of learning algorithms and\nextends the natural proofs barrier of Razborov and Rudich. The proof is based\non a method of exploiting Nisan-Wigderson generators introduced by\nKraj\\'{i}\\v{c}ek (2010) and used to analyze complexity of circuit lower bounds\nin bounded arithmetic.\n  An interesting consequence of known constructions of learning algorithms from\ncircuit lower bounds is a learning speedup of Oliveira and Santhanam (2016). We\npresent an alternative proof of this phenomenon and discuss its potential to\nadvance the program of hardness magnification.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 04:47:36 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Pich", "J\u00e1n", ""]]}, {"id": "2012.14111", "submitter": "Adnan Iftekhar", "authors": "Mir Hassan, Chen Jincai, Adnan Iftekhar, Adnan Shehzad, Xiaohui Cui", "title": "Implementation of Security Systems for Detection and Prevention of Data\n  Loss/Leakage at Organization via Traffic Inspection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data Loss/Leakage Prevention (DLP) continues to be the main issue for many\nlarge organizations. There are multiple numbers of emerging security attach\nscenarios and a limitless number of overcoming solutions. Today's enterprises'\nmajor concern is to protect confidential information because a leakage that\ncompromises confidential data means that sensitive information is in\ncompetitors' hands. Different data types need to be protected. However, our\nresearch is focused only on data in motion (DIM) i-e data transferred through\nthe network. The research and scenarios in this paper demonstrate a recent\nsurvey on information and data leakage incidents, which reveals its importance\nand also proposed a model solution that will offer the combination of previous\nmethodologies with a new way of pattern matching by advanced content checker\nbased on the use of machine learning to protect data within an organization and\nthen take actions accordingly. This paper also proposed a DLP deployment design\non the gateway level that shows how data is moving through intermediate\nchannels before reaching the final destination using the squid proxy server and\nICAP server.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 06:29:16 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Hassan", "Mir", ""], ["Jincai", "Chen", ""], ["Iftekhar", "Adnan", ""], ["Shehzad", "Adnan", ""], ["Cui", "Xiaohui", ""]]}, {"id": "2012.14156", "submitter": "Ugur Erkan", "authors": "U\\u{g}ur Erkan, Abdurrahim Toktas, Serdar Engino\\u{g}lu, Enver\n  Karabacak, Dang N. H. Thanh", "title": "An Image Encryption Scheme Based on Chaotic Logarithmic Map and Key\n  Generation using Deep CNN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR eess.IV math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A secure and reliable image encryption scheme is presented in this study. The\nencryption scheme hereby introduces a novel chaotic log-map, deep convolution\nneural network (CNN) model for key generation, and bit reversion operation for\nthe manipulation process. Thanks to the sensitive key generation, initial\nvalues and control parameters are produced for the hyperchaotic log-map, and\nthus a diverse chaotic sequence is achieved for encrypting operations. The\nscheme then encrypts the images by scrambling and manipulating the pixels of\nimages through four operations: permutation, DNA encoding, diffusion, and bit\nreversion. The encryption scheme is precisely examined for the well-known\nimages in terms of various analyses such as keyspace, key sensitivity,\ninformation entropy, histogram, correlation, differential attack, noisy attack,\nand cropping attack. To corroborate the scheme, the visual and numerical\nresults are even compared with available outcomes of the state of the art.\nTherefore, the proposed log-map based image encryption scheme is successfully\nverified and validated by the superior absolute and comparative results.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 09:20:31 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Erkan", "U\u011fur", ""], ["Toktas", "Abdurrahim", ""], ["Engino\u011flu", "Serdar", ""], ["Karabacak", "Enver", ""], ["Thanh", "Dang N. H.", ""]]}, {"id": "2012.14171", "submitter": "Yue Li", "authors": "Yue Li, Benedetta Tondi and Mauro Barni", "title": "Spread-Transform Dither Modulation Watermarking of Deep Neural Network", "comments": "Submitted to Journal of Information Security and Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DNN watermarking is receiving an increasing attention as a suitable mean to\nprotect the Intellectual Property Rights associated to DNN models. Several\nmethods proposed so far are inspired to the popular Spread Spectrum (SS)\nparadigm according to which the watermark bits are embedded into the projection\nof the weights of the DNN model onto a pseudorandom sequence. In this paper, we\npropose a new DNN watermarking algorithm that leverages on the watermarking\nwith side information paradigm to decrease the obtrusiveness of the watermark\nand increase its payload. In particular, the new scheme exploits the main ideas\nof ST-DM (Spread Transform Dither Modulation) watermarking to improve the\nperformance of a recently proposed algorithm based on conventional SS. The\nexperiments we carried out by applying the proposed scheme to watermark\ndifferent models, demonstrate its capability to provide a higher payload with a\nlower impact on network accuracy than a baseline method based on conventional\nSS, while retaining a satisfactory level of robustness.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 10:23:17 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Li", "Yue", ""], ["Tondi", "Benedetta", ""], ["Barni", "Mauro", ""]]}, {"id": "2012.14205", "submitter": "Marco Guarnieri", "authors": "Marco Guarnieri, Marco Patrignani", "title": "Contract-Aware Secure Compilation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microarchitectural attacks exploit the abstraction gap between the\nInstruction Set Architecture (ISA) and how instructions are actually executed\nby processors to compromise the confidentiality and integrity of a system. To\nsecure systems against microarchitectural attacks, programmers need to reason\nabout and program against these microarchitectural side-effects. However, we\ncannot -- and should not -- expect programmers to manually tailor programs for\nspecific processors and their security guarantees. Instead, we could rely on\ncompilers (and the secure compilation community), as they can play a prominent\nrole in bridging this gap: compilers should target specific processors\nmicroarchitectural security guarantees and they should leverage these\nguarantees to produce secure code. To achieve this, we outline the idea of\nContract-Aware Secure COmpilation (CASCO) where compilers are parametric with\nrespect to a hardware/software security-contract, an abstraction capturing a\nprocessor's security guarantees. That is, compilers will automatically leverage\nthe guarantees formalized in the contract to ensure that program-level security\nproperties are preserved at microarchitectural level.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 11:57:51 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Guarnieri", "Marco", ""], ["Patrignani", "Marco", ""]]}, {"id": "2012.14227", "submitter": "Wei Wang Dr.", "authors": "Yong Huang, Wei Wang, Tao Jiang, Qian Zhang", "title": "Detecting Colluding Sybil Attackers in Robotic Networks using\n  Backscatters", "comments": "To appear in ACM/IEEE Transactions on Networking. arXiv admin note:\n  substantial text overlap with arXiv:1912.04613", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to the openness of wireless medium, robotic networks that consist of many\nminiaturized robots are susceptible to Sybil attackers, who can fabricate\nmyriads of fictitious robots. Such detrimental attacks can overturn the\nfundamental trust assumption in robotic collaboration and thus impede\nwidespread deployments of robotic networks in many collaborative tasks.\nExisting solutions rely on bulky multi-antenna systems to passively obtain\nfine-grained physical layer signatures, making them unaffordable to\nminiaturized robots. To overcome this limitation, we present ScatterID, a\nlightweight system that attaches featherlight and batteryless backscatter tags\nto single-antenna robots for Sybil attack mitigation. Instead of passively\n\"observing\" signatures, ScatterID actively \"manipulates\" multipath propagation\nby exploiting backscatter tags to intentionally create rich multipath\nsignatures obtainable to single-antenna robots. Particularly, these signatures\nare used to carefully construct similarity vectors to thwart advanced Sybil\nattackers, who further trigger power-scaling and colluding attacks to generate\ndissimilar signatures. Then, a customized random forest model is developed to\naccurately infer the identity legitimacy of each robot. We implement ScatterID\non the iRobot Create platform and evaluate it under various Sybil attacks in\nreal-world environments. The experimental results show that ScatterID achieves\na high AUROC of 0.987 and obtains an overall accuracy of 95.4% under basic and\nadvanced Sybil attacks. Specifically, it can successfully detect 96.1% of fake\nrobots while mistakenly rejecting just 5.7% of legitimate ones.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 13:39:52 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Huang", "Yong", ""], ["Wang", "Wei", ""], ["Jiang", "Tao", ""], ["Zhang", "Qian", ""]]}, {"id": "2012.14318", "submitter": "Wenpeng He", "authors": "Wenpeng He, Dan Feng, Fang Wang, Yue Li, Mengting Lu", "title": "IRO: Integrity and Reliability Enhanced Ring ORAM", "comments": "This work has been submitted to the IEEE for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory security and reliability are two of the major design concerns in cloud\ncomputing systems. State-of-the-art memory security-reliability co-designs\n(e.g. Synergy) have achieved a good balance on performance, confidentiality,\nintegrity, and reliability. However, these works merely rely on encryption to\nensure data confidentiality, which has been proven unable to prevent\ninformation leakage from memory access patterns. Ring ORAM is an attractive\nconfidential protection protocol to hide memory access patterns to the\nuntrusted storage system. Unfortunately, it does not compatible with the\nsecurity-reliability co-designs. A forced combination would result in more\nsevere performance loss.\n  In this paper, we propose IRO, an Integrity and Reliability enhanced Ring\nORAM design. To reduce the overhead of integrity verification, we propose a low\noverhead integrity tree RIT and use a Minimum Update Subtree Tree (MUST) to\nreduce metadata update overhead. To improve memory reliability, we present\nSecure Replication to provide channel-level error resilience for the ORAM tree\nand use the mirrored channel technique to guarantee the reliability of the\nMUST. Last, we use the error correction pointer (ECP) to repair permanent\nmemory cell fault to further improve device reliability and lifetime. A compact\nmetadata design is used to reduce the storage and consulting overhead of the\nECP.\n  IRO provides strong security and reliability guarantees, while the resulting\nstorage and performance overhead is very small. Our evaluation shows that IRO\nonly increases 7.54% execution time on average over the Baseline under two\nchannels four AES-GCM units setting. With enough AES-GCM units to perform\nconcurrent MAC computing, IRO can reduce 2.14% execution time of the Baseline.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 16:00:39 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 02:27:56 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["He", "Wenpeng", ""], ["Feng", "Dan", ""], ["Wang", "Fang", ""], ["Li", "Yue", ""], ["Lu", "Mengting", ""]]}, {"id": "2012.14396", "submitter": "Bernardo Huberman", "authors": "Jing Wang and Bernardo Huberman", "title": "A Guide to Global Quantum Key Distribution Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR cs.CY cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe systems and methods for the deployment of global quantum key\ndistribution (QKD) networks covering transoceanic, long-haul, metro, and access\nsegments of the network. A comparative study of the state-of-the-art QKD\ntechnologies is carried out, including both terrestrial QKD via optical fibers\nand free-space optics, as well as spaceborne solutions via satellites. We\ncompare the pros and cons of various existing QKD technologies, including\nchannel loss, potential interference, distance, connection topology, deployment\ncost and requirements, as well as application scenarios. Technical selection\ncriteria and deployment requirements are developed for various different QKD\nsolutions in each segment of networks. For example, optical fiber-based QKD is\nsuitable for access networks due to its limited distance and compatibility with\npoint-to-multipoint (P2MP) topology; with the help of trusted relays, it can be\nextended to long-haul and metro networks. Spaceborne QKD on the other hand, has\nmuch smaller channel loss and extended transmission distance, which can be used\nfor transoceanic and long-haul networks exploiting satellite-based trusted\nrelays.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 18:21:10 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 04:01:15 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Wang", "Jing", ""], ["Huberman", "Bernardo", ""]]}, {"id": "2012.14425", "submitter": "Benjamin Ampel", "authors": "Benjamin M. Ampel", "title": "Predicting Organizational Cybersecurity Risk: A Deep Learning Approach", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cyberattacks conducted by malicious hackers cause irreparable damage to\norganizations, governments, and individuals every year. Hackers use exploits\nfound on hacker forums to carry out complex cyberattacks, making exploration of\nthese forums vital. We propose a hacker forum entity recognition framework\n(HackER) to identify exploits and the entities that the exploits target. HackER\nthen uses a bidirectional long short-term memory model (BiLSTM) to create a\npredictive model for what companies will be targeted by exploits. The results\nof the algorithm will be evaluated using a manually labeled gold-standard test\ndataset, using accuracy, precision, recall, and F1-score as metrics. We choose\nto compare our model against state of the art classical machine learning and\ndeep learning benchmark models. Results show that our proposed HackER BiLSTM\nmodel outperforms all classical machine learning and deep learning models in\nF1-score (79.71%). These results are statistically significant at 0.05 or lower\nfor all benchmarks except LSTM. The results of preliminary work suggest our\nmodel can help key cybersecurity stakeholders (e.g., analysts, researchers,\neducators) identify what type of business an exploit is targeting.\n", "versions": [{"version": "v1", "created": "Sat, 26 Dec 2020 01:15:34 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Ampel", "Benjamin M.", ""]]}, {"id": "2012.14427", "submitter": "Mohit Sewak", "authors": "Mohit Sewak, Sanjay K. Sahay and Hemant Rathore", "title": "Assessment of the Relative Importance of different hyper-parameters of\n  LSTM for an IDS", "comments": null, "journal-ref": "2020 IEEE REGION 10 CONFERENCE (TENCON), Osaka, Japan, 2020, pp.\n  414-419", "doi": "10.1109/TENCON50793.2020.9293731", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent deep learning language models like the LSTM are often used to\nprovide advanced cyber-defense for high-value assets. The underlying assumption\nfor using LSTM networks for malware-detection is that the op-code sequence of\nmalware could be treated as a (spoken) language representation. There are\ndifferences between any spoken-language (sequence of words/sentences) and the\nmachine-language (sequence of op-codes). In this paper, we demonstrate that due\nto these inherent differences, an LSTM model with its default configuration as\ntuned for a spoken-language, may not work well to detect malware (using its\nop-code sequence) unless the network's essential hyper-parameters are tuned\nappropriately. In the process, we also determine the relative importance of all\nthe different hyper-parameters of an LSTM network as applied to malware\ndetection using their op-code sequence representations. We experimented with\ndifferent configurations of LSTM networks, and altered hyper-parameters like\nthe embedding-size, number of hidden layers, number of LSTM-units in a hidden\nlayer, pruning/padding-length of the input-vector, activation-function, and\nbatch-size. We discovered that owing to the enhanced complexity of the\nmalware/machine-language, the performance of an LSTM network configured for an\nIntrusion Detection System, is very sensitive towards the\nnumber-of-hidden-layers, input sequence-length, and the choice of the\nactivation-function. Also, for (spoken) language-modeling, the recurrent\narchitectures by-far outperform their non-recurrent counterparts. Therefore, we\nalso assess how sequential DL architectures like the LSTM compare against their\nnon-sequential counterparts like the MLP-DNN for the purpose of\nmalware-detection.\n", "versions": [{"version": "v1", "created": "Sat, 26 Dec 2020 18:00:37 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Sewak", "Mohit", ""], ["Sahay", "Sanjay K.", ""], ["Rathore", "Hemant", ""]]}, {"id": "2012.14430", "submitter": "Ismail Mustapha", "authors": "Ismail B. Mustapha, Shafaatunnur Hasan, Sunday O. Olatunji, Siti\n  Mariyam Shamsuddin, Afolabi Kazeem", "title": "Effective Email Spam Detection System using Extreme Gradient Boosting", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The popularity, cost-effectiveness and ease of information exchange that\nelectronic mails offer to electronic device users has been plagued with the\nrising number of unsolicited or spam emails. Driven by the need to protect\nemail users from this growing menace, research in spam email\nfiltering/detection systems has being increasingly active in the last decade.\nHowever, the adaptive nature of spam emails has often rendered most of these\nsystems ineffective. While several spam detection models have been reported in\nliterature, the reported performance on an out of sample test data shows the\nroom for more improvement. Presented in this research is an improved spam\ndetection model based on Extreme Gradient Boosting (XGBoost) which to the best\nof our knowledge has received little attention spam email detection problems.\nExperimental results show that the proposed model outperforms earlier\napproaches across a wide range of evaluation metrics. A thorough analysis of\nthe model results in comparison to the results of earlier works is also\npresented.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2020 15:23:58 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Mustapha", "Ismail B.", ""], ["Hasan", "Shafaatunnur", ""], ["Olatunji", "Sunday O.", ""], ["Shamsuddin", "Siti Mariyam", ""], ["Kazeem", "Afolabi", ""]]}, {"id": "2012.14481", "submitter": "Akbar Siami Namin", "authors": "Zulfiqar Ali Khan and Akbar Siami Namin", "title": "A Survey on Vulnerabilities of Ethereum Smart Contracts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart contract (SC) is an extension of BlockChain technology. Ethereum\nBlockChain was the first to incorporate SC and thus started a new era of\ncrypto-currencies and electronic transactions. Solidity helps to program the\nSCs. Still, soon after Solidity's emergence in 2014, Solidity-based SCs\nsuffered many attacks that deprived the SC account holders of their precious\nfunds. The main reason for these attacks was the presence of vulnerabilities in\nSC. This paper discusses SC vulnerabilities and classifies them according to\nthe domain knowledge of the faulty operations. This classification is a source\nof reminding developers and software engineers that for SC's safety, each SC\nrequires proper testing with effective tools to catch those classes'\nvulnerabilities.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 20:57:48 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Khan", "Zulfiqar Ali", ""], ["Namin", "Akbar Siami", ""]]}, {"id": "2012.14488", "submitter": "Akbar Siami Namin", "authors": "Luis Felipe Guti\\'errez, Faranak Abri, Miriam Armstrong, Akbar Siami\n  Namin, Keith S. Jones", "title": "Phishing Detection through Email Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of detecting phishing emails through machine learning techniques\nhas been discussed extensively in the literature. Conventional and\nstate-of-the-art machine learning algorithms have demonstrated the possibility\nof building classifiers with high accuracy. The existing research studies treat\nphishing and genuine emails through general indicators and thus it is not\nexactly clear what phishing features are contributing to variations of the\nclassifiers. In this paper, we crafted a set of phishing and legitimate emails\nwith similar indicators in order to investigate whether these cues are captured\nor disregarded by email embeddings, i.e., vectorizations. We then fed machine\nlearning classifiers with the carefully crafted emails to find out about the\nperformance of email embeddings developed. Our results show that using these\nindicators, email embeddings techniques is effective for classifying emails as\nphishing or legitimate.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 21:16:41 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Guti\u00e9rrez", "Luis Felipe", ""], ["Abri", "Faranak", ""], ["Armstrong", "Miriam", ""], ["Namin", "Akbar Siami", ""], ["Jones", "Keith S.", ""]]}, {"id": "2012.14574", "submitter": "Godwin Badu-Marfo", "authors": "Godwin Badu-Marfo, Bilal Farooq and Zachary Patterson", "title": "A Differentially Private Multi-Output Deep Generative Networks Approach\n  For Activity Diary Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we develop a privacy-by-design generative model for\nsynthesizing the activity diary of the travel population using state-of-art\ndeep learning approaches. This proposed approach extends literature on\npopulation synthesis by contributing novel deep learning to the development and\napplication of synthetic travel data while guaranteeing privacy protection for\nmembers of the sample population on which the synthetic populations are based.\nFirst, we show a complete de-generalization of activity diaries to simulate the\nsocioeconomic features and longitudinal sequences of geographically and\ntemporally explicit activities. Second, we introduce a differential privacy\napproach to control the level of resolution disclosing the uniqueness of survey\nparticipants. Finally, we experiment using the Generative Adversarial Networks\n(GANs). We evaluate the statistical distributions, pairwise correlations and\nmeasure the level of privacy guaranteed on simulated datasets for varying\nnoise. The results of the model show successes in simulating activity diaries\ncomposed of multiple outputs including structured socio-economic features and\nsequential tour activities in a differentially private manner.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 02:37:36 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Badu-Marfo", "Godwin", ""], ["Farooq", "Bilal", ""], ["Patterson", "Zachary", ""]]}, {"id": "2012.14600", "submitter": "Miki Verma", "authors": "Miki E. Verma and Michael D. Iannacone and Robert A. Bridges and\n  Samuel C. Hollifield and Bill Kay and Frank L. Combs", "title": "ROAD: The Real ORNL Automotive Dynamometer Controller Area Network\n  Intrusion Detection Dataset (with a comprehensive CAN IDS dataset survey &\n  guide)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Controller Area Network (CAN) protocol is ubiquitous in modern vehicles,\nbut the protocol lacks many important security properties, such as message\nauthentication. To address these insecurities, a rapidly growing field of\nresearch has emerged that seeks to detect tampering, anomalies, or attacks on\nthese networks; this field has developed a wide variety of novel approaches and\nalgorithms to address these problems. One major impediment to the progression\nof this CAN anomaly detection and intrusion detection system (IDS) research\narea is the lack of high-fidelity datasets with realistic labeled attacks,\nwithout which it is difficult to evaluate, compare, and validate these proposed\napproaches. In this work we present the first comprehensive survey of publicly\navailable CAN intrusion datasets. Based on a thorough analysis of the data and\ndocumentation, for each dataset we provide a detailed description and enumerate\nthe drawbacks, benefits, and suggested use cases. Our analysis is aimed at\nguiding researchers in finding appropriate datasets for testing a CAN IDS. We\npresent the Real ORNL Automotive Dynamometer (ROAD) CAN Intrusion Dataset,\nproviding the first dataset with real, advanced attacks to the existing\ncollection of open datasets.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 04:18:54 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Verma", "Miki E.", ""], ["Iannacone", "Michael D.", ""], ["Bridges", "Robert A.", ""], ["Hollifield", "Samuel C.", ""], ["Kay", "Bill", ""], ["Combs", "Frank L.", ""]]}, {"id": "2012.14663", "submitter": "Sebastiano Battiato", "authors": "Federico Costantini, Fausto Galvan, Marco Alvise de Stefani,\n  Sebastiano Battiato", "title": "Assessing Information Quality in IoT Forensics: Theoretical Framework\n  and Model Implementation", "comments": "accepted for publication in Journal of Applied Logics (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IoT technologies pose serious challenges to digital Forensics. The\nacquisition of digital evidence is hindered by the number and extreme variety\nof IoT items, often lacking physical interfaces, connected in unprotected\nnetworks, feeding data to uncontrolled cloud services. In this paper we address\n\"Information Quality\" in IoT Forensics, taking into account different levels of\ncomplexity and included human factors. After drawing a theoretical framework on\ndata quality and information quality, we focus on forensic analysis challenges\nin IoT environments, providing a use case of evidence collection for\ninvestigative purposes. At the end, we propose a formal framework for assessing\ninformation quality of IoT devices for Forensics analysis.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 08:56:14 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Costantini", "Federico", ""], ["Galvan", "Fausto", ""], ["de Stefani", "Marco Alvise", ""], ["Battiato", "Sebastiano", ""]]}, {"id": "2012.14718", "submitter": "Leonardo Bautista Gomez", "authors": "Mikel Cortes-Goicoechea, Luca Franceschini, Leonardo Bautista-Gomez", "title": "Resource Analysis of Ethereum 2.0 Clients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scalability is a common issue among the most used permissionless blockchains,\nand several approaches have been proposed accordingly. As Ethereum is set to be\na solid foundation for a decentralized Internet web, the need for tackling\nscalability issues while preserving the security of the network is an important\nchallenge. In order to successfully deliver effective scaling solutions,\nEthereum is on the path of a major protocol improvement called Ethereum 2.0\n(Eth2), which implements sharding. As the change of consensus mechanism is an\nextremely delicate matter, this improvement will be achieved through different\nphases, the first of which is the implementation of the Beacon Chain. For this,\na specification has been developed and multiple groups have implemented clients\nto run the new protocol. In this work, we analyse the resource usage behaviour\nof different clients running as Eth2 nodes, comparing their performance and\nanalysing differences. Our results show multiple network perturbations and how\ndifferent clients react to it.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 11:58:55 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Cortes-Goicoechea", "Mikel", ""], ["Franceschini", "Luca", ""], ["Bautista-Gomez", "Leonardo", ""]]}, {"id": "2012.14728", "submitter": "Leonardo Bautista Gomez", "authors": "Mikel Cortes-Goicoechea, Leonardo Bautista-Gomez", "title": "Armiarma: Ethereum2 Network Monitoring Tool", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving the equilibrium between scalability, sustainability and security\nhas prevailed as the ideal solution for decentralized blockchain applications\nover the last years. Several approaches have been proposed being Ethereum a\nsolid proposal among them. Ethereum is on the path of a major protocol\nimprovement called Ethereum 2.0 (Eth2), implementing Sharding and introducing\nthe Proof-of-Stake (PoS). As the change of consensus mechanism is a delicate\nmatter, this improvement will be achieved through different phases, the first\nof which is the implementation of the Beacon Chain. The implementation of the\nlatest has been stated with the recent launch of the Eth2 main net. In this\nwork, we introduce an Eth2 network monitor tool, called Armiarma, used to\ngenerate a complete analysis of the p2p network of the Eth2 main net. In this\npaper, we present some of the results of what this Eth2 network monitor can\nachieve.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 12:22:09 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Cortes-Goicoechea", "Mikel", ""], ["Bautista-Gomez", "Leonardo", ""]]}, {"id": "2012.14738", "submitter": "Lue Tao", "authors": "Lue Tao, Songcan Chen", "title": "With False Friends Like These, Who Can Have Self-Knowledge?", "comments": "Preprint (Under review). In this paper, we were the first to\n  introduce the notion of hypocritical examples (inputs perturbed to correct\n  model prediction). This manuscript was first published at OpenReview on\n  September 28, 2020. Please see https://openreview.net/forum?id=bQtejwuIqB", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples arise from excessive sensitivity of a model. Commonly\nstudied adversarial examples are malicious inputs, crafted by an adversary from\ncorrectly classified examples, to induce misclassification. This paper studies\nan intriguing, yet far overlooked consequence of the excessive sensitivity,\nthat is, a misclassified example can be easily perturbed to help the model to\nproduce correct output. Such perturbed examples look harmless, but actually can\nbe maliciously utilized by a false friend to make the model self-satisfied.\nThus we name them hypocritical examples. With false friends like these, a\npoorly performed model could behave like a state-of-the-art one. Once a\ndeployer trusts the hypocritical performance and uses the \"well-performed\"\nmodel in real-world applications, potential security concerns appear even in\nbenign environments. In this paper, we formalize the hypocritical risk for the\nfirst time and propose a defense method specialized for hypocritical examples\nby minimizing the tradeoff between natural risk and an upper bound of\nhypocritical risk. Moreover, our theoretical analysis reveals connections\nbetween adversarial risk and hypocritical risk. Extensive experiments verify\nthe theoretical results and the effectiveness of our proposed methods.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 12:42:36 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Tao", "Lue", ""], ["Chen", "Songcan", ""]]}, {"id": "2012.14816", "submitter": "Marc Chaumont", "authors": "Hugo Ruiz, Marc Chaumont, Mehdi Yedroudj, Ahmed Oulad Amara,\n  Fr\\'ed\\'eric Comby, G\\'erard Subsol", "title": "Analysis of the Scalability of a Deep-Learning Network for Steganography\n  \"Into the Wild\"", "comments": "Proceeding of the 25th International Conference on Pattern\n  Recognition, ICPR'2021, Worshop on MultiMedia FORensics in the WILD,\n  MMForWILD'2021, Lecture Notes in Computer Science, LNCS, Springer, Virtual\n  Conference due to Covid (formerly Milan, Italy), January 10-15, 2021, 14\n  pages, https://iplab.dmi.unict.it/mmforwild/. Also look at the associated\n  video (youtube)", "journal-ref": "Lecture Notes in Computer Science, LNCS, Springer, 2021", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since the emergence of deep learning and its adoption in steganalysis fields,\nmost of the reference articles kept using small to medium size CNN, and learn\nthem on relatively small databases.\n  Therefore, benchmarks and comparisons between different deep learning-based\nsteganalysis algorithms, more precisely CNNs, are thus made on small to medium\ndatabases. This is performed without knowing:\n  1. if the ranking, with a criterion such as accuracy, is always the same when\nthe database is larger,\n  2. if the efficiency of CNNs will collapse or not if the training database is\na multiple of magnitude larger,\n  3. the minimum size required for a database or a CNN, in order to obtain a\nbetter result than a random guesser.\n  In this paper, after a solid discussion related to the observed behaviour of\nCNNs as a function of their sizes and the database size, we confirm that the\nerror's power-law also stands in steganalysis, and this in a border case, i.e.\nwith a medium-size network, on a big, constrained and very diverse database.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 15:53:55 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Ruiz", "Hugo", ""], ["Chaumont", "Marc", ""], ["Yedroudj", "Mehdi", ""], ["Amara", "Ahmed Oulad", ""], ["Comby", "Fr\u00e9d\u00e9ric", ""], ["Subsol", "G\u00e9rard", ""]]}, {"id": "2012.14867", "submitter": "Jeff Yan", "authors": "Jeff Yan", "title": "Scams in modern societies: how does China differ from the world?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a set of high-profile scams that were well engineered and have hit\npeople hard in China in recent years. We propose a simple but novel theoretical\nframework to examine psychological, situational and social fabric factors that\nhave played a role in these scams. We also use this framework as a tool to\nexplore scam countermeasures. In so doing, we identify how these Chinese scams\ndiffer from their Western counterparts.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 17:40:36 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Yan", "Jeff", ""]]}, {"id": "2012.14884", "submitter": "Henry Corrigan-Gibbs", "authors": "Dan Boneh, Elette Boyle, Henry Corrigan-Gibbs, Niv Gilboa, and Yuval\n  Ishai", "title": "Lightweight Techniques for Private Heavy Hitters", "comments": "To appear in IEEE Security & Privacy 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new protocol for solving the private heavy-hitters\nproblem. In this problem, there are many clients and a small set of\ndata-collection servers. Each client holds a private bitstring. The servers\nwant to recover the set of all popular strings, without learning anything else\nabout any client's string. A web-browser vendor, for instance, can use our\nprotocol to figure out which homepages are popular, without learning any user's\nhomepage. We also consider the simpler private subset-histogram problem, in\nwhich the servers want to count how many clients hold strings in a particular\nset without revealing this set to the clients.\n  Our protocols use two data-collection servers and, in a protocol run, each\nclient send sends only a single message to the servers. Our protocols protect\nclient privacy against arbitrary misbehavior by one of the servers and our\napproach requires no public-key cryptography (except for secure channels), nor\ngeneral-purpose multiparty computation. Instead, we rely on incremental\ndistributed point functions, a new cryptographic tool that allows a client to\nsuccinctly secret-share the labels on the nodes of an exponentially large\nbinary tree, provided that the tree has a single non-zero path. Along the way,\nwe develop new general tools for providing malicious security in applications\nof distributed point functions.\n  In an experimental evaluation with two servers on opposite sides of the U.S.,\nthe servers can find the 200 most popular strings among a set of 400,000\nclient-held 256-bit strings in 54 minutes. Our protocols are highly\nparallelizable. We estimate that with 20 physical machines per logical server,\nour protocols could compute heavy hitters over ten million clients in just over\none hour of computation.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 18:20:16 GMT"}, {"version": "v2", "created": "Fri, 2 Apr 2021 21:13:32 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Boneh", "Dan", ""], ["Boyle", "Elette", ""], ["Corrigan-Gibbs", "Henry", ""], ["Gilboa", "Niv", ""], ["Ishai", "Yuval", ""]]}, {"id": "2012.14897", "submitter": "Yaroslav Balytskyi", "authors": "Yaroslav Balytskyi, Manohar Raavi, Anatoliy Pinchuk and Sang-Yoon\n  Chang", "title": "$\\mathcal{PT}$-Symmetric Quantum Discrimination of Three States", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If the system is known to be in one of two non-orthogonal quantum states,\n$|\\psi_1\\rangle$ or $|\\psi_2\\rangle$, it is not possible to discriminate them\nby a single measurement due to the unitarity constraint. In a regular Hermitian\nquantum mechanics, the successful discrimination is possible to perform with\nthe probability $p < 1$, while in $\\mathcal{PT}$-symmetric quantum mechanics a\n\\textit{simulated single-measurement} quantum state discrimination with the\nsuccess rate $p$ can be done. We extend the $\\mathcal{PT}$-symmetric quantum\nstate discrimination approach for the case of three pure quantum states,\n$|\\psi_1\\rangle$, $|\\psi_2\\rangle$ and $|\\psi_3\\rangle$ without any additional\nrestrictions on the geometry and symmetry possession of these states. We\ndiscuss the relation of our approach with the recent implementation of\n$\\mathcal{PT}$ symmetry on the IBM quantum processor.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 18:40:32 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2021 18:52:43 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Balytskyi", "Yaroslav", ""], ["Raavi", "Manohar", ""], ["Pinchuk", "Anatoliy", ""], ["Chang", "Sang-Yoon", ""]]}, {"id": "2012.14938", "submitter": "Lilas Alrahis", "authors": "Lilas Alrahis, Satwik Patnaik, Johann Knechtel, Hani Saleh, Baker\n  Mohammad, Mahmoud Al-Qutayri, and Ozgur Sinanoglu", "title": "UNSAIL: Thwarting Oracle-Less Machine Learning Attacks on Logic Locking", "comments": "IEEE Transactions on Information Forensics and Security (TIFS)", "journal-ref": null, "doi": "10.1109/TIFS.2021.3057576", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logic locking aims to protect the intellectual property (IP) of integrated\ncircuit (IC) designs throughout the globalized supply chain. The SAIL attack,\nbased on tailored machine learning (ML) models, circumvents combinational logic\nlocking with high accuracy and is amongst the most potent attacks as it does\nnot require a functional IC acting as an oracle. In this work, we propose\nUNSAIL, a logic locking technique that inserts key-gate structures with the\nspecific aim to confuse ML models like those used in SAIL. More specifically,\nUNSAIL serves to prevent attacks seeking to resolve the structural\ntransformations of synthesis-induced obfuscation, which is an essential step\nfor logic locking. Our approach is generic; it can protect any local structure\nof key-gates against such ML-based attacks in an oracle-less setting. We\ndevelop a reference implementation for the SAIL attack and launch it on both\ntraditionally locked and UNSAIL-locked designs. In SAIL, a change-prediction\nmodel is used to determine which key-gate structures to restore using a\nreconstruction model. Our study on benchmarks ranging from the ISCAS-85 and\nITC-99 suites to the OpenRISC Reference Platform System-on-Chip (ORPSoC)\nconfirms that UNSAIL degrades the accuracy of the change-prediction model and\nthe reconstruction model by an average of 20.13 and 17 percentage points (pp)\nrespectively. When the aforementioned models are combined, which is the most\npowerful scenario for SAIL, UNSAIL reduces the attack accuracy of SAIL by an\naverage of 11pp. We further demonstrate that UNSAIL thwarts other oracle-less\nattacks, i.e., SWEEP and the redundancy attack, indicating the generic nature\nand strength of our approach. Detailed layout-level evaluations illustrate that\nUNSAIL incurs minimal area and power overheads of 0.26% and 0.61%,\nrespectively, on the million-gate ORPSoC design.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 20:52:18 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 19:44:50 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Alrahis", "Lilas", ""], ["Patnaik", "Satwik", ""], ["Knechtel", "Johann", ""], ["Saleh", "Hani", ""], ["Mohammad", "Baker", ""], ["Al-Qutayri", "Mahmoud", ""], ["Sinanoglu", "Ozgur", ""]]}, {"id": "2012.14954", "submitter": "Qi Long", "authors": "Yi Deng, Xiaoqian Jiang, Qi Long", "title": "Privacy-Preserving Methods for Vertically Partitioned Incomplete Data", "comments": null, "journal-ref": "2020 AMIA Annual Symposium Proceedings", "doi": null, "report-no": null, "categories": "cs.CR stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed health data networks that use information from multiple sources\nhave drawn substantial interest in recent years. However, missing data are\nprevalent in such networks and present significant analytical challenges. The\ncurrent state-of-the-art methods for handling missing data require pooling data\ninto a central repository before analysis, which may not be possible in a\ndistributed health data network. In this paper, we propose a privacy-preserving\ndistributed analysis framework for handling missing data when data are\nvertically partitioned. In this framework, each institution with a particular\ndata source utilizes the local private data to calculate necessary intermediate\naggregated statistics, which are then shared to build a global model for\nhandling missing data. To evaluate our proposed methods, we conduct simulation\nstudies that clearly demonstrate that the proposed privacy-preserving methods\nperform as well as the methods using the pooled data and outperform several\nna\\\"ive methods. We further illustrate the proposed methods through the\nanalysis of a real dataset. The proposed framework for handling vertically\npartitioned incomplete data is substantially more privacy-preserving than\nmethods that require pooling of the data, since no individual-level data are\nshared, which can lower hurdles for collaboration across multiple institutions\nand build stronger public trust.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 21:46:32 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Deng", "Yi", ""], ["Jiang", "Xiaoqian", ""], ["Long", "Qi", ""]]}, {"id": "2012.14965", "submitter": "Chang Song", "authors": "Chang Song, Elias Fallon, Hai Li", "title": "Improving Adversarial Robustness in Weight-quantized Neural Networks", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural networks are getting deeper and more computation-intensive nowadays.\nQuantization is a useful technique in deploying neural networks on hardware\nplatforms and saving computation costs with negligible performance loss.\nHowever, recent research reveals that neural network models, no matter\nfull-precision or quantized, are vulnerable to adversarial attacks. In this\nwork, we analyze both adversarial and quantization losses and then introduce\ncriteria to evaluate them. We propose a boundary-based retraining method to\nmitigate adversarial and quantization losses together and adopt a nonlinear\nmapping method to defend against white-box gradient-based adversarial attacks.\nThe evaluations demonstrate that our method can better restore accuracy after\nquantization than other baseline methods on both black-box and white-box\nadversarial attacks. The results also show that adversarial training suffers\nquantization loss and does not cooperate well with other training methods.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 22:50:17 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 23:32:39 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Song", "Chang", ""], ["Fallon", "Elias", ""], ["Li", "Hai", ""]]}, {"id": "2012.15019", "submitter": "Chris Cundy", "authors": "Chris Cundy, Stefano Ermon", "title": "Privacy-Constrained Policies via Mutual Information Regularized Policy\n  Gradients", "comments": "8 pages; figure/table formatting fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As reinforcement learning techniques are increasingly applied to real-world\ndecision problems, attention has turned to how these algorithms use potentially\nsensitive information. We consider the task of training a policy that maximizes\nreward while minimizing disclosure of certain sensitive state variables through\nthe actions. We give examples of how this setting covers real-world problems in\nprivacy for sequential decision-making. We solve this problem in the policy\ngradients framework by introducing a regularizer based on the mutual\ninformation (MI) between the sensitive state and the actions at a given\ntimestep. We develop a model-based stochastic gradient estimator for\noptimization of privacy-constrained policies. We also discuss an alternative MI\nregularizer that serves as an upper bound to our main MI regularizer and can be\noptimized in a model-free setting. We contrast previous work in\ndifferentially-private RL to our mutual-information formulation of information\ndisclosure. Experimental results show that our training method results in\npolicies which hide the sensitive state.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 03:22:35 GMT"}, {"version": "v2", "created": "Sat, 2 Jan 2021 03:39:43 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Cundy", "Chris", ""], ["Ermon", "Stefano", ""]]}, {"id": "2012.15041", "submitter": "Jaouhar Fattahi", "authors": "Jaouhar Fattahi and Mohamed Mejri", "title": "Damaged Fingerprint Recognition by Convolutional Long Short-Term Memory\n  Networks for Forensic Purposes", "comments": "This paper was accepted, on December 5, 2020, for publication and\n  oral presentation at the 2021 IEEE 5th International Conference on\n  Cryptography, Security and Privacy (CSP 2021) to be held in Zhuhai, China\n  during January 8-10, 2021 and hosted by Beijing Normal University (Zhuhai)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fingerprint recognition is often a game-changing step in establishing\nevidence against criminals. However, we are increasingly finding that criminals\ndeliberately alter their fingerprints in a variety of ways to make it difficult\nfor technicians and automatic sensors to recognize their fingerprints, making\nit tedious for investigators to establish strong evidence against them in a\nforensic procedure. In this sense, deep learning comes out as a prime candidate\nto assist in the recognition of damaged fingerprints. In particular,\nconvolution algorithms. In this paper, we focus on the recognition of damaged\nfingerprints by Convolutional Long Short-Term Memory networks. We present the\narchitecture of our model and demonstrate its performance which exceeds 95%\naccuracy, 99% precision, and approaches 95% recall and 99% AUC.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 04:51:58 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Fattahi", "Jaouhar", ""], ["Mejri", "Mohamed", ""]]}, {"id": "2012.15080", "submitter": "Vivek Nigam", "authors": "Yuri Gil Dantas, Vivek Nigam, Harald Ruess", "title": "Security Engineering for ISO 21434", "comments": "This is a White Paper. This is a preliminary version. Its figures and\n  template are to be finalized by our marketing department. V3 corrects a\n  number of typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ISO 21434 is a new standard that has been proposed to address the future\nchallenges of automotive cybersecurity. This white paper takes a closer look at\nthe ISO 21434 helping engineers to understand the ISO 21434 parts, the key\nactivities to be carried out and the main artefacts that shall be produced. As\nany certification, obtaining the ISO 21434 certification can be daunting at\nfirst sight. Engineers have to deploy processes that include several security\nrisk assessment methods to produce security arguments and evidence supporting\nitem security claims. In this white paper, we propose a security engineering\napproach that can ease this process by relying on Rigorous Security Assessments\nand Incremental Assessment Maintenance methods supported by automation. We\ndemonstrate by example that the proposed approach can greatly increase the\nquality of the produced artefacts, the efficiency to produce them, as well as\nenable continuous security assessment. Finally, we point out some key research\ndirections that we are investigating to fully realize the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 08:36:45 GMT"}, {"version": "v2", "created": "Sun, 10 Jan 2021 05:56:05 GMT"}, {"version": "v3", "created": "Sun, 17 Jan 2021 08:51:18 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Dantas", "Yuri Gil", ""], ["Nigam", "Vivek", ""], ["Ruess", "Harald", ""]]}, {"id": "2012.15116", "submitter": "Fabio Massimo Zennaro", "authors": "William Arild Dahl, Laszlo Erdodi, Fabio Massimo Zennaro", "title": "Stack-based Buffer Overflow Detection using Recurrent Neural Networks", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting vulnerabilities in software is a critical challenge in the\ndevelopment and deployment of applications. One of the most known and dangerous\nvulnerabilities is stack-based buffer overflows, which may allow potential\nattackers to execute malicious code. In this paper we consider the use of\nmodern machine learning models, specifically recurrent neural networks, to\ndetect stack-based buffer overflow vulnerabilities in the assembly code of a\nprogram. Since assembly code is a generic and common representation, focusing\non this language allows us to potentially consider programs written in several\ndifferent programming languages. Moreover, we subscribe to the hypothesis that\ncode may be treated as natural language, and thus we process assembly code\nusing standard architectures commonly employed in natural language processing.\nWe perform a set of experiments aimed at confirming the validity of the natural\nlanguage hypothesis and the feasibility of using recurrent neural networks for\ndetecting vulnerabilities. Our results show that our architecture is able to\ncapture subtle stack-based buffer overflow vulnerabilities that strongly depend\non the context, thus suggesting that this approach may be extended to\nreal-world setting, as well as to other forms of vulnerability detection.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 11:24:44 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Dahl", "William Arild", ""], ["Erdodi", "Laszlo", ""], ["Zennaro", "Fabio Massimo", ""]]}, {"id": "2012.15128", "submitter": "Zhikun Zhang", "authors": "Zhikun Zhang, Tianhao Wang, Ninghui Li, Jean Honorio, Michael Backes,\n  Shibo He, Jiming Chen, Yang Zhang", "title": "PrivSyn: Differentially Private Data Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In differential privacy (DP), a challenging problem is to generate synthetic\ndatasets that efficiently capture the useful information in the private data.\nThe synthetic dataset enables any task to be done without privacy concern and\nmodification to existing algorithms. In this paper, we present PrivSyn, the\nfirst automatic synthetic data generation method that can handle general\ntabular datasets (with 100 attributes and domain size $>2^{500}$). PrivSyn is\ncomposed of a new method to automatically and privately identify correlations\nin the data, and a novel method to generate sample data from a dense graphic\nmodel. We extensively evaluate different methods on multiple datasets to\ndemonstrate the performance of our method.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 12:32:42 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Zhang", "Zhikun", ""], ["Wang", "Tianhao", ""], ["Li", "Ninghui", ""], ["Honorio", "Jean", ""], ["Backes", "Michael", ""], ["He", "Shibo", ""], ["Chen", "Jiming", ""], ["Zhang", "Yang", ""]]}, {"id": "2012.15254", "submitter": "Alexandru Cojocaru", "authors": "Alexandru Cojocaru, Juan Garay, Aggelos Kiayias, Fang Song, Petros\n  Wallden", "title": "Post-Quantum Security of the Bitcoin Backbone and Quantum Multi-Solution\n  Bernoulli Search", "comments": "34 pages. This work supersedes the result of our previous work in\n  eprint.iacr.org/2019/1150", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Bitcoin and its underlying blockchain protocol have recently received\nsignificant attention in the context of building distributed systems and\nfoundations of the consensus problem. At the same time, the rapid development\nin quantum computing makes the threats to cryptography more and more\nconcerning. In this work, we revisit the formal security of the core of the\nBitcoin consensus protocol, called the Bitcoin backbone (Eurocrypt 2015), in\nthe presence of quantum adversaries -- i.e. adversaries equipped with quantum\ncomputers.\n  We show that the security of the Bitcoin backbone holds under a quantum\nanalogue of the ``honest majority'' assumption that we develop. The critical\ningredient of proving security of the blockchain is to analyzing the quantum\nquery complexity of a Chain-of-Proofs-of-Work search problem. This problem in\nturn reduces to a problem we call multi-solution Bernoulli search, for which we\nestablish its quantum query complexity. This can be viewed as an extension of a\nthreshold direct product theorem to an average-case unstructured search\nproblem. Our proof, adding to active recent efforts, simplifies and generalizes\nthe powerful recording technique due to Zhandry (Crypto 2019).\n  Our analysis indicates that the security of the Bitcoin backbone protocol is\nguaranteed provided that the number of adversarial quantum queries is bounded\nso that each quantum query is worth $O(p^{-1/2})$ classical ones, where $p$ is\nthe probability of success of a single classical query to the protocol's\nunderlying hash function. Perhaps surprisingly, the wait time for safe\nsettlement of transactions in the case of quantum adversaries matches (up to a\nconstant) the safe settlement time in the classical case and thus does not\nresult in any further overhead.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 18:03:56 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 14:31:10 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Cojocaru", "Alexandru", ""], ["Garay", "Juan", ""], ["Kiayias", "Aggelos", ""], ["Song", "Fang", ""], ["Wallden", "Petros", ""]]}, {"id": "2012.15351", "submitter": "Mohsen Toorani", "authors": "Mohsen Toorani, Christian Gehrmann", "title": "A Decentralized Dynamic PKI based on Blockchain", "comments": "19 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The central role of the certificate authority (CA) in traditional public key\ninfrastructure (PKI) makes it fragile and prone to compromises and operational\nfailures. Maintaining CAs and revocation lists is demanding especially in\nloosely-connected and large systems. Log-based PKIs have been proposed as a\nremedy but they do not solve the problem effectively. We provide a general\nmodel and a solution for decentralized and dynamic PKI based on a blockchain\nand web of trust model where the traditional CA and digital certificates are\nremoved and instead, everything is registered on the blockchain. Registration,\nrevocation, and update of public keys are based on a consensus mechanism\nbetween a certain number of entities that are already part of the system. Any\nnode which is part of the system can be an auditor and initiate the revocation\nprocedure once it finds out malicious activities. Revocation lists are no\nlonger required as any node can efficiently verify the public keys through\nwitnesses.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 22:45:23 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Toorani", "Mohsen", ""], ["Gehrmann", "Christian", ""]]}, {"id": "2012.15423", "submitter": "Dung Hoang Duong", "authors": "Huy Quoc Le, Dung Hoang Duong, Partha Sarathi Roy, Willy Susilo,\n  Kazuhide Fukushima and Shinsaku Kiyomoto", "title": "Lattice-based Signcryption with Equality Test in Standard Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A signcryption, which is an integration of a public key encryption and a\ndigital signature, can provide confidentiality and authenticity simultaneously.\nAdditionally, a signcryption associated with equality test allows a third party\n(e.g., a cloud server) to check whether or not two ciphertexts are encrypted\nfrom the same message without knowing the message. This application plays an\nimportant role especially in computing on encrypted data. In this paper, we\npropose the first lattice-based signcryption scheme equipped with a solution to\ntesting the message equality in the standard model. The proposed signcryption\nscheme is proven to be secure against insider attacks under the learning with\nerrors assumption and the intractability of the short integer solution problem.\nAs a by-product, we also show that some existing lattice-based signcryptions\neither is insecure or does not work correctly.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 03:30:13 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Le", "Huy Quoc", ""], ["Duong", "Dung Hoang", ""], ["Roy", "Partha Sarathi", ""], ["Susilo", "Willy", ""], ["Fukushima", "Kazuhide", ""], ["Kiyomoto", "Shinsaku", ""]]}, {"id": "2012.15713", "submitter": "Chang Ge", "authors": "Chang Ge, Shubhankar Mohapatra, Xi He, Ihab F. Ilyas", "title": "Kamino: Constraint-Aware Differentially Private Data Synthesis", "comments": "Update based on reviewers' comments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Organizations are increasingly relying on data to support decisions. When\ndata contains private and sensitive information, the data owner often desires\nto publish a synthetic database instance that is similarly useful as the true\ndata, while ensuring the privacy of individual data records. Existing\ndifferentially private data synthesis methods aim to generate useful data based\non applications, but they fail in keeping one of the most fundamental data\nproperties of the structured data -- the underlying correlations and\ndependencies among tuples and attributes (i.e., the structure of the data).\nThis structure is often expressed as integrity and schema constraints, or with\na probabilistic generative process. As a result, the synthesized data is not\nuseful for any downstream tasks that require this structure to be preserved.\n  This work presents Kamino, a data synthesis system to ensure differential\nprivacy and to preserve the structure and correlations present in the original\ndataset. Kamino takes as input of a database instance, along with its schema\n(including integrity constraints), and produces a synthetic database instance\nwith differential privacy and structure preservation guarantees. We empirically\nshow that while preserving the structure of the data, Kamino achieves\ncomparable and even better usefulness in applications of training\nclassification models and answering marginal queries than the state-of-the-art\nmethods of differentially private data synthesis.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 17:08:19 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 15:48:21 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Ge", "Chang", ""], ["Mohapatra", "Shubhankar", ""], ["He", "Xi", ""], ["Ilyas", "Ihab F.", ""]]}, {"id": "2012.15721", "submitter": "Nasser Aldaghri", "authors": "Nasser Aldaghri, Hessam Mahdavifar, Ahmad Beirami", "title": "Coded Machine Unlearning", "comments": "Accepted for publication in IEEE Access", "journal-ref": null, "doi": "10.1109/ACCESS.2021.3090019", "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There are applications that may require removing the trace of a sample from\nthe system, e.g., a user requests their data to be deleted, or corrupted data\nis discovered. Simply removing a sample from storage units does not necessarily\nremove its entire trace since downstream machine learning models may store some\ninformation about the samples used to train them. A sample can be perfectly\nunlearned if we retrain all models that used it from scratch with that sample\nremoved from their training dataset. When multiple such unlearning requests are\nexpected to be served, unlearning by retraining becomes prohibitively\nexpensive. Ensemble learning enables the training data to be split into smaller\ndisjoint shards that are assigned to non-communicating weak learners. Each\nshard is used to produce a weak model. These models are then aggregated to\nproduce the final central model. This setup introduces an inherent trade-off\nbetween performance and unlearning cost, as reducing the shard size reduces the\nunlearning cost but may cause degradation in performance. In this paper, we\npropose a coded learning protocol where we utilize linear encoders to encode\nthe training data into shards prior to the learning phase. We also present the\ncorresponding unlearning protocol and show that it satisfies the perfect\nunlearning criterion. Our experimental results show that the proposed coded\nmachine unlearning provides a better performance versus unlearning cost\ntrade-off compared to the uncoded baseline.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 17:20:34 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 16:35:51 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Aldaghri", "Nasser", ""], ["Mahdavifar", "Hessam", ""], ["Beirami", "Ahmad", ""]]}, {"id": "2012.15740", "submitter": "Asaf Shabtai", "authors": "Moshe Kravchik and Battista Biggio and Asaf Shabtai", "title": "Poisoning Attacks on Cyber Attack Detectors for Industrial Control\n  Systems", "comments": "ACM SAC'21. arXiv admin note: substantial text overlap with\n  arXiv:2002.02741", "journal-ref": null, "doi": "10.1145/3412841.3441892", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, neural network (NN)-based methods, including autoencoders, have\nbeen proposed for the detection of cyber attacks targeting industrial control\nsystems (ICSs). Such detectors are often retrained, using data collected during\nsystem operation, to cope with the natural evolution (i.e., concept drift) of\nthe monitored signals. However, by exploiting this mechanism, an attacker can\nfake the signals provided by corrupted sensors at training time and poison the\nlearning process of the detector such that cyber attacks go undetected at test\ntime. With this research, we are the first to demonstrate such poisoning\nattacks on ICS cyber attack online NN detectors. We propose two distinct attack\nalgorithms, namely, interpolation- and back-gradient based poisoning, and\ndemonstrate their effectiveness on both synthetic and real-world ICS data. We\nalso discuss and analyze some potential mitigation strategies.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 14:11:26 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Kravchik", "Moshe", ""], ["Biggio", "Battista", ""], ["Shabtai", "Asaf", ""]]}, {"id": "2012.15799", "submitter": "Wensheng Gan", "authors": "Jiahui Chen, Wensheng Gan, Muchuang Hu, Chien-Ming Chen", "title": "On the Construction of a Post-Quantum Blockchain for Smart City", "comments": "Elsevier. 20 pages, 9 figures, 6 tables", "journal-ref": "Journal of Information Security and Applications, 2021", "doi": "10.1016/j.jisa.2021.102780", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Owing to some special characteristics and features, blockchain is a very\nuseful technique that can securely organize diverse devices in a smart city. It\nfinds wide applications, especially in distributed environments, where entities\nsuch as wireless sensors need to be certain of the authenticity of the server.\nAs contemporary blockchain techniques that address post-quantum concerns have\nnot been designed, in this study, we investigate a blockchain in the\npost-quantum setting and seek to discover how it can resist attacks from\nquantum computing. In addition, traditional proof of work (PoW)-based consensus\nprotocols such as Bitcoin cannot supply memory mining, and the transaction\ncapacity of each block in a blockchain is limited and needs to be expanded.\nThus, a new post-quantum proof of work (post-quantum PoW) consensus algorithm\nfor security and privacy of smart city applications is proposed. It can be used\nto not only protect a blockchain under a quantum computing attack compared to\nexisting classical hash-based PoW algorithms but also to supply memory mining.\nMeanwhile, an identity-based post-quantum signature is embedded into a\ntransaction process to construct lightweight transactions. Subsequently, we\nprovide a detailed description on the execution of the post-quantum lightweight\ntransaction in a blockchain. Overall, this work can help enrich the research on\nfuture post-quantum blockchain and support the construction or architecture of\nemerging blockchain-based smart cities.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 18:21:16 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Chen", "Jiahui", ""], ["Gan", "Wensheng", ""], ["Hu", "Muchuang", ""], ["Chen", "Chien-Ming", ""]]}]