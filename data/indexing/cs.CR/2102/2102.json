[{"id": "2102.00021", "submitter": "Christopher Portmann", "authors": "Christopher Portmann and Renato Renner", "title": "Security in Quantum Cryptography", "comments": "60 pages, 34 figures. In submission to RMP. Partly based on\n  arXiv:1409.3525", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum cryptography exploits principles of quantum physics for the secure\nprocessing of information. A prominent example is secure communication, i.e.,\nthe task of transmitting confidential messages from one location to another.\nThe cryptographic requirement here is that the transmitted messages remain\ninaccessible to anyone other than the designated recipients, even if the\ncommunication channel is untrusted. In classical cryptography, this can usually\nonly be guaranteed under computational hardness assumptions, e.g., that\nfactoring large integers is infeasible. In contrast, the security of quantum\ncryptography relies entirely on the laws of quantum mechanics. Here we review\nthis physical notion of security, focusing on quantum key distribution and\nsecure communication.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 19:00:54 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Portmann", "Christopher", ""], ["Renner", "Renato", ""]]}, {"id": "2102.00029", "submitter": "Devin Willmott", "authors": "Devin Willmott, Anit Kumar Sahu, Fatemeh Sheikholeslami, Filipe\n  Condessa, Zico Kolter", "title": "You Only Query Once: Effective Black Box Adversarial Attacks with\n  Minimal Repeated Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers have repeatedly shown that it is possible to craft adversarial\nattacks on deep classifiers (small perturbations that significantly change the\nclass label), even in the \"black-box\" setting where one only has query access\nto the classifier. However, all prior work in the black-box setting attacks the\nclassifier by repeatedly querying the same image with minor modifications,\nusually thousands of times or more, making it easy for defenders to detect an\nensuing attack. In this work, we instead show that it is possible to craft\n(universal) adversarial perturbations in the black-box setting by querying a\nsequence of different images only once. This attack prevents detection from\nhigh number of similar queries and produces a perturbation that causes\nmisclassification when applied to any input to the classifier. In experiments,\nwe show that attacks that adhere to this restriction can produce untargeted\nadversarial perturbations that fool the vast majority of MNIST and CIFAR-10\nclassifier inputs, as well as in excess of $60-70\\%$ of inputs on ImageNet\nclassifiers. In the targeted setting, we exhibit targeted black-box universal\nattacks on ImageNet classifiers with success rates above $20\\%$ when only\nallowed one query per image, and $66\\%$ when allowed two queries per image.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 19:16:51 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Willmott", "Devin", ""], ["Sahu", "Anit Kumar", ""], ["Sheikholeslami", "Fatemeh", ""], ["Condessa", "Filipe", ""], ["Kolter", "Zico", ""]]}, {"id": "2102.00059", "submitter": "Michael Chiu", "authors": "Michael Chiu and Uro\\v{s} Kalabi\\'c", "title": "Debt Representation in UTXO Blockchains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a UTXO model of blockchain transactions that is able to represent\nboth credit and debt on the same blockchain. Ordinarily, the UTXO model is\nsolely used to represent credit and the representation of credit and debit\ntogether is achieved using the account model because of its support for\nbalances. However, the UTXO model provides superior privacy, safety, and\nscalability when compared to the account model. In this work, we introduce a\nUTXO model that has the flexibility of balances with the usual benefits of the\nUTXO model. This model extends the conventional UTXO model, which represents\ncredits as unmatched outputs, by representing debts as unmatched inputs. We\napply our model to solving the problem of transparency in reverse mortgage\nmarkets, in which some transparency is necessary for a healthy market but\ncomplete transparency leads to adverse outcomes. Here the pseudonymous\nproperties of the UTXO model protect the privacy of loan recipients while still\nallowing an aggregate view of the loan market. We present a prototype of our\nimplementation in Tendermint and discuss the design and its benefits.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 20:47:19 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Chiu", "Michael", ""], ["Kalabi\u0107", "Uro\u0161", ""]]}, {"id": "2102.00157", "submitter": "Andreas Heinemann", "authors": "Alexander Zeier and Alexander Wiesmaier and Andreas Heinemann", "title": "Zur Integration von Post-Quantum Verfahren in bestehende\n  Softwareprodukte", "comments": "to be published at 17. Deutscher IT-Sicherheitskongress des BSI,\n  2021. in german, 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Currently, PQC algorithms are being standardized to address the emerging\nthreat to conventional asymmetric algorithms from quantum computing. These new\nalgorithms must then be integrated into existing protocols, applications and\ninfrastructures. Integration problems are to be expected, due to\nincompatibilities with existing standards and implementations on the one hand,\nbut also due to a lack of knowledge among software developers about how to\nhandle PQC algorithms. To illustrate incompatibilities, we integrate two\ndifferent PQC algorithms into two different existing software products (the\nInboxPager email client for the Android OS and the TLS implementation of the\nBouncy Castle crypto library). Here, we rely on the highly-abstract crypto\nlibrary eUCRITE, which hides technical details about the correct usage of\nclassical and PCQ algorithms and thus prevents some potential implementation\nerrors.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 05:54:56 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Zeier", "Alexander", ""], ["Wiesmaier", "Alexander", ""], ["Heinemann", "Andreas", ""]]}, {"id": "2102.00177", "submitter": "Chao Li", "authors": "Chao Li, Balaji Palanisamy, Runhua Xu, Jinlai Xu, and Jingzhe Wang", "title": "SteemOps: Extracting and Analyzing Key Operations in Steemit\n  Blockchain-based Social Media Platform", "comments": "Accepted by ACM CODASPY'21. arXiv admin note: text overlap with\n  arXiv:1904.07310", "journal-ref": null, "doi": "10.1145/3422337.3447845", "report-no": null, "categories": "cs.CR cs.DB cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advancements in distributed ledger technologies are driving the rise of\nblockchain-based social media platforms such as Steemit, where users interact\nwith each other in similar ways as conventional social networks. These\nplatforms are autonomously managed by users using decentralized consensus\nprotocols in a cryptocurrency ecosystem. The deep integration of social\nnetworks and blockchains in these platforms provides potential for numerous\ncross-domain research studies that are of interest to both the research\ncommunities. However, it is challenging to process and analyze large volumes of\nraw Steemit data as it requires specialized skills in both software engineering\nand blockchain systems and involves substantial efforts in extracting and\nfiltering various types of operations. To tackle this challenge, we collect\nover 38 million blocks generated in Steemit during a 45 month time period from\n2016/03 to 2019/11 and extract ten key types of operations performed by the\nusers. The results generate SteemOps, a new dataset that organizes more than\n900 million operations from Steemit into three sub-datasets namely (i)\nsocial-network operation dataset (SOD), (ii) witness-election operation dataset\n(WOD) and (iii) value-transfer operation dataset (VOD). We describe the dataset\nschema and its usage in detail and outline possible future research studies\nusing SteemOps. SteemOps is designed to facilitate future research aimed at\nproviding deeper insights on emerging blockchain-based social media platforms.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 07:18:39 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 05:51:39 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Li", "Chao", ""], ["Palanisamy", "Balaji", ""], ["Xu", "Runhua", ""], ["Xu", "Jinlai", ""], ["Wang", "Jingzhe", ""]]}, {"id": "2102.00319", "submitter": "Nayna Jain", "authors": "Nayna Jain, Karthik Nandakumar, Nalini Ratha, Sharath Pankanti, Uttam\n  Kumar", "title": "Efficient CNN Building Blocks for Encrypted Data", "comments": "The Second AAAI Workshop on Privacy-Preserving Artificial\n  Intelligence (PPAI-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning on encrypted data can address the concerns related to\nprivacy and legality of sharing sensitive data with untrustworthy service\nproviders. Fully Homomorphic Encryption (FHE) is a promising technique to\nenable machine learning and inferencing while providing strict guarantees\nagainst information leakage. Since deep convolutional neural networks (CNNs)\nhave become the machine learning tool of choice in several applications,\nseveral attempts have been made to harness CNNs to extract insights from\nencrypted data. However, existing works focus only on ensuring data security\nand ignore security of model parameters. They also report high level\nimplementations without providing rigorous analysis of the accuracy, security,\nand speed trade-offs involved in the FHE implementation of generic primitive\noperators of a CNN such as convolution, non-linear activation, and pooling. In\nthis work, we consider a Machine Learning as a Service (MLaaS) scenario where\nboth input data and model parameters are secured using FHE. Using the CKKS\nscheme available in the open-source HElib library, we show that operational\nparameters of the chosen FHE scheme such as the degree of the cyclotomic\npolynomial, depth limitations of the underlying leveled HE scheme, and the\ncomputational precision parameters have a major impact on the design of the\nmachine learning model (especially, the choice of the activation function and\npooling method). Our empirical study shows that choice of aforementioned design\nparameters result in significant trade-offs between accuracy, security level,\nand computational time. Encrypted inference experiments on the MNIST dataset\nindicate that other design choices such as ciphertext packing strategy and\nparallelization using multithreading are also critical in determining the\nthroughput and latency of the inference process.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 21:47:23 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Jain", "Nayna", ""], ["Nandakumar", "Karthik", ""], ["Ratha", "Nalini", ""], ["Pankanti", "Sharath", ""], ["Kumar", "Uttam", ""]]}, {"id": "2102.00436", "submitter": "Xiaosen Wang", "authors": "Xiaosen Wang, Xuanran He, Jingdong Wang, Kun He", "title": "Admix: Enhancing the Transferability of Adversarial Attacks", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are known to be extremely vulnerable to adversarial\nexamples under white-box setting. Moreover, the malicious adversaries crafted\non the surrogate (source) model often exhibit black-box transferability on\nother models with the same learning task but having different architectures.\nRecently, various methods have been proposed to boost the adversarial\ntransferability, among which the input transformation is one of the most\neffective approaches. We investigate in this direction and observe that\nexisting transformations are all applied on a single image, which might limit\nthe adversarial transferability. To this end, we propose a new input\ntransformation based attack method called Admix that considers the input image\nand a set of images randomly sampled from other categories. Instead of directly\ncalculating the gradient on the original input, Admix calculates the gradient\non the input image admixed with a small portion of each add-in image while\nusing the original label of the input, to craft more transferable adversaries.\nEmpirical evaluations on standard ImageNet dataset demonstrate that Admix could\nachieve significantly better transferability than existing input transformation\nmethods under both single model setting and ensemble-model setting. By\nincorporating with existing input transformations, our method could further\nimprove the transferability and outperforms the state-of-the-art combination of\ninput transformations by a clear margin when attacking nine advanced defense\nmodels under ensemble-model setting.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 11:40:50 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 03:18:19 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Wang", "Xiaosen", ""], ["He", "Xuanran", ""], ["Wang", "Jingdong", ""], ["He", "Kun", ""]]}, {"id": "2102.00449", "submitter": "Pengrui Quan", "authors": "Pengrui Quan, Ruiming Guo, Mani Srivastava", "title": "Towards Imperceptible Query-limited Adversarial Attacks with Perceptual\n  Feature Fidelity Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, there has been a large amount of work towards fooling\ndeep-learning-based classifiers, particularly for images, via adversarial\ninputs that are visually similar to the benign examples. However, researchers\nusually use Lp-norm minimization as a proxy for imperceptibility, which\noversimplifies the diversity and richness of real-world images and human visual\nperception. In this work, we propose a novel perceptual metric utilizing the\nwell-established connection between the low-level image feature fidelity and\nhuman visual sensitivity, where we call it Perceptual Feature Fidelity Loss. We\nshow that our metric can robustly reflect and describe the imperceptibility of\nthe generated adversarial images validated in various conditions. Moreover, we\ndemonstrate that this metric is highly flexible, which can be conveniently\nintegrated into different existing optimization frameworks to guide the noise\ndistribution for better imperceptibility. The metric is particularly useful in\nthe challenging black-box attack with limited queries, where the\nimperceptibility is hard to achieve due to the non-trivial perturbation power.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 13:32:55 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Quan", "Pengrui", ""], ["Guo", "Ruiming", ""], ["Srivastava", "Mani", ""]]}, {"id": "2102.00459", "submitter": "Neo Chung-Kit Yiu", "authors": "Neo C.K. Yiu", "title": "Toward Blockchain-Enabled Supply Chain Anti-Counterfeiting and\n  Traceability", "comments": "20 pages", "journal-ref": null, "doi": "10.13140/RG.2.2.22989.36322", "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Innovative solutions addressing product anti-counterfeiting and record\nprovenance have been deployed across today's internationally spanning supply\nchain networks. These product anti-counterfeiting solutions are developed and\nimplemented with centralized system architecture relying on centralized\nauthorities or any form of intermediaries. Vulnerabilities of centralized\nproduct anti-counterfeiting solutions could possibly lead to system failure or\nsusceptibility of malicious modifications performed on product records or\nvarious potential attacks to the system components by dishonest participant\nnodes traversing along the supply chain. Blockchain technology has progressed\nfrom merely with a use case of immutable ledger for cryptocurrency transactions\nto a programmable interactive environment of developing decentralized and\nreliable applications addressing different use cases globally. In this\nresearch, so as to facilitate trustworthy data provenance retrieval,\nverification and management, as well as strengthening capability of product\nanti-counterfeiting, key areas of decentralization and feasible mechanisms of\ndeveloping decentralized and distributed product anti-counterfeiting and\ntraceability ecosystems utilizing blockchain technology, are identified via a\nseries of security and threat analyses performed mainly against NFC-Enabled\nAnti-Counterfeiting System (NAS) which is one of the solutions currently\nimplemented in the industry with centralized architecture. A set of fundamental\nsystem requirements are set out for developing a blockchain-enabled autonomous\nand decentralized solution for supply chain anti-counterfeiting and\ntraceability, as a secure and immutable scientific data provenance tracking and\nmanagement platform in which provenance records, providing compelling\nproperties on data integrity of luxurious goods, are recorded and verified\nautomatically, for supply chain industry.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 14:18:37 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Yiu", "Neo C. K.", ""]]}, {"id": "2102.00528", "submitter": "Alexander Kott", "authors": "Alexandre Ligo, Alexander Kott, Igor Linkov", "title": "How to Measure Cyber Resilience of an Autonomous Agent: Approaches and\n  Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Several approaches have been used to assess the performance of cyberphysical\nsystems and their exposure to various types of risks. Such assessments have\nbecome increasingly important as autonomous attackers ramp up the frequency,\nduration and intensity of threats while autonomous agents have the potential to\nrespond to cyber-attacks with unprecedented speed and scale. However, most\nassessment approaches have limitations with respect to measuring cyber\nresilience, or the ability of systems to absorb, recover from, and adapt to\ncyberattacks. In this paper, we provide an overview of several common\napproaches, discuss practical challenges and propose research directions for\nthe development of effective cyber resilience measures.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 20:31:06 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Ligo", "Alexandre", ""], ["Kott", "Alexander", ""], ["Linkov", "Igor", ""]]}, {"id": "2102.00647", "submitter": "Deepti Gupta", "authors": "Raj Chaganti, Deepti Gupta, Naga Vemprala", "title": "Intelligent Network Layer for Cyber-Physical Systems Security", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cyber-Physical System (CPS) has made a tremendous progress in recent years\nand also disrupted many technical fields such as smart industries, smart\nhealth, smart transportation etc. to flourish the nations economy. However, CPS\nSecurity is still one of the concerns for wide adoption owing to high number of\ndevices connecting to the internet and the traditional security solutions may\nnot be suitable to protect the advanced, application specific attacks. This\npaper presents a programmable device network layer architecture to combat\nattacks and efficient network monitoring in heterogeneous environment CPS\napplications. We leverage Industrial control systems (ICS) to discuss the\nexisting issues, highlighting the importance of advanced network layer for CPS.\nThe programmable data plane language (P4) is introduced to detect well known\nHELLO Flood attack with minimal efforts in the network level and also used to\nfeaturing the potential solutions for security.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 05:48:41 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Chaganti", "Raj", ""], ["Gupta", "Deepti", ""], ["Vemprala", "Naga", ""]]}, {"id": "2102.00654", "submitter": "Shun Zhang", "authors": "Shun Zhang, Benfei Duan, Zhili Chen, Tianjiao Ni, and Hong Zhong", "title": "Regionalized location obfuscation mechanism with personalized privacy\n  levels", "comments": "12 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global Positioning Systems are now a standard module in mobile devices, and\ntheir ubiquity is fueling the rapid growth of location-based services (LBSs).\nThis poses the risk of location privacy disclosure. Effective location privacy\npreservation is foremost for various mobile applications. Recently two strong\nprivacy notions, geo-indistinguishability and expected inference error, are\nproposed based on statistical quantification. They are shown to be\ncomplementary for limiting the leakage of location information. In this paper,\nwe argue that personalization means regionalization for\ngeo-indistinguishability, and we propose a regionalized location obfuscation\nmechanism with personalized utility sensitivities. This substantially corrects\nthe differential privacy problem of PIVE framework proposed by Yu, Liu and Pu\non ISOC Network and Distributed System Security Symposium (NDSS) in 2017. Since\nPIVE fails to provide differential privacy guarantees on adaptive protection\nlocation set (PLS) as pointed in our previous work, we develop DPIVE with two\nphases. In Phase I, we determine disjoint sets by partitioning all possible\npositions such that different locations in the same set share the common PLS.\nIn Phase II, we construct a probability distribution matrix by exponential\nmechanism in which the rows corresponding to the same PLS have their own\nsensitivity of utility (diameter of PLS). Moreover, we improve DPIVE with\nrefined location partition and fine-grained personalization, in which each\nlocation has its own privacy level on two privacy control knobs, minimum\ninference error and differential privacy parameter. Experiments with two public\ndatasets demonstrate that our mechanisms have the superior performance\ntypically on skewed locations.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 06:05:10 GMT"}, {"version": "v2", "created": "Fri, 7 May 2021 05:12:13 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Zhang", "Shun", ""], ["Duan", "Benfei", ""], ["Chen", "Zhili", ""], ["Ni", "Tianjiao", ""], ["Zhong", "Hong", ""]]}, {"id": "2102.00724", "submitter": "Tiago Diadami Perez", "authors": "Tiago Perez, Malik Imran, Pablo Vaz, Samuel Pagliarini", "title": "Side-Channel Trojan Insertion -- a Practical Foundry-Side Attack via ECO", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Design companies often outsource their integrated circuit (IC) fabrication to\nthird parties where ICs are susceptible to malicious acts such as the insertion\nof a side-channel hardware trojan horse (SCT). In this paper, we present a\nframework for designing and inserting an SCT based on an engineering change\norder (ECO) flow, which makes it the first to disclose how effortlessly a\ntrojan can be inserted into an IC. The trojan is designed with the goal of\nleaking multiple bits per power signature reading. Our findings and results\nshow that a rogue element within a foundry has, today, all means necessary for\nperforming a foundry-side attack via ECO.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 09:34:09 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 10:11:51 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Perez", "Tiago", ""], ["Imran", "Malik", ""], ["Vaz", "Pablo", ""], ["Pagliarini", "Samuel", ""]]}, {"id": "2102.00790", "submitter": "Stefan Wagner", "authors": "Ana Cristina Franco da Silva, Stefan Wagner, Eddie Lazebnik, Eyal\n  Traitel", "title": "Using a Cyber Digital Twin for Continuous Automotive Security\n  Requirements Verification", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Digital Twin (DT) is a digital representation of a physical object used to\nsimulate it before it is built or to predict failures after the object is\ndeployed. The DT concept was originally applied to manufacturing but has been\ngaining attention in other areas. In this article, we introduce a novel concept\ncalled Cyber Digital Twin (CDT), which transfers the idea of the DT to\nautomotive software for the purpose of security analysis. In our approach, the\nECU software (i.e., firmware) is transformed into a CDT, which contains\nautomatically extracted, security-relevant information from the firmware. With\nthis, we can evaluate automotive security requirements through automated\nsecurity requirements verification using policy enforcement checks and\ndetection of security vulnerabilities. The evaluation can be done continuously\nusing newly integrated checks and published security vulnerabilities.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 12:07:09 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["da Silva", "Ana Cristina Franco", ""], ["Wagner", "Stefan", ""], ["Lazebnik", "Eddie", ""], ["Traitel", "Eyal", ""]]}, {"id": "2102.00856", "submitter": "Cedric Lauradoux", "authors": "Guilhem Lacombe and Kseniia Masalygina and Anass Tahiri and Carole\n  Adam and C\\'edric Lauradoux", "title": "Can You Accept LaTeX Files from Strangers? Ten Years Later", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is well-known that Microsoft Word/Excel compatible documents or PDF files\ncan contain malicious content. LaTeX files are unfortunately no exception\neither. LaTeX users often include third-party codes through sources or packages\n(.sty or .cls files). But those packages can execute malicious commands on the\nusers' system, in order to capture sensitive information or to perform denial\nof service attacks. Checkoway et al. [3] were the first to warn LaTeX users of\nthese threats. Collaborative cloud-based LaTeX editors and services compiling\nLaTeX sources are particularly concerned. In this paper, we have created a\nLaTeX package that collects system data and hides them inside the PDF file\nproduced by the target. Then, we have measured what can be recovered by hackers\nusing malicious LaTeX file on online services, and which measures those\nservices have enforced to thwart the threats. Services defend themselves using\nsandbox or commands restrictions. Commands restrictions are more difficult to\nsetup and we found one service (PMLatex) which is too permissive.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 14:11:57 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Lacombe", "Guilhem", ""], ["Masalygina", "Kseniia", ""], ["Tahiri", "Anass", ""], ["Adam", "Carole", ""], ["Lauradoux", "C\u00e9dric", ""]]}, {"id": "2102.00898", "submitter": "Mohit Sewak", "authors": "Mohit Sewak and Sanjay K. Sahay and Hemant Rathore", "title": "DRLDO: A novel DRL based De-ObfuscationSystem for Defense against\n  Metamorphic Malware", "comments": null, "journal-ref": "Defence Science Journal, 71(1), 55-65", "doi": "10.14429/dsj.71.15780", "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel mechanism to normalize metamorphic and\nobfuscated malware down at the opcode level and hence create an advanced\nmetamorphic malware de-obfuscation and defense system. We name this system\nDRLDO, for Deep Reinforcement Learning based De-Obfuscator. With the inclusion\nof the DRLDO as a sub-component, an existing Intrusion Detection System could\nbe augmented with defensive capabilities against 'zero-day' attacks from\nobfuscated and metamorphic variants of existing malware. This gains importance,\nnot only because there exists no system to date that uses advanced DRL to\nintelligently and automatically normalize obfuscation down even to the opcode\nlevel, but also because the DRLDO system does not mandate any changes to the\nexisting IDS. The DRLDO system does not even mandate the IDS' classifier to be\nretrained with any new dataset containing obfuscated samples. Hence DRLDO could\nbe easily retrofitted into any existing IDS deployment. We designed, developed,\nand conducted experiments on the system to evaluate the same against\nmultiple-simultaneous attacks from obfuscations generated from malware samples\nfrom a standardized dataset that contains multiple generations of malware.\nExperimental results prove that DRLDO was able to successfully make the\notherwise un-detectable obfuscated variants of the malware detectable by an\nexisting pre-trained malware classifier. The detection probability was raised\nwell above the cut-off mark to 0.6 for the classifier to detect the obfuscated\nmalware unambiguously. Further, the de-obfuscated variants generated by DRLDO\nachieved a very high correlation (of 0.99) with the base malware. This\nobservation validates that the DRLDO system is actually learning to\nde-obfuscate and not exploiting a trivial trick.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 15:16:18 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Sewak", "Mohit", ""], ["Sahay", "Sanjay K.", ""], ["Rathore", "Hemant", ""]]}, {"id": "2102.00918", "submitter": "Alireza Bahramali", "authors": "Alireza Bahramali and Milad Nasr and Amir Houmansadr and Dennis\n  Goeckel and Don Towsley", "title": "Robust Adversarial Attacks Against DNN-Based Wireless Communication\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have become prevalent in wireless communication\nsystems due to their promising performance. However, similar to other DNN-based\napplications, they are vulnerable to adversarial examples. In this work, we\npropose an input-agnostic, undetectable, and robust adversarial attack against\nDNN-based wireless communication systems in both white-box and black-box\nscenarios. We design tailored Universal Adversarial Perturbations (UAPs) to\nperform the attack. We also use a Generative Adversarial Network (GAN) to\nenforce an undetectability constraint for our attack. Furthermore, we\ninvestigate the robustness of our attack against countermeasures. We show that\nin the presence of defense mechanisms deployed by the communicating parties,\nour attack performs significantly better compared to existing attacks against\nDNN-based wireless systems. In particular, the results demonstrate that even\nwhen employing well-considered defenses, DNN-based wireless communications are\nvulnerable to adversarial attacks.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 15:36:40 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Bahramali", "Alireza", ""], ["Nasr", "Milad", ""], ["Houmansadr", "Amir", ""], ["Goeckel", "Dennis", ""], ["Towsley", "Don", ""]]}, {"id": "2102.00921", "submitter": "Alexander Schl\\\"ogl", "authors": "Alexander Schl\\\"ogl, Tobias Kupek, Rainer B\\\"ohme", "title": "Forensicability of Deep Neural Network Inference Pipelines", "comments": "Accepted at ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose methods to infer properties of the execution environment of\nmachine learning pipelines by tracing characteristic numerical deviations in\nobservable outputs. Results from a series of proof-of-concept experiments\nobtained on local and cloud-hosted machines give rise to possible forensic\napplications, such as the identification of the hardware platform used to\nproduce deep neural network predictions. Finally, we introduce boundary samples\nthat amplify the numerical deviations in order to distinguish machines by their\npredicted label only.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 15:41:49 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 11:57:12 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Schl\u00f6gl", "Alexander", ""], ["Kupek", "Tobias", ""], ["B\u00f6hme", "Rainer", ""]]}, {"id": "2102.00973", "submitter": "Suryanarayana Sankagiri", "authors": "Suryanarayana Sankagiri, Shreyas Gandlur, Bruce Hajek", "title": "The Longest-Chain Protocol Under Random Delays", "comments": "30 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the field of distributed consensus and blockchains, the synchronous\ncommunication model assumes that all messages between honest parties are\ndelayed at most by a known constant $\\Delta$. Recent literature establishes\nthat the longest-chain blockchain protocol is secure under the synchronous\nmodel. However, for a fixed mining rate, the security guarantees degrade with\n$\\Delta$. We analyze the performance of the longest-chain protocol under the\nassumption that the communication delays are random, independent, and\nidentically distributed. This communication model allows for distributions with\nunbounded support and is a strict generalization of the synchronous model. We\nprovide safety and liveness guarantees with simple, explicit bounds on the\nfailure probabilities. These bounds hold for infinite-horizon executions and\ndecay exponentially with the security parameter. In particular, we show that\nthe longest-chain protocol has good security guarantees when delays are\nsporadically large and possibly unbounded, which is reflective of real-world\nnetwork conditions.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 16:56:08 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Sankagiri", "Suryanarayana", ""], ["Gandlur", "Shreyas", ""], ["Hajek", "Bruce", ""]]}, {"id": "2102.00980", "submitter": "Paul Ryan Mr", "authors": "Paul Ryan, and Harshvardhan J. Pandit and Rob Brennan", "title": "A Common Semantic Model of the GDPR Register of Processing Activities", "comments": null, "journal-ref": null, "doi": "10.3233/FAIA200876", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The creation and maintenance of a Register of Processing Activities (ROPA) is\nan essential process for the demonstration of GDPR compliance. We analyse ROPA\ntemplates from six EU Data Protection Regulators and show that template scope\nand granularity vary widely between jurisdictions. We then propose a flexible,\nconsolidated data model for consistent processing of ROPAs (CSM-ROPA). We\nanalyse the extent that the Data Privacy Vocabulary (DPV) can be used to\nexpress CSM-ROPA. We find that it does not directly address modelling ROPAs,\nand so needs additional concept definitions. We provide a mapping of our\nCSM-ROPA to an extension of the Data Privacy Vocabulary.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 17:05:37 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Ryan", "Paul", ""], ["Pandit", "Harshvardhan J.", ""], ["Brennan", "Rob", ""]]}, {"id": "2102.01048", "submitter": "Vasiliki Kalavri", "authors": "John Liagouris, Vasiliki Kalavri, Muhammad Faisal, Mayank Varia", "title": "Secrecy: Secure collaborative analytics on secret-shared data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study the problem of composing and optimizing relational query plans under\nsecure multi-party computation (MPC). MPC enables mutually distrusting parties\nto jointly compute arbitrary functions over private data, while preserving data\nprivacy from each other and from external entities.\n  In this paper, we propose a relational MPC framework based on replicated\nsecret sharing. We define a set of oblivious operators, explain the secure\nprimitives they rely on, and provide an analysis of their costs in terms of\noperations and inter-party communication. We show how these operators can be\ncomposed to form end-to-end oblivious queries, and we introduce logical and\nphysical optimizations that dramatically reduce the space and communication\nrequirements during query execution, in some cases from quadratic to linear\nwith respect to the cardinality of the input.\n  We provide an efficient implementation of our framework, called Secrecy, and\nevaluate it using real queries from several MPC application areas. Our results\ndemonstrate that the optimizations we propose can result in up to 1000x lower\nexecution times compared to baseline approaches, enabling Secrecy to outperform\nstate-of-the-art frameworks and compute MPC queries on millions of input rows\nwith a single thread per party.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 18:37:20 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Liagouris", "John", ""], ["Kalavri", "Vasiliki", ""], ["Faisal", "Muhammad", ""], ["Varia", "Mayank", ""]]}, {"id": "2102.01072", "submitter": "Scott Freitas", "authors": "Scott Freitas, Rahul Duggal, Duen Horng Chau", "title": "MalNet: A Large-Scale Cybersecurity Image Database of Malicious Software", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer vision is playing an increasingly important role in automated\nmalware detection with to the rise of the image-based binary representation.\nThese binary images are fast to generate, require no feature engineering, and\nare resilient to popular obfuscation methods. Significant research has been\nconducted in this area, however, it has been restricted to small-scale or\nprivate datasets that only a few industry labs and research teams have access\nto. This lack of availability hinders examination of existing work, development\nof new research, and dissemination of ideas. We introduce MalNet, the largest\npublicly available cybersecurity image database, offering 133x more images and\n27x more classes than the only other public binary-image database. MalNet\ncontains over 1.2 million images across a hierarchy of 47 types and 696\nfamilies. We provide extensive analysis of MalNet, discussing its properties\nand provenance. The scale and diversity of MalNet unlocks new and exciting\ncybersecurity opportunities to the computer vision community--enabling\ndiscoveries and research directions that were previously not possible. The\ndatabase is publicly available at www.mal-net.org.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 02:59:03 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Freitas", "Scott", ""], ["Duggal", "Rahul", ""], ["Chau", "Duen Horng", ""]]}, {"id": "2102.01249", "submitter": "Runhua Xu", "authors": "Runhua Xu, Chao Li, James Joshi", "title": "T3AB: Transparent and Trustworthy Third-party Authority using Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Increasingly, information systems rely on computational, storage, and network\nresources deployed in third-party facilities or are supported by service\nproviders. Such an approach further exacerbates cybersecurity concerns\nconstantly raised by numerous incidents of security and privacy attacks\nresulting in data leakage and identity theft, among others. These have in turn\nforced the creation of stricter security and privacy related regulations and\nhave eroded the trust in cyberspace. In particular, security related services\nand infrastructures such as Certificate Authorities (CAs) that provide digital\ncertificate service and Third-Party Authorities (TPAs) that provide\ncryptographic key services, are critical components for establishing trust in\nInternet enabled applications and services. To address such trust issues,\nvarious transparency frameworks and approaches have been recently proposed in\nthe literature. In this paper, we propose a Transparent and Trustworthy TPA\nusing Blockchain (T3AB) to provide transparency and accountability to the\ntrusted third-party entities, such as honest-but-curious third-party IaaS\nservers, and coordinators in various privacy-preserving machine learning (PPML)\napproaches. T3AB employs the Ethereum blockchain as the underlying public\nledger and also includes a novel smart contract to automate accountability with\nan incentive mechanism that motivates participants' to participate in auditing,\nand punishes unintentional or malicious behaviors. We implement T3AB, and show\nthrough experimental evaluation in the Ethereum official test network, Rinkeby,\nthat the framework is efficient. We also formally show the security guarantee\nprovided by T3AB, and analyze the privacy guarantee and trustworthiness it\nprovides.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 01:24:24 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 15:23:54 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Xu", "Runhua", ""], ["Li", "Chao", ""], ["Joshi", "James", ""]]}, {"id": "2102.01356", "submitter": "Tao Bai", "authors": "Tao Bai, Jinqi Luo, Jun Zhao, Bihan Wen, Qian Wang", "title": "Recent Advances in Adversarial Training for Adversarial Robustness", "comments": "accepted by International Joint Conference on Artificial Intelligence\n  (IJCAI-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is one of the most effective approaches defending\nagainst adversarial examples for deep learning models. Unlike other defense\nstrategies, adversarial training aims to promote the robustness of models\nintrinsically. During the last few years, adversarial training has been studied\nand discussed from various aspects. A variety of improvements and developments\nof adversarial training are proposed, which were, however, neglected in\nexisting surveys. For the first time in this survey, we systematically review\nthe recent progress on adversarial training for adversarial robustness with a\nnovel taxonomy. Then we discuss the generalization problems in adversarial\ntraining from three perspectives. Finally, we highlight the challenges which\nare not fully tackled and present potential future directions.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 07:10:22 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 07:13:24 GMT"}, {"version": "v3", "created": "Thu, 18 Feb 2021 06:56:07 GMT"}, {"version": "v4", "created": "Tue, 23 Feb 2021 09:49:42 GMT"}, {"version": "v5", "created": "Wed, 21 Apr 2021 01:57:53 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Bai", "Tao", ""], ["Luo", "Jinqi", ""], ["Zhao", "Jun", ""], ["Wen", "Bihan", ""], ["Wang", "Qian", ""]]}, {"id": "2102.01375", "submitter": "Boyi Liu", "authors": "Zhaohua Zheng, Yize Zhou, Yilong Sun, Zhang Wang, Boyi Liu and Keqiu\n  Li", "title": "Applications of Federated Learning in Smart Cities: Recent Advances,\n  Taxonomy, and Open Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning plays an important role in the process of smart cities.\nWith the development of big data and artificial intelligence, there is a\nproblem of data privacy protection in this process. Federated learning is\ncapable of solving this problem. This paper starts with the current\ndevelopments of federated learning and its applications in various fields. We\nconduct a comprehensive investigation. This paper summarize the latest research\non the application of federated learning in various fields of smart cities.\nIn-depth understanding of the current development of federated learning from\nthe Internet of Things, transportation, communications, finance, medical and\nother fields. Before that, we introduce the background, definition and key\ntechnologies of federated learning. Further more, we review the key\ntechnologies and the latest results. Finally, we discuss the future\napplications and research directions of federated learning in smart cities.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 08:02:38 GMT"}, {"version": "v2", "created": "Sun, 14 Mar 2021 02:44:06 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Zheng", "Zhaohua", ""], ["Zhou", "Yize", ""], ["Sun", "Yilong", ""], ["Wang", "Zhang", ""], ["Liu", "Boyi", ""], ["Li", "Keqiu", ""]]}, {"id": "2102.01397", "submitter": "Simon Scherrer", "authors": "Simon Scherrer, Che-Yu Wu, Yu-Hsi Chiang, Benjamin Rothenberger,\n  Daniele E. Asoni, Arish Sateesan, Jo Vliegen, Nele Mentens, Hsu-Chun Hsiao,\n  Adrian Perrig", "title": "Low-Rate Overuse Flow Tracer (LOFT): An Efficient and Scalable Algorithm\n  for Detecting Overuse Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current probabilistic flow-size monitoring can only detect heavy hitters\n(e.g., flows utilizing 10 times their permitted bandwidth), but cannot detect\nsmaller overuse (e.g., flows utilizing 50-100% more than their permitted\nbandwidth). Thus, these systems lack accuracy in the challenging environment of\nhigh-throughput packet processing, where fast-memory resources are scarce.\nNevertheless, many applications rely on accurate flow-size estimation, e.g. for\nnetwork monitoring, anomaly detection and Quality of Service.\n  We design, analyze, implement, and evaluate LOFT, a new approach for\nefficiently detecting overuse flows that achieves dramatically better\nproperties than prior work. LOFT can detect 1.5x overuse flows in one second,\nwhereas prior approaches fail to detect 2x overuse flows within a timeout of\n300 seconds. We demonstrate LOFT's suitability for high-speed packet processing\nwith implementations in the DPDK framework and on an FPGA.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 09:33:14 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Scherrer", "Simon", ""], ["Wu", "Che-Yu", ""], ["Chiang", "Yu-Hsi", ""], ["Rothenberger", "Benjamin", ""], ["Asoni", "Daniele E.", ""], ["Sateesan", "Arish", ""], ["Vliegen", "Jo", ""], ["Mentens", "Nele", ""], ["Hsiao", "Hsu-Chun", ""], ["Perrig", "Adrian", ""]]}, {"id": "2102.01456", "submitter": "Neo Chung-Kit Yiu", "authors": "Neo C.K. Yiu", "title": "Decentralizing Supply Chain Anti-Counterfeiting Systems Using Blockchain\n  Technology", "comments": "21 pages", "journal-ref": null, "doi": "10.13140/RG.2.2.13309.69609", "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An interesting research problem in supply chain industry is evaluating and\ndetermining provenance of physical goods - demonstrating authenticity of luxury\ngoods. Yet, there have been a few innovative software solutions addressing\nproduct anti-counterfeiting and record provenance of today's goods that are\nproduced and transported in complex and internationally-spanning supply chain\nnetworks. However, these supply chain systems have been implemented with\ncentralized system architecture, relying on centralized authorities or any form\nof intermediaries, and leading to issues such as single-point processing,\nstorage and failure, which could be susceptible to malicious modifications of\nproduct records or various potential attacks to system components by dishonest\nparticipant nodes traversing along the supply chain. Blockchain technology has\nevolved from being merely a decentralized, distributed and immutable ledger of\ncryptocurrency transactions to a programmable interactive environment for\nbuilding decentralized and reliable applications addressing different use cases\nand existing problems in the world. In this research, the Decentralized\nNFC-Enabled Anti-Counterfeiting System (dNAS) is proposed and developed,\ndecentralizing a legacy anti-counterfeiting system of supply chain industry\nusing Blockchain technology, to facilitate trustworthy data provenance\nretrieval, verification and management, as well as strengthening capability of\nproduct anti-counterfeiting in supply chain industry. The proposed dNAS\nutilizes decentralized blockchain network on a consensus protocol compatible\nwith the concept of enterprise consortium, programmable smart contracts and a\ndistributed file storage system to develop a secure and immutable scientific\ndata provenance tracking and management platform on which provenance records,\nproviding compelling properties on data integrity, are validated automatically.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 12:17:10 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Yiu", "Neo C. K.", ""]]}, {"id": "2102.01468", "submitter": "Yinbo Yu", "authors": "Yinbo Yu and Jiajia Liu", "title": "TAPInspector: Safety and Liveness Verification of Concurrent\n  Trigger-Action IoT Systems", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC cs.NI cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Trigger-action programming (TAP) is a popular end-user programming framework\nthat can simplify the Internet of Things (IoT) automation with simple\ntrigger-action rules. However, it also introduces new security and safety\nthreats. A lot of advanced techniques have been proposed to address this\nproblem. Rigorously reasoning about the security of a TAP-based IoT system\nrequires a well-defined model and verification method both against rule\nsemantics and physical-world states, e.g., concurrency, rule latency, and\nconnection-based interactions, which has been missing until now. This paper\npresents TAPInspector, a novel system to detect vulnerabilities in concurrent\nTAP-based IoT systems using model checking. It automatically extracts TAP rules\nfrom IoT apps, translates them into a hybrid model with model slicing and state\ncompression, and performs model checking with various safety and liveness\nproperties. Our experiments corroborate that TAPInspector is effective: it\nidentifies 533 violations with 9 new types of violations from 1108 real-world\nmarket IoT apps and is 60000 times faster than the baseline without\noptimization at least.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 12:39:59 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Yu", "Yinbo", ""], ["Liu", "Jiajia", ""]]}, {"id": "2102.01478", "submitter": "Muneeb Ul Hassan", "authors": "Muneeb Ul Hassan, Mubashir Husain Rehmani, Jinjun Chen", "title": "Differentially Private Demand Side Management for Incentivized Dynamic\n  Pricing in Smart Grid", "comments": "Submitted to Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to efficiently provide demand side management (DSM) in smart grid,\ncarrying out pricing on the basis of real-time energy usage is considered to be\nthe most vital tool because it is directly linked with the finances associated\nwith smart meters. Hence, every smart meter user wants to pay minimum possible\namount along with getting maximum benefits. In here, usage based dynamic\npricing strategies of DSM plays their role and provide users with specific\nincentives that help shaping their load curve according to the forecasted load.\nHowever, these reported real-time values can leak privacy of smart meter users,\nwhich can lead to serious consequences such as spying, etc. Moreover, most of\ndynamic pricing algorithms charges all users equally irrespective of their\ncontribution in causing peak factor. Therefore, in this paper, we propose a\nmodified usage based dynamic pricing mechanism that only charges the users\nresponsible for causing peak factor. We further integrate the concept of\ndifferential privacy to protect the privacy of real-time smart metering data\nand to calculate accurate billing, we propose a noise adjustment method.\nFinally, we propose Demand Response enhancing Differential Pricing (DRDP)\nstrategy that effectively enhances demand response along with providing dynamic\npricing to smart meter users. We also carry out extensive theoretical analysis\nfor differential privacy guarantees and for cooperative state probability to\nanalyse behaviour of cooperative smart meters. The performance evaluation of\nDRDP strategy at various privacy parameters show that the proposed strategy\noutperforms previous mechanisms in terms of dynamic pricing and privacy\npreservation.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 13:05:33 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Hassan", "Muneeb Ul", ""], ["Rehmani", "Mubashir Husain", ""], ["Chen", "Jinjun", ""]]}, {"id": "2102.01480", "submitter": "Muneeb Ul Hassan", "authors": "Muneeb Ul Hassan, Mubashir Husain Rehmani, Jinjun Chen", "title": "VPT: Privacy Preserving Energy Trading and Block Mining Mechanism for\n  Blockchain based Virtual Power Plants", "comments": "Article Submitted for Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The desire to overcome reliability issues of distributed energy resources\n(DERs) lead researchers to development of a novel concept named as virtual\npower plant (VPP). VPPs are supposed to carry out intelligent, secure, and\nsmart energy trading among prosumers, buyers, and generating stations along\nwith providing efficient energy management. Therefore, integrating blockchain\nin decentralized VPP network emerged out as a new paradigm, and recent\nexperiments over this integration have shown fruitful results. However, this\ndecentralization also suffers with energy management, trust, reliability, and\nefficiency issues due to the dynamic nature of DERs. In order to overcome this,\nin this paper, we first work over providing efficient energy management\nstrategy for VPP to enhance demand response, then we propose an energy oriented\ntrading and block mining protocol and named it as proof of energy market\n(PoEM). To enhance it further, we integrate differential privacy in PoEM and\npropose a Private PoEM (PPoEM) model. Collectively, we propose a private\ndecentralized VPP trading model and named it as Virtual Private Trading (VPT)\nmodel. We further carry out extensive theoretical analysis and derive\nstep-by-step valuations for market race probability, market stability\nprobability, energy trading expectation, winning state probability, and\nprospective leading time profit values. Afterwards, we carry out\nsimulation-based experiment of our proposed model. The performance evaluation\nand theoretical analysis of our VPT model make it one of the most viable model\nfor blockchain based VPP network as compared to other state-of-the-art works.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 13:11:24 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Hassan", "Muneeb Ul", ""], ["Rehmani", "Mubashir Husain", ""], ["Chen", "Jinjun", ""]]}, {"id": "2102.01502", "submitter": "Satyapriya Krishna", "authors": "Satyapriya Krishna, Rahul Gupta, Christophe Dupuy", "title": "ADePT: Auto-encoder based Differentially Private Text Transformation", "comments": null, "journal-ref": "The 16th conference of the European Chapter of the Association for\n  Computational Linguistics (EACL), 2021", "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Privacy is an important concern when building statistical models on data\ncontaining personal information. Differential privacy offers a strong\ndefinition of privacy and can be used to solve several privacy concerns (Dwork\net al., 2014). Multiple solutions have been proposed for the\ndifferentially-private transformation of datasets containing sensitive\ninformation. However, such transformation algorithms offer poor utility in\nNatural Language Processing (NLP) tasks due to noise added in the process. In\nthis paper, we address this issue by providing a utility-preserving\ndifferentially private text transformation algorithm using auto-encoders. Our\nalgorithm transforms text to offer robustness against attacks and produces\ntransformations with high semantic quality that perform well on downstream NLP\ntasks. We prove the theoretical privacy guarantee of our algorithm and assess\nits privacy leakage under Membership Inference Attacks(MIA) (Shokri et al.,\n2017) on models trained with transformed data. Our results show that the\nproposed model performs better against MIA attacks while offering lower to no\ndegradation in the utility of the underlying transformation process compared to\nexisting baselines.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 23:15:24 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Krishna", "Satyapriya", ""], ["Gupta", "Rahul", ""], ["Dupuy", "Christophe", ""]]}, {"id": "2102.01509", "submitter": "Yangde Wang", "authors": "Yangde Wang (1), Weidong Qiu (1), Yuming Xie (1), Yan Zha (1) ((1)\n  Shanghai Jiaotong University)", "title": "PatternMonitor: a whole pipeline with a much higher level of automation\n  for guessing Android lock pattern based on videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pattern lock is a general technique used to realize identity authentication\nand access authorization on mobile terminal devices such as Android platform\ndevices, but it is vulnerable to the attack proposed by recent researches that\nexploit information leaked by users while drawing patterns. However, the\nexisting attacks on pattern lock are environmentally sensitive, and rely\nheavily on manual work, which constrains the practicability of these attack\napproaches. To attain a more practical attack, this paper designs the\nPatternMonitor, a whole pipeline with a much higher level of automation system\nagainsts pattern lock, which extracts the guessed candidate patterns from a\nvideo containing pattern drawing: instead of manually cutting the target video\nand setting thresholds, it first employs recognition models to locate the\ntarget phone and keypoints of pattern drawing hand, which enables the gesture\ncan be recognized even when the fingertips are shaded. Then, we extract the\nframes from the video where the drawing starts and ends. These pre-processed\nframes are inputs of target tracking model to generate trajectories, and\nfurther transformed into possible candidate patterns by performing our designed\nalgorithm. To the best of our knowledge, our work is the first attack system to\ngenerate candidate patterns by only relying on hand movement instead of\naccurate fingertips capture. The experimental results demonstrates that our\nwork is as accurate as previous work, which gives more than 90\\% success rate\nwithin 20 attempts.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 14:22:45 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Wang", "Yangde", ""], ["Qiu", "Weidong", ""], ["Xie", "Yuming", ""], ["Zha", "Yan", ""]]}, {"id": "2102.01515", "submitter": "Gadekallu Thippa Reddy", "authors": "V. Priya, I. Sumaiya Thaseen, Thippa Reddy Gadekallu, Mohamed K.\n  Aboudaif, Emad Abouel Nasr", "title": "Robust Attack Detection Approach for IIoT Using Ensemble Classifier", "comments": null, "journal-ref": null, "doi": "10.32604/cmc.2021.013852", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generally, the risks associated with malicious threats are increasing for the\nIIoT and its related applications due to dependency on the Internet and the\nminimal resource availability of IoT devices. Thus, anomaly-based intrusion\ndetection models for IoT networks are vital. Distinct detection methodologies\nneed to be developed for the IIoT network as threat detection is a significant\nexpectation of stakeholders. Machine learning approaches are considered to be\nevolving techniques that learn with experience, and such approaches have\nresulted in superior performance in various applications, such as pattern\nrecognition, outlier analysis, and speech recognition. Traditional techniques\nand tools are not adequate to secure IIoT networks due to the use of various\nprotocols in industrial systems and restricted possibilities of upgradation. In\nthis paper, the objective is to develop a two-phase anomaly detection model to\nenhance the reliability of an IIoT network. In the first phase, SVM and Naive\nBayes are integrated using an ensemble blending technique. K-fold\ncross-validation is performed while training the data with different training\nand testing ratios to obtain optimized training and test sets. Ensemble\nblending uses a random forest technique to predict class labels. An Artificial\nNeural Network (ANN) classifier that uses the Adam optimizer to achieve better\naccuracy is also used for prediction. In the second phase, both the ANN and\nrandom forest results are fed to the model's classification unit, and the\nhighest accuracy value is considered the final result. The proposed model is\ntested on standard IoT attack datasets, such as WUSTL_IIOT-2018, N_BaIoT, and\nBot_IoT. The highest accuracy obtained is 99%. The results also demonstrate\nthat the proposed model outperforms traditional techniques and thus improves\nthe reliability of an IIoT network.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 07:21:44 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Priya", "V.", ""], ["Thaseen", "I. Sumaiya", ""], ["Gadekallu", "Thippa Reddy", ""], ["Aboudaif", "Mohamed K.", ""], ["Nasr", "Emad Abouel", ""]]}, {"id": "2102.01570", "submitter": "Sitan Chen", "authors": "Sitan Chen, Zhao Song, Runzhou Tao, Ruizhe Zhang", "title": "Symmetric Boolean Factor Analysis with Applications to InstaHide", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we examine the security of InstaHide, a recently proposed scheme\nfor distributed learning (Huang et al.). A number of recent works have given\nreconstruction attacks for InstaHide in various regimes by leveraging an\nintriguing connection to the following matrix factorization problem: given the\nGram matrix of a collection of m random k-sparse Boolean vectors in {0,1}^r,\nrecover the vectors (up to the trivial symmetries). Equivalently, this can be\nthought of as a sparse, symmetric variant of the well-studied problem of\nBoolean factor analysis, or as an average-case version of the classic problem\nof recovering a k-uniform hypergraph from its line graph.\n  As previous algorithms either required m to be exponentially large in k or\nonly applied to k = 2, they left open the question of whether InstaHide\npossesses some form of \"fine-grained security\" against reconstruction attacks\nfor moderately large k. In this work, we answer this in the negative by giving\na simple O(m^{\\omega + 1}) time algorithm for the above matrix factorization\nproblem. Our algorithm, based on tensor decomposition, only requires m to be at\nleast quasi-linear in r. We complement this result with a quasipolynomial-time\nalgorithm for a worst-case setting of the problem where the collection of\nk-sparse vectors is chosen arbitrarily.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 15:52:52 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Chen", "Sitan", ""], ["Song", "Zhao", ""], ["Tao", "Runzhou", ""], ["Zhang", "Ruizhe", ""]]}, {"id": "2102.01722", "submitter": "Assane Gueye", "authors": "Assane Gueye and Peter Mell", "title": "A Historical and Statistical Studyof the Software Vulnerability\n  Landscape", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding the landscape of software vulnerabilities is key for developing\neffective security solutions. Fortunately, the evaluation of vulnerability\ndatabases that use a framework for communicating vulnerability attributes and\ntheir severity scores, such as the Common Vulnerability Scoring System (CVSS),\ncan help shed light on the nature of publicly published vulnerabilities. In\nthis paper, we characterize the software vulnerability landscape by performing\na historical and statistical analysis of CVSS vulnerability metrics over the\nperiod of 2005 to 2019 through using data from the National Vulnerability\nDatabase. We conduct three studies analyzing the following: the distribution of\nCVSS scores (both empirical and theoretical), the distribution of CVSS metric\nvalues and how vulnerability characteristics change over time, and the relative\nrankings of the most frequent metric value over time. Our resulting analysis\nshows that the vulnerability threat landscape has been dominated by only a few\nvulnerability types and has changed little during the time period of the study.\nThe overwhelming majority of vulnerabilities are exploitable over the network.\nThe complexity to successfully exploit these vulnerabilities is dominantly low;\nvery little authentication to the target victim is necessary for a successful\nattack. And most of the flaws require very limited interaction with users.\nHowever on the positive side, the damage of these vulnerabilities is mostly\nconfined within the security scope of the impacted components. A discussion of\nlessons that could be learned from this analysis is presented.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 19:35:50 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Gueye", "Assane", ""], ["Mell", "Peter", ""]]}, {"id": "2102.01812", "submitter": "Muslum Ozgur Ozmen", "authors": "Muslum Ozgur Ozmen, Xuansong Li, Andrew Chun-An Chu, Z. Berkay Celik,\n  Bardh Hoxha and Xiangyu Zhang", "title": "Discovering Physical Interaction Vulnerabilities in IoT Deployments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) applications drive the behavior of IoT deployments\naccording to installed sensors and actuators. It has recently been shown that\nIoT deployments are vulnerable to physical interactions, caused by design flaws\nor malicious intent, that can have severe physical consequences. Yet, extant\napproaches to securing IoT do not translate the app source code into its\nphysical behavior to evaluate physical interactions. Thus, IoT consumers and\nmarkets do not possess the capability to assess the safety and security risks\nthese interactions present. In this paper, we introduce the IoTSeer security\nservice for IoT deployments, which uncovers undesired states caused by physical\ninteractions. IoTSeer operates in four phases (1) translation of each actuation\ncommand and sensor event in an app source code into a hybrid I/O automaton that\ndefines an app's physical behavior, (2) combining apps in a novel composite\nautomaton that represents the joint physical behavior of interacting apps, (3)\napplying grid-based testing and falsification to validate whether an IoT\ndeployment conforms to desired physical interaction policies, and (4)\nidentification of the root cause of policy violations and proposing patches\nthat guide users to prevent them. We use IoTSeer in an actual house with 13\nactuators and six sensors with 37 apps and demonstrate its effectiveness and\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 00:31:59 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Ozmen", "Muslum Ozgur", ""], ["Li", "Xuansong", ""], ["Chu", "Andrew Chun-An", ""], ["Celik", "Z. Berkay", ""], ["Hoxha", "Bardh", ""], ["Zhang", "Xiangyu", ""]]}, {"id": "2102.01815", "submitter": "Xinqiao Zhang", "authors": "Xinqiao Zhang, Huili Chen and Farinaz Koushanfar", "title": "TAD: Trigger Approximation based Black-box Trojan Detection for AI", "comments": "6 body pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  An emerging amount of intelligent applications have been developed with the\nsurge of Machine Learning (ML). Deep Neural Networks (DNNs) have demonstrated\nunprecedented performance across various fields such as medical diagnosis and\nautonomous driving. While DNNs are widely employed in security-sensitive\nfields, they are identified to be vulnerable to Neural Trojan (NT) attacks that\nare controlled and activated by the stealthy trigger. We call this vulnerable\nmodel adversarial artificial intelligence (AI). In this paper, we target to\ndesign a robust Trojan detection scheme that inspects whether a pre-trained AI\nmodel has been Trojaned before its deployment. Prior works are oblivious of the\nintrinsic property of trigger distribution and try to reconstruct the trigger\npattern using simple heuristics, i.e., stimulating the given model to incorrect\noutputs. As a result, their detection time and effectiveness are limited. We\nleverage the observation that the pixel trigger typically features spatial\ndependency and propose TAD, the first trigger approximation based Trojan\ndetection framework that enables fast and scalable search of the trigger in the\ninput space. Furthermore, TAD can also detect Trojans embedded in the feature\nspace where certain filter transformations are used to activate the Trojan. We\nperform extensive experiments to investigate the performance of the TAD across\nvarious datasets and ML models. Empirical results show that TAD achieves a\nROC-AUC score of 0:91 on the public TrojAI dataset 1 and the average detection\ntime per model is 7:1 minutes.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 00:49:50 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 18:45:48 GMT"}, {"version": "v3", "created": "Tue, 20 Apr 2021 21:46:32 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Zhang", "Xinqiao", ""], ["Chen", "Huili", ""], ["Koushanfar", "Farinaz", ""]]}, {"id": "2102.01854", "submitter": "Xiaoyu Cao", "authors": "Xiaoyu Cao, Jinyuan Jia, Neil Zhenqiang Gong", "title": "Provably Secure Federated Learning against Malicious Clients", "comments": "Accepted by AAAI-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning enables clients to collaboratively learn a shared global\nmodel without sharing their local training data with a cloud server. However,\nmalicious clients can corrupt the global model to predict incorrect labels for\ntesting examples. Existing defenses against malicious clients leverage\nByzantine-robust federated learning methods. However, these methods cannot\nprovably guarantee that the predicted label for a testing example is not\naffected by malicious clients. We bridge this gap via ensemble federated\nlearning. In particular, given any base federated learning algorithm, we use\nthe algorithm to learn multiple global models, each of which is learnt using a\nrandomly selected subset of clients. When predicting the label of a testing\nexample, we take majority vote among the global models. We show that our\nensemble federated learning with any base federated learning algorithm is\nprovably secure against malicious clients. Specifically, the label predicted by\nour ensemble global model for a testing example is provably not affected by a\nbounded number of malicious clients. Moreover, we show that our derived bound\nis tight. We evaluate our method on MNIST and Human Activity Recognition\ndatasets. For instance, our method can achieve a certified accuracy of 88% on\nMNIST when 20 out of 1,000 clients are malicious.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 03:24:17 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 03:43:50 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 16:14:35 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Cao", "Xiaoyu", ""], ["Jia", "Jinyuan", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "2102.01873", "submitter": "Praneet Singh", "authors": "Praneet Singh, Jishnu Jaykumar, Akhil Pankaj, Reshmi Mitra", "title": "Edge-Detect: Edge-centric Network Intrusion Detection using Deep Neural\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge nodes are crucial for detection against multitudes of cyber attacks on\nInternet-of-Things endpoints and is set to become part of a multi-billion\nindustry. The resource constraints in this novel network infrastructure tier\nconstricts the deployment of existing Network Intrusion Detection System with\nDeep Learning models (DLM). We address this issue by developing a novel light,\nfast and accurate 'Edge-Detect' model, which detects Distributed Denial of\nService attack on edge nodes using DLM techniques. Our model can work within\nresource restrictions i.e. low power, memory and processing capabilities, to\nproduce accurate results at a meaningful pace. It is built by creating layers\nof Long Short-Term Memory or Gated Recurrent Unit based cells, which are known\nfor their excellent representation of sequential data. We designed a practical\ndata science pipeline with Recurring Neural Network to learn from the network\npacket behavior in order to identify whether it is normal or attack-oriented.\nThe model evaluation is from deployment on actual edge node represented by\nRaspberry Pi using current cybersecurity dataset (UNSW2015). Our results\ndemonstrate that in comparison to conventional DLM techniques, our model\nmaintains a high testing accuracy of 99% even with lower resource utilization\nin terms of cpu and memory. In addition, it is nearly 3 times smaller in size\nthan the state-of-art model and yet requires a much lower testing time.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 04:24:34 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Singh", "Praneet", ""], ["Jaykumar", "Jishnu", ""], ["Pankaj", "Akhil", ""], ["Mitra", "Reshmi", ""]]}, {"id": "2102.01908", "submitter": "Yucheng Liu", "authors": "Yucheng Liu, Lawrence Ong, Sarah Johnson, Joerg Kliewer, Parastoo\n  Sadeghi, Phee Lep Yeoh", "title": "Information Leakage in Zero-Error Source Coding: A Graph-Theoretic\n  Perspective", "comments": "A shortened version has been submitted to ISIT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the information leakage to a guessing adversary in zero-error source\ncoding. The source coding problem is defined by a confusion graph capturing the\ndistinguishability between source symbols. The information leakage is measured\nby the ratio of the adversary's successful guessing probability after and\nbefore eavesdropping the codeword, maximized over all possible source\ndistributions. Such measurement under the basic adversarial model where the\nadversary makes a single guess and allows no distortion between its estimator\nand the true sequence is known as the maximum min-entropy leakage or the\nmaximal leakage in the literature. We develop a single-letter characterization\nof the optimal normalized leakage under the basic adversarial model, together\nwith an optimum-achieving scalar stochastic mapping scheme. An interesting\nobservation is that the optimal normalized leakage is equal to the optimal\ncompression rate with fixed-length source codes, both of which can be\nsimultaneously achieved by some deterministic coding schemes. We then extend\nthe leakage measurement to generalized adversarial models where the adversary\nmakes multiple guesses and allows certain level of distortion, for which we\nderive single-letter lower and upper bounds.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 06:58:12 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Liu", "Yucheng", ""], ["Ong", "Lawrence", ""], ["Johnson", "Sarah", ""], ["Kliewer", "Joerg", ""], ["Sadeghi", "Parastoo", ""], ["Yeoh", "Phee Lep", ""]]}, {"id": "2102.01944", "submitter": "Zainab Abaid", "authors": "Zainab Abaid and Dilip Sarkar and Mohamed Ali Kaafar and Sanjay Jha", "title": "All Infections are Not Created Equal: Time-Sensitive Prediction of\n  Malware Generated Network Attacks", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many techniques have been proposed for quickly detecting and containing\nmalware-generated network attacks such as large-scale denial of service\nattacks; unfortunately, much damage is already done within the first few\nminutes of an attack, before it is identified and contained. There is a need\nfor an early warning system that can predict attacks before they actually\nmanifest, so that upcoming attacks can be prevented altogether by blocking the\nhosts that are likely to engage in attacks. However, blocking responses may\ndisrupt legitimate processes on blocked hosts; in order to minimise user\ninconvenience, it is important to also foretell the time when the predicted\nattacks will occur, so that only the most urgent threats result in\nauto-blocking responses, while less urgent ones are first manually\ninvestigated. To this end, we identify a typical infection sequence followed by\nmodern malware; modelling this sequence as a Markov chain and training it on\nreal malicious traffic, we are able to identify behaviour most likely to lead\nto attacks and predict 98\\% of real-world spamming and port-scanning attacks\nbefore they occur. Moreover, using a Semi-Markov chain model, we are able to\nforetell the time of upcoming attacks, a novel capability that allows\naccurately predicting the times of 97% of real-world malware attacks. Our work\nrepresents an important and timely step towards enabling flexible threat\nresponse models that minimise disruption to legitimate users.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 08:45:34 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Abaid", "Zainab", ""], ["Sarkar", "Dilip", ""], ["Kaafar", "Mohamed Ali", ""], ["Jha", "Sanjay", ""]]}, {"id": "2102.02126", "submitter": "Erik M{\\aa}rtensson", "authors": "Qian Guo, Erik M{\\aa}rtensson and Paul Stankovski Wagner", "title": "On the Sample Complexity of solving LWE using BKW-Style Algorithms", "comments": "This paper is the arXiv version of a paper submitted to ISIT 2021.\n  Appendices A and B are not included in the conference version due to page\n  restrictions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Learning with Errors (LWE) problem receives much attention in\ncryptography, mainly due to its fundamental significance in post-quantum\ncryptography. Among its solving algorithms, the Blum-Kalai-Wasserman (BKW)\nalgorithm, originally proposed for solving the Learning Parity with Noise (LPN)\nproblem, performs well, especially for certain parameter settings with\ncryptographic importance. The BKW algorithm consists of two phases, the\nreduction phase and the solving phase.\n  In this work, we study the performance of distinguishers used in the solving\nphase. We show that the Fast Fourier Transform (FFT) distinguisher from\nEurocrypt'15 has the same sample complexity as the optimal distinguisher, when\nmaking the same number of hypotheses. We also show that it performs much better\nthan theory predicts and introduce an improvement of it called the pruned FFT\ndistinguisher. Finally, we indicate, via extensive experiments, that the sample\ndependency due to both LF2 and sample amplification is limited.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 16:08:38 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Guo", "Qian", ""], ["M\u00e5rtensson", "Erik", ""], ["Wagner", "Paul Stankovski", ""]]}, {"id": "2102.02128", "submitter": "Yixiang Wang", "authors": "Yixiang Wang, Jiqiang Liu, Xiaolin Chang, Jelena Mi\\v{s}i\\'c, and\n  Vojislav B. Mi\\v{s}i\\'c", "title": "IWA: Integrated Gradient based White-box Attacks for Fooling Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread application of deep neural network (DNN) techniques is being\nchallenged by adversarial examples, the legitimate input added with\nimperceptible and well-designed perturbations that can fool DNNs easily in the\nDNN testing/deploying stage. Previous adversarial example generation algorithms\nfor adversarial white-box attacks used Jacobian gradient information to add\nperturbations. This information is too imprecise and inexplicit, which will\ncause unnecessary perturbations when generating adversarial examples. This\npaper aims to address this issue. We first propose to apply a more informative\nand distilled gradient information, namely integrated gradient, to generate\nadversarial examples. To further make the perturbations more imperceptible, we\npropose to employ the restriction combination of $L_0$ and $L_1/L_2$ secondly,\nwhich can restrict the total perturbations and perturbation points\nsimultaneously. Meanwhile, to address the non-differentiable problem of $L_1$,\nwe explore a proximal operation of $L_1$ thirdly. Based on these three works,\nwe propose two Integrated gradient based White-box Adversarial example\ngeneration algorithms (IWA): IFPA and IUA. IFPA is suitable for situations\nwhere there are a determined number of points to be perturbed. IUA is suitable\nfor situations where no perturbation point number is preset in order to obtain\nmore adversarial examples. We verify the effectiveness of the proposed\nalgorithms on both structured and unstructured datasets, and we compare them\nwith five baseline generation algorithms. The results show that our proposed\nalgorithms do craft adversarial examples with more imperceptible perturbations\nand satisfactory crafting rate. $L_2$ restriction is more suitable for\nunstructured dataset and $L_1$ restriction performs better in structured\ndataset.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 16:10:42 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Wang", "Yixiang", ""], ["Liu", "Jiqiang", ""], ["Chang", "Xiaolin", ""], ["Mi\u0161i\u0107", "Jelena", ""], ["Mi\u0161i\u0107", "Vojislav B.", ""]]}, {"id": "2102.02196", "submitter": "Markku-Juhani Saarinen", "authors": "Markku-Juhani O. Saarinen", "title": "On Entropy and Bit Patterns of Ring Oscillator Jitter", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thermal jitter (phase noise) from a free-running ring oscillator is a common,\neasily implementable physical randomness source in True Random Number\nGenerators (TRNGs). We show how to evaluate entropy, autocorrelation, and bit\npattern distributions of such entropy sources, even when they have low jitter\nlevels or some bias. Our numerical evaluation algorithms vastly outperform\nsimple Monte Carlo simulations in speed and accuracy. This helps in choosing\nthe most appropriate parameters for TRNG self-tests and cryptographic\npost-processing. We also propose a new, safer lower bound estimation formula\nfor the entropy of such randomness sources.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 18:48:44 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 10:55:58 GMT"}, {"version": "v3", "created": "Thu, 25 Feb 2021 09:45:39 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Saarinen", "Markku-Juhani O.", ""]]}, {"id": "2102.02243", "submitter": "Setareh Sharifian", "authors": "Setareh Sharifian, Reihaneh Safavi-Naini", "title": "Information-theoretic Key Encapsulation and its Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hybrid encryption scheme is a public-key encryption system that consists of\na public-key part called the key encapsulation mechanism (KEM), and a\n(symmetric) secret-key part called data encapsulation mechanism (DEM): the\npublic-key part is used to generate a shared secret key between two parties,\nand the symmetric key part is used to encrypt the message using the generated\nkey. Hybrid encryption schemes are widely used for secure communication over\nthe Internet. In this paper, we initiate the study of hybrid encryption in\npreprocessing model which assumes access to initial correlated variables by all\nparties (including the eavesdropper). We define information-theoretic KEM\n(iKEM) that, together with a (computationally) secure DEM, results in a hybrid\nencryption scheme in preprocessing model. We define the security of each\nbuilding block, and prove a composition theorem that guarantees (computational)\nqe-chosen plaintext (CPA) security of the hybrid encryption system if the iKEM\nand the DEM satisfy qe-chosen encapculation attack and one-time security,\nrespectively. We show that iKEM can be realized by a one-way SKA (OW-SKA)\nprotocol with a revised security definition. Using an OW-SKA that satisfies\nthis revised definition of security effectively allows the secret key that is\ngenerated by the OW-SKA to be used with a one-time symmetric key encryption\nsystem such as XORing a pseudorandom string with the message, and provide\nqe-CPA security for the hybrid encryption system.We discuss our results and\ndirections for future work.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 19:23:55 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 23:15:20 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Sharifian", "Setareh", ""], ["Safavi-Naini", "Reihaneh", ""]]}, {"id": "2102.02247", "submitter": "Michael Neuder", "authors": "Michael Neuder, Daniel J. Moroz, Rithvik Rao and David C. Parkes", "title": "Low-cost attacks on Ethereum 2.0 by sub-1/3 stakeholders", "comments": "First appeared in the Workshop for Game Theory in Blockchain (GTiB)\n  at the 2020 Conference on Web and Internet Economics (WINE).\n  https://econcs.pku.edu.cn/wine2020/wine2020/Workshop/GTiB20_paper_8.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We outline two dishonest strategies that can be cheaply executed on the\nEthereum 2.0 beacon chain, even by validators holding less than one-third of\nthe total stake: malicious chain reorganizations (\"reorgs\") and finality\ndelays. In a malicious reorg, an attacker withholds their blocks and\nattestations before releasing them at an opportune time in order to force a\nchain reorganization, which they can take advantage of by double-spending or\nfront-running transactions. To execute a finality delay an attacker uses\ndelayed block releases and withholding of attestations to increase the mean and\nvariance of the time it takes blocks to become finalized. This impacts the\nefficiency and predictability of the system. We provide a probabilistic and\ncost analysis for each of these attacks, considering a validator with 30% of\nthe total stake.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 19:30:54 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Neuder", "Michael", ""], ["Moroz", "Daniel J.", ""], ["Rao", "Rithvik", ""], ["Parkes", "David C.", ""]]}, {"id": "2102.02308", "submitter": "Timothy Trippel", "authors": "Timothy Trippel, Kang G. Shin, Alex Chernyakhovsky, Garret Kelly,\n  Dominic Rizzo, Matthew Hicks", "title": "Fuzzing Hardware Like Software", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware flaws are permanent and potent: hardware cannot be patched once\nfabricated, and any flaws may undermine any software executing on top.\nConsequently, verification time dominates implementation time. The gold\nstandard in hardware Design Verification (DV) is concentrated at two extremes:\nrandom dynamic verification and formal verification. Both struggle to root out\nthe subtle flaws in complex hardware that often manifest as security\nvulnerabilities. The root problem with random verification is its undirected\nnature, making it inefficient, while formal verification is constrained by the\nstate-space explosion problem, making it infeasible against complex designs.\nWhat is needed is a solution that is directed, yet under-constrained.\n  Instead of making incremental improvements to existing DV approaches, we\nleverage the observation that existing software fuzzers already provide such a\nsolution, and adapt them for hardware DV. Specifically, we translate RTL\nhardware to a software model and fuzz that model. The central challenge we\naddress is how best to mitigate the differences between the hardware execution\nmodel and software execution model. This includes: 1) how to represent test\ncases, 2) what is the hardware equivalent of a crash, 3) what is an appropriate\ncoverage metric, and 4) how to create a general-purpose fuzzing harness for\nhardware.\n  To evaluate our approach, we fuzz four IP blocks from Google's OpenTitan SoC.\nOur experiments reveal a two orders-of-magnitude reduction in run time to\nachieve Finite State Machine (FSM) coverage over traditional dynamic\nverification schemes. Moreover, with our design-agnostic harness, we achieve\nover 88% HDL line coverage in three out of four of our designs -- even without\nany initial seeds.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 22:03:30 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Trippel", "Timothy", ""], ["Shin", "Kang G.", ""], ["Chernyakhovsky", "Alex", ""], ["Kelly", "Garret", ""], ["Rizzo", "Dominic", ""], ["Hicks", "Matthew", ""]]}, {"id": "2102.02368", "submitter": "Thlaes Silva", "authors": "Thales Silva, Carmina Porto, Erickson Alves, Lucas Cordeiro and\n  Herbert Rocha", "title": "Verifying Security Vulnerabilities in Large Software Systems using\n  Multi-Core k-Induction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Computer-based systems have been used to solve several domain problems, such\nas industrial, military, education, and wearable. Those systems need\nhigh-quality software to guarantee security and safety. We advocate that\nBounded Model Checking (BMC) techniques can detect security vulnerabilities in\nthe early stages of development processes. However, this technique struggles to\nscale up and verify large software commonly found on computer-based systems.\nHere, we develop and evaluate a pragmatic approach to verify large software\nsystems using a state-of-the-art bounded model checker. In particular, we\npre-process the input source-code files and then guide the model checker to\nexplore the code systematically. We also present a multi-core implementation of\nthe k-induction proof algorithm to verify and falsify large software systems\niteratively. Our experimental results using the Efficient SMT-based Model\nChecker (ESBMC) show that our approach can guide ESBMC to efficiently verify\nlarge software systems. We evaluate our approach using the PuTTY application to\nverify 136 files and 2803 functions in less than 86 minutes, and the SlimGuard\nallocator, where we have found real security vulnerabilities confirmed by the\ndevelopers. We conclude that our approach can successfully guide a bounded\nmodel checker to verify large software systems systematically.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 01:55:31 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Silva", "Thales", ""], ["Porto", "Carmina", ""], ["Alves", "Erickson", ""], ["Cordeiro", "Lucas", ""], ["Rocha", "Herbert", ""]]}, {"id": "2102.02394", "submitter": "Ivica Nikolic", "authors": "Ivica Nikolic and Radu Mantu and Shiqi Shen and Prateek Saxena", "title": "Refined Grey-Box Fuzzing with SIVO", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-80825-9", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design and implement from scratch a new fuzzer called SIVO that refines\nmultiple stages of grey-box fuzzing. First, SIVO refines data-flow fuzzing in\ntwo ways: (a) it provides a new taint inference engine that requires only\nlogarithmic in the input size number of tests to infer the dependency of all\nprogram branches on the input bytes, and (b) it deploys a novel method for\ninverting branches by solving directly and efficiently systems of inequalities.\nSecond, our fuzzer refines accurate tracking and detection of code coverage\nwith simple and easily implementable methods. Finally, SIVO refines selection\nof parameters and strategies by parameterizing all stages of fuzzing and then\ndynamically selecting optimal values during fuzzing. Thus the fuzzer can easily\nadapt to a target program and rapidly increase coverage. We compare our fuzzer\nto 11 other state-of-the-art grey-box fuzzers on 27 popular benchmarks. Our\nevaluation shows that SIVO scores the highest both in terms of code coverage\nand in terms of number of found vulnerabilities.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 03:40:30 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 06:59:07 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Nikolic", "Ivica", ""], ["Mantu", "Radu", ""], ["Shen", "Shiqi", ""], ["Saxena", "Prateek", ""]]}, {"id": "2102.02402", "submitter": "Zhuosheng Zhang", "authors": "Zhuosheng Zhang, Jiarui Li, Shucheng Yu, Christian Makaya", "title": "SAFELearning: Enable Backdoor Detectability In Federated Learning With\n  Secure Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For model privacy, local model parameters in federated learning shall be\nobfuscated before sent to the remote aggregator. This technique is referred to\nas \\emph{secure aggregation}. However, secure aggregation makes model poisoning\nattacks, e.g., to insert backdoors, more convenient given existing anomaly\ndetection methods mostly require access to plaintext local models. This paper\nproposes SAFELearning which supports backdoor detection for secure aggregation.\nWe achieve this through two new primitives - \\emph{oblivious random grouping\n(ORG)} and \\emph{partial parameter disclosure (PPD)}. ORG partitions\nparticipants into one-time random subgroups with group configurations oblivious\nto participants; PPD allows secure partial disclosure of aggregated subgroup\nmodels for anomaly detection without leaking individual model privacy.\nSAFELearning is able to significantly reduce backdoor model accuracy without\njeopardizing the main task accuracy under common backdoor strategies. Extensive\nexperiments show SAFELearning reduces backdoor accuracy from $100\\%$ to $8.2\\%$\nfor ResNet-18 over CIFAR-10 when $10\\%$ participants are malicious.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 04:07:39 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Zhang", "Zhuosheng", ""], ["Li", "Jiarui", ""], ["Yu", "Shucheng", ""], ["Makaya", "Christian", ""]]}, {"id": "2102.02456", "submitter": "Kris Shrishak", "authors": "Kris Shrishak and Haya Shulman", "title": "Privacy Preserving and Resilient RPKI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Resource Public Key Infrastructure (RPKI) is vital to the security of\ninter-domain routing. However, RPKI enables Regional Internet Registries (RIRs)\nto unilaterally takedown IP prefixes - indeed, such attacks have been launched\nby nation-state adversaries. The threat of IP prefix takedowns is one of the\nfactors hindering RPKI adoption.\n  In this work, we propose the first distributed RPKI system, based on\nthreshold signatures, that requires the coordination of a number of RIRs to\nmake changes to RPKI objects; hence, preventing unilateral prefix takedown. We\nperform extensive evaluations using our implementation demonstrating the\npracticality of our solution. Furthermore, we show that our system is scalable\nand remains efficient even when RPKI is widely deployed.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 07:34:38 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Shrishak", "Kris", ""], ["Shulman", "Haya", ""]]}, {"id": "2102.02465", "submitter": "Lizhi Sun", "authors": "Lizhi Sun, Shuocheng Wang, Hao Wu, Yuhang Gong, Fengyuan Xu, Yunxin\n  Liu, Hao Han, Sheng Zhong", "title": "App Developer Centric Trusted Execution Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ARM TrustZone is the de-facto hardware TEE implementation on mobile devices\nlike smartphones. As a vendor-centric TEE, TrustZone greatly overlooks the\nstrong protection demands and requirements from the App developers. Several\nsecurity solutions have been proposed to enable the TEE-assisted isolation in\nthe Normal World of ARM, attempting to balance the security and usability.\nHowever, they are still not full-fledged in serving Apps' needs. In this paper,\nwe introduce LEAP, which is a lightweight App developer Centric TEE solution in\nthe Normal World. LEAP offers the auto DevOps tool to help developers to\nprepare the codes running on it, enables isolated codes to execute in parallel\nand access peripheral (e.g. mobile GPUs) with ease, and dynamically manage\nsystem resources upon Apps' requests. We implement the LEAP prototype on the\noff-the-shelf ARM platform without any hardware change. We perform the\ncomprehensive analyses and experiments to demonstrate that LEAP is efficient in\ndesign, comprehensive in support, and convenient in adoption.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 07:49:36 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Sun", "Lizhi", ""], ["Wang", "Shuocheng", ""], ["Wu", "Hao", ""], ["Gong", "Yuhang", ""], ["Xu", "Fengyuan", ""], ["Liu", "Yunxin", ""], ["Han", "Hao", ""], ["Zhong", "Sheng", ""]]}, {"id": "2102.02527", "submitter": "Andrea Fioraldi", "authors": "Andrea Fioraldi and Luigi Paolo Pileggi", "title": "FuzzSplore: Visualizing Feedback-Driven Fuzzing Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fuzz Testing techniques are the state of the art in software testing for\nsecurity issues nowadays. Their great effectiveness attracted the attention of\nresearchers and hackers and involved them in developing a lot of new techniques\nto improve Fuzz Testing. The evaluation and the cross-comparison of these\ntechniques is an almost open problem. In this paper, we propose a human-driven\napproach to this problem based on information visualization. We developed a\nprototype upon the AFL++ fuzzing framework, FuzzSplore, that an analyst can use\nto get useful insights about different fuzzing configurations applied to a\nspecific target in order to choose or tune the best technique during a fuzzing\ncampaign.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 10:35:36 GMT"}, {"version": "v2", "created": "Sat, 6 Feb 2021 13:19:52 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Fioraldi", "Andrea", ""], ["Pileggi", "Luigi Paolo", ""]]}, {"id": "2102.02551", "submitter": "Yang Zhang", "authors": "Yugeng Liu and Rui Wen and Xinlei He and Ahmed Salem and Zhikun Zhang\n  and Michael Backes and Emiliano De Cristofaro and Mario Fritz and Yang Zhang", "title": "ML-Doctor: Holistic Risk Assessment of Inference Attacks Against Machine\n  Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Inference attacks against Machine Learning (ML) models allow adversaries to\nlearn information about training data, model parameters, etc. While researchers\nhave studied these attacks thoroughly, they have done so in isolation. We lack\na comprehensive picture of the risks caused by the attacks, such as the\ndifferent scenarios they can be applied to, the common factors that influence\ntheir performance, the relationship among them, or the effectiveness of defense\ntechniques. In this paper, we fill this gap by presenting a first-of-its-kind\nholistic risk assessment of different inference attacks against machine\nlearning models. We concentrate on four attacks - namely, membership inference,\nmodel inversion, attribute inference, and model stealing - and establish a\nthreat model taxonomy. Our extensive experimental evaluation conducted over\nfive model architectures and four datasets shows that the complexity of the\ntraining dataset plays an important role with respect to the attack's\nperformance, while the effectiveness of model stealing and membership inference\nattacks are negatively correlated. We also show that defenses like DP-SGD and\nKnowledge Distillation can only hope to mitigate some of the inference attacks.\nOur analysis relies on a modular re-usable software, ML-Doctor, which enables\nML model owners to assess the risks of deploying their models, and equally\nserves as a benchmark tool for researchers and practitioners.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 11:35:13 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Liu", "Yugeng", ""], ["Wen", "Rui", ""], ["He", "Xinlei", ""], ["Salem", "Ahmed", ""], ["Zhang", "Zhikun", ""], ["Backes", "Michael", ""], ["De Cristofaro", "Emiliano", ""], ["Fritz", "Mario", ""], ["Zhang", "Yang", ""]]}, {"id": "2102.02583", "submitter": "Muneeb Ul Hassan", "authors": "Muneeb Ul Hassan, Mubashir Husain Rehmani, Jinjun Chen", "title": "Optimizing Blockchain Based Smart Grid Auctions: A Green Revolution", "comments": "Submitted to Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional smart grid energy auctions cannot directly be integrated in\nblockchain due to its decentralized nature. Therefore, research works are being\ncarried out to propose efficient decentralized auctions for energy trading.\nSince, blockchain is a novel paradigm which ensures trust, but it also comes up\nwith a curse of high computation and communication complexity which eventually\ncauses resource scarcity. Therefore, there is a need to develop and encourage\ndevelopment of greener and computational-friendly auctions to carry out\ndecentralized energy trading. In this paper, we first provide a thorough\nmotivation of decentralized auctions over traditional auctions. Afterwards, we\nprovide in-depth design requirements that can be taken into consideration while\ndeveloping such auctions. After that, we analyze technical works that have\ndeveloped blockchain based energy auctions from green perspective. Finally, we\nsummarize the article by providing challenges and possible future research\ndirections of blockchain based energy auction from green viewpoint.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 12:56:24 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 02:25:41 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Hassan", "Muneeb Ul", ""], ["Rehmani", "Mubashir Husain", ""], ["Chen", "Jinjun", ""]]}, {"id": "2102.02601", "submitter": "Neo Chung-Kit Yiu", "authors": "Neo C.K. Yiu", "title": "An Empirical Analysis of Implementing Enterprise Blockchain Protocols in\n  Supply Chain Anti-Counterfeiting and Traceability", "comments": "18 pages", "journal-ref": null, "doi": "10.13140/RG.2.2.20322.04805", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of innovative software solutions, addressing product\nanti-counterfeiting and record provenance of the wider supply chain industry,\nhave been implemented. However, these solutions have been developed with\ncentralized system architecture which could be susceptible to malicious\nmodifications on states of product records and various potential security\nattacks leading to system failure and downtime. Blockchain technology has been\nenabling decentralized trust with a network of distributed peer nodes to\nmaintain consistent shared states via a decentralized consensus reached, with\nwhich an idea of developing decentralized and reliable solutions has been\nbasing on. A Decentralized NFC-Enabled Anti-Counterfeiting System (dNAS) was\ntherefore proposed and developed, decentralizing a legacy anti-counterfeiting\nsystem of supply chain industry utilizing enterprise blockchain protocols and\nenterprise consortium, to facilitate trustworthy data provenance retrieval,\nverification and management, as well as strengthening capability of product\nanti-counterfeiting and traceability in supply chain industry. The adoption of\nenterprise blockchain protocols and implementations has been surging in supply\nchain industry given its advantages in scalability, governance and\ncompatibility with existing supply chain systems and networks, but development\nand adoption of decentralized solutions could also impose additional\nimplications to supply chain integrity, in terms of security, privacy and\nconfidentiality. In this research, an empirical analysis performed against\ndecentralized solutions, including dNAS, summarizes the effectiveness,\nlimitations and future opportunities of developing decentralized solutions\nbuilt around existing enterprise blockchain protocols and implementations for\nsupply chain anti-counterfeiting and traceability.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 13:31:33 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Yiu", "Neo C. K.", ""]]}, {"id": "2102.02623", "submitter": "Suat Mercan", "authors": "Suat Mercan, Ahmet Kurt, Enes Erdin, and Kemal Akkaya", "title": "Cryptocurrency Solutions to Enable Micro-payments in Consumer IoT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The successful amalgamation of cryptocurrency and consumer Internet of Things\n(IoT) devices can pave the way for novel applications in machine-to-machine\neconomy. However, the lack of scalability and heavy resource requirements of\ninitial blockchain designs hinders the integration as they prioritized\ndecentralization and security. Numerous solutions have been proposed since the\nemergence of Bitcoin to achieve this goal. However, none of them seem to\ndominate and thus it is unclear how consumer devices will be adopting these\napproaches. Therefore, in this paper, we critically review the existing\nintegration approaches and cryptocurrency designs that strive to enable\nmicro-payments among consumer devices. We identify and discuss solutions under\nthree main categories; direct integration, payment channel network and new\ncryptocurrency design. The first approach utilizes a full node to interact with\nthe payment system. Offline channel payment is suggested as a second layer\nsolution to solve the scalability issue and enable instant payment with low\nfee. New designs converge to semi-centralized scheme and focuson lightweight\nconsensus protocol that does not require highcomputation power which might mean\nloosening the initial designchoices in favor of scalability. We evaluate the\npros and cons ofeach of these approaches and then point out future\nresearchchallenges. Our goal is to help researchers and practitioners tobetter\nfocus their efforts to facilitate micro-payment adoptions.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 14:21:38 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Mercan", "Suat", ""], ["Kurt", "Ahmet", ""], ["Erdin", "Enes", ""], ["Akkaya", "Kemal", ""]]}, {"id": "2102.02659", "submitter": "Suat Mercan", "authors": "Enes Erdin, Suat Mercan, and Kemal Akkaya", "title": "An Evaluation of Cryptocurrency Payment Channel Networks and Their\n  Privacy Implications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptocurrencies redefined how money can be stored and transferred among\nusers. However, independent of the amount being sent, public blockchain-based\ncryptocurrencies suffer from high transaction waiting times and fees. These\ndrawbacks hinder the wide use of cryptocurrencies by masses. To address these\nchallenges, payment channel network concept is touted as the most viable\nsolution to be used for micro-payments. The idea is exchanging the ownership of\nmoney by keeping the state of the accounts locally. The users inform the\nblockchain rarely, which decreases the load on the blockchain. Specifically,\npayment channel networks can provide transaction approvals in seconds by\ncharging a nominal fee proportional to the payment amount. Such attraction on\npayment channel networks inspired many recent studies which focus on how to\ndesign them and allocate channels such that the transactions will be secure and\nefficient. However, as payment channel networks are emerging and reaching large\nnumber of users, privacy issues are becoming more relevant that raise concerns\nabout exposing not only individual habits but also businesses' revenues. In\nthis paper, we first propose a categorization of the existing payment networks\nformed on top of blockchain-backed cryptocurrencies. After discussing several\nemerging attacks on user/business privacy in these payment channel networks, we\nqualitatively evaluate them based on a number of privacy metrics that relate to\nour case. Based on the discussions on the strengths and weaknesses of the\napproaches, we offer possible directions for research for the future of privacy\nbased payment channel networks.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 14:58:23 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Erdin", "Enes", ""], ["Mercan", "Suat", ""], ["Akkaya", "Kemal", ""]]}, {"id": "2102.02743", "submitter": "Friederike Groschupp", "authors": "Friederike Groschupp, Moritz Schneider, Ivan Puddu, Shweta Shinde,\n  Srdjan Capkun", "title": "Sovereign Smartphone: To Enjoy Freedom We Have to Control Our Phones", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of smartphones either run iOS or Android operating systems. This\nhas created two distinct ecosystems largely controlled by Apple and Google -\nthey dictate which applications can run, how they run, and what kind of phone\nresources they can access. Barring some exceptions in Android where different\nphone manufacturers may have influence, users, developers, and governments are\nleft with little to no choice. Specifically, users need to entrust their\nsecurity and privacy to OS vendors and accept the functionality constraints\nthey impose. Given the wide use of Android and iOS, immediately leaving these\necosystems is not practical, except in niche application areas. In this work,\nwe draw attention to the magnitude of this problem and why it is an undesirable\nsituation. As an alternative, we advocate the development of a new smartphone\narchitecture that securely transfers the control back to the users while\nmaintaining compatibility with the rich existing smartphone ecosystems. We\npropose and analyze one such design based on advances in trusted execution\nenvironments for ARM and RISC-V.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 17:11:43 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Groschupp", "Friederike", ""], ["Schneider", "Moritz", ""], ["Puddu", "Ivan", ""], ["Shinde", "Shweta", ""], ["Capkun", "Srdjan", ""]]}, {"id": "2102.02867", "submitter": "Nastaran Abadi Khooshemehr", "authors": "Nastaran Abadi Khooshemehr, Mohammad Ali Maddah-Ali", "title": "The Discrepancy Attack on Polyshard-ed Blockchains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Sharding, i.e. splitting the miners or validators to form and run several\nsubchains in parallel, is known as one of the main solutions to the scalability\nproblem of blockchains. The drawback is that as the number of miners expanding\neach subchain becomes small, it becomes vulnerable to security attacks. To\nsolve this problem, a framework, named as \\textit{Polyshard}, has been proposed\nin which each validator verifies a coded combination of the blocks introduced\nby different subchains, thus helping to protect the security of all subchains.\nIn this paper, we introduce an attack on Polyshard, called \\textit{the\ndiscrepancy} attack, which is the result of malicious nodes controlling a few\nsubchains and dispersing different blocks to different nodes. We show that this\nattack undermines the security of Polyshard and is undetectable in its current\nsetting.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 20:01:54 GMT"}, {"version": "v2", "created": "Sun, 14 Feb 2021 15:57:01 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Khooshemehr", "Nastaran Abadi", ""], ["Maddah-Ali", "Mohammad Ali", ""]]}, {"id": "2102.02923", "submitter": "Junfeng Guo", "authors": "Junfeng Guo, Yaswanth Yadlapalli, Thiele Lothar, Ang Li, and Cong Liu", "title": "PredCoin: Defense against Query-based Hard-label Attack", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many adversarial attacks and defenses have recently been proposed for Deep\nNeural Networks (DNNs). While most of them are in the white-box setting, which\nis impractical, a new class of query-based hard-label (QBHL) black-box attacks\npose a significant threat to real-world applications (e.g., Google Cloud,\nTencent API). Till now, there has been no generalizable and practical approach\nproposed to defend against such attacks.\n  This paper proposes and evaluates PredCoin, a practical and generalizable\nmethod for providing robustness against QBHL attacks. PredCoin poisons the\ngradient estimation step, an essential component of most QBHL attacks. PredCoin\nsuccessfully identifies gradient estimation queries crafted by an attacker and\nintroduces uncertainty to the output. Extensive experiments show that PredCoin\nsuccessfully defends against four state-of-the-art QBHL attacks across various\nsettings and tasks while preserving the target model's overall accuracy.\n  PredCoin is also shown to be robust and effective against several\ndefense-aware attacks, which may have full knowledge regarding the internal\nmechanisms of PredCoin.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 22:47:05 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Guo", "Junfeng", ""], ["Yadlapalli", "Yaswanth", ""], ["Lothar", "Thiele", ""], ["Li", "Ang", ""], ["Liu", "Cong", ""]]}, {"id": "2102.02956", "submitter": "Chong Xiang", "authors": "Chong Xiang, Prateek Mittal", "title": "DetectorGuard: Provably Securing Object Detectors against Localized\n  Patch Hiding Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art object detectors are vulnerable to localized patch hiding\nattacks where an adversary introduces a small adversarial patch to make\ndetectors miss the detection of salient objects. The patch attacker can carry\nout a physical-world attack by printing and attaching an adversarial patch to\nthe victim object. In this paper, we propose DetectorGuard, the first general\nframework for building provably robust detectors against localized patch hiding\nattacks. To start with, we aim to take advantage of recent advancements of\nrobust image classification research by asking: can we adapt robust image\nclassifiers for robust object detection? Unfortunately, due to their task\ndifference, an object detector naively adapted from a robust image classifier\n1) may not necessarily be robust in the adversarial setting or 2) even maintain\ndecent performance in the clean setting. To build a high-performance robust\nobject detector, we propose an objectness explaining strategy: we adapt a\nrobust image classifier to predict objectness for every image location and then\nexplain each objectness using the bounding boxes predicted by a conventional\nobject detector. If all objectness is well explained, we output the predictions\nmade by the conventional object detector; otherwise, we issue an attack alert.\nNotably, 1) in the adversarial setting, we formally prove the end-to-end\nrobustness of DetectorGuard on certified objects, i.e., it either detects the\nobject or triggers an alert, against any patch hiding attacker within our\nthreat model; 2) in the clean setting, we have almost the same performance as\nstate-of-the-art object detectors. Our evaluation on the PASCAL VOC, MS COCO,\nand KITTI datasets further demonstrates that DetectorGuard achieves the first\nprovable robustness against localized patch hiding attacks at a negligible cost\n(<1%) of clean performance.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 02:02:21 GMT"}, {"version": "v2", "created": "Sun, 9 May 2021 13:14:02 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Xiang", "Chong", ""], ["Mittal", "Prateek", ""]]}, {"id": "2102.03000", "submitter": "Anna Georgiadou Mrs", "authors": "Anna Georgiadou, Spiros Mouzakitis and Dimitris Askounis", "title": "Designing a Cyber-security Culture Assessment Survey Targeting Critical\n  Infrastructures During Covid-19 Crisis", "comments": "18 pages, 1 figure, 4 tables. arXiv admin note: substantial text\n  overlap with arXiv:2012.13718", "journal-ref": "International Journal of Network Security & Its Applications\n  (IJNSA) Vol.13, No.1, January 2021", "doi": "10.5121/ijnsa.2021.13103", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper at hand presents the design of a survey aiming at the\ncyber-security culture assessment of critical infrastructures during the\nCOVID-19 crisis, when living reality was heavily disturbed and working\nconditions fundamentally affected. The survey is rooted in a security culture\nframework layered into two levels, organizational and individual, further\nanalyzed into 10 different security dimensions consisted of 52 domains. An\nin-depth questionnaire building analysis is presented focusing on the aims,\ngoals, and expected results. It concludes with the survey implementation\napproach while underlining the framework's first application and its revealing\ninsights during a global crisis.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 05:17:03 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Georgiadou", "Anna", ""], ["Mouzakitis", "Spiros", ""], ["Askounis", "Dimitris", ""]]}, {"id": "2102.03013", "submitter": "Sivakanth Gopi", "authors": "Zhiqi Bu, Sivakanth Gopi, Janardhan Kulkarni, Yin Tat Lee, Judy Hanwen\n  Shen, Uthaipon Tantipongpipat", "title": "Fast and Memory Efficient Differentially Private-SGD via JL Projections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Differentially Private-SGD (DP-SGD) of Abadi et al. (2016) and its variations\nare the only known algorithms for private training of large scale neural\nnetworks. This algorithm requires computation of per-sample gradients norms\nwhich is extremely slow and memory intensive in practice. In this paper, we\npresent a new framework to design differentially private optimizers called\nDP-SGD-JL and DP-Adam-JL. Our approach uses Johnson-Lindenstrauss (JL)\nprojections to quickly approximate the per-sample gradient norms without\nexactly computing them, thus making the training time and memory requirements\nof our optimizers closer to that of their non-DP versions.\n  Unlike previous attempts to make DP-SGD faster which work only on a subset of\nnetwork architectures or use compiler techniques, we propose an algorithmic\nsolution which works for any network in a black-box manner which is the main\ncontribution of this paper. To illustrate this, on IMDb dataset, we train a\nRecurrent Neural Network (RNN) to achieve good privacy-vs-accuracy tradeoff,\nwhile being significantly faster than DP-SGD and with a similar memory\nfootprint as non-private SGD. The privacy analysis of our algorithms is more\ninvolved than DP-SGD, we use the recently proposed f-DP framework of Dong et\nal. (2019) to prove privacy.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 06:02:10 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Bu", "Zhiqi", ""], ["Gopi", "Sivakanth", ""], ["Kulkarni", "Janardhan", ""], ["Lee", "Yin Tat", ""], ["Shen", "Judy Hanwen", ""], ["Tantipongpipat", "Uthaipon", ""]]}, {"id": "2102.03131", "submitter": "Marcus Niemietz", "authors": "Marcus Niemietz, Mario Korth, Christian Mainka, Juraj Somorovsky", "title": "Over 100 Bugs in a Row: Security Analysis of the Top-Rated Joomla\n  Extensions", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nearly every second website is using a Content Management System (CMS) such\nas WordPress, Drupal, and Joomla. These systems help to create and modify\ndigital data, typically within a collaborative environment. One common feature\nis to enrich their functionality by using extensions. Popular extensions allow\ndevelopers to easily include payment gateways, backup tools, and social media\ncomponents.\n  Due to the extended functionality, it is not surprising that such an\nexpansion of complexity implies a bigger attack surface. In contrast to CMS\ncore systems, extensions are usually not considered during public security\naudits. However, a Cross-Site Scripting (XSS) or SQL injection (SQLi) attack\nwithin an activated extension has the same effect on the security of a CMS as\nthe same issue within the core itself. Therefore, vulnerabilities within\nextensions are a very attractive tool for malicious parties.\n  We study the security of CMS extensions using the example Joomla; one of the\nmost popular systems. We discovered that nearly every second installation of\nsuch a system also includes Joomla's official top-10 rated extensions as a per\nse requirement. Moreover, we have detected that every single extension of the\nofficial top-10 rated extensions is vulnerable to XSS and 30% of them against\nSQLi. We show that our findings are not only relevant to Joomla; two of the\nanalyzed extensions are available within systems like WordPress or Drupal, and\nintroduce the same vulnerabilities. Finally, we pinpoint mitigation strategies\nthat can be realized within extensions to achieve the same security level as\nthe core CMS.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 12:15:06 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Niemietz", "Marcus", ""], ["Korth", "Mario", ""], ["Mainka", "Christian", ""], ["Somorovsky", "Juraj", ""]]}, {"id": "2102.03148", "submitter": "Siaw-Lynn Ng Dr", "authors": "Liqun Chen, Siaw-Lynn Ng", "title": "Securing emergent behaviour in swarm robotics", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Swarm robotics is the study of how a large number of relatively simple robots\ncan be designed so that a desired collective behaviour emerges from the local\ninteractions among robots and between the robots and their environment. While\nmany aspects of a swarm may be modelled as various types of ad hoc networks,\nand accordingly many aspects of security of the swarm may be achieved by\nconventional means, here we will focus on swarm emergent behaviour as something\nthat most distinguishes swarm robotics from ad hoc networks. We discuss the\nchallenges emergent behaviour poses on communications security, and by\nclassifying a swarm by types of robots, types of communication channels, and\ntypes of adversaries, we examine what classes may be secured by traditional\nmethods and focus on aspects that are most relevant to allowing emergent\nbehaviour. We will examine how this can be secured by ensuring that\ncommunication is secure. We propose a simple solution using hash chains, and by\nmodelling swarm communications using a series of random graphs, we show that\nthis allows us to identify rogue robots with a high probability.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 12:52:52 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Chen", "Liqun", ""], ["Ng", "Siaw-Lynn", ""]]}, {"id": "2102.03215", "submitter": "Ioannis Zografopoulos", "authors": "Ioannis Zografopoulos, Charalambos Konstantinou, Nektarios Georgios\n  Tsoutsos, Dan Zhu, Robert Broadwater", "title": "Security Assessment and Impact Analysis of Cyberattacks in Integrated\n  T&D Power Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CR cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we examine the impact of cyberattacks in an integrated\ntransmission and distribution (T&D) power grid model with distributed energy\nresource (DER) integration. We adopt the OCTAVE Allegro methodology to identify\ncritical system assets, enumerate potential threats, analyze, and prioritize\nrisks for threat scenarios. Based on the analysis, attack strategies and\nexploitation scenarios are identified which could lead to system compromise.\nSpecifically, we investigate the impact of data integrity attacks in\ninverted-based solar PV controllers, control signal blocking attacks in\nprotective switches and breakers, and coordinated monitoring and switching\ntime-delay attacks.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 15:00:36 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 10:42:05 GMT"}, {"version": "v3", "created": "Sun, 11 Apr 2021 14:16:08 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Zografopoulos", "Ioannis", ""], ["Konstantinou", "Charalambos", ""], ["Tsoutsos", "Nektarios Georgios", ""], ["Zhu", "Dan", ""], ["Broadwater", "Robert", ""]]}, {"id": "2102.03314", "submitter": "Emiliano De Cristofaro", "authors": "Bristena Oprisanu and Georgi Ganev and Emiliano De Cristofaro", "title": "Measuring Utility and Privacy of Synthetic Genomic Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The availability of genomic data is often essential to progress in biomedical\nresearch, personalized medicine, drug development, etc. However, its extreme\nsensitivity makes it problematic, if not outright impossible, to publish or\nshare it. As a result, several initiatives have been launched to experiment\nwith synthetic genomic data, e.g., using generative models to learn the\nunderlying distribution of the real data and generate artificial datasets that\npreserve its salient characteristics without exposing it. This paper provides\nthe first evaluation of the utility and the privacy protection of six\nstate-of-the-art models for generating synthetic genomic data. We assess the\nperformance of the synthetic data on several common tasks, such as allele\npopulation statistics and linkage disequilibrium. We then measure privacy\nthrough the lens of membership inference attacks, i.e., inferring whether a\nrecord was part of the training data. Our experiments show that no single\napproach to generate synthetic genomic data yields both high utility and strong\nprivacy across the board. Also, the size and nature of the training dataset\nmatter. Moreover, while some combinations of datasets and models produce\nsynthetic data with distributions close to the real data, there often are\ntarget data points that are vulnerable to membership inference. Looking\nforward, our techniques can be used by practitioners to assess the risks of\ndeploying synthetic genomic data in the wild and serve as a benchmark for\nfuture work.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 17:41:01 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 17:23:38 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Oprisanu", "Bristena", ""], ["Ganev", "Georgi", ""], ["De Cristofaro", "Emiliano", ""]]}, {"id": "2102.03316", "submitter": "Winston Chou", "authors": "Winston Chou", "title": "Randomized Controlled Trials with Minimal Data Retention", "comments": "20 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Amidst rising appreciation for privacy and data usage rights, researchers\nhave increasingly recognized the principle of data minimization, which holds\nthat the accessibility, collection, and retention of subjects' data should be\nkept to the minimum necessary to answer focused research questions. Applying\nthis principle to randomized controlled trials (RCTs), this paper presents\nalgorithms for drawing precise inferences from RCTs under stringent data\nretention and anonymization policies. In particular, we show how to use\nrecursive algorithms to construct running estimates of treatment effects in\nRCTs, thereby allowing individualized records to be deleted or anonymized\nshortly after collection. Devoting special attention to the case of non-i.i.d.\ndata, we further demonstrate how to draw robust inferences from RCTs by\ncombining recursive algorithms with bootstrap and federated strategies.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 17:42:14 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Chou", "Winston", ""]]}, {"id": "2102.03347", "submitter": "Christof Ferreira Torres", "authors": "Christof Ferreira Torres, Ramiro Camino, Radu State", "title": "Frontrunner Jones and the Raiders of the Dark Forest: An Empirical Study\n  of Frontrunning on the Ethereum Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ethereum prospered the inception of a plethora of smart contract\napplications, ranging from gambling games to decentralized finance. However,\nEthereum is also considered a highly adversarial environment, where vulnerable\nsmart contracts will eventually be exploited. Recently, Ethereum's pool of\npending transaction has become a far more aggressive environment. In the hope\nof making some profit, attackers continuously monitor the transaction pool and\ntry to frontrun their victims' transactions by either displacing or suppressing\nthem, or strategically inserting their transactions. This paper aims to shed\nsome light into what is known as a dark forest and uncover these predators'\nactions. We present a methodology to efficiently measure the three types of\nfrontrunning: displacement, insertion, and suppression. We perform a\nlarge-scale analysis on more than 11M blocks and identify almost 200K attacks\nwith an accumulated profit of 18.41M USD for the attackers, providing evidence\nthat frontrunning is both, lucrative and a prevalent issue.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 18:49:50 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 12:37:58 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Torres", "Christof Ferreira", ""], ["Camino", "Ramiro", ""], ["State", "Radu", ""]]}, {"id": "2102.03382", "submitter": "Tu Le", "authors": "Tu Le, Danny Yuxing Huang, Noah Apthorpe, Yuan Tian", "title": "SkillBot: Identifying Risky Content for Children in Alexa Skills", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CL cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many households include children who use voice personal assistants (VPA) such\nas Amazon Alexa. Children benefit from the rich functionalities of VPAs and\nthird-party apps but are also exposed to new risks in the VPA ecosystem (e.g.,\ninappropriate content or information collection). To study the risks VPAs pose\nto children, we build a Natural Language Processing (NLP)-based system to\nautomatically interact with VPA apps and analyze the resulting conversations to\nidentify contents risky to children. We identify 28 child-directed apps with\nrisky contents and maintain a growing dataset of 31,966 non-overlapping app\nbehaviors collected from 3,434 Alexa apps. Our findings suggest that although\nvoice apps designed for children are subject to more policy requirements and\nintensive vetting, children are still vulnerable to risky content. We then\nconduct a user study showing that parents are more concerned about VPA apps\nwith inappropriate content than those that ask for personal information, but\nmany parents are not aware that risky apps of either type exist. Finally, we\nidentify a new threat to users of VPA apps: confounding utterances, or voice\ncommands shared by multiple apps that may cause a user to invoke or interact\nwith a different app than intended. We identify 4,487 confounding utterances,\nincluding 581 shared by child-directed and non-child-directed apps.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 19:07:39 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Le", "Tu", ""], ["Huang", "Danny Yuxing", ""], ["Apthorpe", "Noah", ""], ["Tian", "Yuan", ""]]}, {"id": "2102.03410", "submitter": "Michael Bartholic", "authors": "Michael Bartholic, Zhengrong Gu, Jianan Su, Justin Goldstein,\n  Shin'ichiro Matsuo", "title": "Smart Auto Insurance: High Resolution, Dynamic, Privacy-Driven,\n  Telematic Insurance", "comments": "15 pages, 1 figure, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data driven approaches to problem solving are, in many regards, the holy\ngrail of evidence backed decision making. Using first-party empirical data to\nanalyze behavior and establish predictions yields us the ability to base\nin-depth analyses on particular individuals and reduce our dependence on\ngeneralizations. Modern mobile and embedded devices provide a wealth of sensors\nand means for collecting and tracking individualized data. Applying these\nassets to the realm of insurance (which is a statistically backed endeavor at\nheart) is certainly nothing new; yet doing so in a way that is privacy-driven\nand secure has not been a central focus of implementers. Existing data-driven\ninsurance technologies require a certain level of trust in the data tracking\nagency (i.e. insurer) to not misuse, mishandle, or over-collect user data.\nSmart contracts and blockchain technology provide us an opportunity to\nre-balance these systems such that the blockchain itself is a trusted agent\nwhich both insurers and the insured can confide in. We propose a \"Smart Auto\nInsurance\" system that minimizes data sharing while simultaneously providing\nquality-of-life improvements to both sides. Furthermore, we use a simple game\ntheoretical argument to show that the clients using such a system are\ndisincentivized from behaving adversarially.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 20:20:53 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Bartholic", "Michael", ""], ["Gu", "Zhengrong", ""], ["Su", "Jianan", ""], ["Goldstein", "Justin", ""], ["Matsuo", "Shin'ichiro", ""]]}, {"id": "2102.03412", "submitter": "Waleed Yousef", "authors": "William Briguglio, Parisa Moghaddam, Waleed A. Yousef, Issa Traore,\n  Mohammad Mamun", "title": "Machine Learning in Precision Medicine to Preserve Privacy via\n  Encryption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precision medicine is an emerging approach for disease treatment and\nprevention that delivers personalized care to individual patients by\nconsidering their genetic makeups, medical histories, environments, and\nlifestyles. Despite the rapid advancement of precision medicine and its\nconsiderable promise, several underlying technological challenges remain\nunsolved. One such challenge of great importance is the security and privacy of\nprecision health-related data, such as genomic data and electronic health\nrecords, which stifle collaboration and hamper the full potential of\nmachine-learning (ML) algorithms. To preserve data privacy while providing ML\nsolutions, this article makes three contributions. First, we propose a generic\nmachine learning with encryption (MLE) framework, which we used to build an ML\nmodel that predicts cancer from one of the most recent comprehensive genomics\ndatasets in the field. Second, our framework's prediction accuracy is slightly\nhigher than that of the most recent studies conducted on the same dataset, yet\nit maintains the privacy of the patients' genomic data. Third, to facilitate\nthe validation, reproduction, and extension of this work, we provide an\nopen-source repository that contains the design and implementation of the\nframework, all the ML experiments and code, and the final predictive model\ndeployed to a free cloud service.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 20:22:15 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Briguglio", "William", ""], ["Moghaddam", "Parisa", ""], ["Yousef", "Waleed A.", ""], ["Traore", "Issa", ""], ["Mamun", "Mohammad", ""]]}, {"id": "2102.03494", "submitter": "Jie Lin", "authors": "Yuxiao Lu, Jie Lin, Chao Jin, Zhe Wang, Khin Mi Mi Aung, Xiaoli Li", "title": "FFConv: Fast Factorized Neural Network Inference on Encrypted Data", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Homomorphic Encryption (HE), allowing computations on encrypted data\n(ciphertext) without decrypting it first, enables secure but prohibitively slow\nNeural Network (HENN) inference for privacy-preserving applications in clouds.\nTo reduce HENN inference latency, one approach is to pack multiple messages\ninto a single ciphertext in order to reduce the number of ciphertexts and\nsupport massive parallelism of Homomorphic Multiply-Add (HMA) operations\nbetween ciphertexts. However, different ciphertext packing schemes have to be\ndesigned for different convolution layers and each of them introduces overheads\nthat are far more expensive than HMA operations. In this paper, we propose a\nlow-rank factorization method called FFConv to unify convolution and ciphertext\npacking. To our knowledge, FFConv is the first work that is capable of\naccelerating the overheads induced by different ciphertext packing schemes\nsimultaneously, without incurring a significant increase in noise budget.\nCompared to prior art LoLa and Falcon, our method reduces the inference latency\nby up to 87% and 12%, respectively, with comparable accuracy on MNIST and\nCIFAR-10.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 03:10:13 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Lu", "Yuxiao", ""], ["Lin", "Jie", ""], ["Jin", "Chao", ""], ["Wang", "Zhe", ""], ["Aung", "Khin Mi Mi", ""], ["Li", "Xiaoli", ""]]}, {"id": "2102.03513", "submitter": "Rafael Dowsley", "authors": "Sikha Pentyala and Rafael Dowsley and Martine De Cock", "title": "Privacy-Preserving Video Classification with Convolutional Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many video classification applications require access to personal data,\nthereby posing an invasive security risk to the users' privacy. We propose a\nprivacy-preserving implementation of single-frame method based video\nclassification with convolutional neural networks that allows a party to infer\na label from a video without necessitating the video owner to disclose their\nvideo to other entities in an unencrypted manner. Similarly, our approach\nremoves the requirement of the classifier owner from revealing their model\nparameters to outside entities in plaintext. To this end, we combine existing\nSecure Multi-Party Computation (MPC) protocols for private image classification\nwith our novel MPC protocols for oblivious single-frame selection and secure\nlabel aggregation across frames. The result is an end-to-end privacy-preserving\nvideo classification pipeline. We evaluate our proposed solution in an\napplication for private human emotion recognition. Our results across a variety\nof security settings, spanning honest and dishonest majority configurations of\nthe computing parties, and for both passive and active adversaries, demonstrate\nthat videos can be classified with state-of-the-art accuracy, and without\nleaking sensitive user information.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 05:05:31 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Pentyala", "Sikha", ""], ["Dowsley", "Rafael", ""], ["De Cock", "Martine", ""]]}, {"id": "2102.03517", "submitter": "Rafael Dowsley", "authors": "Xiling Li and Rafael Dowsley and Martine De Cock", "title": "Privacy-Preserving Feature Selection with Secure Multiparty Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing work on privacy-preserving machine learning with Secure Multiparty\nComputation (MPC) is almost exclusively focused on model training and on\ninference with trained models, thereby overlooking the important data\npre-processing stage. In this work, we propose the first MPC based protocol for\nprivate feature selection based on the filter method, which is independent of\nmodel training, and can be used in combination with any MPC protocol to rank\nfeatures. We propose an efficient feature scoring protocol based on Gini\nimpurity to this end. To demonstrate the feasibility of our approach for\npractical data science, we perform experiments with the proposed MPC protocols\nfor feature selection in a commonly used machine-learning-as-a-service\nconfiguration where computations are outsourced to multiple servers, with\nsemi-honest and with malicious adversaries. Regarding effectiveness, we show\nthat secure feature selection with the proposed protocols improves the accuracy\nof classifiers on a variety of real-world data sets, without leaking\ninformation about the feature values or even which features were selected.\nRegarding efficiency, we document runtimes ranging from several seconds to an\nhour for our protocols to finish, depending on the size of the data set and the\nsecurity settings.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 05:33:04 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Li", "Xiling", ""], ["Dowsley", "Rafael", ""], ["De Cock", "Martine", ""]]}, {"id": "2102.03523", "submitter": "Xiaoxuan Lou", "authors": "Xiaoxuan Lou, Shangwei Guo, Tianwei Zhang, Yinqian Zhang, Yang Liu", "title": "When NAS Meets Watermarking: Ownership Verification of DNN Models via\n  Cache Side Channels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel watermarking scheme to verify the ownership of DNN models.\nExisting solutions embedded watermarks into the model parameters, which were\nproven to be removable and detectable by an adversary to invalidate the\nprotection. In contrast, we propose to implant watermarks into the model\narchitectures. We design new algorithms based on Neural Architecture Search\n(NAS) to generate watermarked architectures, which are unique enough to\nrepresent the ownership, while maintaining high model usability. We further\nleverage cache side channels to extract and verify watermarks from the\nblack-box models at inference. Theoretical analysis and extensive evaluations\nshow our scheme has negligible impact on the model performance, and exhibits\nstrong robustness against various model transformations.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 06:25:59 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 12:27:41 GMT"}, {"version": "v3", "created": "Fri, 5 Mar 2021 05:55:55 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Lou", "Xiaoxuan", ""], ["Guo", "Shangwei", ""], ["Zhang", "Tianwei", ""], ["Zhang", "Yinqian", ""], ["Liu", "Yang", ""]]}, {"id": "2102.03546", "submitter": "Huy Kang Kim", "authors": "Seonghoon Jeong, Boosun Jeon, Boheung Chung, Huy Kang Kim", "title": "Convolutional Neural Network-based Intrusion Detection System for AVTP\n  Streams in Automotive Ethernet-based Networks", "comments": "35 pages, 9 figures, accepted to Vehicular Communications (Elsevier)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connected and autonomous vehicles (CAVs) are an innovative form of\ntraditional vehicles. Automotive Ethernet replaces the controller area network\nand FlexRay to support the large throughput required by high-definition\napplications. As CAVs have numerous functions, they exhibit a large attack\nsurface and an increased vulnerability to attacks. However, no previous studies\nhave focused on intrusion detection in automotive Ethernet-based networks. In\nthis paper, we present an intrusion detection method for detecting audio-video\ntransport protocol (AVTP) stream injection attacks in automotive Ethernet-based\nnetworks. To the best of our knowledge, this is the first such method developed\nfor automotive Ethernet. The proposed intrusion detection model is based on\nfeature generation and a convolutional neural network (CNN). To evaluate our\nintrusion detection system, we built a physical BroadR-Reach-based testbed and\ncaptured real AVTP packets. The experimental results show that the model\nexhibits outstanding performance: the F1-score and recall are greater than\n0.9704 and 0.9949, respectively. In terms of the inference time per input and\nthe generation intervals of AVTP traffic, our CNN model can readily be employed\nfor real-time detection.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 09:37:09 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Jeong", "Seonghoon", ""], ["Jeon", "Boosun", ""], ["Chung", "Boheung", ""], ["Kim", "Huy Kang", ""]]}, {"id": "2102.03625", "submitter": "Daniel Oliveira", "authors": "Daniel Oliveira, Tiago Gomes, and Sandro Pinto", "title": "uTango: an open-source TEE for the Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security is one of the main challenges of the Internet of Things (IoT). IoT\ndevices are mainly powered by low-cost microcontrollers (MCUs) that typically\nlack basic hardware security mechanisms to separate security-critical\napplications from less critical components. Recently, Arm has started to\nrelease Cortex-M MCUs enhanced with TrustZone technology (i.e., TrustZone-M), a\nsystem-wide security solution aiming at providing robust protection for IoT\ndevices. Trusted Execution Environments (TEEs) relying on TrustZone hardware\nhave been perceived as safe havens for securing mobile devices. However, for\nthe past few years, considerable effort has gone into unveiling hundreds of\nvulnerabilities and proposing a collection of relevant defense techniques to\naddress several issues. While new TEE solutions built on TrustZone-M start\nflourishing, the lessons gathered from the research community appear to be\nfalling short, as these new systems are trapping into the d\\'ej\\`a vu pitfalls\nof the past. In this paper, we present uTango, the first multi-world TEE for\nmodern IoT devices. uTango proposes a novel architecture aiming at tackling the\nmajor architectural deficiencies currently affecting TrustZone(-M)-assisted\nTEEs. In particular, we leverage the very same TrustZone hardware primitives\nused by dual-world implementations to create multiple, equally-secure execution\nenvironments within the normal world. We demonstrate the benefits of uTango by\nconducting an extensive evaluation on a real TrustZone-M hardware platform,\ni.e., Arm Musca-B1. uTango will be open-sourced and freely available on GitHub\nin hopes of engaging academia and industry on securing the foreseeable trillion\nIoT devices.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 17:55:47 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Oliveira", "Daniel", ""], ["Gomes", "Tiago", ""], ["Pinto", "Sandro", ""]]}, {"id": "2102.03721", "submitter": "Kentaro Sako", "authors": "Kentaro Sako, Shin'ichiro Matsuo, Sachin Meier", "title": "Fairness in ERC token markets: A Case Study of CryptoKitties", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fairness is an important trait of open, free markets. Ethereum is a platform\nmeant to enable digital, decentralized markets. Though many researchers debate\nthe market's fairness, there are few discussions around the fairness of\nautomated markets, such as those hosted on Ethereum. In this paper, using pilot\nstudies, we consider unfair factors caused by adding the program. Because\nCryptoKitties is one of the major blockchain-based games and has been in\noperation for an extended period of time, we focus on its market to examine\nfairness. As a result, we concluded that a gene determination algorithm in this\ngame has little randomness, and a significant advantage to gain profit is given\nto players who know its bias over those who do not. We state incompleteness and\nimpact of the algorithm and other factors. Besides, we suppose countermeasures\nto reduce CryptoKitties' unfairness as a market.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 05:28:33 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Sako", "Kentaro", ""], ["Matsuo", "Shin'ichiro", ""], ["Meier", "Sachin", ""]]}, {"id": "2102.03722", "submitter": "Kenneth Co", "authors": "Zhongyuan Hau, Kenneth T. Co, Soteris Demetriou, Emil C. Lupu", "title": "Object Removal Attacks on LiDAR-based 3D Object Detectors", "comments": "Accepted to AutoSec at NDSS 2021", "journal-ref": null, "doi": "10.14722/autosec.2021.23", "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LiDARs play a critical role in Autonomous Vehicles' (AVs) perception and\ntheir safe operations. Recent works have demonstrated that it is possible to\nspoof LiDAR return signals to elicit fake objects. In this work we demonstrate\nhow the same physical capabilities can be used to mount a new, even more\ndangerous class of attacks, namely Object Removal Attacks (ORAs). ORAs aim to\nforce 3D object detectors to fail. We leverage the default setting of LiDARs\nthat record a single return signal per direction to perturb point clouds in the\nregion of interest (RoI) of 3D objects. By injecting illegitimate points behind\nthe target object, we effectively shift points away from the target objects'\nRoIs. Our initial results using a simple random point selection strategy show\nthat the attack is effective in degrading the performance of commonly used 3D\nobject detection models.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 05:34:14 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Hau", "Zhongyuan", ""], ["Co", "Kenneth T.", ""], ["Demetriou", "Soteris", ""], ["Lupu", "Emil C.", ""]]}, {"id": "2102.03750", "submitter": "Lorenzo Ghiro", "authors": "Lorenzo Ghiro (1), Francesco Restuccia (2), Salvatore D'Oro (2),\n  Stefano Basagni (2), Tommaso Melodia (2), Leonardo Maccari (3), Renato Lo\n  Cigno (4) ((1) University of Trento, Italy, (2) Northeastern University, USA,\n  (3) University of Venice, Italy, (4) University of Brescia, Italy)", "title": "What is a Blockchain? A Definition to Clarify the Role of the Blockchain\n  in the Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The use of the term blockchain is documented for disparate projects, from\ncryptocurrencies to applications for the Internet of Things (IoT), and many\nmore. The concept of blockchain appears therefore blurred, as it is hard to\nbelieve that the same technology can empower applications that have extremely\ndifferent requirements and exhibit dissimilar performance and security. This\nposition paper elaborates on the theory of distributed systems to advance a\nclear definition of blockchain that allows us to clarify its role in the IoT.\nThis definition inextricably binds together three elements that, as a whole,\nprovide the blockchain with those unique features that distinguish it from\nother distributed ledger technologies: immutability, transparency and\nanonimity. We note however that immutability comes at the expense of remarkable\nresource consumption, transparency demands no confidentiality and anonymity\nprevents user identification and registration. This is in stark contrast to the\nrequirements of most IoT applications that are made up of resource constrained\ndevices, whose data need to be kept confidential and users to be clearly known.\nBuilding on the proposed definition, we derive new guidelines for selecting the\nproper distributed ledger technology depending on application requirements and\ntrust models, identifying common pitfalls leading to improper applications of\nthe blockchain. We finally indicate a feasible role of the blockchain for the\nIoT: myriads of local, IoT transactions can be aggregated off-chain and then be\nsuccessfully recorded on an external blockchain as a means of public\naccountability when required.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 09:07:52 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Ghiro", "Lorenzo", ""], ["Restuccia", "Francesco", ""], ["D'Oro", "Salvatore", ""], ["Basagni", "Stefano", ""], ["Melodia", "Tommaso", ""], ["Maccari", "Leonardo", ""], ["Cigno", "Renato Lo", ""]]}, {"id": "2102.03785", "submitter": "Rami Mochaourab", "authors": "Rami Mochaourab and Sugandh Sinha and Stanley Greenstein and\n  Panagiotis Papapetrou", "title": "Robust Explanations for Private Support Vector Machines", "comments": "13 pages, 9 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider counterfactual explanations for private support vector machines\n(SVM), where the privacy mechanism that publicly releases the classifier\nguarantees differential privacy. While privacy preservation is essential when\ndealing with sensitive data, there is a consequent degradation in the\nclassification accuracy due to the introduced perturbations in the classifier\nweights. For such classifiers, counterfactual explanations need to be robust\nagainst the uncertainties in the SVM weights in order to ensure, with high\nconfidence, that the classification of the data instance to be explained is\ndifferent than its explanation. We model the uncertainties in the SVM weights\nthrough a random vector, and formulate the explanation problem as an\noptimization problem with probabilistic constraint. Subsequently, we\ncharacterize the problem's deterministic equivalent and study its solution. For\nlinear SVMs, the problem is a convex second-order cone program. For non-linear\nSVMs, the problem is non-convex. Thus, we propose a sub-optimal solution that\nis based on the bisection method. The results show that, contrary to non-robust\nexplanations, the quality of explanations from the robust solution degrades\nwith increasing privacy in order to guarantee a prespecified confidence level\nfor correct classifications.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 11:55:32 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 19:21:19 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Mochaourab", "Rami", ""], ["Sinha", "Sugandh", ""], ["Greenstein", "Stanley", ""], ["Papapetrou", "Panagiotis", ""]]}, {"id": "2102.03915", "submitter": "Shangyu Xie", "authors": "Shangyu Xie, Bingyu Liu, Yuan Hong", "title": "Privacy-preserving Cloud-based DNN Inference", "comments": "Accepted to ICASSP'2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning as a service (DLaaS) has been intensively studied to facilitate\nthe wider deployment of the emerging deep learning applications. However, DLaaS\nmay compromise the privacy of both clients and cloud servers. Although some\nprivacy preserving deep neural network (DNN) based inference techniques have\nbeen proposed by composing cryptographic primitives, the challenges on\ncomputational efficiency have not been well-addressed due to the complexity of\nDNN models and expensive cryptographic primitives. In this paper, we propose a\nnovel privacy preserving cloud-based DNN inference framework (namely, \"PROUD\"),\nwhich greatly improves the computational efficiency. Finally, we conduct\nextensive experiments on two commonly-used datasets to validate both\neffectiveness and efficiency for the PROUD, which also outperforms the\nstate-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 21:13:00 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 00:35:25 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Xie", "Shangyu", ""], ["Liu", "Bingyu", ""], ["Hong", "Yuan", ""]]}, {"id": "2102.03933", "submitter": "Thomas Hardjono", "authors": "Thomas Hardjono", "title": "Blockchain Gateways, Bridges and Delegated Hash-Locks", "comments": "8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In the current work we discuss the notion of gateways as a means for\ninteroperability across different blockchain systems. We discuss two key\nprinciples for the design of gateway nodes and scalable gateway protocols,\nnamely (i) the opaque ledgers principle as the analogue of the autonomous\nsystems principle in IP datagram routing, and (ii) the externalization of value\nprinciple as the analogue of the end-to-end principle in the Internet\narchitecture. We illustrate the need for a standard gateway protocol by\ndescribing a unidirectional asset movement protocol between two peer gateways,\nunder the strict condition of both blockchains being private/permissioned with\ntheir ledgers inaccessible to external entities. Several aspects of gateways\nand the gateway protocol is discussed, including gateway identities, gateway\ncertificates and certificate hierarchies, passive locking transactions by\ngateways, and the potential use of delegated hash-locks to expand the\nfunctionality of gateways.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 22:14:04 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Hardjono", "Thomas", ""]]}, {"id": "2102.04063", "submitter": "Alex Auvolat", "authors": "Alex Auvolat (WIDE), Y\\'erom-David Bromberg (WIDE), Davide Frey\n  (WIDE), Fran\\c{c}ois Ta\\\"iani (WIDE)", "title": "$\\scriptstyle{BASALT}$: A Rock-Solid Foundation for Epidemic Consensus\n  Algorithms in Very Large, Very Open Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.NI cs.SE cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have proposed new Byzantine consensus algorithms for blockchains\nbased on epidemics, a design which enables highly scalable performance at a low\ncost. These methods however critically depend on a secure random peer sampling\nservice: a service that provides a stream of random network nodes where no\nattacking entity can become over-represented. To ensure this security property,\ncurrent epidemic platforms use a Proof-of-Stake system to select peer samples.\nHowever such a system limits the openness of the system as only nodes with\nsignificant stake can participate in the consensus, leading to an oligopoly\nsituation. Moreover, this design introduces a complex interdependency between\nthe consensus algorithm and the cryptocurrency built upon it. In this paper, we\npropose a radically different security design for the peer sampling service,\nbased on the distribution of IP addresses to prevent Sybil attacks. We propose\na new algorithm, $\\scriptstyle{BASALT}$, that implements our design using a\nstubborn chaotic search to counter attackers' attempts at becoming\nover-represented. We show in theory and using Monte Carlo simulations that\n$\\scriptstyle{BASALT}$ provides samples which are extremely close to the\noptimal distribution even in adversarial scenarios such as tentative Eclipse\nattacks. Live experiments on a production cryptocurrency platform confirm that\nthe samples obtained using $\\scriptstyle{BASALT}$ are equitably distributed\namongst nodes, allowing for a system which is both open and where no single\nentity can gain excessive power.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 08:52:19 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Auvolat", "Alex", "", "WIDE"], ["Bromberg", "Y\u00e9rom-David", "", "WIDE"], ["Frey", "Davide", "", "WIDE"], ["Ta\u00efani", "Fran\u00e7ois", "", "WIDE"]]}, {"id": "2102.04120", "submitter": "Delaram Kahrobaei", "authors": "Delaram Kahrobaei, Antonio Tortora, Maria Tota", "title": "A Closer Look at the Multilinear Cryptography using Nilpotent Groups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a previous paper we generalized the definition of a multilinear map to\narbitrary groups and introduced two multiparty key-exchange protocols using\nnilpotent groups. In this paper we have a closer look at the protocols and will\naddress some incorrect cryptanalysis which have been proposed.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 10:49:47 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Kahrobaei", "Delaram", ""], ["Tortora", "Antonio", ""], ["Tota", "Maria", ""]]}, {"id": "2102.04140", "submitter": "XInlei He", "authors": "Xinlei He and Yang Zhang", "title": "Quantifying and Mitigating Privacy Risks of Contrastive Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data is the key factor to drive the development of machine learning (ML)\nduring the past decade. However, high-quality data, in particular labeled data,\nis often hard and expensive to collect. To leverage large-scale unlabeled data,\nself-supervised learning, represented by contrastive learning, is introduced.\nThe objective of contrastive learning is to map different views derived from a\ntraining sample (e.g., through data augmentation) closer in their\nrepresentation space, while different views derived from different samples more\ndistant. In this way, a contrastive model learns to generate informative\nrepresentations for data samples, which are then used to perform downstream ML\ntasks. Recent research has shown that machine learning models are vulnerable to\nvarious privacy attacks. However, most of the current efforts concentrate on\nmodels trained with supervised learning. Meanwhile, data samples' informative\nrepresentations learned with contrastive learning may cause severe privacy\nrisks as well.\n  In this paper, we perform the first privacy analysis of contrastive learning\nthrough the lens of membership inference and attribute inference. Our\nexperimental results show that contrastive models are less vulnerable to\nmembership inference attacks but more vulnerable to attribute inference attacks\ncompared to supervised models. The former is due to the fact that contrastive\nmodels are less prone to overfitting, while the latter is caused by contrastive\nmodels' capability of representing data samples expressively. To remedy this\nsituation, we propose the first privacy-preserving contrastive learning\nmechanism, namely Talos, relying on adversarial training. Empirical results\nshow that Talos can successfully mitigate attribute inference risks for\ncontrastive models while maintaining their membership privacy and model\nutility.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 11:38:11 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["He", "Xinlei", ""], ["Zhang", "Yang", ""]]}, {"id": "2102.04288", "submitter": "Nikita Korzhitskii", "authors": "Nikita Korzhitskii and Niklas Carlsson", "title": "Revocation Statuses on the Internet", "comments": "Accepted to Passive and Active Measurement Conference 2021. Author's\n  edition, 15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The modern Internet is highly dependent on the trust communicated via X.509\ncertificates. However, in some cases certificates become untrusted and it is\nnecessary to revoke them. In practice, the problem of secure certificate\nrevocation has not yet been solved, and today no revocation procedure (similar\nto Certificate Transparency w.r.t. certificate issuance) has been adopted to\nprovide transparent and immutable history of all revocations. Instead, the\nstatus of most certificates can only be checked with Online Certificate Status\nProtocol (OCSP) and/or Certificate Revocation Lists (CRLs). In this paper, we\npresent the first longitudinal characterization of the revocation statuses\ndelivered by CRLs and OCSP servers from the time of certificate expiration to\nstatus disappearance. The analysis captures the status history of over 1\nmillion revoked certificates, including 773K certificates mass-revoked by Let's\nEncrypt. Our characterization provides a new perspective on the Internet's\nrevocation rates, quantifies how short-lived the revocation statuses are,\nhighlights differences in revocation practices within and between different\nCAs, and captures biases and oddities in the handling of revoked certificates.\nCombined, the findings motivate the development and adoption of a revocation\ntransparency standard.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 15:46:23 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Korzhitskii", "Nikita", ""], ["Carlsson", "Niklas", ""]]}, {"id": "2102.04291", "submitter": "Shawn Shan", "authors": "Shawn Shan, Arjun Nitin Bhagoji, Haitao Zheng, Ben Y. Zhao", "title": "A Real-time Defense against Website Fingerprinting Attacks", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Anonymity systems like Tor are vulnerable to Website Fingerprinting (WF)\nattacks, where a local passive eavesdropper infers the victim's activity.\nCurrent WF attacks based on deep learning classifiers have successfully\novercome numerous proposed defenses. While recent defenses leveraging\nadversarial examples offer promise, these adversarial examples can only be\ncomputed after the network session has concluded, thus offer users little\nprotection in practical settings.\n  We propose Dolos, a system that modifies user network traffic in real time to\nsuccessfully evade WF attacks. Dolos injects dummy packets into traffic traces\nby computing input-agnostic adversarial patches that disrupt deep learning\nclassifiers used in WF attacks. Patches are then applied to alter and protect\nuser traffic in real time. Importantly, these patches are parameterized by a\nuser-side secret, ensuring that attackers cannot use adversarial training to\ndefeat Dolos. We experimentally demonstrate that Dolos provides 94+% protection\nagainst state-of-the-art WF attacks under a variety of settings. Against prior\ndefenses, Dolos outperforms in terms of higher protection performance and lower\ninformation leakage and bandwidth overhead. Finally, we show that Dolos is\nrobust against a variety of adaptive countermeasures to detect or disrupt the\ndefense.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 15:52:09 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Shan", "Shawn", ""], ["Bhagoji", "Arjun Nitin", ""], ["Zheng", "Haitao", ""], ["Zhao", "Ben Y.", ""]]}, {"id": "2102.04351", "submitter": "Sudip Mittal", "authors": "Priyanka Ranade, Aritran Piplai, Sudip Mittal, Anupam Joshi, Tim Finin", "title": "Generating Fake Cyber Threat Intelligence Using Transformer-Based Models", "comments": "In Proceedings of International Joint Conference on Neural Networks\n  2021 (IJCNN 2021), July 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Cyber-defense systems are being developed to automatically ingest Cyber\nThreat Intelligence (CTI) that contains semi-structured data and/or text to\npopulate knowledge graphs. A potential risk is that fake CTI can be generated\nand spread through Open-Source Intelligence (OSINT) communities or on the Web\nto effect a data poisoning attack on these systems. Adversaries can use fake\nCTI examples as training input to subvert cyber defense systems, forcing the\nmodel to learn incorrect inputs to serve their malicious needs.\n  In this paper, we automatically generate fake CTI text descriptions using\ntransformers. We show that given an initial prompt sentence, a public language\nmodel like GPT-2 with fine-tuning, can generate plausible CTI text with the\nability of corrupting cyber-defense systems. We utilize the generated fake CTI\ntext to perform a data poisoning attack on a Cybersecurity Knowledge Graph\n(CKG) and a cybersecurity corpus. The poisoning attack introduced adverse\nimpacts such as returning incorrect reasoning outputs, representation\npoisoning, and corruption of other dependent AI-based cyber defense systems. We\nevaluate with traditional approaches and conduct a human evaluation study with\ncybersecurity professionals and threat hunters. Based on the study,\nprofessional threat hunters were equally likely to consider our fake generated\nCTI as true.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 16:54:35 GMT"}, {"version": "v2", "created": "Sat, 10 Apr 2021 14:36:16 GMT"}, {"version": "v3", "created": "Fri, 18 Jun 2021 18:00:10 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Ranade", "Priyanka", ""], ["Piplai", "Aritran", ""], ["Mittal", "Sudip", ""], ["Joshi", "Anupam", ""], ["Finin", "Tim", ""]]}, {"id": "2102.04362", "submitter": "Chee Seng Chan", "authors": "Ding Sheng Ong, Chee Seng Chan, Kam Woh Ng, Lixin Fan, Qiang Yang", "title": "Protecting Intellectual Property of Generative Adversarial Networks from\n  Ambiguity Attack", "comments": "Accepted at CVPR2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ever since Machine Learning as a Service (MLaaS) emerges as a viable business\nthat utilizes deep learning models to generate lucrative revenue, Intellectual\nProperty Right (IPR) has become a major concern because these deep learning\nmodels can easily be replicated, shared, and re-distributed by any unauthorized\nthird parties. To the best of our knowledge, one of the prominent deep learning\nmodels - Generative Adversarial Networks (GANs) which has been widely used to\ncreate photorealistic image are totally unprotected despite the existence of\npioneering IPR protection methodology for Convolutional Neural Networks (CNNs).\nThis paper therefore presents a complete protection framework in both black-box\nand white-box settings to enforce IPR protection on GANs. Empirically, we show\nthat the proposed method does not compromise the original GANs performance\n(i.e. image generation, image super-resolution, style transfer), and at the\nsame time, it is able to withstand both removal and ambiguity attacks against\nembedded watermarks.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 17:12:20 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 03:31:03 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Ong", "Ding Sheng", ""], ["Chan", "Chee Seng", ""], ["Ng", "Kam Woh", ""], ["Fan", "Lixin", ""], ["Yang", "Qiang", ""]]}, {"id": "2102.04513", "submitter": "Mima Stanojkovski", "authors": "Delaram Kahrobaei and Mima Stanojkovski", "title": "Cryptographic multilinear maps using pro-p groups", "comments": "To appear in Advances in Mathematics of Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To any nilpotent group of class n, one can associate a non-interactive key\nexchange protocol between n+1 users. The multilinear commutator maps associated\nto nilpotent groups play a key role in this protocol. In the present paper, we\ndiscuss the security of this key exchange when applied to finite p-groups and\nexplore some alternative platforms, such as pro-p groups.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 20:23:55 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 13:19:50 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Kahrobaei", "Delaram", ""], ["Stanojkovski", "Mima", ""]]}, {"id": "2102.04660", "submitter": "Drew Stone", "authors": "Drew Stone", "title": "Trustless, privacy-preserving blockchain bridges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a protocol for facilitating trust-less cross-chain\ncryptocurrency transfers that preserve privacy of bridge withdrawals. We\nleverage zero-knowledge primitives that are commonly used to design\ncryptocurrency mixing protocols to provide similar functionality but across two\nor more blockchains. To that end, we receive cryptocurrency mixing for free\nthrough the bridge operations and de-scribe how to extend these protocols to\nincentivise bridge transfers using past ideas. We describe how resulting\nprotocols lead to similar vampire style attacks coined in the Uniswap vs.\nSushiswap saga but across chains.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 06:05:10 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Stone", "Drew", ""]]}, {"id": "2102.04661", "submitter": "Ayodeji Oseni", "authors": "Ayodeji Oseni, Nour Moustafa, Helge Janicke, Peng Liu, Zahir Tari and\n  Athanasios Vasilakos", "title": "Security and Privacy for Artificial Intelligence: Opportunities and\n  Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increased adoption of Artificial Intelligence (AI) presents an\nopportunity to solve many socio-economic and environmental challenges; however,\nthis cannot happen without securing AI-enabled technologies. In recent years,\nmost AI models are vulnerable to advanced and sophisticated hacking techniques.\nThis challenge has motivated concerted research efforts into adversarial AI,\nwith the aim of developing robust machine and deep learning models that are\nresilient to different types of adversarial scenarios. In this paper, we\npresent a holistic cyber security review that demonstrates adversarial attacks\nagainst AI applications, including aspects such as adversarial knowledge and\ncapabilities, as well as existing methods for generating adversarial examples\nand existing cyber defence models. We explain mathematical AI models,\nespecially new variants of reinforcement and federated learning, to demonstrate\nhow attack vectors would exploit vulnerabilities of AI models. We also propose\na systematic framework for demonstrating attack techniques against AI\napplications and reviewed several cyber defences that would protect AI\napplications against those attacks. We also highlight the importance of\nunderstanding the adversarial goals and their capabilities, especially the\nrecent attacks against industry applications, to develop adaptive defences that\nassess to secure AI applications. Finally, we describe the main challenges and\nfuture research directions in the domain of security and privacy of AI\ntechnologies.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 06:06:13 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Oseni", "Ayodeji", ""], ["Moustafa", "Nour", ""], ["Janicke", "Helge", ""], ["Liu", "Peng", ""], ["Tari", "Zahir", ""], ["Vasilakos", "Athanasios", ""]]}, {"id": "2102.04685", "submitter": "Songlin He", "authors": "Songlin He, Yuan Lu, Qiang Tang, Guiling Wang, Chase Qishi Wu", "title": "Fair Peer-to-Peer Content Delivery via Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peer-to-peer (p2p) content delivery is promising to provide benefits like\ncost-saving and scalable peak-demand handling in comparison with conventional\ncontent delivery networks (CDNs) and complement the decentralized storage\nnetworks such as Filecoin. However, reliable p2p delivery requires proper\nenforcement of delivery fairness, i.e., the deliverers should be rewarded\naccording to their in-time delivery. Unfortunately, most existing studies on\ndelivery fairness are based on non-cooperative game-theoretic assumptions that\nare arguably unrealistic in the ad-hoc p2p setting. We for the first time put\nforth the expressive yet still minimalist securities for p2p content delivery,\nand give two efficient solutions FairDownload and FairStream via the blockchain\nfor p2p downloading and p2p streaming scenarios, respectively. Our designs not\nonly guarantee delivery fairness to ensure deliverers be paid (nearly)\nproportional to his in-time delivery, but also ensure the content consumers and\ncontent providers to be fairly treated. The fairness of each party can be\nguaranteed when the other two parties collude to arbitrarily misbehave.\nMoreover, the systems are efficient in the sense of attaining asymptotically\noptimal on-chain costs and optimal deliverer communication. We implement the\nprotocols to build the prototype systems atop the Ethereum Ropsten network.\nExtensive experiments done in LAN and WAN settings showcase their high\npracticality.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 07:22:48 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 13:58:06 GMT"}, {"version": "v3", "created": "Fri, 14 May 2021 22:39:21 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["He", "Songlin", ""], ["Lu", "Yuan", ""], ["Tang", "Qiang", ""], ["Wang", "Guiling", ""], ["Wu", "Chase Qishi", ""]]}, {"id": "2102.04704", "submitter": "Andrew Lowy", "authors": "Andrew Lowy and Meisam Razaviyayn", "title": "Output Perturbation for Differentially Private Convex Optimization with\n  Improved Population Loss Bounds, Runtimes and Applications to Private\n  Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding efficient, easily implementable differentially private (DP)\nalgorithms that offer strong excess risk bounds is an important problem in\nmodern machine learning. To date, most work has focused on private empirical\nrisk minimization (ERM) or private population loss minimization. However, there\nare often other objectives--such as fairness, adversarial robustness, or\nsensitivity to outliers--besides average performance that are not captured in\nthe classical ERM setup. To this end, we study a completely general family of\nconvex, Lipschitz loss functions and establish the first known DP excess risk\nand runtime bounds for optimizing this broad class. We provide similar bounds\nunder additional assumptions of smoothness and/or strong convexity. We also\naddress private stochastic convex optimization (SCO). While $(\\epsilon,\n\\delta)$-DP ($\\delta > 0$) has been the focus of much recent work in private\nSCO, proving tight population loss bounds and runtime bounds for $(\\epsilon,\n0)$-DP remains a challenging open problem. We provide the tightest known\n$(\\epsilon, 0)$-DP population loss bounds and fastest runtimes under the\npresence of (or lack of) smoothness and strong convexity. Our methods extend to\nthe $\\delta > 0$ setting, where we offer the unique benefit of ensuring\ndifferential privacy for arbitrary $\\epsilon > 0$ by incorporating a new form\nof Gaussian noise. Finally, we apply our theory to two learning frameworks:\ntilted ERM and adversarial learning. In particular, our theory quantifies\ntradeoffs between adversarial robustness, privacy, and runtime. Our results are\nachieved using perhaps the simplest DP algorithm: output perturbation. Although\nthis method is not novel conceptually, our novel implementation scheme and\nanalysis show that the power of this method to achieve strong privacy, utility,\nand runtime guarantees has not been fully appreciated in prior works.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 08:47:06 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Lowy", "Andrew", ""], ["Razaviyayn", "Meisam", ""]]}, {"id": "2102.04737", "submitter": "Onur G\\\"unl\\\"u Dr.-Ing.", "authors": "Muah Kim, Onur G\\\"unl\\\"u, and Rafael F. Schaefer", "title": "Federated Learning with Local Differential Privacy: Trade-offs between\n  Privacy, Utility, and Communication", "comments": "To appear in IEEE International Conference on Acoustics, Speech, and\n  Signal Processing 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC cs.IT eess.SP math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning (FL) allows to train a massive amount of data privately\ndue to its decentralized structure. Stochastic gradient descent (SGD) is\ncommonly used for FL due to its good empirical performance, but sensitive user\ninformation can still be inferred from weight updates shared during FL\niterations. We consider Gaussian mechanisms to preserve local differential\nprivacy (LDP) of user data in the FL model with SGD. The trade-offs between\nuser privacy, global utility, and transmission rate are proved by defining\nappropriate metrics for FL with LDP. Compared to existing results, the query\nsensitivity used in LDP is defined as a variable and a tighter privacy\naccounting method is applied. The proposed utility bound allows heterogeneous\nparameters over all users. Our bounds characterize how much utility decreases\nand transmission rate increases if a stronger privacy regime is targeted.\nFurthermore, given a target privacy level, our results guarantee a\nsignificantly larger utility and a smaller transmission rate as compared to\nexisting privacy accounting methods.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 10:04:18 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Kim", "Muah", ""], ["G\u00fcnl\u00fc", "Onur", ""], ["Schaefer", "Rafael F.", ""]]}, {"id": "2102.04763", "submitter": "Lukas Daniel Klausner", "authors": "Djordje Slijep\\v{c}evi\\'c, Maximilian Henzl, Lukas Daniel Klausner,\n  Tobias Dam, Peter Kieseberg, Matthias Zeppelzauer", "title": "$k$-Anonymity in Practice: How Generalisation and Suppression Affect\n  Machine Learning Classifiers", "comments": "42 pages, 27 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The protection of private information is a crucial issue in data-driven\nresearch and business contexts. Typically, techniques like anonymisation or\n(selective) deletion are introduced in order to allow data sharing, \\eg\\ in the\ncase of collaborative research endeavours. For use with anonymisation\ntechniques, the $k$-anonymity criterion is one of the most popular, with\nnumerous scientific publications on different algorithms and metrics.\nAnonymisation techniques often require changing the data and thus necessarily\naffect the results of machine learning models trained on the underlying data.\nIn this work, we conduct a systematic comparison and detailed investigation\ninto the effects of different $k$-anonymisation algorithms on the results of\nmachine learning models. We investigate a set of popular $k$-anonymisation\nalgorithms with different classifiers and evaluate them on different real-world\ndatasets. Our systematic evaluation shows that with an increasingly strong\n$k$-anonymity constraint, the classification performance generally degrades,\nbut to varying degrees and strongly depending on the dataset and anonymisation\nmethod. Furthermore, Mondrian can be considered as the method with the most\nappealing properties for subsequent classification.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 11:28:20 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Slijep\u010devi\u0107", "Djordje", ""], ["Henzl", "Maximilian", ""], ["Klausner", "Lukas Daniel", ""], ["Dam", "Tobias", ""], ["Kieseberg", "Peter", ""], ["Zeppelzauer", "Matthias", ""]]}, {"id": "2102.04796", "submitter": "Javier Yuste", "authors": "Javier Yuste, Sergio Pastrana", "title": "Avaddon ransomware: an in-depth analysis and decryption of infected\n  systems", "comments": null, "journal-ref": "Computers & Security 109 (2021) 102388", "doi": "10.1016/j.cose.2021.102388", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The commoditization of Malware-as-a-Service (MaaS) allows criminals to obtain\nfinancial benefits at a low risk and with little technical background. One such\npopular product in the underground economy is ransomware. In ransomware\nattacks, data from infected systems is held hostage (encrypted) until a fee is\npaid to the criminals. This modus operandi disrupts legitimate businesses,\nwhich may become unavailable until the data is restored. A recent blackmailing\nstrategy adopted by criminals is to leak data online from the infected systems\nif the ransom is not paid. Besides reputational damage, data leakage might\nproduce further economical losses due to fines imposed by data protection laws.\nThus, research on prevention and recovery measures to mitigate the impact of\nsuch attacks is needed to adapt existing countermeasures to new strains.\n  In this work, we perform an in-depth analysis of Avaddon, a ransomware\noffered in the underground economy as an affiliate program business. This has\ninfected and leaked data from at least 23 organizations. Additionally, it runs\nDistributed Denial-of-Service (DDoS) attacks against victims that do not pay\nthe ransom. We first provide an analysis of the criminal business model from\nthe underground economy. Then, we identify and describe its technical\ncapabilities. We provide empirical evidence of links between this variant and a\nprevious family, suggesting that the same group was behind the development and,\npossibly, the operation of both campaigns.\n  Finally, we describe a method to decrypt files encrypted with Avaddon in real\ntime. We implement and test the decryptor in a tool that can recover the\nencrypted data from an infected system, thus mitigating the damage caused by\nthe ransomware. The tool is released open-source so it can be incorporated in\nexisting Antivirus engines.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 12:31:49 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Yuste", "Javier", ""], ["Pastrana", "Sergio", ""]]}, {"id": "2102.04805", "submitter": "Gr\\'egoire Menguy", "authors": "Gr\\'egoire Menguy, S\\'ebastien Bardin, Richard Bonichon, Cauim de\n  Souza Lima", "title": "AI-based Blackbox Code Deobfuscation: Understand, Improve and Mitigate", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Code obfuscation aims at protecting Intellectual Property and other secrets\nembedded into software from being retrieved. Recent works leverage advances in\nartificial intelligence with the hope of getting blackbox deobfuscators\ncompletely immune to standard (whitebox) protection mechanisms. While\npromising, this new field of AI-based blackbox deobfuscation is still in its\ninfancy. In this article we deepen the state of AI-based blackbox deobfuscation\nin three key directions: understand the current state-of-the-art, improve over\nit and design dedicated protection mechanisms. In particular, we define a novel\ngeneric framework for AI-based blackbox deobfuscation encompassing prior work\nand highlighting key components; we are the first to point out that the search\nspace underlying code deobfuscation is too unstable for simulation-based\nmethods (e.g., Monte Carlo Tres Search used in prior work) and advocate the use\nof robust methods such as S-metaheuritics; we propose the new optimized\nAI-based blackbox deobfuscator Xyntia which significantly outperforms prior\nwork in terms of success rate (especially with small time budget) while being\ncompletely immune to the most recent anti-analysis code obfuscation methods;\nand finally we propose two novel protections against AI-based blackbox\ndeobfuscation, allowing to counter Xyntia's powerful attacks.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 12:52:24 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Menguy", "Gr\u00e9goire", ""], ["Bardin", "S\u00e9bastien", ""], ["Bonichon", "Richard", ""], ["Lima", "Cauim de Souza", ""]]}, {"id": "2102.05104", "submitter": "Sahar Abdelnabi", "authors": "Sahar Abdelnabi and Mario Fritz", "title": "\"What's in the box?!\": Deflecting Adversarial Attacks by Randomly\n  Deploying Adversarially-Disjoint Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are now widely deployed in real-world applications.\nHowever, the existence of adversarial examples has been long considered a real\nthreat to such models. While numerous defenses aiming to improve the robustness\nhave been proposed, many have been shown ineffective. As these vulnerabilities\nare still nowhere near being eliminated, we propose an alternative\ndeployment-based defense paradigm that goes beyond the traditional white-box\nand black-box threat models. Instead of training a single partially-robust\nmodel, one could train a set of same-functionality, yet, adversarially-disjoint\nmodels with minimal in-between attack transferability. These models could then\nbe randomly and individually deployed, such that accessing one of them\nminimally affects the others. Our experiments on CIFAR-10 and a wide range of\nattacks show that we achieve a significantly lower attack transferability\nacross our disjoint models compared to a baseline of ensemble diversity. In\naddition, compared to an adversarially trained set, we achieve a higher average\nrobust accuracy while maintaining the accuracy of clean examples.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 20:07:13 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 13:53:52 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Abdelnabi", "Sahar", ""], ["Fritz", "Mario", ""]]}, {"id": "2102.05123", "submitter": "Guangyu Shen", "authors": "Guangyu Shen, Yingqi Liu, Guanhong Tao, Shengwei An, Qiuling Xu,\n  Siyuan Cheng, Shiqing Ma, Xiangyu Zhang", "title": "Backdoor Scanning for Deep Neural Networks through K-Arm Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Back-door attack poses a severe threat to deep learning systems. It injects\nhidden malicious behaviors to a model such that any input stamped with a\nspecial pattern can trigger such behaviors. Detecting back-door is hence of\npressing need. Many existing defense techniques use optimization to generate\nthe smallest input pattern that forces the model to misclassify a set of benign\ninputs injected with the pattern to a target label. However, the complexity is\nquadratic to the number of class labels such that they can hardly handle models\nwith many classes. Inspired by Multi-Arm Bandit in Reinforcement Learning, we\npropose a K-Arm optimization method for backdoor detection. By iteratively and\nstochastically selecting the most promising labels for optimization with the\nguidance of an objective function, we substantially reduce the complexity,\nallowing to handle models with many classes. Moreover, by iteratively refining\nthe selection of labels to optimize, it substantially mitigates the uncertainty\nin choosing the right labels, improving detection accuracy. At the time of\nsubmission, the evaluation of our method on over 4000 models in the IARPA\nTrojAI competition from round 1 to the latest round 4 achieves top performance\non the leaderboard. Our technique also supersedes three state-of-the-art\ntechniques in terms of accuracy and the scanning time needed.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 20:49:06 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 19:17:09 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Shen", "Guangyu", ""], ["Liu", "Yingqi", ""], ["Tao", "Guanhong", ""], ["An", "Shengwei", ""], ["Xu", "Qiuling", ""], ["Cheng", "Siyuan", ""], ["Ma", "Shiqing", ""], ["Zhang", "Xiangyu", ""]]}, {"id": "2102.05143", "submitter": "Waleed Yousef", "authors": "Waleed A. Yousef, Issa Traore, William Briguglio", "title": "Classifier Calibration: with implications to threat scores in\n  cybersecurity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the calibration of a classifier output score in binary\nclassification problems. A calibrator is a function that maps the arbitrary\nclassifier score, of a testing observation, onto $[0,1]$ to provide an estimate\nfor the posterior probability of belonging to one of the two classes.\nCalibration is important for two reasons; first, it provides a meaningful\nscore, that is the posterior probability; second, it puts the scores of\ndifferent classifiers on the same scale for comparable interpretation. The\npaper presents three main contributions: (1) Introducing multi-score\ncalibration, when more than one classifier provides a score for a single\nobservation. (2) Introducing the idea that the classifier scores to a\ncalibration process are nothing but features to a classifier, hence proposing\nextending the classifier scores to higher dimensions to boost the calibrator's\nperformance. (3) Conducting a massive simulation study, in the order of 24,000\nexperiments, that incorporates different configurations, in addition to\nexperimenting on two real datasets from the cybersecurity domain. The results\nshow that there is no overall winner among the different calibrators and\ndifferent configurations. However, general advices for practitioners include\nthe following: the Platt's\ncalibrator~\\citep{Platt1999ProbabilisticOutputsForSupport}, a version of the\nlogistic regression that decreases bias for a small sample size, has a very\nstable and acceptable performance among all experiments; our suggested\nmulti-score calibration provides better performance than single score\ncalibration in the majority of experiments, including the two real datasets. In\naddition, extending the scores can help in some experiments.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 21:45:23 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Yousef", "Waleed A.", ""], ["Traore", "Issa", ""], ["Briguglio", "William", ""]]}, {"id": "2102.05188", "submitter": "Adam Dziedzic", "authors": "Christopher A. Choquette-Choo, Natalie Dullerud, Adam Dziedzic,\n  Yunxiang Zhang, Somesh Jha, Nicolas Papernot, Xiao Wang", "title": "CaPC Learning: Confidential and Private Collaborative Learning", "comments": "Published as a conference paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning benefits from large training datasets, which may not always\nbe possible to collect by any single entity, especially when using\nprivacy-sensitive data. In many contexts, such as healthcare and finance,\nseparate parties may wish to collaborate and learn from each other's data but\nare prevented from doing so due to privacy regulations. Some regulations\nprevent explicit sharing of data between parties by joining datasets in a\ncentral location (confidentiality). Others also limit implicit sharing of data,\ne.g., through model predictions (privacy). There is currently no method that\nenables machine learning in such a setting, where both confidentiality and\nprivacy need to be preserved, to prevent both explicit and implicit sharing of\ndata. Federated learning only provides confidentiality, not privacy, since\ngradients shared still contain private information. Differentially private\nlearning assumes unreasonably large datasets. Furthermore, both of these\nlearning paradigms produce a central model whose architecture was previously\nagreed upon by all parties rather than enabling collaborative learning where\neach party learns and improves their own local model. We introduce Confidential\nand Private Collaborative (CaPC) learning, the first method provably achieving\nboth confidentiality and privacy in a collaborative setting. We leverage secure\nmulti-party computation (MPC), homomorphic encryption (HE), and other\ntechniques in combination with privately aggregated teacher models. We\ndemonstrate how CaPC allows participants to collaborate without having to\nexplicitly join their training sets or train a central model. Each party is\nable to improve the accuracy and fairness of their model, even in settings\nwhere each party has a model that performs well on their own dataset or when\ndatasets are not IID and model architectures are heterogeneous across parties.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 23:50:24 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 19:31:05 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Choquette-Choo", "Christopher A.", ""], ["Dullerud", "Natalie", ""], ["Dziedzic", "Adam", ""], ["Zhang", "Yunxiang", ""], ["Jha", "Somesh", ""], ["Papernot", "Nicolas", ""], ["Wang", "Xiao", ""]]}, {"id": "2102.05195", "submitter": "Hyun Bin Lee", "authors": "Hyun Bin Lee (1), Tushar M. Jois (2), Christopher W. Fletcher (1),\n  Carl A. Gunter (1) ((1) University of Illinois at Urbana-Champaign, (2) Johns\n  Hopkins University)", "title": "DOVE: A Data-Oblivious Virtual Environment", "comments": "Appears in the proceedings of the 28th Network and Distributed System\n  Security Symposium (NDSS), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users can improve the security of remote communications by using Trusted\nExecution Environments (TEEs) to protect against direct introspection and\ntampering of sensitive data. This can even be done with applications coded in\nhigh-level languages with complex programming stacks such as R, Python, and\nRuby. However, this creates a trade-off between programming convenience versus\nthe risk of attacks using microarchitectural side channels.\n  In this paper, we argue that it is possible to address this problem for\nimportant applications by instrumenting a complex programming environment (like\nR) to produce a Data-Oblivious Transcript (DOT) that is explicitly designed to\nsupport computation that excludes side channels. Such a transcript is then\nevaluated on a Trusted Execution Environment (TEE) containing the sensitive\ndata using a small trusted computing base called the Data-Oblivious Virtual\nEnvironment (DOVE).\n  To motivate the problem, we demonstrate a number of subtle side-channel\nvulnerabilities in the R language. We then provide an illustrative design and\nimplementation of DOVE for R, creating the first side-channel resistant R\nprogramming stack. We demonstrate that the two-phase architecture provided by\nDOT generation and DOVE evaluation can provide practical support for complex\nprogramming languages with usable performance and high security assurances\nagainst side channels.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 00:15:29 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Lee", "Hyun Bin", ""], ["Jois", "Tushar M.", ""], ["Fletcher", "Christopher W.", ""], ["Gunter", "Carl A.", ""]]}, {"id": "2102.05196", "submitter": "Ian Goldberg", "authors": "Rob Jansen, Justin Tracey, Ian Goldberg", "title": "Once is Never Enough: Foundations for Sound Statistical Inference in Tor\n  Network Experimentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tor is a popular low-latency anonymous communication system that focuses on\nusability and performance: a faster network will attract more users, which in\nturn will improve the anonymity of everyone using the system. The standard\npractice for previous research attempting to enhance Tor performance is to draw\nconclusions from the observed results of a single simulation for standard Tor\nand for each research variant. But because the simulations are run in sampled\nTor networks, it is possible that sampling error alone could cause the observed\neffects. Therefore, we call into question the practical meaning of any\nconclusions that are drawn without considering the statistical significance of\nthe reported results.\n  In this paper, we build foundations upon which we improve the Tor\nexperimental method. First, we present a new Tor network modeling methodology\nthat produces more representative Tor networks as well as new and improved\nexperimentation tools that run Tor simulations faster and at a larger scale\nthan was previously possible. We showcase these contributions by running\nsimulations with 6,489 relays and 792k simultaneously active users, the largest\nknown Tor network simulations and the first at a network scale of 100%. Second,\nwe present new statistical methodologies through which we: (i) show that\nrunning multiple simulations in independently sampled networks is necessary in\norder to produce informative results; and (ii) show how to use the results from\nmultiple simulations to conduct sound statistical inference. We present a case\nstudy using 420 simulations to demonstrate how to apply our methodologies to a\nconcrete set of Tor experiments and how to analyze the results.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 00:28:57 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 18:50:28 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Jansen", "Rob", ""], ["Tracey", "Justin", ""], ["Goldberg", "Ian", ""]]}, {"id": "2102.05238", "submitter": "Shantanu Sharma", "authors": "Peeyush Gupta, Sharad Mehrotra, Shantanu Sharma, Nalini\n  Venkatasubramanian, Guoxi Wang", "title": "Concealer: SGX-based Secure, Volume Hiding, and Verifiable Processing of\n  Spatial Time-Series Datasets", "comments": "A preliminary version of this paper has been accepted in the 24th\n  International Conference on Extending Database Technology (EDBT) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.DC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a system, entitled Concealer that allows sharing\ntime-varying spatial data (e.g., as produced by sensors) in encrypted form to\nan untrusted third-party service provider to provide location-based\napplications (involving aggregation queries over selected regions over time\nwindows) to users. Concealer exploits carefully selected encryption techniques\nto use indexes supported by database systems and combines ways to add fake\ntuples in order to realize an efficient system that protects against leakage\nbased on output-size. Thus, the design of Concealer overcomes two limitations\nof existing symmetric searchable encryption (SSE) techniques: (i) it avoids the\nneed of specialized data structures that limit usability/practicality of SSE in\nlarge scale deployments, and (ii) it avoids information leakages based on the\noutput-size, which may leak data distributions. Experimental results validate\nthe efficiency of the proposed algorithms over a spatial time-series dataset\n(collected from a smart space) and TPC-H datasets, each of 136 Million rows,\nthe size of which prior approaches have not scaled to.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 03:28:25 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Gupta", "Peeyush", ""], ["Mehrotra", "Sharad", ""], ["Sharma", "Shantanu", ""], ["Venkatasubramanian", "Nalini", ""], ["Wang", "Guoxi", ""]]}, {"id": "2102.05257", "submitter": "Ching Pui Wan", "authors": "Ching Pui Wan, Qifeng Chen", "title": "Robust Federated Learning with Attack-Adaptive Aggregation", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning is vulnerable to various attacks, such as model poisoning\nand backdoor attacks, even if some existing defense strategies are used. To\naddress this challenge, we propose an attack-adaptive aggregation strategy to\ndefend against various attacks for robust federated learning. The proposed\napproach is based on training a neural network with an attention mechanism that\nlearns the vulnerability of federated learning models from a set of plausible\nattacks. To the best of our knowledge, our aggregation strategy is the first\none that can be adapted to defend against various attacks in a data-driven\nfashion. Our approach has achieved competitive performance in defending model\npoisoning and backdoor attacks in federated learning tasks on image and text\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 04:23:23 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Wan", "Ching Pui", ""], ["Chen", "Qifeng", ""]]}, {"id": "2102.05289", "submitter": "Matthew Wicker", "authors": "Matthew Wicker, Luca Laurenti, Andrea Patane, Zhoutong Chen, Zheng\n  Zhang, Marta Kwiatkowska", "title": "Bayesian Inference with Certifiable Adversarial Robustness", "comments": "Accepted AISTATS2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider adversarial training of deep neural networks through the lens of\nBayesian learning, and present a principled framework for adversarial training\nof Bayesian Neural Networks (BNNs) with certifiable guarantees. We rely on\ntechniques from constraint relaxation of non-convex optimisation problems and\nmodify the standard cross-entropy error model to enforce posterior robustness\nto worst-case perturbations in $\\epsilon$-balls around input points. We\nillustrate how the resulting framework can be combined with methods commonly\nemployed for approximate inference of BNNs. In an empirical investigation, we\ndemonstrate that the presented approach enables training of certifiably robust\nmodels on MNIST, FashionMNIST and CIFAR-10 and can also be beneficial for\nuncertainty calibration. Our method is the first to directly train certifiable\nBNNs, thus facilitating their deployment in safety-critical applications.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 07:17:49 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 04:23:58 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Wicker", "Matthew", ""], ["Laurenti", "Luca", ""], ["Patane", "Andrea", ""], ["Chen", "Zhoutong", ""], ["Zhang", "Zheng", ""], ["Kwiatkowska", "Marta", ""]]}, {"id": "2102.05290", "submitter": "Ryo Kawaoka", "authors": "Ryo Kawaoka, Daiki Chiba, Takuya Watanabe, Mitsuaki Akiyama, Tatsuya\n  Mori", "title": "A First Look at COVID-19 Domain Names: Origin and Implications", "comments": "9 pages, 4 figures, 4 tables. Accepted at the Passive and Active\n  Measurement Conference 2021 (PAM 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work takes a first look at domain names related to COVID-19 (Cov19doms\nin short), using a large-scale registered Internet domain name database, which\naccounts for 260M of distinct domain names registered for 1.6K of distinct\ntop-level domains. We extracted 167K of Cov19doms that have been registered\nbetween the end of December 2019 and the end of September 2020. We attempt to\nanswer the following research questions through our measurement study: RQ1: Is\nthe number of Cov19doms registrations correlated with the COVID-19 outbreaks?,\nRQ2: For what purpose do people register Cov19doms? Our chief findings are as\nfollows: (1) Similar to the global COVID-19 pandemic observed around April\n2020, the number of Cov19doms registrations also experienced the drastic\ngrowth, which, interestingly, pre-ceded the COVID-19 pandemic by about a month,\n(2) 70 % of active Cov19doms websites with visible content provided useful\ninformation such as health, tools, or product sales related to COVID-19, and\n(3) non-negligible number of registered Cov19doms was used for malicious\npurposes. These findings imply that it has become more challenging to\ndistinguish domain names registered for legitimate purposes from others and\nthat it is crucial to pay close attention to how Cov19doms will be used/misused\nin the future.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 07:19:36 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Kawaoka", "Ryo", ""], ["Chiba", "Daiki", ""], ["Watanabe", "Takuya", ""], ["Akiyama", "Mitsuaki", ""], ["Mori", "Tatsuya", ""]]}, {"id": "2102.05334", "submitter": "Yael Mathov", "authors": "Yael Mathov, Lior Rokach, Yuval Elovici", "title": "Enhancing Real-World Adversarial Patches with 3D Modeling Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Although many studies have examined adversarial examples in the real world,\nmost of them relied on 2D photos of the attack scene; thus, the attacks\nproposed cannot address realistic environments with 3D objects or varied\nconditions. Studies that use 3D objects are limited, and in many cases, the\nreal-world evaluation process is not replicable by other researchers,\npreventing others from reproducing the results. In this study, we present a\nframework that crafts an adversarial patch for an existing real-world scene.\nOur approach uses a 3D digital approximation of the scene as a simulation of\nthe real world. With the ability to add and manipulate any element in the\ndigital scene, our framework enables the attacker to improve the patch's\nrobustness in real-world settings. We use the framework to create a patch for\nan everyday scene and evaluate its performance using a novel evaluation process\nthat ensures that our results are reproducible in both the digital space and\nthe real world. Our evaluation results show that the framework can generate\nadversarial patches that are robust to different settings in the real world.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 09:16:09 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Mathov", "Yael", ""], ["Rokach", "Lior", ""], ["Elovici", "Yuval", ""]]}, {"id": "2102.05363", "submitter": "Liwei Wang", "authors": "Bohang Zhang, Tianle Cai, Zhou Lu, Di He, Liwei Wang", "title": "Towards Certifying L-infinity Robustness using Neural Networks with\n  L-inf-dist Neurons", "comments": "Appearing at International Conference on Machine Learning (ICML) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that standard neural networks, even with a high\nclassification accuracy, are vulnerable to small $\\ell_\\infty$-norm bounded\nadversarial perturbations. Although many attempts have been made, most previous\nworks either can only provide empirical verification of the defense to a\nparticular attack method, or can only develop a certified guarantee of the\nmodel robustness in limited scenarios. In this paper, we seek for a new\napproach to develop a theoretically principled neural network that inherently\nresists $\\ell_\\infty$ perturbations. In particular, we design a novel neuron\nthat uses $\\ell_\\infty$-distance as its basic operation (which we call\n$\\ell_\\infty$-dist neuron), and show that any neural network constructed with\n$\\ell_\\infty$-dist neurons (called $\\ell_{\\infty}$-dist net) is naturally a\n1-Lipschitz function with respect to $\\ell_\\infty$-norm. This directly provides\na rigorous guarantee of the certified robustness based on the margin of\nprediction outputs. We then prove that such networks have enough expressive\npower to approximate any 1-Lipschitz function with robust generalization\nguarantee. We further provide a holistic training strategy that can greatly\nalleviate optimization difficulties. Experimental results show that using\n$\\ell_{\\infty}$-dist nets as basic building blocks, we consistently achieve\nstate-of-the-art performance on commonly used datasets: 93.09% certified\naccuracy on MNIST ($\\epsilon=0.3$), 35.42% on CIFAR-10 ($\\epsilon=8/255$) and\n16.31% on TinyImageNet ($\\epsilon=1/255$).\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 10:03:58 GMT"}, {"version": "v2", "created": "Sat, 22 May 2021 04:57:54 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 08:01:16 GMT"}, {"version": "v4", "created": "Mon, 14 Jun 2021 10:40:48 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Zhang", "Bohang", ""], ["Cai", "Tianle", ""], ["Lu", "Zhou", ""], ["He", "Di", ""], ["Wang", "Liwei", ""]]}, {"id": "2102.05368", "submitter": "Thibault Maho", "authors": "Thibault Maho, Beno\\^it Bonnet, Teddy Furon, Erwan Le Merrer", "title": "RoBIC: A benchmark suite for assessing classifiers robustness", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many defenses have emerged with the development of adversarial attacks.\nModels must be objectively evaluated accordingly. This paper systematically\ntackles this concern by proposing a new parameter-free benchmark we coin RoBIC.\nRoBIC fairly evaluates the robustness of image classifiers using a new\nhalf-distortion measure. It gauges the robustness of the network against white\nand black box attacks, independently of its accuracy. RoBIC is faster than the\nother available benchmarks. We present the significant differences in the\nrobustness of 16 recent models as assessed by RoBIC.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 10:13:39 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Maho", "Thibault", ""], ["Bonnet", "Beno\u00eet", ""], ["Furon", "Teddy", ""], ["Merrer", "Erwan Le", ""]]}, {"id": "2102.05429", "submitter": "XInlei He", "authors": "Xinlei He and Rui Wen and Yixin Wu and Michael Backes and Yun Shen and\n  Yang Zhang", "title": "Node-Level Membership Inference Attacks Against Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many real-world data comes in the form of graphs, such as social networks and\nprotein structure. To fully utilize the information contained in graph data, a\nnew family of machine learning (ML) models, namely graph neural networks\n(GNNs), has been introduced. Previous studies have shown that machine learning\nmodels are vulnerable to privacy attacks. However, most of the current efforts\nconcentrate on ML models trained on data from the Euclidean space, like images\nand texts. On the other hand, privacy risks stemming from GNNs remain largely\nunstudied.\n  In this paper, we fill the gap by performing the first comprehensive analysis\nof node-level membership inference attacks against GNNs. We systematically\ndefine the threat models and propose three node-level membership inference\nattacks based on an adversary's background knowledge. Our evaluation on three\nGNN structures and four benchmark datasets shows that GNNs are vulnerable to\nnode-level membership inference even when the adversary has minimal background\nknowledge. Besides, we show that graph density and feature similarity have a\nmajor impact on the attack's success. We further investigate two defense\nmechanisms and the empirical results indicate that these defenses can reduce\nthe attack performance but with moderate utility loss.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 13:51:54 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["He", "Xinlei", ""], ["Wen", "Rui", ""], ["Wu", "Yixin", ""], ["Backes", "Michael", ""], ["Shen", "Yun", ""], ["Zhang", "Yang", ""]]}, {"id": "2102.05431", "submitter": "Thorsten Eisenhofer", "authors": "Thorsten Eisenhofer, Lea Sch\\\"onherr, Joel Frank, Lars Speckemeier,\n  Dorothea Kolossa, Thorsten Holz", "title": "Dompteur: Taming Audio Adversarial Examples", "comments": "Accepted at USENIX Security Symposium 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples seem to be inevitable. These specifically crafted inputs\nallow attackers to arbitrarily manipulate machine learning systems. Even worse,\nthey often seem harmless to human observers. In our digital society, this poses\na significant threat. For example, Automatic Speech Recognition (ASR) systems,\nwhich serve as hands-free interfaces to many kinds of systems, can be attacked\nwith inputs incomprehensible for human listeners. The research community has\nunsuccessfully tried several approaches to tackle this problem. In this paper\nwe propose a different perspective: We accept the presence of adversarial\nexamples against ASR systems, but we require them to be perceivable by human\nlisteners. By applying the principles of psychoacoustics, we can remove\nsemantically irrelevant information from the ASR input and train a model that\nresembles human perception more closely. We implement our idea in a tool named\nDOMPTEUR and demonstrate that our augmented system, in contrast to an\nunmodified baseline, successfully focuses on perceptible ranges of the input\nsignal. This change forces adversarial examples into the audible range, while\nusing minimal computational overhead and preserving benign performance. To\nevaluate our approach, we construct an adaptive attacker that actively tries to\navoid our augmentations and demonstrate that adversarial examples from this\nattacker remain clearly perceivable. Finally, we substantiate our claims by\nperforming a hearing test with crowd-sourced human listeners.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 13:53:32 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 12:46:05 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Eisenhofer", "Thorsten", ""], ["Sch\u00f6nherr", "Lea", ""], ["Frank", "Joel", ""], ["Speckemeier", "Lars", ""], ["Kolossa", "Dorothea", ""], ["Holz", "Thorsten", ""]]}, {"id": "2102.05475", "submitter": "Grzegorz G{\\l}uch", "authors": "Grzegorz G{\\l}uch, R\\\"udiger Urbanke", "title": "Adversarial Robustness: What fools you makes you stronger", "comments": "15 pages, 1 figure [V2 - fixed typos]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove an exponential separation for the sample complexity between the\nstandard PAC-learning model and a version of the Equivalence-Query-learning\nmodel. We then show that this separation has interesting implications for\nadversarial robustness. We explore a vision of designing an adaptive defense\nthat in the presence of an attacker computes a model that is provably robust.\nIn particular, we show how to realize this vision in a simplified setting.\n  In order to do so, we introduce a notion of a strong adversary: he is not\nlimited by the type of perturbations he can apply but when presented with a\nclassifier can repetitively generate different adversarial examples. We explain\nwhy this notion is interesting to study and use it to prove the following.\nThere exists an efficient adversarial-learning-like scheme such that for every\nstrong adversary $\\mathbf{A}$ it outputs a classifier that (a) cannot be\nstrongly attacked by $\\mathbf{A}$, or (b) has error at most $\\epsilon$. In both\ncases our scheme uses exponentially (in $\\epsilon$) fewer samples than what the\nPAC bound requires.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 15:00:24 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 16:27:32 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["G\u0142uch", "Grzegorz", ""], ["Urbanke", "R\u00fcdiger", ""]]}, {"id": "2102.05561", "submitter": "Omid Aramoon", "authors": "Omid Aramoon, Pin-Yu Chen, Gang Qu, Yuan Tian", "title": "Meta Federated Learning", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to its distributed methodology alongside its privacy-preserving features,\nFederated Learning (FL) is vulnerable to training time adversarial attacks. In\nthis study, our focus is on backdoor attacks in which the adversary's goal is\nto cause targeted misclassifications for inputs embedded with an adversarial\ntrigger while maintaining an acceptable performance on the main learning task\nat hand. Contemporary defenses against backdoor attacks in federated learning\nrequire direct access to each individual client's update which is not feasible\nin recent FL settings where Secure Aggregation is deployed. In this study, we\nseek to answer the following question, Is it possible to defend against\nbackdoor attacks when secure aggregation is in place?, a question that has not\nbeen addressed by prior arts. To this end, we propose Meta Federated Learning\n(Meta-FL), a novel variant of federated learning which not only is compatible\nwith secure aggregation protocol but also facilitates defense against backdoor\nattacks. We perform a systematic evaluation of Meta-FL on two classification\ndatasets: SVHN and GTSRB. The results show that Meta-FL not only achieves\nbetter utility than classic FL, but also enhances the performance of\ncontemporary defenses in terms of robustness against adversarial attacks.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 16:48:32 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Aramoon", "Omid", ""], ["Chen", "Pin-Yu", ""], ["Qu", "Gang", ""], ["Tian", "Yuan", ""]]}, {"id": "2102.05571", "submitter": "Nidhi Rastogi", "authors": "Nidhi Rastogi, Sharmishtha Dutta, Ryan Christian, Jared Gridley,\n  Mohammad Zaki, Alex Gittens, Charu Aggarwal", "title": "Predicting malware threat intelligence using KGs", "comments": "14 pages", "journal-ref": null, "doi": "10.13140/RG.2.2.12526.54083", "report-no": null, "categories": "cs.CR cs.AI cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Large amounts of threat intelligence information about malware attacks are\navailable in disparate, typically unstructured, formats. Knowledge graphs can\ncapture this information and its context using RDF triples represented by\nentities and relations. Sparse or inaccurate threat information, however, leads\nto challenges such as incomplete or erroneous triples. Generic information\nextraction (IE) models used to populate the knowledge graph cannot fully\nguarantee domain-specific context. This paper proposes a system to generate a\nMalware Knowledge Graph called MalKG, the first open-source automated knowledge\ngraph for malware threat intelligence. MalKG dataset (MT40K\\footnote{ Anonymous\nGitHub link: https://github.com/malkg-researcher/MalKG}) contains approximately\n40,000 triples generated from 27,354 unique entities and 34 relations. For\nground truth, we manually curate a knowledge graph called MT3K, with 3,027\ntriples generated from 5,741 unique entities and 22 relations. We demonstrate\nthe intelligence prediction of MalKG using two use cases. Predicting malware\nthreat information using the benchmark model achieves 80.4 for the hits@10\nmetric (predicts the top 10 options for an information class), and 0.75 for the\nMRR (mean reciprocal rank). We also propose an automated, contextual framework\nfor information extraction, both manually and automatically, at the sentence\nlevel from 1,100 malware threat reports and from the common vulnerabilities and\nexposures (CVE) database.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 17:08:09 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 05:03:10 GMT"}, {"version": "v3", "created": "Mon, 24 May 2021 19:36:44 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Rastogi", "Nidhi", ""], ["Dutta", "Sharmishtha", ""], ["Christian", "Ryan", ""], ["Gridley", "Jared", ""], ["Zaki", "Mohammad", ""], ["Gittens", "Alex", ""], ["Aggarwal", "Charu", ""]]}, {"id": "2102.05583", "submitter": "Nidhi Rastogi", "authors": "Sharmishtha Dutta, Nidhi Rastogi, Destin Yee, Chuqiao Gu, Qicheng Ma", "title": "Malware Knowledge Graph Generation", "comments": "5 pages", "journal-ref": null, "doi": "10.13140/RG.2.2.27340.95367", "report-no": null, "categories": "cs.CR cs.IR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Cyber threat and attack intelligence information are available in\nnon-standard format from heterogeneous sources. Comprehending them and\nutilizing them for threat intelligence extraction requires engaging security\nexperts. Knowledge graphs enable converting this unstructured information from\nheterogeneous sources into a structured representation of data and factual\nknowledge for several downstream tasks such as predicting missing information\nand future threat trends. Existing large-scale knowledge graphs mainly focus on\ngeneral classes of entities and relationships between them. Open-source\nknowledge graphs for the security domain do not exist. To fill this gap, we've\nbuilt \\textsf{TINKER} - a knowledge graph for threat intelligence\n(\\textbf{T}hreat \\textbf{IN}telligence \\textbf{K}nowl\\textbf{E}dge\ng\\textbf{R}aph). \\textsf{TINKER} is generated using RDF triples describing\nentities and relations from tokenized unstructured natural language text from\n83 threat reports published between 2006-2021. We built \\textsf{TINKER} using\nclasses and properties defined by open-source malware ontology and using\nhand-annotated RDF triples. We also discuss ongoing research and challenges\nfaced while creating \\textsf{TINKER}.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 17:26:43 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Dutta", "Sharmishtha", ""], ["Rastogi", "Nidhi", ""], ["Yee", "Destin", ""], ["Gu", "Chuqiao", ""], ["Ma", "Qicheng", ""]]}, {"id": "2102.05600", "submitter": "Nidhi Rastogi", "authors": "Nidhi Rastogi, Qicheng Ma", "title": "DANTE: Predicting Insider Threat using LSTM on system logs", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Insider threat is one of the most pernicious threat vectors to information\nand communication technologies (ICT)across the world due to the elevated level\nof trust and access that an insider is afforded. This type of threat can stem\nfrom both malicious users with a motive as well as negligent users who\ninadvertently reveal details about trade secrets, company information, or even\naccess information to malignant players. In this paper, we propose a novel\napproach that uses system logs to detect insider behavior using a special\nrecurrent neural network (RNN) model. Ground truth is established using DANTE\nand used as the baseline for identifying anomalous behavior. For this, system\nlogs are modeled as a natural language sequence and patterns are extracted from\nthese sequences. We create workflows of sequences of actions that follow a\nnatural language logic and control flow. These flows are assigned various\ncategories of behaviors - malignant or benign. Any deviation from these\nsequences indicates the presence of a threat. We further classify threats into\none of the five categories provided in the CERT insider threat dataset. Through\nexperimental evaluation, we show that the proposed model can achieve 99%\nprediction accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 17:56:09 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Rastogi", "Nidhi", ""], ["Ma", "Qicheng", ""]]}, {"id": "2102.05606", "submitter": "Leonardo Bonati", "authors": "Leonardo Bonati, Salvatore D'Oro, Francesco Restuccia, Stefano\n  Basagni, Tommaso Melodia", "title": "SteaLTE: Private 5G Cellular Connectivity as a Service with Full-stack\n  Wireless Steganography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fifth-generation (5G) systems will extensively employ radio access network\n(RAN) softwarization. This key innovation enables the instantiation of \"virtual\ncellular networks\" running on different slices of the shared physical\ninfrastructure. In this paper, we propose the concept of Private Cellular\nConnectivity as a Service (PCCaaS), where infrastructure providers deploy\ncovert network slices known only to a subset of users. We then present SteaLTE\nas the first realization of a PCCaaS-enabling system for cellular networks. At\nits core, SteaLTE utilizes wireless steganography to disguise data as noise to\nadversarial receivers. Differently from previous work, however, it takes a\nfull-stack approach to steganography, contributing an LTE-compliant\nsteganographic protocol stack for PCCaaS-based communications, and packet\nschedulers and operations to embed covert data streams on top of traditional\ncellular traffic (primary traffic). SteaLTE balances undetectability and\nperformance by mimicking channel impairments so that covert data waveforms are\nalmost indistinguishable from noise. We evaluate the performance of SteaLTE on\nan indoor LTE-compliant testbed under different traffic profiles, distance and\nmobility patterns. We further test it on the outdoor PAWR POWDER platform over\nlong-range cellular links. Results show that in most experiments SteaLTE\nimposes little loss of primary traffic throughput in presence of covert data\ntransmissions (< 6%), making it suitable for undetectable PCCaaS networking.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 18:09:30 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Bonati", "Leonardo", ""], ["D'Oro", "Salvatore", ""], ["Restuccia", "Francesco", ""], ["Basagni", "Stefano", ""], ["Melodia", "Tommaso", ""]]}, {"id": "2102.05631", "submitter": "Federico Turrin", "authors": "Mauro Conti and Denis Donadel and Federico Turrin", "title": "A Survey on Industrial Control System Testbeds and Datasets for Security\n  Research", "comments": null, "journal-ref": null, "doi": "10.1109/COMST.2021.3094360", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing digitization and interconnection of legacy Industrial Control\nSystems (ICSs) open new vulnerability surfaces, exposing such systems to\nmalicious attackers. Furthermore, since ICSs are often employed in critical\ninfrastructures (e.g., nuclear plants) and manufacturing companies (e.g.,\nchemical industries), attacks can lead to devastating physical damages. In\ndealing with this security requirement, the research community focuses on\ndeveloping new security mechanisms such as Intrusion Detection Systems (IDSs),\nfacilitated by leveraging modern machine learning techniques. However, these\nalgorithms require a testing platform and a considerable amount of data to be\ntrained and tested accurately. To satisfy this prerequisite, Academia,\nIndustry, and Government are increasingly proposing testbed (i.e., scaled-down\nversions of ICSs or simulations) to test the performances of the IDSs.\nFurthermore, to enable researchers to cross-validate security systems (e.g.,\nsecurity-by-design concepts or anomaly detectors), several datasets have been\ncollected from testbeds and shared with the community. In this paper, we\nprovide a deep and comprehensive overview of ICSs, presenting the architecture\ndesign, the employed devices, and the security protocols implemented. We then\ncollect, compare, and describe testbeds and datasets in the literature,\nhighlighting key challenges and design guidelines to keep in mind in the design\nphases. Furthermore, we enrich our work by reporting the best performing IDS\nalgorithms tested on every dataset to create a baseline in state of the art for\nthis field. Finally, driven by knowledge accumulated during this survey's\ndevelopment, we report advice and good practices on the development, the\nchoice, and the utilization of testbeds, datasets, and IDSs.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 18:45:02 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 09:01:59 GMT"}, {"version": "v3", "created": "Thu, 25 Feb 2021 09:15:27 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Conti", "Mauro", ""], ["Donadel", "Denis", ""], ["Turrin", "Federico", ""]]}, {"id": "2102.05656", "submitter": "Reza Fotohi", "authors": "Hossein Pakdel and Reza Fotohi", "title": "A firefly algorithm for power management in wireless sensor networks\n  (WSNs)", "comments": "7 Figures, 1 Table, J Supercomput (2021)", "journal-ref": null, "doi": "10.1007/s11227-021-03639-1", "report-no": null, "categories": "cs.NI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In wireless sensor networks (WSNs), designing a stable, low-power routing\nprotocol is a major challenge because successive changes in links or breakdowns\ndestabilize the network topology. Therefore, choosing the right route in this\ntype of network due to resource constraints and their operating environment is\none of the most important challenges in these networks. Therefore, the main\npurpose of these networks is to collect appropriate routing information about\nthe environment around the network sensors while observing the energy\nconsumption of the sensors. One of the important approaches to reduce energy\nconsumption in sensor networks is the use of the clustering technique, but in\nmost clustering methods, only the criterion of the amount of energy of the\ncluster or the distance of members to the cluster has been considered.\nTherefore, in this paper, a method is presented using the firefly algorithm and\nusing the four criteria of residual energy, noise rate, number of hops, and\ndistance. The proposed method called EM-FIREFLY is introduced which selects the\nbest cluster head with high attractiveness and based on the fitness function\nand transfers the data packets through these cluster head to the sink. The\nproposed method is evaluated with NS-2 simulator and compared with the\nalgorithm-PSO and optimal clustering methods. The evaluation results show the\nefficiency of the EM-FIREFLY method in maximum relative load and network\nlifetime criteria compared to other methods discussed in this article.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 18:37:55 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Pakdel", "Hossein", ""], ["Fotohi", "Reza", ""]]}, {"id": "2102.05709", "submitter": "Mohsen Ahmadi", "authors": "Mohsen Ahmadi, Pantea Kiaei and Navid Emamdoost", "title": "SN4KE: Practical Mutation Testing at Binary Level", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mutation analysis is an effective technique to evaluate a test suite adequacy\nin terms of revealing unforeseen bugs in software. Traditional source- or\nIR-level mutation analysis is not applicable to the software only available in\nbinary format. This paper proposes a practical binary mutation analysis via\nbinary rewriting, along with a rich set of mutation operators to represent more\nrealistic bugs. We implemented our approach using two state-of-the-art binary\nrewriting tools and evaluated its effectiveness and scalability by applying\nthem to SPEC CPU benchmarks. Our analysis revealed that the richer mutation\noperators contribute to generating more diverse mutants, which, compared to\nprevious works leads to a higher mutation score for the test harness. We also\nconclude that the reassembleable disassembly rewriting yields better\nscalability in comparison to lifting to an intermediate representation and\nperforming a full translation.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 19:28:42 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 08:56:08 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Ahmadi", "Mohsen", ""], ["Kiaei", "Pantea", ""], ["Emamdoost", "Navid", ""]]}, {"id": "2102.05855", "submitter": "Jiayuan Ye", "authors": "Rishav Chourasia, Jiayuan Ye, Reza Shokri", "title": "Differential Privacy Dynamics of Langevin Diffusion and Noisy Gradient\n  Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What is the information leakage of an iterative learning algorithm about its\ntraining data, when the internal state of the algorithm is \\emph{not}\nobservable? How much is the contribution of each specific training epoch to the\nfinal leakage? We study this problem for noisy gradient descent algorithms, and\nmodel the \\emph{dynamics} of R\\'enyi differential privacy loss throughout the\ntraining process. Our analysis traces a provably tight bound on the R\\'enyi\ndivergence between the pair of probability distributions over parameters of\nmodels with neighboring datasets. We prove that the privacy loss converges\nexponentially fast, for smooth and strongly convex loss functions, which is a\nsignificant improvement over composition theorems. For Lipschitz, smooth, and\nstrongly convex loss functions, we prove optimal utility for differential\nprivacy algorithms with a small gradient complexity.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 05:49:37 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 04:18:03 GMT"}, {"version": "v3", "created": "Wed, 21 Jul 2021 16:38:48 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Chourasia", "Rishav", ""], ["Ye", "Jiayuan", ""], ["Shokri", "Reza", ""]]}, {"id": "2102.05867", "submitter": "Vahid Behzadan", "authors": "Pooya Tavallali, Vahid Behzadan, Peyman Tavallali, Mukesh Singhal", "title": "Adversarial Poisoning Attacks and Defense for General Multi-Class Models\n  Based On Synthetic Reduced Nearest Neighbors", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  State-of-the-art machine learning models are vulnerable to data poisoning\nattacks whose purpose is to undermine the integrity of the model. However, the\ncurrent literature on data poisoning attacks is mainly focused on ad hoc\ntechniques that are only applicable to specific machine learning models.\nAdditionally, the existing data poisoning attacks in the literature are limited\nto either binary classifiers or to gradient-based algorithms. To address these\nlimitations, this paper first proposes a novel model-free label-flipping attack\nbased on the multi-modality of the data, in which the adversary targets the\nclusters of classes while constrained by a label-flipping budget. The\ncomplexity of our proposed attack algorithm is linear in time over the size of\nthe dataset. Also, the proposed attack can increase the error up to two times\nfor the same attack budget. Second, a novel defense technique based on the\nSynthetic Reduced Nearest Neighbor (SRNN) model is proposed. The defense\ntechnique can detect and exclude flipped samples on the fly during the training\nprocedure. Through extensive experimental analysis, we demonstrate that (i) the\nproposed attack technique can deteriorate the accuracy of several models\ndrastically, and (ii) under the proposed attack, the proposed defense technique\nsignificantly outperforms other conventional machine learning models in\nrecovering the accuracy of the targeted model.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 06:55:40 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Tavallali", "Pooya", ""], ["Behzadan", "Vahid", ""], ["Tavallali", "Peyman", ""], ["Singhal", "Mukesh", ""]]}, {"id": "2102.05883", "submitter": "Kai-Fung Chu", "authors": "Kai-Fung Chu, Lintao Zhang", "title": "Privacy-Preserving Self-Taught Federated Learning for Heterogeneous Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Many application scenarios call for training a machine learning model among\nmultiple participants. Federated learning (FL) was proposed to enable joint\ntraining of a deep learning model using the local data in each party without\nrevealing the data to others. Among various types of FL methods, vertical FL is\na category to handle data sources with the same ID space and different feature\nspaces. However, existing vertical FL methods suffer from limitations such as\nrestrictive neural network structure, slow training speed, and often lack the\nability to take advantage of data with unmatched IDs. In this work, we propose\nan FL method called self-taught federated learning to address the\naforementioned issues, which uses unsupervised feature extraction techniques\nfor distributed supervised deep learning tasks. In this method, only latent\nvariables are transmitted to other parties for model training, while privacy is\npreserved by storing the data and parameters of activations, weights, and\nbiases locally. Extensive experiments are performed to evaluate and demonstrate\nthe validity and efficiency of the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 08:07:51 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Chu", "Kai-Fung", ""], ["Zhang", "Lintao", ""]]}, {"id": "2102.05888", "submitter": "Michael Schirner", "authors": "Michael Schirner, Lia Domide, Dionysios Perdikis, Paul Triebkorn, Leon\n  Stefanovski, Roopa Pai, Paula Popa, Bogdan Valean, Jessica Palmer, Chlo\\^e\n  Langford, Andr\\'e Blickensd\\\"orfer, Michiel van der Vlag, Sandra Diaz-Pier,\n  Alexander Peyser, Wouter Klijn, Dirk Pleiter, Anne Nahm, Oliver Schmid,\n  Marmaduke Woodman, Lyuba Zehl, Jan Fousek, Spase Petkoski, Lionel Kusch,\n  Meysam Hashemi, Daniele Marinazzo, Jean-Fran\\c{c}ois Mangin, Agnes Fl\\\"oel,\n  Simisola Akintoye, Bernd Carsten Stahl, Michael Cepic, Emily Johnson, Gustavo\n  Deco, Anthony R. McIntosh, Claus C. Hilgetag, Marc Morgan, Bernd Schuller,\n  Alex Upton, Colin McMurtrie, Timo Dickscheid, Jan G. Bjaalie, Katrin Amunts,\n  Jochen Mersmann, Viktor Jirsa, Petra Ritter", "title": "Brain Modelling as a Service: The Virtual Brain on EBRAINS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.CR cs.DC q-bio.NC q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Virtual Brain (TVB) is now available as open-source cloud ecosystem on\nEBRAINS, a shared digital research platform for brain science. It offers\nservices for constructing, simulating and analysing brain network models (BNMs)\nincluding the TVB network simulator; magnetic resonance imaging (MRI)\nprocessing pipelines to extract structural and functional connectomes;\nmultiscale co-simulation of spiking and large-scale networks; a domain specific\nlanguage for automatic high-performance code generation from user-specified\nmodels; simulation-ready BNMs of patients and healthy volunteers; Bayesian\ninference of epilepsy spread; data and code for mouse brain simulation; and\nextensive educational material. TVB cloud services facilitate reproducible\nonline collaboration and discovery of data assets, models, and software\nembedded in scalable and secure workflows, a precondition for research on large\ncohort data sets, better generalizability and clinical translation.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 08:33:50 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 11:22:38 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Schirner", "Michael", ""], ["Domide", "Lia", ""], ["Perdikis", "Dionysios", ""], ["Triebkorn", "Paul", ""], ["Stefanovski", "Leon", ""], ["Pai", "Roopa", ""], ["Popa", "Paula", ""], ["Valean", "Bogdan", ""], ["Palmer", "Jessica", ""], ["Langford", "Chlo\u00ea", ""], ["Blickensd\u00f6rfer", "Andr\u00e9", ""], ["van der Vlag", "Michiel", ""], ["Diaz-Pier", "Sandra", ""], ["Peyser", "Alexander", ""], ["Klijn", "Wouter", ""], ["Pleiter", "Dirk", ""], ["Nahm", "Anne", ""], ["Schmid", "Oliver", ""], ["Woodman", "Marmaduke", ""], ["Zehl", "Lyuba", ""], ["Fousek", "Jan", ""], ["Petkoski", "Spase", ""], ["Kusch", "Lionel", ""], ["Hashemi", "Meysam", ""], ["Marinazzo", "Daniele", ""], ["Mangin", "Jean-Fran\u00e7ois", ""], ["Fl\u00f6el", "Agnes", ""], ["Akintoye", "Simisola", ""], ["Stahl", "Bernd Carsten", ""], ["Cepic", "Michael", ""], ["Johnson", "Emily", ""], ["Deco", "Gustavo", ""], ["McIntosh", "Anthony R.", ""], ["Hilgetag", "Claus C.", ""], ["Morgan", "Marc", ""], ["Schuller", "Bernd", ""], ["Upton", "Alex", ""], ["McMurtrie", "Colin", ""], ["Dickscheid", "Timo", ""], ["Bjaalie", "Jan G.", ""], ["Amunts", "Katrin", ""], ["Mersmann", "Jochen", ""], ["Jirsa", "Viktor", ""], ["Ritter", "Petra", ""]]}, {"id": "2102.05889", "submitter": "Andreas Nautsch", "authors": "Andreas Nautsch, Xin Wang, Nicholas Evans, Tomi Kinnunen, Ville\n  Vestman, Massimiliano Todisco, H\\'ector Delgado, Md Sahidullah, Junichi\n  Yamagishi, Kong Aik Lee", "title": "ASVspoof 2019: spoofing countermeasures for the detection of\n  synthesized, converted and replayed speech", "comments": null, "journal-ref": "IEEE Transactions on Biometrics, Behavior, and Identity Science\n  2021", "doi": "10.1109/TBIOM.2021.3059479", "report-no": null, "categories": "eess.AS cs.CR cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ASVspoof initiative was conceived to spearhead research in anti-spoofing\nfor automatic speaker verification (ASV). This paper describes the third in a\nseries of bi-annual challenges: ASVspoof 2019. With the challenge database and\nprotocols being described elsewhere, the focus of this paper is on results and\nthe top performing single and ensemble system submissions from 62 teams, all of\nwhich out-perform the two baseline systems, often by a substantial margin.\nDeeper analyses shows that performance is dominated by specific conditions\ninvolving either specific spoofing attacks or specific acoustic environments.\nWhile fusion is shown to be particularly effective for the logical access\nscenario involving speech synthesis and voice conversion attacks, participants\nlargely struggled to apply fusion successfully for the physical access scenario\ninvolving simulated replay attacks. This is likely the result of a lack of\nsystem complementarity, while oracle fusion experiments show clear potential to\nimprove performance. Furthermore, while results for simulated data are\npromising, experiments with real replay data show a substantial gap, most\nlikely due to the presence of additive noise in the latter. This finding, among\nothers, leads to a number of ideas for further research and directions for\nfuture editions of the ASVspoof challenge.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 08:41:42 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Nautsch", "Andreas", ""], ["Wang", "Xin", ""], ["Evans", "Nicholas", ""], ["Kinnunen", "Tomi", ""], ["Vestman", "Ville", ""], ["Todisco", "Massimiliano", ""], ["Delgado", "H\u00e9ctor", ""], ["Sahidullah", "Md", ""], ["Yamagishi", "Junichi", ""], ["Lee", "Kong Aik", ""]]}, {"id": "2102.05950", "submitter": "Sohail Ahmed Khan", "authors": "Sohail Ahmed Khan, Alessandro Artusi, Hang Dai", "title": "Adversarially robust deepfake media detection using fused convolutional\n  neural network predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deepfakes are synthetically generated images, videos or audios, which\nfraudsters use to manipulate legitimate information. Current deepfake detection\nsystems struggle against unseen data. To address this, we employ three\ndifferent deep Convolutional Neural Network (CNN) models, (1) VGG16, (2)\nInceptionV3, and (3) XceptionNet to classify fake and real images extracted\nfrom videos. We also constructed a fusion of the deep CNN models to improve the\nrobustness and generalisation capability. The proposed technique outperforms\nstate-of-the-art models with 96.5% accuracy, when tested on publicly available\nDeepFake Detection Challenge (DFDC) test data, comprising of 400 videos. The\nfusion model achieves 99% accuracy on lower quality DeepFake-TIMIT dataset\nvideos and 91.88% on higher quality DeepFake-TIMIT videos. In addition to this,\nwe prove that prediction fusion is more robust against adversarial attacks. If\none model is compromised by an adversarial attack, the prediction fusion does\nnot let it affect the overall classification.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 11:28:00 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Khan", "Sohail Ahmed", ""], ["Artusi", "Alessandro", ""], ["Dai", "Hang", ""]]}, {"id": "2102.05981", "submitter": "Abdullah Giray Ya\\u{g}l{\\i}k\\c{c}{\\i}", "authors": "Abdullah Giray Ya\\u{g}l{\\i}k\\c{c}{\\i}, Minesh Patel, Jeremie S. Kim,\n  Roknoddin Azizi, Ataberk Olgun, Lois Orosa, Hasan Hassan, Jisung Park,\n  Konstantinos Kanellopoulos, Taha Shahroodi, Saugata Ghose, Onur Mutlu", "title": "BlockHammer: Preventing RowHammer at Low Cost by Blacklisting\n  Rapidly-Accessed DRAM Rows", "comments": "A shorter version of this work is to appear at the 27th IEEE\n  International Symposium on High-Performance Computer Architecture (HPCA-27),\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Aggressive memory density scaling causes modern DRAM devices to suffer from\nRowHammer, a phenomenon where rapidly activating a DRAM row can cause bit-flips\nin physically-nearby rows. Recent studies demonstrate that modern DRAM chips,\nincluding chips previously marketed as RowHammer-safe, are even more vulnerable\nto RowHammer than older chips. Many works show that attackers can exploit\nRowHammer bit-flips to reliably mount system-level attacks to escalate\nprivilege and leak private data. Therefore, it is critical to ensure\nRowHammer-safe operation on all DRAM-based systems. Unfortunately,\nstate-of-the-art RowHammer mitigation mechanisms face two major challenges.\nFirst, they incur increasingly higher performance and/or area overheads when\napplied to more vulnerable DRAM chips. Second, they require either proprietary\ninformation about or modifications to the DRAM chip design. In this paper, we\nshow that it is possible to efficiently and scalably prevent RowHammer\nbit-flips without knowledge of or modification to DRAM internals. We introduce\nBlockHammer, a low-cost, effective, and easy-to-adopt RowHammer mitigation\nmechanism that overcomes the two key challenges by selectively throttling\nmemory accesses that could otherwise cause RowHammer bit-flips. The key idea of\nBlockHammer is to (1) track row activation rates using area-efficient Bloom\nfilters and (2) use the tracking data to ensure that no row is ever activated\nrapidly enough to induce RowHammer bit-flips. By doing so, BlockHammer (1)\nmakes it impossible for a RowHammer bit-flip to occur and (2) greatly reduces a\nRowHammer attack's impact on the performance of co-running benign applications.\nCompared to state-of-the-art RowHammer mitigation mechanisms, BlockHammer\nprovides competitive performance and energy when the system is not under a\nRowHammer attack and significantly better performance and energy when the\nsystem is under attack.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 12:56:45 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Ya\u011fl\u0131k\u00e7\u0131", "Abdullah Giray", ""], ["Patel", "Minesh", ""], ["Kim", "Jeremie S.", ""], ["Azizi", "Roknoddin", ""], ["Olgun", "Ataberk", ""], ["Orosa", "Lois", ""], ["Hassan", "Hasan", ""], ["Park", "Jisung", ""], ["Kanellopoulos", "Konstantinos", ""], ["Shahroodi", "Taha", ""], ["Ghose", "Saugata", ""], ["Mutlu", "Onur", ""]]}, {"id": "2102.06020", "submitter": "Chuan Guo", "authors": "Ruihan Wu, Chuan Guo, Felix Wu, Rahul Kidambi, Laurens van der Maaten,\n  Kilian Q. Weinberger", "title": "Making Paper Reviewing Robust to Bid Manipulation Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most computer science conferences rely on paper bidding to assign reviewers\nto papers. Although paper bidding enables high-quality assignments in days of\nunprecedented submission numbers, it also opens the door for dishonest\nreviewers to adversarially influence paper reviewing assignments. Anecdotal\nevidence suggests that some reviewers bid on papers by \"friends\" or colluding\nauthors, even though these papers are outside their area of expertise, and\nrecommend them for acceptance without considering the merit of the work. In\nthis paper, we study the efficacy of such bid manipulation attacks and find\nthat, indeed, they can jeopardize the integrity of the review process. We\ndevelop a novel approach for paper bidding and assignment that is much more\nrobust against such attacks. We show empirically that our approach provides\nrobustness even when dishonest reviewers collude, have full knowledge of the\nassignment system's internal workings, and have access to the system's inputs.\nIn addition to being more robust, the quality of our paper review assignments\nis comparable to that of current, non-robust assignment approaches.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 21:24:16 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 17:07:04 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Wu", "Ruihan", ""], ["Guo", "Chuan", ""], ["Wu", "Felix", ""], ["Kidambi", "Rahul", ""], ["van der Maaten", "Laurens", ""], ["Weinberger", "Kilian Q.", ""]]}, {"id": "2102.06028", "submitter": "Shoma Matsui", "authors": "Shoma Matsui and St\\'ephane Lafortune", "title": "Synthesis of Winning Attacks on Communication Protocols using\n  Supervisory Control Theory: Two Case Studies", "comments": "29 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increasing need to study the vulnerability of communication\nprotocols in distributed systems to malicious attacks that attempt to violate\nproperties such as safety or liveness. In this paper, we propose a common\nmethodology for formal synthesis of successful attacks against two well-known\nprotocols, the Alternating Bit Protocol (ABP) and the Transmission Control\nProtocol (TCP), where the attacker can always eventually win, called For-all\nattacks. This generalizes previous work on the synthesis of There-exists\nattacks for TCP, where the attacker can sometimes win. We model the ABP and TCP\nprotocols and system architecture by finite-state automata and employ the\nsupervisory control theory of discrete event systems to pose and solve the\nsynthesis of For-all attacks, where the attacker has partial observability and\ncontrollability of the system events. We consider several scenarios of\nperson-in-themiddle attacks against ABP and TCP and present the results of\nattack synthesis using our methodology for each case.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 22:47:13 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 23:34:54 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Matsui", "Shoma", ""], ["Lafortune", "St\u00e9phane", ""]]}, {"id": "2102.06182", "submitter": "Seunghoon Woo", "authors": "Seunghoon Woo, Sunghan Park, Seulbae Kim, Heejo Lee, Hakjoo Oh", "title": "CENTRIS: A Precise and Scalable Approach for Identifying Modified\n  Open-Source Software Reuse", "comments": "To appear in the 43rd International Conference on Software\n  Engineering (ICSE 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Open-source software (OSS) is widely reused as it provides convenience and\nefficiency in software development. Despite evident benefits, unmanaged OSS\ncomponents can introduce threats, such as vulnerability propagation and license\nviolation. Unfortunately, however, identifying reused OSS components is a\nchallenge as the reused OSS is predominantly modified and nested. In this\npaper, we propose CENTRIS, a precise and scalable approach for identifying\nmodified OSS reuse. By segmenting an OSS code base and detecting the reuse of a\nunique part of the OSS only, CENTRIS is capable of precisely identifying\nmodified OSS reuse in the presence of nested OSS components. For scalability,\nCENTRIS eliminates redundant code comparisons and accelerates the search using\nhash functions. When we applied CENTRIS on 10,241 widely-employed GitHub\nprojects, comprising 229,326 versions and 80 billion lines of code, we observed\nthat modified OSS reuse is a norm in software development, occurring 20 times\nmore frequently than exact reuse. Nonetheless, CENTRIS identified reused OSS\ncomponents with 91% precision and 94% recall in less than a minute per\napplication on average, whereas a recent clone detection technique, which does\nnot take into account modified and nested OSS reuse, hardly reached 10%\nprecision and 40% recall.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 18:48:26 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Woo", "Seunghoon", ""], ["Park", "Sunghan", ""], ["Kim", "Seulbae", ""], ["Lee", "Heejo", ""], ["Oh", "Hakjoo", ""]]}, {"id": "2102.06202", "submitter": "Anastasios Angelopoulos", "authors": "Anastasios N. Angelopoulos and Stephen Bates and Tijana Zrnic and\n  Michael I. Jordan", "title": "Private Prediction Sets", "comments": "Code available at\n  https://github.com/aangelopoulos/private_prediction_sets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world settings involving consequential decision-making, the\ndeployment of machine learning systems generally requires both reliable\nuncertainty quantification and protection of individuals' privacy. We present a\nframework that treats these two desiderata jointly. Our framework is based on\nconformal prediction, a methodology that augments predictive models to return\nprediction sets that provide uncertainty quantification -- they provably cover\nthe true response with a user-specified probability, such as 90%. One might\nhope that when used with privately-trained models, conformal prediction would\nyield privacy guarantees for the resulting prediction sets; unfortunately this\nis not the case. To remedy this key problem, we develop a method that takes any\npre-trained predictive model and outputs differentially private prediction\nsets. Our method follows the general approach of split conformal prediction; we\nuse holdout data to calibrate the size of the prediction sets but preserve\nprivacy by using a privatized quantile subroutine. This subroutine compensates\nfor the noise introduced to preserve privacy in order to guarantee correct\ncoverage. We evaluate the method with experiments on the CIFAR-10, ImageNet,\nand CoronaHack datasets.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 18:59:11 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Angelopoulos", "Anastasios N.", ""], ["Bates", "Stephen", ""], ["Zrnic", "Tijana", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2102.06238", "submitter": "Francesco Regazzoni", "authors": "Francesco Regazzoni, Emna Amri, Samuel Burri, Davide Rusca, Hugo\n  Zbinden, Edoardo Charbon", "title": "A High Speed Integrated Quantum Random Number Generator with on-Chip\n  Real-Time Randomness Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The security of electronic devices has become a key requisite for the\nrapidly-expanding pervasive and hyper-connected world. Robust security\nprotocols ensuring secure communication, device's resilience to attacks,\nauthentication control and users privacy need to be implemented. Random Number\nGenerators (RNGs) are the fundamental primitive in most secure protocols but,\noften, also the weakest one. Establishing security in billions of devices\nrequires high quality random data generated at a sufficiently high throughput.\nOn the other hand, the RNG should exhibit a high integration level with on-chip\nextraction to remove, in real time, potential imperfections. We present the\nfirst integrated Quantum RNG (QRNG) in a standard CMOS technology node. The\nQRNG is based on a parallel array of independent Single-Photon Avalanche Diodes\n(SPADs), homogeneously illuminated by a DC-biased LED, and co-integrated logic\ncircuits for postprocessing. We describe the randomness generation process and\nwe prove the quantum origin of entropy. We show that co-integration of\ncombinational logic, even of high complexity, does not affect the quality of\nrandomness. Our CMOS QRNG can reach up to 400 Mbit/s throughput with low power\nconsumption. Thanks to the use of standard CMOS technology and a modular\narchitecture, our QRNG is suitable for a highly scalable solution.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 19:55:29 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Regazzoni", "Francesco", ""], ["Amri", "Emna", ""], ["Burri", "Samuel", ""], ["Rusca", "Davide", ""], ["Zbinden", "Hugo", ""], ["Charbon", "Edoardo", ""]]}, {"id": "2102.06249", "submitter": "Harun Oz", "authors": "Harun Oz, Ahmet Aris, Albert Levi, A. Selcuk Uluagac", "title": "A Survey on Ransomware: Evolution, Taxonomy, and Defense Solutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, ransomware has been one of the most notorious malware\ntargeting end users, governments, and business organizations. It has become a\nvery profitable business for cybercriminals with revenues of millions of\ndollars, and a very serious threat to organizations with financial loss of\nbillions of dollars. Numerous studies were proposed to address the ransomware\nthreat, including surveys that cover certain aspects of ransomware research.\nHowever, no study exists in the literature that gives the complete picture on\nransomware and ransomware defense research with respect to the diversity of\ntargeted platforms. Since ransomware is already prevalent in\nPCs/workstations/desktops/laptops, is becoming more prevalent in mobile\ndevices, and has already hit IoT/CPS recently, and will likely grow further in\nthe IoT/CPS domain very soon, understanding ransomware and analyzing defense\nmechanisms with respect to target platforms is becoming more imperative. In\norder to fill this gap and motivate further research, in this paper, we present\na comprehensive survey on ransomware and ransomware defense research with\nrespect to PCs/workstations, mobile devices, and IoT/CPS platforms.\nSpecifically, covering 137 studies over the period of 1990-2020, we give a\ndetailed overview of ransomware evolution, comprehensively analyze the key\nbuilding blocks of ransomware, present a taxonomy of notable ransomware\nfamilies, and provide an extensive overview of ransomware defense research\n(i.e., analysis, detection, and recovery) with respect to platforms of\nPCs/workstations, mobile devices, and IoT/CPS. Moreover, we derive an extensive\nlist of open issues for future ransomware research. We believe this survey will\nmotivate further research by giving a complete picture on state-of-the-art\nransomware research.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 20:21:32 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Oz", "Harun", ""], ["Aris", "Ahmet", ""], ["Levi", "Albert", ""], ["Uluagac", "A. Selcuk", ""]]}, {"id": "2102.06254", "submitter": "Ahmed Raoof", "authors": "Ahmed Raoof, Chung-Horng Lung, Ashraf Matrawy", "title": "Securing RPL using Network Coding: The Chained Secure Mode (CSM)", "comments": "10 pages, 20 figures, 2 tables, Submitted to IEEE IoT Journal for\n  review. This is an significantly extended version of arXiv:2006.00310 which\n  was published in NCA 2020 (available at IEEExplore)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the de facto routing protocol for many Internet of Things (IoT) networks\nnowadays, and to assure the confidentiality and integrity of its control\nmessages, the Routing Protocol for Low Power and Lossy Networks (RPL)\nincorporates three modes of security: the Unsecured Mode (UM), Preinstalled\nSecure Mode (PSM), and the Authenticated Secure Mode (ASM). While the PSM and\nASM are intended to protect against external routing attacks and some replay\nattacks (through an optional replay protection mechanism), recent research\nshowed that RPL in PSM is still vulnerable to many routing attacks, both\ninternal and external. In this paper, we propose a novel secure mode for RPL,\nthe Chained Secure Mode (CSM), based on the concept of intraflow Network Coding\n(NC). The CSM is designed to enhance RPL resilience and mitigation capability\nagainst replay attacks while allowing the integration with external security\nmeasures such as Intrusion Detection Systems (IDSs). The security and\nperformance of the proposed CSM were evaluated and compared against RPL in UM\nand PSM (with and without the optional replay protection) under several routing\nattacks: the Neighbor attack (NA), Wormhole (WH), and CloneID attack (CA),\nusing average packet delivery rate (PDR), End-to-End (E2E) latency, and power\nconsumption as metrics. It showed that CSM has better performance and more\nenhanced security than both the UM and PSM with the replay protection, while\nmitigating both the NA and WH attacks and significantly reducing the effect of\nthe CA in the investigated scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 20:29:22 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Raoof", "Ahmed", ""], ["Lung", "Chung-Horng", ""], ["Matrawy", "Ashraf", ""]]}, {"id": "2102.06301", "submitter": "Aadesh Bagmar", "authors": "Aadesh Bagmar, Josiah Wedgwood, Dave Levin, Jim Purtilo", "title": "I Know What You Imported Last Summer: A study of security threats in\n  thePython ecosystem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The popularity of Python has risen rapidly over the past 15 years. It is a\nmajor language in some of the most exciting technologies today. This popularity\nhas led to a large ecosystem of third-party packages available via the pip\npackage registry which hosts more than 200,000 packages. These third-party\npackages can be reused by simply importing the package after installing using\npackage managers like pip. The ease of reuse of third-party software comes with\nsecurity risks putting millions of users in danger. In this project, we study\nthe ecosystem to analyze this threat. The mature ecosystem of Python has\nmultiple weak spots that we highlight in our project. First, we demonstrate how\ntrivial it is to exploit the Python ecosystem. Then, we systematically analyze\ndependencies amongst packages, maintainers, and publicly reported security\nissues. Most attacks are possible only if users install malicious packages. We\nthus try to analyze and evaluate different methods used by attackers to force\nincorrect downloads. We quantify your ideas by estimating the potential threat\nthat can be caused by exploiting a popular Python package. We also discuss\nmethods used in the industry to defend against such attacks\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 22:46:17 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Bagmar", "Aadesh", ""], ["Wedgwood", "Josiah", ""], ["Levin", "Dave", ""], ["Purtilo", "Jim", ""]]}, {"id": "2102.06344", "submitter": "Stephen D. Miller", "authors": "Tamar Lichter Blanks and Stephen D. Miller", "title": "Generating cryptographically-strong random lattice bases and recognizing\n  rotations of $\\mathbb{Z}^n$", "comments": "20 pages, 2 figures, to appear in PQCrypto 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.GR math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lattice-based cryptography relies on generating random bases which are\ndifficult to fully reduce. Given a lattice basis (such as the private basis for\na cryptosystem), all other bases are related by multiplication by matrices in\n$GL(n,\\mathbb{Z})$. We compare the strengths of various methods to sample\nrandom elements of $GL(n,\\mathbb{Z})$, finding some are stronger than others\nwith respect to the problem of recognizing rotations of the $\\mathbb{Z}^n$\nlattice. In particular, the standard algorithm of multiplying unipotent\ngenerators together (as implemented in Magma's RandomSLnZ command) generates\ninstances of this last problem which can be efficiently broken, even in\ndimensions nearing 1,500. Likewise, we find that the random basis generation\nmethod in one of the NIST Post-Quantum Cryptography competition submissions\n(DRS) generates instances which can be efficiently broken, even at its 256-bit\nsecurity settings. Other random basis generation algorithms (some older, some\nnewer) are described which appear to be much stronger.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 04:10:53 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 14:25:09 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Blanks", "Tamar Lichter", ""], ["Miller", "Stephen D.", ""]]}, {"id": "2102.06362", "submitter": "Wenjing Chu", "authors": "Wenjing Chu", "title": "A Decentralized Approach Towards Responsible AI in Social Ecosystems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For AI technology to fulfill its full promises, we must design effective\nmechanisms into the AI systems to support responsible AI behavior and curtail\npotential irresponsible use, e.g. in areas of privacy protection, human\nautonomy, robustness, and prevention of biases and discrimination in automated\ndecision making. In this paper, we present a framework that provides\ncomputational facilities for parties in a social ecosystem to produce the\ndesired responsible AI behaviors. To achieve this goal, we analyze AI systems\nat the architecture level and propose two decentralized cryptographic\nmechanisms for an AI system architecture: (1) using Autonomous Identity to\nempower human users, and (2) automating rules and adopting conventions within\nsocial institutions. We then propose a decentralized approach and outline the\nkey concepts and mechanisms based on Decentralized Identifier (DID) and\nVerifiable Credentials (VC) for a general-purpose computational infrastructure\nto realize these mechanisms. We argue the case that a decentralized approach is\nthe most promising path towards Responsible AI from both the computer science\nand social science perspectives.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 06:33:42 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Chu", "Wenjing", ""]]}, {"id": "2102.06511", "submitter": "Sai Vishwanath Venkatesh", "authors": "Sai Vishwanath Venkatesh, Prasanna D. Kumaran, Joish J Bosco, Pravin\n  R. Kumaar, Vineeth Vijayaraghavan", "title": "A Non-Intrusive Machine Learning Solution for Malware Detection and Data\n  Theft Classification in Smartphones", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Smartphones contain information that is more sensitive and personal than\nthose found on computers and laptops. With an increase in the versatility of\nsmartphone functionality, more data has become vulnerable and exposed to\nattackers. Successful mobile malware attacks could steal a user's location,\nphotos, or even banking information. Due to a lack of post-attack strategies\nfirms also risk going out of business due to data theft. Thus, there is a need\nbesides just detecting malware intrusion in smartphones but to also identify\nthe data that has been stolen to assess, aid in recovery and prevent future\nattacks. In this paper, we propose an accessible, non-intrusive machine\nlearning solution to not only detect malware intrusion but also identify the\ntype of data stolen for any app under supervision. We do this with Android\nusage data obtained by utilising publicly available data collection framework-\nSherLock. We test the performance of our architecture for multiple users on\nreal-world data collected using the same framework. Our architecture exhibits\nless than 9% inaccuracy in detecting malware and can classify with 83%\ncertainty on the type of data that is being stolen.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 13:31:27 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Venkatesh", "Sai Vishwanath", ""], ["Kumaran", "Prasanna D.", ""], ["Bosco", "Joish J", ""], ["Kumaar", "Pravin R.", ""], ["Vijayaraghavan", "Vineeth", ""]]}, {"id": "2102.06580", "submitter": "Emilio Coppa", "authors": "Luca Borzacchiello, Emilio Coppa, Camil Demetrescu", "title": "Fuzzing Symbolic Expressions", "comments": null, "journal-ref": "Proceedings of the 43rd International Conference on Software\n  Engineering (ICSE 2021)", "doi": "10.1109/ICSE43902.2021.00071", "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed a wide array of results in software testing,\nexploring different approaches and methodologies ranging from fuzzers to\nsymbolic engines, with a full spectrum of instances in between such as concolic\nexecution and hybrid fuzzing. A key ingredient of many of these tools is\nSatisfiability Modulo Theories (SMT) solvers, which are used to reason over\nsymbolic expressions collected during the analysis. In this paper, we\ninvestigate whether techniques borrowed from the fuzzing domain can be applied\nto check whether symbolic formulas are satisfiable in the context of concolic\nand hybrid fuzzing engines, providing a viable alternative to classic SMT\nsolving techniques. We devise a new approximate solver, FUZZY-SAT, and show\nthat it is both competitive with and complementary to state-of-the-art solvers\nsuch as Z3 with respect to handling queries generated by hybrid fuzzers.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 15:42:36 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Borzacchiello", "Luca", ""], ["Coppa", "Emilio", ""], ["Demetrescu", "Camil", ""]]}, {"id": "2102.06632", "submitter": "Pascal Debus", "authors": "Pascal Debus, Nicolas M\\\"uller, Konstantin B\\\"ottinger", "title": "Deep Reinforcement Learning for Backup Strategies against Adversaries", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many defensive measures in cyber security are still dominated by heuristics,\ncatalogs of standard procedures, and best practices. Considering the case of\ndata backup strategies, we aim towards mathematically modeling the underlying\nthreat models and decision problems. By formulating backup strategies in the\nlanguage of stochastic processes, we can translate the challenge of finding\noptimal defenses into a reinforcement learning problem. This enables us to\ntrain autonomous agents that learn to optimally support planning of defense\nprocesses. In particular, we tackle the problem of finding an optimal backup\nscheme in the following adversarial setting: Given $k$ backup devices, the goal\nis to defend against an attacker who can infect data at one time but chooses to\ndestroy or encrypt it at a later time, potentially also corrupting multiple\nbackups made in between. In this setting, the usual round-robin scheme, which\nalways replaces the oldest backup, is no longer optimal with respect to\navoidable exposure. Thus, to find a defense strategy, we model the problem as a\nhybrid discrete-continuous action space Markov decision process and\nsubsequently solve it using deep deterministic policy gradients. We show that\nthe proposed algorithm can find storage device update schemes which match or\nexceed existing schemes with respect to various exposure metrics.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 17:19:44 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Debus", "Pascal", ""], ["M\u00fcller", "Nicolas", ""], ["B\u00f6ttinger", "Konstantin", ""]]}, {"id": "2102.06638", "submitter": "Francesco Betti Sorbelli", "authors": "Francesco Betti Sorbelli, Mauro Conti, Cristina M. Pinotti, Giulio\n  Rigoni", "title": "UAVs Path Deviation Attacks: Survey and Research Challenges", "comments": "Published in: 2020 IEEE International Conference on Sensing,\n  Communication and Networking (SECON Workshops)", "journal-ref": null, "doi": "10.1109/SECONWorkshops50264.2020.9149780", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, Unmanned Aerial Vehicles (UAVs) are employed for a plethora of\ncivilian applications. Such flying vehicles can accomplish tasks under the\npilot's eyesight within the range of a remote controller, or autonomously\naccording to a certain pre-loaded path configuration. Different path deviation\nattacks can be performed by malicious users against UAVs. We classify such\nattacks and the relative defenses based on the UAV's flight mode, i.e., (i)\nFirst Person View (FPV), (ii) civilian Global Navigation Satellite System based\n(GNSS), and (iii) GNSS \"plus\" auxiliary technologies (GNSS+), and on the\nmultiplicity, i.e., (i) Single UAV, and (ii) Multiple UAVs. We found that very\nlittle has been done to secure the FPV flight mode against path deviation. In\nGNSS mode, spoofing is the most worrisome attack. The best defense against\nspoofing seems to be redundancy, such as adding vision chips to single UAV or\nusing multiple arranged UAVs. No specific attacks and defenses have been found\nin literature for GNSS+ or for UAVs moving in group without a pre-ordered\narrangement. These aspects require further investigation.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 17:26:15 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Sorbelli", "Francesco Betti", ""], ["Conti", "Mauro", ""], ["Pinotti", "Cristina M.", ""], ["Rigoni", "Giulio", ""]]}, {"id": "2102.06747", "submitter": "Raphael Labaca-Castro", "authors": "Raphael Labaca-Castro, Luis Mu\\~noz-Gonz\\'alez, Feargus Pendlebury,\n  Gabi Dreo Rodosek, Fabio Pierazzi, Lorenzo Cavallaro", "title": "Universal Adversarial Perturbations for Malware", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine learning classification models are vulnerable to adversarial examples\n-- effective input-specific perturbations that can manipulate the model's\noutput. Universal Adversarial Perturbations (UAPs), which identify noisy\npatterns that generalize across the input space, allow the attacker to greatly\nscale up the generation of these adversarial examples. Although UAPs have been\nexplored in application domains beyond computer vision, little is known about\ntheir properties and implications in the specific context of realizable\nattacks, such as malware, where attackers must reason about satisfying\nchallenging problem-space constraints.\n  In this paper, we explore the challenges and strengths of UAPs in the context\nof malware classification. We generate sequences of problem-space\ntransformations that induce UAPs in the corresponding feature-space embedding\nand evaluate their effectiveness across threat models that consider a varying\ndegree of realistic attacker knowledge. Additionally, we propose adversarial\ntraining-based mitigations using knowledge derived from the problem-space\ntransformations, and compare against alternative feature-space defenses. Our\nexperiments limit the effectiveness of a white box Android evasion attack to\n~20 % at the cost of 3 % TPR at 1 % FPR. We additionally show how our method\ncan be adapted to more restrictive application domains such as Windows malware.\n  We observe that while adversarial training in the feature space must deal\nwith large and often unconstrained regions, UAPs in the problem space identify\nspecific vulnerabilities that allow us to harden a classifier more effectively,\nshifting the challenges and associated cost of identifying new universal\nadversarial transformations back to the attacker.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 20:06:10 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Labaca-Castro", "Raphael", ""], ["Mu\u00f1oz-Gonz\u00e1lez", "Luis", ""], ["Pendlebury", "Feargus", ""], ["Rodosek", "Gabi Dreo", ""], ["Pierazzi", "Fabio", ""], ["Cavallaro", "Lorenzo", ""]]}, {"id": "2102.06774", "submitter": "Hanieh Rafiee", "authors": "Haniyeh Rafiee and Mohammad Fakhredanesh", "title": "Presenting a Method for Improving Echo Hiding", "comments": "14 page, This paper is printed in Journal of Computer and Knowledge\n  Engineering, Vol. 2, No. 1", "journal-ref": null, "doi": "10.22067/CKE.V2I1.74388", "report-no": null, "categories": "cs.CR cs.MM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this article, one of the most important methods of steganography on VoIP\ncalled echo hiding is improved. This method has advantages in maintaining the\nstatistical and perceptual characteristics of audio signals as well as security\nagainst the sensitivity of the human audio system (HAS). However, it has lots\nof errors in detecting coded and hidden messages, which is detectable using\nexisting steganalysis methods. The percentage of extracting messages in these\nimproved methods of echo hiding is high, but they lower the security of the\nmethod. In this article, a method is presented to improve the method of\nextracting echo hiding, and enhance its security through a combined method\nbased on spread spectrum. To improve the extraction, a wrong hypothesis is\ncorrected and substituted. To improve security using a pseudo-random key\ngeneration algorithm, spread spectrum and echo hiding methods are used\nrandomly. To evaluate the proposed extraction, numerous extraction tests are\ncarried out in the normal state and in the event of attacks. A steganalyser has\nalso been used to assess security improvements. The results gained through\ndifferent experiments on the security of steganography indicate a 3-percent\nincrease in steganalysis errors. The proposed extraction method was modified\nbased on the main method and resulted in more than 10% improvement.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 21:09:36 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Rafiee", "Haniyeh", ""], ["Fakhredanesh", "Mohammad", ""]]}, {"id": "2102.06792", "submitter": "Anselmo Ferreira", "authors": "Anselmo Ferreira, Ehsan Nowroozi and Mauro Barni", "title": "VIPPrint: A Large Scale Dataset of Printed and Scanned Images for\n  Synthetic Face Images Detection and Source Linking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The possibility of carrying out a meaningful forensics analysis on printed\nand scanned images plays a major role in many applications. First of all,\nprinted documents are often associated with criminal activities, such as\nterrorist plans, child pornography pictures, and even fake packages.\nAdditionally, printing and scanning can be used to hide the traces of image\nmanipulation or the synthetic nature of images, since the artifacts commonly\nfound in manipulated and synthetic images are gone after the images are printed\nand scanned. A problem hindering research in this area is the lack of large\nscale reference datasets to be used for algorithm development and benchmarking.\nMotivated by this issue, we present a new dataset composed of a large number of\nsynthetic and natural printed face images. To highlight the difficulties\nassociated with the analysis of the images of the dataset, we carried out an\nextensive set of experiments comparing several printer attribution methods. We\nalso verified that state-of-the-art methods to distinguish natural and\nsynthetic face images fail when applied to print and scanned images. We\nenvision that the availability of the new dataset and the preliminary\nexperiments we carried out will motivate and facilitate further research in\nthis area.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 13:00:29 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Ferreira", "Anselmo", ""], ["Nowroozi", "Ehsan", ""], ["Barni", "Mauro", ""]]}, {"id": "2102.06800", "submitter": "Jacob Dineen", "authors": "Jacob Dineen, A S M Ahsan-Ul Haque, Matthew Bielskas", "title": "Reinforcement Learning For Data Poisoning on Graph Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-80387-2_14", "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Adversarial Machine Learning has emerged as a substantial subfield of\nComputer Science due to a lack of robustness in the models we train along with\ncrowdsourcing practices that enable attackers to tamper with data. In the last\ntwo years, interest has surged in adversarial attacks on graphs yet the Graph\nClassification setting remains nearly untouched. Since a Graph Classification\ndataset consists of discrete graphs with class labels, related work has forgone\ndirect gradient optimization in favor of an indirect Reinforcement Learning\napproach. We will study the novel problem of Data Poisoning (training time)\nattack on Neural Networks for Graph Classification using Reinforcement Learning\nAgents.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 22:34:53 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Dineen", "Jacob", ""], ["Haque", "A S M Ahsan-Ul", ""], ["Bielskas", "Matthew", ""]]}, {"id": "2102.06826", "submitter": "Hanzhou Wu", "authors": "Hanzhou Wu, Gen Liu and Xinpeng Zhang", "title": "Hiding Data Hiding", "comments": "https://hzwu.github.io", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data hiding is referred to as the art of hiding secret data into a digital\ncover for covert communication. In this letter, we propose a novel method to\ndisguise data hiding tools, including a data embedding tool and a data\nextraction tool, as a deep neural network (DNN) with an ordinary task. After\ntraining a DNN for both style transfer and data hiding, while the DNN can\ntransfer the style of an image to a target one, it can be also used to hide\nsecret data into a cover image or extract secret data from a stego image by\ninputting the trigger signal. In other words, the tools of data hiding are\nhidden to avoid arousing suspicion.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 00:23:58 GMT"}, {"version": "v2", "created": "Sat, 3 Apr 2021 06:39:04 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Wu", "Hanzhou", ""], ["Liu", "Gen", ""], ["Zhang", "Xinpeng", ""]]}, {"id": "2102.06829", "submitter": "Amit Seal Ami", "authors": "Amit Seal Ami, Kaushal Kafle, Kevin Moran, Adwait Nadkarni and Denys\n  Poshyvanyk", "title": "Systematic Mutation-based Evaluation of the Soundness of\n  Security-focused Android Static Analysis Techniques", "comments": "Published in ACM Transactions on Privacy and Security, extends\n  USENIX'18 paper (arXiv:1806.09761)", "journal-ref": "ACM Transactions on Privacy and Security, Volume 24, Issue 3,\n  Article No. 15, 2021", "doi": "10.1145/3439802", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile application security has been a major area of focus for security\nresearch over the course of the last decade. Numerous application analysis\ntools have been proposed in response to malicious, curious, or vulnerable apps.\nHowever, existing tools, and specifically, static analysis tools, trade\nsoundness of the analysis for precision and performance and are hence soundy.\nUnfortunately, the specific unsound choices or flaws in the design of these\ntools is often not known or well-documented, leading to misplaced confidence\namong researchers, developers, and users. This paper describes the\nMutation-based Soundness Evaluation ($\\mu$SE) framework, which systematically\nevaluates Android static analysis tools to discover, document, and fix flaws,\nby leveraging the well-founded practice of mutation analysis. We implemented\n$\\mu$SE and applied it to a set of prominent Android static analysis tools that\ndetect private data leaks in apps. In a study conducted previously, we used\n$\\mu$SE to discover $13$ previously undocumented flaws in FlowDroid, one of the\nmost prominent data leak detectors for Android apps. Moreover, we discovered\nthat flaws also propagated to other tools that build upon the design or\nimplementation of FlowDroid or its components. This paper substantially extends\nour $\\mu$SE framework and offers an new in-depth analysis of two more major\ntools in our 2020 study, we find $12$ new, undocumented flaws and demonstrate\nthat all $25$ flaws are found in more than one tool, regardless of any\ninheritance-relation among the tools. Our results motivate the need for\nsystematic discovery and documentation of unsound choices in soundy tools and\ndemonstrate the opportunities in leveraging mutation testing in achieving this\ngoal.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 00:33:40 GMT"}, {"version": "v2", "created": "Sat, 17 Jul 2021 17:54:28 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Ami", "Amit Seal", ""], ["Kafle", "Kaushal", ""], ["Moran", "Kevin", ""], ["Nadkarni", "Adwait", ""], ["Poshyvanyk", "Denys", ""]]}, {"id": "2102.06846", "submitter": "Chia-Wei Tsai", "authors": "Chia-Wei Tsai, Chun-Wei Yang, and Jason Lin", "title": "Multiparty Mediated Semi-Quantum Secret Sharing Protocol", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes the first multiparty mediated semi-quantum secret sharing\n(MSQSS) protocol to overcome two existing challenges in current semi-quantum\nsecret sharing protocols: (1) dealer must be the quantum user, and (2)\nclassical users must be equipped with Trojan horse detectors. In the proposed\nMSQSS protocol, a classical dealer can share secrets with multiple classical\nagents via the help of a dishonest quantum third party. Security analysis is\nperformed to prove that the proposed protocol cannot suffer from a collective\nattack, a collusion attack, or a Trojan horse attack. Furthermore, the proposed\nMSQSS protocol is more lightweight than existing SQSS protocols because the\nclassical user is equipped with only two quantum capabilities.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 02:09:16 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 06:15:01 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Tsai", "Chia-Wei", ""], ["Yang", "Chun-Wei", ""], ["Lin", "Jason", ""]]}, {"id": "2102.06884", "submitter": "Ali Raza", "authors": "Ali Raza, Lachlan Hardy, Erin Roehrer, Soonja Yeom, Byeong ho Kang", "title": "GPSPiChain-Blockchain based Self-Contained Family Security System in\n  Smart Home", "comments": "15 pages, 6 figures, accepted in The 4th International Workshop on\n  Smart Simulation and Modelling for Complex Systems, IJCAI2019", "journal-ref": null, "doi": null, "report-no": "SSMCS2019-13", "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With advancements in technology, personal computing devices are better\nadapted for and further integrated into people's lives and homes. The\nintegration of technology into society also results in an increasing desire to\ncontrol who and what has access to sensitive information, especially for\nvulnerable people including children and the elderly. With blockchain coming in\nto the picture as a technology that can revolutionise the world, it is now\npossible to have an immutable audit trail of locational data over time. By\ncontrolling the process through inexpensive equipment in the home, it is\npossible to control whom has access to such personal data. This paper presents\na blockchain based family security system for tracking the location of\nconsenting family members' smart phones. The locations of the family members'\nsmart phones are logged and stored in a private blockchain which can be\naccessed through a node installed in the family home on a computer. The data\nfor the whereabouts of family members stays within the family unit and does not\ngo to any third party. The system is implemented in a small scale (one miner\nand two other nodes) and the technical feasibility is discussed along with the\nlimitations of the system. Further research will cover the integration of the\nsystem into a smart home environment, and ethical implementations of tracking,\nespecially of vulnerable people, using the immutability of blockchain.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 09:06:19 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Raza", "Ali", ""], ["Hardy", "Lachlan", ""], ["Roehrer", "Erin", ""], ["Yeom", "Soonja", ""], ["Kang", "Byeong ho", ""]]}, {"id": "2102.06905", "submitter": "Laurent Meunier", "authors": "Laurent Meunier, Meyer Scetbon, Rafael Pinot, Jamal Atif, Yann\n  Chevaleyre", "title": "Mixed Nash Equilibria in the Adversarial Examples Game", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper tackles the problem of adversarial examples from a game theoretic\npoint of view. We study the open question of the existence of mixed Nash\nequilibria in the zero-sum game formed by the attacker and the classifier.\nWhile previous works usually allow only one player to use randomized\nstrategies, we show the necessity of considering randomization for both the\nclassifier and the attacker. We demonstrate that this game has no duality gap,\nmeaning that it always admits approximate Nash equilibria. We also provide the\nfirst optimization algorithms to learn a mixture of classifiers that\napproximately realizes the value of this game, \\emph{i.e.} procedures to build\nan optimally robust randomized classifier.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 11:47:20 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Meunier", "Laurent", ""], ["Scetbon", "Meyer", ""], ["Pinot", "Rafael", ""], ["Atif", "Jamal", ""], ["Chevaleyre", "Yann", ""]]}, {"id": "2102.06972", "submitter": "David Barrera", "authors": "William Findlay, David Barrera, Anil Somayaji", "title": "BPFContain: Fixing the Soft Underbelly of Container Security", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.OS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Linux containers currently provide limited isolation guarantees. While\ncontainers separate namespaces and partition resources, the patchwork of\nmechanisms used to ensure separation cannot guarantee consistent security\nsemantics. Even worse, attempts to ensure complete coverage results in a\nmishmash of policies that are difficult to understand or audit. Here we present\nBPFContain, a new container confinement mechanism designed to integrate with\nexisting container management systems. BPFContain combines a simple yet\nflexible policy language with an eBPF-based implementation that allows for\ndeployment on virtually any Linux system running a recent kernel. In this\npaper, we present BPFContain's policy language, describe its current\nimplementation as integrated into docker, and present benchmarks comparing it\nwith current container confinement technologies.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 18:12:34 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Findlay", "William", ""], ["Barrera", "David", ""], ["Somayaji", "Anil", ""]]}, {"id": "2102.06994", "submitter": "Ying Zhang", "authors": "Ying Zhang, Mahir Kabir, Ya Xiao, Danfeng (Daphne) Yao, Na Meng", "title": "Data-Driven Vulnerability Detection and Repair in Java Code", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Java platform provides various APIs to facilitate secure coding. However,\ncorrectly using security APIs is usually challenging for developers who lack\ncybersecurity training. Prior work shows that many developers misuse security\nAPIs; such misuses can introduce vulnerabilities into software, void security\nprotections, and present security exploits to hackers. To eliminate such\nAPI-related vulnerabilities, this paper presents SEADER -- our new approach\nthat detects and repairs security API misuses. Given an exemplar, insecure code\nsnippet, and its secure counterpart, SEADER compares the snippets and conducts\ndata dependence analysis to infer the security API misuse templates and\ncorresponding fixing operations. Based on the inferred information, given a\nprogram, SEADER performs inter-procedural static analysis to search for any\nsecurity API misuse and to propose customized fixing suggestions for those\nvulnerabilities.\n  To evaluate SEADER, we applied it to 25 <insecure, secure> code pairs, and\nSEADER successfully inferred 18 unique API misuse templates and related fixes.\nWith these vulnerability repair patterns, we further applied SEADER to 10\nopen-source projects that contain in total 32 known vulnerabilities. Our\nexperiment shows that SEADER detected vulnerabilities with 100% precision, 84%\nrecall, and 91% accuracy. Additionally, we applied SEADER to 100 Apache\nopen-source projects and detected 988 vulnerabilities; SEADER always customized\nrepair suggestions correctly. Based on SEADER's outputs, we filed 60 pull\nrequests. Up till now, developers of 18 projects have offered positive\nfeedbacks on SEADER's suggestions. Our results indicate that SEADER can\neffectively help developers detect and fix security API misuses. Whereas prior\nwork either detects API misuses or suggests simple fixes, SEADER is the first\ntool to do both for nontrivial vulnerability repairs.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 20:00:23 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Zhang", "Ying", "", "Daphne"], ["Kabir", "Mahir", "", "Daphne"], ["Xiao", "Ya", "", "Daphne"], ["Danfeng", "", "", "Daphne"], ["Yao", "", ""], ["Meng", "Na", ""]]}, {"id": "2102.07001", "submitter": "Friedhelm Victor", "authors": "Friedhelm Victor, Andrea Marie Weintraud", "title": "Detecting and Quantifying Wash Trading on Decentralized Cryptocurrency\n  Exchanges", "comments": "Accepted at the Web Conference 2021 (WWW '21) 10 pages, 10 figures", "journal-ref": null, "doi": "10.1145/3442381.3449824", "report-no": null, "categories": "cs.CR econ.GN q-fin.EC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cryptoassets such as cryptocurrencies and tokens are increasingly traded on\ndecentralized exchanges. The advantage for users is that the funds are not in\ncustody of a centralized external entity. However, these exchanges are prone to\nmanipulative behavior. In this paper, we illustrate how wash trading activity\ncan be identified on two of the first popular limit order book-based\ndecentralized exchanges on the Ethereum blockchain, IDEX and EtherDelta. We\nidentify a lower bound of accounts and trading structures that meet the legal\ndefinitions of wash trading, discovering that they are responsible for a wash\ntrading volume in equivalent of 159 million U.S. Dollars. While self-trades and\ntwo-account structures are predominant, complex forms also occur. We quantify\nthese activities, finding that on both exchanges, more than 30\\% of all traded\ntokens have been subject to wash trading activity. On EtherDelta, 10% of the\ntokens have almost exclusively been wash traded. All data is made available for\nfuture research. Our findings underpin the need for countermeasures that are\napplicable in decentralized systems.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 20:58:48 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Victor", "Friedhelm", ""], ["Weintraud", "Andrea Marie", ""]]}, {"id": "2102.07014", "submitter": "Ivan De Oliveira Nunes", "authors": "Esmerald Aliaj, Ivan De Oliveira Nunes, Gene Tsudik", "title": "GAROTA: Generalized Active Root-Of-Trust Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we set out to systematically design a minimal active RoT for\ntiny low-end MCU-s. We begin with the following questions: (1) What functions\nand hardware support are required to guarantee actions in the presence of\nmalware?, (2) How to implement this efficiently?, and (3) What security\nbenefits stem from such an active RoT architecture? We then design, implement,\nformally verify, and evaluate GAROTA: Generalized Active Root-Of-Trust\nArchitecture. We believe that GAROTA is the first clean-slate design of an\nactive RoT for low-end MCU-s. We show how GAROTA guarantees that even a fully\nsoftware-compromised low-end MCU performs a desired action. We demonstrate its\npracticality by implementing GAROTA in the context of three types of\napplications where actions are triggered by: sensing hardware, network events\nand timers. We also formally specify and verify GAROTA functionality and\nproperties.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 22:11:47 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 23:18:32 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Aliaj", "Esmerald", ""], ["Nunes", "Ivan De Oliveira", ""], ["Tsudik", "Gene", ""]]}, {"id": "2102.07022", "submitter": "Ivan Sendin", "authors": "Ivan da Silva Sendin and Rodrigo Sanches Miani", "title": "Towards reliable and transparent vaccine phase III trials with smart\n  contracts", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Transforming a vaccine concept into a real vaccine product is a complicated\nprocess and includes finding suitable antigens and regulatory, technical, and\nmanufacturing obstacles. A relevant issue within this scope is the clinical\ntrial process. Monitoring and ensuring the integrity of trial data using the\ntraditional system is not always feasible. The search for a vaccine against the\ncoronavirus SARS-CoV-2 illustrates this situation. The scientific credibility\nof findings from several vaccines' clinical trials contributed to distorted\nperceptions concerning the benefits and risks of the drug. This scenario is\nideal for applying technologies such as Blockchain and Smart Contracts in\nhealthcare issues. This paper proposes a protocol based on Smart Contracts,\nnamed VaccSC, to enable transparency, accounting, and confidentiality to Phase\nIII of vaccine experiments. The protocol was implemented in Solidity language,\nand results show that the VaccSC enables double-blindness, randomization, and\nthe auditability of clinical data, even in the presence of dishonest\nparticipants.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 22:38:36 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Sendin", "Ivan da Silva", ""], ["Miani", "Rodrigo Sanches", ""]]}, {"id": "2102.07137", "submitter": "Akbar Morshed Aski", "authors": "Akbar Morshed Aski, Hamid Haj Seyyed Javadi", "title": "A novel key pre-distribution scheme based on $\\mu$-PBIBD combinatorial\n  design in the resource-constrained IoT network", "comments": "in Persian language", "journal-ref": "The CSI Journal on Computing Science and Information Technology\n  Vol. 18, No.1, 2020", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In a resource-constrained IoT network, end nodes like WSN, RFID, and embedded\nsystems are used which have memory, processing, and energy limitations. One of\nthe key distribution solutions in these types of networks is to use the key\npre-distribution scheme, which accomplishes the key distribution operation\noffline before the resource-constrained devices deployment in the environment.\nAlso, in order to reduce the shared key discovery computing and communication\noverhead, the use of combinatorial design in key pre-distribution has been\nproposed as a solution in recent years. In this study, a ${\\mu}$-PBIBD\ncombinatorial design is introduced and constructed and the mapping of such\ndesign as a key pre-distribution scheme in the resource-constrained IoT network\nis explained. Through using such key pre-distribution scheme, more keys are\nobtained for communication between two devices in the IoT network. This means\nthat there will be a maximum of q + 2 keys between the two devices in the\nnetwork, where q is the prime power, that is, instead of having a common key\nfor a direct secure connection, the two devices can have q + 2 common keys in\ntheir key chain. Accordingly, we would increase the resilience of the key\npre-distribution scheme compared to the SBIBD, TD, Trade-KP, UKP *, RD * and\n2-D ${\\mu}$-PBIBD designs.\n  Keywords: resource-constrained IoT network; combinatorial design;\n${\\mu}$-PBIBD; resilience.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 12:22:29 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Aski", "Akbar Morshed", ""], ["Javadi", "Hamid Haj Seyyed", ""]]}, {"id": "2102.07140", "submitter": "Muhammad Zaid Hameed", "authors": "Muhammad Zaid Hameed, Andras Gyorgy", "title": "Perceptually Constrained Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by previous observations that the usually applied $L_p$ norms\n($p=1,2,\\infty$) do not capture the perceptual quality of adversarial examples\nin image classification, we propose to replace these norms with the structural\nsimilarity index (SSIM) measure, which was developed originally to measure the\nperceptual similarity of images. Through extensive experiments with\nadversarially trained classifiers for MNIST and CIFAR-10, we demonstrate that\nour SSIM-constrained adversarial attacks can break state-of-the-art\nadversarially trained classifiers and achieve similar or larger success rate\nthan the elastic net attack, while consistently providing adversarial images of\nbetter perceptual quality. Utilizing SSIM to automatically identify and\ndisallow adversarial images of low quality, we evaluate the performance of\nseveral defense schemes in a perceptually much more meaningful way than was\ndone previously in the literature.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 12:28:51 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Hameed", "Muhammad Zaid", ""], ["Gyorgy", "Andras", ""]]}, {"id": "2102.07164", "submitter": "Viresh Gupta", "authors": "Viresh Gupta, Tanmoy Chakraborty", "title": "Adversarial Attack on Network Embeddings via Supervised Network\n  Poisoning", "comments": "13 pages, 2 tables, 3 figures, PAKDD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning low-level node embeddings using techniques from network\nrepresentation learning is useful for solving downstream tasks such as node\nclassification and link prediction. An important consideration in such\napplications is the robustness of the embedding algorithms against adversarial\nattacks, which can be examined by performing perturbation on the original\nnetwork. An efficient perturbation technique can degrade the performance of\nnetwork embeddings on downstream tasks. In this paper, we study network\nembedding algorithms from an adversarial point of view and observe the effect\nof poisoning the network on downstream tasks. We propose VIKING, a supervised\nnetwork poisoning strategy that outperforms the state-of-the-art poisoning\nmethods by upto 18% on the original network structure. We also extend VIKING to\na semi-supervised attack setting and show that it is comparable to its\nsupervised counterpart.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 14:47:39 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Gupta", "Viresh", ""], ["Chakraborty", "Tanmoy", ""]]}, {"id": "2102.07195", "submitter": "Mohamed Alrshah", "authors": "Ali A. Elrowayati, Mohamed A. Alrshah, M.F.L. Abdullah, Rohaya Latip", "title": "HEVC Watermarking Techniques for Authentication and Copyright\n  Applications: Challenges and Opportunities", "comments": "Review article, 20 pages", "journal-ref": null, "doi": "10.1109/ACCESS.2020.3004049", "report-no": null, "categories": "cs.CR cs.MM", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recently, High-Efficiency Video Coding (HEVC/H.265) has been chosen to\nreplace previous video coding standards, such as H.263 and H.264. Despite the\nefficiency of HEVC, it still lacks reliable and practical functionalities to\nsupport authentication and copyright applications. In order to provide this\nsupport, several watermarking techniques have been proposed by many researchers\nduring the last few years. However, those techniques are still suffering from\nmany issues that need to be considered for future designs. In this paper, a\nSystematic Literature Review (SLR) is introduced to identify HEVC challenges\nand potential research directions for interested researchers and developers.\nThe time scope of this SLR covers all research articles published during the\nlast six years starting from January 2014 up to the end of April 2020.\nForty-two articles have met the criteria of selection out of 343 articles\npublished in this area during the mentioned time scope. A new classification\nhas been drawn followed by an identification of the challenges of implementing\nHEVC watermarking techniques based on the analysis and discussion of those\nchosen articles. Eventually, recommendations for HEVC watermarking techniques\nhave been listed to help researchers to improve the existing techniques or to\ndesign new efficient ones.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 16:56:42 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Elrowayati", "Ali A.", ""], ["Alrshah", "Mohamed A.", ""], ["Abdullah", "M. F. L.", ""], ["Latip", "Rohaya", ""]]}, {"id": "2102.07240", "submitter": "Zhuolun Xiang", "authors": "Ittai Abraham, Kartik Nayak, Ling Ren, Zhuolun Xiang", "title": "Good-case Latency of Byzantine Broadcast: a Complete Categorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the problem good-case latency of Byzantine fault-tolerant\nbroadcast, motivated by the real-world latency and performance of practical\nstate machine replication protocols. The good-case latency measures the time it\ntakes for all non-faulty parties to commit when the designated broadcaster is\nnon-faulty. We provide a complete characterization of tight bounds on good-case\nlatency, in the authenticated setting under synchrony, partial synchrony and\nasynchrony. Some of our new results may be surprising, e.g., 2-round PBFT-style\npartially synchronous Byzantine broadcast is possible if and only if $n\\geq\n5f-1$, and a tight bound for good-case latency under $n/3<f<n/2$ under\nsynchrony is not an integer multiple of the delay bound.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 20:41:28 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 23:13:57 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Abraham", "Ittai", ""], ["Nayak", "Kartik", ""], ["Ren", "Ling", ""], ["Xiang", "Zhuolun", ""]]}, {"id": "2102.07244", "submitter": "Danda Rawat", "authors": "Felix Olowononi and Danda B. Rawat and Chunmei Liu", "title": "Resilient Machine Learning for Networked Cyber Physical Systems: A\n  Survey for Machine Learning Security to Securing Machine Learning for CPS", "comments": null, "journal-ref": null, "doi": "10.1109/COMST.2020.3036778", "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber Physical Systems (CPS) are characterized by their ability to integrate\nthe physical and information or cyber worlds. Their deployment in critical\ninfrastructure have demonstrated a potential to transform the world. However,\nharnessing this potential is limited by their critical nature and the far\nreaching effects of cyber attacks on human, infrastructure and the environment.\nAn attraction for cyber concerns in CPS rises from the process of sending\ninformation from sensors to actuators over the wireless communication medium,\nthereby widening the attack surface. Traditionally, CPS security has been\ninvestigated from the perspective of preventing intruders from gaining access\nto the system using cryptography and other access control techniques. Most\nresearch work have therefore focused on the detection of attacks in CPS.\nHowever, in a world of increasing adversaries, it is becoming more difficult to\ntotally prevent CPS from adversarial attacks, hence the need to focus on making\nCPS resilient. Resilient CPS are designed to withstand disruptions and remain\nfunctional despite the operation of adversaries. One of the dominant\nmethodologies explored for building resilient CPS is dependent on machine\nlearning (ML) algorithms. However, rising from recent research in adversarial\nML, we posit that ML algorithms for securing CPS must themselves be resilient.\nThis paper is therefore aimed at comprehensively surveying the interactions\nbetween resilient CPS using ML and resilient ML when applied in CPS. The paper\nconcludes with a number of research trends and promising future research\ndirections. Furthermore, with this paper, readers can have a thorough\nunderstanding of recent advances on ML-based security and securing ML for CPS\nand countermeasures, as well as research trends in this active research area.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 20:50:18 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Olowononi", "Felix", ""], ["Rawat", "Danda B.", ""], ["Liu", "Chunmei", ""]]}, {"id": "2102.07277", "submitter": "Radhabai Gopinathan Nair Gayathri", "authors": "R G Gayathri, Atul Sajjanhar, Yong Xiang and Xingjun Ma", "title": "Anomaly Detection for Scenario-based Insider Activities using CGAN\n  Augmented Data", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Insider threats are the cyber attacks from within the trusted entities of an\norganization. Lack of real-world data and issue of data imbalance leave insider\nthreat analysis an understudied research area. To mitigate the effect of skewed\nclass distribution and prove the potential of multinomial classification\nalgorithms for insider threat detection, we propose an approach that combines\ngenerative model with supervised learning to perform multi-class classification\nusing deep learning. The generative adversarial network (GAN) based insider\ndetection model introduces Conditional Generative Adversarial Network (CGAN) to\nenrich minority class samples to provide data for multi-class anomaly\ndetection. The comprehensive experiments performed on the benchmark dataset\ndemonstrates the effectiveness of introducing GAN derived synthetic data and\nthe capability of multi-class anomaly detection in insider activity analysis.\nMoreover, the method is compared with other existing methods against different\nparameters and performance metrics.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 00:08:39 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 05:06:16 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Gayathri", "R G", ""], ["Sajjanhar", "Atul", ""], ["Xiang", "Yong", ""], ["Ma", "Xingjun", ""]]}, {"id": "2102.07304", "submitter": "Mingu Kang", "authors": "Mingu Kang, Trung Quang Tran, Seungju Cho, Daeyoung Kim", "title": "CAP-GAN: Towards Adversarial Robustness with Cycle-consistent\n  Attentional Purification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attack is aimed at fooling the target classifier with\nimperceptible perturbation. Adversarial examples, which are carefully crafted\nwith a malicious purpose, can lead to erroneous predictions, resulting in\ncatastrophic accidents. To mitigate the effects of adversarial attacks, we\npropose a novel purification model called CAP-GAN. CAP-GAN takes account of the\nidea of pixel-level and feature-level consistency to achieve reasonable\npurification under cycle-consistent learning. Specifically, we utilize the\nguided attention module and knowledge distillation to convey meaningful\ninformation to the purification model. Once a model is fully trained, inputs\nwould be projected into the purification model and transformed into clean-like\nimages. We vary the capacity of the adversary to argue the robustness against\nvarious types of attack strategies. On the CIFAR-10 dataset, CAP-GAN\noutperforms other pre-processing based defenses under both black-box and\nwhite-box settings.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 02:23:33 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 02:26:40 GMT"}, {"version": "v3", "created": "Tue, 25 May 2021 13:22:10 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Kang", "Mingu", ""], ["Tran", "Trung Quang", ""], ["Cho", "Seungju", ""], ["Kim", "Daeyoung", ""]]}, {"id": "2102.07357", "submitter": "Emre Yilmaz", "authors": "Emre Yilmaz, Tianxi Ji, Erman Ayday and Pan Li", "title": "Genomic Data Sharing under Dependent Local Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy-preserving genomic data sharing is prominent to increase the pace of\ngenomic research, and hence to pave the way towards personalized genomic\nmedicine. In this paper, we introduce ($\\epsilon , T$)-dependent local\ndifferential privacy (LDP) for privacy-preserving sharing of correlated data\nand propose a genomic data sharing mechanism under this privacy definition. We\nfirst show that the original definition of LDP is not suitable for genomic data\nsharing, and then we propose a new mechanism to share genomic data. The\nproposed mechanism considers the correlations in data during data sharing,\neliminates statistically unlikely data values beforehand, and adjusts the\nprobability distributions for each shared data point accordingly. By doing so,\nwe show that we can avoid an attacker from inferring the correct values of the\nshared data points by utilizing the correlations in the data. By adjusting the\nprobability distributions of the shared states of each data point, we also\nimprove the utility of shared data for the data collector. Furthermore, we\ndevelop a greedy algorithm that strategically identifies the processing order\nof the shared data points with the aim of maximizing the utility of the shared\ndata. Considering the interdependent privacy risks while sharing genomic data,\nwe also analyze the information gain of an attacker about genomes of a donor's\nfamily members by observing perturbed data of the genome donor and we propose a\nmechanism to select the privacy budget (i.e., $\\epsilon$ parameter of LDP) of\nthe donor by also considering privacy preferences of her family members. Our\nevaluation results on a real-life genomic dataset show the superiority of the\nproposed mechanism compared to the randomized response mechanism (a widely used\ntechnique to achieve LDP).\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 06:15:00 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Yilmaz", "Emre", ""], ["Ji", "Tianxi", ""], ["Ayday", "Erman", ""], ["Li", "Pan", ""]]}, {"id": "2102.07389", "submitter": "Alessandro Fontana", "authors": "Alessandro Fontana", "title": "And/or trade-off in artificial neurons: impact on adversarial robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since its discovery in 2013, the phenomenon of adversarial examples has\nattracted a growing amount of attention from the machine learning community. A\ndeeper understanding of the problem could lead to a better comprehension of how\ninformation is processed and encoded in neural networks and, more in general,\ncould help to solve the issue of interpretability in machine learning. Our idea\nto increase adversarial resilience starts with the observation that artificial\nneurons can be divided in two broad categories: AND-like neurons and OR-like\nneurons. Intuitively, the former are characterised by a relatively low number\nof combinations of input values which trigger neuron activation, while for the\nlatter the opposite is true. Our hypothesis is that the presence in a network\nof a sufficiently high number of OR-like neurons could lead to classification\n\"brittleness\" and increase the network's susceptibility to adversarial attacks.\nAfter constructing an operational definition of a neuron AND-like behaviour, we\nproceed to introduce several measures to increase the proportion of AND-like\nneurons in the network: L1 norm weight normalisation; application of an input\nfilter; comparison between the neuron output's distribution obtained when the\nnetwork is fed with the actual data set and the distribution obtained when the\nnetwork is fed with a randomised version of the former called \"scrambled data\nset\". Tests performed on the MNIST data set hint that the proposed measures\ncould represent an interesting direction to explore.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 08:19:05 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Fontana", "Alessandro", ""]]}, {"id": "2102.07414", "submitter": "Jonas Vogt", "authors": "Jonas Vogt, Manuel F\\\"unfrocken, Niclas Wolniak, Horst Wieker", "title": "Secure Hybrid ITS Communication with Data Protection", "comments": "Presented at 24th ITS World Congress, Montreal, Canada, October 29 to\n  November 2 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the future world of safe traffic, intelligent transportation systems play\na vital role. The connections between traffic participants and systems on the\none and infrastructure and service providers on the other side are a necessary\nprerequisite for informed and safe driving. The key for the connection between\nall stakeholders is a reliable and secure connection. Reliability can be\nachieved in different ways. For the information exchange, we utilize hybrid\ncommunication technologies in different scenarios. This includes long-range\ntechnologies like DAB+ and cellular networks and short- and medium-range\ntechnologies like ETSI ITS G5 or RFID. Those technologies can only be used if\nmessages transmitted via the wireless communication links are protected.\nProtection not only means encryption but most importantly means to verify if\nthe data was sent by a legit sender. This is a necessary requirement for a\nrecipient to trust the data received. In ITS, transmitted data could be used\nfor user tracing and collection of user data. Therefore, a communication system\nshould be designed in such a way that personal user data is protected. The user\nmust be untraceable, but nevertheless able to use all services without\nlimitations. In this paper, we describe the approach and ideas we took to\ndesign a secure hybrid communication architecture that is at the same time data\nprotection friendly.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 09:31:32 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Vogt", "Jonas", ""], ["F\u00fcnfrocken", "Manuel", ""], ["Wolniak", "Niclas", ""], ["Wieker", "Horst", ""]]}, {"id": "2102.07420", "submitter": "Mojtaba Eshghie", "authors": "Mojtaba Eshghie, Cyrille Artho, Dilian Gurov", "title": "Dynamic Vulnerability Detection on Smart Contracts Using Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we propose Dynamit, a monitoring framework to detect reentrancy\nvulnerabilities in Ethereum smart contracts. The novelty of our framework is\nthat it relies only on transaction metadata and balance data from the\nblockchain system; our approach requires no domain knowledge, code\ninstrumentation, or special execution environment. Dynamit extracts features\nfrom transaction data and uses a machine learning model to classify\ntransactions as benign or harmful. Therefore, not only can we find the\ncontracts that are vulnerable to reentrancy attacks, but we also get an\nexecution trace that reproduces the attack.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 09:49:10 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Eshghie", "Mojtaba", ""], ["Artho", "Cyrille", ""], ["Gurov", "Dilian", ""]]}, {"id": "2102.07427", "submitter": "Stephen DiAdamo", "authors": "Stephen DiAdamo and Janis N\\\"otzel", "title": "Undoing Causal Effects of a Causal Broadcast Channel with Cooperating\n  Receivers using Entanglement Resources", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We analyse a communication scenario over a particular causal broadcast\nchannel whose state depends on a modulo sum. The receivers of the broadcast\nreceive channel state information and collaborate to determine the channel\nstate as to decode their private messages. Further, the receivers of the\nbroadcast can collude up to the minimum non-collusion condition to determine\nstate information of the other non-colluding receivers. We analyse three\nresource scenarios for the receivers: receivers can share entanglement without\nclassically communicating, can just use classical communication, or have both\nentanglement and classical communication. Using results from secure multi-party\ncommunication, we find that when the receivers can share entanglement and\ncommunicate classically, they can receive messages from the sender at a\nnon-zero rate with verifiable secure collaboration. In the entanglement only\ncase a positive capacity is not possible. In the classical communication case,\na non-zero rate of communication is achievable but the communication complexity\noverhead grows quadratically in the number of receivers versus linear in the\nnumber of receivers with entanglement.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 10:05:04 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["DiAdamo", "Stephen", ""], ["N\u00f6tzel", "Janis", ""]]}, {"id": "2102.07681", "submitter": "Philip Lazos", "authors": "Philip Lazos, Francisco J. Marmolejo-Coss\\'io, Xinyu Zhou, Jonathan\n  Katz", "title": "RPPLNS: Pay-per-last-N-shares with a Randomised Twist", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Pay-per-last-$N$-shares\" (PPLNS) is one of the most common payout strategies\nused by mining pools in Proof-of-Work (PoW) cryptocurrencies. As with any\npayment scheme, it is imperative to study issues of incentive compatibility of\nminers within the pool. For PPLNS this question has only been partially\nanswered; we know that reasonably-sized miners within a PPLNS pool prefer\nfollowing the pool protocol over employing specific deviations. In this paper,\nwe present a novel modification to PPLNS where we randomise the protocol in a\nnatural way. We call our protocol \"Randomised pay-per-last-$N$-shares\"\n(RPPLNS), and note that the randomised structure of the protocol greatly\nsimplifies the study of its incentive compatibility. We show that RPPLNS\nmaintains the strengths of PPLNS (i.e., fairness, variance reduction, and\nresistance to pool hopping), while also being robust against a richer class of\nstrategic mining than what has been shown for PPLNS.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 17:14:50 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 22:57:11 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Lazos", "Philip", ""], ["Marmolejo-Coss\u00edo", "Francisco J.", ""], ["Zhou", "Xinyu", ""], ["Katz", "Jonathan", ""]]}, {"id": "2102.07690", "submitter": "Xiangguo Liu", "authors": "Xiangguo Liu, Baiting Luo, Ahmed Abdo, Nael Abu-Ghazaleh, Qi Zhu", "title": "Securing Connected Vehicle Applications with an Efficient Dual\n  Cyber-Physical Blockchain Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  While connected vehicle (CV) applications have the potential to revolutionize\ntraditional transportation system, cyber and physical attacks on them could be\ndevastating. In this work, we propose an efficient dual cyber-physical\nblockchain framework to build trust and secure communication for CV\napplications. Our approach incorporates blockchain technology and physical\nsensing capabilities of vehicles to quickly react to attacks in a large-scale\nvehicular network, with low resource overhead. We explore the application of\nour framework to three CV applications, i.e., highway merging, intelligent\nintersection management, and traffic network with route choices. Simulation\nresults demonstrate the effectiveness of our blockchain-based framework in\ndefending against spoofing attacks, bad mouthing attacks, and Sybil and voting\nattacks. We also provide analysis to demonstrate the timing efficiency of our\nframework and the low computation, communication, and storage overhead for its\nimplementation.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 17:37:10 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Liu", "Xiangguo", ""], ["Luo", "Baiting", ""], ["Abdo", "Ahmed", ""], ["Abu-Ghazaleh", "Nael", ""], ["Zhu", "Qi", ""]]}, {"id": "2102.07711", "submitter": "Anshuka Rangi", "authors": "Anshuka Rangi, Long Tran-Thanh, Haifeng Xu, Massimo Franceschetti", "title": "Secure-UCB: Saving Stochastic Bandits from Poisoning Attacks via Limited\n  Data Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies bandit algorithms under data poisoning attacks in a\nbounded reward setting. We consider a strong attacker model in which the\nattacker can observe both the selected actions and their corresponding rewards,\nand can contaminate the rewards with additive noise. We show that \\emph{any}\nbandit algorithm with regret $O(\\log T)$ can be forced to suffer a regret\n$\\Omega(T)$ with an expected amount of contamination $O(\\log T)$. This amount\nof contamination is also necessary, as we prove that there exists an $O(\\log\nT)$ regret bandit algorithm, specifically the classical UCB, that requires\n$\\Omega(\\log T)$ amount of contamination to suffer regret $\\Omega(T)$. To\ncombat such poising attacks, our second main contribution is to propose a novel\nalgorithm, Secure-UCB, which uses limited \\emph{verification} to access a\nlimited number of uncontaminated rewards. We show that with $O(\\log T)$\nexpected number of verifications, Secure-UCB can restore the order optimal\n$O(\\log T)$ regret \\emph{irrespective of the amount of contamination} used by\nthe attacker. Finally, we prove that for any bandit algorithm, this number of\nverifications $O(\\log T)$ is necessary to recover the order-optimal regret. We\ncan then conclude that Secure-UCB is order-optimal in terms of both the\nexpected regret and the expected number of verifications, and can save\nstochastic bandits from any data poisoning attack.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 18:02:46 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Rangi", "Anshuka", ""], ["Tran-Thanh", "Long", ""], ["Xu", "Haifeng", ""], ["Franceschetti", "Massimo", ""]]}, {"id": "2102.07731", "submitter": "Johannes Sedlmeir", "authors": "Tobias Guggenberger and Johannes Sedlmeir and Gilbert Fridgen and\n  Andr\\'e Luckow", "title": "An In-Depth Investigation of Performance Characteristics of Hyperledger\n  Fabric", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.CR cs.DB cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Private permissioned blockchains, such as Hyperledger Fabric, are widely\ndeployed across the industry to facilitate cross-organizational processes and\npromise improved performance compared to their public counterparts. However,\nthe lack of empirical and theoretical results prevent precise prediction of the\nreal-world performance. We address this gap by conducting an in-depth\nperformance analysis of Hyperledger Fabric. The paper presents a detailed\ncompilation of various performance characteristics using an enhanced version of\nthe Distributed Ledger Performance Scan. Researchers and practitioners alike\ncan use the results as guidelines to better configure and implement their\nblockchains and utilize the DLPS framework to conduct their measurements.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 18:30:43 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Guggenberger", "Tobias", ""], ["Sedlmeir", "Johannes", ""], ["Fridgen", "Gilbert", ""], ["Luckow", "Andr\u00e9", ""]]}, {"id": "2102.07762", "submitter": "Avital Shafran", "authors": "Avital Shafran, Shmuel Peleg, Yedid Hoshen", "title": "Reconstruction-Based Membership Inference Attacks are Easier on\n  Difficult Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Membership inference attacks (MIA) try to detect if data samples were used to\ntrain a neural network model, e.g. to detect copyright abuses. We show that\nmodels with higher dimensional input and output are more vulnerable to MIA, and\naddress in more detail models for image translation and semantic segmentation,\nincluding medical image segmentation. We show that reconstruction-errors can\nlead to very effective MIA attacks as they are indicative of memorization.\nUnfortunately, reconstruction error alone is less effective at discriminating\nbetween non-predictable images used in training and easy to predict images that\nwere never seen before. To overcome this, we propose using a novel\npredictability error that can be computed for each sample, and its computation\ndoes not require a training set. Our membership error, obtained by subtracting\nthe predictability error from the reconstruction error, is shown to achieve\nhigh MIA accuracy on an extensive number of benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 18:57:22 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 17:53:34 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Shafran", "Avital", ""], ["Peleg", "Shmuel", ""], ["Hoshen", "Yedid", ""]]}, {"id": "2102.07869", "submitter": "Octavian Suciu", "authors": "Octavian Suciu, Connor Nelson, Zhuoer Lyu, Tiffany Bao, Tudor Dumitras", "title": "Expected Exploitability: Predicting the Development of Functional\n  Vulnerability Exploits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Assessing the exploitability of software vulnerabilities at the time of\ndisclosure is difficult and error-prone, as features extracted via technical\nanalysis by existing metrics are poor predictors for exploit development.\nMoreover, exploitability assessments suffer from a class bias because \"not\nexploitable\" labels could be inaccurate.\n  To overcome these challenges, we propose a new metric, called Expected\nExploitability (EE), which reflects, over time, the likelihood that functional\nexploits will be developed. Key to our solution is a time-varying view of\nexploitability, a departure from existing metrics, which allows us to learn EE\nusing data-driven techniques from artifacts published after disclosure, such as\ntechnical write-ups, proof-of-concept exploits, and social media discussions.\nOur analysis reveals that prior features proposed for related exploit\nprediction tasks are not always beneficial for predicting functional exploits,\nand we design novel feature sets to capitalize on previously under-utilized\nartifacts.\n  This view also allows us to investigate the effect of the label biases on the\nclassifiers. We characterize the noise-generating process for exploit\nprediction, showing that our problem is subject to class- and feature-dependent\nlabel noise, considered the most challenging type. By leveraging\ndomain-specific observations, we then develop techniques to incorporate noise\nrobustness into learning EE.\n  On a dataset of 103,137 vulnerabilities, we show that EE increases precision\nfrom 49\\% to 86\\% over existing metrics, including two state-of-the-art exploit\nclassifiers, while the performance of our metric also improving over time. EE\nscores capture exploitation imminence, by distinguishing exploits which are\ngoing to be developed in the near future.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 22:24:42 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Suciu", "Octavian", ""], ["Nelson", "Connor", ""], ["Lyu", "Zhuoer", ""], ["Bao", "Tiffany", ""], ["Dumitras", "Tudor", ""]]}, {"id": "2102.07886", "submitter": "Johannes Sedlmeir", "authors": "Johannes Sedlmeir and Hans Ulrich Buhl and Gilbert Fridgen and Robert\n  Keller", "title": "Recent Developments in Blockchain Technology and their Impact on Energy\n  Consumption", "comments": "This is a translated version of a German article published in\n  Informatik Spektrum", "journal-ref": null, "doi": "10.1007/s00287-020-01321-z", "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The enormous power consumption of Bitcoin has led to undifferentiated\ndiscussions in science and practice about the sustainability of blockchain and\ndistributed ledger technology in general. However, blockchain technology is far\nfrom homogeneous - not only with regard to its applications, which now go far\nbeyond cryptocurrencies and have reached businesses and the public sector, but\nalso with regard to its technical characteristics and, in particular, its power\nconsumption. This paper summarizes the status quo of the power consumption of\nvarious implementations of blockchain technology, with special emphasis on the\nrecent 'Bitcoin Halving' and so-called 'zk-rollups'. We argue that although\nBitcoin and other proof-of-work blockchains do indeed consume a lot of power,\nalternative blockchain solutions with significantly lower power consumption are\nalready available today, and new promising concepts are being tested that could\nfurther reduce in particular the power consumption of large blockchain networks\nin the near future. From this we conclude that although the criticism of\nBitcoin's power consumption is legitimate, it should not be used to derive an\nenergy problem of blockchain technology in general. In many cases in which\nprocesses can be digitised or improved with the help of more energy-efficient\nblockchain variants, one can even expect net energy savings.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 22:55:30 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Sedlmeir", "Johannes", ""], ["Buhl", "Hans Ulrich", ""], ["Fridgen", "Gilbert", ""], ["Keller", "Robert", ""]]}, {"id": "2102.07904", "submitter": "Cristopher Salvi", "authors": "Thomas Cochrane, Peter Foster, Varun Chhabra, Maud Lemercier,\n  Cristopher Salvi, Terry Lyons", "title": "SK-Tree: a systematic malware detection algorithm on streaming trees via\n  the signature kernel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of machine learning algorithms in the cyber security domain\nhas been impeded by the complex, hierarchical, sequential and multimodal nature\nof the data involved. In this paper we introduce the notion of a streaming tree\nas a generic data structure encompassing a large portion of real-world cyber\nsecurity data. Starting from host-based event logs we represent computer\nprocesses as streaming trees that evolve in continuous time. Leveraging the\nproperties of the signature kernel, a machine learning tool that recently\nemerged as a leading technology for learning with complex sequences of data, we\ndevelop the SK-Tree algorithm. SK-Tree is a supervised learning method for\nsystematic malware detection on streaming trees that is robust to irregular\nsampling and high dimensionality of the underlying streams. We demonstrate the\neffectiveness of SK-Tree to detect malicious events on a portion of the\npublicly available DARPA OpTC dataset, achieving an AUROC score of 98%.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 01:16:32 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 19:40:52 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2021 08:57:55 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Cochrane", "Thomas", ""], ["Foster", "Peter", ""], ["Chhabra", "Varun", ""], ["Lemercier", "Maud", ""], ["Salvi", "Cristopher", ""], ["Lyons", "Terry", ""]]}, {"id": "2102.07932", "submitter": "Zhuolun Xiang", "authors": "Ittai Abraham, Kartik Nayak, Ling Ren, Zhuolun Xiang", "title": "Brief Note: Fast Authenticated Byzantine Consensus", "comments": "This is a complementary note of our previous paper on the good-case\n  latency of Byzantine broadcast", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Byzantine fault-tolerant (BFT) state machine replication (SMR) has been\nstudied for over 30 years. Recently it has received more attention due to its\napplication in permissioned blockchain systems. A sequence of research efforts\nfocuses on improving the commit latency of the SMR protocol in the common good\ncase, including PBFT with $3$-round latency and $n\\geq 3f+1$ and FaB with\n$2$-round latency and $n\\geq 5f+1$. In this paper, we propose an authenticated\nprotocol that solves $2$-round BFT SMR with only $n\\geq 5f-1$ replicas, which\nrefutes the optimal resiliency claim made in FaB for needing $n \\geq 5f+1$ for\n$2$-round PBFT-style BFT protocols. For the special case when $f=1$, our\nprotocol needs only $4$ replicas, and strictly improves PBFT by reducing the\nlatency by one round (even when one backup is faulty).\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 03:02:34 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 22:39:50 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Abraham", "Ittai", ""], ["Nayak", "Kartik", ""], ["Ren", "Ling", ""], ["Xiang", "Zhuolun", ""]]}, {"id": "2102.07969", "submitter": "Yuantian Miao", "authors": "Yuantian Miao, Chao Chen, Lei Pan, Qing-Long Han, Jun Zhang, Yang\n  Xiang", "title": "Machine Learning Based Cyber Attacks Targeting on Controlled\n  Information: A Survey", "comments": "Under 3rd round review of ACM Computing Surveys", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Stealing attack against controlled information, along with the increasing\nnumber of information leakage incidents, has become an emerging cyber security\nthreat in recent years. Due to the booming development and deployment of\nadvanced analytics solutions, novel stealing attacks utilize machine learning\n(ML) algorithms to achieve high success rate and cause a lot of damage.\nDetecting and defending against such attacks is challenging and urgent so that\ngovernments, organizations, and individuals should attach great importance to\nthe ML-based stealing attacks. This survey presents the recent advances in this\nnew type of attack and corresponding countermeasures. The ML-based stealing\nattack is reviewed in perspectives of three categories of targeted controlled\ninformation, including controlled user activities, controlled ML model-related\ninformation, and controlled authentication information. Recent publications are\nsummarized to generalize an overarching attack methodology and to derive the\nlimitations and future directions of ML-based stealing attacks. Furthermore,\ncountermeasures are proposed towards developing effective protections from\nthree aspects -- detection, disruption, and isolation.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 05:46:10 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Miao", "Yuantian", ""], ["Chen", "Chao", ""], ["Pan", "Lei", ""], ["Han", "Qing-Long", ""], ["Zhang", "Jun", ""], ["Xiang", "Yang", ""]]}, {"id": "2102.08013", "submitter": "Yunyi Xie", "authors": "Yunyi Xie, Jie Jin, Jian Zhang, Shanqing Yu, and Qi Xuan", "title": "Temporal-Amount Snapshot MultiGraph for Ethereum Transaction Tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the wide application of blockchain in the financial field, the rise of\nvarious types of cybercrimes has brought great challenges to the security of\nblockchain. In order to better understand this emerging market and explore more\nefficient countermeasures for effective supervision, it is imperative to track\ntransactions on blockchain-based systems. Due to the openness of Ethereum, we\ncan easily access the publicly available transaction records, model them as a\ncomplex network, and further study the problem of transaction tracking via link\nprediction, which provides a deeper understanding of Ethereum transactions from\na network perspective. Specifically, we introduce an embedding based link\nprediction framework that is composed of temporal-amount snapshot multigraph\n(TASMG) and present temporal-amount walk (TAW). By taking the realistic rules\nand features of transaction networks into consideration, we propose TASMG to\nmodel Ethereum transaction records as a temporal-amount network and then\npresent TAW to effectively embed accounts via their transaction records, which\nintegrates temporal and amount information of the proposed network.\nExperimental results demonstrate the superiority of the proposed framework in\nlearning more informative representations and could be an effective method for\ntransaction tracking.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 08:21:16 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Xie", "Yunyi", ""], ["Jin", "Jie", ""], ["Zhang", "Jian", ""], ["Yu", "Shanqing", ""], ["Xuan", "Qi", ""]]}, {"id": "2102.08026", "submitter": "Nabil Ibtehaz", "authors": "Nabil Ibtehaz, Muhammad E. H. Chowdhury, Amith Khandakar, Serkan\n  Kiranyaz, M. Sohel Rahman, Anas Tahir, Yazan Qiblawey, and Tawsifur Rahman", "title": "EDITH :ECG biometrics aided by Deep learning for reliable Individual\n  auTHentication", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, physiological signal based authentication has shown great\npromises,for its inherent robustness against forgery. Electrocardiogram (ECG)\nsignal, being the most widely studied biosignal, has also received the highest\nlevel of attention in this regard. It has been proven with numerous studies\nthat by analyzing ECG signals from different persons, it is possible to\nidentify them, with acceptable accuracy. In this work, we present, EDITH, a\ndeep learning-based framework for ECG biometrics authentication system.\nMoreover, we hypothesize and demonstrate that Siamese architectures can be used\nover typical distance metrics for improved performance. We have evaluated EDITH\nusing 4 commonly used datasets and outperformed the prior works using less\nnumber of beats. EDITH performs competitively using just a single heartbeat\n(96-99.75% accuracy) and can be further enhanced by fusing multiple beats (100%\naccuracy from 3 to 6 beats). Furthermore, the proposed Siamese architecture\nmanages to reduce the identity verification Equal Error Rate (EER) to 1.29%. A\nlimited case study of EDITH with real-world experimental data also suggests its\npotential as a practical authentication system.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 08:45:17 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Ibtehaz", "Nabil", ""], ["Chowdhury", "Muhammad E. H.", ""], ["Khandakar", "Amith", ""], ["Kiranyaz", "Serkan", ""], ["Rahman", "M. Sohel", ""], ["Tahir", "Anas", ""], ["Qiblawey", "Yazan", ""], ["Rahman", "Tawsifur", ""]]}, {"id": "2102.08166", "submitter": "John Stephan", "authors": "Rachid Guerraoui, Nirupam Gupta, Rafa\\\"el Pinot, S\\'ebastien Rouault,\n  John Stephan", "title": "Differential Privacy and Byzantine Resilience in SGD: Do They Add Up?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of combining Byzantine resilience with\nprivacy in machine learning (ML). Specifically, we study if a distributed\nimplementation of the renowned Stochastic Gradient Descent (SGD) learning\nalgorithm is feasible with both differential privacy (DP) and\n$(\\alpha,f)$-Byzantine resilience. To the best of our knowledge, this is the\nfirst work to tackle this problem from a theoretical point of view. A key\nfinding of our analyses is that the classical approaches to these two\n(seemingly) orthogonal issues are incompatible. More precisely, we show that a\ndirect composition of these techniques makes the guarantees of the resulting\nSGD algorithm depend unfavourably upon the number of parameters of the ML\nmodel, making the training of large models practically infeasible. We validate\nour theoretical results through numerical experiments on publicly-available\ndatasets; showing that it is impractical to ensure DP and Byzantine resilience\nsimultaneously.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 14:10:38 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 15:11:52 GMT"}, {"version": "v3", "created": "Thu, 24 Jun 2021 15:44:21 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Guerraoui", "Rachid", ""], ["Gupta", "Nirupam", ""], ["Pinot", "Rafa\u00ebl", ""], ["Rouault", "S\u00e9bastien", ""], ["Stephan", "John", ""]]}, {"id": "2102.08185", "submitter": "Fathima Begum M", "authors": "Fathima Begum M, M. Abdul Naseer", "title": "Efficient Data Gathering and Aggregation for Multiple Applications in\n  Wireless Sensor Networks", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": "1234", "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Data aggregation in wireless sensor networks refers to acquiring the sensed\ndata from the sensors to the gateway node. It reduces the amount of power\nconsumed during data transmission between the sensor nodes. Generally\nhomomorphic encryptions have been applied to conceal communication during\naggregation. Since enciphered data can be aggregated algebraically without\ndecryption. Here adversaries are able to forge aggregated results by\ncompromising them. However, these schemes are not satisfying multi-application\nenvironments, provide insecure transmission and do not provide secure counting\nfor unauthorized aggregation attacks. In this paper, we propose a new concealed\ndata aggregation scheme extended from homomorphic privacy encryption system.\nThe proposed scheme designed for a multi-application environment, mitigates the\nimpact of compromising attacks in single application environments and also it\ncan avoid the damage from unauthorized aggregations by the privacy homomorphic\nencryption scheme.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 09:01:26 GMT"}, {"version": "v2", "created": "Mon, 5 Jul 2021 15:21:09 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["M", "Fathima Begum", ""], ["Naseer", "M. Abdul", ""]]}, {"id": "2102.08199", "submitter": "Volker Steinhage", "authors": "Jakob Greis, Artem Yushchenko, Daniel Vogel, Michael Meier and Volker\n  Steinhage", "title": "Automated Identification of Vulnerable Devices in Networks using Traffic\n  Data and Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many IoT devices are vulnerable to attacks due to flawed security designs and\nlacking mechanisms for firmware updates or patches to eliminate the security\nvulnerabilities. Device-type identification combined with data from\nvulnerability databases can pinpoint vulnerable IoT devices in a network and\ncan be used to constrain the communications of vulnerable devices for\npreventing damage. In this contribution, we present and evaluate two deep\nlearning approaches to the reliable IoT device-type identification, namely a\nrecurrent and a convolutional network architecture. Both deep learning\napproaches show accuracies of 97% and 98%, respectively, and thereby outperform\nan up-to-date IoT device-type identification approach using hand-crafted\nfingerprint features obtaining an accuracy of 82%. The runtime performance for\nthe IoT identification of both deep learning approaches outperforms the\nhand-crafted approach by three magnitudes. Finally, importance metrics explain\nthe results of both deep learning approaches in terms of the utilization of the\nanalyzed traffic data flow.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 14:49:34 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Greis", "Jakob", ""], ["Yushchenko", "Artem", ""], ["Vogel", "Daniel", ""], ["Meier", "Michael", ""], ["Steinhage", "Volker", ""]]}, {"id": "2102.08244", "submitter": "Matthew Joseph", "authors": "Jennifer Gillenwater, Matthew Joseph, Alex Kulesza", "title": "Differentially Private Quantiles", "comments": "This version adds the FFT optimization and corresponds to the ICML\n  2021 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantiles are often used for summarizing and understanding data. If that data\nis sensitive, it may be necessary to compute quantiles in a way that is\ndifferentially private, providing theoretical guarantees that the result does\nnot reveal private information. However, when multiple quantiles are needed,\nexisting differentially private algorithms fare poorly: they either compute\nquantiles individually, splitting the privacy budget, or summarize the entire\ndistribution, wasting effort. In either case the result is reduced accuracy. In\nthis work we propose an instance of the exponential mechanism that\nsimultaneously estimates exactly $m$ quantiles from $n$ data points while\nguaranteeing differential privacy. The utility function is carefully structured\nto allow for an efficient implementation that returns estimates of all $m$\nquantiles in time $O(mn\\log(n) + m^2n)$. Experiments show that our method\nsignificantly outperforms the current state of the art on both real and\nsynthetic data while remaining efficient enough to be practical.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 16:02:59 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 17:50:34 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Gillenwater", "Jennifer", ""], ["Joseph", "Matthew", ""], ["Kulesza", "Alex", ""]]}, {"id": "2102.08304", "submitter": "Burak Hasircioglu", "authors": "Burak Hasircioglu, Jesus Gomez-Vilardebo, Deniz Gunduz", "title": "Speeding Up Private Distributed Matrix Multiplication via Bivariate\n  Polynomial Codes", "comments": "To appear in IEEE International Symposium on Information Theory\n  (ISIT) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of private distributed matrix multiplication under\nlimited resources. Coded computation has been shown to be an effective solution\nin distributed matrix multiplication, both providing privacy against the\nworkers and boosting the computation speed by efficiently mitigating\nstragglers. In this work, we propose the use of recently-introduced bivariate\npolynomial codes to further speed up private distributed matrix multiplication\nby exploiting the partial work done by the stragglers rather than completely\nignoring them. We show that the proposed approach reduces the average\ncomputation time of private distributed matrix multiplication compared to its\ncompetitors in the literature while improving the upload communication cost and\nthe workers' storage efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 17:40:30 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 17:56:56 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Hasircioglu", "Burak", ""], ["Gomez-Vilardebo", "Jesus", ""], ["Gunduz", "Deniz", ""]]}, {"id": "2102.08308", "submitter": "Ecenaz Erdemir", "authors": "Ecenaz Erdemir and Pier Luigi Dragotti and Deniz Gunduz", "title": "Active Privacy-utility Trade-off Against a Hypothesis Testing Adversary", "comments": "Accepted to IEEE International Conference on Acoustics, Speech and\n  Signal Processing (ICASSP 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a user releasing her data containing some personal information in\nreturn of a service. We model user's personal information as two correlated\nrandom variables, one of them, called the secret variable, is to be kept\nprivate, while the other, called the useful variable, is to be disclosed for\nutility. We consider active sequential data release, where at each time step\nthe user chooses from among a finite set of release mechanisms, each revealing\nsome information about the user's personal information, i.e., the true\nhypotheses, albeit with different statistics. The user manages data release in\nan online fashion such that maximum amount of information is revealed about the\nlatent useful variable, while the confidence for the sensitive variable is kept\nbelow a predefined level. For the utility, we consider both the probability of\ncorrect detection of the useful variable and the mutual information (MI)\nbetween the useful variable and released data. We formulate both problems as a\nMarkov decision process (MDP), and numerically solve them by advantage\nactor-critic (A2C) deep reinforcement learning (RL).\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 17:49:31 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 11:59:00 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Erdemir", "Ecenaz", ""], ["Dragotti", "Pier Luigi", ""], ["Gunduz", "Deniz", ""]]}, {"id": "2102.08332", "submitter": "Nguyen Phong Hoang", "authors": "Nguyen Phong Hoang, Arian Akhavan Niaki, Phillipa Gill, Michalis\n  Polychronakis", "title": "Domain Name Encryption Is Not Enough: Privacy Leakage via IP-based\n  Website Fingerprinting", "comments": "To appear in Proceedings of the 21st Privacy Enhancing Technologies\n  Symposium (PETS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the security benefits of domain name encryption technologies such as\nDNS over TLS (DoT), DNS over HTTPS (DoH), and Encrypted Client Hello (ECH) are\nclear, their positive impact on user privacy is weakened by--the still\nexposed--IP address information. However, content delivery networks, DNS-based\nload balancing, co-hosting of different websites on the same server, and IP\naddress churn, all contribute towards making domain-IP mappings unstable, and\nprevent straightforward IP-based browsing tracking.\n  In this paper, we show that this instability is not a roadblock (assuming a\nuniversal DoT/DoH and ECH deployment), by introducing an IP-based website\nfingerprinting technique that allows a network-level observer to identify at\nscale the website a user visits. Our technique exploits the complex structure\nof most websites, which load resources from several domains besides their\nprimary one. Using the generated fingerprints of more than 200K websites\nstudied, we could successfully identify 84% of them when observing solely\ndestination IP addresses. The accuracy rate increases to 92% for popular\nwebsites, and 95% for popular and sensitive websites. We also evaluated the\nrobustness of the generated fingerprints over time, and demonstrate that they\nare still effective at successfully identifying about 70% of the tested\nwebsites after two months. We conclude by discussing strategies for website\nowners and hosting providers towards hindering IP-based website fingerprinting\nand maximizing the privacy benefits offered by DoT/DoH and ECH.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 18:19:37 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 04:53:59 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Hoang", "Nguyen Phong", ""], ["Niaki", "Arian Akhavan", ""], ["Gill", "Phillipa", ""], ["Polychronakis", "Michalis", ""]]}, {"id": "2102.08355", "submitter": "Muhammad Umer", "authors": "Muhammad Umer, Robi Polikar", "title": "Adversarial Targeted Forgetting in Regularization and Generative Based\n  Continual Learning Models", "comments": "arXiv admin note: text overlap with arXiv:2002.07111", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Continual (or \"incremental\") learning approaches are employed when additional\nknowledge or tasks need to be learned from subsequent batches or from streaming\ndata. However these approaches are typically adversary agnostic, i.e., they do\nnot consider the possibility of a malicious attack. In our prior work, we\nexplored the vulnerabilities of Elastic Weight Consolidation (EWC) to the\nperceptible misinformation. We now explore the vulnerabilities of other\nregularization-based as well as generative replay-based continual learning\nalgorithms, and also extend the attack to imperceptible misinformation. We show\nthat an intelligent adversary can take advantage of a continual learning\nalgorithm's capabilities of retaining existing knowledge over time, and force\nit to learn and retain deliberately introduced misinformation. To demonstrate\nthis vulnerability, we inject backdoor attack samples into the training data.\nThese attack samples constitute the misinformation, allowing the attacker to\ncapture control of the model at test time. We evaluate the extent of this\nvulnerability on both rotated and split benchmark variants of the MNIST dataset\nunder two important domain and class incremental learning scenarios. We show\nthat the adversary can create a \"false memory\" about any task by inserting\ncarefully-designed backdoor samples to the test instances of that task thereby\ncontrolling the amount of forgetting of any task of its choosing. Perhaps most\nimportantly, we show this vulnerability to be very acute and damaging: the\nmodel memory can be easily compromised with the addition of backdoor samples\ninto as little as 1\\% of the training data, even when the misinformation is\nimperceptible to human eye.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 18:45:01 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Umer", "Muhammad", ""], ["Polikar", "Robi", ""]]}, {"id": "2102.08411", "submitter": "Konstantinos Demertzis", "authors": "Konstantinos Demertzis, Konstantinos Tsiknas, Dimitrios Takezis,\n  Charalabos Skianis and Lazaros Iliadis", "title": "Darknet Traffic Big-Data Analysis and Network Management to Real-Time\n  Automating the Malicious Intent Detection Process by a Weight Agnostic Neural\n  Networks Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attackers are perpetually modifying their tactics to avoid detection and\nfrequently leverage legitimate credentials with trusted tools already deployed\nin a network environment, making it difficult for organizations to proactively\nidentify critical security risks. Network traffic analysis products have\nemerged in response to attackers relentless innovation, offering organizations\na realistic path forward for combatting creative attackers. Additionally,\nthanks to the widespread adoption of cloud computing, Device Operators\nprocesses, and the Internet of Things, maintaining effective network visibility\nhas become a highly complex and overwhelming process. What makes network\ntraffic analysis technology particularly meaningful is its ability to combine\nits core capabilities to deliver malicious intent detection. In this paper, we\npropose a novel darknet traffic analysis and network management framework to\nreal-time automating the malicious intent detection process, using a weight\nagnostic neural networks architecture. It is an effective and accurate\ncomputational intelligent forensics tool for network traffic analysis, the\ndemystification of malware traffic, and encrypted traffic identification in\nreal-time. Based on Weight Agnostic Neural Networks methodology, we propose an\nautomated searching neural net architectures strategy that can perform various\ntasks such as identify zero-day attacks. By automating the malicious intent\ndetection process from the darknet, the advanced proposed solution is reducing\nthe skills and effort barrier that prevents many organizations from effectively\nprotecting their most critical assets.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 19:03:25 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Demertzis", "Konstantinos", ""], ["Tsiknas", "Konstantinos", ""], ["Takezis", "Dimitrios", ""], ["Skianis", "Charalabos", ""], ["Iliadis", "Lazaros", ""]]}, {"id": "2102.08452", "submitter": "Klas Leino", "authors": "Klas Leino, Zifan Wang, Matt Fredrikson", "title": "Globally-Robust Neural Networks", "comments": "Appearing in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The threat of adversarial examples has motivated work on training certifiably\nrobust neural networks to facilitate efficient verification of local robustness\nat inference time. We formalize a notion of global robustness, which captures\nthe operational properties of on-line local robustness certification while\nyielding a natural learning objective for robust training. We show that\nwidely-used architectures can be easily adapted to this objective by\nincorporating efficient global Lipschitz bounds into the network, yielding\ncertifiably-robust models by construction that achieve state-of-the-art\nverifiable accuracy. Notably, this approach requires significantly less time\nand memory than recent certifiable training methods, and leads to negligible\ncosts when certifying points on-line; for example, our evaluation shows that it\nis possible to train a large robust Tiny-Imagenet model in a matter of hours.\nOur models effectively leverage inexpensive global Lipschitz bounds for\nreal-time certification, despite prior suggestions that tighter local bounds\nare needed for good performance; we posit this is possible because our models\nare specifically trained to achieve tighter global bounds. Namely, we prove\nthat the maximum achievable verifiable accuracy for a given dataset is not\nimproved by using a local bound.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 21:10:52 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 20:36:25 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Leino", "Klas", ""], ["Wang", "Zifan", ""], ["Fredrikson", "Matt", ""]]}, {"id": "2102.08458", "submitter": "Bal\\'azs Pej\\'o", "authors": "Frederick Ayala-Gomez, Ismo Horppu, Erlin Gulbenkoglu, Vesa Siivola,\n  and Bal\\'azs Pej\\'o", "title": "Revenue Attribution on iOS 14 using Conversion Values in F2P Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile app developers use paid advertising campaigns to acquire new users,\nand they need to know the campaigns' performance to guide their spending.\nDetermining the campaign that led to an install requires that the app and\nadvertising network share an identifier that allows matching ad clicks to\ninstalls. Ad networks use the identifier to build user profiles that help with\ntargeting and personalization. Modern mobile operating systems have features to\nprotect the privacy of the user. The privacy features of Apple's iOS 14\nenforces all apps to get system permission for tracking explicitly instead of\nasking the user to opt-out of tracking as before. If the user does not allow\ntracking, the identifier for advertisers (IDFA) required for attributing the\ninstallation to the campaign is not shared. The lack of an identifier for the\nattribution changes profoundly how user acquisition campaigns' performance is\nmeasured. For users who do not allow tracking, there is a new feature that\nstill allows following campaign performance. The app can set an integer, so\ncalled conversion value for each user, and the developer can get the number of\ninstalls per conversion value for each campaign. This paper investigates the\ntask of distributing revenue to advertising campaigns using the conversion\nvalues. Our contributions are to formalize the problem, find the theoretically\noptimal revenue attribution function for any conversion value schema, and show\nempirical results on past data of a free-to-play mobile game using different\nconversion value schemas.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 21:31:38 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 06:50:25 GMT"}, {"version": "v3", "created": "Sat, 27 Feb 2021 00:44:33 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Ayala-Gomez", "Frederick", ""], ["Horppu", "Ismo", ""], ["Gulbenkoglu", "Erlin", ""], ["Siivola", "Vesa", ""], ["Pej\u00f3", "Bal\u00e1zs", ""]]}, {"id": "2102.08492", "submitter": "Adish Singla", "authors": "Amin Rakhsha, Xuezhou Zhang, Xiaojin Zhu, Adish Singla", "title": "Reward Poisoning in Reinforcement Learning: Attacks Against Unknown\n  Learners in Unknown Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study black-box reward poisoning attacks against reinforcement learning\n(RL), in which an adversary aims to manipulate the rewards to mislead a\nsequence of RL agents with unknown algorithms to learn a nefarious policy in an\nenvironment unknown to the adversary a priori. That is, our attack makes\nminimum assumptions on the prior knowledge of the adversary: it has no initial\nknowledge of the environment or the learner, and neither does it observe the\nlearner's internal mechanism except for its performed actions. We design a\nnovel black-box attack, U2, that can provably achieve a near-matching\nperformance to the state-of-the-art white-box attack, demonstrating the\nfeasibility of reward poisoning even in the most challenging black-box setting.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 23:20:15 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Rakhsha", "Amin", ""], ["Zhang", "Xuezhou", ""], ["Zhu", "Xiaojin", ""], ["Singla", "Adish", ""]]}, {"id": "2102.08504", "submitter": "Jiankai Sun", "authors": "Oscar Li and Jiankai Sun and Xin Yang and Weihao Gao and Hongyi Zhang\n  and Junyuan Xie and Virginia Smith and Chong Wang", "title": "Label Leakage and Protection in Two-party Split Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In vertical federated learning, two-party split learning has become an\nimportant topic and has found many applications in real business scenarios.\nHowever, how to prevent the participants' ground-truth labels from possible\nleakage is not well studied. In this paper, we consider answering this question\nin an imbalanced binary classification setting, a common case in online\nbusiness applications. We first show that, norm attack, a simple method that\nuses the norm of the communicated gradients between the parties, can largely\nreveal the ground-truth labels from the participants. We then discuss several\nprotection techniques to mitigate this issue. Among them, we have designed a\nprincipled approach that directly maximizes the worst-case error of label\ndetection. This is proved to be more effective in countering norm attack and\nbeyond. We experimentally demonstrate the competitiveness of our proposed\nmethod compared to several other baselines.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 00:01:49 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Li", "Oscar", ""], ["Sun", "Jiankai", ""], ["Yang", "Xin", ""], ["Gao", "Weihao", ""], ["Zhang", "Hongyi", ""], ["Xie", "Junyuan", ""], ["Smith", "Virginia", ""], ["Wang", "Chong", ""]]}, {"id": "2102.08510", "submitter": "Damjan Vukcevic", "authors": "Michelle Blom, Philip B. Stark, Peter J. Stuckey, Vanessa Teague and\n  Damjan Vukcevic", "title": "Auditing Hamiltonian Elections", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Presidential primaries are a critical part of the United States Presidential\nelectoral process, since they are used to select the candidates in the\nPresidential election. While methods differ by state and party, many primaries\ninvolve proportional delegate allocation using the so-called Hamilton method.\nIn this paper we show how to conduct risk-limiting audits for delegate\nallocation elections using variants of the Hamilton method where the viability\nof candidates is determined either by a plurality vote or using instant runoff\nvoting. Experiments on real-world elections show that we can audit primary\nelections to high confidence (small risk limits) usually at low cost.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 00:20:26 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 13:06:15 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Blom", "Michelle", ""], ["Stark", "Philip B.", ""], ["Stuckey", "Peter J.", ""], ["Teague", "Vanessa", ""], ["Vukcevic", "Damjan", ""]]}, {"id": "2102.08517", "submitter": "Ozlem Uzuner", "authors": "Kahyun Lee, Nicholas J. Dobbins, Bridget McInnes, Meliha Yetisgen,\n  \\\"Ozlem Uzuner", "title": "Transferability of Neural Network-based De-identification Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Methods and Materials: We investigated transferability of neural\nnetwork-based de-identification sys-tems with and without domain\ngeneralization. We used two domain generalization approaches: a novel approach\nJoint-Domain Learning (JDL) as developed in this paper, and a state-of-the-art\ndomain general-ization approach Common-Specific Decomposition (CSD) from the\nliterature. First, we measured trans-ferability from a single external source.\nSecond, we used two external sources and evaluated whether domain\ngeneralization can improve transferability of de-identification models across\ndomains which rep-resent different note types from the same institution. Third,\nusing two external sources with in-domain training data, we studied whether\nexternal source data are useful even in cases where sufficient in-domain\ntraining data are available. Finally, we investigated transferability of the\nde-identification mod-els across institutions. Results and Conclusions: We\nfound transferability from a single external source gave inconsistent re-sults.\nUsing additional external sources consistently yielded an F1-score of\napproximately 80%, but domain generalization was not always helpful to improve\ntransferability. We also found that external sources were useful even in cases\nwhere in-domain training data were available by reducing the amount of needed\nin-domain training data or by improving performance. Transferability across\ninstitutions was differed by note type and annotation label. External sources\nfrom a different institution were also useful to further improve performance.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 00:49:34 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Lee", "Kahyun", ""], ["Dobbins", "Nicholas J.", ""], ["McInnes", "Bridget", ""], ["Yetisgen", "Meliha", ""], ["Uzuner", "\u00d6zlem", ""]]}, {"id": "2102.08557", "submitter": "Rajagopal Venkatesaramani", "authors": "Rajagopal Venkatesaramani, Bradley A. Malin, Yevgeniy Vorobeychik", "title": "Re-identification of Individuals in Genomic Datasets Using Public Face\n  Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  DNA sequencing is becoming increasingly commonplace, both in medical and\ndirect-to-consumer settings. To promote discovery, collected genomic data is\noften de-identified and shared, either in public repositories, such as OpenSNP,\nor with researchers through access-controlled repositories. However, recent\nstudies have suggested that genomic data can be effectively matched to\nhigh-resolution three-dimensional face images, which raises a concern that the\nincreasingly ubiquitous public face images can be linked to shared genomic\ndata, thereby re-identifying individuals in the genomic data. While these\ninvestigations illustrate the possibility of such an attack, they assume that\nthose performing the linkage have access to extremely well-curated data. Given\nthat this is unlikely to be the case in practice, it calls into question the\npragmatic nature of the attack. As such, we systematically study this\nre-identification risk from two perspectives: first, we investigate how\nsuccessful such linkage attacks can be when real face images are used, and\nsecond, we consider how we can empower individuals to have better control over\nthe associated re-identification risk. We observe that the true risk of\nre-identification is likely substantially smaller for most individuals than\nprior literature suggests. In addition, we demonstrate that the addition of a\nsmall amount of carefully crafted noise to images can enable a controlled\ntrade-off between re-identification success and the quality of shared images,\nwith risk typically significantly lowered even with noise that is imperceptible\nto humans.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 03:54:25 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Venkatesaramani", "Rajagopal", ""], ["Malin", "Bradley A.", ""], ["Vorobeychik", "Yevgeniy", ""]]}, {"id": "2102.08598", "submitter": "Terrance Liu", "authors": "Terrance Liu, Giuseppe Vietri, Thomas Steinke, Jonathan Ullman, Zhiwei\n  Steven Wu", "title": "Leveraging Public Data for Practical Private Query Release", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many statistical problems, incorporating priors can significantly improve\nperformance. However, the use of prior knowledge in differentially private\nquery release has remained underexplored, despite such priors commonly being\navailable in the form of public datasets, such as previous US Census releases.\nWith the goal of releasing statistics about a private dataset, we present\nPMW^Pub, which -- unlike existing baselines -- leverages public data drawn from\na related distribution as prior information. We provide a theoretical analysis\nand an empirical evaluation on the American Community Survey (ACS) and ADULT\ndatasets, which shows that our method outperforms state-of-the-art methods.\nFurthermore, PMW^Pub scales well to high-dimensional data domains, where\nrunning many existing methods would be computationally infeasible.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 06:19:34 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 03:13:22 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Liu", "Terrance", ""], ["Vietri", "Giuseppe", ""], ["Steinke", "Thomas", ""], ["Ullman", "Jonathan", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "2102.08779", "submitter": "Emmanouil Papadogiannakis", "authors": "Emmanouil Papadogiannakis, Panagiotis Papadopoulos, Nicolas Kourtellis\n  and Evangelos P. Markatos", "title": "User Tracking in the Post-cookie Era: How Websites Bypass GDPR Consent\n  to Track Users", "comments": "12 pages, To be published at The Web Conference 2021 (WWW 2021).\n  Please cite the WWW version", "journal-ref": null, "doi": "10.1145/3442381.3450056", "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  During the past few years, mostly as a result of the GDPR and the CCPA,\nwebsites have started to present users with cookie consent banners. These\nbanners are web forms where the users can state their preference and declare\nwhich cookies they would like to accept, if such option exists. Although\nrequesting consent before storing any identifiable information is a good start\ntowards respecting the user privacy, yet previous research has shown that\nwebsites do not always respect user choices. Furthermore, considering the ever\ndecreasing reliance of trackers on cookies and actions browser vendors take by\nblocking or restricting third-party cookies, we anticipate a world where\nstateless tracking emerges, either because trackers or websites do not use\ncookies, or because users simply refuse to accept any.\n  In this paper, we explore whether websites use more persistent and\nsophisticated forms of tracking in order to track users who said they do not\nwant cookies. Such forms of tracking include first-party ID leaking, ID\nsynchronization, and browser fingerprinting. Our results suggest that websites\ndo use such modern forms of tracking even before users had the opportunity to\nregister their choice with respect to cookies. To add insult to injury, when\nusers choose to raise their voice and reject all cookies, user tracking only\nintensifies. As a result, users' choices play very little role with respect to\ntracking: we measured that more than 75% of tracking activities happened before\nusers had the opportunity to make a selection in the cookie consent banner, or\nwhen users chose to reject all cookies.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 14:11:10 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Papadogiannakis", "Emmanouil", ""], ["Papadopoulos", "Panagiotis", ""], ["Kourtellis", "Nicolas", ""], ["Markatos", "Evangelos P.", ""]]}, {"id": "2102.08780", "submitter": "Prajwol Nakarmi", "authors": "Prajwol Kumar Nakarmi, Mehmet Akif Ersoy, Elif Ustundag Soykan, Karl\n  Norrman", "title": "Murat: Multi-RAT False Base Station Detector", "comments": "13 pages, 12 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there has been an increasing interest in false base station\ndetection systems. Most of these rely on software that users download into\ntheir mobile phones. The software either performs an analysis of radio\nenvironment measurements taken by the mobile phone or reports these\nmeasurements to a server on the Internet, which then analyzes the aggregated\nmeasurements collected from many mobile phones. These systems suffer from two\nmain drawbacks. First, they require modification to the mobile phones in the\nform of software and an active decision to participate from users. This\nseverely limits the number of obtained measurements. Second, they do not make\nuse of the information the mobile network has regarding network topology and\nconfiguration. This results in less reliable predictions than could be made. We\npresent a network-based system for detecting false base stations that operate\non any 3GPP radio access technology, without requiring modifications to mobile\nphones, and that allows taking full advantage of network topology and\nconfiguration information available to an operator. The analysis is performed\nby the mobile network based on measurement reports delivered by mobile phones\nas part of normal operations to maintain the wireless link. We implemented and\nvalidated the system in a lab experiment and a real operator trial. Our\napproach was adopted by the 3GPP standardization organization.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 14:11:38 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Nakarmi", "Prajwol Kumar", ""], ["Ersoy", "Mehmet Akif", ""], ["Soykan", "Elif Ustundag", ""], ["Norrman", "Karl", ""]]}, {"id": "2102.08788", "submitter": "Ali Burak \\\"Unal", "authors": "Ali Burak \\\"Unal, Nico Pfeifer, Mete Akg\\\"un", "title": "ppAURORA: Privacy Preserving Area Under Receiver Operating\n  Characteristic and Precision-Recall Curves with Secure 3-Party Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computing an AUC as a performance measure to compare the quality of different\nmachine learning models is one of the final steps of many research projects.\nMany of these methods are trained on privacy-sensitive data and there are\nseveral different approaches like $\\epsilon$-differential privacy, federated\nmachine learning and methods based on cryptographic approaches if the datasets\ncannot be shared or evaluated jointly at one place. In this setting, it can\nalso be a problem to compute the global performance measure like an AUC, since\nthe labels might also contain privacy-sensitive information. There have been\napproaches based on $\\epsilon$-differential privacy to deal with this problem,\nbut to the best of our knowledge, no exact privacy preserving solution has been\nintroduced. In this paper, we propose an MPC-based framework, called \\fw{},\nwith private merging of sorted lists and novel methods for comparing two\nsecret-shared values, selecting between two secret-shared values, converting\nthe modulus, and performing division to compute the exact AUC as one could\nobtain on the pooled original test samples. With \\fw{} computation of the exact\narea under precision-recall curve and receiver operating characteristic curve\nis even possible when ties between prediction confidence values exist. To show\nthe applicability of \\fw{}, we use it to evaluate a model trained to predict\nacute myeloid leukemia therapy response and we also assess its scalability via\nexperiments on synthetic data. The experiments show that we efficiently compute\nexactly the same AUC with both evaluation metrics in a privacy preserving\nmanner as one can obtain on the pooled test samples in the plaintext domain.\nOur solution provides security against semi-honest corruption of at most one of\nthe servers performing the secure computation.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 14:30:22 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 12:17:28 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["\u00dcnal", "Ali Burak", ""], ["Pfeifer", "Nico", ""], ["Akg\u00fcn", "Mete", ""]]}, {"id": "2102.08804", "submitter": "Carlton Shepherd", "authors": "Carlton Shepherd, Konstantinos Markantonakis, Georges-Axel Jaloyan", "title": "LIRA-V: Lightweight Remote Attestation for Constrained RISC-V Devices", "comments": "Accepted at IEEE SafeThings (in conjunction with IEEE Security &\n  Privacy '21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents LIRA-V, a lightweight system for performing remote\nattestation between constrained devices using the RISC-V architecture. We\npropose using read-only memory and the RISC-V Physical Memory Protection (PMP)\nprimitive to build a trust anchor for remote attestation and secure channel\ncreation. Moreover, we show how LIRA-V can be used for trusted communication\nbetween two devices using mutual attestation. We present the design,\nimplementation and evaluation of LIRA-V using an off-the-shelf RISC-V\nmicrocontroller and present performance results to demonstrate its suitability.\nTo our knowledge, we present the first remote attestation mechanism suitable\nfor constrained RISC-V devices, with applications to cyber-physical systems and\nInternet of Things (IoT) devices.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 15:04:29 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 17:45:26 GMT"}, {"version": "v3", "created": "Thu, 11 Mar 2021 14:20:16 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Shepherd", "Carlton", ""], ["Markantonakis", "Konstantinos", ""], ["Jaloyan", "Georges-Axel", ""]]}, {"id": "2102.08847", "submitter": "Joerg Drechsler", "authors": "Joerg Drechsler", "title": "Differential Privacy for Government Agencies -- Are We There Yet?", "comments": "41 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.OT", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Government agencies always need to carefully consider potential risks of\ndisclosure whenever they publish statistics based on their data or give\nexternal researchers access to the collected data. For this reason, research on\ndisclosure avoiding techniques has a long tradition at statistical agencies. In\nthis context, the promise of formal privacy guarantees offered by concepts such\nas differential privacy seem to be the panacea enabling the agencies to exactly\nquantify and control the privacy loss incurred by any data release. Still,\ndespite the excitement in academia and industry, most agencies-with the\nprominent exception of the U.S. Census Bureau-have been reluctant to even\nconsider the concept for their data release strategy.\n  This paper aims to shed some light on potential reasons for this. We argue\nthat the requirements when implementing differential privacy approaches at\ngovernment agencies are often fundamentally different from the requirements in\nindustry. This raises many challenging problems and open questions that still\nneed to be addressed before the concept might be used as an overarching\nprinciple when sharing data with the public. The paper will not offer any\nsolutions to these challenges. Instead, we hope to stimulate some collaborative\nresearch efforts, as we believe that many of the problems can only be addressed\nby inter-disciplinary collaborations.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 16:13:09 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Drechsler", "Joerg", ""]]}, {"id": "2102.08866", "submitter": "Kahraman Kostas Mr", "authors": "Kahraman Kostas, Mike Just, Michael A. Lones", "title": "IoTDevID: A Behaviour-Based Fingerprinting Method for Device\n  Identification in the IoT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Device identification is one way to secure a network of IoT devices, whereby\ndevices identified as suspicious can subsequently be isolated from a network.\nWe introduce a novel fingerprinting method, IoTDevID, for device identification\nthat uses machine learning to model the behaviour of IoT devices based on\nnetwork packets. Our method uses an enhanced combination of features from\nprevious work and includes an approach for dealing with unbalanced device data\nvia data augmentation. We further demonstrate how to enhance device\nidentification via a group-wise data aggregation. We provide a comparative\nevaluation of our method against two recent identification methods using three\npublic IoT datasets which together contain data from over 100 devices. Through\nour evaluation we demonstrate improved performance over previous results with\nF1-scores above 99%, with considerable improvement gained from data\naggregation.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 16:50:25 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Kostas", "Kahraman", ""], ["Just", "Mike", ""], ["Lones", "Michael A.", ""]]}, {"id": "2102.08885", "submitter": "Marek Eli\\'a\\v{s}", "authors": "Mark Bun, Marek Eli\\'a\\v{s}, Janardhan Kulkarni", "title": "Differentially Private Correlation Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Correlation clustering is a widely used technique in unsupervised machine\nlearning. Motivated by applications where individual privacy is a concern, we\ninitiate the study of differentially private correlation clustering. We propose\nan algorithm that achieves subquadratic additive error compared to the optimal\ncost. In contrast, straightforward adaptations of existing non-private\nalgorithms all lead to a trivial quadratic error. Finally, we give a lower\nbound showing that any pure differentially private algorithm for correlation\nclustering requires additive error of $\\Omega(n)$.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 17:27:48 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Bun", "Mark", ""], ["Eli\u00e1\u0161", "Marek", ""], ["Kulkarni", "Janardhan", ""]]}, {"id": "2102.08896", "submitter": "Arvind Kiwelekar", "authors": "Arvind W. Kiwelekar, Pramod Patil, Laxman D. Netak, Sanjay U Waikar", "title": "Blockchain-based Security Services for Fog Computing", "comments": "This is a pre-print of the following Chapter: Arvind W. Kiwelekar,\n  Pramod Patil Laxman D. Netak and Sanjay U Waikar, {\\em Blockchain-Based\n  Security Services for Fog Computing} accepted and final version is published\n  in Chang W., Wu J. (eds) Fog/Edge Computing For Security, Privacy, and\n  Applications. Advances in Information Security, vol 83. Springer", "journal-ref": null, "doi": "10.1007/978-3-030-57328-7_11", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fog computing is a paradigm for distributed computing that enables sharing of\nresources such as computing, storage and network services. Unlike cloud\ncomputing, fog computing platforms primarily support {\\em non-functional\nproperties} such as location awareness, mobility and reduced latency. This\nemerging paradigm has many potential applications in domains such as smart\ngrids, smart cities, and transport management.\n  Most of these domains collect and monitor personal information through edge\ndevices to offer personalized services. A {\\em centralized} server either at\nthe level of cloud or fog, has been found ineffective to provide a high degree\nof security and privacy-preserving services.\n  Blockchain technology supports the development of {\\em decentralized}\napplications designed around the principles of immutability, cryptography,\nconsistency preserving consensus protocols and smart contracts. Hence\nblockchain technology has emerged as a preferred technology in recent times to\nbuild trustworthy distributed applications.\n  The chapter describes the potential of blockchain technology to realize\nsecurity services such as authentication, secured communication, availability,\nprivacy and trust management to support the development of dependable fog\nservices.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 08:26:20 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Kiwelekar", "Arvind W.", ""], ["Patil", "Pramod", ""], ["Netak", "Laxman D.", ""], ["Waikar", "Sanjay U", ""]]}, {"id": "2102.08985", "submitter": "Chuadhry Mujeeb Ahmed", "authors": "Chuadhry Mujeeb Ahmed, Martin Ochoa, Jianying Zhou and Aditya Mathur", "title": "Scanning the Cycle: Timing-based Authentication on PLCs", "comments": "To appear in ACM AsiaCCS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Programmable Logic Controllers (PLCs) are a core component of an Industrial\nControl System (ICS). However, if a PLC is compromised or the commands sent\nacross a network from the PLCs are spoofed, consequences could be catastrophic.\nIn this work, a novel technique to authenticate PLCs is proposed that aims at\nraising the bar against powerful attackers while being compatible with\nreal-time systems. The proposed technique captures timing information for each\ncontroller in a non-invasive manner. It is argued that Scan Cycle is a unique\nfeature of a PLC that can be approximated passively by observing network\ntraffic. An attacker that spoofs commands issued by the PLCs would deviate from\nsuch fingerprints. To detect replay attacks a PLC Watermarking technique is\nproposed. PLC Watermarking models the relationship between the scan cycle and\nthe control logic by modeling the input/output as a function of\nrequest/response messages of a PLC. The proposed technique is validated on an\noperational water treatment plant (SWaT) and smart grid (EPIC) testbed. Results\nfrom experiments indicate that PLCs can be distinguished based on their scan\ncycle timing characteristics.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 19:26:07 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Ahmed", "Chuadhry Mujeeb", ""], ["Ochoa", "Martin", ""], ["Zhou", "Jianying", ""], ["Mathur", "Aditya", ""]]}, {"id": "2102.09057", "submitter": "Jiangnan Li", "authors": "Jiangnan Li, Yingyuan Yang, Jinyuan Stella Sun, Kevin Tomsovic,\n  Hairong Qi", "title": "Towards Adversarial-Resilient Deep Neural Networks for False Data\n  Injection Attack Detection in Power Grids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  False data injection attack (FDIA) is a critical security issue in power\nsystem state estimation. In recent years, machine learning (ML) techniques,\nespecially deep neural networks (DNNs), have been proposed in the literature\nfor FDIA detection. However, they have not considered the risk of adversarial\nattacks, which were shown to be threatening to DNN's reliability in different\nML applications. In this paper, we evaluate the vulnerability of DNNs used for\nFDIA detection through adversarial attacks and study the defensive approaches.\nWe analyze several representative adversarial defense mechanisms and\ndemonstrate that they have intrinsic limitations in FDIA detection. We then\ndesign an adversarial-resilient DNN detection framework for FDIA by introducing\nrandom input padding in both the training and inference phases. Extensive\nsimulations based on an IEEE standard power system show that our framework\ngreatly reduces the effectiveness of adversarial attacks while having little\nimpact on the detection performance of the DNNs.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 22:26:34 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Li", "Jiangnan", ""], ["Yang", "Yingyuan", ""], ["Sun", "Jinyuan Stella", ""], ["Tomsovic", "Kevin", ""], ["Qi", "Hairong", ""]]}, {"id": "2102.09149", "submitter": "Takashi Yamakawa", "authors": "Tomoyuki Morimae and Takashi Yamakawa", "title": "Classically Verifiable (Dual-Mode) NIZK for QMA with Preprocessing", "comments": "46 pages This is a major update version of arXiv:2003.10712", "journal-ref": null, "doi": null, "report-no": "YITP-21-10", "categories": "quant-ph cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose three constructions of classically verifiable non-interactive\nproofs (CV-NIP) and non-interactive zero-knowledge proofs and arguments\n(CV-NIZK) for QMA in various preprocessing models.\n  - We construct an information theoretically sound CV-NIP for QMA in the\nsecret parameter model where a trusted party generates a quantum proving key\nand classical verification key and gives them to the corresponding parties\nwhile keeping it secret from the other party. Alternatively, we can think of\nthe protocol as one in a model where the verifier sends an instance-independent\nquantum message to the prover as preprocessing.\n  - We construct a CV-NIZK for QMA in the secret parameter model. It is\ninformation theoretically sound and zero-knowledge.\n  - Assuming the quantum hardness of the leaning with errors problem, we\nconstruct a CV-NIZK for QMA in a model where a trusted party generates a CRS\nand the verifier sends an instance-independent quantum message to the prover as\npreprocessing. This model is the same as one considered in the recent work by\nColadangelo, Vidick, and Zhang (CRYPTO '20). Our construction has the so-called\ndual-mode property, which means that there are two computationally\nindistinguishable modes of generating CRS, and we have information theoretical\nsoundness in one mode and information theoretical zero-knowledge property in\nthe other. This answers an open problem left by Coladangelo et al, which is to\nachieve either of soundness or zero-knowledge information theoretically. To the\nbest of our knowledge, ours is the first dual-mode NIZK for QMA in any kind of\nmodel.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 04:10:00 GMT"}, {"version": "v2", "created": "Sun, 16 May 2021 09:12:34 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Morimae", "Tomoyuki", ""], ["Yamakawa", "Takashi", ""]]}, {"id": "2102.09159", "submitter": "Sewoong Oh", "authors": "Xiyang Liu, Weihao Kong, Sham Kakade, and Sewoong Oh", "title": "Robust and Differentially Private Mean Estimation", "comments": "55 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IT math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Differential privacy has emerged as a standard requirement in a variety of\napplications ranging from the U.S. Census to data collected in commercial\ndevices, initiating an extensive line of research in accurately and privately\nreleasing statistics of a database. An increasing number of such databases\nconsist of data from multiple sources, not all of which can be trusted. This\nleaves existing private analyses vulnerable to attacks by an adversary who\ninjects corrupted data. Despite the significance of designing algorithms that\nguarantee privacy and robustness (to a fraction of data being corrupted)\nsimultaneously, even the simplest questions remain open. For the canonical\nproblem of estimating the mean from i.i.d. samples, we introduce the first\nefficient algorithm that achieves both privacy and robustness for a wide range\nof distributions. This achieves optimal accuracy matching the known lower\nbounds for robustness, but the sample complexity has a factor of $d^{1/2}$ gap\nfrom known lower bounds. We further show that this gap is due to the\ncomputational efficiency; we introduce the first family of algorithms that\nclose this gap but takes exponential time. The innovation is in exploiting\nresilience (a key property in robust estimation) to adaptively bound the\nsensitivity and improve privacy.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 05:02:49 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Liu", "Xiyang", ""], ["Kong", "Weihao", ""], ["Kakade", "Sham", ""], ["Oh", "Sewoong", ""]]}, {"id": "2102.09171", "submitter": "Minghong Fang", "authors": "Minghong Fang, Minghao Sun, Qi Li, Neil Zhenqiang Gong, Jin Tian, Jia\n  Liu", "title": "Data Poisoning Attacks and Defenses to Crowdsourcing Systems", "comments": "To appear in the Web Conference 2021 (WWW '21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge of big data analytics is how to collect a large volume of\n(labeled) data. Crowdsourcing aims to address this challenge via aggregating\nand estimating high-quality data (e.g., sentiment label for text) from\npervasive clients/users. Existing studies on crowdsourcing focus on designing\nnew methods to improve the aggregated data quality from unreliable/noisy\nclients. However, the security aspects of such crowdsourcing systems remain\nunder-explored to date. We aim to bridge this gap in this work. Specifically,\nwe show that crowdsourcing is vulnerable to data poisoning attacks, in which\nmalicious clients provide carefully crafted data to corrupt the aggregated\ndata. We formulate our proposed data poisoning attacks as an optimization\nproblem that maximizes the error of the aggregated data. Our evaluation results\non one synthetic and two real-world benchmark datasets demonstrate that the\nproposed attacks can substantially increase the estimation errors of the\naggregated data. We also propose two defenses to reduce the impact of malicious\nclients. Our empirical results show that the proposed defenses can\nsubstantially reduce the estimation errors of the data poisoning attacks.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 06:03:48 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 23:10:31 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Fang", "Minghong", ""], ["Sun", "Minghao", ""], ["Li", "Qi", ""], ["Gong", "Neil Zhenqiang", ""], ["Tian", "Jin", ""], ["Liu", "Jia", ""]]}, {"id": "2102.09173", "submitter": "Ngoc Tran", "authors": "Quang Pham Huu, Thoi Hoang Dinh, Ngoc N. Tran, Toan Pham Van and Thanh\n  Ta Minh", "title": "Deep Neural Networks based Invisible Steganography for Audio-into-Image\n  Algorithm", "comments": "Published in 2019 IEEE 8th Global Conference on Consumer Electronics\n  (GCCE)", "journal-ref": "2019 IEEE 8th Global Conference on Consumer Electronics (GCCE),\n  Osaka, Japan, 2019, pp. 423-427", "doi": "10.1109/GCCE46687.2019.9015498", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In the last few years, steganography has attracted increasing attention from\na large number of researchers since its applications are expanding further than\njust the field of information security. The most traditional method is based on\ndigital signal processing, such as least significant bit encoding. Recently,\nthere have been some new approaches employing deep learning to address the\nproblem of steganography. However, most of the existing approaches are designed\nfor image-in-image steganography. In this paper, the use of deep learning\ntechniques to hide secret audio into the digital images is proposed. We employ\na joint deep neural network architecture consisting of two sub-models: the\nfirst network hides the secret audio into an image, and the second one is\nresponsible for decoding the image to obtain the original audio. Extensive\nexperiments are conducted with a set of 24K images and the VIVOS Corpus audio\ndataset. Through experimental results, it can be seen that our method is more\neffective than traditional approaches. The integrity of both image and audio is\nwell preserved, while the maximum length of the hidden audio is significantly\nimproved.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 06:13:05 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Huu", "Quang Pham", ""], ["Dinh", "Thoi Hoang", ""], ["Tran", "Ngoc N.", ""], ["Van", "Toan Pham", ""], ["Minh", "Thanh Ta", ""]]}, {"id": "2102.09258", "submitter": "Marta Gomez-Barrero", "authors": "Marta Gomez-Barrero, Pawel Drozdowski, Christian Rathgeb, Jose Patino,\n  Massimmiliano Todisco, Andras Nautsch, Naser Damer, Jannis Priesnitz,\n  Nicholas Evans, Christoph Busch", "title": "Biometrics in the Era of COVID-19: Challenges and Opportunities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.CV cs.HC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Since early 2020 the COVID-19 pandemic has had a considerable impact on many\naspects of daily life. A range of different measures have been implemented\nworldwide to reduce the rate of new infections and to manage the pressure on\nnational health services. A primary strategy has been to reduce gatherings and\nthe potential for transmission through the prioritisation of remote working and\neducation. Enhanced hand hygiene and the use of facial masks have decreased the\nspread of pathogens when gatherings are unavoidable. These particular measures\npresent challenges for reliable biometric recognition, e.g. for facial-, voice-\nand hand-based biometrics. At the same time, new challenges create new\nopportunities and research directions, e.g. renewed interest in non-constrained\niris or periocular recognition, touch-less fingerprint- and vein-based\nauthentication and the use of biometric characteristics for disease detection.\nThis article presents an overview of the research carried out to address those\nchallenges and emerging opportunities.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 10:32:59 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Gomez-Barrero", "Marta", ""], ["Drozdowski", "Pawel", ""], ["Rathgeb", "Christian", ""], ["Patino", "Jose", ""], ["Todisco", "Massimmiliano", ""], ["Nautsch", "Andras", ""], ["Damer", "Naser", ""], ["Priesnitz", "Jannis", ""], ["Evans", "Nicholas", ""], ["Busch", "Christoph", ""]]}, {"id": "2102.09301", "submitter": "Yana Dimova", "authors": "Yana Dimova, Gunes Acar, Lukasz Olejnik, Wouter Joosen, Tom Van\n  Goethem", "title": "The CNAME of the Game: Large-scale Analysis of DNS-based Tracking\n  Evasion", "comments": "To be published in PETS 2021. 21 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Online tracking is a whack-a-mole game between trackers who build and\nmonetize behavioral user profiles through intrusive data collection, and\nanti-tracking mechanisms, deployed as a browser extension, built-in to the\nbrowser, or as a DNS resolver. As a response to pervasive and opaque online\ntracking, more and more users adopt anti-tracking tools to preserve their\nprivacy. Consequently, as the information that trackers can gather on users is\nbeing curbed, some trackers are looking for ways to evade these tracking\ncountermeasures. In this paper we report on a large-scale longitudinal\nevaluation of an anti-tracking evasion scheme that leverages CNAME records to\ninclude tracker resources in a same-site context, effectively bypassing\nanti-tracking measures that use fixed hostname-based block lists. Using\nhistorical HTTP Archive data we find that this tracking scheme is rapidly\ngaining traction, especially among high-traffic websites. Furthermore, we\nreport on several privacy and security issues inherent to the technical setup\nof CNAME-based tracking that we detected through a combination of automated and\nmanual analyses. We find that some trackers are using the technique against the\nSafari browser, which is known to include strict anti-tracking configurations.\nOur findings show that websites using CNAME trackers must take extra\nprecautions to avoid leaking sensitive information to third parties.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 12:20:23 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 13:46:05 GMT"}, {"version": "v3", "created": "Fri, 5 Mar 2021 13:30:43 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Dimova", "Yana", ""], ["Acar", "Gunes", ""], ["Olejnik", "Lukasz", ""], ["Joosen", "Wouter", ""], ["Van Goethem", "Tom", ""]]}, {"id": "2102.09429", "submitter": "G\\\"unther Eibl", "authors": "G\\\"unther Eibl (1), Sanaz Taheri-Boshrooyeh (2), Alptekin\n  K\\\"up\\c{c}\\\"u (3) ((1) Center for Secure Energy Informatics, Salzburg\n  University of Applied Sciences, (2) Work partly done at Ko\\c{c} University,\n  (3) Cryptography, Security and Privacy Research Group, Ko\\c{c} University)", "title": "AggFT: Low-Cost Fault-Tolerant Smart Meter Aggregation with Proven\n  Termination and Privacy", "comments": "This work is the long preprint indluding full proofs of a paper that\n  will be submitted to the IEEE for possible publication. It is intended for\n  reviewers that would like to check the proofs in detail. Copyright may be\n  transferred without notice, after which this version may no longer be\n  accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Smart meter data aggregation protocols have been developed to address rising\nprivacy threats against customers' consumption data. However, these protocols\ndo not work satisfactorily in the presence of failures of smart meters or\nnetwork communication links. In this paper, we propose a lightweight and\nfault-tolerant aggregation algorithm that can serve as a solid foundation for\nfurther research. We revisit an existing error-resilient privacy-preserving\naggregation protocol based on masking and improve it by: (i) performing changes\nin the cryptographic parts that lead to a reduction of computational costs,\n(ii) simplifying the behaviour of the protocol in the presence of faults, and\nshowing a proof of proper termination under a well-defined failure model, (iii)\ndecoupling the computation part from the data flow so that the algorithm can\nalso be used with homomorphic encryption as a basis for privacy-preservation.\nTo best of our knowledge, this is the first algorithm that is formulated for\nboth, masking and homomorphic encryption. (iv) Finally, we provide a formal\nproof of the privacy guarantee under failure. The systematic treatment with\nstrict proofs and the established connection to graph theory may also serve as\na starting point for possible generalizations and improvements with respect to\nincreased resilience.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 15:43:12 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Eibl", "G\u00fcnther", ""], ["Taheri-Boshrooyeh", "Sanaz", ""], ["K\u00fcp\u00e7\u00fc", "Alptekin", ""]]}, {"id": "2102.09435", "submitter": "Alexander Barabanov", "authors": "Alexander Barabanov, Denis Makrushin", "title": "Security audit logging in microservice-based systems: survey of\n  architecture patterns", "comments": "The work was done in Advanced Software Technology Laboratory, Huawei.\n  It is planned to be published in \"Voprosy kiberbezopasnosti\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Objective. Service-oriented architecture increases technical abilities for\nattacker to move laterally and maintain multiple pivot points inside of\ncompromised environment. Microservice-based infrastructure brings more\nchallenges for security architect related to internal event visibility and\nmonitoring. Properly implemented logging and audit approach is a baseline for\nsecurity operations and incident management. The aim of this study is to\nprovide helpful resource to application and product security architects,\nsoftware and operation engineers on existing architecture patterns to implement\ntrustworthy logging and audit process in microservice-based environments.\nMethod. In this paper, we conduct information security threats modeling and a\nsystematic review of major electronic databases and libraries, security\nstandards and presentations at the major security conferences as well as\narchitecture whitepapers of industry vendors with relevant products. Results\nand practical relevance. In this work based on research papers and major\nsecurity conferences presentations analysis, we identified industry best\npractices in logging audit patterns and its applicability depending on\nenvironment characteristic. We provided threat modeling for typical\narchitecture pattern of logging system and identified 8 information security\nthreats. We provided security threat mitigation and as a result of 11\nhigh-level security requirements for audit logging system were identified.\nHigh-level security requirements can be used by application security architect\nin order to secure their products.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 15:51:31 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Barabanov", "Alexander", ""], ["Makrushin", "Denis", ""]]}, {"id": "2102.09455", "submitter": "Alexander Kott", "authors": "Alexander Kott, Igor Linkov", "title": "To Improve Cyber Resilience, Measure It", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We are not very good at measuring -- rigorously and quantitatively -- the\ncyber security of systems. Our ability to measure cyber resilience is even\nworse. And without measuring cyber resilience, we can neither improve it nor\ntrust its efficacy. It is difficult to know if we are improving or degrading\ncyber resilience when we add another control, or a mix of controls, to harden\nthe system. The only way to know is to specifically measure cyber resilience\nwith and without a particular set of controls. What needs to be measured are\ntemporal patterns of recovery and adaptation, and not time-independent failure\nprobabilities. In this paper, we offer a set of criteria that would ensure\ndecision-maker confidence in the reliability of the methodology used in\nobtaining a meaningful measurement.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 16:20:17 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Kott", "Alexander", ""], ["Linkov", "Igor", ""]]}, {"id": "2102.09458", "submitter": "Khadija Hafeez", "authors": "Khadija Hafeez, Mubashir Husain Rehmani, Donna OShea", "title": "DPNCT: A Differential Private Noise Cancellation Scheme for Load\n  Monitoring and Billing for Smart Meters", "comments": "Accepted in IEEE International Conference on Communications (ICC)\n  2021 - Workshop on Communication, Computing, and Networking in Cyber-Physical\n  Systems (IEEE CCN-CPS 2021), Montreal, Canada, June 2021, 6 pages, 3 figures,\n  3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Highly accurate profiles of consumers daily energy usage are reported to\npower grid via smart meters which enables smart grid to effectively regulate\npower demand and supply. However, consumers energy consumption pattern can\nreveal personal and sensitive information regarding their lifestyle. Therefore,\nto ensure users privacy, differentially distributed noise is added to the\noriginal data. This technique comes with a trade off between privacy of the\nconsumer versus utility of the data in terms of providing services like\nbilling, Demand Response schemes, and Load Monitoring. In this paper, we\npropose a technique - Differential Privacy with Noise Cancellation Technique\n(DPNCT) - to maximize utility in aggregated load monitoring and fair billing\nwhile preserving users privacy by using noise cancellation mechanism on\ndifferentially private data. We introduce noise to the sensitive data stream\nbefore it leaves smart meters in order to guarantee privacy at individual\nlevel. Further, we evaluate the effects of different periodic noise cancelling\nschemes on privacy and utility i.e., billing and load monitoring. Our proposed\nscheme outperforms the existing scheme in terms of preserving the privacy while\naccurately calculating the bill.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 16:22:12 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 17:02:17 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Hafeez", "Khadija", ""], ["Rehmani", "Mubashir Husain", ""], ["OShea", "Donna", ""]]}, {"id": "2102.09499", "submitter": "Rohit Singh Dr.", "authors": "Yasasvi Hari, Rohit Singh, Kizito Nyuytiymbiy, David Butera", "title": "Consenting to Internet of Things Across Different Social Settings", "comments": "9 pages, 6 figures, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Devices connected to the Internet of Things (IoT) are rapidly becoming\nubiquitous across modern homes, workplaces, and other social environments.\nWhile these devices provide users with extensive functionality, they pose\nsignificant privacy concerns due to difficulties in consenting to these\ndevices. In this work, we present the results of a pilot study that shows how\nusers consent to devices in common locations at a friends house in which the\nuser is a guest attending a party. We use this pilot study to indicate a\ndirection for a larger study, which will capture a more granular understanding\nof how users will consent to a variety of devices placed in different social\nsettings (i.e. a party house owned by a friend, an office space for the user\nand some 40 other employees, the bathroom of a department store). Our final\ncontribution of this work will be to build a probability distribution which\nwill indicate how probable a given user is to consent to a device given what\nsensors it has, where it is, and the awareness and preferences of each user.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 17:29:39 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Hari", "Yasasvi", ""], ["Singh", "Rohit", ""], ["Nyuytiymbiy", "Kizito", ""], ["Butera", "David", ""]]}, {"id": "2102.09599", "submitter": "Parham Gohari", "authors": "Parham Gohari, Bo Chen, Bo Wu, Matthew Hale, and Ufuk Topcu", "title": "Privacy-Preserving Kickstarting Deep Reinforcement Learning with\n  Privacy-Aware Learners", "comments": "Under double-blind review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kickstarting deep reinforcement learning algorithms facilitate a\nteacher-student relationship among the agents and allow for a well-performing\nteacher to share demonstrations with a student to expedite the student's\ntraining. However, despite the known benefits, the demonstrations may contain\nsensitive information about the teacher's training data and existing\nkickstarting methods do not take any measures to protect it. Therefore, we use\nthe framework of differential privacy to develop a mechanism that securely\nshares the teacher's demonstrations with the student. The mechanism allows for\nthe teacher to decide upon the accuracy of its demonstrations with respect to\nthe privacy budget that it consumes, thereby granting the teacher full control\nover its data privacy. We then develop a kickstarted deep reinforcement\nlearning algorithm for the student that is privacy-aware because we calibrate\nits objective with the parameters of the teacher's privacy mechanism. The\nprivacy-aware design of the algorithm makes it possible to kickstart the\nstudent's learning despite the perturbations induced by the privacy mechanism.\nFrom numerical experiments, we highlight three empirical results: (i) the\nalgorithm succeeds in expediting the student's learning, (ii) the student\nconverges to a performance level that was not possible without the\ndemonstrations, and (iii) the student maintains its enhanced performance even\nafter the teacher stops sharing useful demonstrations due to its privacy budget\nconstraints.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 20:15:09 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 20:47:39 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Gohari", "Parham", ""], ["Chen", "Bo", ""], ["Wu", "Bo", ""], ["Hale", "Matthew", ""], ["Topcu", "Ufuk", ""]]}, {"id": "2102.09604", "submitter": "Timour Igamberdiev", "authors": "Timour Igamberdiev and Ivan Habernal", "title": "Privacy-Preserving Graph Convolutional Networks for Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Graph convolutional networks (GCNs) are a powerful architecture for\nrepresentation learning on documents that naturally occur as graphs, e.g.,\ncitation or social networks. However, sensitive personal information, such as\ndocuments with people's profiles or relationships as edges, are prone to\nprivacy leaks, as the trained model might reveal the original input. Although\ndifferential privacy (DP) offers a well-founded privacy-preserving framework,\nGCNs pose theoretical and practical challenges due to their training specifics.\nWe address these challenges by adapting differentially-private gradient-based\ntraining to GCNs and conduct experiments using two optimizers on five NLP\ndatasets in two languages. We propose a simple yet efficient method based on\nrandom graph splits that not only improves the baseline privacy bounds by a\nfactor of 2.7 while retaining competitive F1 scores, but also provides strong\nprivacy guarantees of epsilon = 1.0. We show that, under certain modeling\nchoices, privacy-preserving GCNs perform up to 90% of their non-private\nvariants, while formally guaranteeing strong privacy measures.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 15:27:38 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 14:11:40 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Igamberdiev", "Timour", ""], ["Habernal", "Ivan", ""]]}, {"id": "2102.09651", "submitter": "Simon Oya", "authors": "Zhiwei Shang, Simon Oya, Andreas Peter, Florian Kerschbaum", "title": "Obfuscated Access and Search Patterns in Searchable Encryption", "comments": "To be published at Network and Distributed Systems Security (NDSS)\n  Symposium 2021, 21-24 February 2021, San Diego, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Searchable Symmetric Encryption (SSE) allows a data owner to securely\noutsource its encrypted data to a cloud server while maintaining the ability to\nsearch over it and retrieve matched documents. Most existing SSE schemes leak\nwhich documents are accessed per query, i.e., the so-called access pattern, and\nthus are vulnerable to attacks that can recover the database or the queried\nkeywords. Current techniques that fully hide access patterns, such as ORAM or\nPIR, suffer from heavy communication or computational costs, and are not\ndesigned with search capabilities in mind. Recently, Chen et al. (INFOCOM'18)\nproposed an obfuscation framework for SSE that protects the access pattern in a\ndifferentially private way with a reasonable utility cost. However, this scheme\nleaks the so-called search pattern, i.e., how many times a certain query is\nperformed. This leakage makes the proposal vulnerable to certain database and\nquery recovery attacks.\n  In this paper, we propose OSSE (Obfuscated SSE), an SSE scheme that\nobfuscates the access pattern independently for each query performed. This in\nturn hides the search pattern and makes our scheme resistant against attacks\nthat rely on this leakage. Under certain reasonable assumptions, our scheme has\nsmaller communication overhead than ORAM-based SSE. Furthermore, our scheme\nworks in a single communication round and requires very small constant\nclient-side storage. Our empirical evaluation shows that OSSE is highly\neffective at protecting against different query recovery attacks while keeping\na reasonable utility level. Our protocol provides significantly more protection\nthan the proposal by Chen et al.~against some state-of-the-art attacks, which\ndemonstrates the importance of hiding search patterns in designing effective\nprivacy-preserving SSE schemes.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 22:36:50 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Shang", "Zhiwei", ""], ["Oya", "Simon", ""], ["Peter", "Andreas", ""], ["Kerschbaum", "Florian", ""]]}, {"id": "2102.09674", "submitter": "Berenike Vollmer BVollmer", "authors": "Berenike Vollmer", "title": "NATOs Mission-Critical Space Capabilities under Threat: Cybersecurity\n  Gaps in the Military Space Asset Supply Chain", "comments": "93 pages, 6 Tables, 19 High-Level Interviews; Research collaboration\n  with NATO Cooperative Cyber Defence Centre of Excellence (CCDCOE) Tallinn,\n  Estonia; Keywords: NATO, military, cybersecurity, space, SATCOM, supply\n  chain, intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The North Atlantic Treaty Organizations (NATO) public-private Space Asset\nSupply Chain (SASC) currently exhibits significant cybersecurity gaps. It is\nwell-established that data obtained from space assets is fundamental to NATO,\nas they allow for the facilitation of its missions, self-defence and effective\ndeterrence of its adversaries. Any hostile cyber operation, suspending control\nover a space asset, severely impacts both NATO missions and allied Member\nStates national security. This threat is exacerbated by NATOs mostly\nunregulated cyber SASC. Hence, this thesis answers a twofold research question:\na) What are current cybersecurity gaps along NATOs global SASC; and b) How can\nNATO and its allied Member States gain greater control over such gaps to\nsafeguard the supply of NATO mission-critical information? An ontological field\nstudy is carried out by conducting nineteen semi-structured interviews with\nhigh-level representatives from relevant public, private and academic\norganizations. This research was undertaken in collaboration with the NATO\nCooperative Cyber Defence Centre of Excellence (CCDCOE) in Tallinn, Estonia.\nThis thesis concludes that current cybersecurity gaps along NATOs SASC are\ncaused by cyber vulnerabilities such as legacy systems or the use of\nCommercial-Off-the-Shelf (COTS) technology. Inadequate cyber SASC management is\ncaused by hindrances such as misaligned classification levels and significant\nunderstaffing. On this basis, NATO should consider two major collaboration\ninitiatives: a) Raising Awareness throughout the whole of the NATO system, and\nb) Pushing forward the creation of regulation through a standardized security\nframework on SASC cybersecurity. Doing so would enable NATO and its Member\nStates to recognise cyberthreats to mission-critical data early on along its\ncyber SASC, and thus increase transparency, responsibility, and liability.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 23:45:09 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Vollmer", "Berenike", ""]]}, {"id": "2102.09695", "submitter": "Matthew Ciolino", "authors": "Matthew Ciolino, Josh Kalin, David Noever", "title": "Fortify Machine Learning Production Systems: Detect and Classify\n  Adversarial Attacks", "comments": "5 Pages, 5 Figures, 5 Tables, 17 References, ICMLA 2021, IEEE\n  Conference Format", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Production machine learning systems are consistently under attack by\nadversarial actors. Various deep learning models must be capable of accurately\ndetecting fake or adversarial input while maintaining speed. In this work, we\npropose one piece of the production protection system: detecting an incoming\nadversarial attack and its characteristics. Detecting types of adversarial\nattacks has two primary effects: the underlying model can be trained in a\nstructured manner to be robust from those attacks and the attacks can be\npotentially filtered out in real-time before causing any downstream damage. The\nadversarial image classification space is explored for models commonly used in\ntransfer learning.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 00:47:16 GMT"}, {"version": "v2", "created": "Sat, 20 Mar 2021 19:22:56 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 16:11:30 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Ciolino", "Matthew", ""], ["Kalin", "Josh", ""], ["Noever", "David", ""]]}, {"id": "2102.09751", "submitter": "Birhanu Eshete", "authors": "Ismat Jarin, Birhanu Eshete", "title": "PRICURE: Privacy-Preserving Collaborative Inference in a Multi-Party\n  Setting", "comments": "12 pages, 9 figures, to appear in the proceedings of the 7th ACM\n  International Workshop on Security and Privacy Analytics (IWSPA'21)\n  co-located with ACM CODASPY'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When multiple parties that deal with private data aim for a collaborative\nprediction task such as medical image classification, they are often\nconstrained by data protection regulations and lack of trust among\ncollaborating parties. If done in a privacy-preserving manner, predictive\nanalytics can benefit from the collective prediction capability of multiple\nparties holding complementary datasets on the same machine learning task. This\npaper presents PRICURE, a system that combines complementary strengths of\nsecure multi-party computation (SMPC) and differential privacy (DP) to enable\nprivacy-preserving collaborative prediction among multiple model owners. SMPC\nenables secret-sharing of private models and client inputs with non-colluding\nsecure servers to compute predictions without leaking model parameters and\ninputs. DP masks true prediction results via noisy aggregation so as to deter a\nsemi-honest client who may mount membership inference attacks. We evaluate\nPRICURE on neural networks across four datasets including benchmark medical\nimage classification datasets. Our results suggest PRICURE guarantees privacy\nfor tens of model owners and clients with acceptable accuracy loss. We also\nshow that DP reduces membership inference attack exposure without hurting\naccuracy.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 05:55:53 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Jarin", "Ismat", ""], ["Eshete", "Birhanu", ""]]}, {"id": "2102.09764", "submitter": "Guozhu Meng", "authors": "Dongsong Yu and Guangliang Yang and Guozhu Meng and Xiaorui Gong and\n  Xiu Zhang and Xiaobo Xiang and Xiaoyu Wang and Yue Jiang and Kai Chen and Wei\n  Zou and Wenke Lee and Wenchang Shi", "title": "SEPAL: Towards a Large-scale Analysis of SEAndroid Policy Customization", "comments": "12 pages, 9 figures, accepted by WWW'21", "journal-ref": null, "doi": "10.1145/3442381.3450007", "report-no": null, "categories": "cs.CR cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To investigate the status quo of SEAndroid policy customization, we propose\nSEPAL, a universal tool to automatically retrieve and examine the customized\npolicy rules. SEPAL applies the NLP technique and employs and trains a\nwide&deep model to quickly and precisely predict whether one rule is\nunregulated or not.Our evaluation shows SEPAL is effective, practical and\nscalable. We verify SEPAL outperforms the state of the art approach (i.e.,\nEASEAndroid) by 15% accuracy rate on average. In our experiments, SEPAL\nsuccessfully identifies 7,111 unregulated policy rules with a low false\npositive rate from 595,236 customized rules (extracted from 774 Android\nfirmware images of 72 manufacturers). We further discover the policy\ncustomization problem is getting worse in newer Android versions (e.g., around\n8% for Android 7 and nearly 20% for Android 9), even though more and more\nefforts are made. Then, we conduct a deep study and discuss why the unregulated\nrules are introduced and how they can compromise user devices. Last, we report\nsome unregulated rules to seven vendors and so far four of them confirm our\nfindings.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 06:44:35 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Yu", "Dongsong", ""], ["Yang", "Guangliang", ""], ["Meng", "Guozhu", ""], ["Gong", "Xiaorui", ""], ["Zhang", "Xiu", ""], ["Xiang", "Xiaobo", ""], ["Wang", "Xiaoyu", ""], ["Jiang", "Yue", ""], ["Chen", "Kai", ""], ["Zou", "Wei", ""], ["Lee", "Wenke", ""], ["Shi", "Wenchang", ""]]}, {"id": "2102.09790", "submitter": "Awais Rashid", "authors": "Joseph Hallett, Nikhil Patnaik, Benjamin Shreeve, Awais Rashid", "title": "\"Do this! Do that!, And nothing will happen\" Do specifications lead to\n  securely stored passwords?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Does the act of writing a specification (how the code should behave) for a\npiece of security sensitive code lead to developers producing more secure code?\nWe asked 138 developers to write a snippet of code to store a password: Half of\nthem were asked to write down a specification of how the code should behave\nbefore writing the program, the other half were asked to write the code but\nwithout being prompted to write a specification first. We find that explicitly\nprompting developers to write a specification has a small positive effect on\nthe security of password storage approaches implemented. However, developers\noften fail to store passwords securely, despite claiming to be confident and\nknowledgeable in their approaches, and despite considering an appropriate range\nof threats. We find a need for developer-centered usable mechanisms for telling\ndevelopers how to store passwords: lists of what they must do are not working.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 08:13:34 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Hallett", "Joseph", ""], ["Patnaik", "Nikhil", ""], ["Shreeve", "Benjamin", ""], ["Rashid", "Awais", ""]]}, {"id": "2102.09799", "submitter": "Behrooz Khadem", "authors": "Behrooz Khadem, Saeed Rajavzade", "title": "Construction of Side Channel Attacks Resistant S-boxes using Genetic\n  Algorithms based on Coordinate Functions", "comments": "9 pages, one algorithm, 14 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background and Objectives: Substitution-box (s-box) is one of the essential\ncomponents to create confusion and nonlinear properties in cryptography. To\nstrengthening a cipher against various attacks, including side channel attacks,\nthese boxes need to have numerous security properties. In this paper, a novel\nmethod to generate s-boxes is introduced aimed at improving the resistance of\ns-boxes against side channel attacks. Methods: In the preprocessing phase of\nthis approach, a suitable initial s-box which has some basic security\nproperties is generated by adopting a fast algorithm. Then, in the main stage,\nusing the initial s-box, we generate new s-boxes which not only have the\nproperties of the initial S-box but also have been significantly improved under\nanother set of security properties. To do this, new s-boxes are generated using\na genetic algorithm on a particular subset of the linear combination set of\ncoordinate functions of the initial s-box in the preprocessing stage. Results:\nThe performed experiments demonstrate that the values of all security\nproperties of these new s-boxes, especially the measures of transparency order,\nsignal-to-noise ratio, confusion coefficient, bijection property, fixed point,\nand opposite fixed points, have been substantially improved. For example, our\nexperiments indicate that 70, 220, 2071, 43, and 406 s-boxes are found better\nthan the initial s-box, respectively, in the dimensions of 4x4 through 8x8\nConclusion: In this article, a new s-box construction method is introduced in\nwhich the properties related to side channel attacks are improved, without\nreducing other security properties. Besides, some results obtained from\ngenerated s-boxes in the dimensions of 4x4 through 8x8 demonstrated that the\ngenerated s-boxes are not only improved relative to the initial s-box, but in\nsome cases, considerably better than some well-known s-boxes.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 08:29:33 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Khadem", "Behrooz", ""], ["Rajavzade", "Saeed", ""]]}, {"id": "2102.09805", "submitter": "Mesam Zarei", "authors": "Seyed Meysam Zarei and Reza Fotohi", "title": "Defense against flooding attacks using probabilistic thresholds in the\n  internet of things ecosystem", "comments": "19 pages, 8 Figure, 9 Table", "journal-ref": "Security and Privacy. 2021;e152", "doi": "10.1002/spy2.152", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Internet of Things (IoT) ecosystem allows communication between billions\nof devices worldwide that are collecting data autonomously. The vast amount of\ndata generated by these devices must be controlled totally securely. The\ncentralized solutions are not capable of responding to these concerns due to\nsecurity challenges problems. Thus, the Average Packet Transmission RREQ\n(APT-RREQ) as an effective solution, has been employed to overcome these\nconcerns to allow for entirely secure communication between devices. In this\npaper, an approach called LSFA-IoT is proposed that protects the AODV routing\nprotocol as well as the IoT network against flooding. The proposed method is\ndivided into two main phases; The first phase includes a physical layer\nintrusion and attack detection system used to detect attacks, and the second\nphase involves detecting incorrect events through APT-RREQ messages. The\nsimulation results indicated the superiority of the proposed method in terms of\nFalse Positive Rate (FPR), False Negative Rate (FPR), Detection Rate (DR), and\nPacket Delivery Rate (PDR) compared to REATO and IRAD. Also, the simulation\nresults show how the proposed approach can significantly increase the security\nof each thing and network security.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 08:36:59 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Zarei", "Seyed Meysam", ""], ["Fotohi", "Reza", ""]]}, {"id": "2102.09809", "submitter": "Piotr Krasnowski", "authors": "Piotr Krasnowski and Jerome Lebrun and Bruno Martin", "title": "Introducing an experimental distortion-tolerant speech encryption scheme\n  for secure voice communication", "comments": "26 pages, 45 figures; to be published in Speech Communication,\n  Elsevier", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The current increasing need for privacy-preserving voice communications is\nleading to new ideas for securing voice transmission. This paper refers to a\nrelatively new concept of sending encrypted speech as pseudo-speech in the\naudio domain over digital voice communication infrastructures, like 3G cellular\nnetwork and VoIP.\n  This work presents a novel distortion-tolerant speech encryption scheme for\nsecure voice communications over voice channels that combines the robustness of\nanalog speech scrambling and elevated security offered by digital ciphers like\nAES-CTR. The system scrambles vocal parameters of a speech signal (loudness,\npitch, timbre) using distance-preserving pseudo-random translations and\nrotations on a hypersphere of parameters. Next, scrambled parameters are\nencoded to a pseudo-speech signal adapted to transmission over digital voice\nchannels equipped with voice activity detection. Upon reception of this\npseudo-speech signal, the legitimate receiver restores distorted copies of the\ninitial vocal parameters. Despite some deciphering errors, an integrated\nneural-based vocoder based on the LPCNet architecture reconstructs an\nintelligible speech.\n  The experimental implementation of this speech encryption scheme has been\ntested by simulations and sending an encrypted signal over FaceTime between two\niPhones 6 connected to the same WiFi network. Moreover, speech excerpts\nrestored from encrypted signals were evaluated by a speech quality assessment\non a group of about 40 participants. The experiments demonstrated that the\nproposed scheme produces intelligible speech with a gracefully progressive\nquality degradation depending on the channel noise. Finally, the preliminary\ncomputational analysis suggested that the presented setting may operate on\nhigh-end portable devices in nearly real-time.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 08:40:56 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Krasnowski", "Piotr", ""], ["Lebrun", "Jerome", ""], ["Martin", "Bruno", ""]]}, {"id": "2102.09857", "submitter": "Muhammad Islam", "authors": "Muhammad Islam (1), Mubashir Husain Rehmani (2) and Jinjun Chen (3)\n  ((1)(3) Swinburne University of Technology, Hawthorn, Australia, (2) Munster\n  Technological University, Cork, Ireland)", "title": "Differential Privacy-based Permissioned Blockchain for Private Data\n  Sharing in Industrial IoT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Permissioned blockchain such as Hyperledger fabric enables a secure supply\nchain model in Industrial Internet of Things (IIoT) through multichannel and\nprivate data collection mechanisms. Sharing of Industrial data including\nprivate data exchange at every stage between supply chain partners helps to\nimprove product quality, enable future forecast, and enhance management\nactivities. However, the existing data sharing and querying mechanism in\nHyperledger fabric is not suitable for supply chain environment in IIoT because\nthe queries are evaluated on actual data stored on ledger which consists of\nsensitive information such as business secrets, and special discounts offered\nto retailers and individuals. To solve this problem, we propose a differential\nprivacy-based permissioned blockchain using Hyperledger fabric to enable\nprivate data sharing in supply chain in IIoT (DH-IIoT). We integrate\ndifferential privacy into the chaindcode (smart contract) of Hyperledger fabric\nto achieve privacy preservation. As a result, the query response consists of\nperturbed data which protects the sensitive information in the ledger. The\nproposed work (DH-IIoT) is evaluated by simulating a permissioned blockchain\nusing Hyperledger fabric. We compare our differential privacy integrated\nchaincode of Hyperledger fabric with the default chaincode setting of\nHyperledger fabric for supply chain scenario. The results confirm that the\nproposed work maintains 96.15% of accuracy in the shared data while guarantees\nthe protection of sensitive ledger's data.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 10:53:49 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 14:48:48 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Islam", "Muhammad", ""], ["Rehmani", "Mubashir Husain", ""], ["Chen", "Jinjun", ""]]}, {"id": "2102.09980", "submitter": "Maximilian Bachl", "authors": "Maximilian Bachl, Joachim Fabini, Tanja Zseby", "title": "A flow-based IDS using Machine Learning in eBPF", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI cs.OS", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  eBPF is a new technology which allows dynamically loading pieces of code into\nthe Linux kernel. It can greatly speed up networking since it enables the\nkernel to process certain packets without the involvement of a userspace\nprogram. So far eBPF has been used for simple packet filtering applications\nsuch as firewalls or Denial of Service protection. We show that it is possible\nto develop a flow based network intrusion detection system based on machine\nlearning entirely in eBPF. Our solution uses a decision tree and decides for\neach packet whether it is malicious or not, considering the entire previous\ncontext of the network flow. We achieve a performance increase of over 20\\%\ncompared to the same solution implemented as a userspace program.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 15:20:51 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Bachl", "Maximilian", ""], ["Fabini", "Joachim", ""], ["Zseby", "Tanja", ""]]}, {"id": "2102.10006", "submitter": "Neo Chung-Kit Yiu", "authors": "Neo C.K. Yiu", "title": "An Overview of Forks and Coordination in Blockchain Development", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.36579.07207", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain is a continuously developing technology that has made digital\ntransactions and related computing operations more transparent and secure\nthrough globally distributed and decentralized management of states, as well as\nthe strong immutability of blocks mined and transactions validated in a network\nenabled by the blockchain technology. This manuscript is aimed at elaborating\nthe concept of blockchain technology alongside its coordination and\nimplementation with other emerging technologies, such as smart contract, which\nworks with different blockchain frameworks, as well as enabling anonymous\ntransactions and decentralized consensus amongst different untrusting parties.\nThe discussion of blockchain forks is also covered in this manuscript,\ndepicting fork events created in the blockchain process, their brief history,\ntypes, and impacts upon the blockchain development and operation.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 16:18:16 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Yiu", "Neo C. K.", ""]]}, {"id": "2102.10049", "submitter": "Richard Derbyshire", "authors": "B. Green, W. Knowles, M. Krotofil, R. Derbyshire, D. Prince, N. Suri", "title": "PCaaD: Towards Automated Determination and Exploitation of Industrial\n  Processes", "comments": "17 pages, 10 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over the last decade, Programmable Logic Controllers (PLCs) have been\nincreasingly targeted by attackers to obtain control over industrial processes\nthat support critical services. Such targeted attacks typically require\ndetailed knowledge of system-specific attributes, including hardware\nconfigurations, adopted protocols, and PLC control-logic, i.e. process\ncomprehension. The consensus from both academics and practitioners suggests\nstealthy process comprehension obtained from a PLC alone, to conduct targeted\nattacks, is impractical. In contrast, we assert that current PLC programming\npractices open the door to a new vulnerability class based on control-logic\nconstructs. To support this, we propose the concept of Process Comprehension at\na Distance (PCaaD), as a novel methodological and automatable approach for\nsystem-agnostic exploitation of PLC library functions, leading to the targeted\nexfiltration of operational data, manipulation of control-logic behavior, and\nestablishment of covert command and control channels through unused memory. We\nvalidate PCaaD on widely used PLCs, by identification of practical attacks.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 17:31:30 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Green", "B.", ""], ["Knowles", "W.", ""], ["Krotofil", "M.", ""], ["Derbyshire", "R.", ""], ["Prince", "D.", ""], ["Suri", "N.", ""]]}, {"id": "2102.10109", "submitter": "Bowen Zhao", "authors": "Bowen Zhao, Ximeng Liu, Wei-neng Chen", "title": "When Crowdsensing Meets Federated Learning: Privacy-Preserving Mobile\n  Crowdsensing System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mobile crowdsensing (MCS) is an emerging sensing data collection pattern with\nscalability, low deployment cost, and distributed characteristics. Traditional\nMCS systems suffer from privacy concerns and fair reward distribution.\nMoreover, existing privacy-preserving MCS solutions usually focus on the\nprivacy protection of data collection rather than that of data processing. To\ntackle faced problems of MCS, in this paper, we integrate federated learning\n(FL) into MCS and propose a privacy-preserving MCS system, called\n\\textsc{CrowdFL}. Specifically, in order to protect privacy, participants\nlocally process sensing data via federated learning and only upload encrypted\ntraining models. Particularly, a privacy-preserving federated averaging\nalgorithm is proposed to average encrypted training models. To reduce\ncomputation and communication overhead of restraining dropped participants,\ndiscard and retransmission strategies are designed. Besides, a\nprivacy-preserving posted pricing incentive mechanism is designed, which tries\nto break the dilemma of privacy protection and data evaluation. Theoretical\nanalysis and experimental evaluation on a practical MCS application demonstrate\nthe proposed \\textsc{CrowdFL} can effectively protect participants privacy and\nis feasible and efficient.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 15:34:23 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Zhao", "Bowen", ""], ["Liu", "Ximeng", ""], ["Chen", "Wei-neng", ""]]}, {"id": "2102.10128", "submitter": "Shabbir Ahmed", "authors": "Shabbir Ahmed (1), Marcio Juliato (1), Christopher Gutierrez (1),\n  Manoj Sastry (1) ((1) Intel Corporation, Hillsboro, Oregon)", "title": "Two-Point Voltage Fingerprinting: Increasing Detectability of ECU\n  Masquerading Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automotive systems continuously increase their dependency on Electronic\nControl Units (ECUs) and become more interconnected to improve safety, comfort\nand Advanced Driving Assistance Systems (ADAS) functions to passengers and\ndrivers. As a consequence of that trend, there is an expanding attack surface\nwhich may potentially expose vehicle's critical functions to cyberattacks. It\nis possible for an adversary to reach the underlying Control Area Network (CAN)\nthrough a compromised node or external-facing network interface, and launch\nmasquerading attacks that can compromise road and passenger safety. Due to lack\nof native authentication in the CAN protocol, an approach to detect\nmasquerading attacks is to use ECU voltage fingerprinting schemes to verify\nthat the messages are sent by authentic ECUs. Though effective against simple\nmasquerading attacks, prior work is unable to detect attackers such as hardware\nTrojans, which can mimic ECU voltages in addition to spoofing messages. We\nintroduce a novel Two-point ECU Fingerprinting scheme and demonstrate efficacy\nin a controlled lab setting and on a moving vehicle. Our results show that our\nproposed two-point fingerprinting scheme is capable of an overall F1-score over\n99.4%. The proposed approach raises the bar for attackers trying to compromise\nautomotive security both remotely and physically, therefore improving security\nand safety of autonomous vehicles.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 19:13:19 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Ahmed", "Shabbir", "", "Intel Corporation, Hillsboro, Oregon"], ["Juliato", "Marcio", "", "Intel Corporation, Hillsboro, Oregon"], ["Gutierrez", "Christopher", "", "Intel Corporation, Hillsboro, Oregon"], ["Sastry", "Manoj", "", "Intel Corporation, Hillsboro, Oregon"]]}, {"id": "2102.10269", "submitter": "Zhi Zhang", "authors": "Zhi Zhang, Yueqiang Cheng, Minghua Wang, Wei He, Wenhao Wang, Nepal\n  Surya, Yansong Gao, Kang Li, Zhe Wang, Chenggang Wu", "title": "SoftTRR: Protect Page Tables Against RowHammer Attacks using\n  Software-only Target Row Refresh", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.OS cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rowhammer attacks that corrupt level-1 page tables to gain kernel privilege\nare the most detrimental to system security and hard to mitigate. However,\nrecently proposed software-only mitigations are not effective against such\nkernel privilege escalation attacks. In this paper, we propose an effective and\npractical software-only defense, called SoftTRR, to protect page tables from\nall existing rowhammer attacks on x86. The key idea of SoftTRR is to refresh\nthe rows occupied by page tables when a suspicious rowhammer activity is\ndetected. SoftTRR is motivated by DRAM-chip-based target row refresh (ChipTRR)\nbut eliminates its main security limitation (i.e., ChipTRR tracks a limited\nnumber of rows and thus can be bypassed by many-sided hammer). Specifically,\nSoftTRR protects an unlimited number of page tables by tracking memory accesses\nto the rows that are in close proximity to page-table rows and refreshing the\npage-table rows once the tracked access count exceeds a pre-defined threshold.\nWe implement a prototype of SoftTRR as a loadable kernel module, and evaluate\nits security effectiveness, performance overhead, and memory consumption. The\nexperimental results show that SoftTRR protects page tables from real-world\nrowhammer attacks and incurs small performance overhead as well as memory cost.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 06:20:33 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Zhang", "Zhi", ""], ["Cheng", "Yueqiang", ""], ["Wang", "Minghua", ""], ["He", "Wei", ""], ["Wang", "Wenhao", ""], ["Surya", "Nepal", ""], ["Gao", "Yansong", ""], ["Li", "Kang", ""], ["Wang", "Zhe", ""], ["Wu", "Chenggang", ""]]}, {"id": "2102.10314", "submitter": "Giacomo Giuliari", "authors": "Giacomo Giuliari, Marc Wyss, Markus Legner, Adrian Perrig", "title": "GMA: A Pareto Optimal Distributed Resource-Allocation Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To address the rising demand for strong packet delivery guarantees in\nnetworking, we study a novel way to perform graph resource allocation. We first\nintroduce allocation graphs, in which nodes can independently set local\nresource limits based on physical constraints or policy decisions. In this\nscenario we formalize the distributed path-allocation (PAdist) problem, which\nconsists in allocating resources to paths considering only local on-path\ninformation -- importantly, not knowing which other paths could have an\nallocation -- while at the same time achieving the global property of never\nexceeding available resources.\n  Our core contribution, the global myopic allocation (GMA) algorithm, is a\nsolution to this problem. We prove that GMA can compute unconditional\nallocations for all paths on a graph, while never over-allocating resources.\nFurther, we prove that GMA is Pareto optimal with respect to the allocation\nsize, and it has linear complexity in the input size. Finally, we show with\nsimulations that this theoretical result could be indeed applied to practical\nscenarios, as the resulting path allocations are large enough to fit the\nrequirements of practically relevant applications.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 11:15:24 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 10:56:53 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Giuliari", "Giacomo", ""], ["Wyss", "Marc", ""], ["Legner", "Markus", ""], ["Perrig", "Adrian", ""]]}, {"id": "2102.10321", "submitter": "Christoph Capellaro", "authors": "Christoph Capellaro", "title": "Design of Ciphers based on the Geometric Structure of the M\\\"obius Plane", "comments": "18 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Till now geometric structures don't play a major role in cryptography.\nGilbert, MacWilliams and Sloane introduced in 1974 an authentication scheme in\nthe projective plane and showed its perfectness in the sense of the definition\nof Shannon. In this paper we will show that this authentication scheme also\nfulfills the requirement of completeness according to Kam and Davida and we\nwill extend the application of geometric structures in cryptography by\nintroducing an encryption scheme in the M\\\"obius plane. We will further examine\nits properties, showing that it also fulfills the requirement of completeness\nand Shannon's requirement of perfectness in first approximation. The results of\nthis paper can be used to define similar encryption schemes in the circle\ngeometries of Laguerre and Minkowski.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 12:06:14 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 19:38:05 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Capellaro", "Christoph", ""]]}, {"id": "2102.10343", "submitter": "Sizhe Chen", "authors": "Sizhe Chen, Qinghua Tao, Zhixing Ye, Xiaolin Huang", "title": "Going Far Boosts Attack Transferability, but Do Not Do It", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) could be easily fooled by Adversarial Examples\n(AEs) with an imperceptible difference to original ones in human eyes. Also,\nthe AEs from attacking one surrogate DNN tend to cheat other black-box DNNs as\nwell, i.e., the attack transferability. Existing works reveal that adopting\ncertain optimization algorithms in attack improves transferability, but the\nunderlying reasons have not been thoroughly studied. In this paper, we\ninvestigate the impacts of optimization on attack transferability by\ncomprehensive experiments concerning 7 optimization algorithms, 4 surrogates,\nand 9 black-box models. Through the thorough empirical analysis from three\nperspectives, we surprisingly find that the varied transferability of AEs from\noptimization algorithms is strongly related to the corresponding Root Mean\nSquare Error (RMSE) from their original samples. On such a basis, one could\nsimply approach high transferability by attacking until RMSE decreases, which\nmotives us to propose a LArge RMSE Attack (LARA). Although LARA significantly\nimproves transferability by 20%, it is insufficient to exploit the\nvulnerability of DNNs, leading to a natural urge that the strength of all\nattacks should be measured by both the widely used $\\ell_\\infty$ bound and the\nRMSE addressed in this paper, so that tricky enhancement of transferability\nwould be avoided.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 13:19:31 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Chen", "Sizhe", ""], ["Tao", "Qinghua", ""], ["Ye", "Zhixing", ""], ["Huang", "Xiaolin", ""]]}, {"id": "2102.10369", "submitter": "Tuan Anh Nguyen", "authors": "Anh Nguyen, Anh Tran", "title": "WaNet -- Imperceptible Warping-based Backdoor Attack", "comments": "Accepted to ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the thriving of deep learning and the widespread practice of using\npre-trained networks, backdoor attacks have become an increasing security\nthreat drawing many research interests in recent years. A third-party model can\nbe poisoned in training to work well in normal conditions but behave\nmaliciously when a trigger pattern appears. However, the existing backdoor\nattacks are all built on noise perturbation triggers, making them noticeable to\nhumans. In this paper, we instead propose using warping-based triggers. The\nproposed backdoor outperforms the previous methods in a human inspection test\nby a wide margin, proving its stealthiness. To make such models undetectable by\nmachine defenders, we propose a novel training mode, called the ``noise mode.\nThe trained networks successfully attack and bypass the state-of-the-art\ndefense methods on standard classification datasets, including MNIST, CIFAR-10,\nGTSRB, and CelebA. Behavior analyses show that our backdoors are transparent to\nnetwork inspection, further proving this novel attack mechanism's efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 15:25:36 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 04:08:35 GMT"}, {"version": "v3", "created": "Wed, 24 Feb 2021 15:15:13 GMT"}, {"version": "v4", "created": "Thu, 4 Mar 2021 04:09:38 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Nguyen", "Anh", ""], ["Tran", "Anh", ""]]}, {"id": "2102.10430", "submitter": "Tiago Espinha Gasiba", "authors": "Tiago Espinha Gasiba, Ulrike Lechner, Maria Pinto-Albuquerque, Anmoal\n  Porwal", "title": "Cybersecurity Awareness Platform with Virtual Coach and Automated\n  Challenge Assessment", "comments": "Preprint accepted for publication at the 6th Workshop On The Security\n  Of Industrial Control Systems & Of Cyber-Physical Systems (CyberICPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last years, the number of cyber-attacks on industrial control\nsystems has been steadily increasing. Among several factors, proper software\ndevelopment plays a vital role in keeping these systems secure. To achieve\nsecure software, developers need to be aware of secure coding guidelines and\nsecure coding best practices. This work presents a platform geared towards\nsoftware developers in the industry that aims to increase awareness of secure\nsoftware development. The authors also introduce an interactive game component,\na virtual coach, which implements a simple artificial intelligence engine based\non the laddering technique for interviews. Through a survey, a preliminary\nevaluation of the implemented artifact with real-world players (from academia\nand industry) shows a positive acceptance of the developed platform.\nFurthermore, the players agree that the platform is adequate for training their\nsecure coding skills. The impact of our work is to introduce a new automatic\nchallenge evaluation method together with a virtual coach to improve existing\ncybersecurity awareness training programs. These training workshops can be\neasily held remotely or off-line.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 20:08:32 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Gasiba", "Tiago Espinha", ""], ["Lechner", "Ulrike", ""], ["Pinto-Albuquerque", "Maria", ""], ["Porwal", "Anmoal", ""]]}, {"id": "2102.10433", "submitter": "Yonghong Bai", "authors": "Yonghong Bai and Zhiyuan Yan", "title": "A Novel Key Generation Scheme Using Quaternary PUF Responses and Wiretap\n  Polar Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Physical unclonable functions (PUFs) are widely considered in secret key\ngeneration for resource constrained devices. However, PUFs require additional\nhardware overhead. In this paper, we focus on developing a PUF-efficient,\nrobust, and secure key generation scheme. First, a novel method for extracting\nquaternary PUF responses is proposed to increase the entropy of a PUF response,\nin which a 2-bit response is extracted from evaluating a single PUF cell\nmultiple times. The probability masses of the responses can be adjusted by\nsetting parameters appropriately. Then, a chosen secret model based fuzzy\nextractor (FE) is designed to extract secret keys from the quaternary PUF\nresponses. To improve the security of this FE, it is modeled as a wiretap\nchannel system, and wiretap polar coding is adopted to reduce secrecy leakage.\nAn upper bound of secrecy leakage is also given in this paper, and it suggests\nthat an arbitrarily small (even zero) leakage can be achieved by properly\nchoosing parameters of the quaternary PUF responses generation. Comparison\nresults show that the required number of PUF cells to achieve the same level of\nsecrecy in our scheme is as low as half that of the state-of-the-art schemes.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 20:10:56 GMT"}, {"version": "v2", "created": "Sun, 7 Mar 2021 19:44:15 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Bai", "Yonghong", ""], ["Yan", "Zhiyuan", ""]]}, {"id": "2102.10452", "submitter": "Zhilong Wang", "authors": "Zhilong Wang, Li Yu, Suhang Wang and Peng Liu", "title": "Spotting Silent Buffer Overflows in Execution Trace through Graph Neural\n  Network Assisted Data Flow Analysis", "comments": "15 pages conference paper (still in submission progress)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A software vulnerability could be exploited without any visible symptoms.\nWhen no source code is available, although such silent program executions could\ncause very serious damage, the general problem of analyzing silent yet harmful\nexecutions is still an open problem. In this work, we propose a graph neural\nnetwork (GNN) assisted data flow analysis method for spotting silent buffer\noverflows in execution traces. The new method combines a novel graph structure\n(denoted DFG+) beyond data-flow graphs, a tool to extract {\\tt DFG+} from\nexecution traces, and a modified Relational Graph Convolutional Network as the\nGNN model to be trained. The evaluation results show that a well-trained model\ncan be used to analyze vulnerabilities in execution traces (of\npreviously-unseen programs) without support of any source code. Our model\nachieves 94.39\\% accuracy on the test data and successfully locates 29 out of\n30 real-world silent buffer overflow vulnerabilities. Leveraging deep learning,\nthe proposed method is, to our best knowledge, the first general-purpose\nanalysis method for silent buffer overflows. It is also the first method to\nspot silent buffer overflows in global variables, stack variables, or heap\nvariables without crossing the boundary of allocated chunks.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 21:40:53 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Wang", "Zhilong", ""], ["Yu", "Li", ""], ["Wang", "Suhang", ""], ["Liu", "Peng", ""]]}, {"id": "2102.10496", "submitter": "Jiawang Bai", "authors": "Jiawang Bai, Baoyuan Wu, Yong Zhang, Yiming Li, Zhifeng Li, Shu-Tao\n  Xia", "title": "Targeted Attack against Deep Neural Networks via Flipping Limited Weight\n  Bits", "comments": "Accepted by ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To explore the vulnerability of deep neural networks (DNNs), many attack\nparadigms have been well studied, such as the poisoning-based backdoor attack\nin the training stage and the adversarial attack in the inference stage. In\nthis paper, we study a novel attack paradigm, which modifies model parameters\nin the deployment stage for malicious purposes. Specifically, our goal is to\nmisclassify a specific sample into a target class without any sample\nmodification, while not significantly reduce the prediction accuracy of other\nsamples to ensure the stealthiness. To this end, we formulate this problem as a\nbinary integer programming (BIP), since the parameters are stored as binary\nbits ($i.e.$, 0 and 1) in the memory. By utilizing the latest technique in\ninteger programming, we equivalently reformulate this BIP problem as a\ncontinuous optimization problem, which can be effectively and efficiently\nsolved using the alternating direction method of multipliers (ADMM) method.\nConsequently, the flipped critical bits can be easily determined through\noptimization, rather than using a heuristic strategy. Extensive experiments\ndemonstrate the superiority of our method in attacking DNNs.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 03:13:27 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Bai", "Jiawang", ""], ["Wu", "Baoyuan", ""], ["Zhang", "Yong", ""], ["Li", "Yiming", ""], ["Li", "Zhifeng", ""], ["Xia", "Shu-Tao", ""]]}, {"id": "2102.10567", "submitter": "Stefanos Leonardos Mr.", "authors": "Stefanos Leonardos, Barnab\\'e Monnot, Dani\\\"el Reijsbergen, Stratis\n  Skoulakis, Georgios Piliouras", "title": "Dynamical Analysis of the EIP-1559 Ethereum Fee Market", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR math.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Participation in permissionless blockchains results in competition over\nsystem resources, which needs to be controlled with fees. Ethereum's current\nfee mechanism is implemented via a first-price auction that results in\nunpredictable fees as well as other inefficiencies. EIP-1559 is a recent,\nimproved proposal that introduces a number of innovative features such as a\ndynamically adaptive base fee that is burned, instead of being paid to the\nminers. Despite intense interest in understanding its properties, several basic\nquestions such as whether and under what conditions does this protocol\nself-stabilize have remained elusive thus far.\n  We perform a thorough analysis of the resulting fee market dynamic mechanism\nvia a combination of tools from game theory and dynamical systems. We start by\nproviding bounds on the step-size of the base fee update rule that suffice for\nglobal convergence to equilibrium via Lyapunov arguments. In the negative\ndirection, we show that for larger step-sizes instability and even formally\nchaotic behavior are possible under a wide range of settings. We complement\nthese qualitative results with quantitative bounds on the resulting range of\nbase fees. We conclude our analysis with a thorough experimental case study\nthat corroborates our theoretical findings.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 09:38:04 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 08:49:10 GMT"}, {"version": "v3", "created": "Sat, 5 Jun 2021 08:50:59 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Leonardos", "Stefanos", ""], ["Monnot", "Barnab\u00e9", ""], ["Reijsbergen", "Dani\u00ebl", ""], ["Skoulakis", "Stratis", ""], ["Piliouras", "Georgios", ""]]}, {"id": "2102.10594", "submitter": "Sankarshan Damle", "authors": "Sankarshan Damle, Sujit Gujar, Moin Hussain Moti", "title": "FASTEN: Fair and Secure Distributed Voting Using Smart Contracts", "comments": "A version of this paper will appear in the IEEE International\n  Conference on Blockchain and Cryptocurrency (IEEE ICBC 2021). This is a full\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electing democratic representatives via voting has been a common mechanism\nsince the 17th century. However, these mechanisms raise concerns about\nfairness, privacy, vote concealment, fair calculations of tally, and proxies\nvoting on their behalf for the voters. Ballot voting, and in recent times,\nelectronic voting via electronic voting machines (EVMs) improves fairness by\nrelying on centralized trust. Homomorphic encryption-based voting protocols\nalso assure fairness but cannot scale to large scale elections such as\npresidential elections. In this paper, we leverage the blockchain technology of\ndistributing trust to propose a smart contract-based protocol, namely, \\proto.\nThere are many existing protocols for voting using smart contracts. We observe\nthat these either are not scalable or leak the vote tally during the voting\nstage, i.e., do not provide vote concealment. In contrast, we show that FASTEN\npreserves voter's privacy ensures vote concealment, immutability, and avoids\ndouble voting. We prove that the probability of privacy breaches is negligibly\nsmall. Further, our cost analysis of executing FASTEN over Ethereum is\ncomparable to most of the existing cost of elections.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 12:29:23 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Damle", "Sankarshan", ""], ["Gujar", "Sujit", ""], ["Moti", "Moin Hussain", ""]]}, {"id": "2102.10612", "submitter": "Peeter Laud", "authors": "Aleksandr Lenin and Peeter Laud", "title": "Content Confidentiality in Named Data Networking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the design of name based access control scheme which\nfacilitates data confidentiality by applying end-to-end encryption to data\npublished on NDN with flexible fine-grained access control, which allows to\ndefine an enforce access policies on published data. The scheme is based on\nciphertext-policy attribute-based encryption (CP-ABE). We discuss the use of\nthe scheme on the basis of two use-cases, and report overhead associated with\nit, based on our implementation.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 14:37:20 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Lenin", "Aleksandr", ""], ["Laud", "Peeter", ""]]}, {"id": "2102.10632", "submitter": "Aaron Zimba", "authors": "Aaron Zimba, Mumbi Chishimba, Sipiwe Chihana", "title": "A Ransomware Classification Framework Based on File-Deletion and\n  File-Encryption Attack Structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ransomware has emerged as an infamous malware that has not escaped a lot of\nmyths and inaccuracies from media hype. Victims are not sure whether or not to\npay a ransom demand without fully understanding the lurking consequences. In\nthis paper, we present a ransomware classification framework based on\nfile-deletion and file-encryption attack structures that provides a deeper\ncomprehension of potential flaws and inadequacies exhibited in ransomware. We\nformulate a threat and attack model representative of a typical ransomware\nattack process from which we derive the ransomware categorization framework\nbased on a proposed classification algorithm. The framework classifies the\nvirulence of a ransomware attack to entail the overall effectiveness of\npotential ways of recovering the attacked data without paying the ransom demand\nas well as the technical prowess of the underlying attack structures. Results\nof the categorization, in increasing severity from CAT1 through to CAT5, show\nthat many ransomwares exhibit flaws in their implementation of encryption and\ndeletion attack structures which make data recovery possible without paying the\nransom. The most severe categories CAT4 and CAT5 are better mitigated by\nexploiting encryption essentials while CAT3 can be effectively mitigated via\nreverse engineering. CAT1 and CAT2 are not common and are easily mitigated\nwithout any decryption essentials.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 16:05:02 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Zimba", "Aaron", ""], ["Chishimba", "Mumbi", ""], ["Chihana", "Sipiwe", ""]]}, {"id": "2102.10634", "submitter": "Aaron Zimba", "authors": "Aaron Zimba, Mumbi Chishimba, Christabel Ngongola-Reinke, Tozgani\n  Fainess Mbale", "title": "Demystifying Cryptocurrency Mining Attacks: A Semi-supervised Learning\n  Approach Based on Digital Forensics and Dynamic Network Characteristics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cryptocurrencies have emerged as a new form of digital money that has not\nescaped the eyes of cyber-attackers. Traditionally, they have been maliciously\nused as a medium of exchange for proceeds of crime in the cyber dark-market by\ncyber-criminals. However, cyber-criminals have devised an exploitative\ntechnique of directly acquiring cryptocurrencies from benign users' CPUs\nwithout their knowledge through a process called crypto mining. The presence of\ncrypto mining activities in a network is often an indicator of compromise of\nillegal usage of network resources for crypto mining purposes. Crypto mining\nhas had a financial toll on victims such as corporate networks and individual\nhome users. This paper addresses the detection of crypto mining attacks in a\ngeneric network environment using dynamic network characteristics. It tackles\nan in-depth overview of crypto mining operational details and proposes a\nsemi-supervised machine learning approach to detection using various crypto\nmining features derived from complex network characteristics. The results\ndemonstrate that the integration of semi-supervised learning with complex\nnetwork theory modeling is effective at detecting crypto mining activities in a\nnetwork environment. Such an approach is helpful during security mitigation by\nnetwork security administrators and law enforcement agencies.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 16:13:50 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Zimba", "Aaron", ""], ["Chishimba", "Mumbi", ""], ["Ngongola-Reinke", "Christabel", ""], ["Mbale", "Tozgani Fainess", ""]]}, {"id": "2102.10695", "submitter": "Luis Puche Rondon", "authors": "Luis Puche Rondon, Leonardo Babun, Ahmet Aris, Kemal Akkaya, and A.\n  Selcuk Uluagac", "title": "Survey on Enterprise Internet-of-Things Systems (E-IoT): A Security\n  Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As technology becomes more widely available, millions of users worldwide have\ninstalled some form of smart device in their homes or workplaces. These devices\nare often off-the-shelf commodity systems, such as Google Home or Samsung\nSmartThings, that are installed by end-users looking to automate a small\ndeployment. In contrast to these \"plug-and-play\" systems, purpose-built\nEnterprise Internet-of-Things (E-IoT) systems such as Crestron, Control4, RTI,\nSavant offer a smart solution for more sophisticated applications (e.g.,\ncomplete lighting control, A/V management, security). In contrast to commodity\nsystems, E-IoT systems are usually closed source, costly, require certified\ninstallers, and are overall more robust for their use cases. Due to this, E-IoT\nsystems are often found in expensive smart homes, government and academic\nconference rooms, yachts, and smart private offices. However, while there has\nbeen plenty of research on the topic of commodity systems, no current study\nexists that provides a complete picture of E-IoT systems, their components, and\nrelevant threats. As such, lack of knowledge of E-IoT system threats, coupled\nwith the cost of E-IoT systems has led many to assume that E-IoT systems are\nsecure. To address this research gap, raise awareness on E-IoT security, and\nmotivate further research, this work emphasizes E-IoT system components, E-IoT\nvulnerabilities, solutions, and their security implications. In order to\nsystematically analyze the security of E-IoT systems, we divide E-IoT systems\ninto four layers: E-IoT Devices Layer, Communications Layer, Monitoring and\nApplications Layer, and Business Layer. We survey attacks and defense\nmechanisms, considering the E-IoT components at each layer and the associated\nthreats. In addition, we present key observations in state-of-the-art E-IoT\nsecurity and provide a list of open research problems that need further\nresearch.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 21:51:11 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Rondon", "Luis Puche", ""], ["Babun", "Leonardo", ""], ["Aris", "Ahmet", ""], ["Akkaya", "Kemal", ""], ["Uluagac", "A. Selcuk", ""]]}, {"id": "2102.10784", "submitter": "Zihan Zhao", "authors": "Ryan Song, Zihan Zhao, Yuxi Cai, Andreas Veneris, Fan Long", "title": "SigVM: Toward Fully Autonomous Smart Contracts", "comments": "14 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents SigVM, a novel blockchain virtual machine that supports\nan event-driven execution model, enabling developers to build fully autonomous\nsmart contracts. SigVM introduces another way for a contract to interact with\nanother. Contracts in SigVM can emit signal events, on which other contracts\ncan listen. Once an event is triggered, corresponding handler functions are\nautomatically executed as signal transactions. We built an end-to-end\nblockchain platform SigChain and a contract language compiler SigSolid to\nrealize the potential of SigVM. Experimental results show that SigVM enables\ncontracts in our benchmark applications to be reimplemented in a fully\nautonomous way, eliminating the dependency on unreliable mechanisms like\noff-chain relay servers. SigVM can significantly simplify the execution flow of\nour benchmark applications, and can avoid security risks such as front-run\nattacks.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 05:37:30 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Song", "Ryan", ""], ["Zhao", "Zihan", ""], ["Cai", "Yuxi", ""], ["Veneris", "Andreas", ""], ["Long", "Fan", ""]]}, {"id": "2102.10802", "submitter": "Praneeth Vepakomma", "authors": "Praneeth Vepakomma, Julia Balla, Ramesh Raskar", "title": "Differentially Private Supervised Manifold Learning with Applications\n  like Private Image Retrieval", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential Privacy offers strong guarantees such as immutable privacy under\npost processing. Thus it is often looked to as a solution to learning on\nscattered and isolated data. This work focuses on supervised manifold learning,\na paradigm that can generate fine-tuned manifolds for a target use case. Our\ncontributions are two fold. 1) We present a novel differentially private method\n\\textit{PrivateMail} for supervised manifold learning, the first of its kind to\nour knowledge. 2) We provide a novel private geometric embedding scheme for our\nexperimental use case. We experiment on private \"content based image retrieval\"\n- embedding and querying the nearest neighbors of images in a private manner -\nand show extensive privacy-utility tradeoff results, as well as the\ncomputational efficiency and practicality of our methods.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 06:58:46 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Vepakomma", "Praneeth", ""], ["Balla", "Julia", ""], ["Raskar", "Ramesh", ""]]}, {"id": "2102.10869", "submitter": "Piotr Krasnowski", "authors": "Piotr Krasnowski and Bruno Martin and Jerome Lebrun", "title": "Introducing a Novel Data over Voice Technique for Secure Voice\n  Communication", "comments": "22 pages, 43 figures; submitted to Wireless Personal Communications,\n  Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The current increasing need for privacy-preserving voice communications is\nleading to new ideas for securing voice transmission. This paper refers to a\nrelatively new concept of sending encrypted data or speech as pseudo-speech in\nthe audio domain over existing voice communication infrastructures, like 3G\ncellular network and Voice over IP (VoIP). The distinctive characteristic of\nsuch a communication system is that it relies on the robust transmission of\nbinary information in the form of audio signal.\n  This work presents a novel Data over Voice (DoV) technique based on codebooks\nof short harmonic waveforms. The technique provides a sufficiently fast and\nreliable data rate over cellular networks and many VoIP applications. The new\nmethod relies on general principles of Linear Predictive Coding for voice\ncompression (LPC voice coding) and is more versatile compared to solutions\ntrained on exact channel models. The technique gives by design a high control\nover the desired rate of transmission and provides robustness to channel\ndistortion. In addition, an efficient codebook design approach inspired by\nquaternary error correcting codes is proposed.\n  The usability of the proposed DoV technique for secure voice communication\nover cellular networks and VoIP has been successfully validated by empirical\nexperiments. The paper details the system parameters, putting a special\nemphasis on system's security and technical challenges.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 10:09:23 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Krasnowski", "Piotr", ""], ["Martin", "Bruno", ""], ["Lebrun", "Jerome", ""]]}, {"id": "2102.10908", "submitter": "Weitao Xu", "authors": "Weitao Xu, Zhenjiang Li, Wanli Xue, Xiaotong Yu, Bo Wei, Jia Wang,\n  Chengwen Luo, Wei Li, Albert Y. Zomaya", "title": "InaudibleKey: Generic Inaudible Acoustic Signal based Key Agreement\n  Protocol for Mobile Devices", "comments": "13 pages, 11 figures, IPSN 2021", "journal-ref": null, "doi": "10.1145/3412382.3458260", "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secure Device-to-Device (D2D) communication is becoming increasingly\nimportant with the ever-growing number of Internet-of-Things (IoT) devices in\nour daily life. To achieve secure D2D communication, the key agreement between\ndifferent IoT devices without any prior knowledge is becoming desirable.\nAlthough various approaches have been proposed in the literature, they suffer\nfrom a number of limitations, such as low key generation rate and short pairing\ndistance. In this paper, we present InaudibleKey, an inaudible acoustic\nsignal-based key generation protocol for mobile devices. Based on acoustic\nchannel reciprocity, InaudibleKey exploits the acoustic channel frequency\nresponse of two legitimate devices as a common secret to generating keys.\nInaudibleKey employs several novel technologies to significantly improve its\nperformance. We conduct extensive experiments to evaluate the proposed system\nin different real environments. Compared to state-of-the-art works,\nInaudibleKey improves key generation rate by 3-145 times, extends pairing\ndistance by 3.2-44 times, and reduces information reconciliation counts by\n2.5-16 times. Security analysis demonstrates that InaudibleKey is resilient to\na number of malicious attacks. We also implement InaudibleKey on modern\nsmartphones and resource-limited IoT devices. Results show that it is\nenergy-efficient and can run on both powerful and resource-limited IoT devices\nwithout incurring excessive resource consumption.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 11:23:50 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 05:03:00 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Xu", "Weitao", ""], ["Li", "Zhenjiang", ""], ["Xue", "Wanli", ""], ["Yu", "Xiaotong", ""], ["Wei", "Bo", ""], ["Wang", "Jia", ""], ["Luo", "Chengwen", ""], ["Li", "Wei", ""], ["Zomaya", "Albert Y.", ""]]}, {"id": "2102.10997", "submitter": "Subhash Sagar Mr.", "authors": "Subhash Sagar, Adnan Mahmood, Quan Z. Sheng, and Wei Emma Zhang", "title": "Trust Computational Heuristic for Social Internet of Things: A Machine\n  Learning-based Approach", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PF", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The Internet of Things (IoT) is an evolving network of billions of\ninterconnected physical objects, such as numerous sensors, smartphones,\nwearables, and embedded devices. These physical objects, generally referred to\nas the smart objects, when deployed in the real-world aggregates useful\ninformation from their surrounding environment. As-of-late, this notion of IoT\nhas been extended to incorporate the social networking facets which have led to\nthe promising paradigm of the `Social Internet of Things' (SIoT). In SIoT, the\ndevices operate as an autonomous agent and provide an exchange of information\nand service discovery in an intelligent manner by establishing social\nrelationships among them with respect to their owners. Trust plays an important\nrole in establishing trustworthy relationships among the physical objects and\nreduces probable risks in the decision-making process. In this paper, a trust\ncomputational model is proposed to extract individual trust features in a SIoT\nenvironment. Furthermore, a machine learning-based heuristic is used to\naggregate all the trust features in order to ascertain an aggregate trust\nscore. Simulation results illustrate that the proposed trust-based model\nisolates the trustworthy and untrustworthy nodes within the network in an\nefficient manner.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 10:52:02 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Sagar", "Subhash", ""], ["Mahmood", "Adnan", ""], ["Sheng", "Quan Z.", ""], ["Zhang", "Wei Emma", ""]]}, {"id": "2102.10998", "submitter": "Subhash Sagar Mr.", "authors": "Subhash Sagar, Adnan Mahmood, Quan Z. Sheng, Munazza Zaib and Wei Emma\n  Zhang", "title": "Towards a Machine Learning-driven Trust Evaluation Model for Social\n  Internet of Things: A Time-aware Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The emerging paradigm of the Social Internet of Things (SIoT) has transformed\nthe traditional notion of the Internet of Things (IoT) into a social network of\nbillions of interconnected smart objects by integrating social networking\nfacets into the same. In SIoT, objects can establish social relationships in an\nautonomous manner and interact with the other objects in the network based on\ntheir social behaviour. A fundamental problem that needs attention is\nestablishing of these relationships in a reliable and trusted way, i.e.,\nestablishing trustworthy relationships and building trust amongst objects. In\naddition, it is also indispensable to ascertain and predict an object's\nbehaviour in the SIoT network over a period of time. Accordingly, in this\npaper, we have proposed an efficient time-aware machine learning-driven trust\nevaluation model to address this particular issue. The envisaged model\ndeliberates social relationships in terms of friendship and community-interest,\nand further takes into consideration the working relationships and\ncooperativeness (object-object interactions) as trust parameters to quantify\nthe trustworthiness of an object. Subsequently, in contrast to the traditional\nweighted sum heuristics, a machine learning-driven aggregation scheme is\ndelineated to synthesize these trust parameters to ascertain a single trust\nscore. The experimental results demonstrate that the proposed model can\nefficiently segregates the trustworthy and untrustworthy objects within a\nnetwork, and further provides the insight on how the trust of an object varies\nwith time along with depicting the effect of each trust parameter on a trust\nscore.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 09:25:44 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Sagar", "Subhash", ""], ["Mahmood", "Adnan", ""], ["Sheng", "Quan Z.", ""], ["Zaib", "Munazza", ""], ["Zhang", "Wei Emma", ""]]}, {"id": "2102.11072", "submitter": "William Croft", "authors": "William Croft, J\\\"org-R\\\"udiger Sack, Wei Shi", "title": "Obfuscation of Images via Differential Privacy: From Facial Images to\n  General Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the pervasiveness of image capturing devices in every-day life, images\nof individuals are routinely captured. Although this has enabled many benefits,\nit also infringes on personal privacy. A promising direction in research on\nobfuscation of facial images has been the work in the k-same family of methods\nwhich employ the concept of k-anonymity from database privacy. However, there\nare a number of deficiencies of k-anonymity that carry over to the k-same\nmethods, detracting from their usefulness in practice. In this paper, we first\noutline several of these deficiencies and discuss their implications in the\ncontext of facial obfuscation. We then develop a framework through which we\nobtain a formal differentially private guarantee for the obfuscation of facial\nimages in generative machine learning models. Our approach provides a provable\nprivacy guarantee that is not susceptible to the outlined deficiencies of\nk-same obfuscation and produces photo-realistic obfuscated output. In addition,\nwe demonstrate through experimental comparisons that our approach can achieve\ncomparable utility to k-same obfuscation in terms of preservation of useful\nfeatures in the images. Furthermore, we propose a method to achieve\ndifferential privacy for any image (i.e., without restriction to facial images)\nthrough the direct modification of pixel intensities. Although the addition of\nnoise to pixel intensities does not provide the high visual quality obtained\nvia generative machine learning models, it offers greater versatility by\neliminating the need for a trained model. We demonstrate that our proposed use\nof the exponential mechanism in this context is able to provide superior visual\nquality to pixel-space obfuscation using the Laplace mechanism.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 16:14:38 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Croft", "William", ""], ["Sack", "J\u00f6rg-R\u00fcdiger", ""], ["Shi", "Wei", ""]]}, {"id": "2102.11158", "submitter": "Shuxiao Chen", "authors": "Qinqing Zheng, Shuxiao Chen, Qi Long, Weijie J. Su", "title": "Federated $f$-Differential Privacy", "comments": "Accepted to AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a training paradigm where the clients\ncollaboratively learn models by repeatedly sharing information without\ncompromising much on the privacy of their local sensitive data. In this paper,\nwe introduce federated $f$-differential privacy, a new notion specifically\ntailored to the federated setting, based on the framework of Gaussian\ndifferential privacy. Federated $f$-differential privacy operates on record\nlevel: it provides the privacy guarantee on each individual record of one\nclient's data against adversaries. We then propose a generic private federated\nlearning framework {PriFedSync} that accommodates a large family of\nstate-of-the-art FL algorithms, which provably achieves federated\n$f$-differential privacy. Finally, we empirically demonstrate the trade-off\nbetween privacy guarantee and prediction performance for models trained by\n{PriFedSync} in computer vision tasks.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 16:28:21 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Zheng", "Qinqing", ""], ["Chen", "Shuxiao", ""], ["Long", "Qi", ""], ["Su", "Weijie J.", ""]]}, {"id": "2102.11401", "submitter": "Dan Li", "authors": "Dan Li, Nagi Gebraeel, Kamran Paynabar, and A.P. Sakis Meliopoulos", "title": "An Online Approach to Cyberattack Detection and Localization in Smart\n  Grid", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex interconnections between information technology and digital control\nsystems have significantly increased cybersecurity vulnerabilities in smart\ngrids. Cyberattacks involving data integrity can be very disruptive because of\ntheir potential to compromise physical control by manipulating measurement\ndata. This is especially true in large and complex electric networks that often\nrely on traditional intrusion detection systems focused on monitoring network\ntraffic. In this paper, we develop an online detection algorithm to detect and\nlocalize covert attacks on smart grids. Using a network system model, we\ndevelop a theoretical framework by characterizing a covert attack on a\ngenerator bus in the network as sparse features in the state-estimation\nresiduals. We leverage such sparsity via a regularized linear regression method\nto detect and localize covert attacks based on the regression coefficients. We\nconduct a comprehensive numerical study on both linear and nonlinear system\nmodels to validate our proposed method. The results show that our method\noutperforms conventional methods in both detection delay and localization\naccuracy.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 23:09:12 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Li", "Dan", ""], ["Gebraeel", "Nagi", ""], ["Paynabar", "Kamran", ""], ["Meliopoulos", "A. P. Sakis", ""]]}, {"id": "2102.11442", "submitter": "Yanyan Li", "authors": "Yanyan Li, Sara Kim, Eric Sy", "title": "A Survey on Amazon Alexa Attack Surfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since being launched in 2014, Alexa, Amazon's versatile cloud-based voice\nservice, is now active in over 100 million households worldwide. Alexa's\nuser-friendly, personalized vocal experience offers customers a more natural\nway of interacting with cutting-edge technology by allowing the ability to\ndirectly dictate commands to the assistant. Now in the present year, the Alexa\nservice is more accessible than ever, available on hundreds of millions of\ndevices from not only Amazon but third-party device manufacturers.\nUnfortunately, that success has also been the source of concern and\ncontroversy. The success of Alexa is based on its effortless usability, but in\nturn, that has led to a lack of sufficient security. This paper surveys various\nattacks against Amazon Alexa ecosystem including attacks against the frontend\nvoice capturing and the cloud backend voice command recognition and processing.\nOverall, we have identified six attack surfaces covering the lifecycle of Alexa\nvoice interaction that spans several stages including voice data collection,\ntransmission, processing and storage. We also discuss the potential mitigation\nsolutions for each attack surface to better improve Alexa or other voice\nassistants in terms of security and privacy.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 01:14:19 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Li", "Yanyan", ""], ["Kim", "Sara", ""], ["Sy", "Eric", ""]]}, {"id": "2102.11455", "submitter": "Abhijeet Sahu", "authors": "Patrick Wlazlo, Abhijeet Sahu, Zeyu Mao, Hao Huang, Ana Goulart,\n  Katherine Davis, Saman Zonouz", "title": "Man-in-The-Middle Attacks and Defense in a Power System Cyber-Physical\n  Testbed", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Man-in-The-Middle (MiTM) attacks present numerous threats to a smart grid. In\na MiTM attack, an intruder embeds itself within a conversation between two\ndevices to either eavesdrop or impersonate one of the devices, making it appear\nto be a normal exchange of information. Thus, the intruder can perform false\ndata injection (FDI) and false command injection (FCI) attacks that can\ncompromise power system operations, such as state estimation, economic\ndispatch, and automatic generation control (AGC). Very few researchers have\nfocused on MiTM methods that are difficult to detect within a smart grid. To\naddress this, we are designing and implementing multi-stage MiTM intrusions in\nan emulation-based cyber-physical power system testbed against a large-scale\nsynthetic grid model to demonstrate how such attacks can cause physical\ncontingencies such as misguided operation and false measurements. MiTM\nintrusions create FCI, FDI, and replay attacks in this synthetic power grid.\nThis work enables stakeholders to defend against these stealthy attacks, and we\npresent detection mechanisms that are developed using multiple alerts from\nintrusion detection systems and network monitoring tools. Our contribution will\nenable other smart grid security researchers and industry to develop further\ndetection mechanisms for inconspicuous MiTM attacks.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 01:59:56 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Wlazlo", "Patrick", ""], ["Sahu", "Abhijeet", ""], ["Mao", "Zeyu", ""], ["Huang", "Hao", ""], ["Goulart", "Ana", ""], ["Davis", "Katherine", ""], ["Zonouz", "Saman", ""]]}, {"id": "2102.11484", "submitter": "Maanak Gupta", "authors": "Maanak Gupta and Ravi Sandhu", "title": "Towards Activity-Centric Access Control for Smart Collaborative\n  Ecosystems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The ubiquitous presence of smart devices along with advancements in\nconnectivity coupled with the elastic capabilities of cloud and edge systems\nhave nurtured and revolutionized smart ecosystems. Intelligent, integrated\ncyber-physical systems offer increased productivity, safety, efficiency, speed\nand support for data driven applications beyond imagination just a decade ago.\nSince several connected devices work together as a coordinated unit to ensure\nefficiency and automation, the individual operations they perform are often\nreliant on each other. Therefore, it is important to control what functions or\nactivities different devices can perform at a particular moment of time, and\nhow they are related to each other. It is also important to consider additional\nfactors such as conditions, obligation or mutability of activities, which are\ncritical in deciding whether or not a device can perform a requested activity.\nIn this paper, we take an initial step to propose and discuss the concept of\nActivity-Centric Access Control (ACAC) for smart and connected ecosystem. We\ndiscuss the notion of activity with respect to the collaborative and\ndistributed yet integrated systems and identify the different entities involved\nalong with the important factors to make an activity control decision. We\noutline a preliminary approach for defining activity control expressions which\ncan be applied to different smart objects in the system. The main goal of this\npaper is to present the vision and need for the activity-centric approach for\naccess control in connected smart systems, and foster discussion on the\nidentified future research agenda.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 04:28:15 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Gupta", "Maanak", ""], ["Sandhu", "Ravi", ""]]}, {"id": "2102.11491", "submitter": "Dmytro Humeniuk", "authors": "Dmytro Humeniuk, Giuliano Antoniol, Foutse Khomh", "title": "Data Driven Testing of Cyber Physical Systems", "comments": "4 pages, to be published in SBST2021 workshop proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Consumer grade cyber-physical systems (CPS) are becoming an integral part of\nour life, automatizing and simplifying everyday tasks. Indeed, due to complex\ninteractions between hardware, networking and software, developing and testing\nsuch systems is known to be a challenging task. Various quality assurance and\ntesting strategies have been proposed. The most common approach for\npre-deployment testing is to model the system and run simulations with models\nor software in the loop. In practice, most often, tests are run for a small\nnumber of simulations, which are selected based on the engineers' domain\nknowledge and experience. In this paper we propose an approach to automatically\ngenerate fault-revealing test cases for CPS. We have implemented our approach\nin Python, using standard frameworks and used it to generate scenarios\nviolating temperature constraints for a smart thermostat implemented as a part\nof our IoT testbed. Data collected from an application managing a smart\nbuilding have been used to learn models of the environment under ever changing\nconditions. The suggested approach allowed us to identify several pit-fails,\nscenarios (i.e., environment conditions and inputs), where the system behaves\nnot as expected.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 04:55:10 GMT"}, {"version": "v2", "created": "Tue, 23 Mar 2021 11:52:02 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Humeniuk", "Dmytro", ""], ["Antoniol", "Giuliano", ""], ["Khomh", "Foutse", ""]]}, {"id": "2102.11498", "submitter": "Siddhartha Shankar Das", "authors": "Siddhartha Shankar Das, Edoardo Serra, Mahantesh Halappanavar, Alex\n  Pothen, Ehab Al-Shaer", "title": "V2W-BERT: A Framework for Effective Hierarchical Multiclass\n  Classification of Software Vulnerabilities", "comments": "Under submission to KDD 2021 Applied Data Science Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Weaknesses in computer systems such as faults, bugs and errors in the\narchitecture, design or implementation of software provide vulnerabilities that\ncan be exploited by attackers to compromise the security of a system. Common\nWeakness Enumerations (CWE) are a hierarchically designed dictionary of\nsoftware weaknesses that provide a means to understand software flaws,\npotential impact of their exploitation, and means to mitigate these flaws.\nCommon Vulnerabilities and Exposures (CVE) are brief low-level descriptions\nthat uniquely identify vulnerabilities in a specific product or protocol.\nClassifying or mapping of CVEs to CWEs provides a means to understand the\nimpact and mitigate the vulnerabilities. Since manual mapping of CVEs is not a\nviable option, automated approaches are desirable but challenging.\n  We present a novel Transformer-based learning framework (V2W-BERT) in this\npaper. By using ideas from natural language processing, link prediction and\ntransfer learning, our method outperforms previous approaches not only for CWE\ninstances with abundant data to train, but also rare CWE classes with little or\nno data to train. Our approach also shows significant improvements in using\nhistorical data to predict links for future instances of CVEs, and therefore,\nprovides a viable approach for practical applications. Using data from MITRE\nand National Vulnerability Database, we achieve up to 97% prediction accuracy\nfor randomly partitioned data and up to 94% prediction accuracy in temporally\npartitioned data. We believe that our work will influence the design of better\nmethods and training models, as well as applications to solve increasingly\nharder problems in cybersecurity.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 05:16:57 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Das", "Siddhartha Shankar", ""], ["Serra", "Edoardo", ""], ["Halappanavar", "Mahantesh", ""], ["Pothen", "Alex", ""], ["Al-Shaer", "Ehab", ""]]}, {"id": "2102.11502", "submitter": "Hu Wang", "authors": "Liuqiao Chen, Hu Wang, Benjamin Zi Hao Zhao, Minhui Xue and Haifeng\n  Qian", "title": "Oriole: Thwarting Privacy against Trustworthy Deep Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks have achieved unprecedented success in the field of face\nrecognition such that any individual can crawl the data of others from the\nInternet without their explicit permission for the purpose of training\nhigh-precision face recognition models, creating a serious violation of\nprivacy. Recently, a well-known system named Fawkes (published in USENIX\nSecurity 2020) claimed this privacy threat can be neutralized by uploading\ncloaked user images instead of their original images. In this paper, we present\nOriole, a system that combines the advantages of data poisoning attacks and\nevasion attacks, to thwart the protection offered by Fawkes, by training the\nattacker face recognition model with multi-cloaked images generated by Oriole.\nConsequently, the face recognition accuracy of the attack model is maintained\nand the weaknesses of Fawkes are revealed. Experimental results show that our\nproposed Oriole system is able to effectively interfere with the performance of\nthe Fawkes system to achieve promising attacking results. Our ablation study\nhighlights multiple principal factors that affect the performance of the Oriole\nsystem, including the DSSIM perturbation budget, the ratio of leaked clean user\nimages, and the numbers of multi-cloaks for each uncloaked image. We also\nidentify and discuss at length the vulnerabilities of Fawkes. We hope that the\nnew methodology presented in this paper will inform the security community of a\nneed to design more robust privacy-preserving deep learning models.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 05:33:55 GMT"}, {"version": "v2", "created": "Sun, 16 May 2021 06:37:27 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Chen", "Liuqiao", ""], ["Wang", "Hu", ""], ["Zhao", "Benjamin Zi Hao", ""], ["Xue", "Minhui", ""], ["Qian", "Haifeng", ""]]}, {"id": "2102.11656", "submitter": "Thilo Krachenfels", "authors": "Thilo Krachenfels, Tuba Kiyan, Shahin Tajik, Jean-Pierre Seifert", "title": "Automatic Extraction of Secrets from the Transistor Jungle using\n  Laser-Assisted Side-Channel Attacks", "comments": "This is the preprint of the article accepted for publication at\n  USENIX Security 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The security of modern electronic devices relies on secret keys stored on\nsecure hardware modules as the root-of-trust (RoT). Extracting those keys would\nbreak the security of the entire system. As shown before, sophisticated\nside-channel analysis (SCA) attacks, using chip failure analysis (FA)\ntechniques, can extract data from on-chip memory cells. However, since the\nchip's layout is unknown to the adversary in practice, secret key localization\nand reverse engineering are onerous tasks. Consequently, hardware vendors\ncommonly believe that the ever-growing physical complexity of the integrated\ncircuit (IC) designs can be a natural barrier against potential adversaries. In\nthis work, we present a novel approach that can extract the secret key without\nany knowledge of the IC's layout, and independent from the employed memory\ntechnology as key storage. We automate the -- traditionally very\nlabor-intensive -- reverse engineering and data extraction process. To that\nend, we demonstrate that black-box measurements captured using laser-assisted\nSCA techniques from a training device with known key can be used to profile the\ndevice for a later key prediction on other victim devices with unknown keys. To\nshowcase the potential of our approach, we target keys on three different\nhardware platforms, which are utilized as RoT in different products.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 12:23:46 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Krachenfels", "Thilo", ""], ["Kiyan", "Tuba", ""], ["Tajik", "Shahin", ""], ["Seifert", "Jean-Pierre", ""]]}, {"id": "2102.11773", "submitter": "Mark Vella", "authors": "Mark Vella and Christian Colombo", "title": "SpotCheck: On-Device Anomaly Detection for Android", "comments": null, "journal-ref": "SIN 2020: 13th International Conference on Security of Information\n  and Networks, Merkez, Turkey, November 2020", "doi": "10.1145/3433174.3433591", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In recent years the PC has been replaced by mobile devices for many security\nsensitive operations, both from a privacy and a financial standpoint. While\nsecurity mechanisms are deployed at various levels, these are frequently put\nunder strain by previously unseen malware. An additional protection layer\ncapable of novelty detection is therefore needed. In this work we propose\nSpotCheck, an anomaly detector intended to run on Android devices. It samples\napp executions and submits suspicious apps to more thorough processing by\nmalware sandboxes. We compare Kernel Principal Component Analysis (KPCA) and\nVariational Autoencoders (VAE) on app execution representations based on the\nwell-known system call traces, as well as a novel approach based on memory\ndumps. Results show that when using VAE, SpotCheck attains a level of\neffectiveness comparable to what has been previously achieved for network\nanomaly detection. Interestingly this is also true for the memory dump\napproach, relinquishing the need for continuous app monitoring.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 16:09:35 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 06:53:27 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Vella", "Mark", ""], ["Colombo", "Christian", ""]]}, {"id": "2102.11845", "submitter": "Daniel Levy", "authors": "Daniel Levy, Ziteng Sun, Kareem Amin, Satyen Kale, Alex Kulesza,\n  Mehryar Mohri, Ananda Theertha Suresh", "title": "Learning with User-Level Privacy", "comments": "39 pages, 0 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and analyze algorithms to solve a range of learning tasks under\nuser-level differential privacy constraints. Rather than guaranteeing only the\nprivacy of individual samples, user-level DP protects a user's entire\ncontribution ($m \\ge 1$ samples), providing more stringent but more realistic\nprotection against information leaks. We show that for high-dimensional mean\nestimation, empirical risk minimization with smooth losses, stochastic convex\noptimization, and learning hypothesis class with finite metric entropy, the\nprivacy cost decreases as $O(1/\\sqrt{m})$ as users provide more samples. In\ncontrast, when increasing the number of users $n$, the privacy cost decreases\nat a faster $O(1/n)$ rate. We complement these results with lower bounds\nshowing the worst-case optimality of our algorithm for mean estimation and\nstochastic convex optimization. Our algorithms rely on novel techniques for\nprivate mean estimation in arbitrary dimension with error scaling as the\nconcentration radius $\\tau$ of the distribution rather than the entire range.\nUnder uniform convergence, we derive an algorithm that privately answers a\nsequence of $K$ adaptively chosen queries with privacy cost proportional to\n$\\tau$, and apply it to solve the learning tasks we consider.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 18:25:13 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 06:37:09 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Levy", "Daniel", ""], ["Sun", "Ziteng", ""], ["Amin", "Kareem", ""], ["Kale", "Satyen", ""], ["Kulesza", "Alex", ""], ["Mohri", "Mehryar", ""], ["Suresh", "Ananda Theertha", ""]]}, {"id": "2102.11849", "submitter": "Saptarshi Purkayastha", "authors": "Saptarshi Purkayastha, Shreya Goyal, Bolu Oluwalade, Tyler Phillips,\n  Huanmei Wu, Xukai Zou", "title": "Usability and Security of Different Authentication Methods for an\n  Electronic Health Records System", "comments": "HEALTHINF21 at the 14th International Joint Conference on Biomedical\n  Engineering Systems and Technologies (BIOSTEC 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conducted a survey of 67 graduate students enrolled in the Privacy and\nSecurity in Healthcare course at Indiana University Purdue University\nIndianapolis. This was done to measure user preference and their understanding\nof usability and security of three different Electronic Health Records\nauthentication methods: single authentication method (username and password),\nSingle sign-on with Central Authentication Service (CAS) authentication method,\nand a bio-capsule facial authentication method. This research aims to explore\nthe relationship between security and usability, and measure the effect of\nperceived security on usability in these three aforementioned authentication\nmethods. We developed a formative-formative Partial Least Square Structural\nEquation Modeling (PLS-SEM) model to measure the relationship between the\nlatent variables of Usability, and Security. The measurement model was\ndeveloped using five observed variables (measures). - Efficiency and\nEffectiveness, Satisfaction, Preference, Concerns, and Confidence. The results\nobtained highlight the importance and impact of these measures on the latent\nvariables and the relationship among the latent variables. From the PLS-SEM\nanalysis, it was found that security has a positive impact on usability for\nSingle sign-on and bio-capsule facial authentication methods. We conclude that\nthe facial authentication method was the most secure and usable among the three\nauthentication methods. Further, descriptive analysis was done to draw out the\ninteresting findings from the survey regarding the observed variables.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 18:29:26 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Purkayastha", "Saptarshi", ""], ["Goyal", "Shreya", ""], ["Oluwalade", "Bolu", ""], ["Phillips", "Tyler", ""], ["Wu", "Huanmei", ""], ["Zou", "Xukai", ""]]}, {"id": "2102.11955", "submitter": "Casey Meehan", "authors": "Casey Meehan, Kamalika Chaudhuri", "title": "Location Trace Privacy Under Conditional Priors", "comments": "To be published in the proceedings of AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Providing meaningful privacy to users of location based services is\nparticularly challenging when multiple locations are revealed in a short period\nof time. This is primarily due to the tremendous degree of dependence that can\nbe anticipated between points. We propose a R\\'enyi divergence based privacy\nframework for bounding expected privacy loss for conditionally dependent data.\nAdditionally, we demonstrate an algorithm for achieving this privacy under\nGaussian process conditional priors. This framework both exemplifies why\nconditionally dependent data is so challenging to protect and offers a strategy\nfor preserving privacy to within a fixed radius for sensitive locations in a\nuser's trace.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 21:55:34 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Meehan", "Casey", ""], ["Chaudhuri", "Kamalika", ""]]}, {"id": "2102.11976", "submitter": "Dana Yang", "authors": "Jiaming Xu, Kuang Xu and Dana Yang", "title": "Learner-Private Online Convex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online convex optimization is a framework where a learner sequentially\nqueries an external data source in order to arrive at the optimal solution of a\nconvex function. The paradigm has gained significant popularity recently thanks\nto its scalability in large-scale optimization and machine learning. The\nrepeated interactions, however, expose the learner to privacy risks from\neavesdropping adversary that observe the submitted queries. In this paper, we\nstudy how to optimally obfuscate the learner's queries in first-order online\nconvex optimization, so that their learned optimal value is provably difficult\nto estimate for the eavesdropping adversary. We consider two formulations of\nlearner privacy: a Bayesian formulation in which the convex function is drawn\nrandomly, and a minimax formulation in which the function is fixed and the\nadversary's probability of error is measured with respect to a minimax\ncriterion. We show that, if the learner wants to ensure the probability of\naccurate prediction by the adversary be kept below $1/L$, then the overhead in\nquery complexity is additive in $L$ in the minimax formulation, but\nmultiplicative in $L$ in the Bayesian formulation. Compared to existing\nlearner-private sequential learning models with binary feedback, our results\napply to the significantly richer family of general convex functions with\nfull-gradient feedback. Our proofs are largely enabled by tools from the theory\nof Dirichlet processes, as well as more sophisticated lines of analysis aimed\nat measuring the amount of information leakage under a full-gradient oracle.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 23:00:44 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Xu", "Jiaming", ""], ["Xu", "Kuang", ""], ["Yang", "Dana", ""]]}, {"id": "2102.12002", "submitter": "Ecenaz Erdemir", "authors": "Ecenaz Erdemir, Jeffrey Bickford, Luca Melis and Sergul Aydore", "title": "Adversarial Robustness with Non-uniform Perturbations", "comments": "21 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustness of machine learning models is critical for security related\napplications, where real-world adversaries are uniquely focused on evading\nneural network based detectors. Prior work mainly focus on crafting adversarial\nexamples (AEs) with small uniform norm-bounded perturbations across features to\nmaintain the requirement of imperceptibility. However, uniform perturbations do\nnot result in realistic AEs in domains such as malware, finance, and social\nnetworks. For these types of applications, features typically have some\nsemantically meaningful dependencies. The key idea of our proposed approach is\nto enable non-uniform perturbations that can adequately represent these feature\ndependencies during adversarial training. We propose using characteristics of\nthe empirical data distribution, both on correlations between the features and\nthe importance of the features themselves. Using experimental datasets for\nmalware classification, credit risk prediction, and spam detection, we show\nthat our approach is more robust to real-world attacks. Finally, we present\nrobustness certification utilizing non-uniform perturbation bounds, and show\nthat non-uniform bounds achieve better certification.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 00:54:43 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 21:40:50 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Erdemir", "Ecenaz", ""], ["Bickford", "Jeffrey", ""], ["Melis", "Luca", ""], ["Aydore", "Sergul", ""]]}, {"id": "2102.12099", "submitter": "Vitaly Feldman", "authors": "Vitaly Feldman and Kunal Talwar", "title": "Lossless Compression of Efficient Private Local Randomizers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Locally Differentially Private (LDP) Reports are commonly used for collection\nof statistics and machine learning in the federated setting. In many cases the\nbest known LDP algorithms require sending prohibitively large messages from the\nclient device to the server (such as when constructing histograms over large\ndomain or learning a high-dimensional model). This has led to significant\nefforts on reducing the communication cost of LDP algorithms.\n  At the same time LDP reports are known to have relatively little information\nabout the user's data due to randomization. Several schemes are known that\nexploit this fact to design low-communication versions of LDP algorithm but all\nof them do so at the expense of a significant loss in utility. Here we\ndemonstrate a general approach that, under standard cryptographic assumptions,\ncompresses every efficient LDP algorithm with negligible loss in privacy and\nutility guarantees. The practical implication of our result is that in typical\napplications the message can be compressed to the size of the server's\npseudo-random generator seed. More generally, we relate the properties of an\nLDP randomizer to the power of a pseudo-random generator that suffices for\ncompressing the LDP randomizer. From this general approach we derive\nlow-communication algorithms for the problems of frequency estimation and\nhigh-dimensional mean estimation. Our algorithms are simpler and more accurate\nthan existing low-communication LDP algorithms for these well-studied problems.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 07:04:30 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Feldman", "Vitaly", ""], ["Talwar", "Kunal", ""]]}, {"id": "2102.12192", "submitter": "Noga Bar", "authors": "Noga Bar, Tomer Koren, Raja Giryes", "title": "Multiplicative Reweighting for Robust Neural Network Optimization", "comments": "Our code is publicly available in\n  https://github.com/NogaBar/mr_robust_optim", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Deep neural networks are widespread due to their powerful performance. Yet,\nthey suffer from degraded performance in the presence of noisy labels at train\ntime or adversarial examples during inference. Inspired by the setting of\nlearning with expert advice, where multiplicative weights (MW) updates were\nrecently shown to be robust to moderate adversarial corruptions, we propose to\nuse MW for reweighting examples during neural networks optimization. We\nestablish the convergence of our method when used with gradient descent and\nshow its advantage in two simple examples. We then validate empirically our\nfindings by demonstrating that MW improve networks accuracy in the presence of\nlabel noise on CIFAR-10, CIFAR-100 and Clothing1M, and leads to better\nrobustness to adversarial attacks.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 10:40:25 GMT"}, {"version": "v2", "created": "Sat, 19 Jun 2021 19:03:57 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Bar", "Noga", ""], ["Koren", "Tomer", ""], ["Giryes", "Raja", ""]]}, {"id": "2102.12222", "submitter": "Sheik Mohammad Mostakim Fattah", "authors": "Sheik Mohammad Mostakim Fattah, Athman Bouguettaya, and Sajib Mistry", "title": "Long-term IaaS Provider Selection using Short-term Trial Experience", "comments": "published in IEEE ICWS 2019", "journal-ref": null, "doi": "10.1109/ICWS.2019.00058", "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel approach to select privacy-sensitive IaaS providers for a\nlong-term period. The proposed approach leverages a consumer's short-term trial\nexperiences for long-term selection. We design a novel equivalence partitioning\nbased trial strategy to discover the temporal and unknown QoS performance\nvariability of an IaaS provider. The consumer's long-term workloads are\npartitioned into multiple Virtual Machines in the short-term trial. We propose\na performance fingerprint matching approach to ascertain the confidence of the\nconsumer's trial experience. A trial experience transformation method is\nproposed to estimate the actual long-term performance of the provider.\nExperimental results with real-world datasets demonstrate the efficiency of the\nproposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 11:22:53 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Fattah", "Sheik Mohammad Mostakim", ""], ["Bouguettaya", "Athman", ""], ["Mistry", "Sajib", ""]]}, {"id": "2102.12273", "submitter": "Alberto Sonnino", "authors": "Alberto Sonnino", "title": "Scaling Distributed Ledgers and Privacy-Preserving Applications", "comments": "PhD thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This thesis proposes techniques aiming to make blockchain technologies and\nsmart contract platforms practical by improving their scalability, latency, and\nprivacy. This thesis starts by presenting the design and implementation of\nChainspace, a distributed ledger that supports user defined smart contracts and\nexecute user-supplied transactions on their objects. The correct execution of\nsmart contract transactions is publicly verifiable. Chainspace is scalable by\nsharding state; it is secure against subsets of nodes trying to compromise its\nintegrity or availability properties through Byzantine Fault Tolerance (BFT).\nThis thesis also introduces a family of replay attacks against sharded\ndistributed ledgers targeting cross-shard consensus protocols; they allow an\nattacker, with network access only, to double-spend resources with minimal\nefforts. We then build Byzcuit, a new cross-shard consensus protocol that is\nimmune to those attacks and that is tailored to run at the heart of Chainspace.\nNext, we propose FastPay, a high-integrity settlement system for pre-funded\npayments that can be used as a financial side-infrastructure for Chainspace to\nsupport low-latency retail payments. This settlement system is based on\nByzantine Consistent Broadcast as its core primitive, foregoing the expenses of\nfull atomic commit channels (consensus). The resulting system has extremely\nlow-latency for both confirmation and payment finality. Finally, this thesis\nproposes Coconut, a selective disclosure credential scheme supporting\ndistributed threshold issuance, public and private attributes,\nre-randomization, and multiple unlinkable selective attribute revelations. It\nensures authenticity and availability even when a subset of credential issuing\nauthorities are malicious or offline, and natively integrates with Chainspace\nto enable a number of scalable privacy-preserving applications.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 13:29:02 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Sonnino", "Alberto", ""]]}, {"id": "2102.12284", "submitter": "Dunjie Zhang", "authors": "Jinyin Chen, Xiang Lin, Dunjie Zhang, Wenrong Jiang, Guohan Huang, Hui\n  Xiong, and Yun Xiang", "title": "Graphfool: Targeted Label Adversarial Attack on Graph Embedding", "comments": "9 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is effective in graph analysis. It is widely applied in many\nrelated areas, such as link prediction, node classification, community\ndetection, and graph classification etc. Graph embedding, which learns\nlow-dimensional representations for vertices or edges in the graph, usually\nemploys deep models to derive the embedding vector. However, these models are\nvulnerable. We envision that graph embedding methods based on deep models can\nbe easily attacked using adversarial examples. Thus, in this paper, we propose\nGraphfool, a novel targeted label adversarial attack on graph embedding. It can\ngenerate adversarial graph to attack graph embedding methods via classifying\nboundary and gradient information in graph convolutional network (GCN).\nSpecifically, we perform the following steps: 1),We first estimate the\nclassification boundaries of different classes. 2), We calculate the minimal\nperturbation matrix to misclassify the attacked vertex according to the target\nclassification boundary. 3), We modify the adjacency matrix according to the\nmaximal absolute value of the disturbance matrix. This process is implemented\niteratively. To the best of our knowledge, this is the first targeted label\nattack technique. The experiments on real-world graph networks demonstrate that\nGraphfool can derive better performance than state-of-art techniques. Compared\nwith the second best algorithm, Graphfool can achieve an average improvement of\n11.44% in attack success rate.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 13:45:38 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Chen", "Jinyin", ""], ["Lin", "Xiang", ""], ["Zhang", "Dunjie", ""], ["Jiang", "Wenrong", ""], ["Huang", "Guohan", ""], ["Xiong", "Hui", ""], ["Xiang", "Yun", ""]]}, {"id": "2102.12345", "submitter": "Jan Tobias Muehlberg", "authors": "Timothy Werquin and Mathijs Hubrechtsen and Ashok Thangarajan and\n  Frank Piessens and Jan Tobias Muehlberg", "title": "Automated Fuzzing of Automotive Control Units", "comments": "Appeared in 2019 International Workshop on Attacks and Defenses for\n  Internet-of-Things (ADIoT) / International Workshop on the Secure Internet of\n  Things (SIoT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern vehicles are governed by a network of Electronic Control Units (ECUs),\nwhich are programmed to sense inputs from the driver and the environment, to\nprocess these inputs, and to control actuators that, e.g., regulate the engine\nor even control the steering system. ECUs within a vehicle communicate via\nautomotive bus systems such as the Controller Area Network (CAN), and beyond\nthe vehicles boundaries through upcoming vehicle-to-vehicle and\nvehicle-to-infrastructure channels. Approaches to manipulate the communication\nbetween ECUs for the purpose of security testing and reverse-engineering of\nvehicular functions have been presented in the past, all of which struggle with\nautomating the detection of system change in response to message injection. In\nthis paper we present our findings with fuzzing CAN networks, in particular\nwhile observing individual ECUs with a sensor harness. The harness detects\nphysical responses, which we then use in a oracle functions to inform the\nfuzzing process. We systematically define fuzzers, fuzzing configurations and\noracle functions for testing ECUs. We evaluate our approach based on case\nstudies of commercial instrument clusters and with an experimental framework\nfor CAN authentication. Our results show that the approach is capable of\nidentifying interesting ECU states with a high level of automation. Our\napproach is applicable in distributed cyber-physical systems beyond automotive\ncomputing.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 15:28:36 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Werquin", "Timothy", ""], ["Hubrechtsen", "Mathijs", ""], ["Thangarajan", "Ashok", ""], ["Piessens", "Frank", ""], ["Muehlberg", "Jan Tobias", ""]]}, {"id": "2102.12362", "submitter": "Mirza Beg", "authors": "Ayesha Qamar, Tehreem Javed, and Mirza Omer Beg", "title": "Detecting Compliance of Privacy Policies with Data Protection Laws", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Privacy Policies are the legal documents that describe the practices that an\norganization or company has adopted in the handling of the personal data of its\nusers. But as policies are a legal document, they are often written in\nextensive legal jargon that is difficult to understand. Though work has been\ndone on privacy policies but none that caters to the problem of verifying if a\ngiven privacy policy adheres to the data protection laws of a given country or\nstate. We aim to bridge that gap by providing a framework that analyzes privacy\npolicies in light of various data protection laws, such as the General Data\nProtection Regulation (GDPR). To achieve that, firstly we labeled both the\nprivacy policies and laws. Then a correlation scheme is developed to map the\ncontents of a privacy policy to the appropriate segments of law that a policy\nmust conform to. Then we check the compliance of privacy policy's text with the\ncorresponding text of the law using NLP techniques. By using such a tool, users\nwould be better equipped to understand how their personal data is managed. For\nnow, we have provided a mapping for the GDPR and PDPA, but other laws can\neasily be incorporated in the already built pipeline.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 09:15:15 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Qamar", "Ayesha", ""], ["Javed", "Tehreem", ""], ["Beg", "Mirza Omer", ""]]}, {"id": "2102.12412", "submitter": "Antti Koskela", "authors": "Antti Koskela and Antti Honkela", "title": "Computing Differential Privacy Guarantees for Heterogeneous Compositions\n  Using FFT", "comments": "44 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recently proposed Fast Fourier Transform (FFT)-based accountant for\nevaluating $(\\varepsilon,\\delta)$-differential privacy guarantees using the\nprivacy loss distribution formalism has been shown to give tighter bounds than\ncommonly used methods such as R\\'enyi accountants when applied to homogeneous\ncompositions, i.e., to compositions of identical mechanisms. In this paper, we\nextend this approach to heterogeneous compositions. We carry out a full error\nanalysis that allows choosing the parameters of the algorithm such that a\ndesired accuracy is obtained. The analysis also extends previous results by\ntaking into account all the parameters of the algorithm. Using the error\nanalysis, we also give a bound for the computational complexity in terms of the\nerror which is analogous to and slightly tightens the one given by Murtagh and\nVadhan (2018). We also show how to speed up the evaluation of tight privacy\nguarantees using the Plancherel theorem at the cost of increased\npre-computation and memory usage.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 17:05:38 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 11:27:44 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Koskela", "Antti", ""], ["Honkela", "Antti", ""]]}, {"id": "2102.12467", "submitter": "Abhimanyu Dubey", "authors": "Abhimanyu Dubey", "title": "No-Regret Algorithms for Private Gaussian Process Bandit Optimization", "comments": "AISTATS21 Camera Ready v1", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread proliferation of data-driven decision-making has ushered in a\nrecent interest in the design of privacy-preserving algorithms. In this paper,\nwe consider the ubiquitous problem of gaussian process (GP) bandit optimization\nfrom the lens of privacy-preserving statistics. We propose a solution for\ndifferentially private GP bandit optimization that combines a uniform kernel\napproximator with random perturbations, providing a generic framework to create\ndifferentially-private (DP) Gaussian process bandit algorithms. For two\nspecific DP settings - joint and local differential privacy, we provide\nalgorithms based on efficient quadrature Fourier feature approximators, that\nare computationally efficient and provably no-regret for popular stationary\nkernel functions. Our algorithms maintain differential privacy throughout the\noptimization procedure and critically do not rely explicitly on the sample path\nfor prediction, making the parameters straightforward to release as well.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 18:52:24 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Dubey", "Abhimanyu", ""]]}, {"id": "2102.12473", "submitter": "Thomas Hardjono", "authors": "Thomas Hardjono", "title": "Attestation Infrastructures for Private Wallets", "comments": "9 pages; 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper we focus on one part of the trust infrastructures needed for\nthe future virtual assets industry, namely the attestation infrastructure\nrelated to key management in private wallet systems. Our focus is on regulated\nprivate wallets utilizing trusted hardware, and the capability of the wallet to\nyield attestation evidence suitable to address requirements in several\nuse-cases, such as asset insurance and regulatory compliance. We argue that\nattestation services will be needed as a core part of the key management\nlifecycle for private wallets in true decentralized systems.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 18:56:33 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Hardjono", "Thomas", ""]]}, {"id": "2102.12566", "submitter": "Stephen MacDonell", "authors": "Sherlock A. Licorish, Stephen G. MacDonell and Tony Clear", "title": "Analyzing Confidentiality and Privacy Concerns: Insights from Android\n  Issue Logs", "comments": "Conference paper, 10 pages, 3 figures, 7 tables", "journal-ref": "Proceedings of the 19th International Conference on Evaluation and\n  Assessment in Software Engineering (EASE2015). Nanjing, China, ACM Press,\n  pp.1-10", "doi": "10.1145/2745802.2745819", "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context: Post-release user feedback plays an integral role in improving\nsoftware quality and informing new features. Given its growing importance,\nfeedback concerning security enhancements is particularly noteworthy. In\nconsidering the rapid uptake of Android we have examined the scale and severity\nof Android security threats as reported by its stakeholders. Objective: We\nsystematically mine Android issue logs to derive insights into stakeholder\nperceptions and experiences in relation to certain Android security issues.\nMethod: We employed contextual analysis techniques to study issues raised\nregarding confidentiality and privacy in the last three major Android releases,\nconsidering covariance of stakeholder comments, and the level of consistency in\nuser preferences and priorities. Results: Confidentiality and privacy concerns\nvaried in severity, and were most prevalent over Jelly Bean releases. Issues\nraised in regard to confidentiality related mostly to access, user credentials\nand permission management, while privacy concerns were mainly expressed about\nphone locking. Community users also expressed divergent preferences for new\nsecurity features, ranging from more relaxed to very strict. Conclusion:\nStrategies that support continuous corrective measures for both old and new\nAndroid releases would likely maintain stakeholder confidence. An approach that\nprovides users with basic default security settings, but with the power to\nconfigure additional security features if desired, would provide the best\nbalance for Android's wide cohort of stakeholders.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 21:31:00 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Licorish", "Sherlock A.", ""], ["MacDonell", "Stephen G.", ""], ["Clear", "Tony", ""]]}, {"id": "2102.12621", "submitter": "Ba Dung Le Dr", "authors": "Ba Dung Le and Tanveer Zia", "title": "Discrete Distribution Estimation with Local Differential Privacy: A\n  Comparative Analysis", "comments": "Accepted for publication to SPT-IoT 2021: The Fifth Workshop on\n  Security, Privacy and Trust in the Internet of Things", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Local differential privacy is a promising privacy-preserving model for\nstatistical aggregation of user data that prevents user privacy leakage from\nthe data aggregator. This paper focuses on the problem of estimating the\ndistribution of discrete user values with Local differential privacy. We review\nand present a comparative analysis on the performance of the existing discrete\ndistribution estimation algorithms in terms of their accuracy on benchmark\ndatasets. Our evaluation benchmarks include real-world and synthetic datasets\nof categorical individual values with the number of individuals from hundreds\nto millions and the domain size up to a few hundreds of values. The\nexperimental results show that the Basic RAPPOR algorithm generally performs\nbest for the benchmark datasets in the high privacy regime while the k-RR\nalgorithm often gives the best estimation in the low privacy regime. In the\nmedium privacy regime, the performance of the k-RR, the k-subset, and the HR\nalgorithms are fairly competitive with each other and generally better than the\nperformance of the Basic RAPPOR and the CMS algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 01:32:06 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Le", "Ba Dung", ""], ["Zia", "Tanveer", ""]]}, {"id": "2102.12699", "submitter": "Marzieh Masoumi", "authors": "Marzieh Masoumi, Ahmad Keshavarz, Reza Fotohi", "title": "File fragment recognition based on content and statistical features", "comments": "16 pages, 7 figures, 8 tables. Multimed Tools Appl (2021)", "journal-ref": null, "doi": "10.1007/s11042-021-10681-x", "report-no": null, "categories": "cs.CR cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nowadays, the speed up development and use of digital devices such as\nsmartphones have put people at risk of internet crimes. The evidence of present\ncrimes in a computer file can be easily unreachable by changing the prefix of a\nfile or other algorithms. In more complex cases, either file divided into\ndifferent parts or the parts of a file that has information about the file type\nare deleted, where the file fragment recognition issue is discussed. The known\nfiles are divided into different fragments, and different classification\nalgorithms are used to solve the problems of file fragment recognition. The\nissue of identifying the type of file fragment due to its importance in\ncybercrime issues as well as antivirus has been highly emphasized and has been\naddressed in many articles. Increasing the accuracy in this field on the types\nof widely used files due to the sensitivity of the subject of recognizing the\ntype of file under study is the main goal of researchers in this field. Failure\nto identify the correct type of file will lead to deviations of the results and\nevidence from the main issue or failure to conclude. In this paper, first, the\nfile is divided into different fragments. Then, the file fragment features,\nwhich are obtained from Binary Frequency Distribution, are reduced by 2 feature\nreduction algorithms; Sequential Forward Selection algorithm as well as\nSequential Floating Forward Selection algorithm to delete sparse features that\nresult in increased accuracy and speed. Finally, the reduced features are given\nto 3 Multiclass classifier algorithms, Multilayer Perceptron, Support Vector\nMachines, and K-Nearest Neighbor for classification and comparison of the\nresults. The proposed recognition algorithm can recognize 6 types of useful\nfiles and may distinguish a type of file fragments with higher accuracy than\nthe similar works done.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 06:00:25 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Masoumi", "Marzieh", ""], ["Keshavarz", "Ahmad", ""], ["Fotohi", "Reza", ""]]}, {"id": "2102.12730", "submitter": "Shravan Ravi Narayan", "authors": "Shravan Narayan, Craig Disselkoen, Daniel Moghimi, Sunjay Cauligi,\n  Evan Johnson, Zhao Gang, Anjo Vahldiek-Oberwagner, Ravi Sahita, Hovav\n  Shacham, Dean Tullsen, Deian Stefan", "title": "Swivel: Hardening WebAssembly against Spectre", "comments": "Accepted at USENIX 21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe Swivel, a new compiler framework for hardening WebAssembly (Wasm)\nagainst Spectre attacks. Outside the browser, Wasm has become a popular\nlightweight, in-process sandbox and is, for example, used in production to\nisolate different clients on edge clouds and function-as-a-service platforms.\nUnfortunately, Spectre attacks can bypass Wasm's isolation guarantees. Swivel\nhardens Wasm against this class of attacks by ensuring that potentially\nmalicious code can neither use Spectre attacks to break out of the Wasm sandbox\nnor coerce victim code-another Wasm client or the embedding process-to leak\nsecret data.\n  We describe two Swivel designs, a software-only approach that can be used on\nexisting CPUs, and a hardware-assisted approach that uses extension available\nin Intel 11th generation CPUs. For both, we evaluate a randomized approach that\nmitigates Spectre and a deterministic approach that eliminates Spectre\naltogether. Our randomized implementations impose under 10.3% overhead on the\nWasm-compatible subset of SPEC 2006, while our deterministic implementations\nimpose overheads between 3.3% and 240.2%. Though high on some benchmarks,\nSwivel's overhead is still between 9x and 36.3x smaller than existing defenses\nthat rely on pipeline fences.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 08:37:19 GMT"}, {"version": "v2", "created": "Sat, 20 Mar 2021 01:52:41 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Narayan", "Shravan", ""], ["Disselkoen", "Craig", ""], ["Moghimi", "Daniel", ""], ["Cauligi", "Sunjay", ""], ["Johnson", "Evan", ""], ["Gang", "Zhao", ""], ["Vahldiek-Oberwagner", "Anjo", ""], ["Sahita", "Ravi", ""], ["Shacham", "Hovav", ""], ["Tullsen", "Dean", ""], ["Stefan", "Deian", ""]]}, {"id": "2102.12746", "submitter": "Konstantinos Demertzis", "authors": "Konstantinos Demertzis", "title": "Blockchained Federated Learning for Threat Defense", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the increasing complexity of threats in smart cities, the changing\nenvironment, and the weakness of traditional security systems, which in most\ncases fail to detect serious threats such as zero-day attacks, the need for\nalternative more active and more effective security methods keeps increasing.\nSuch approaches are the adoption of intelligent solutions to prevent, detect\nand deal with threats or anomalies under the conditions and the operating\nparameters of the infrastructure in question. This research paper introduces\nthe development of an intelligent Threat Defense system, employing Blockchain\nFederated Learning, which seeks to fully upgrade the way passive intelligent\nsystems operate, aiming at implementing an Advanced Adaptive Cooperative\nLearning (AACL) mechanism for smart cities networks. The AACL is based on the\nmost advanced methods of computational intelligence while ensuring privacy and\nanonymity for participants and stakeholders. The proposed framework combines\nFederated Learning for the distributed and continuously validated learning of\nthe tracing algorithms. Learning is achieved through encrypted smart contracts\nwithin the blockchain technology, for unambiguous validation and control of the\nprocess. The aim of the proposed Framework is to intelligently classify smart\ncities networks traffic derived from Industrial IoT (IIoT) by Deep Content\nInspection (DCI) methods, in order to identify anomalies that are usually due\nto Advanced Persistent Threat (APT) attacks.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 09:16:48 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Demertzis", "Konstantinos", ""]]}, {"id": "2102.12774", "submitter": "Matthias Grundmann", "authors": "Matthias Grundmann and Hedwig Amberg and Hannes Hartenstein", "title": "On the Estimation of the Number of Unreachable Peers in the Bitcoin P2P\n  Network by Observation of Peer Announcements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin is based on a P2P network that is used to propagate transactions and\nblocks. While the P2P network design intends to hide the topology of the P2P\nnetwork, information about the topology is required to understand the network\nfrom a scientific point of view. Thus, there is a natural tension between the\n'desire' for unobservability on the one hand, and for observability on the\nother hand. On a middle ground, one would at least be interested on some\nstatistical features of the Bitcoin network like the number of peers that\nparticipate in the propagation of transactions and blocks. This number is\ncomposed of the number of reachable peers that accept incoming connections and\nunreachable peers that do not accept incoming connections. While the number of\nreachable peers can be measured, it is inherently difficult to determine the\nnumber of unreachable peers. Thus, the number of unreachable peers can only be\nestimated based on some indicators. In this paper, we first define our\nunderstanding of unreachable peers and then propose the PAL (Passive\nAnnouncement Listening) method which gives an estimate of the number of\nunreachable peers by observing ADDR messages that announce active IP addresses\nin the network. The PAL method allows for detecting unreachable peers that\nindicate that they provide services useful to the P2P network. In conjunction\nwith previous methods, the PAL method can help to get a better estimate of the\nnumber of unreachable peers. We use the PAL method to analyze data from a\nlong-term measurement of the Bitcoin P2P network that gives insights into the\ndevelopment of the number of unreachable peers over five years from 2015 to\n2020. Results show that about 31,000 unreachable peers providing useful\nservices were active per day at the end of the year 2020. An empirical\nvalidation indicates that the approach finds about 50 % of unreachable peers\nthat provide useful services.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 10:41:27 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Grundmann", "Matthias", ""], ["Amberg", "Hedwig", ""], ["Hartenstein", "Hannes", ""]]}, {"id": "2102.12869", "submitter": "Gianluca Stringhini", "authors": "Yun Shen, Pierre-Antoine Vervier, Gianluca Stringhini", "title": "Understanding Worldwide Private Information Collection on Android", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile phones enable the collection of a wealth of private information, from\nunique identifiers (e.g., email addresses), to a user's location, to their text\nmessages. This information can be harvested by apps and sent to third parties,\nwhich can use it for a variety of purposes. In this paper we perform the\nlargest study of private information collection (PIC) on Android to date.\nLeveraging an anonymized dataset collected from the customers of a popular\nmobile security product, we analyze the flows of sensitive information\ngenerated by 2.1M unique apps installed by 17.3M users over a period of 21\nmonths between 2018 and 2019. We find that 87.2% of all devices send private\ninformation to at least five different domains, and that actors active in\ndifferent regions (e.g., Asia compared to Europe) are interested in collecting\ndifferent types of information. The United States (62% of the total) and China\n(7% of total flows) are the countries that collect most private information.\nOur findings raise issues regarding data regulation, and would encourage\npolicymakers to further regulate how private information is used by and shared\namong the companies and how accountability can be truly guaranteed.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 14:10:16 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Shen", "Yun", ""], ["Vervier", "Pierre-Antoine", ""], ["Stringhini", "Gianluca", ""]]}, {"id": "2102.12892", "submitter": "Marc Brooker", "authors": "Marc Brooker and Adrian Costin Catangiu and Mike Danilov and Alexander\n  Graf and Colm MacCarthaigh and Andrei Sandu", "title": "Restoring Uniqueness in MicroVM Snapshots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code initialization -- the step of loading code, executing static code,\nfilling caches, and forming re-used connections -- tends to dominate cold-start\ntime in serverless compute systems such as AWS Lambda. Post-initialization\nmemory snapshots, cloned and restored on start, have emerged as a viable\nsolution to this problem, with incremental snapshot and fast restore support in\nVMMs like Firecracker.\n  Saving memory introduces the challenge of managing high-value memory\ncontents, such as cryptographic secrets. Cloning introduces the challenge of\nrestoring the uniqueness of the VMs, to allow them to do unique things like\ngenerate UUIDs, secrets, and nonces. This paper examines solutions to these\nproblems in the every microsecond counts context of serverless cold-start, and\ndiscusses the state-of-the-art of available solutions. We present two new\ninterfaces aimed at solving this problem -- MADV\\_WIPEONSUSPEND and SysGenId --\nand compare them to alternative solutions.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 21:56:28 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Brooker", "Marc", ""], ["Catangiu", "Adrian Costin", ""], ["Danilov", "Mike", ""], ["Graf", "Alexander", ""], ["MacCarthaigh", "Colm", ""], ["Sandu", "Andrei", ""]]}, {"id": "2102.12918", "submitter": "Jingjing Li", "authors": "Jingjing Li and Zhuo Sun and Lei Zhang and Hongyu Zhu", "title": "Dual MINE-based Neural Secure Communications under Gaussian Wiretap\n  Channel", "comments": "6 pages, 6 figures, ICC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, some researches are devoted to the topic of end-to-end learning a\nphysical layer secure communication system based on autoencoder under Gaussian\nwiretap channel. However, in those works, the reliability and security of the\nencoder model were learned through necessary decoding outputs of not only\nlegitimate receiver but also the eavesdropper. In fact, the assumption of known\neavesdropper's decoder or its output is not practical. To address this issue,\nin this paper we propose a dual mutual information neural estimation (MINE)\nbased neural secure communications model. The security constraints of this\nmethod is constructed only with the input and output signal samples of the\nlegal and eavesdropper channels and benefit that training the encoder is\ncompletely independent of the decoder. Moreover, since the design of secure\ncoding does not rely on the eavesdropper's decoding results, the security\nperformance would not be affected by the eavesdropper's decoding means.\nNumerical results show that the performance of our model is guaranteed whether\nthe eavesdropper learns the decoder himself or uses the legal decoder.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 15:09:39 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Li", "Jingjing", ""], ["Sun", "Zhuo", ""], ["Zhang", "Lei", ""], ["Zhu", "Hongyu", ""]]}, {"id": "2102.13023", "submitter": "Davide Caputo", "authors": "Andrea Ranieri, Davide Caputo, Luca Verderame, Alessio Merlo, Luca\n  Caviglione", "title": "Deep Adversarial Learning on Google Home devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart speakers and voice-based virtual assistants are core components for the\nsuccess of the IoT paradigm. Unfortunately, they are vulnerable to various\nprivacy threats exploiting machine learning to analyze the generated encrypted\ntraffic. To cope with that, deep adversarial learning approaches can be used to\nbuild black-box countermeasures altering the network traffic (e.g., via packet\npadding) and its statistical information. This letter showcases the inadequacy\nof such countermeasures against machine learning attacks with a dedicated\nexperimental campaign on a real network dataset. Results indicate the need for\na major re-engineering to guarantee the suitable protection of commercially\navailable smart speakers.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 17:29:00 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Ranieri", "Andrea", ""], ["Caputo", "Davide", ""], ["Verderame", "Luca", ""], ["Merlo", "Alessio", ""], ["Caviglione", "Luca", ""]]}, {"id": "2102.13190", "submitter": "George Papakostas Prof.", "authors": "G.K. Sidiropoulos, G.A. Papakostas", "title": "Machine Biometrics -- Towards Identifying Machines in a Smart City\n  Environment", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper deals with the identification of machines in a smart city\nenvironment. The concept of machine biometrics is proposed in this work for the\nfirst time, as a way to authenticate machine identities interacting with humans\nin everyday life. This definition is imposed in modern years where autonomous\nvehicles, social robots, etc. are considered active members of contemporary\nsocieties. In this context, the case of car identification from the engine\nbehavioral biometrics is examined. For this purpose, 22 sound features were\nextracted and their discrimination capabilities were tested in combination with\n9 different machine learning classifiers, towards identifying 5 car\nmanufacturers. The experimental results revealed the ability of the proposed\nbiometrics to identify cars with high accuracy up to 98% for the case of the\nMultilayer Perceptron (MLP) neural network model.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 21:49:20 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Sidiropoulos", "G. K.", ""], ["Papakostas", "G. A.", ""]]}, {"id": "2102.13223", "submitter": "Mir Mehedi Ahsan Pritom", "authors": "Mir Mehedi Ahsan Pritom, Kristin M. Schweitzer, Raymond M. Bateman,\n  Min Xu, Shouhuai Xu", "title": "Characterizing the Landscape of COVID-19 Themed Cyberattacks and\n  Defenses", "comments": "6 pages, 2 figures, manuscript published in 2020 IEEE International\n  Conference on Intelligence and Security Informatics (ISI 2020)", "journal-ref": "2020 IEEE International Conference on Intelligence and Security\n  Informatics (ISI), 2020, pp. 1-6", "doi": "10.1109/ISI49825.2020.9280539", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19 (Coronavirus) hit the global society and economy with a big\nsurprise. In particular, work-from-home has become a new norm for employees.\nDespite the fact that COVID-19 can equally attack innocent people and\ncybercriminals, it is ironic to see surges in cyberattacks leveraging COVID-19\nas a theme, dubbed COVID-19 themed cyberattacks or COVID-19 attacks for short,\nwhich represent a new phenomenon that has yet to be systematically understood.\nIn this paper, we make the first step towards fully characterizing the\nlandscape of these attacks, including their sophistication via the Cyber Kill\nChain model. We also explore the solution space of defenses against these\nattacks.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 23:11:12 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Pritom", "Mir Mehedi Ahsan", ""], ["Schweitzer", "Kristin M.", ""], ["Bateman", "Raymond M.", ""], ["Xu", "Min", ""], ["Xu", "Shouhuai", ""]]}, {"id": "2102.13226", "submitter": "Mir Mehedi Ahsan Pritom", "authors": "Mir Mehedi Ahsan Pritom, Kristin M. Schweitzer, Raymond M. Bateman,\n  Min Xu, Shouhuai Xu", "title": "Data-Driven Characterization and Detection of COVID-19 Themed Malicious\n  Websites", "comments": "6 pages, 5 figures, manuscript published in 2020 IEEE International\n  Conference on Intelligence and Security Informatics (ISI 2020)", "journal-ref": "2020 IEEE International Conference on Intelligence and Security\n  Informatics (ISI), 2020, pp. 1-6", "doi": "10.1109/ISI49825.2020.9280522", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19 has hit hard on the global community, and organizations are working\ndiligently to cope with the new norm of \"work from home\". However, the volume\nof remote work is unprecedented and creates opportunities for cyber attackers\nto penetrate home computers. Attackers have been leveraging websites with\nCOVID-19 related names, dubbed COVID-19 themed malicious websites. These\nwebsites mostly contain false information, fake forms, fraudulent payments,\nscams, or malicious payloads to steal sensitive information or infect victims'\ncomputers. In this paper, we present a data-driven study on characterizing and\ndetecting COVID-19 themed malicious websites. Our characterization study shows\nthat attackers are agile and are deceptively crafty in designing geolocation\ntargeted websites, often leveraging popular domain registrars and top-level\ndomains. Our detection study shows that the Random Forest classifier can detect\nCOVID-19 themed malicious websites based on the lexical and WHOIS features\ndefined in this paper, achieving a 98% accuracy and 2.7% false-positive rate.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 23:27:04 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Pritom", "Mir Mehedi Ahsan", ""], ["Schweitzer", "Kristin M.", ""], ["Bateman", "Raymond M.", ""], ["Xu", "Min", ""], ["Xu", "Shouhuai", ""]]}, {"id": "2102.13241", "submitter": "Antonios Saravanos", "authors": "Antonios Saravanos (1), Dongnanzi Zheng (1), Stavros Zervoudakis (1),\n  Donatella Delfino (1) ((1) New York University)", "title": "Exploring the Effect of Resolution on the Usability of Locimetric\n  Authentication", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Locimetric authentication is a form of graphical authentication in which\nusers validate their identity by selecting predetermined points on a\npredetermined image. Its primary advantage over the ubiquitous text-based\napproach stems from users' superior ability to remember visual information over\ntextual information, coupled with the authentication process being transformed\nto one requiring recognition (instead of recall). Ideally, these\ndifferentiations enable users to create more complex passwords, which\ntheoretically are more secure. Yet locimetric authentication has one\nsignificant weakness: hot-spots. This term refers to areas of an image that\nusers gravitate towards, and which consequently have a higher probability of\nbeing selected. Although many strategies have been proposed to counter the\nhot-spot problem, one area that has received little attention is that of\nresolution. The hypothesis here is that high-resolution images would afford the\nuser a larger password space, and consequently any hot-spots would dissipate.\nWe employ an experimental approach, where users generate a series of locimetric\npasswords on either low- or high-resolution images. Our research reveals the\npresence of hot-spots even in high-resolution images, albeit at a lower level\nthan that exhibited with low-resolution images. We conclude by reinforcing that\nother techniques - such as existing or new software controls or training - need\nto be utilized to mitigate the emergence of hot-spots with the locimetric\nscheme.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 00:15:09 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 20:45:54 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Saravanos", "Antonios", "", "New York University"], ["Zheng", "Dongnanzi", "", "New York University"], ["Zervoudakis", "Stavros", "", "New York University"], ["Delfino", "Donatella", "", "New York University"]]}, {"id": "2102.13256", "submitter": "Ranwa Al Mallah", "authors": "Ranwa Al Mallah, Godwin Badu-Marfo, Bilal Farooq", "title": "Cybersecurity Threats in Connected and Automated Vehicles based\n  Federated Learning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a machine learning technique that aims at training\nan algorithm across decentralized entities holding their local data private.\nWireless mobile networks allow users to communicate with other fixed or mobile\nusers. The road traffic network represents an infrastructure-based\nconfiguration of a wireless mobile network where the Connected and Automated\nVehicles (CAV) represent the communicating entities. Applying FL in a wireless\nmobile network setting gives rise to a new threat in the mobile environment\nthat is very different from the traditional fixed networks. The threat is due\nto the intrinsic characteristics of the wireless medium and is caused by the\ncharacteristics of the vehicular networks such as high node-mobility and\nrapidly changing topology. Most cyber defense techniques depend on highly\nreliable and connected networks. This paper explores falsified information\nattacks, which target the FL process that is ongoing at the RSU. We identified\na number of attack strategies conducted by the malicious CAVs to disrupt the\ntraining of the global model in vehicular networks. We show that the attacks\nwere able to increase the convergence time and decrease the accuracy the model.\nWe demonstrate that our attacks bypass FL defense strategies in their primary\nform and highlight the need for novel poisoning resilience defense mechanisms\nin the wireless mobile setting of the future road networks.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 01:39:16 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 22:50:44 GMT"}, {"version": "v3", "created": "Thu, 3 Jun 2021 23:56:46 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Mallah", "Ranwa Al", ""], ["Badu-Marfo", "Godwin", ""], ["Farooq", "Bilal", ""]]}, {"id": "2102.13340", "submitter": "Parvaneh Asghari", "authors": "Parvaneh Asghari and Seyyed Hamid Haj Seyyed Javadi", "title": "Lightweight Key-Dependent Dynamic S-Boxes based on Hyperelliptic Curve\n  for IoT Devices", "comments": "in Persian language", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Security is one of the main issues in Internet of Things (IoT). Encryption\nplays a curtail role in making these systems secure. Substitution Box (S-Box)\nhas an effective impact in block encryption methods. Due to the restricted\nresource capacities of IoT nodes, providing a lightweight S-Box is a\nchallenging problem. This paper presents a key-dependent S-Box using\nHyperelliptic curve. The proposed S-Box is analytically evaluated using\nperformance criteria including bijection, nonlinearity, strict avalanche\neffect, and algebraic degree. The evaluation results endorse that the offered\nS-Box production algorithm is considerably an effective way to generate\ncryptographic strong S-Box.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 07:38:43 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Asghari", "Parvaneh", ""], ["Javadi", "Seyyed Hamid Haj Seyyed", ""]]}, {"id": "2102.13364", "submitter": "Yizhong Liu", "authors": "Yizhong Liu, Jianwei Liu, Marcos Antonio Vaz Salles, Zongyang Zhang,\n  Tong Li, Bin Hu, Fritz Henglein, Rongxing Lu", "title": "Building Blocks of Sharding Blockchain Systems: Concepts, Approaches,\n  and Open Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sharding is the prevalent approach to breaking the trilemma of simultaneously\nachieving decentralization, security, and scalability in traditional blockchain\nsystems, which are implemented as replicated state machines relying on atomic\nbroadcast for consensus on an immutable chain of valid transactions. Sharding\nis to be understood broadly as techniques for dynamically partitioning nodes in\na blockchain system into subsets (shards) that perform storage, communication,\nand computation tasks without fine-grained synchronization with each other.\nDespite much recent research on sharding blockchains, much remains to be\nexplored in the design space of these systems. Towards that aim, we conduct a\nsystematic analysis of existing sharding blockchain systems and derive a\nconceptual decomposition of their architecture into functional components and\nthe underlying assumptions about system models and attackers they are built on.\nThe functional components identified are node selection, epoch randomness, node\nassignment, intra-shard consensus, cross-shard transaction processing, shard\nreconfiguration, and motivation mechanism. We describe interfaces,\nfunctionality, and properties of each component and show how they compose into\na sharding blockchain system. For each component, we systematically review\nexisting approaches, identify potential and open problems, and propose future\nresearch directions. We focus on potential security attacks and performance\nproblems, including system throughput and latency concerns such as confirmation\ndelays. We believe our modular architectural decomposition and in-depth\nanalysis of each component, based on a comprehensive literature study, provides\na systematic basis for conceptualizing state-of-the-art sharding blockchain\nsystems, proving or improving security and performance properties of\ncomponents, and developing new sharding blockchain system designs.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 09:12:54 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Liu", "Yizhong", ""], ["Liu", "Jianwei", ""], ["Salles", "Marcos Antonio Vaz", ""], ["Zhang", "Zongyang", ""], ["Li", "Tong", ""], ["Hu", "Bin", ""], ["Henglein", "Fritz", ""], ["Lu", "Rongxing", ""]]}, {"id": "2102.13376", "submitter": "Jay Kumar", "authors": "Rajesh Kumar, WenYong Wang, Jay Kumar, Zakria, Ting Yang, and Waqar\n  Ali", "title": "Collective Intelligence: Decentralized Learning for Android Malware\n  Detection in IoT with Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread significance of Android IoT devices is due to its flexibility\nand hardware support features which revolutionized the digital world by\nintroducing exciting applications almost in all walks of daily life, such as\nhealthcare, smart cities, smart environments, safety, remote sensing, and many\nmore. Such versatile applicability gives incentive for more malware attacks. In\nthis paper, we propose a framework which continuously aggregates multiple user\ntrained models on non-overlapping data into single model. Specifically for\nmalware detection task, (i) we propose a novel user (local) neural network\n(LNN) which trains on local distribution and (ii) then to assure the model\nauthenticity and quality, we propose a novel smart contract which enable\naggregation process over blokchain platform. The LNN model analyzes various\nstatic and dynamic features of both malware and benign whereas the smart\ncontract verifies the malicious applications both for uploading and downloading\nprocesses in the network using stored aggregated features of local models. In\nthis way, the proposed model not only improves malware detection accuracy using\ndecentralized model network but also model efficacy with blockchain. We\nevaluate our approach with three state-of-the-art models and performed deep\nanalyses of extracted features of the relative model.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 09:51:23 GMT"}, {"version": "v2", "created": "Sat, 26 Jun 2021 07:38:45 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Kumar", "Rajesh", ""], ["Wang", "WenYong", ""], ["Kumar", "Jay", ""], ["Zakria", "", ""], ["Yang", "Ting", ""], ["Ali", "Waqar", ""]]}, {"id": "2102.13472", "submitter": "Jianzong Wang", "authors": "Yong Liu, Xinghua Zhu, Jianzong Wang, Jing Xiao", "title": "A Quantitative Metric for Privacy Leakage in Federated Learning", "comments": "Accepted to ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the federated learning system, parameter gradients are shared among\nparticipants and the central modulator, while the original data never leave\ntheir protected source domain. However, the gradient itself might carry enough\ninformation for precise inference of the original data. By reporting their\nparameter gradients to the central server, client datasets are exposed to\ninference attacks from adversaries. In this paper, we propose a quantitative\nmetric based on mutual information for clients to evaluate the potential risk\nof information leakage in their gradients. Mutual information has received\nincreasing attention in the machine learning and data mining community over the\npast few years. However, existing mutual information estimation methods cannot\nhandle high-dimensional variables. In this paper, we propose a novel method to\napproximate the mutual information between the high-dimensional gradients and\nbatched input data. Experimental results show that the proposed metric reliably\nreflect the extent of information leakage in federated learning. In addition,\nusing the proposed metric, we investigate the influential factors of risk\nlevel. It is proven that, the risk of information leakage is related to the\nstatus of the task model, as well as the inherent data distribution.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 02:48:35 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Liu", "Yong", ""], ["Zhu", "Xinghua", ""], ["Wang", "Jianzong", ""], ["Xiao", "Jing", ""]]}, {"id": "2102.13488", "submitter": "Victor von Wachter", "authors": "Johannes Rude Jensen, Victor von Wachter, Omri Ross", "title": "Leveraged Trading on Blockchain Technology", "comments": "Blockchain Technology, Distributed Ledger Technology, Leveraged\n  Trading, Design Science Research, Decentralized Finance (DeFi)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We document an ongoing research process towards the implementation and\nintegration of a digital artefact, executing the lifecycle of a leveraged trade\nwith permissionless blockchain technology. By employing core functions of the\n'Dai Stablecoin system' deployed on the Ethereum blockchain, we produce the\nequivalent exposure of a leveraged position while deterministically automating\nthe monitoring and liquidation processes. We demonstrate the implementation and\nearly integration of the artefact into a hardened exchange environment through\na microservice utilizing standardized API calls. The early results presented in\nthis paper were produced in collaboration with a team of stakeholders at a\nhosting organization, a multi-national online brokerage and cryptocurrency\nexchange. We utilize the design science research methodology (DSR) guiding the\ndesign, development, and evaluation of the artefact. Our findings indicate\nthat, while it is feasible to implement the lifecycle of a leveraged trade on\nthe blockchain, the integration of the artefact into a traditional exchange\nenvironment involves multiple compromises and drawback. Generalizing the\ntentative findings presented in this paper, we introduce three propositions on\nthe implementation, integration, and implications of executing key business\nprocesses with permissionless blockchain technologies. By conducting\ncomputational design science research, we contribute to the information systems\ndiscourse on the applied utility of permissionless blockchain technologies in\nfinance and beyond.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 10:28:28 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Jensen", "Johannes Rude", ""], ["von Wachter", "Victor", ""], ["Ross", "Omri", ""]]}, {"id": "2102.13607", "submitter": "Kiavash Satvat", "authors": "Kiavash Satvat, Maliheh Shirvanian, Nitesh Saxena", "title": "PASSAT: Single Password Authenticated Secret-Shared Intrusion-Tolerant\n  Storage with Server Transparency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we introduce PASSAT, a practical system to boost the security\nassurance delivered by the current cloud architecture without requiring any\nchanges or cooperation from the cloud service providers. PASSAT is an\napplication transparent to the cloud servers that allows users to securely and\nefficiently store and access their files stored on public cloud storage based\non a single master password. Using a fast and light-weight XOR secret sharing\nscheme, PASSAT secret-shares users' files and distributes them among n publicly\navailable cloud platforms. To access the files, PASSAT communicates with any k\nout of n cloud platforms to receive the shares and runs a secret-sharing\nreconstruction algorithm to recover the files. An attacker (insider or\noutsider) who compromises or colludes with less than k platforms cannot learn\nthe user's files or modify the files stealthily. To authenticate the user to\nmultiple cloud platforms, PASSAT crucially stores the authentication\ncredentials, specific to each platform on a password manager, protected under\nthe user's master password. Upon requesting access to files, the user enters\nthe password to unlock the vault and fetches the authentication tokens using\nwhich PASSAT can interact with cloud storage. Our instantiation of PASSAT based\non (2, 3)-XOR secret sharing of Kurihara et al., implemented with three popular\nstorage providers, namely, Google Drive, Box, and Dropbox, confirms that our\napproach can efficiently enhance the confidentiality, integrity, and\navailability of the stored files with no changes on the servers.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 17:26:05 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Satvat", "Kiavash", ""], ["Shirvanian", "Maliheh", ""], ["Saxena", "Nitesh", ""]]}, {"id": "2102.13613", "submitter": "Bernhard Haslhofer", "authors": "Bernhard Haslhofer and Rainer St\\\"utz and Matteo Romiti and Ross King", "title": "GraphSense: A General-Purpose Cryptoasset Analytics Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There is currently an increasing demand for cryptoasset analysis tools among\ncryptoasset service providers, the financial industry in general, as well as\nacross academic fields. At the moment, one can choose between commercial\nservices or low-level open-source tools providing programmatic access. In this\npaper, we present the design and implementation of another option: the\nGraphSense Cryptoasset Analytics Platform, which can be used for interactive\ninvestigations of monetary flows and, more importantly, for executing advanced\nanalytics tasks using a standard data science tool stack. By providing a\ngrowing set of open-source components, GraphSense could ultimately become an\ninstrument for scientific investigations in academia and a possible response to\nemerging compliance and regulation challenges for businesses and organizations\ndealing with cryptoassets.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 17:31:12 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Haslhofer", "Bernhard", ""], ["St\u00fctz", "Rainer", ""], ["Romiti", "Matteo", ""], ["King", "Ross", ""]]}, {"id": "2102.13624", "submitter": "Jonas Geiping", "authors": "Jonas Geiping, Liam Fowl, Gowthami Somepalli, Micah Goldblum, Michael\n  Moeller, Tom Goldstein", "title": "What Doesn't Kill You Makes You Robust(er): Adversarial Training against\n  Poisons and Backdoors", "comments": "17 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data poisoning is a threat model in which a malicious actor tampers with\ntraining data to manipulate outcomes at inference time. A variety of defenses\nagainst this threat model have been proposed, but each suffers from at least\none of the following flaws: they are easily overcome by adaptive attacks, they\nseverely reduce testing performance, or they cannot generalize to diverse data\npoisoning threat models. Adversarial training, and its variants, is currently\nconsidered the only empirically strong defense against (inference-time)\nadversarial attacks. In this work, we extend the adversarial training framework\nto instead defend against (training-time) poisoning and backdoor attacks. Our\nmethod desensitizes networks to the effects of poisoning by creating poisons\nduring training and injecting them into training batches. We show that this\ndefense withstands adaptive attacks, generalizes to diverse threat models, and\nincurs a better performance trade-off than previous defenses.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 17:54:36 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Geiping", "Jonas", ""], ["Fowl", "Liam", ""], ["Somepalli", "Gowthami", ""], ["Goldblum", "Micah", ""], ["Moeller", "Michael", ""], ["Goldstein", "Tom", ""]]}]