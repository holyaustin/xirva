[{"id": "2010.00206", "submitter": "Keita Emura", "authors": "Teppei Sato and Keita Emura and Tomoki Fujitani and Kazumasa Omote", "title": "An Anonymous Trust-Marking Scheme on Blockchain Systems", "comments": "An extended abstract appeared at the 3rd IEEE International\n  Conference on Blockchain and Cryptocurrency, ICBC 2021. This is the full\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the Coincheck incident, which recorded the largest damages in\ncryptocurrency history in 2018, it was demonstrated that using Mosaic token can\nhave a certain effect. Although it seems attractive to employ tokens as\ncountermeasures for cryptocurrency leakage, Mosaic is a specific token for the\nNew Economy Movement (NEM) cryptocurrency and is not employed for other\nblockchain systems or cryptocurrencies. Moreover, although some volunteers\ntracked leaked NEM using Mosaic in the CoinCheck incident, it would be better\nto verify that the volunteers can be trusted. Simultaneously, if someone (e.g.,\nwho stole cryptocurrencies) can identify the volunteers, then that person or\norganization may be targets of them.\n  In this paper, we propose an anonymous trust-marking scheme on blockchain\nsystems that is universally applicable to any cryptocurrency. In our scheme,\nentities called token admitters are allowed to generate tokens adding\ntrustworthiness or untrustworthiness to addresses. Anyone can anonymously\nverify whether these tokens were issued by a token admitter. Simultaneously,\nonly the designated auditor and no one else, including nondesignated auditors,\ncan identify the token admitters. Our scheme is based on accountable ring\nsignatures and commitment, and is implemented on an elliptic curve called\nCurve25519, and we confirm that both cryptographic tools are efficient.\nMoreover, we also confirm that our scheme is applicable to Bitcoin, Ethereum,\nand NEM.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 05:56:35 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 03:10:44 GMT"}, {"version": "v3", "created": "Thu, 25 Feb 2021 06:26:32 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Sato", "Teppei", ""], ["Emura", "Keita", ""], ["Fujitani", "Tomoki", ""], ["Omote", "Kazumasa", ""]]}, {"id": "2010.00217", "submitter": "Steven Cao", "authors": "Steven Cao, Swanand Kadhe, Kannan Ramchandran", "title": "CoVer: Collaborative Light-Node-Only Verification and Data Availability\n  for Blockchains", "comments": "IEEE Blockchain 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Validating a blockchain incurs heavy computation, communication, and storage\ncosts. As a result, clients with limited resources, called light nodes, cannot\nverify transactions independently and must trust full nodes, making them\nvulnerable to security attacks. Motivated by this problem, we ask a fundamental\nquestion: can light nodes securely validate without any full nodes? We answer\naffirmatively by proposing CoVer, a decentralized protocol that allows a group\nof light nodes to collaboratively verify blocks even under a dishonest\nmajority, achieving the same level of security for block validation as full\nnodes while only requiring a fraction of the work. In particular, work per node\nscales down proportionally with the number of participants (up to a log\nfactor), resulting in computation, communication, and storage requirements that\nare sublinear in block size. Our main contributions are light-node-only\nprotocols for fraud proofs and data availability.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 06:58:07 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Cao", "Steven", ""], ["Kadhe", "Swanand", ""], ["Ramchandran", "Kannan", ""]]}, {"id": "2010.00268", "submitter": "Moritz Schulze Darup", "authors": "M. Schulze Darup and A. B. Alexandru and D. E. Quevedo and G. J.\n  Pappas", "title": "Encrypted control for networked systems -- An illustrative introduction\n  and current challenges", "comments": "The paper is a preprint of an accepted paper in the IEEE Control\n  Systems Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CR cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing and distributed computing are becoming ubiquitous in many\nmodern control systems such as smart grids, building automation, robot swarms\nor intelligent transportation systems. Compared to \"isolated\" control systems,\nthe advantages of cloud-based and distributed control systems are, in\nparticular, resource pooling and outsourcing, rapid scalability, and high\nperformance. However, these capabilities do not come without risks. In fact,\nthe involved communication and processing of sensitive data via public networks\nand on third-party platforms promote, among other cyberthreats, eavesdropping\nand manipulation of data. Encrypted control addresses this security gap and\nprovides confidentiality of the processed data in the entire control loop. This\npaper presents a tutorial-style introduction to this young but emerging field\nin the framework of secure control for networked dynamical systems.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 09:19:30 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Darup", "M. Schulze", ""], ["Alexandru", "A. B.", ""], ["Quevedo", "D. E.", ""], ["Pappas", "G. J.", ""]]}, {"id": "2010.00302", "submitter": "Anna Melman", "authors": "Anna Melman, Oleg Evsutin, Alexander Shelupanov", "title": "An authorship protection technology for electronic documents based on\n  image watermarking", "comments": "21 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of information technology, information security technologies\nhold a special place. They ensure the security of the use of information\ntechnology. One of the urgent tasks is the protection of electronic documents\nduring their transfer in information systems. This paper proposes a technology\nfor protecting electronic documents containing digital images. The main idea is\nthat the electronic document authorship protection can be implemented by\ndigital watermark embedding in the images that are contained in this document.\nThe paper considers three cases of using the proposed technology: full copying\nof an electronic document, copying of images contained in the document, and\ncopying of text. It is shown that in all three cases the authorship\nconfirmation can be successfully implemented. Computational experiments are\nconducted with robust watermarking algorithms that can be used within the\ntechnology. A scenario of technology implementation is proposed, which provides\nfor the joint use of different class algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 11:05:47 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Melman", "Anna", ""], ["Evsutin", "Oleg", ""], ["Shelupanov", "Alexander", ""]]}, {"id": "2010.00339", "submitter": "Stephan Wiefling", "authors": "Stephan Wiefling, Markus D\\\"urmuth, Luigi Lo Iacono", "title": "More Than Just Good Passwords? A Study on Usability and Security\n  Perceptions of Risk-based Authentication", "comments": "16 pages, 10 figures, 6 tables", "journal-ref": "36th Annual Computer Security Applications Conference (ACSAC '20).\n  December 07-11, 2020", "doi": "10.1145/3427228.3427243", "report-no": null, "categories": "cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Risk-based Authentication (RBA) is an adaptive security measure to strengthen\npassword-based authentication. RBA monitors additional features during login,\nand when observed feature values differ significantly from previously seen\nones, users have to provide additional authentication factors such as a\nverification code. RBA has the potential to offer more usable authentication,\nbut the usability and the security perceptions of RBA are not studied well.\n  We present the results of a between-group lab study (n=65) to evaluate\nusability and security perceptions of two RBA variants, one 2FA variant, and\npassword-only authentication. Our study shows with significant results that RBA\nis considered to be more usable than the studied 2FA variants, while it is\nperceived as more secure than password-only authentication in general and\ncomparably secure to 2FA in a variety of application types. We also observed\nRBA usability problems and provide recommendations for mitigation. Our\ncontribution provides a first deeper understanding of the users' perception of\nRBA and helps to improve RBA implementations for a broader user acceptance.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 12:11:51 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Wiefling", "Stephan", ""], ["D\u00fcrmuth", "Markus", ""], ["Iacono", "Luigi Lo", ""]]}, {"id": "2010.00341", "submitter": "Michael Rodler", "authors": "Michael Rodler, Wenting Li, Ghassan O. Karame, Lucas Davi", "title": "EVMPatch: Timely and Automated Patching of Ethereum Smart Contracts", "comments": "A slightly shorter version of this paper will be published at USENIX\n  Security Symposium 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent attacks exploiting errors in smart contract code had devastating\nconsequences thereby questioning the benefits of this technology. It is\ncurrently highly challenging to fix errors and deploy a patched contract in\ntime. Instant patching is especially important since smart contracts are always\nonline due to the distributed nature of blockchain systems. They also manage\nconsiderable amounts of assets, which are at risk and often beyond recovery\nafter an attack. Existing solutions to upgrade smart contracts depend on manual\nand error-prone processes. This paper presents a framework, called EVMPatch, to\ninstantly and automatically patch faulty smart contracts. EVMPatch features a\nbytecode rewriting engine for the popular Ethereum blockchain, and\ntransparently/automatically rewrites common off-the-shelf contracts to\nupgradable contracts. The proof-of-concept implementation of EVMPatch\nautomatically hardens smart contracts that are vulnerable to integer\nover/underflows and access control errors, but can be easily extended to cover\nmore bug classes. Our extensive evaluation on 14,000 real-world (vulnerable)\ncontracts demonstrate that our approach successfully blocks attack transactions\nlaunched on these contracts, while keeping the intended functionality of the\ncontract intact. We perform a study with experienced software developers,\nshowing that EVMPatch is practical, and reduces the time for converting a given\nSolidity smart contract to an upgradable contract by 97.6 %, while ensuring\nfunctional equivalence to the original contract.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 12:19:01 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 11:38:36 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Rodler", "Michael", ""], ["Li", "Wenting", ""], ["Karame", "Ghassan O.", ""], ["Davi", "Lucas", ""]]}, {"id": "2010.00533", "submitter": "Erik Hemberg", "authors": "Erik Hemberg, Jonathan Kelly, Michal Shlapentokh-Rothman, Bryn\n  Reinstadler, Katherine Xu, Nick Rutar, Una-May O'Reilly", "title": "Linking Threat Tactics, Techniques, and Patterns with Defensive\n  Weaknesses, Vulnerabilities and Affected Platform Configurations for Cyber\n  Hunting", "comments": "13 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many public sources of cyber threat and vulnerability information exist to\nhelp defend cyber systems. This paper links MITRE's ATT&CK MATRIX of Tactics\nand Techniques, NIST's Common Weakness Enumerations (CWE), Common\nVulnerabilities and Exposures (CVE), and Common Attack Pattern Enumeration and\nClassification list (CAPEC), to gain further insight from alerts, threats and\nvulnerabilities. We preserve all entries and relations of the sources, while\nenabling bi-directional, relational path tracing within an aggregate data graph\ncalled BRON. In one example, we use BRON to enhance the information derived\nfrom a list of the top 10 most frequently exploited CVEs. We identify attack\npatterns, tactics, and techniques that exploit these CVEs and also uncover a\ndisparity in how much linked information exists for each of these CVEs. This\nprompts us to further inventory BRON's collection of sources to provide a view\nof the extent and range of the coverage and blind spots of public data sources.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 16:31:46 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 16:59:20 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Hemberg", "Erik", ""], ["Kelly", "Jonathan", ""], ["Shlapentokh-Rothman", "Michal", ""], ["Reinstadler", "Bryn", ""], ["Xu", "Katherine", ""], ["Rutar", "Nick", ""], ["O'Reilly", "Una-May", ""]]}, {"id": "2010.00544", "submitter": "Imani Sherman", "authors": "Imani N. Sherman, Elissa M. Redmiles, Jack W. Stokes", "title": "Designing Indicators to Combat Fake Media", "comments": "26 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growth of misinformation technology necessitates the need to identify\nfake videos. One approach to preventing the consumption of these fake videos is\nprovenance which allows the user to authenticate media content to its original\nsource. This research designs and investigates the use of provenance indicators\nto help users identify fake videos. We first interview users regarding their\nexperiences with different misinformation modes (text, image, video) to guide\nthe design of indicators within users' existing perspectives. Then, we conduct\na participatory design study to develop and design fake video indicators.\nFinally, we evaluate participant-designed indicators via both expert\nevaluations and quantitative surveys with a large group of end-users. Our\nresults provide concrete design guidelines for the emerging issue of fake\nvideos. Our findings also raise concerns regarding users' tendency to\novergeneralize from misinformation warning messages, suggesting the need for\nfurther research on warning design in the ongoing fight against misinformation.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 16:58:12 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Sherman", "Imani N.", ""], ["Redmiles", "Elissa M.", ""], ["Stokes", "Jack W.", ""]]}, {"id": "2010.00624", "submitter": "Xavier-Lewis Palmer", "authors": "Lucas Potter, Orlando Ayala, and Xavier-Lewis Palmer", "title": "Biocybersecurity -- A Converging Threat as an Auxiliary to War", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biodefense is the discipline of ensuring biosecurity with respect to select\ngroups of organisms and limiting their spread. This field has increasingly been\nchallenged by novel threats from nature that have been weaponized such as SARS,\nAnthrax, and similar pathogens, but has emerged victorious through\ncollaboration of national and world health groups. However, it may come under\nadditional stress in the 21st century as the field intersects with the\ncyberworld -- a world where governments have already been struggling to keep up\nwith cyber attacks from small to state-level actors as cyberthreats have been\nrelied on to level the playing field in international disputes. Disruptions to\nmilitary logistics and economies through cyberattacks have been able to be done\nat a mere fraction of economic and moral costs through conventional military\nmeans, making it an increasingly tempting means of disruption. In the field of\nbiocybersecurity (BCS), the strengths within biotechnology and cybersecurity\nmerge, along with many of their vulnerabilities, and this could spell increased\ntrouble for biodefense, as novel threats can be synthesized and disseminated in\nways that fuse the routes of attacks seen in biosecurity and cybersecurity.\nHerein, we offer an exploration of how threats in the domain of\nbiocybersecurity may emerge through less foreseen routes as it might be an\nattractive auxiliary to conventional war. This is done through an analysis of\npotential payload and delivery methods to develop notional threat\nvectorizations. We conclude with several paradigms through which to view\nBCS-based threats.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 18:07:16 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Potter", "Lucas", ""], ["Ayala", "Orlando", ""], ["Palmer", "Xavier-Lewis", ""]]}, {"id": "2010.00661", "submitter": "Md Hasan Shahriar", "authors": "Nur Imtiazul Haque, Md Hasan Shahriar, Md Golam Dastgir, Anjan\n  Debnath, Imtiaz Parvez, Arif Sarwat, Mohammad Ashiqur Rahman", "title": "Machine Learning in Generation, Detection, and Mitigation of\n  Cyberattacks in Smart Grid: A Survey", "comments": "6 pages, 4 figures, accepted in 2020 North American Power Symposium\n  (NAPS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SY eess.SP eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart grid (SG) is a complex cyber-physical system that utilizes modern cyber\nand physical equipment to run at an optimal operating point. Cyberattacks are\nthe principal threats confronting the usage and advancement of the\nstate-of-the-art systems. The advancement of SG has added a wide range of\ntechnologies, equipment, and tools to make the system more reliable, efficient,\nand cost-effective. Despite attaining these goals, the threat space for the\nadversarial attacks has also been expanded because of the extensive\nimplementation of the cyber networks. Due to the promising computational and\nreasoning capability, machine learning (ML) is being used to exploit and defend\nthe cyberattacks in SG by the attackers and system operators, respectively. In\nthis paper, we perform a comprehensive summary of cyberattacks generation,\ndetection, and mitigation schemes by reviewing state-of-the-art research in the\nSG domain. Additionally, we have summarized the current research in a\nstructured way using tabular format. We also present the shortcomings of the\nexisting works and possible future research direction based on our\ninvestigation.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 05:16:51 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Haque", "Nur Imtiazul", ""], ["Shahriar", "Md Hasan", ""], ["Dastgir", "Md Golam", ""], ["Debnath", "Anjan", ""], ["Parvez", "Imtiaz", ""], ["Sarwat", "Arif", ""], ["Rahman", "Mohammad Ashiqur", ""]]}, {"id": "2010.00677", "submitter": "Jiaming Shen", "authors": "Jiaming Shen and Heng Ji and Jiawei Han", "title": "Near-imperceptible Neural Linguistic Steganography via Self-Adjusting\n  Arithmetic Coding", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linguistic steganography studies how to hide secret messages in natural\nlanguage cover texts. Traditional methods aim to transform a secret message\ninto an innocent text via lexical substitution or syntactical modification.\nRecently, advances in neural language models (LMs) enable us to directly\ngenerate cover text conditioned on the secret message. In this study, we\npresent a new linguistic steganography method which encodes secret messages\nusing self-adjusting arithmetic coding based on a neural language model. We\nformally analyze the statistical imperceptibility of this method and\nempirically show it outperforms the previous state-of-the-art methods on four\ndatasets by 15.3% and 38.9% in terms of bits/word and KL metrics, respectively.\nFinally, human evaluations show that 51% of generated cover texts can indeed\nfool eavesdroppers.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2020 20:40:23 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Shen", "Jiaming", ""], ["Ji", "Heng", ""], ["Han", "Jiawei", ""]]}, {"id": "2010.00770", "submitter": "Kexin Pei", "authors": "Kexin Pei, Jonas Guan, David Williams-King, Junfeng Yang, Suman Jana", "title": "XDA: Accurate, Robust Disassembly with Transfer Learning", "comments": "2021 Network and Distributed System Security Symposium (NDSS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate and robust disassembly of stripped binaries is challenging. The root\nof the difficulty is that high-level structures, such as instruction and\nfunction boundaries, are absent in stripped binaries and must be recovered\nbased on incomplete information. Current disassembly approaches rely on\nheuristics or simple pattern matching to approximate the recovery, but these\nmethods are often inaccurate and brittle, especially across different compiler\noptimizations.\n  We present XDA, a transfer-learning-based disassembly framework that learns\ndifferent contextual dependencies present in machine code and transfers this\nknowledge for accurate and robust disassembly. We design a self-supervised\nlearning task motivated by masked Language Modeling to learn interactions among\nbyte sequences in binaries. The outputs from this task are byte embeddings that\nencode sophisticated contextual dependencies between input binaries' byte\ntokens, which can then be finetuned for downstream disassembly tasks.\n  We evaluate XDA's performance on two disassembly tasks, recovering function\nboundaries and assembly instructions, on a collection of 3,121 binaries taken\nfrom SPEC CPU2017, SPEC CPU2006, and the BAP corpus. The binaries are compiled\nby GCC, ICC, and MSVC on x86/x64 Windows and Linux platforms over 4\noptimization levels. XDA achieves 99.0% and 99.7% F1 score at recovering\nfunction boundaries and instructions, respectively, surpassing the previous\nstate-of-the-art on both tasks. It also maintains speed on par with the fastest\nML-based approach and is up to 38x faster than hand-written disassemblers like\nIDA Pro. We release the code of XDA at https://github.com/CUMLSec/XDA.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 04:14:17 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 23:38:39 GMT"}, {"version": "v3", "created": "Thu, 19 Nov 2020 04:40:24 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Pei", "Kexin", ""], ["Guan", "Jonas", ""], ["Williams-King", "David", ""], ["Yang", "Junfeng", ""], ["Jana", "Suman", ""]]}, {"id": "2010.00801", "submitter": "MaungMaung AprilPyone", "authors": "MaungMaung AprilPyone, Hitoshi Kiya", "title": "Block-wise Image Transformation with Secret Key for Adversarially Robust\n  Defense", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel defensive transformation that enables us to\nmaintain a high classification accuracy under the use of both clean images and\nadversarial examples for adversarially robust defense. The proposed\ntransformation is a block-wise preprocessing technique with a secret key to\ninput images. We developed three algorithms to realize the proposed\ntransformation: Pixel Shuffling, Bit Flipping, and FFX Encryption. Experiments\nwere carried out on the CIFAR-10 and ImageNet datasets by using both black-box\nand white-box attacks with various metrics including adaptive ones. The results\nshow that the proposed defense achieves high accuracy close to that of using\nclean images even under adaptive attacks for the first time. In the best-case\nscenario, a model trained by using images transformed by FFX Encryption (block\nsize of 4) yielded an accuracy of 92.30% on clean images and 91.48% under PGD\nattack with a noise distance of 8/255, which is close to the non-robust\naccuracy (95.45%) for the CIFAR-10 dataset, and it yielded an accuracy of\n72.18% on clean images and 71.43% under the same attack, which is also close to\nthe standard accuracy (73.70%) for the ImageNet dataset. Overall, all three\nproposed algorithms are demonstrated to outperform state-of-the-art defenses\nincluding adversarial training whether or not a model is under attack.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 06:07:12 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["AprilPyone", "MaungMaung", ""], ["Kiya", "Hitoshi", ""]]}, {"id": "2010.00852", "submitter": "Muhammad Rana", "authors": "Muhammad Rana, Quazi Mamun, Rafiqul Islam", "title": "Current Lightweight Cryptography Protocols in Smart City IoT Networks: A\n  Survey", "comments": "22 pages, 3 figures and 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of advanced technology, IoT introduces a vast number of\ndevices connecting with each other and collecting a sheer volume of data. Thus,\nthe demands of IoT security is paramount. Cryptography is being used to secure\nthe networks for authentication, confidentiality, data integrity and access\ncontrol. However, due to the resource constraint nature of IoT devices, the\ntraditional cryptographic protocols may not be suited in all IoT environments.\nResearchers, as a result, have been proposing various lightweight cryptographic\nalgorithms and protocols. In this paper, we discuss the state of the art\nlightweight cryptographic protocols for IoT networks and present a comparative\nanalysis of the existing protocols. In doing so, this paper has classified the\nmost current algorithm into two parts, such as symmetric and asymmetric\nlightweight cryptography. Additionally, we consider several recent developed\nblock cipher and stream cipher algorithms. Furthermore, various research\nchallenges of lightweight cryptography have been addressed.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 08:32:08 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Rana", "Muhammad", ""], ["Mamun", "Quazi", ""], ["Islam", "Rafiqul", ""]]}, {"id": "2010.00906", "submitter": "Antoine Boutet", "authors": "Vasisht Duddu, Antoine Boutet, Virat Shejwalkar", "title": "Quantifying Privacy Leakage in Graph Embedding", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph embeddings have been proposed to map graph data to low dimensional\nspace for downstream processing (e.g., node classification or link prediction).\nWith the increasing collection of personal data, graph embeddings can be\ntrained on private and sensitive data. For the first time, we quantify the\nprivacy leakage in graph embeddings through three inference attacks targeting\nGraph Neural Networks. We propose a membership inference attack to infer\nwhether a graph node corresponding to individual user's data was member of the\nmodel's training or not. We consider a blackbox setting where the adversary\nexploits the output prediction scores, and a whitebox setting where the\nadversary has also access to the released node embeddings. This attack provides\nan accuracy up to 28% (blackbox) 36% (whitebox) beyond random guess by\nexploiting the distinguishable footprint between train and test data records\nleft by the graph embedding. We propose a Graph Reconstruction attack where the\nadversary aims to reconstruct the target graph given the corresponding graph\nembeddings. Here, the adversary can reconstruct the graph with more than 80% of\naccuracy and link inference between two nodes around 30% more confidence than a\nrandom guess. We then propose an attribute inference attack where the adversary\naims to infer a sensitive attribute. We show that graph embeddings are strongly\ncorrelated to node attributes letting the adversary inferring sensitive\ninformation (e.g., gender or location).\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 10:28:16 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 09:07:40 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Duddu", "Vasisht", ""], ["Boutet", "Antoine", ""], ["Shejwalkar", "Virat", ""]]}, {"id": "2010.00912", "submitter": "Antoine Boutet", "authors": "Vasisht Duddu, Antoine Boutet, Virat Shejwalkar", "title": "GECKO: Reconciling Privacy, Accuracy and Efficiency in Embedded Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedded systems demand on-device processing of data using Neural Networks\n(NNs) while conforming to the memory, power and computation constraints,\nleading to an efficiency and accuracy tradeoff. To bring NNs to edge devices,\nseveral optimizations such as model compression through pruning, quantization,\nand off-the-shelf architectures with efficient design have been extensively\nadopted. These algorithms when deployed to real world sensitive applications,\nrequires to resist inference attacks to protect privacy of users training data.\nHowever, resistance against inference attacks is not accounted for designing NN\nmodels for IoT. In this work, we analyse the three-dimensional\nprivacy-accuracy-efficiency tradeoff in NNs for IoT devices and propose Gecko\ntraining methodology where we explicitly add resistance to private inferences\nas a design objective. We optimize the inference-time memory, computation, and\npower constraints of embedded devices as a criterion for designing NN\narchitecture while also preserving privacy. We choose quantization as design\nchoice for highly efficient and private models. This choice is driven by the\nobservation that compressed models leak more information compared to baseline\nmodels while off-the-shelf efficient architectures indicate poor efficiency and\nprivacy tradeoff. We show that models trained using Gecko methodology are\ncomparable to prior defences against black-box membership attacks in terms of\naccuracy and privacy while providing efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 10:36:55 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 09:13:10 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Duddu", "Vasisht", ""], ["Boutet", "Antoine", ""], ["Shejwalkar", "Virat", ""]]}, {"id": "2010.01031", "submitter": "Xiao Fan Liu", "authors": "Xiao Fan Liu, Xin-Jian Jiang, Si-Hao Liu, Chi Kong Tse", "title": "Knowledge Discovery in Cryptocurrency Transactions: A Survey", "comments": "60 pages, 217 refs, 6 tables, and 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptocurrencies gain trust in users by publicly disclosing the full creation\nand transaction history. In return, the transaction history faithfully records\nthe whole spectrum of cryptocurrency user behaviors. This article analyzes and\nsummarizes the existing research on knowledge discovery in the cryptocurrency\ntransactions using data mining techniques. Specifically, we classify the\nexisting research into three aspects, i.e., transaction tracings and blockchain\naddress linking, the analyses of collective user behaviors, and the study of\nindividual user behaviors. For each aspect, we present the problems, summarize\nthe methodologies, and discuss major findings in the literature. Furthermore,\nan enumeration of transaction data parsing and visualization tools and services\nis also provided. Finally, we outline several future directions in this\nresearch area, such as the current rapid development of Decentralized Finance\n(De-Fi) and digital fiat money.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 14:38:08 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Liu", "Xiao Fan", ""], ["Jiang", "Xin-Jian", ""], ["Liu", "Si-Hao", ""], ["Tse", "Chi Kong", ""]]}, {"id": "2010.01034", "submitter": "Matthew Smith", "authors": "Matthew Smith, Martin Strohmeier, Vincent Lenders and Ivan Martinovic", "title": "Understanding Realistic Attacks on Airborne Collision Avoidance Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Airborne collision avoidance systems provide an onboard safety net should\nnormal air traffic control procedures fail to keep aircraft separated. These\nsystems are widely deployed and have been constantly refined over the past\nthree decades, usually in response to near misses or mid-air collisions. Recent\nyears have seen security research increasingly focus on aviation, identifying\nthat key wireless links---some of which are used in collision avoidance---are\nvulnerable to attack. In this paper, we go one step further to understand\nwhether an attacker can remotely trigger false collision avoidance alarms.\nPrimarily considering the next-generation Airborne Collision Avoidance System X\n(ACAS X), we adopt a modelling approach to extract attacker constraints from\ntechnical standards before simulating collision avoidance attacks against\nstandardized ACAS X code. We find that in 44% of cases, an attacker can\nsuccessfully trigger a collision avoidance alert which on average results in a\n590 ft altitude deviation; when the aircraft is at lower altitudes, this\nsuccess rate rises considerably to 79%. Furthermore, we show how our simulation\napproach can be used to help defend against attacks by identifying where\nattackers are most likely to be successful.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 14:47:17 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Smith", "Matthew", ""], ["Strohmeier", "Martin", ""], ["Lenders", "Vincent", ""], ["Martinovic", "Ivan", ""]]}, {"id": "2010.01039", "submitter": "Grzegorz G{\\l}uch", "authors": "Grzegorz G{\\l}uch, R\\\"udiger Urbanke", "title": "Query complexity of adversarial attacks", "comments": "32 pages, 2 figures Generalized the results. Adversarial examples no\n  longer need to be in the support of the data distribution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are two main attack models considered in the adversarial robustness\nliterature: black-box and white-box. We consider these threat models as two\nends of a fine-grained spectrum, indexed by the number of queries the adversary\ncan ask. Using this point of view we investigate how many queries the adversary\nneeds to make to design an attack that is comparable to the best possible\nattack in the white-box model. We give a lower bound on that number of queries\nin terms of entropy of decision boundaries of the classifier. Using this result\nwe analyze two classical learning algorithms on two synthetic tasks for which\nwe prove meaningful security guarantees. The obtained bounds suggest that some\nlearning algorithms are inherently more robust against query-bounded\nadversaries than others.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 15:01:29 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 14:38:56 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["G\u0142uch", "Grzegorz", ""], ["Urbanke", "R\u00fcdiger", ""]]}, {"id": "2010.01056", "submitter": "Duc Le", "authors": "Duc V. Le and Arthur Gervais", "title": "AMR:Autonomous Coin Mixer with Privacy Preserving Reward Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that users on open blockchains are tracked by an industry\nproviding services to governments, law enforcement, secret services, and alike.\nWhile most blockchains do not protect their users' privacy and allow external\nobservers to link transactions and addresses, a growing research interest\nattempts to design add-on privacy solutions to help users regain their privacy\non non-private blockchains.\n  In this work, we propose to our knowledge the first censorship resilient\nmixer, which can reward its users in a privacy-preserving manner for\nparticipating in the system. Increasing the anonymity set size, and diversity\nof users, is, as we believe, an important endeavor to raise a mixer's\ncontributed privacy in practice. The paid-out rewards can take the form of\ngovernance tokens to decentralize the voting on system parameters, similar to\nhow popular \"DeFi farming\" protocols operate. Moreover, by leveraging existing\n\"Defi\" lending platforms, AMR is the first mixer design that allows\nparticipating clients to earn financial interests on their deposited funds.\n  Our system AMR is autonomous as it does not rely on any external server or\nthird party. The evaluation of our AMR implementation shows that the system\nsupports today on Ethereum anonymity set sizes beyond thousands of users, and a\ncapacity of over $66,000$ deposits per day, at constant system costs. We\nprovide a formal specification of our zksnark-based AMR system, a privacy and\nsecurity analysis, implementation, and evaluation with both the MiMC and\nPoseidon hash functions.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 15:36:46 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 12:28:57 GMT"}, {"version": "v3", "created": "Mon, 7 Jun 2021 17:02:04 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Le", "Duc V.", ""], ["Gervais", "Arthur", ""]]}, {"id": "2010.01172", "submitter": "Peng Zhang", "authors": "Peng Zhang, Douglas C. Schmidt, Jules White", "title": "A Pattern Sequence for Designing Blockchain-Based Healthcare Information\n  Technology Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Known for its decentralized and tamper-aware properties, blockchain is\nattractive to enhance the infrastructure of systems that have been constrained\nby traditionally centralized and vendor-locked environments. Although\nblockchain has commonly been used as the operational model behind\ncryptocurrency, it has far more foreseeable utilities in domains like\nhealthcare, where efficient data flow is highly demanded. Particularly,\nblockchain and related technologies have been touted as foundational\ntechnologies for addressing healthcare interoperability challenges, such as\npromoting effective communications and securing data exchanges across various\nhealthcare systems. Despite the increasing interests in leveraging blockchain\ntechnology to improve healthcare infrastructures, a major gap in literature is\nthe lack of available recommendations for concrete architectural styles and\ndesign considerations for creating blockchain-based apps and systems with a\nhealthcare focus. This research provides two contributions to bridge the gap in\nexisting research. First, we introduce a pattern sequence for designing\nblockchain-based healthcare systems focused on secure and at-scale data\nexchange. Our approach adapts traditional software patterns and proposes novel\npatterns that take into account both the technical requirements specific to\nhealthcare systems and the implications of these requirements on naive\nblockchain-based solutions. Second, we provide a pattern-oriented reference\narchitecture using an example application of the pattern sequence for guiding\nsoftware developers to design interoperable (on the technical level) healthcare\nIT systems atop blockchain-based infrastructures. The reference architecture\nfocuses on minimizing storage requirements on-chain, preserving the privacy of\nsensitive information, facilitating scalable communications, and maximizing\nevolvability of the system.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 19:14:23 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Zhang", "Peng", ""], ["Schmidt", "Douglas C.", ""], ["White", "Jules", ""]]}, {"id": "2010.01175", "submitter": "Lun Wang", "authors": "Lun Wang, Qi Pang, Shuai Wang and Dawn Song", "title": "Towards Bidirectional Protection in Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Prior efforts in enhancing federated learning (FL) security fall into two\ncategories. At one end of the spectrum, some work uses secure aggregation\ntechniques to hide the individual client's updates and only reveal the\naggregated global update to a malicious server that strives to infer the\nclients' privacy from their updates. At the other end of the spectrum, some\nwork uses Byzantine-robust FL protocols to suppress the influence of malicious\nclients' updates. We present a federated learning protocol F2ED-LEARNING,\nwhich, for the first time, offers bidirectional defense to simultaneously\ncombat against the malicious centralized server and Byzantine malicious\nclients. To defend against Byzantine malicious clients, F2ED-LEARNING provides\ndimension-free estimation error by employing and calibrating a well-studied\nrobust mean estimator FilterL2. F2ED-LEARNING also leverages secure aggregation\nto protect clients from a malicious server. One key challenge of F2ED-LEARNING\nis to address the incompatibility between FilterL2 and secure aggregation\nschemes. Concretely, FilterL2 has to check the individual updates from clients\nwhereas secure aggregation hides those updates from the malicious server. To\nthis end, we propose a practical and highly effective solution to split the\nclients into shards, where F2ED-LEARNING securely aggregates each shard's\nupdate and launches FilterL2 on updates from different shards. The evaluation\nshows that F2ED-LEARNING consistently achieves optimal or close-to-optimal\nperformance and outperforms five secure FL protocols under five popular\nattacks.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 19:37:02 GMT"}, {"version": "v2", "created": "Sun, 30 May 2021 20:24:12 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wang", "Lun", ""], ["Pang", "Qi", ""], ["Wang", "Shuai", ""], ["Song", "Dawn", ""]]}, {"id": "2010.01234", "submitter": "Zhili Chen Prof.", "authors": "Tianjiao Ni, Minghao Qiao, Zhili Chen, Shun Zhang, Hong Zhong", "title": "Utility-efficient Differentially Private K-means Clustering based on\n  Cluster Merging", "comments": "13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy is widely used in data analysis. State-of-the-art\n$k$-means clustering algorithms with differential privacy typically add an\nequal amount of noise to centroids for each iterative computation. In this\npaper, we propose a novel differentially private $k$-means clustering\nalgorithm, DP-KCCM, that significantly improves the utility of clustering by\nadding adaptive noise and merging clusters. Specifically, to obtain $k$\nclusters with differential privacy, the algorithm first generates $n \\times k$\ninitial centroids, adds adaptive noise for each iteration to get $n \\times k$\nclusters, and finally merges these clusters into $k$ ones. We theoretically\nprove the differential privacy of the proposed algorithm. Surprisingly,\nextensive experimental results show that: 1) cluster merging with equal amounts\nof noise improves the utility somewhat; 2) although adding adaptive noise only\ndoes not improve the utility, combining both cluster merging and adaptive noise\nfurther improves the utility significantly.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 00:09:09 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Ni", "Tianjiao", ""], ["Qiao", "Minghao", ""], ["Chen", "Zhili", ""], ["Zhang", "Shun", ""], ["Zhong", "Hong", ""]]}, {"id": "2010.01235", "submitter": "Zhili Chen Prof.", "authors": "Zhili Chen, Yuting Wang, Tianjiao Ni, Hong Zhong", "title": "DCDChain: A Credible Architecture of Digital Copyright Detection Based\n  on Blockchain", "comments": "5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Copyright detection is an effective method to prevent piracy. However,\nuntrustworthy detection parties may lead to falsified detection results. Due to\nits credibility and tamper resistance, blockchain has been applied to copyright\nprotection. Previous works mainly utilized blockchain for reliable copyright\ninformation storage or copyrighted digital media trading. As far as we know,\nthe problem of credible copyright detection has not been addressed. In this\npaper, we propose a credible copyright detection architecture based on the\nblockchain, called DCDChain. In this architecture, the detection agency first\ndetects copyrights off the chain, then uploads the detection records to the\nblockchain. Since data on the blockchain are publicly accessible, media\nproviders can verify the correctness of the copyright detection, and appeal to\na smart contract if there is any dissent. The smart contract then arbitrates\nthe disputes by verifying the correctness of detection on the chain. The\ndetect-verify-and-arbitrate mechanism guarantees the credibility of copyright\ndetection. Privacy and security analysis and experimental simulations show that\nthe digital copyright detection architecture is reliable, secure and efficient.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 00:24:50 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Chen", "Zhili", ""], ["Wang", "Yuting", ""], ["Ni", "Tianjiao", ""], ["Zhong", "Hong", ""]]}, {"id": "2010.01250", "submitter": "Zhichao Huang", "authors": "Zhichao Huang, Yaowei Huang, Tong Zhang", "title": "CorrAttack: Black-box Adversarial Attack with Structured Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for score-based adversarial attack, where the\nattacker queries the loss-oracle of the target model. Our method employs a\nparameterized search space with a structure that captures the relationship of\nthe gradient of the loss function. We show that searching over the structured\nspace can be approximated by a time-varying contextual bandits problem, where\nthe attacker takes feature of the associated arm to make modifications of the\ninput, and receives an immediate reward as the reduction of the loss function.\nThe time-varying contextual bandits problem can then be solved by a Bayesian\noptimization procedure, which can take advantage of the features of the\nstructured action space. The experiments on ImageNet and the Google Cloud\nVision API demonstrate that the proposed method achieves the state of the art\nsuccess rates and query efficiencies for both undefended and defended models.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 01:44:16 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Huang", "Zhichao", ""], ["Huang", "Yaowei", ""], ["Zhang", "Tong", ""]]}, {"id": "2010.01285", "submitter": "Xuanli He", "authors": "Lingjuan Lyu, Xuanli He, Yitong Li", "title": "Differentially Private Representation for NLP: Formal Guarantee and An\n  Empirical Study on Privacy and Fairness", "comments": "accepted to Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been demonstrated that hidden representation learned by a deep model\ncan encode private information of the input, hence can be exploited to recover\nsuch information with reasonable accuracy. To address this issue, we propose a\nnovel approach called Differentially Private Neural Representation (DPNR) to\npreserve the privacy of the extracted representation from text. DPNR utilises\nDifferential Privacy (DP) to provide a formal privacy guarantee. Further, we\nshow that masking words via dropout can further enhance privacy. To maintain\nutility of the learned representation, we integrate DP-noisy representation\ninto a robust training process to derive a robust target model, which also\nhelps for model fairness over various demographic variables. Experimental\nresults on benchmark datasets under various parameter settings demonstrate that\nDPNR largely reduces privacy leakage without significantly sacrificing the main\ntask performance.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 05:58:32 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Lyu", "Lingjuan", ""], ["He", "Xuanli", ""], ["Li", "Yitong", ""]]}, {"id": "2010.01329", "submitter": "Felice Antonio Merra", "authors": "Vito Walter Anelli, Alejandro Bellog\\'in, Yashar Deldjoo, Tommaso Di\n  Noia, Felice Antonio Merra", "title": "Multi-Step Adversarial Perturbations on Recommender Systems Embeddings", "comments": "10 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems (RSs) have attained exceptional performance in learning\nusers' preferences and helping them in finding the most suitable products.\nRecent advances in adversarial machine learning (AML) in the computer vision\ndomain have raised interests in the security of state-of-the-art model-based\nrecommenders. Recently, worrying deterioration of recommendation accuracy has\nbeen acknowledged on several state-of-the-art model-based recommenders (e.g.,\nBPR-MF) when machine-learned adversarial perturbations contaminate model\nparameters. However, while the single-step fast gradient sign method (FGSM) is\nthe most explored perturbation strategy, multi-step (iterative) perturbation\nstrategies, that demonstrated higher efficacy in the computer vision domain,\nhave been highly under-researched in recommendation tasks.\n  In this work, inspired by the basic iterative method (BIM) and the projected\ngradient descent (PGD) strategies proposed in the CV domain, we adapt the\nmulti-step strategies for the item recommendation task to study the possible\nweaknesses of embedding-based recommender models under minimal adversarial\nperturbations. Letting the magnitude of the perturbation be fixed, we\nillustrate the highest efficacy of the multi-step perturbation compared to the\nsingle-step one with extensive empirical evaluation on two widely adopted\nrecommender datasets. Furthermore, we study the impact of structural dataset\ncharacteristics, i.e., sparsity, density, and size, on the performance\ndegradation issued by presented perturbations to support RS designer in\ninterpreting recommendation performance variation due to minimal variations of\nmodel parameters. Our implementation and datasets are available at\nhttps://anonymous.4open.science/r/9f27f909-93d5-4016-b01c-8976b8c14bc5/.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 11:25:47 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Anelli", "Vito Walter", ""], ["Bellog\u00edn", "Alejandro", ""], ["Deldjoo", "Yashar", ""], ["Di Noia", "Tommaso", ""], ["Merra", "Felice Antonio", ""]]}, {"id": "2010.01347", "submitter": "Massimo Bartoletti", "authors": "Massimo Bartoletti and Stefano Lande and Roberto Zunino", "title": "Computationally sound Bitcoin tokens", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a secure and efficient implementation of fungible tokens on\nBitcoin. Our technique is based on a small extension of the Bitcoin script\nlanguage, which allows the spending conditions in a transaction to depend on\nthe neighbour transactions. We show that our implementation is computationally\nsound: that is, adversaries can make tokens diverge from their ideal\nfunctionality only with negligible probability.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 13:03:26 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 05:44:06 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Bartoletti", "Massimo", ""], ["Lande", "Stefano", ""], ["Zunino", "Roberto", ""]]}, {"id": "2010.01373", "submitter": "Wang Taotao", "authors": "Taotao Wang, Chonghe Zhao, Qing Yang, Shengli Zhang, and Soung Chang\n  Liew", "title": "Ethna: Analyzing the Underlying Peer-to-Peer Network of the Ethereum\n  Blockchain", "comments": "15 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The peer-to-peer (P2P) network of blockchain used to transport its\ntransactions and blocks has a high impact on the efficiency and security of the\nsystem. The P2P network topologies of popular blockchains such as Bitcoin and\nEthereum, therefore, deserve our highest attention. The current Ethereum\nblockchain explorers (e.g., Etherscan) focus on the tracking of block and\ntransaction records but omit the characterization of the underlying P2P\nnetwork. This work presents the Ethereum Network Analyzer (Ethna), a tool that\nprobes and analyzes the P2P network of the Ethereum blockchain. Unlike Bitcoin\nthat adopts an unstructured P2P network, Ethereum relies on the Kademlia DHT to\nmanage its P2P network. Therefore, the existing analytical methods for\nBitcoin-like P2P networks are not applicable to Ethereum. Ethna implements a\nnovel method that accurately measures the degrees of Ethereum nodes.\nFurthermore, it incorporates an algorithm that derives the latency metrics of\nmessage propagation in the Ethereum P2P network. We ran Ethna on the Ethereum\nMainnet and conducted extensive experiments to analyze the topological features\nof its P2P network. Our analysis shows that the Ethereum P2P network possesses\na certain effect of small-world networks, and the degrees of nodes follow a\npower-law distribution that characterizes scale-free networks.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2020 15:09:04 GMT"}, {"version": "v2", "created": "Sat, 27 Mar 2021 14:14:42 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Wang", "Taotao", ""], ["Zhao", "Chonghe", ""], ["Yang", "Qing", ""], ["Zhang", "Shengli", ""], ["Liew", "Soung Chang", ""]]}, {"id": "2010.01582", "submitter": "Pierangelo Lombardo", "authors": "Salvatore Saeli, Federica Bisio, Pierangelo Lombardo, Danilo Massa", "title": "DNS Covert Channel Detection via Behavioral Analysis: a Machine Learning\n  Approach", "comments": "This is a pre-print of an article published in the proceedings of\n  14th International Conference on Malicious and Unwanted Software (MALWARE),\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting covert channels among legitimate traffic represents a severe\nchallenge due to the high heterogeneity of networks. Therefore, we propose an\neffective covert channel detection method, based on the analysis of DNS network\ndata passively extracted from a network monitoring system. The framework is\nbased on a machine learning module and on the extraction of specific anomaly\nindicators able to describe the problem at hand. The contribution of this paper\nis two-fold: (i) the machine learning models encompass network profiles\ntailored to the network users, and not to the single query events, hence\nallowing for the creation of behavioral profiles and spotting possible\ndeviations from the normal baseline; (ii) models are created in an unsupervised\nmode, thus allowing for the identification of zero-days attacks and avoiding\nthe requirement of signatures or heuristics for new variants. The proposed\nsolution has been evaluated over a 15-day-long experimental session with the\ninjection of traffic that covers the most relevant exfiltration and tunneling\nattacks: all the malicious variants were detected, while producing a low\nfalse-positive rate during the same period.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 13:28:28 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Saeli", "Salvatore", ""], ["Bisio", "Federica", ""], ["Lombardo", "Pierangelo", ""], ["Massa", "Danilo", ""]]}, {"id": "2010.01592", "submitter": "Ali Khodabakhsh", "authors": "Ali Khodabakhsh, Zahid Akhtar", "title": "Unknown Presentation Attack Detection against Rational Attackers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the impressive progress in the field of presentation attack detection\nand multimedia forensics over the last decade, these systems are still\nvulnerable to attacks in real-life settings. Some of the challenges for\nexisting solutions are the detection of unknown attacks, the ability to perform\nin adversarial settings, few-shot learning, and explainability. In this study,\nthese limitations are approached by reliance on a game-theoretic view for\nmodeling the interactions between the attacker and the detector. Consequently,\na new optimization criterion is proposed and a set of requirements are defined\nfor improving the performance of these systems in real-life settings.\nFurthermore, a novel detection technique is proposed using generator-based\nfeature sets that are not biased towards any specific attack species. To\nfurther optimize the performance on known attacks, a new loss function coined\ncategorical margin maximization loss (C-marmax) is proposed which gradually\nimproves the performance against the most powerful attack. The proposed\napproach provides a more balanced performance across known and unknown attacks\nand achieves state-of-the-art performance in known and unknown attack detection\ncases against rational attackers. Lastly, the few-shot learning potential of\nthe proposed approach is studied as well as its ability to provide pixel-level\nexplainability.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 14:37:10 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2021 22:37:17 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Khodabakhsh", "Ali", ""], ["Akhtar", "Zahid", ""]]}, {"id": "2010.01670", "submitter": "Xinyuan Zhang", "authors": "Xinyuan Zhang", "title": "Mixing Strategies in Cryptocurrencies and An Alternative Implementation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Since the initial launch of Bitcoin by Satoshi Nakamoto in 2009,\ndecentralized digital currencies have long been of major interest in both the\nacademia and the industry. Till today, there are more than 3000 different\ncryptocurrencies over the internet. Each one relies on mathematical soundness\nand cryptographic wit to provide unique properties in addition to securing\nbasic correctness. A common misbelief for cryptocurrencies is that they provide\ncomplete anonymity by replacing people's real-life identity with a randomly\ngenerated wallet address in payments. However, this \"pseudonymity\" is easily\nbreakable under the public ledger. Many attacks demonstrate ways to deanonymize\npeople through observing the transaction patterns or network interactions.\nThus, cryptocurrency fungibility has become a popular topic in the research\ncommunity. This report reviews a partial list of existing schemes and describes\nan alternative implementation, Eth-Tumbler. Eth-Tumbler utilizes layered\nencryption and multiple signatures and thus efficiently hides a user under\nk-anonymity.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 19:46:18 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Zhang", "Xinyuan", ""]]}, {"id": "2010.01700", "submitter": "Emery Berger", "authors": "Breanna Devore-McDonald and Emery D. Berger", "title": "Mossad: Defeating Software Plagiarism Detection", "comments": "30 pages. To appear, OOPSLA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.NE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic software plagiarism detection tools are widely used in educational\nsettings to ensure that submitted work was not copied. These tools have grown\nin use together with the rise in enrollments in computer science programs and\nthe widespread availability of code on-line. Educators rely on the robustness\nof plagiarism detection tools; the working assumption is that the effort\nrequired to evade detection is as high as that required to actually do the\nassigned work.\n  This paper shows this is not the case. It presents an entirely automatic\nprogram transformation approach, Mossad, that defeats popular software\nplagiarism detection tools. Mossad comprises a framework that couples\ntechniques inspired by genetic programming with domain-specific knowledge to\neffectively undermine plagiarism detectors. Mossad is effective at defeating\nfour plagiarism detectors, including Moss and JPlag. Mossad is both fast and\neffective: it can, in minutes, generate modified versions of programs that are\nlikely to escape detection. More insidiously, because of its non-deterministic\napproach, Mossad can, from a single program, generate dozens of variants, which\nare classified as no more suspicious than legitimate assignments. A detailed\nstudy of Mossad across a corpus of real student assignments demonstrates its\nefficacy at evading detection. A user study shows that graduate student\nassistants consistently rate Mossad-generated code as just as readable as\nauthentic student code. This work motivates the need for both research on more\nrobust plagiarism detection tools and greater integration of naturally\nplagiarism-resistant methodologies like code review into computer science\neducation.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 22:02:38 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Devore-McDonald", "Breanna", ""], ["Berger", "Emery D.", ""]]}, {"id": "2010.01712", "submitter": "Gueltoum Bendiab", "authors": "Gueltoum Bendiab, Stavros Shiaeles, Abdulrahman Alruban, Nicholas\n  Kolokotronis", "title": "IoT Malware Network Traffic Classification using Visual Representation\n  and Deep Learning", "comments": "10 pages, 5 figures, 2 tables", "journal-ref": "2020 6th IEEE Conference on Network Softwarization (NetSoft) 2020\n  6th IEEE Conference on Network Softwarization (NetSoft) 2020 6th IEEE\n  Conference on Network Softwarization (NetSoft) year 2020; Pages 444 - 449;", "doi": "10.1109/NetSoft48620.2020.9165381", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increase of IoT devices and technologies coming into service,\nMalware has risen as a challenging threat with increased infection rates and\nlevels of sophistication. Without strong security mechanisms, a huge amount of\nsensitive data is exposed to vulnerabilities, and therefore, easily abused by\ncybercriminals to perform several illegal activities. Thus, advanced network\nsecurity mechanisms that are able of performing a real-time traffic analysis\nand mitigation of malicious traffic are required. To address this challenge, we\nare proposing a novel IoT malware traffic analysis approach using deep learning\nand visual representation for faster detection and classification of new\nmalware (zero-day malware). The detection of malicious network traffic in the\nproposed approach works at the package level, significantly reducing the time\nof detection with promising results due to the deep learning technologies used.\nTo evaluate our proposed method performance, a dataset is constructed which\nconsists of 1000 pcap files of normal and malware traffic that are collected\nfrom different network traffic sources. The experimental results of Residual\nNeural Network (ResNet50) are very promising, providing a 94.50% accuracy rate\nfor detection of malware traffic.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 22:44:04 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Bendiab", "Gueltoum", ""], ["Shiaeles", "Stavros", ""], ["Alruban", "Abdulrahman", ""], ["Kolokotronis", "Nicholas", ""]]}, {"id": "2010.01785", "submitter": "Yuan Chen", "authors": "Yuwei Li, Shouling Ji, Yuan Chen, Sizhuang Liang, Wei-Han Lee, Yueyao\n  Chen, Chenyang Lyu, Chunming Wu, Raheem Beyah, Peng Cheng, Kangjie Lu, Ting\n  Wang", "title": "UNIFUZZ: A Holistic and Pragmatic Metrics-Driven Platform for Evaluating\n  Fuzzers", "comments": "To appear in the Proceedings of the 30th USENIX Security Symposium\n  (USENIX Security 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A flurry of fuzzing tools (fuzzers) have been proposed in the literature,\naiming at detecting software vulnerabilities effectively and efficiently. To\ndate, it is however still challenging to compare fuzzers due to the\ninconsistency of the benchmarks, performance metrics, and/or environments for\nevaluation, which buries the useful insights and thus impedes the discovery of\npromising fuzzing primitives. In this paper, we design and develop UNIFUZZ, an\nopen-source and metrics-driven platform for assessing fuzzers in a\ncomprehensive and quantitative manner. Specifically, UNIFUZZ to date has\nincorporated 35 usable fuzzers, a benchmark of 20 real-world programs, and six\ncategories of performance metrics. We first systematically study the usability\nof existing fuzzers, find and fix a number of flaws, and integrate them into\nUNIFUZZ. Based on the study, we propose a collection of pragmatic performance\nmetrics to evaluate fuzzers from six complementary perspectives. Using UNIFUZZ,\nwe conduct in-depth evaluations of several prominent fuzzers including AFL [1],\nAFLFast [2], Angora [3], Honggfuzz [4], MOPT [5], QSYM [6], T-Fuzz [7] and\nVUzzer64 [8]. We find that none of them outperforms the others across all the\ntarget programs, and that using a single metric to assess the performance of a\nfuzzer may lead to unilateral conclusions, which demonstrates the significance\nof comprehensive metrics. Moreover, we identify and investigate previously\noverlooked factors that may significantly affect a fuzzer's performance,\nincluding instrumentation methods and crash analysis tools. Our empirical\nresults show that they are critical to the evaluation of a fuzzer. We hope that\nour findings can shed light on reliable fuzzing evaluation, so that we can\ndiscover promising fuzzing primitives to effectively facilitate fuzzer designs\nin the future.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 05:25:32 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Li", "Yuwei", ""], ["Ji", "Shouling", ""], ["Chen", "Yuan", ""], ["Liang", "Sizhuang", ""], ["Lee", "Wei-Han", ""], ["Chen", "Yueyao", ""], ["Lyu", "Chenyang", ""], ["Wu", "Chunming", ""], ["Beyah", "Raheem", ""], ["Cheng", "Peng", ""], ["Lu", "Kangjie", ""], ["Wang", "Ting", ""]]}, {"id": "2010.01862", "submitter": "Ferhat Ozgur Catak", "authors": "Ferhat Ozgur Catak, Javed Ahmed, Kevser Sahinbas, Zahid Hussain Khand", "title": "Data Augmentation Based Malware Detection using Convolutional Neural\n  Networks", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, cyber-attacks have been extensively seen due to the everlasting\nincrease of malware in the cyber world. These attacks cause irreversible damage\nnot only to end-users but also to corporate computer systems. Ransomware\nattacks such as WannaCry and Petya specifically targets to make critical\ninfrastructures such as airports and rendered operational processes inoperable.\nHence, it has attracted increasing attention in terms of volume, versatility,\nand intricacy. The most important feature of this type of malware is that they\nchange shape as they propagate from one computer to another. Since standard\nsignature-based detection software fails to identify this type of malware\nbecause they have different characteristics on each contaminated computer. This\npaper aims at providing an image augmentation enhanced deep convolutional\nneural network (CNN) models for the detection of malware families in a\nmetamorphic malware environment. The main contributions of the paper's model\nstructure consist of three components, including image generation from malware\nsamples, image augmentation, and the last one is classifying the malware\nfamilies by using a convolutional neural network model. In the first component,\nthe collected malware samples are converted binary representation to 3-channel\nimages using windowing technique. The second component of the system create the\naugmented version of the images, and the last component builds a classification\nmodel. In this study, five different deep convolutional neural network model\nfor malware family detection is used.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 08:58:07 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Catak", "Ferhat Ozgur", ""], ["Ahmed", "Javed", ""], ["Sahinbas", "Kevser", ""], ["Khand", "Zahid Hussain", ""]]}, {"id": "2010.01950", "submitter": "Hoki Kim", "authors": "Hoki Kim", "title": "Torchattacks: A PyTorch Repository for Adversarial Attacks", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Torchattacks is a PyTorch library that contains adversarial attacks to\ngenerate adversarial examples and to verify the robustness of deep learning\nmodels. The code can be found at\nhttps://github.com/Harry24k/adversarial-attacks-pytorch.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 01:34:42 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 01:16:12 GMT"}, {"version": "v3", "created": "Fri, 19 Feb 2021 15:42:38 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Kim", "Hoki", ""]]}, {"id": "2010.01973", "submitter": "Adam Aviv", "authors": "Hirak Ray and Flynn Wolf and Ravi Kuber and Adam J. Aviv", "title": "Why Older Adults (Don't) Use Password Managers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Password managers (PMs) are considered highly effective tools for increasing\nsecurity, and a recent study by Pearman et al. (SOUPS'19) highlighted the\nmotivations and barriers to adopting PMs. We expand these findings by\nreplicating Pearman et al.'s protocol and interview instrument applied to a\nsample of strictly older adults (>60 years of age), as the prior work focused\non a predominantly younger cohort. We conducted n=26 semi-structured interviews\nwith PM users, built-in browser/operating system PM users, and non-PM users.\nThe average participant age was 70.4 years. Using the same codebook from\nPearman et al., we showcase differences and similarities in PM adoption between\nthe samples, including fears of a single point of failure and the importance of\nhaving control over one's private information. Meanwhile, older adults were\nfound to have higher mistrust of cloud storage of passwords and cross-device\nsynchronization. We also highlight PM adoption motivators for older adults,\nincluding the power of recommendations from family members and the importance\nof education and outreach to improve familiarity.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 13:02:47 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Ray", "Hirak", ""], ["Wolf", "Flynn", ""], ["Kuber", "Ravi", ""], ["Aviv", "Adam J.", ""]]}, {"id": "2010.02117", "submitter": "Thomas Gross", "authors": "Thomas Gro{\\ss}", "title": "Statistical Reliability of 10 Years of Cyber Security User Studies\n  (Extended Version)", "comments": "Open Science Framework: https://osf.io/bcyte. 31 pages. This is the\n  author's copy. This work was supported by the ERC Starting Grant\n  Confidentiality-Preserving Security Assurance (CASCAde), GA no 716980", "journal-ref": "Proceedings of the 10th International Workshop on Socio-Technical\n  Aspects in Security (STAST 2020), LNCS 11739, Springer, 2020", "doi": null, "report-no": null, "categories": "cs.HC cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background. In recent years, cyber security security user studies have been\nappraised in meta-research, mostly focusing on the completeness of their\nstatistical inferences and the fidelity of their statistical reporting.\nHowever, estimates of the field's distribution of statistical power and its\npublication bias have not received much attention. Aim. In this study, we aim\nto estimate the effect sizes and their standard errors present as well as the\nimplications on statistical power and publication bias. Method. We built upon a\npublished systematic literature review of $146$ user studies in cyber security\n(2006--2016). We took into account $431$ statistical inferences including $t$-,\n$\\chi^2$-, $r$-, one-way $F$-tests, and $Z$-tests. In addition, we coded the\ncorresponding total sample sizes, group sizes and test families. Given these\ndata, we established the observed effect sizes and evaluated the overall\npublication bias. We further computed the statistical power vis-{\\`a}-vis of\nparametrized population thresholds to gain unbiased estimates of the power\ndistribution. Results. We obtained a distribution of effect sizes and their\nconversion into comparable log odds ratios together with their standard errors.\nWe, further, gained funnel-plot estimates of the publication bias present in\nthe sample as well as insights into the power distribution and its\nconsequences. Conclusions. Through the lenses of power and publication bias, we\nshed light on the statistical reliability of the studies in the field. The\nupshot of this introspection is practical recommendations on conducting and\nevaluating studies to advance the field.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 16:02:32 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Gro\u00df", "Thomas", ""]]}, {"id": "2010.02124", "submitter": "Karl Palmskog", "authors": "Elaine Li, Karl Palmskog, Mircea Sebe, Grigore Ro\\c{s}u", "title": "Specification of the Giskard Consensus Protocol", "comments": "15 pages plus 2 pages as appendix, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Giskard consensus protocol is used to validate transactions and\ncomputations in the PlatON network. In this paper, we provide a rigorous\nspecification of Giskard, suitable to serve as a reference in protocol\nimplementation and in formal verification. Using our specification, we prove\nthat the protocol guarantees several notable safety properties.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 16:10:33 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Li", "Elaine", ""], ["Palmskog", "Karl", ""], ["Sebe", "Mircea", ""], ["Ro\u015fu", "Grigore", ""]]}, {"id": "2010.02169", "submitter": "Mohammad Javad Shayegan", "authors": "Kiarash Shamsi, Koosha Esmaielzadeh Khorasani, Mohammad Javad Shayegan", "title": "A Secure and Efficient Approach for Issuing KYC Token As COVID-19 Health\n  Certificate Based on Stellar Blockchain Network", "comments": "This paper has been published in the International Journal of Web\n  Research, Volume 3, Issue 1, 2020", "journal-ref": "International Journal of Web Research, 3(1), 42-49 (2020)", "doi": "10.22133/IJWR.2020.250275.1070", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's world is struggling with the COVID-19 pandemic, as one of the\ngreatest challenges of the 21st century. During the lockdown caused by this\ndisease, many financial losses have been inflicted on people and all\nindustries. One of the fastest ways to save these industries from the COVID-19\nis to provide a reliable solution for people's health assessment. In this\narticle, blockchain technology is used to propose a model which provides and\nvalidates the health certificates for people who travel or present in society.\nFor this purpose, we take advantage of blockchain features in protecting\npeople's privacy. Since a variety of antibody and human health proving tests\nagainst the virus are developing, this study tries simultaneously to design an\nintegrated and secure system to meet the authenticity and accuracy of different\npeople's health certificates for the companies requiring these certifications.\nIn this system, on the one hand, there are qualified laboratories that are\nresponsible for performing standard testing and also providing results to the\nsystem controller. Finally, people are considered as the end-user of the\nsystem. To provide test information for the entities, the mechanism of KYC\ntokens will be used based on the Stellar private blockchain network. In this\nmechanism, the user will buy a certain amount of KYC tokens from the system\ncontroller. These tokens are charged in the user's wallet, and the user can\nsend these tokens from his wallet to any destination company, to exchange the\nencrypted health certificate information. Finally, considering the appropriate\nplatform provided by blockchain technology and the requirement of a reliable\nand accurate solution for issuing health certificates during the Covid-19\npandemic or any other disease, this article offers a solution to meet the\nrequirements.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 17:18:35 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Shamsi", "Kiarash", ""], ["Khorasani", "Koosha Esmaielzadeh", ""], ["Shayegan", "Mohammad Javad", ""]]}, {"id": "2010.02387", "submitter": "Mayana Pereira", "authors": "Mayana Pereira, Rahul Dodhia and Richard Brown", "title": "Metadata-Based Detection of Child Sexual Abuse Material", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, the scale of creation and distribution of child sexual\nabuse medias (CSAM) has exponentially increased. Technologies that aid law\nenforcement agencies worldwide to identify such crimes rapidly can potentially\nresult in the mitigation of child victimization, and the apprehending of\noffenders. Machine learning presents the potential to help law enforcement\nrapidly identify such material, and even block such content from being\ndistributed digitally. However, collecting and storing CSAM files to train\nmachine learning models has many ethical and legal constraints, creating a\nbarrier to the development of accurate computer vision-based models. With such\nrestrictions in place, the development of accurate machine learning classifiers\nfor CSAM identification based on file metadata becomes crucial.\n  In this work, we propose a system for CSAM identification on file storage\nsystems based solely on metadata - file paths. Our aim is to provide a tool\nthat is material type agnostic (image, video, PDF), and can potentially scans\nthousands of file storage systems in a short time. Our approach uses\nconvolutional neural networks, and achieves an accuracy of 97% and recall of\n94%. Additionally, we address the potential problem of offenders trying to\nevade detection by this model by evaluating the robustness of our model against\nadversarial modifications in the file paths.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 23:10:21 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Pereira", "Mayana", ""], ["Dodhia", "Rahul", ""], ["Brown", "Richard", ""]]}, {"id": "2010.02421", "submitter": "Farid Javani", "authors": "Farid Javani and Alan T. Sherman", "title": "BVOT: Self-Tallying Boardroom Voting with Oblivious Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A boardroom election is an election with a small number of voters carried out\nwith public communications. We present BVOT, a self-tallying boardroom voting\nprotocol with ballot secrecy, fairness (no tally information is available\nbefore the polls close), and dispute-freeness (voters can observe that all\nvoters correctly followed the protocol).\n  BVOT works by using a multiparty threshold homomorphic encryption system in\nwhich each candidate is associated with a masked unique prime. Each voter\nengages in an oblivious transfer with an untrusted distributor: the voter\nselects the index of a prime associated with a candidate and receives the\nselected prime in masked form. The voter then casts their vote by encrypting\ntheir masked prime and broadcasting it to everyone. The distributor does not\nlearn the voter's choice, and no one learns the mapping between primes and\ncandidates until the audit phase. By hiding the mapping between primes and\ncandidates, BVOT provides voters with insufficient information to carry out\neffective cheating. The threshold feature prevents anyone from computing any\npartial tally---until everyone has voted. Multiplying all votes, their\ndecryption shares, and the unmasking factor yields a product of the primes each\nraised to the number of votes received.\n  In contrast to some existing boardroom voting protocols, BVOT does not rely\non any zero-knowledge proof; instead, it uses oblivious transfer to assure\nballot secrecy and correct vote casting. Also, BVOT can handle multiple\ncandidates in one election. BVOT prevents cheating by hiding crucial\ninformation: an attempt to increase the tally of one candidate might increase\nthe tally of another candidate. After all votes are cast, any party can tally\nthe votes.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 01:28:34 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Javani", "Farid", ""], ["Sherman", "Alan T.", ""]]}, {"id": "2010.02432", "submitter": "Sanghyun Hong", "authors": "Sanghyun Hong, Yi\\u{g}itcan Kaya, Ionu\\c{t}-Vlad Modoranu, Tudor\n  Dumitra\\c{s}", "title": "A Panda? No, It's a Sloth: Slowdown Attacks on Adaptive Multi-Exit\n  Neural Network Inference", "comments": "Accepted to ICLR 2021 [Spotlight]; First two authors contributed\n  equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent increases in the computational demands of deep neural networks (DNNs),\ncombined with the observation that most input samples require only simple\nmodels, have sparked interest in $input$-$adaptive$ multi-exit architectures,\nsuch as MSDNets or Shallow-Deep Networks. These architectures enable faster\ninferences and could bring DNNs to low-power devices, e.g., in the Internet of\nThings (IoT). However, it is unknown if the computational savings provided by\nthis approach are robust against adversarial pressure. In particular, an\nadversary may aim to slowdown adaptive DNNs by increasing their average\ninference time$-$a threat analogous to the $denial$-$of$-$service$ attacks from\nthe Internet. In this paper, we conduct a systematic evaluation of this threat\nby experimenting with three generic multi-exit DNNs (based on VGG16, MobileNet,\nand ResNet56) and a custom multi-exit architecture, on two popular image\nclassification benchmarks (CIFAR-10 and Tiny ImageNet). To this end, we show\nthat adversarial example-crafting techniques can be modified to cause slowdown,\nand we propose a metric for comparing their impact on different architectures.\nWe show that a slowdown attack reduces the efficacy of multi-exit DNNs by\n90-100%, and it amplifies the latency by 1.5-5$\\times$ in a typical IoT\ndeployment. We also show that it is possible to craft universal, reusable\nperturbations and that the attack can be effective in realistic black-box\nscenarios, where the attacker has limited knowledge about the victim. Finally,\nwe show that adversarial training provides limited protection against\nslowdowns. These results suggest that further research is needed for defending\nmulti-exit architectures against this emerging threat. Our code is available at\nhttps://github.com/sanghyun-hong/deepsloth.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 02:06:52 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 22:38:35 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Hong", "Sanghyun", ""], ["Kaya", "Yi\u011fitcan", ""], ["Modoranu", "Ionu\u0163-Vlad", ""], ["Dumitra\u015f", "Tudor", ""]]}, {"id": "2010.02456", "submitter": "Andrew Lohn", "authors": "Andrew J. Lohn", "title": "Downscaling Attack and Defense: Turning What You See Back Into What You\n  Get", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The resizing of images, which is typically a required part of preprocessing\nfor computer vision systems, is vulnerable to attack. Images can be created\nsuch that the image is completely different at machine-vision scales than at\nother scales and the default settings for some common computer vision and\nmachine learning systems are vulnerable. We show that defenses exist and are\ntrivial to administer provided that defenders are aware of the threat. These\nattacks and defenses help to establish the role of input sanitization in\nmachine learning.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 03:41:05 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 18:24:29 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Lohn", "Andrew J.", ""]]}, {"id": "2010.02508", "submitter": "Ryan Campbell", "authors": "Ryan Campbell, Chris Finlay, Adam M Oberman", "title": "Adversarial Boot Camp: label free certified robustness in one epoch", "comments": "13 pages, 5 figures, 5 tables. Under review as a conference paper at\n  ICLR 2021. arXiv admin note: substantial text overlap with arXiv:2006.06061", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are vulnerable to adversarial attacks. One approach\nto addressing this vulnerability is certification, which focuses on models that\nare guaranteed to be robust for a given perturbation size. A drawback of recent\ncertified models is that they are stochastic: they require multiple\ncomputationally expensive model evaluations with random noise added to a given\ninput. In our work, we present a deterministic certification approach which\nresults in a certifiably robust model. This approach is based on an equivalence\nbetween training with a particular regularized loss, and the expected values of\nGaussian averages. We achieve certified models on ImageNet-1k by retraining a\nmodel with this loss for one epoch without the use of label information.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2020 13:47:45 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Campbell", "Ryan", ""], ["Finlay", "Chris", ""], ["Oberman", "Adam M", ""]]}, {"id": "2010.02524", "submitter": "Rishabh Poddar", "authors": "Andrew Law, Chester Leung, Rishabh Poddar, Raluca Ada Popa, Chenyu\n  Shi, Octavian Sima, Chaofan Yu, Xingmeng Zhang, Wenting Zheng", "title": "Secure Collaborative Training and Inference for XGBoost", "comments": "ACM CCS PPMLP'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, gradient boosted decision tree learning has proven to be an\neffective method of training robust models. Moreover, collaborative learning\namong multiple parties has the potential to greatly benefit all parties\ninvolved, but organizations have also encountered obstacles in sharing\nsensitive data due to business, regulatory, and liability concerns.\n  We propose Secure XGBoost, a privacy-preserving system that enables\nmultiparty training and inference of XGBoost models. Secure XGBoost protects\nthe privacy of each party's data as well as the integrity of the computation\nwith the help of hardware enclaves. Crucially, Secure XGBoost augments the\nsecurity of the enclaves using novel data-oblivious algorithms that prevent\naccess side-channel attacks on enclaves induced via access pattern leakage.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 06:56:05 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Law", "Andrew", ""], ["Leung", "Chester", ""], ["Poddar", "Rishabh", ""], ["Popa", "Raluca Ada", ""], ["Shi", "Chenyu", ""], ["Sima", "Octavian", ""], ["Yu", "Chaofan", ""], ["Zhang", "Xingmeng", ""], ["Zheng", "Wenting", ""]]}, {"id": "2010.02529", "submitter": "Zhenyu Wu", "authors": "Yuli Zheng, Zhenyu Wu, Ye Yuan, Tianlong Chen, Zhangyang Wang", "title": "PCAL: A Privacy-preserving Intelligent Credit Risk Modeling Framework\n  Based on Adversarial Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Credit risk modeling has permeated our everyday life. Most banks and\nfinancial companies use this technique to model their clients' trustworthiness.\nWhile machine learning is increasingly used in this field, the resulting\nlarge-scale collection of user private information has reinvigorated the\nprivacy debate, considering dozens of data breach incidents every year caused\nby unauthorized hackers, and (potentially even more) information misuse/abuse\nby authorized parties. To address those critical concerns, this paper proposes\na framework of Privacy-preserving Credit risk modeling based on Adversarial\nLearning (PCAL). PCAL aims to mask the private information inside the original\ndataset, while maintaining the important utility information for the target\nprediction task performance, by (iteratively) weighing between a privacy-risk\nloss and a utility-oriented loss. PCAL is compared against off-the-shelf\noptions in terms of both utility and privacy protection. Results indicate that\nPCAL can learn an effective, privacy-free representation from user data,\nproviding a solid foundation towards privacy-preserving machine learning for\ncredit risk analysis.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 07:04:59 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Zheng", "Yuli", ""], ["Wu", "Zhenyu", ""], ["Yuan", "Ye", ""], ["Chen", "Tianlong", ""], ["Wang", "Zhangyang", ""]]}, {"id": "2010.02671", "submitter": "Ricardo P\\'erez-Marco", "authors": "Cyril Grunspan, Ricardo P\\'erez-Marco", "title": "Profit lag and alternate network mining", "comments": "19 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a mining strategy we define the notion of \"profit lag\" as the minimum\ntime it takes to be profitable after that moment. We compute closed forms for\nthe profit lag and the revenue ratio for the strategies \"selfish mining\" and\n\"intermittent selfish mining\". This confirms some earlier numerical simulations\nand clarifies misunderstandings on profitability in the literature. We also\nstudy mining pairs of PoW cryptocurrencies, often coming from a fork, with the\nsame mining algorithm. This represents a vector of attack that can be exploited\nusing the \"alternate network mining\" strategy that we define. We compute closed\nforms for the profit lag and the revenue ratiofor this strategy that is more\nprofitable than selfish mining and intermittent selfish mining. It is also\nharder to counter since it does not rely on a flaw in the difficulty adjustment\nformula that is the reason for profitability of the other strategies.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 12:42:06 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Grunspan", "Cyril", ""], ["P\u00e9rez-Marco", "Ricardo", ""]]}, {"id": "2010.02772", "submitter": "Yangsibo Huang", "authors": "Yangsibo Huang, Zhao Song, Kai Li, Sanjeev Arora", "title": "InstaHide: Instance-hiding Schemes for Private Distributed Learning", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CC cs.DS cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  How can multiple distributed entities collaboratively train a shared deep net\non their private data while preserving privacy? This paper introduces\nInstaHide, a simple encryption of training images, which can be plugged into\nexisting distributed deep learning pipelines. The encryption is efficient and\napplying it during training has minor effect on test accuracy.\n  InstaHide encrypts each training image with a \"one-time secret key\" which\nconsists of mixing a number of randomly chosen images and applying a random\npixel-wise mask. Other contributions of this paper include: (a) Using a large\npublic dataset (e.g. ImageNet) for mixing during its encryption, which improves\nsecurity. (b) Experimental results to show effectiveness in preserving privacy\nagainst known attacks with only minor effects on accuracy. (c) Theoretical\nanalysis showing that successfully attacking privacy requires attackers to\nsolve a difficult computational problem. (d) Demonstrating that use of the\npixel-wise mask is important for security, since Mixup alone is shown to be\ninsecure to some some efficient attacks. (e) Release of a challenge dataset\nhttps://github.com/Hazelsuko07/InstaHide_Challenge\n  Our code is available at https://github.com/Hazelsuko07/InstaHide\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 14:43:23 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 18:54:19 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Huang", "Yangsibo", ""], ["Song", "Zhao", ""], ["Li", "Kai", ""], ["Arora", "Sanjeev", ""]]}, {"id": "2010.03007", "submitter": "Ahmed Salem", "authors": "Ahmed Salem, Yannick Sautter, Michael Backes, Mathias Humbert, Yang\n  Zhang", "title": "BAAAN: Backdoor Attacks Against Autoencoder and GAN-Based Machine\n  Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tremendous progress of autoencoders and generative adversarial networks\n(GANs) has led to their application to multiple critical tasks, such as fraud\ndetection and sanitized data generation. This increasing adoption has fostered\nthe study of security and privacy risks stemming from these models. However,\nprevious works have mainly focused on membership inference attacks. In this\nwork, we explore one of the most severe attacks against machine learning\nmodels, namely the backdoor attack, against both autoencoders and GANs. The\nbackdoor attack is a training time attack where the adversary implements a\nhidden backdoor in the target model that can only be activated by a secret\ntrigger. State-of-the-art backdoor attacks focus on classification-based tasks.\nWe extend the applicability of backdoor attacks to autoencoders and GAN-based\nmodels. More concretely, we propose the first backdoor attack against\nautoencoders and GANs where the adversary can control what the decoded or\ngenerated images are when the backdoor is activated. Our results show that the\nadversary can build a backdoored autoencoder that returns a target output for\nall backdoored inputs, while behaving perfectly normal on clean inputs.\nSimilarly, for the GANs, our experiments show that the adversary can generate\ndata from a different distribution when the backdoor is activated, while\nmaintaining the same utility when the backdoor is not.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 20:26:16 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 07:28:17 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Salem", "Ahmed", ""], ["Sautter", "Yannick", ""], ["Backes", "Michael", ""], ["Humbert", "Mathias", ""], ["Zhang", "Yang", ""]]}, {"id": "2010.03072", "submitter": "Ryutaroh Matsumoto", "authors": "Koichiro Yamanaka, Ryutaroh Matsumoto, Keita Takahashi, and Toshiaki\n  Fujii", "title": "Adversarial Patch Attacks on Monocular Depth Estimation Networks", "comments": "Publisher's Open Access PDF with the CC-BY copyright. Associated\n  video, data and programs are available at\n  https://www.fujii.nuee.nagoya-u.ac.jp/Research/MonoDepth/", "journal-ref": "IEEE Access, vol.8, pp.179094-179104, October 2020", "doi": "10.1109/ACCESS.2020.3027372", "report-no": null, "categories": "cs.CV cs.CR eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Thanks to the excellent learning capability of deep convolutional neural\nnetworks (CNN), monocular depth estimation using CNNs has achieved great\nsuccess in recent years. However, depth estimation from a monocular image alone\nis essentially an ill-posed problem, and thus, it seems that this approach\nwould have inherent vulnerabilities. To reveal this limitation, we propose a\nmethod of adversarial patch attack on monocular depth estimation. More\nspecifically, we generate artificial patterns (adversarial patches) that can\nfool the target methods into estimating an incorrect depth for the regions\nwhere the patterns are placed. Our method can be implemented in the real world\nby physically placing the printed patterns in real scenes. We also analyze the\nbehavior of monocular depth estimation under attacks by visualizing the\nactivation levels of the intermediate layers and the regions potentially\naffected by the adversarial attack.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2020 22:56:22 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Yamanaka", "Koichiro", ""], ["Matsumoto", "Ryutaroh", ""], ["Takahashi", "Keita", ""], ["Fujii", "Toshiaki", ""]]}, {"id": "2010.03094", "submitter": "Tao Zhang", "authors": "Tao Zhang, Tianqing Zhu, Ping Xiong, Huan Huo, Zahir Tari, Wanlei Zhou", "title": "Correlated Differential Privacy: Feature Selection in Machine Learning", "comments": "This paper has been published in IEEE Transactions on Industrial\n  Informatics", "journal-ref": "IEEE Transactions on Industrial Informatics, vol. 16, no. 3, pp.\n  2115-2124, March 2020", "doi": "10.1109/TII.2019.2936825", "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy preserving in machine learning is a crucial issue in industry\ninformatics since data used for training in industries usually contain\nsensitive information. Existing differentially private machine learning\nalgorithms have not considered the impact of data correlation, which may lead\nto more privacy leakage than expected in industrial applications. For example,\ndata collected for traffic monitoring may contain some correlated records due\nto temporal correlation or user correlation. To fill this gap, we propose a\ncorrelation reduction scheme with differentially private feature selection\nconsidering the issue of privacy loss when data have correlation in machine\nlearning tasks. %The key to the proposed scheme is to describe the data\ncorrelation and select features which leads to less data correlation across the\nwhole dataset. The proposed scheme involves five steps with the goal of\nmanaging the extent of data correlation, preserving the privacy, and supporting\naccuracy in the prediction results. In this way, the impact of data correlation\nis relieved with the proposed feature selection scheme, and moreover, the\nprivacy issue of data correlation in learning is guaranteed. The proposed\nmethod can be widely used in machine learning algorithms which provide services\nin industrial areas. Experiments show that the proposed scheme can produce\nbetter prediction results with machine learning tasks and fewer mean square\nerrors for data queries compared to existing schemes.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 00:33:24 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Zhang", "Tao", ""], ["Zhu", "Tianqing", ""], ["Xiong", "Ping", ""], ["Huo", "Huan", ""], ["Tari", "Zahir", ""], ["Zhou", "Wanlei", ""]]}, {"id": "2010.03180", "submitter": "Asaf Shabtai", "authors": "Eden Levy, Yael Mathov, Ziv Katzir, Asaf Shabtai, Yuval Elovici", "title": "Not All Datasets Are Born Equal: On Heterogeneous Data and Adversarial\n  Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on adversarial learning has focused mainly on neural networks and\ndomains where they excel, such as computer vision. The data in these domains is\nhomogeneous, whereas heterogeneous tabular data domains remain underexplored\ndespite their prevalence. Constructing an attack on models with heterogeneous\ninput spaces is challenging, as they are governed by complex domain-specific\nvalidity rules and comprised of nominal, ordinal, and numerical features. We\nargue that machine learning models trained on heterogeneous tabular data are as\nsusceptible to adversarial manipulations as those trained on continuous or\nhomogeneous data such as images. In this paper, we introduce an optimization\nframework for identifying adversarial perturbations in heterogeneous input\nspaces. We define distribution-aware constraints for preserving the consistency\nof the adversarial examples and incorporate them by embedding the heterogeneous\ninput into a continuous latent space. Our approach focuses on an adversary who\naims to craft valid perturbations of minimal l_0-norms and apply them in real\nlife. We propose a neural network-based implementation of our approach and\ndemonstrate its effectiveness using three datasets from different content\ndomains. Our results suggest that despite the several constraints heterogeneity\nimposes on the input space of a machine learning model, the susceptibility to\nadversarial examples remains unimpaired.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 05:24:23 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Levy", "Eden", ""], ["Mathov", "Yael", ""], ["Katzir", "Ziv", ""], ["Shabtai", "Asaf", ""], ["Elovici", "Yuval", ""]]}, {"id": "2010.03232", "submitter": "Mohamed-Lamine Messai", "authors": "Mohamed-Lamine Messai and Hamida Seba", "title": "Short Paper: Privacy Comparison of Contact Tracing Mobile Applications\n  for COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the COVID-19 pandemic, quarantines took place across the globe. In the\naim of stopping or slowing the progression of the COVID-19 contamination, many\ncountries have deployed a contact tracing system to notify persons that be in\ncontact with a COVID-positive person. The contact tracing system is implemented\nin a mobile application and leverages technologies such as Bluetooth to trace\ninteractions between persons. This paper discusses different smart-phone\napplications based on contact tracing system from privacy point of view.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 07:27:39 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Messai", "Mohamed-Lamine", ""], ["Seba", "Hamida", ""]]}, {"id": "2010.03241", "submitter": "Tzonelih Hwang", "authors": "Jun Gu and Tzonelih Hwang", "title": "Two attacks and counterattacks on the mutual semi-quantum key agreement\n  protocol using Bell states", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a mutual semi-quantum key agreement protocol using Bell states is\nproposed by Yan et al. (Mod. Phys. Lett. A, 34, 1950294, 2019). The proposed\nprotocol tries to help a quantum participant share a key with a classical\nparticipant who just has limited quantum capacities. Yan et al. claimed that\nboth the participants have the same influence on the final shared key. However,\nthis study points out that the classical participant can manipulate the final\nshared key by himself/herself without being detected. To solve this problem, an\nimproved method is proposed here.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 07:44:50 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Gu", "Jun", ""], ["Hwang", "Tzonelih", ""]]}, {"id": "2010.03282", "submitter": "Ahmed Salem", "authors": "Ahmed Salem, Michael Backes, Yang Zhang", "title": "Don't Trigger Me! A Triggerless Backdoor Attack Against Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backdoor attack against deep neural networks is currently being profoundly\ninvestigated due to its severe security consequences. Current state-of-the-art\nbackdoor attacks require the adversary to modify the input, usually by adding a\ntrigger to it, for the target model to activate the backdoor. This added\ntrigger not only increases the difficulty of launching the backdoor attack in\nthe physical world, but also can be easily detected by multiple defense\nmechanisms. In this paper, we present the first triggerless backdoor attack\nagainst deep neural networks, where the adversary does not need to modify the\ninput for triggering the backdoor. Our attack is based on the dropout\ntechnique. Concretely, we associate a set of target neurons that are dropped\nout during model training with the target label. In the prediction phase, the\nmodel will output the target label when the target neurons are dropped again,\ni.e., the backdoor attack is launched. This triggerless feature of our attack\nmakes it practical in the physical world. Extensive experiments show that our\ntriggerless backdoor attack achieves a perfect attack success rate with a\nnegligible damage to the model's utility.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 09:01:39 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Salem", "Ahmed", ""], ["Backes", "Michael", ""], ["Zhang", "Yang", ""]]}, {"id": "2010.03288", "submitter": "Philipp Benz", "authors": "Philipp Benz, Chaoning Zhang, Tooba Imtiaz, In So Kweon", "title": "Double Targeted Universal Adversarial Perturbations", "comments": "Accepted at ACCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their impressive performance, deep neural networks (DNNs) are widely\nknown to be vulnerable to adversarial attacks, which makes it challenging for\nthem to be deployed in security-sensitive applications, such as autonomous\ndriving. Image-dependent perturbations can fool a network for one specific\nimage, while universal adversarial perturbations are capable of fooling a\nnetwork for samples from all classes without selection. We introduce a double\ntargeted universal adversarial perturbations (DT-UAPs) to bridge the gap\nbetween the instance-discriminative image-dependent perturbations and the\ngeneric universal perturbations. This universal perturbation attacks one\ntargeted source class to sink class, while having a limited adversarial effect\non other non-targeted source classes, for avoiding raising suspicions.\nTargeting the source and sink class simultaneously, we term it double targeted\nattack (DTA). This provides an attacker with the freedom to perform precise\nattacks on a DNN model while raising little suspicion. We show the\neffectiveness of the proposed DTA algorithm on a wide range of datasets and\nalso demonstrate its potential as a physical attack.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 09:08:51 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Benz", "Philipp", ""], ["Zhang", "Chaoning", ""], ["Imtiaz", "Tooba", ""], ["Kweon", "In So", ""]]}, {"id": "2010.03300", "submitter": "Philipp Benz", "authors": "Chaoning Zhang, Philipp Benz, Tooba Imtiaz, In So Kweon", "title": "CD-UAP: Class Discriminative Universal Adversarial Perturbation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A single universal adversarial perturbation (UAP) can be added to all natural\nimages to change most of their predicted class labels. It is of high practical\nrelevance for an attacker to have flexible control over the targeted classes to\nbe attacked, however, the existing UAP method attacks samples from all classes.\nIn this work, we propose a new universal attack method to generate a single\nperturbation that fools a target network to misclassify only a chosen group of\nclasses, while having limited influence on the remaining classes. Since the\nproposed attack generates a universal adversarial perturbation that is\ndiscriminative to targeted and non-targeted classes, we term it class\ndiscriminative universal adversarial perturbation (CD-UAP). We propose one\nsimple yet effective algorithm framework, under which we design and compare\nvarious loss function configurations tailored for the class discriminative\nuniversal attack. The proposed approach has been evaluated with extensive\nexperiments on various benchmark datasets. Additionally, our proposed approach\nachieves state-of-the-art performance for the original task of UAP attacking\nall classes, which demonstrates the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 09:26:42 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Zhang", "Chaoning", ""], ["Benz", "Philipp", ""], ["Imtiaz", "Tooba", ""], ["Kweon", "In So", ""]]}, {"id": "2010.03465", "submitter": "Simon Oya", "authors": "Simon Oya, Florian Kerschbaum", "title": "Hiding the Access Pattern is Not Enough: Exploiting Search Pattern\n  Leakage in Searchable Encryption", "comments": "16 pages. 11 figures. To appear at Proceedings of the 30th USENIX\n  Security Symposium (August 11-13, 2021, Vancouver, B.C., Canada)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent Searchable Symmetric Encryption (SSE) schemes enable secure searching\nover an encrypted database stored in a server while limiting the information\nleaked to the server. These schemes focus on hiding the access pattern, which\nrefers to the set of documents that match the client's queries. This provides\nprotection against current attacks that largely depend on this leakage to\nsucceed. However, most SSE constructions also leak whether or not two queries\naim for the same keyword, also called the search pattern.\n  In this work, we show that search pattern leakage can severely undermine\ncurrent SSE defenses. We propose an attack that leverages both access and\nsearch pattern leakage, as well as some background and query distribution\ninformation, to recover the keywords of the queries performed by the client.\nOur attack follows a maximum likelihood estimation approach, and is easy to\nadapt against SSE defenses that obfuscate the access pattern. We empirically\nshow that our attack is efficient, it outperforms other proposed attacks, and\nit completely thwarts two out of the three defenses we evaluate it against,\neven when these defenses are set to high privacy regimes. These findings\nhighlight that hiding the search pattern, a feature that most constructions are\nlacking, is key towards providing practical privacy guarantees in SSE.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 15:02:10 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Oya", "Simon", ""], ["Kerschbaum", "Florian", ""]]}, {"id": "2010.03482", "submitter": "Wenshuo Wang", "authors": "Wenshuo Wang, Liang Cheng, Yang Zhang", "title": "Fuzzing Based on Function Importance by Interprocedural Control Flow\n  Graph", "comments": "This paper contains many grammatical errors. we need time to further\n  correct these errors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coverage-based graybox fuzzer (CGF), such as AFL has gained great success in\nvulnerability detection thanks to its ease-of-use and bug-finding power. Since\nsome code fragments such as memory allocation are more vulnerable than others,\nvarious improving techniques have been proposed to explore the more vulnerable\nareas by collecting extra information from the program under test or its\nexecutions. However, these improvements only consider limited types of\ninformation sources and ignore the fact that the priority a seed input to be\nfuzzed may be influenced by all the code it covers. Based on the above\nobservations, we propose a fuzzing method based on the importance of functions.\nFirst, a data structure called Attributed Interprocedural Control Flow Graph\n(AICFG) is devised to combine different features of code fragments. Second, the\nimportance of each node in the AICFG is calculated based on an improved\nPageRank algorithm, which also models the influence between connected nodes.\nDuring the fuzzing process, the node importance is updated periodically by a\npropagation algorithm. Then the seed selection and energy scheduling of a seed\ninput are determined by the importance of its execution trace. We implement\nthis approach on top of AFL in a tool named FunAFL and conduct an evaluation on\n14 real-world programs against AFL and two of its improvements. FunAFL, with\n17% higher branch coverage than others on average, finds 13 bugs and 3 of them\nare confirmed by CVE after 72 hours.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 15:36:08 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 05:12:22 GMT"}, {"version": "v3", "created": "Sat, 13 Feb 2021 15:36:32 GMT"}, {"version": "v4", "created": "Sat, 27 Feb 2021 15:08:50 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Wang", "Wenshuo", ""], ["Cheng", "Liang", ""], ["Zhang", "Yang", ""]]}, {"id": "2010.03484", "submitter": "Richard Harang", "authors": "Younghoo Lee, Joshua Saxe, Richard Harang", "title": "CATBERT: Context-Aware Tiny BERT for Detecting Social Engineering Emails", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Targeted phishing emails are on the rise and facilitate the theft of billions\nof dollars from organizations a year. While malicious signals from attached\nfiles or malicious URLs in emails can be detected by conventional malware\nsignatures or machine learning technologies, it is challenging to identify\nhand-crafted social engineering emails which don't contain any malicious code\nand don't share word choices with known attacks. To tackle this problem, we\nfine-tune a pre-trained BERT model by replacing the half of Transformer blocks\nwith simple adapters to efficiently learn sophisticated representations of the\nsyntax and semantics of the natural language. Our Context-Aware network also\nlearns the context representations between email's content and context features\nfrom email headers. Our CatBERT(Context-Aware Tiny Bert) achieves a 87%\ndetection rate as compared to DistilBERT, LSTM, and logistic regression\nbaselines which achieve 83%, 79%, and 54% detection rates at false positive\nrates of 1%, respectively. Our model is also faster than competing transformer\napproaches and is resilient to adversarial attacks which deliberately replace\nkeywords with typos or synonyms.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 15:40:36 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Lee", "Younghoo", ""], ["Saxe", "Joshua", ""], ["Harang", "Richard", ""]]}, {"id": "2010.03502", "submitter": "Josep Domingo-Ferrer", "authors": "Josep Domingo-Ferrer, Krishnamurty Muralidhar and Maria Bras-Amor\\'os", "title": "General Confidentiality and Utility Metrics for Privacy-Preserving Data\n  Publishing Based on the Permutation Model", "comments": "IEEE Transactions on Dependable and Secure Computing (to appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anonymization for privacy-preserving data publishing, also known as\nstatistical disclosure control (SDC), can be viewed under the lens of the\npermutation model. According to this model, any SDC method for individual data\nrecords is functionally equivalent to a permutation step plus a noise addition\nstep, where the noise added is marginal, in the sense that it does not alter\nranks. Here, we propose metrics to quantify the data confidentiality and\nutility achieved by SDC methods based on the permutation model. We distinguish\ntwo privacy notions: in our work, anonymity refers to subjects and hence mainly\nto protection against record re-identification, whereas confidentiality refers\nto the protection afforded to attribute values against attribute disclosure.\nThus, our confidentiality metrics are useful even if using a privacy model\nensuring an anonymity level ex ante. The utility metric is a general-purpose\nmetric that can be conveniently traded off against the confidentiality metrics,\nbecause all of them are bounded between 0 and 1. As an application, we compare\nthe utility-confidentiality trade-offs achieved by several anonymization\napproaches, including privacy models (k-anonymity and $\\epsilon$-differential\nprivacy) as well as SDC methods (additive noise, multiplicative noise and\nsynthetic data) used without privacy models.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 16:15:16 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Domingo-Ferrer", "Josep", ""], ["Muralidhar", "Krishnamurty", ""], ["Bras-Amor\u00f3s", "Maria", ""]]}, {"id": "2010.03671", "submitter": "AKM Iqtidar Newaz", "authors": "AKM Iqtidar Newaz, Nur Imtiazul Haque, Amit Kumar Sikder, Mohammad\n  Ashiqur Rahman, A. Selcuk Uluagac", "title": "Adversarial Attacks to Machine Learning-Based Smart Healthcare Systems", "comments": "6 pages, 5 figures, Accepted in IEEE Globecom 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing availability of healthcare data requires accurate analysis of\ndisease diagnosis, progression, and realtime monitoring to provide improved\ntreatments to the patients. In this context, Machine Learning (ML) models are\nused to extract valuable features and insights from high-dimensional and\nheterogeneous healthcare data to detect different diseases and patient\nactivities in a Smart Healthcare System (SHS). However, recent researches show\nthat ML models used in different application domains are vulnerable to\nadversarial attacks. In this paper, we introduce a new type of adversarial\nattacks to exploit the ML classifiers used in a SHS. We consider an adversary\nwho has partial knowledge of data distribution, SHS model, and ML algorithm to\nperform both targeted and untargeted attacks. Employing these adversarial\ncapabilities, we manipulate medical device readings to alter patient status\n(disease-affected, normal condition, activities, etc.) in the outcome of the\nSHS. Our attack utilizes five different adversarial ML algorithms (HopSkipJump,\nFast Gradient Method, Crafting Decision Tree, Carlini & Wagner, Zeroth Order\nOptimization) to perform different malicious activities (e.g., data poisoning,\nmisclassify outputs, etc.) on a SHS. Moreover, based on the training and\ntesting phase capabilities of an adversary, we perform white box and black box\nattacks on a SHS. We evaluate the performance of our work in different SHS\nsettings and medical devices. Our extensive evaluation shows that our proposed\nadversarial attack can significantly degrade the performance of a ML-based SHS\nin detecting diseases and normal activities of the patients correctly, which\neventually leads to erroneous treatment.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 21:55:10 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Newaz", "AKM Iqtidar", ""], ["Haque", "Nur Imtiazul", ""], ["Sikder", "Amit Kumar", ""], ["Rahman", "Mohammad Ashiqur", ""], ["Uluagac", "A. Selcuk", ""]]}, {"id": "2010.03672", "submitter": "Bernardo Huberman", "authors": "Bernardo A. Huberman and Tad Hogg", "title": "Privacy and Data Balkanization: Circumventing the Barriers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth in digital data forms the basis for a wide range of new\nservices and research, e.g, large-scale medical studies. At the same time,\nincreasingly restrictive privacy concerns and laws are leading to significant\noverhead in arranging for sharing or combining different data sets to obtain\nthese benefits. For new applications, where the benefit of combined data is not\nyet clear, this overhead can inhibit organizations from even trying to\ndetermine whether they can mutually benefit from sharing their data. In this\npaper, we discuss techniques to overcome this difficulty by employing private\ninformation transfer to determine whether there is a benefit from sharing data,\nand whether there is room to negotiate acceptable prices. These techniques\ninvolve cryptographic protocols. While currently considered secure, these\nprotocols are potentially vulnerable to the development of quantum technology,\nparticularly for ensuring privacy over significant periods of time into the\nfuture. To mitigate this concern, we describe how developments in practical\nquantum technology can improve the security of these protocols.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2020 22:05:28 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Huberman", "Bernardo A.", ""], ["Hogg", "Tad", ""]]}, {"id": "2010.03849", "submitter": "Katina Kralevska", "authors": "Simen Haga, Ali Esmaeily, Katina Kralevska, Danilo Gligoroski", "title": "5G Network Slice Isolation with WireGuard and Open Source MANO: A VPNaaS\n  Proof-of-Concept", "comments": "Accepted for presentation at IEEE NFV-SDN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fifth-generation (5G) mobile networks aim to host different types of\nservices on the same physical infrastructure. Network slicing is considered as\nthe key enabler for achieving this goal. Although there is some progress in\napplying and implementing network slicing in the context of 5G, the security\nand performance of network slicing still have many open research questions. In\nthis paper, we propose the first OSM-WireGuard framework and its lifecycle. We\nimplement the WireGuard secure network tunneling protocol in a 5G network to\nprovide a VPN-as-a-Service (VPNaaS) functionality for virtualized network\nfunctions. We demonstrate that OSM instantiates WireGuard-enabled services up\nand running in 4 min 26 sec, with potential the initialization time to go down\nto 2 min 44 sec if the operator prepares images with a pre-installed and\nup-to-date version of WireGuard before the on-boarding process. We also show\nthat the OSM-WireGuard framework provides considerable enhancement of up to 5.3\ntimes higher network throughput and up to 41% lower latency compared to\nOpenVPN. The reported results show that the proposed framework is a promising\nsolution for providing traffic isolation with strict latency and throughput\nrequirements.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 09:07:46 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Haga", "Simen", ""], ["Esmaeily", "Ali", ""], ["Kralevska", "Katina", ""], ["Gligoroski", "Danilo", ""]]}, {"id": "2010.03856", "submitter": "Feargus Pendlebury", "authors": "Federico Barbero, Feargus Pendlebury, Fabio Pierazzi, Lorenzo\n  Cavallaro", "title": "Transcending Transcend: Revisiting Malware Classification in the\n  Presence of Concept Drift", "comments": "Draft copy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning for malware classification shows encouraging results, but\nreal deployments suffer from performance degradation as malware authors adapt\ntheir techniques to evade detection. This phenomenon, known as concept drift,\noccurs as new malware examples evolve and become less and less like the\noriginal training examples. One promising method to cope with concept drift is\nclassification with rejection in which examples that are likely to be\nmisclassified are instead quarantined until they can be expertly analyzed. We\npropose TRANSCENDENT, a rejection framework built on Transcend, a recently\nproposed strategy based on conformal prediction theory. In particular, we\nprovide a formal treatment of Transcend, enabling us to refine conformal\nevaluation theory -- its underlying statistical engine -- and gain a better\nunderstanding of the theoretical reasons for its effectiveness. In the process,\nwe develop two additional conformal evaluators that match or surpass the\nperformance of the original while significantly decreasing the computational\noverhead. We evaluate TRANSCENDENT on a malware dataset spanning 5 years that\nremoves sources of experimental bias present in the original evaluation. To\nfurther assist practitioners, we determine the optimal operational settings for\na TRANSCENDENT deployment and show how it can be applied to many popular\nlearning algorithms. These insights support both old and new empirical\nfindings, making Transcend a sound and practical solution for the first time.\nTo this end, we release TRANSCENDENT as open source, to aid the adoption of\nrejection strategies by the security community.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 09:21:36 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 13:53:17 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2020 16:11:26 GMT"}, {"version": "v4", "created": "Wed, 27 Jan 2021 17:37:55 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Barbero", "Federico", ""], ["Pendlebury", "Feargus", ""], ["Pierazzi", "Fabio", ""], ["Cavallaro", "Lorenzo", ""]]}, {"id": "2010.03859", "submitter": "Fabian Schillinger", "authors": "Fabian Schillinger and Christian Schindelhauer", "title": "Partitioned Private User Storages in End-to-End Encrypted Online Social\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In secure Online Social Networks (OSN), often end-to-end encryption\napproaches are used. This ensures the privacy of communication between the\nparticipants. To manage, store, or transfer the cryptographic keys from one\ndevice to another one, encrypted private storages can be used. To gain access\nto such storages, login credentials, only known to the user, are needed. Losing\nthese credentials results in a permanent loss of cryptographic keys and\nmessages because the storage is encrypted. We present a scheme to split\nencrypted user storages into multiple storages. Each one can be reconstructed\nwith the help of other participants of the OSN. The more of the storages can be\nreconstructed, the higher the chance of successfully reconstructing the\ncomplete private storage is. Therefore, regaining possession of the\ncryptographic keys used for communication is increased. We achieve high rates\nof successful reconstructions, even if a large fraction of the distributed\nshares are not accessible anymore because the shareholders are inactive or\nmalicious.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 09:25:40 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Schillinger", "Fabian", ""], ["Schindelhauer", "Christian", ""]]}, {"id": "2010.03860", "submitter": "Fabian Schillinger", "authors": "Fabian Schillinger and Christian Schindelhauer", "title": "A Proxy-Based Encrypted Online Social Network With Fine-Grained Access", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When using Online Social Networks, users often share information with\ndifferent social groups. When considering the backgrounds of the groups there\nis often no or little intersection within the members. This means that a user\nwho shares information often has to share it with all members of all groups. It\ncan be problematic that the user cannot decide which group sees which\ninformation. Our approach therefore, allows users to decide for every bit of\ninformation who can access it. Further, protected circles can be created, where\nusers can share information within. Shared information and circles are\nencrypted and the keys can be distributed by proxies.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 09:28:47 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Schillinger", "Fabian", ""], ["Schindelhauer", "Christian", ""]]}, {"id": "2010.03864", "submitter": "Fabian Schillinger", "authors": "Fabian Schillinger and Christian Schindelhauer", "title": "Concealed Communication in Online Social Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online social networks are used frequently by many people: Staying in contact\nwith friends and sharing experiences with them is very important. However,\nusers are increasingly concerned that their data will end up in the hands of\nstrangers or that personal data may even be misused. Secure OSNs can help.\nThese often use different types of encryption to keep the communication between\nthe participants incomprehensible to outsiders. However, participants in such\nsocial networks cannot be sure that their data is secure. Various approaches\nshow that even harmless-looking metadata, such as the number of contacts of\nusers, can be evaluated to draw conclusions about the users and their\ncommunication. These attack methods are analyzed, and existing secure OSNs are\nexamined, whether these attack methods can be utilized to violate the user's\nprivacy. To prevent these privacy attacks, protocols for a secure centralized\nOSN are developed. Metadata is obscured in the presented OSM and end-to-end\nencryption is used for secure communication between clients. Additionally,\ncommunication channels are concealed using mix networks such that adversaries\ncannot determine which user is accessing which data or which user is\ncommunicating with whom even with access to the server.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 09:36:36 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Schillinger", "Fabian", ""], ["Schindelhauer", "Christian", ""]]}, {"id": "2010.04126", "submitter": "Hengchu Zhang", "authors": "Hengchu Zhang, Edo Roth, Andreas Haeberlen, Benjamin C. Pierce, Aaron\n  Roth", "title": "Testing Differential Privacy with Dual Interpreters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying differential privacy at scale requires convenient ways to check that\nprograms computing with sensitive data appropriately preserve privacy. We\npropose here a fully automated framework for {\\em testing} differential\nprivacy, adapting a well-known \"pointwise\" technique from informal proofs of\ndifferential privacy. Our framework, called DPCheck, requires no programmer\nannotations, handles all previously verified or tested algorithms, and is the\nfirst fully automated framework to distinguish correct and buggy\nimplementations of PrivTree, a probabilistically terminating algorithm that has\nnot previously been mechanically checked.\n  We analyze the probability of DPCheck mistakenly accepting a non-private\nprogram and prove that, theoretically, the probability of false acceptance can\nbe made exponentially small by suitable choice of test size.\n  We demonstrate DPCheck's utility empirically by implementing all benchmark\nalgorithms from prior work on mechanical verification of differential privacy,\nplus several others and their incorrect variants, and show DPCheck accepts the\ncorrect implementations and rejects the incorrect variants.\n  We also demonstrate how DPCheck can be deployed in a practical workflow to\ntest differentially privacy for the 2020 US Census Disclosure Avoidance System\n(DAS).\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 17:09:03 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Zhang", "Hengchu", ""], ["Roth", "Edo", ""], ["Haeberlen", "Andreas", ""], ["Pierce", "Benjamin C.", ""], ["Roth", "Aaron", ""]]}, {"id": "2010.04235", "submitter": "Andres Munoz Medina", "authors": "Andr\\'es Mu\\~noz Medina and Jenny Gillenwater", "title": "Duff: A Dataset-Distance-Based Utility Function Family for the\n  Exponential Mechanism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and analyze a general-purpose dataset-distance-based utility\nfunction family, Duff, for differential privacy's exponential mechanism. Given\na particular dataset and a statistic (e.g., median, mode), this function family\nassigns utility to a possible output o based on the number of individuals whose\ndata would have to be added to or removed from the dataset in order for the\nstatistic to take on value o. We show that the exponential mechanism based on\nDuff often offers provably higher fidelity to the statistic's true value\ncompared to existing differential privacy mechanisms based on smooth\nsensitivity. In particular, Duff is an affirmative answer to the open question\nof whether it is possible to have a noise distribution whose variance is\nproportional to smooth sensitivity and whose tails decay at a\nfaster-than-polynomial rate. We conclude our paper with an empirical evaluation\nof the practical advantages of Duff for the task of computing medians.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 19:37:37 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 21:54:31 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Medina", "Andr\u00e9s Mu\u00f1oz", ""], ["Gillenwater", "Jenny", ""]]}, {"id": "2010.04280", "submitter": "Shahriar Ferdous", "authors": "Shahriar Ferdous, Christiana Chamon, Laszlo B. Kish", "title": "Comments on the \"Generalized\" KLJN Key Exchanger with Arbitrary\n  Resistors: Power, Impedance, Security", "comments": null, "journal-ref": "Fluctuation and Noise Letter 20 (2021) 2130002 , (open access)", "doi": "10.1142/S0219477521300020", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In (Nature) Science Report 5 (2015) 13653, Vadai, Mingesz and Gingl (VMG)\nintroduce a new Kirchhoff-law-Johnson-noise (KLJN) secure key exchanger that\noperates with 4 arbitrary resistors (instead of 2 arbitrary resistance values\nforming 2 identical resistor pairs in the original system). They state that in\nthis new, VMG-KLJN, non-equilibrium system with nonzero power flow, the\nsecurity during the exchange of the two (HL and LH) bit values is as strong as\nin the original KLJN scheme. Moreover, they claim that, at practical\nconditions, their VMG-KLJN protocol \"supports more robust protection against\nattacks\". First, we investigate the power flow and thermal equilibrium issues\nof the VMG-KLJN system with 4 arbitrary resistors. Then we introduce a new KLJN\nprotocol that allows the arbitrary choice of 3 resistors from the 4, while it\nstill operates with zero power flow during the exchange of single bits by\nutilizing a specific value of the 4th resistor and a binary temperature set for\nthe exchanged (HL and LH) bit values. Then we show that, in general, the KLJN\nschemes with more than 2 arbitrary resistors (including our new protocol\nmentioned above) are prone to 4 new passive attacks utilizing the parasitic\ncapacitance and inductance in the cable, while the original KLJN scheme is\nnaturally immune against these new attacks. The core of the security\nvulnerability exploited by these attacks is the different line resistances in\nthe HL and LH cases. Therefore, on the contrary of the statement and claim\ncited above, the practical VMG-KLJN system is less secure than the original\nKLJN scheme. We introduce another 2, modified, non-equilibrium KLJN systems to\neliminate the vulnerability against some - but not all - of these attacks.\nHowever the price for that is the loss of arbitrariness of the selection of the\n4th resistor and the information leak still remains greater than zero.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 22:03:18 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Ferdous", "Shahriar", ""], ["Chamon", "Christiana", ""], ["Kish", "Laszlo B.", ""]]}, {"id": "2010.04327", "submitter": "Keyu Zhu", "authors": "Keyu Zhu, Pascal Van Hentenryck, Ferdinando Fioretto", "title": "Bias and Variance of Post-processing in Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Post-processing immunity is a fundamental property of differential privacy:\nit enables the application of arbitrary data-independent transformations to the\nresults of differentially private outputs without affecting their privacy\nguarantees. When query outputs must satisfy domain constraints, post-processing\ncan be used to project the privacy-preserving outputs onto the feasible region.\nMoreover, when the feasible region is convex, a widely adopted class of\npost-processing steps is also guaranteed to improve accuracy. Post-processing\nhas been applied successfully in many applications including census\ndata-release, energy systems, and mobility. However, its effects on the noise\ndistribution is poorly understood: It is often argued that post-processing may\nintroduce bias and increase variance. This paper takes a first step towards\nunderstanding the properties of post-processing. It considers the release of\ncensus data and examines, both theoretically and empirically, the behavior of a\nwidely adopted class of post-processing functions.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 02:12:54 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Zhu", "Keyu", ""], ["Van Hentenryck", "Pascal", ""], ["Fioretto", "Ferdinando", ""]]}, {"id": "2010.04382", "submitter": "Perry Deng", "authors": "Perry Deng, Cooper Linsky, Matthew Wright", "title": "Weaponizing Unicodes with Deep Learning -- Identifying Homoglyphs with\n  Weakly Labeled Data", "comments": "Updated DOI", "journal-ref": null, "doi": "10.1109/ISI49825.2020.9280538", "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visually similar characters, or homoglyphs, can be used to perform social\nengineering attacks or to evade spam and plagiarism detectors. It is thus\nimportant to understand the capabilities of an attacker to identify homoglyphs\n-- particularly ones that have not been previously spotted -- and leverage them\nin attacks. We investigate a deep-learning model using embedding learning,\ntransfer learning, and augmentation to determine the visual similarity of\ncharacters and thereby identify potential homoglyphs. Our approach uniquely\ntakes advantage of weak labels that arise from the fact that most characters\nare not homoglyphs. Our model drastically outperforms the Normalized\nCompression Distance approach on pairwise homoglyph identification, for which\nwe achieve an average precision of 0.97. We also present the first attempt at\nclustering homoglyphs into sets of equivalence classes, which is more efficient\nthan pairwise information for security practitioners to quickly lookup\nhomoglyphs or to normalize confusable string encodings. To measure clustering\nperformance, we propose a metric (mBIOU) building on the classic\nIntersection-Over-Union (IOU) metric. Our clustering method achieves 0.592\nmBIOU, compared to 0.430 for the naive baseline. We also use our model to\npredict over 8,000 previously unknown homoglyphs, and find good early\nindications that many of these may be true positives. Source code and list of\npredicted homoglyphs are uploaded to Github:\nhttps://github.com/PerryXDeng/weaponizing_unicode\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 06:03:18 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 16:45:21 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2020 03:13:22 GMT"}, {"version": "v4", "created": "Tue, 22 Dec 2020 18:11:46 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Deng", "Perry", ""], ["Linsky", "Cooper", ""], ["Wright", "Matthew", ""]]}, {"id": "2010.04391", "submitter": "Fangyuan Zhao", "authors": "Fangyuan Zhao, Xuebin Ren, Shusen Yang, Qing Han, Peng Zhao, and Xinyu\n  Yang", "title": "Latent Dirichlet Allocation Model Training with Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent Dirichlet Allocation (LDA) is a popular topic modeling technique for\nhidden semantic discovery of text data and serves as a fundamental tool for\ntext analysis in various applications. However, the LDA model as well as the\ntraining process of LDA may expose the text information in the training data,\nthus bringing significant privacy concerns. To address the privacy issue in\nLDA, we systematically investigate the privacy protection of the main-stream\nLDA training algorithm based on Collapsed Gibbs Sampling (CGS) and propose\nseveral differentially private LDA algorithms for typical training scenarios.\nIn particular, we present the first theoretical analysis on the inherent\ndifferential privacy guarantee of CGS based LDA training and further propose a\ncentralized privacy-preserving algorithm (HDP-LDA) that can prevent data\ninference from the intermediate statistics in the CGS training. Also, we\npropose a locally private LDA training algorithm (LP-LDA) on crowdsourced data\nto provide local differential privacy for individual data contributors.\nFurthermore, we extend LP-LDA to an online version as OLP-LDA to achieve LDA\ntraining on locally private mini-batches in a streaming setting. Extensive\nanalysis and experiment results validate both the effectiveness and efficiency\nof our proposed privacy-preserving LDA training algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 06:58:40 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Zhao", "Fangyuan", ""], ["Ren", "Xuebin", ""], ["Yang", "Shusen", ""], ["Han", "Qing", ""], ["Zhao", "Peng", ""], ["Yang", "Xinyu", ""]]}, {"id": "2010.04607", "submitter": "Doriane Perard", "authors": "Doriane Perard, Xavier Goffin, J\\'er\\^ome Lacan", "title": "Using Homomorphic hashes in coded blockchains", "comments": "arXiv admin note: text overlap with arXiv:1805.00860", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the scalability issues of blockchains is the increase of their sizes\nwhich can prevent users from storing them and thus from contributing to the\ndecentralization effort. Recent works developed the concept of coded\nblockchains, which allow users to store only some coded fragments of the\nblockchains. However, this solution is not protected against malicious nodes\nthat can propagate erroneous coded fragments.\n  We propose in the paper to add homomorphic hashes to this system. This allows\nfor instantaneous detection of erroneous fragments and thus avoids decoding\nwith wrong data. We describe the integration of this mechanism in coded\nblockchains and we evaluate its complexity theoretically and by simulation.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 15:58:03 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Perard", "Doriane", ""], ["Goffin", "Xavier", ""], ["Lacan", "J\u00e9r\u00f4me", ""]]}, {"id": "2010.04840", "submitter": "Jiahao Chen", "authors": "Leo de Castro and Jiahao Chen and Antigoni Polychroniadou", "title": "CryptoCredit: Securely Training Fair Models", "comments": "8 pages", "journal-ref": "Proceedings of the 1st ACM International Conference on AI in\n  Finance (ICAIF '20), October 15-16, 2020, New York, NY, USA", "doi": "10.1145/3383455.3422567", "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When developing models for regulated decision making, sensitive features like\nage, race and gender cannot be used and must be obscured from model developers\nto prevent bias. However, the remaining features still need to be tested for\ncorrelation with sensitive features, which can only be done with the knowledge\nof those features. We resolve this dilemma using a fully homomorphic encryption\nscheme, allowing model developers to train linear regression and logistic\nregression models and test them for possible bias without ever revealing the\nsensitive features in the clear. We demonstrate how it can be applied to\nleave-one-out regression testing, and show using the adult income data set that\nour method is practical to run.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 23:05:37 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["de Castro", "Leo", ""], ["Chen", "Jiahao", ""], ["Polychroniadou", "Antigoni", ""]]}, {"id": "2010.04851", "submitter": "Yuqing Zhu", "authors": "Yuqing Zhu, Xiang Yu, Yi-Hsuan Tsai, Francesco Pittaluga, Masoud\n  Faraki, Manmohan chandraker and Yu-Xiang Wang", "title": "Voting-based Approaches For Differentially Private Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentially Private Federated Learning (DPFL) is an emerging field with\nmany applications. Gradient averaging based DPFL methods require costly\ncommunication rounds and hardly work with large-capacity models, due to the\nexplicit dimension dependence in its added noise. In this work, inspired by\nknowledge transfer non-federated privacy learning from Papernot et al.(2017;\n2018), we design two new DPFL schemes, by voting among the data labels returned\nfrom each local model, instead of averaging the gradients, which avoids the\ndimension dependence and significantly reduces the communication cost.\nTheoretically, by applying secure multi-party computation, we could\nexponentially amplify the (data-dependent) privacy guarantees when the margin\nof the voting scores are large. Extensive experiments show that our approaches\nsignificantly improve the privacy-utility trade-off over the state-of-the-arts\nin DPFL.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 23:55:19 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 00:34:52 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Zhu", "Yuqing", ""], ["Yu", "Xiang", ""], ["Tsai", "Yi-Hsuan", ""], ["Pittaluga", "Francesco", ""], ["Faraki", "Masoud", ""], ["chandraker", "Manmohan", ""], ["Wang", "Yu-Xiang", ""]]}, {"id": "2010.04902", "submitter": "Konstantinos Konstantinidis", "authors": "Konstantinos Konstantinidis, Aditya Ramamoorthy", "title": "ByzShield: An Efficient and Robust System for Distributed Training", "comments": "17 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training of large scale models on distributed clusters is a critical\ncomponent of the machine learning pipeline. However, this training can easily\nbe made to fail if some workers behave in an adversarial (Byzantine) fashion\nwhereby they return arbitrary results to the parameter server (PS). A plethora\nof existing papers consider a variety of attack models and propose robust\naggregation and/or computational redundancy to alleviate the effects of these\nattacks. In this work we consider an omniscient attack model where the\nadversary has full knowledge about the gradient computation assignments of the\nworkers and can choose to attack (up to) any q out of K worker nodes to induce\nmaximal damage. Our redundancy-based method ByzShield leverages the properties\nof bipartite expander graphs for the assignment of tasks to workers; this helps\nto effectively mitigate the effect of the Byzantine behavior. Specifically, we\ndemonstrate an upper bound on the worst case fraction of corrupted gradients\nbased on the eigenvalues of our constructions which are based on mutually\northogonal Latin squares and Ramanujan graphs. Our numerical experiments\nindicate over a 36% reduction on average in the fraction of corrupted gradients\ncompared to the state of the art. Likewise, our experiments on training\nfollowed by image classification on the CIFAR-10 dataset show that ByzShield\nhas on average a 20% advantage in accuracy under the most sophisticated\nattacks. ByzShield also tolerates a much larger fraction of adversarial nodes\ncompared to prior work.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 04:41:53 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 05:12:44 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Konstantinidis", "Konstantinos", ""], ["Ramamoorthy", "Aditya", ""]]}, {"id": "2010.04955", "submitter": "Chetan Kumar Kuraganti", "authors": "Chetan Kumar Kuraganti, Bryan Paul Robert, Gurunath Gurrala, Ashish\n  Joglekar, Arun Babu Puthuparambil, Rajesh Sundaresan and Himanshu Tyagi", "title": "A Distributed Hierarchy Framework for Enhancing Cyber Security of\n  Control Center Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent cyber-attacks on power grids highlight the necessity to protect the\ncritical functionalities of a control center vital for the safe operation of a\ngrid. Even in a distributed framework one central control center acts as a\ncoordinator in majority of the control center architectures. Such a control\ncenter can become a prime target for cyber as well as physical attacks, and,\nhence, a single point failure can lead to complete loss of visibility of the\npower grid. If the control center which runs the critical functions in a\ndistributed computing environment can be randomly chosen between the available\ncontrol centers in a secure framework, the ability of the attacker in causing a\nsingle point failure can be reduced to a great extent. To achieve this, a novel\ndistributed hierarchy based framework to secure critical functions is proposed\nin this paper. The proposed framework ensures that the data aggregation and the\ncritical functions are carried out at a random location, and incorporates\nsecurity features such as attestation and trust management to detect\ncompromised agents. A theoretical result is proved on the evolution and\nconvergence of the trust values in the proposed trust management protocol. It\nis also shown that the system is nominally robust so long as the number of\ncompromised nodes is strictly less than one-half of the nodes minus 1. For\ndemonstration, a Kalman filter-based state estimation using phasor measurements\nis used as the critical function to be secured. The proposed framework's\nimplementation feasibility is tested on a physical hardware cluster of\nParallella boards. The framework is also validated using simulations on the\nIEEE 118 bus system.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 09:25:42 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Kuraganti", "Chetan Kumar", ""], ["Robert", "Bryan Paul", ""], ["Gurrala", "Gurunath", ""], ["Joglekar", "Ashish", ""], ["Puthuparambil", "Arun Babu", ""], ["Sundaresan", "Rajesh", ""], ["Tyagi", "Himanshu", ""]]}, {"id": "2010.05144", "submitter": "Arash Shaghaghi", "authors": "Syed W. Shah, Naeem F. Syed, Arash Shaghaghi, Adnan Anwar, Zubair\n  Baig, Robin Doss", "title": "Towards a Lightweight Continuous Authentication Protocol for\n  Device-to-Device Communication", "comments": "This is a copy of the accepted version at The 19th IEEE International\n  Conference on Trust, Security and Privacy in Computing and Communications\n  (TrustCom 2020) [Core Rank: A]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous Authentication (CA) has been proposed as a potential solution to\ncounter complex cybersecurity attacks that exploit conventional static\nauthentication mechanisms that authenticate users only at an ingress point.\nHowever, widely researched human user characteristics-based CA mechanisms\ncannot be extended to continuously authenticate Internet of Things (IoT)\ndevices. The challenges are exacerbated with increased adoption of\ndevice-to-device (d2d) communication in critical infrastructures. Existing d2d\nauthentication protocols proposed in the literature are either prone to\nsubversion or are computationally infeasible to be deployed on constrained IoT\ndevices. In view of these challenges, we propose a novel, lightweight, and\nsecure CA protocol that leverages communication channel properties and a\ntunable mathematical function to generate dynamically changing session keys.\nOur preliminary informal protocol analysis suggests that the proposed protocol\nis resistant to known attack vectors and thus has strong potential for\ndeployment in securing critical and resource-constrained d2d communication.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 03:00:33 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Shah", "Syed W.", ""], ["Syed", "Naeem F.", ""], ["Shaghaghi", "Arash", ""], ["Anwar", "Adnan", ""], ["Baig", "Zubair", ""], ["Doss", "Robin", ""]]}, {"id": "2010.05156", "submitter": "Robert Ramirez", "authors": "Robert Ramirez, Nazli Choucri", "title": "Improving Interdisciplinary Communication With Standardized Cyber\n  Security Terminology: A Literature Review", "comments": "Accepted version of IEEE Access paper published under the Open Access\n  Publishing agreement", "journal-ref": "in IEEE Access, vol. 4, pp. 2216-2243, 2016", "doi": "10.1109/ACCESS.2016.2544381", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing demand for computer security and the cyberization trend are\nhallmarks of the 21st century. The rise in cyber-crime, digital currency,\ne-governance, and more, is well met by a corresponding recent jump in\ninvestment in new technology for securing computers around the globe. Recently,\nbusiness and government sectors have begun to focus efforts on comprehensive\ncyber security solutions. With this growth has emerged the need for greater\nmethods of collabo-ration and measurement of security. Despite all these\nefforts, this need has not been met, and there is still too little\ncross-disciplinary collaboration in the realm of computer security. This paper\nreviews the new trends in cyber security research, their contributions, and\nsome identifiable limitations. We argue that these limitations are due largely\nto the absence of co-operation required to address a problem that is clearly\nmultifaceted. We then identify a need for further standardization of\nterminology in computer security and propose guidelines for the global Internet\nmultistakeholder community to consider when crafting such standards. We also\nassess the viability of some specific terms, including whether cyber should be\nused as a separate word when it is a descriptor (e.g. cyber security or\ncybersecurity), and conclude with recommendations for writing future papers on\ncyber security or the broader new field of all things relating to cyberspace,\nwhich has recently been dubbed Cybermatics, a term we also examine and propose\nalternatives to, like Cyber or Cybernomics. By furthering the effort of\nstandardizing cyber security terminology, this paper lays groundwork for\ncross-disciplinary collaboration, agreement between technical and nontechnical\nstakeholders, and the drafting of universal Internet governance laws.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 04:06:16 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Ramirez", "Robert", ""], ["Choucri", "Nazli", ""]]}, {"id": "2010.05168", "submitter": "Yinghua Hu", "authors": "Yinghua Hu, Kaixin Yang, Shahin Nazarian, Pierluigi Nuzzo", "title": "SANSCrypt: A Sporadic-Authentication-Based Sequential Logic Encryption\n  Scheme", "comments": "This paper has been accepted at the 28th IFIP/IEEE International\n  Conference on Very Large Scale Integration (VLSI-SoC)", "journal-ref": null, "doi": "10.1109/VLSI-SOC46417.2020.9344079", "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose SANSCrypt, a novel sequential logic encryption scheme to protect\nintegrated circuits against reverse engineering. Previous sequential encryption\nmethods focus on modifying the circuit state machine such that the correct\nfunctionality can be accessed by applying the correct key sequence only once.\nConsidering the risk associated with one-time authentication, SANSCrypt adopts\na new temporal dimension to logic encryption, by requiring the user to\nsporadically perform multiple authentications according to a protocol based on\npseudo-random number generation. Analysis and validation results on a set of\nbenchmark circuits show that SANSCrypt offers a substantial output\ncorruptibility if the key sequences are applied incorrectly. Moreover, it\nexhibits an exponential resilience to existing attacks, including SAT-based\nattacks, while maintaining a reasonably low overhead.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 05:12:58 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Hu", "Yinghua", ""], ["Yang", "Kaixin", ""], ["Nazarian", "Shahin", ""], ["Nuzzo", "Pierluigi", ""]]}, {"id": "2010.05209", "submitter": "Abhishek Nair", "authors": "Abhishek Nair, Patanjali SLPSK, Chester Rebeiro, Swarup Bhunia", "title": "SIGNED: A Challenge-Response Based Interrogation Scheme for Simultaneous\n  Watermarking and Trojan Detection", "comments": "5 page version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of distributed manufacturing ecosystems for electronic hardware\ninvolving untrusted parties has given rise to diverse trust issues. In\nparticular, IP piracy, overproduction, and hardware Trojan attacks pose\nsignificant threats to digital design manufacturers. Watermarking has been one\nof the solutions employed by the semiconductor industry to overcome many of the\ntrust issues. However, current watermarking techniques have low coverage, incur\nhardware overheads, and are vulnerable to removal or tampering attacks.\nAdditionally, these watermarks cannot detect Trojan implantation attacks where\nan adversary alters a design for malicious purposes. We address these issues in\nour framework called SIGNED: Secure Lightweight Watermarking Scheme for Digital\nDesigns.\n  SIGNED relies on a challenge-response protocol based interrogation scheme for\ngenerating the watermark. SIGNED identifies sensitive regions in the target\nnetlist and samples them to form a compact signature that is representative of\nthe functional and structural characteristics of a design. We show that this\nsignature can be used to simultaneously verify, in a robust manner, the\nprovenance of a design, as well as any malicious alterations to it at any stage\nduring design process. We evaluate SIGNED on the ISCAS85 and ITC benchmark\ncircuits and obtain a detection accuracy of 87.61\\% even for modifications as\nlow as 5-gates. We further demonstrate that SIGNED can benefit from integration\nwith a logic locking solution, where it can achieve increased protection\nagainst removal/tempering attacks and incurs lower overhead through judicious\nreuse of the locking logic for watermark creation.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 10:13:10 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Nair", "Abhishek", ""], ["SLPSK", "Patanjali", ""], ["Rebeiro", "Chester", ""], ["Bhunia", "Swarup", ""]]}, {"id": "2010.05253", "submitter": "Teng Wang", "authors": "Teng Wang, Xuefeng Zhang, Jingyu Feng, Xinyu Yang", "title": "A Comprehensive Survey on Local Differential Privacy Toward Data\n  Statistics and Analysis", "comments": "28pages", "journal-ref": "Sensors 2020, 20(24), 7030", "doi": "10.3390/s20247030", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collecting and analyzing massive data generated from smart devices have\nbecome increasingly pervasive in crowdsensing, which are the building blocks\nfor data-driven decision-making. However, extensive statistics and analysis of\nsuch data will seriously threaten the privacy of participating users. Local\ndifferential privacy (LDP) has been proposed as an excellent and prevalent\nprivacy model with distributed architecture, which can provide strong privacy\nguarantees for each user while collecting and analyzing data. LDP ensures that\neach user's data is locally perturbed first in the client-side and then sent to\nthe server-side, thereby protecting data from privacy leaks on both the\nclient-side and server-side. This survey presents a comprehensive and\nsystematic overview of LDP with respect to privacy models, research tasks,\nenabling mechanisms, and various applications. Specifically, we first provide a\ntheoretical summarization of LDP, including the LDP model, the variants of LDP,\nand the basic framework of LDP algorithms. Then, we investigate and compare the\ndiverse LDP mechanisms for various data statistics and analysis tasks from the\nperspectives of frequency estimation, mean estimation, and machine learning.\nWhat's more, we also summarize practical LDP-based application scenarios.\nFinally, we outline several future research directions under LDP.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 14:33:43 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 06:08:57 GMT"}, {"version": "v3", "created": "Thu, 28 Jan 2021 14:46:54 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Wang", "Teng", ""], ["Zhang", "Xuefeng", ""], ["Feng", "Jingyu", ""], ["Yang", "Xinyu", ""]]}, {"id": "2010.05296", "submitter": "Duc-Phong Le", "authors": "Duc-Phong Le, Rongxing Lu, and Ali A. Ghorbani", "title": "Improved Fault Analysis on SIMECK Ciphers", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advances of the Internet of Things (IoT) have had a fundamental impact\nand influence in sharping our rich living experiences. However, since IoT\ndevices are usually resource-constrained, lightweight block ciphers have played\na major role in serving as a building block for secure IoT protocols. In CHES\n2015, SIMECK, a family of block ciphers, was designed for resource-constrained\nIoT devices. Since its publication, there have been many analyses on its\nsecurity. In this paper, under the one bit-flip model, we propose a new\nefficient fault analysis attack on SIMECK ciphers. Compared to those previously\nreported attacks, our attack can recover the full master key by injecting\nfaults into only a single round of all SIMECK family members. This property is\ncrucial, as it is infeasible for an attacker to inject faults into different\nrounds of a SIMECK implementation on IoT devices in the real world.\nSpecifically, our attack is characterized by exercising a deep analysis of\ndifferential trail between the correct and faulty immediate ciphertexts.\nExtensive simulation evaluations are conducted, and the results demonstrate the\neffectiveness and correctness of our proposed attack.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 17:43:08 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Le", "Duc-Phong", ""], ["Lu", "Rongxing", ""], ["Ghorbani", "Ali A.", ""]]}, {"id": "2010.05344", "submitter": "Christian Pilato", "authors": "Christian Pilato, Animesh Basak Chowdhury, Donatella Sciuto, Siddharth\n  Garg, Ramesh Karri", "title": "ASSURE: RTL Locking Against an Untrusted Foundry", "comments": "Accepted for publication in IEEE Transactions on VLSI Systems on\n  06-Apr-2021", "journal-ref": null, "doi": "10.1109/TVLSI.2021.3074004", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semiconductor design companies are integrating proprietary intellectual\nproperty (IP) blocks to build custom integrated circuits (IC) and fabricate\nthem in a third-party foundry. Unauthorized IC copies cost these companies\nbillions of dollars annually. While several methods have been proposed for\nhardware IP obfuscation, they operate on the gate-level netlist, i.e., after\nthe synthesis tools embed the semantic information into the netlist. We propose\nASSURE to protect hardware IP modules operating on the register-transfer level\n(RTL) description. The RTL approach has three advantages: (i) it allows\ndesigners to obfuscate IP cores generated with many different methods (e.g.,\nhardware generators, high-level synthesis tools, and pre-existing IPs). (ii) it\nobfuscates the semantics of an IC before logic synthesis; (iii) it does not\nrequire modifications to EDA flows. We perform a cost and security assessment\nof ASSURE.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 21:08:59 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 14:16:43 GMT"}, {"version": "v3", "created": "Sun, 18 Apr 2021 16:33:04 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Pilato", "Christian", ""], ["Chowdhury", "Animesh Basak", ""], ["Sciuto", "Donatella", ""], ["Garg", "Siddharth", ""], ["Karri", "Ramesh", ""]]}, {"id": "2010.05370", "submitter": "Kosuke Toda", "authors": "Kosuke Toda, Naomi Kuze, and Toshimitsu Ushio", "title": "Game-theoric approach to decision-making problem for blockchain mining", "comments": "7 pages, 6 figures an extended version of a manuscript accepted to\n  IEEE L-CSS", "journal-ref": null, "doi": "10.1109/LCSYS.2020.3043834", "report-no": null, "categories": "cs.GT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is an important decision-making problem for a miner in the blockchain\nnetworks if he/she participates in the mining so that he/she earns a reward by\ncreating a new block earlier than other miners. We formulate this\ndecision-making problem as a noncooperative game, because the probability of\ncreating a block depends not only on one's own available computational\nresources, but also those of other miners. Through theoretical and numerical\nanalyses, we show a hysteresis phenomenon of Nash equilibria depending on the\nreward and a jump phenomenon of miner decisions by a slight change in reward.\nWe also show that the reward for which miners decide not to participate in the\nmining becomes smaller as the number of miners increases.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 23:25:13 GMT"}, {"version": "v2", "created": "Sat, 12 Dec 2020 04:21:55 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Toda", "Kosuke", ""], ["Kuze", "Naomi", ""], ["Ushio", "Toshimitsu", ""]]}, {"id": "2010.05420", "submitter": "Khodakhast Bibak", "authors": "Khodakhast Bibak, Bruce M. Kapron, Venkatesh Srinivasan", "title": "MMH* with arbitrary modulus is always almost-universal", "comments": null, "journal-ref": "Information Processing Letters 116 (2016), 481-483", "doi": "10.1016/j.ipl.2016.03.009", "report-no": null, "categories": "cs.CR math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Universal hash functions, discovered by Carter and Wegman in 1979, are of\ngreat importance in computer science with many applications. MMH$^*$ is a\nwell-known $\\triangle$-universal hash function family, based on the evaluation\nof a dot product modulo a prime. In this paper, we introduce a generalization\nof MMH$^*$, that we call GMMH$^*$, using the same construction as MMH$^*$ but\nwith an arbitrary integer modulus $n>1$, and show that GMMH$^*$ is\n$\\frac{1}{p}$-almost-$\\triangle$-universal, where $p$ is the smallest prime\ndivisor of $n$. This bound is tight.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 02:57:04 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Bibak", "Khodakhast", ""], ["Kapron", "Bruce M.", ""], ["Srinivasan", "Venkatesh", ""]]}, {"id": "2010.05470", "submitter": "Simone Raponi", "authors": "Gabriele Oligeri, Simone Raponi, Savio Sciancalepore, Roberto Di\n  Pietro", "title": "PAST-AI: Physical-layer Authentication of Satellite Transmitters via\n  Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical-layer security is regaining traction in the research community, due\nto the performance boost introduced by deep learning classification algorithms.\nThis is particularly true for sender authentication in wireless communications\nvia radio fingerprinting. However, previous research efforts mainly focused on\nterrestrial wireless devices while, to the best of our knowledge, none of the\nprevious work took into consideration satellite transmitters. The satellite\nscenario is generally challenging because, among others, satellite radio\ntransducers feature non-standard electronics (usually aged and specifically\ndesigned for harsh conditions). Moreover, the fingerprinting task is\nspecifically difficult for Low-Earth Orbit (LEO) satellites (like the ones we\nfocus in this paper) since they orbit at about 800Km from the Earth, at a speed\nof around 25,000Km/h, thus making the receiver experiencing a down-link with\nunique attenuation and fading characteristics. In this paper, we propose\nPAST-AI, a methodology tailored to authenticate LEO satellites through\nfingerprinting of their IQ samples, using advanced AI solutions. Our\nmethodology is tested on real data -- more than 100M I/Q samples -- collected\nfrom an extensive measurements campaign on the IRIDIUM LEO satellites\nconstellation, lasting 589 hours. Results are striking: we prove that\nConvolutional Neural Networks (CNN) and autoencoders (if properly calibrated)\ncan be successfully adopted to authenticate the satellite transducers, with an\naccuracy spanning between 0.8 and 1, depending on prior assumptions. The\nproposed methodology, the achieved results, and the provided insights, other\nthan being interesting on their own, when associated to the dataset that we\nmade publicly available, will also pave the way for future research in the\narea.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 06:08:11 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Oligeri", "Gabriele", ""], ["Raponi", "Simone", ""], ["Sciancalepore", "Savio", ""], ["Di Pietro", "Roberto", ""]]}, {"id": "2010.05586", "submitter": "Iftach Haitner", "authors": "Iftach Haitner and Omer Reingold and Salil Vadhan and Hoeteck Wee", "title": "Inaccessible Entropy I: Inaccessible Entropy Generators and\n  Statistically Hiding Commitments from One-Way Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We put forth a new computational notion of entropy, measuring the\n(in)feasibility of sampling high-entropy strings that are consistent with a\ngiven generator. Specifically, the i'th output block of a generator G has\naccessible entropy at most k if the following holds: when conditioning on its\nprior coin tosses, no polynomial-time strategy $\\widetilde{G}$ can generate\nvalid output for G's i'th output block with entropy greater than k. A generator\nhas inaccessible entropy if the total accessible entropy (summed over the\nblocks) is noticeably smaller than the real entropy of G's output.\n  As an application of the above notion, we improve upon the result of Haitner,\nNguyen, Ong, Reingold, and Vadhan [Sicomp '09], presenting a much simpler and\nmore efficient construction of statistically hiding commitment schemes from\narbitrary one-way functions.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 10:23:05 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Haitner", "Iftach", ""], ["Reingold", "Omer", ""], ["Vadhan", "Salil", ""], ["Wee", "Hoeteck", ""]]}, {"id": "2010.05589", "submitter": "Nomvelo Sibisi", "authors": "Nomvelo Sibisi", "title": "Growth of Random Trees by Leaf Attachment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR math.PR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the growth of a time-ordered rooted tree by probabilistic attachment\nof new vertices to leaves. We construct a likelihood function of the leaves\nbased on the connectivity of the tree. We take such connectivity to be induced\nby the merging of directed ordered paths from leaves to the root. Combining the\nlikelihood with an assigned prior distribution leads to a posterior leaf\ndistribution from which we sample attachment points for new vertices. We\npresent computational examples of such Bayesian tree growth. Although the\ndiscussion is generic, the initial motivation for the paper is the concept of a\ndistributed ledger, which may be regarded as a time-ordered random tree that\ngrows by probabilistic leaf attachment.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 10:29:32 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 10:37:39 GMT"}, {"version": "v3", "created": "Sat, 31 Oct 2020 11:32:12 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Sibisi", "Nomvelo", ""]]}, {"id": "2010.05658", "submitter": "Luis Puche Rondon", "authors": "Luis Puche Rondon, Leonardo Babun, Ahmet Aris, Kemal Akkaya, and A.\n  Selcuk Uluagac", "title": "PoisonIvy: (In)secure Practices of Enterprise IoT Systems in Smart\n  Buildings", "comments": "10 pages, BuildSys 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of IoT devices has led to the proliferation of smart buildings,\noffices, and homes worldwide. Although commodity IoT devices are employed by\nordinary end-users, complex environments such as smart buildings, smart\noffices, conference rooms, or hospitality require customized and highly\nreliable solutions. Those systems called Enterprise Internet of Things (EIoT)\nconnect such environments to the Internet and are professionally managed\nsolutions usually offered by dedicated vendors. As EIoT systems require\nspecialized training, software, and equipment to deploy, this has led to very\nlittle research investigating the security of EIoT systems and their\ncomponents. In effect, EIoT systems in smart settings such as smart buildings\npresent an unprecedented and unexplored threat vector for an attacker. In this\nwork, we explore EIoT system vulnerabilities and insecure development\npractices. Specifically, focus on the usage of drivers as an attack mechanism,\nand introduce PoisonIvy, a number of novel attacks that demonstrate an attacker\ncan easily compromise EIoT system controllers using malicious drivers.\nSpecifically, we show how drivers used to integrate third-party devices to EIoT\nsystems can be misused in a systematic fashion. To demonstrate the capabilities\nof attackers, we implement and evaluate PoisonIvy using a testbed of real EIoT\ndevices. We show that an attacker can perform DoS attacks, gain remote control,\nand maliciously abuse system resources of EIoT systems. To the best of our\nknowledge, this is the first work to analyze the (in)securities of EIoT\ndeployment practices and demonstrate the associated vulnerabilities in this\necosystem. With this work, we raise awareness on the (in)secure development\npractices used for EIoT systems, the consequences of which can largely impact\nthe security, privacy, reliability, and performance of millions of EIoT systems\nworldwide.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 12:55:37 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Rondon", "Luis Puche", ""], ["Babun", "Leonardo", ""], ["Aris", "Ahmet", ""], ["Akkaya", "Kemal", ""], ["Uluagac", "A. Selcuk", ""]]}, {"id": "2010.05683", "submitter": "Shouhuai Xu", "authors": "Shouhuai Xu", "title": "Cybersecurity Dynamics: A Foundation for the Science of Cybersecurity", "comments": "31 pages. Chapter in Springer 2019 book entitled \"Proactive and\n  Dynamic Network Defense\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cybersecurity Dynamics is new concept that aims to achieve the modeling,\nanalysis, quantification, and management of cybersecurity from a holistic\nperspective, rather than from a building-blocks perspective. It is centered at\nmodeling and analyzing the attack-defense interactions in cyberspace, which\ncause a ``natural'' phenomenon -- the evolution of the global cybersecurity\nstate. In this Chapter, we systematically introduce and review the\nCybersecurity Dynamics foundation for the Science of Cybersecurity. We review\nthe core concepts, technical approaches, research axes, and results that have\nbeen obtained in this endeavor. We outline a research roadmap towards the\nultimate research goal, including a systematic set of technical barriers.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 04:09:43 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Xu", "Shouhuai", ""]]}, {"id": "2010.05692", "submitter": "Shouhuai Xu", "authors": "Shouhuai Xu", "title": "On the Security of Group Communication Schemes", "comments": "41 pages", "journal-ref": "Journal of Computer Security, 15(1): 129-169 (2007)", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secure group communications are a mechanism facilitating protected\ntransmission of messages from a sender to multiple receivers, and many emerging\napplications in both wired and wireless networks need the support of such a\nmechanism. There have been many secure group communication schemes in wired\nnetworks, which can be directly adopted in, or appropriately adapted to,\nwireless networks such as mobile ad hoc networks (MANETs) and sensor networks.\nIn this paper we show that the popular group communication schemes that we have\nexamined are vulnerable to the following attack: An outside adversary who\ncompromises a certain legitimate group member could obtain {\\em all} past and\npresent group keys (and thus all the messages protected by them); this is in\nsharp contrast to the widely-accepted belief that a such adversary can only\nobtain the present group key (and thus the messages protected by it). In order\nto understand and deal with the attack, we formalize two security models for\nstateful and stateless group communication schemes. We show that some practical\nmethods can make a {\\em subclass} of existing group communication schemes\nimmune to the attack.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 04:33:45 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Xu", "Shouhuai", ""]]}, {"id": "2010.05809", "submitter": "Nader Sehatbakhsh", "authors": "Nader Sehatbakhsh, Ellie Daw, Onur Savas, Amin Hassanzadeh, Ian\n  McCulloh", "title": "Security and Privacy Considerations for Machine Learning Models Deployed\n  in the Government and Public Sector (white paper)", "comments": "5 pages", "journal-ref": "Proceedings of the AAAI Conference on Artificial Intelligence,\n  Fall Symposium Series (AAAI-FSS); 2019", "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning becomes a more mainstream technology, the objective for\ngovernments and public sectors is to harness the power of machine learning to\nadvance their mission by revolutionizing public services. Motivational\ngovernment use cases require special considerations for implementation given\nthe significance of the services they provide. Not only will these applications\nbe deployed in a potentially hostile environment that necessitates protective\nmechanisms, but they are also subject to government transparency and\naccountability initiatives which further complicates such protections.\n  In this paper, we describe how the inevitable interactions between a user of\nunknown trustworthiness and the machine learning models, deployed in\ngovernments and public sectors, can jeopardize the system in two major ways: by\ncompromising the integrity or by violating the privacy. We then briefly\noverview the possible attacks and defense scenarios, and finally, propose\nrecommendations and guidelines that once considered can enhance the security\nand privacy of the provided services.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 16:05:29 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Sehatbakhsh", "Nader", ""], ["Daw", "Ellie", ""], ["Savas", "Onur", ""], ["Hassanzadeh", "Amin", ""], ["McCulloh", "Ian", ""]]}, {"id": "2010.05821", "submitter": "Yiming Li", "authors": "Yiming Li, Ziqi Zhang, Jiawang Bai, Baoyuan Wu, Yong Jiang, Shu-Tao\n  Xia", "title": "Open-sourced Dataset Protection via Backdoor Watermarking", "comments": "Accepted by the NeurIPS Workshop on Dataset Curation and Security,\n  2020. 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid development of deep learning has benefited from the release of some\nhigh-quality open-sourced datasets ($e.g.$, ImageNet), which allows researchers\nto easily verify the effectiveness of their algorithms. Almost all existing\nopen-sourced datasets require that they can only be adopted for academic or\neducational purposes rather than commercial purposes, whereas there is still no\ngood way to protect them. In this paper, we propose a \\emph{backdoor embedding\nbased dataset watermarking} method to protect an open-sourced\nimage-classification dataset by verifying whether it is used for training a\nthird-party model. Specifically, the proposed method contains two main\nprocesses, including \\emph{dataset watermarking} and \\emph{dataset\nverification}. We adopt classical poisoning-based backdoor attacks ($e.g.$,\nBadNets) for dataset watermarking, ie, generating some poisoned samples by\nadding a certain trigger ($e.g.$, a local patch) onto some benign samples,\nlabeled with a pre-defined target class. Based on the proposed backdoor-based\nwatermarking, we use a hypothesis test guided method for dataset verification\nbased on the posterior probability generated by the suspicious third-party\nmodel of the benign samples and their correspondingly watermarked samples\n($i.e.$, images with trigger) on the target class. Experiments on some\nbenchmark datasets are conducted, which verify the effectiveness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 16:16:27 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2020 08:32:27 GMT"}, {"version": "v3", "created": "Thu, 19 Nov 2020 04:51:13 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Li", "Yiming", ""], ["Zhang", "Ziqi", ""], ["Bai", "Jiawang", ""], ["Wu", "Baoyuan", ""], ["Jiang", "Yong", ""], ["Xia", "Shu-Tao", ""]]}, {"id": "2010.05867", "submitter": "David Byrd", "authors": "David Byrd and Antigoni Polychroniadou", "title": "Differentially Private Secure Multi-Party Computation for Federated\n  Learning in Financial Applications", "comments": "ACM ICAIF 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.MA q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning enables a population of clients, working with a trusted\nserver, to collaboratively learn a shared machine learning model while keeping\neach client's data within its own local systems. This reduces the risk of\nexposing sensitive data, but it is still possible to reverse engineer\ninformation about a client's private data set from communicated model\nparameters. Most federated learning systems therefore use differential privacy\nto introduce noise to the parameters. This adds uncertainty to any attempt to\nreveal private client data, but also reduces the accuracy of the shared model,\nlimiting the useful scale of privacy-preserving noise. A system can further\nreduce the coordinating server's ability to recover private client information,\nwithout additional accuracy loss, by also including secure multiparty\ncomputation. An approach combining both techniques is especially relevant to\nfinancial firms as it allows new possibilities for collaborative learning\nwithout exposing sensitive client data. This could produce more accurate models\nfor important tasks like optimal trade execution, credit origination, or fraud\ndetection. The key contributions of this paper are: We present a\nprivacy-preserving federated learning protocol to a non-specialist audience,\ndemonstrate it using logistic regression on a real-world credit card fraud data\nset, and evaluate it using an open-source simulation platform which we have\nadapted for the development of federated learning systems.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 17:16:27 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Byrd", "David", ""], ["Polychroniadou", "Antigoni", ""]]}, {"id": "2010.06053", "submitter": "Zhao Song", "authors": "Yangsibo Huang, Zhao Song, Danqi Chen, Kai Li, Sanjeev Arora", "title": "TextHide: Tackling Data Privacy in Language Understanding Tasks", "comments": "Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.DS cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  An unsolved challenge in distributed or federated learning is to effectively\nmitigate privacy risks without slowing down training or reducing accuracy. In\nthis paper, we propose TextHide aiming at addressing this challenge for natural\nlanguage understanding tasks. It requires all participants to add a simple\nencryption step to prevent an eavesdropping attacker from recovering private\ntext data. Such an encryption step is efficient and only affects the task\nperformance slightly. In addition, TextHide fits well with the popular\nframework of fine-tuning pre-trained language models (e.g., BERT) for any\nsentence or sentence-pair task. We evaluate TextHide on the GLUE benchmark, and\nour experiments show that TextHide can effectively defend attacks on shared\ngradients or representations and the averaged accuracy reduction is only\n$1.9\\%$. We also present an analysis of the security of TextHide using a\nconjecture about the computational intractability of a mathematical problem.\n  Our code is available at https://github.com/Hazelsuko07/TextHide\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 22:22:15 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Huang", "Yangsibo", ""], ["Song", "Zhao", ""], ["Chen", "Danqi", ""], ["Li", "Kai", ""], ["Arora", "Sanjeev", ""]]}, {"id": "2010.06131", "submitter": "He Zhao", "authors": "He Zhao, Trung Le, Paul Montague, Olivier De Vel, Tamas Abraham, Dinh\n  Phung", "title": "Towards Understanding Pixel Vulnerability under Adversarial Attacks for\n  Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep neural network image classifiers are reported to be susceptible to\nadversarial evasion attacks, which use carefully crafted images created to\nmislead a classifier. Recently, various kinds of adversarial attack methods\nhave been proposed, most of which focus on adding small perturbations to all of\nthe pixels of a real image. We find that a considerable amount of the\nperturbations on an image generated by some widely-used attacks may contribute\nlittle in attacking a classifier. However, they usually result in a more easily\ndetectable adversarial image by both humans and adversarial attack detection\nalgorithms. Therefore, it is important to impose the perturbations on the most\nvulnerable pixels of an image that can change the predictions of classifiers\nmore readily. With the pixel vulnerability, given an existing attack, we can\nmake its adversarial images more realistic and less detectable with fewer\nperturbations but keep its attack performance the same. Moreover, the\ndiscovered vulnerability assists to get a better understanding of the weakness\nof deep classifiers. Derived from the information-theoretic perspective, we\npropose a probabilistic approach for automatically finding the pixel\nvulnerability of an image, which is compatible with and improves over many\nexisting adversarial attacks.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 02:51:10 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Zhao", "He", ""], ["Le", "Trung", ""], ["Montague", "Paul", ""], ["De Vel", "Olivier", ""], ["Abraham", "Tamas", ""], ["Phung", "Dinh", ""]]}, {"id": "2010.06135", "submitter": "Lei Shi", "authors": "Lei Shi, Yahui Li, Rajeev Alur, Boon Thau Loo", "title": "Session-layer Attack Traffic Classification by Program Synthesis", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Writing classification rules to identify malicious network traffic is a\ntime-consuming and error-prone task. Learning-based classification systems\nautomatically extract such rules from positive and negative traffic examples.\nHowever, due to limitations in the representation of network traffic and the\nlearning strategy, these systems lack both expressiveness to cover a range of\nattacks and interpretability in fully describing the attack traffic's structure\nat the session layer. This paper presents Sharingan system, which uses program\nsynthesis techniques to generate network classification programs at the session\nlayer. Sharingan accepts raw network traces as inputs, and reports potential\npatterns of the attack traffic in NetQRE, a domain specific language designed\nfor specifying session-layer quantitative properties. Using Sharingan, network\noperators can better analyze the attack pattern due to the following advantages\nof Sharingan's learning process: (1) it requires minimal feature engineering,\n(2) it is amenable to efficient implementation of the learnt classifier, and\n(3) the synthesized program is easy to decipher and edit. We develop a range of\nnovel optimizations that reduce the synthesis time for large and complex tasks\nto a matter of minutes. Our experiments show that Sharingan is able to\ncorrectly identify attacks from a diverse set of network attack traces and\ngenerates explainable outputs, while achieving accuracy comparable to\nstate-of-the-art learning-based intrusion detection systems.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 03:07:08 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Shi", "Lei", ""], ["Li", "Yahui", ""], ["Alur", "Rajeev", ""], ["Loo", "Boon Thau", ""]]}, {"id": "2010.06139", "submitter": "Abu Naser", "authors": "Abu Naser, Mehran Sadeghi Lahijani, Cong Wu, Mohsen Gavahi, Viet Tung\n  Hoang, Zhi Wang, and Xin Yuan", "title": "Performance Evaluation and Modeling of Cryptographic Libraries for MPI\n  Communications", "comments": "Under review - IEEE Transactions on Dependable and Secure Computing\n  (TDSC). 12 figures, 11 tables, and 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order for High-Performance Computing (HPC) applications with data security\nrequirements to execute in the public cloud, the cloud infrastructure must\nensure the privacy and integrity of data. To meet this goal, we consider\nincorporating encryption in the Message Passing Interface (MPI) library. We\nempirically evaluate four contemporary cryptographic libraries, OpenSSL,\nBoringSSL, Libsodium, and CryptoPP using micro-benchmarks and NAS parallel\nbenchmarks on two different networking technologies, 10Gbps Ethernet and 40Gbps\nInfiniBand. We also develop accurate models that allow us to reason about the\nperformance of encrypted MPI communication in different situations and give\nguidance on how to improve encrypted MPI performance.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 03:28:20 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Naser", "Abu", ""], ["Lahijani", "Mehran Sadeghi", ""], ["Wu", "Cong", ""], ["Gavahi", "Mohsen", ""], ["Hoang", "Viet Tung", ""], ["Wang", "Zhi", ""], ["Yuan", "Xin", ""]]}, {"id": "2010.06154", "submitter": "Hongyang Zhang", "authors": "Maria-Florina Balcan and Avrim Blum and Dravyansh Sharma and Hongyang\n  Zhang", "title": "On the Power of Abstention and Data-Driven Decision Making for\n  Adversarial Robustness", "comments": "32 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formally define a feature-space attack where the adversary can perturb\ndatapoints by arbitrary amounts but in restricted directions. By restricting\nthe attack to a small random subspace, our model provides a clean abstraction\nfor non-Lipschitz networks which map small input movements to large feature\nmovements. We prove that classifiers with the ability to abstain are provably\nmore powerful than those that cannot in this setting. Specifically, we show\nthat no matter how well-behaved the natural data is, any classifier that cannot\nabstain will be defeated by such an adversary. However, by allowing abstention,\nwe give a parameterized algorithm with provably good performance against such\nan adversary when classes are reasonably well-separated in feature space and\nthe dimension of the feature space is high. We further use a data-driven method\nto set our algorithm parameters to optimize over the accuracy vs. abstention\ntrade-off with strong theoretical guarantees. Our theory has direct\napplications to the technique of contrastive learning, where we empirically\ndemonstrate the ability of our algorithms to obtain high robust accuracy with\nonly small amounts of abstention in both supervised and self-supervised\nsettings. Our results provide a first formal abstention-based gap, and a first\nprovable optimization for the induced trade-off in an adversarial defense\nsetting.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 03:56:39 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2020 04:19:49 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Balcan", "Maria-Florina", ""], ["Blum", "Avrim", ""], ["Sharma", "Dravyansh", ""], ["Zhang", "Hongyang", ""]]}, {"id": "2010.06177", "submitter": "Anwaar Ulhaq Dr", "authors": "Anwaar Ulhaq, Oliver Burmeister", "title": "COVID-19 Imaging Data Privacy by Federated Learning Design: A\n  Theoretical Framework", "comments": "2 images, 0 Table,8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To address COVID-19 healthcare challenges, we need frequent sharing of health\ndata, knowledge and resources at a global scale. However, in this digital age,\ndata privacy is a big concern that requires the secure embedding of privacy\nassurance into the design of all technological solutions that use health data.\nIn this paper, we introduce differential privacy by design (dPbD) framework and\ndiscuss its embedding into the federated machine learning system. To limit the\nscope of our paper, we focus on the problem scenario of COVID-19 imaging data\nprivacy for disease diagnosis by computer vision and deep learning approaches.\nWe discuss the evaluation of the proposed design of federated machine learning\nsystems and discuss how differential privacy by design (dPbD) framework can\nenhance data privacy in federated learning systems with scalability and\nrobustness. We argue that scalable differentially private federated learning\ndesign is a promising solution for building a secure, private and collaborative\nmachine learning model such as required to combat COVID19 challenge.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 04:34:30 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Ulhaq", "Anwaar", ""], ["Burmeister", "Oliver", ""]]}, {"id": "2010.06198", "submitter": "Warit Sirichotedumrong", "authors": "Warit Sirichotedumrong and Hitoshi Kiya", "title": "Visual Security Evaluation of Learnable Image Encryption Methods against\n  Ciphertext-only Attacks", "comments": "To be appeared in APSIPA ASC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various visual information protection methods have been proposed for\nprivacy-preserving deep neural networks (DNNs). In contrast, attack methods on\nsuch protection methods have been studied simultaneously. In this paper, we\nevaluate state-of-the-art visual protection methods for privacy-preserving DNNs\nin terms of visual security against ciphertext-only attacks (COAs). We focus on\nbrute-force attack, feature reconstruction attack (FR-Attack), inverse\ntransformation attack (ITN-Attack), and GAN-based attack (GAN-Attack), which\nhave been proposed to reconstruct visual information on plain images from the\nvisually-protected images. The detail of various attack is first summarized,\nand then visual security of the protection methods is evaluated. Experimental\nresults demonstrate that most of protection methods, including pixel-wise\nencryption, have not enough robustness against GAN-Attack, while a few\nprotection methods are robust enough against GAN-Attack.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 06:44:43 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Sirichotedumrong", "Warit", ""], ["Kiya", "Hitoshi", ""]]}, {"id": "2010.06212", "submitter": "Junming Ma", "authors": "Junming Ma, Chaofan Yu, Aihui Zhou, Bingzhe Wu, Xibin Wu, Xingyu Chen,\n  Xiangqun Chen, Lei Wang, Donggang Cao", "title": "S3ML: A Secure Serving System for Machine Learning Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present S3ML, a secure serving system for machine learning inference in\nthis paper. S3ML runs machine learning models in Intel SGX enclaves to protect\nusers' privacy. S3ML designs a secure key management service to construct\nflexible privacy-preserving server clusters and proposes novel SGX-aware load\nbalancing and scaling methods to satisfy users' Service-Level Objectives. We\nhave implemented S3ML based on Kubernetes as a low-overhead, high-available,\nand scalable system. We demonstrate the system performance and effectiveness of\nS3ML through extensive experiments on a series of widely-used models.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 07:41:13 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Ma", "Junming", ""], ["Yu", "Chaofan", ""], ["Zhou", "Aihui", ""], ["Wu", "Bingzhe", ""], ["Wu", "Xibin", ""], ["Chen", "Xingyu", ""], ["Chen", "Xiangqun", ""], ["Wang", "Lei", ""], ["Cao", "Donggang", ""]]}, {"id": "2010.06286", "submitter": "Suleiman Kharroub", "authors": "Ahmad M.N. Zaza, Suleiman K. Kharroub, Khalid Abualsaud", "title": "Lightweight IoT Malware Detection Solution Using CNN Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) is becoming more frequently used in more\napplications as the number of connected devices is in a rapid increase. More\nconnected devices result in bigger challenges in terms of scalability,\nmaintainability and most importantly security especially when it comes to 5G\nnetworks. The security aspect of IoT devices is an infant field, which is why\nit is our focus in this paper. Multiple IoT device manufacturers do not\nconsider securing the devices they produce for different reasons like cost\nreduction or to avoid using energy-harvesting components. Such potentially\nmalicious devices might be exploited by the adversary to do multiple harmful\nattacks. Therefore, we developed a system that can recognize malicious behavior\nof a specific IoT node on the network. Through convolutional neural network and\nmonitoring, we were able to provide malware detection for IoT using a central\nnode that can be installed within the network. The achievement shows how such\nmodels can be generalized and applied easily to any network while clearing out\nany stigma regarding deep learning techniques.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 10:56:33 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 15:05:45 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Zaza", "Ahmad M. N.", ""], ["Kharroub", "Suleiman K.", ""], ["Abualsaud", "Khalid", ""]]}, {"id": "2010.06371", "submitter": "Debjyoti Mukherjee", "authors": "Debjyoti Mukherjee, Alireza Ahmadi, Maryam Vahdat Pour, Joel Reardon", "title": "An Empirical Study on User Reviews Targeting Mobile Apps' Security &\n  Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Application markets provide a communication channel between app developers\nand their end-users in form of app reviews, which allow users to provide\nfeedback about the apps. Although security and privacy in mobile apps are one\nof the biggest issues, it is unclear how much people are aware of these or\ndiscuss them in reviews.\n  In this study, we explore the privacy and security concerns of users using\nreviews in the Google Play Store. For this, we conducted a study by analyzing\naround 2.2M reviews from the top 539 apps of this Android market. We found that\n0.5\\% of these reviews are related to the security and privacy concerns of the\nusers. We further investigated these apps by performing dynamic analysis which\nprovided us valuable insights into their actual behaviors. Based on the\ndifferent perspectives, we categorized the apps and evaluated how the different\nfactors influence the users' perception of the apps. It was evident from the\nresults that the number of permissions that the apps request plays a dominant\nrole in this matter. We also found that sending out the location can affect the\nusers' thoughts about the app. The other factors do not directly affect the\nprivacy and security concerns for the users.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 02:00:36 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Mukherjee", "Debjyoti", ""], ["Ahmadi", "Alireza", ""], ["Pour", "Maryam Vahdat", ""], ["Reardon", "Joel", ""]]}, {"id": "2010.06377", "submitter": "Martin Albrecht", "authors": "Martin R. Albrecht and Rikke Bjerg Jensen", "title": "The Vacuity of the Open Source Security Testing Methodology Manual", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Open Source Security Testing Methodology Manual (OSSTMM) provides a\n\"scientific methodology for the accurate characterization of operational\nsecurity\" [Her10, p.13]. It is extensively referenced in writings aimed at\nsecurity testing professionals such as textbooks, standards and academic\npapers. In this work we offer a fundamental critique of OSSTMM and argue that\nit fails to deliver on its promise of actual security. Our contribution is\nthreefold and builds on a textual critique of this methodology. First, OSSTMM's\ncentral principle is that security can be understood as a quantity of which an\nentity has more or less. We show why this is wrong and how OSSTMM's unified\nsecurity score, the rav, is an empty abstraction. Second, OSSTMM disregards\nrisk by replacing it with a trust metric which confuses multiple definitions of\ntrust and, as a result, produces a meaningless score. Finally, OSSTMM has been\nhailed for its attention to human security. Yet it understands all human agency\nas a security threat that needs to be constantly monitored and controlled.\nThus, we argue that OSSTMM is neither fit for purpose nor can it be salvaged,\nand it should be abandoned by security professionals.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 13:33:34 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Albrecht", "Martin R.", ""], ["Jensen", "Rikke Bjerg", ""]]}, {"id": "2010.06404", "submitter": "Nampoina Andriamilanto", "authors": "Nampoina Andriamilanto, Tristan Allard, Ga\\\"etan Le Guelvouit", "title": "FPSelect: Low-Cost Browser Fingerprints for Mitigating Dictionary\n  Attacks against Web Authentication Mechanisms", "comments": null, "journal-ref": null, "doi": "10.1145/3427228.3427297", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Browser fingerprinting consists into collecting attributes from a web\nbrowser. Hundreds of attributes have been discovered through the years. Each\none of them provides a way to distinguish browsers, but also comes with a\nusability cost (e.g., additional collection time). In this work, we propose\nFPSelect, an attribute selection framework allowing verifiers to tune their\nbrowser fingerprinting probes for web authentication. We formalize the problem\nas searching for the attribute set that satisfies a security requirement and\nminimizes the usability cost. The security is measured as the proportion of\nimpersonated users given a fingerprinting probe, a user population, and an\nattacker that knows the exact fingerprint distribution among the user\npopulation. The usability is quantified by the collection time of browser\nfingerprints, their size, and their instability. We compare our framework with\ncommon baselines, based on a real-life fingerprint dataset, and find out that\nin our experimental settings, our framework selects attribute sets of lower\nusability cost. Compared to the baselines, the attribute sets found by FPSelect\ngenerate fingerprints that are up to 97 times smaller, are collected up to\n3,361 times faster, and with up to 7.2 times less changing attributes between\ntwo observations, on average.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 14:02:17 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Andriamilanto", "Nampoina", ""], ["Allard", "Tristan", ""], ["Guelvouit", "Ga\u00ebtan Le", ""]]}, {"id": "2010.06457", "submitter": "Deevashwer Rathee", "authors": "Deevashwer Rathee, Mayank Rathee, Nishant Kumar, Nishanth Chandran,\n  Divya Gupta, Aseem Rastogi, Rahul Sharma", "title": "CrypTFlow2: Practical 2-Party Secure Inference", "comments": "To appear at ACM CCS 2020. Code available at:\n  https://github.com/mpc-msri/EzPC", "journal-ref": null, "doi": "10.1145/3372297.3417274", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present CrypTFlow2, a cryptographic framework for secure inference over\nrealistic Deep Neural Networks (DNNs) using secure 2-party computation.\nCrypTFlow2 protocols are both correct -- i.e., their outputs are bitwise\nequivalent to the cleartext execution -- and efficient -- they outperform the\nstate-of-the-art protocols in both latency and scale. At the core of\nCrypTFlow2, we have new 2PC protocols for secure comparison and division,\ndesigned carefully to balance round and communication complexity for secure\ninference tasks. Using CrypTFlow2, we present the first secure inference over\nImageNet-scale DNNs like ResNet50 and DenseNet121. These DNNs are at least an\norder of magnitude larger than those considered in the prior work of 2-party\nDNN inference. Even on the benchmarks considered by prior work, CrypTFlow2\nrequires an order of magnitude less communication and 20x-30x less time than\nthe state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 15:12:28 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Rathee", "Deevashwer", ""], ["Rathee", "Mayank", ""], ["Kumar", "Nishant", ""], ["Chandran", "Nishanth", ""], ["Gupta", "Divya", ""], ["Rastogi", "Aseem", ""], ["Sharma", "Rahul", ""]]}, {"id": "2010.06471", "submitter": "Abu Naser", "authors": "Abu Naser, Cong Wu, Mehran Sadeghi Lahijani, Mohsen Gavahi, Viet Tung\n  Hoang, Zhi Wang, and Xin Yuan", "title": "CryptMPI: A Fast Encrypted MPI Library", "comments": "Updated system description, format changed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cloud infrastructure must provide security for High-Performance Computing\n(HPC) applications of sensitive data to execute in such an environment.\nHowever, supporting security in the communication infrastructure of today's\npublic cloud is challenging, because current networks for data centers are so\nfast that adding encryption can incur very significant overheads. In this work,\nwe introduce CryptMPI, a high performance encrypted MPI library that supports\ncommunication with both integrity and privacy. We present the techniques in\nCryptMPI and report our benchmarking results using micro-benchmarks and NAS\nparallel benchmarks. The evaluation results indicate that the aforementioned\ntechniques are effective in improving the performance of encrypted\ncommunication.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 15:23:20 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 23:04:58 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Naser", "Abu", ""], ["Wu", "Cong", ""], ["Lahijani", "Mehran Sadeghi", ""], ["Gavahi", "Mohsen", ""], ["Hoang", "Viet Tung", ""], ["Wang", "Zhi", ""], ["Yuan", "Xin", ""]]}, {"id": "2010.06571", "submitter": "Amelia Holcomb", "authors": "Amelia Holcomb, Geovandro C. C. F. Pereira, Bhargav Das, Michele Mosca", "title": "PQFabric: A Permissioned Blockchain Secure from Both Classical and\n  Quantum Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperledger Fabric is a prominent and flexible solution for building\npermissioned distributed ledger platforms. Access control and identity\nmanagement relies on a Membership Service Provider (MSP) whose cryptographic\ninterface only handles standard PKI methods for authentication: RSA and ECDSA\nclassical signatures. Also, MSP-issued credentials may use only one signature\nscheme, tying the credential-related functions to classical single-signature\nprimitives. RSA and ECDSA are vulnerable to quantum attacks, with an ongoing\npost-quantum standardization process to identify quantum-safe drop-in\nreplacements. In this paper, we propose a redesign of Fabric's\ncredential-management procedures and related specifications in order to\nincorporate hybrid digital signatures, protecting against both classical and\nquantum attacks using one classical and one quantum-safe signature. We create\nPQFabric, an implementation of Fabric with hybrid signatures that integrates\nwith the Open Quantum Safe (OQS) library. Our implementation offers complete\ncrypto-agility, with the ability to perform live migration to a hybrid\nquantum-safe blockchain and select any existing OQS signature algorithm for\neach node. We perform comparative benchmarks of PQFabric with each of the NIST\ncandidates and alternates, revealing that long public keys and signatures lead\nto an increase in hashing time that is sometimes comparable to the time spent\nsigning or verifying messages itself. This is a new and potentially significant\nissue in the migration of blockchains to post-quantum signatures.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 17:45:08 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 17:49:38 GMT"}, {"version": "v3", "created": "Wed, 23 Dec 2020 16:19:12 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Holcomb", "Amelia", ""], ["Pereira", "Geovandro C. C. F.", ""], ["Das", "Bhargav", ""], ["Mosca", "Michele", ""]]}, {"id": "2010.06613", "submitter": "Paul Staat", "authors": "Paul Staat, Harald Elders-Boll, Markus Heinrichs, Rainer Kronberger,\n  Christian Zenger, Christof Paar", "title": "Intelligent Reflecting Surface-Assisted Wireless Key Generation for\n  Low-Entropy Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical layer key generation is a promising candidate for cryptographic key\nestablishment between two wireless communication parties. It offers\ninformation-theoretic security and is an attractive alternative to public-key\ntechniques. Here, the inherent randomness of wireless radio channels is used as\na shared entropy source to generate cryptographic key material. However,\npractical implementations often suffer from static channel conditions which\nexhibit a limited amount of randomness. In the past, considerable research\nefforts have been made to address this fundamental limitation. However, current\nsolutions are not generic or require dedicated hardware extensions such as\nreconfigurable antennas. In this paper, we propose a novel wireless key\ngeneration architecture based on randomized channel responses from an\nintelligent reflecting surface (IRS). Due to its passive nature, a cooperative\nIRS is well-suited to provide randomness for conventional resource-constrained\nradios. We conduct the first practical studies to successfully demonstrate\nIRS-based physical-layer key generation with an OFDM system. In a static\nenvironment, using a single subcarrier only, our IRS-assisted prototype system\nachieves a key generation rate (KGR) of 97.39 bps with 6.5% key disagreement\nrate (KDR) after quantization, while passing standard randomness tests.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 18:06:33 GMT"}, {"version": "v2", "created": "Sat, 6 Mar 2021 18:36:12 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Staat", "Paul", ""], ["Elders-Boll", "Harald", ""], ["Heinrichs", "Markus", ""], ["Kronberger", "Rainer", ""], ["Zenger", "Christian", ""], ["Paar", "Christof", ""]]}, {"id": "2010.06667", "submitter": "Vinith Suriyakumar", "authors": "Vinith M. Suriyakumar, Nicolas Papernot, Anna Goldenberg, Marzyeh\n  Ghassemi", "title": "Chasing Your Long Tails: Differentially Private Prediction in Health\n  Care Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models in health care are often deployed in settings where\nit is important to protect patient privacy. In such settings, methods for\ndifferentially private (DP) learning provide a general-purpose approach to\nlearn models with privacy guarantees. Modern methods for DP learning ensure\nprivacy through mechanisms that censor information judged as too unique. The\nresulting privacy-preserving models, therefore, neglect information from the\ntails of a data distribution, resulting in a loss of accuracy that can\ndisproportionately affect small groups. In this paper, we study the effects of\nDP learning in health care. We use state-of-the-art methods for DP learning to\ntrain privacy-preserving models in clinical prediction tasks, including x-ray\nclassification of images and mortality prediction in time series data. We use\nthese models to perform a comprehensive empirical investigation of the\ntradeoffs between privacy, utility, robustness to dataset shift, and fairness.\nOur results highlight lesser-known limitations of methods for DP learning in\nhealth care, models that exhibit steep tradeoffs between privacy and utility,\nand models whose predictions are disproportionately influenced by large\ndemographic groups in the training data. We discuss the costs and benefits of\ndifferentially private learning in health care.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 19:56:37 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Suriyakumar", "Vinith M.", ""], ["Papernot", "Nicolas", ""], ["Goldenberg", "Anna", ""], ["Ghassemi", "Marzyeh", ""]]}, {"id": "2010.06709", "submitter": "Xingyu Zhou", "authors": "Xingyu Zhou and Jian Tan", "title": "Local Differential Privacy for Bayesian Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivated by the increasing concern about privacy in nowadays data-intensive\nonline learning systems, we consider a black-box optimization in the\nnonparametric Gaussian process setting with local differential privacy (LDP)\nguarantee. Specifically, the rewards from each user are further corrupted to\nprotect privacy and the learner only has access to the corrupted rewards to\nminimize the regret. We first derive the regret lower bounds for any LDP\nmechanism and any learning algorithm. Then, we present three almost optimal\nalgorithms based on the GP-UCB framework and Laplace DP mechanism. In this\nprocess, we also propose a new Bayesian optimization (BO) method (called\nMoMA-GP-UCB) based on median-of-means techniques and kernel approximations,\nwhich complements previous BO algorithms for heavy-tailed payoffs with a\nreduced complexity. Further, empirical comparisons of different algorithms on\nboth synthetic and real-world datasets highlight the superior performance of\nMoMA-GP-UCB in both private and non-private scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 21:50:09 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Zhou", "Xingyu", ""], ["Tan", "Jian", ""]]}, {"id": "2010.06712", "submitter": "Emma Dauterman", "authors": "Emma Dauterman, Henry Corrigan-Gibbs, David Mazi\\`eres", "title": "SafetyPin: Encrypted Backups with Human-Memorable Secrets", "comments": "This is an extended version of a paper published at OSDI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the design and implementation of SafetyPin, a system for encrypted\nmobile-device backups. Like existing cloud-based mobile-backup systems,\nincluding those of Apple and Google, SafetyPin requires users to remember only\na short PIN and defends against brute-force PIN-guessing attacks using hardware\nsecurity protections. Unlike today's systems, SafetyPin splits trust over a\ncluster of hardware security modules (HSMs) in order to provide security\nguarantees that scale with the number of HSMs. In this way, SafetyPin protects\nbacked-up user data even against an attacker that can adaptively compromise\nmany of the system's constituent HSMs. SafetyPin provides this protection\nwithout sacrificing scalability or fault tolerance. Decentralizing trust while\nrespecting the resource limits of today's HSMs requires a synthesis of\nsystems-design principles and cryptographic tools. We evaluate SafetyPin on a\ncluster of 100 low-cost HSMs and show that a SafetyPin-protected recovery takes\n1.01 seconds. To process 1B recoveries a year, we estimate that a SafetyPin\ndeployment would need 3,100 low-cost HSMs.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 21:55:38 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 17:36:04 GMT"}, {"version": "v3", "created": "Mon, 8 Mar 2021 23:33:39 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Dauterman", "Emma", ""], ["Corrigan-Gibbs", "Henry", ""], ["Mazi\u00e8res", "David", ""]]}, {"id": "2010.06785", "submitter": "Peiyao Sheng", "authors": "Peiyao Sheng, Gerui Wang, Kartik Nayak, Sreeram Kannan, Pramod\n  Viswanath", "title": "BFT Protocol Forensics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Byzantine fault-tolerant (BFT) protocols allow a group of replicas to come to\na consensus even when some of the replicas are Byzantine faulty. There exist\nmultiple BFT protocols to securely tolerate an optimal number of faults $t$\nunder different network settings. However, if the number of faults $f$ exceeds\n$t$ then security could be violated. In this paper we mathematically formalize\nthe study of forensic support of BFT protocols: we aim to identify (with\ncryptographic integrity) as many of the malicious replicas as possible and in\nas a distributed manner as possible. Our main result is that forensic support\nof BFT protocols depends heavily on minor implementation details that do not\naffect the protocol's security or complexity. Focusing on popular BFT protocols\n(PBFT, HotStuff, Algorand) we exactly characterize their forensic support,\nshowing that there exist minor variants of each protocol for which the forensic\nsupports vary widely. We show strong forensic support capability of LibraBFT,\nthe consensus protocol of Diem cryptocurrency; our lightweight forensic module\nimplemented on a Diem client is open-sourced and is under active consideration\nfor deployment in Diem. Finally, we show that all secure BFT protocols designed\nfor $2t+1$ replicas communicating over a synchronous network forensic support\nare inherently nonexistent; this impossibility result holds for all BFT\nprotocols and even if one has access to the states of all replicas (including\nByzantine ones).\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 02:55:11 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 01:30:23 GMT"}, {"version": "v3", "created": "Thu, 21 Jan 2021 22:44:04 GMT"}, {"version": "v4", "created": "Mon, 25 Jan 2021 02:54:10 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Sheng", "Peiyao", ""], ["Wang", "Gerui", ""], ["Nayak", "Kartik", ""], ["Kannan", "Sreeram", ""], ["Viswanath", "Pramod", ""]]}, {"id": "2010.06812", "submitter": "Mahmoud Hossam", "authors": "Mahmoud Hossam, Trung Le, He Zhao, and Dinh Phung", "title": "Explain2Attack: Text Adversarial Attacks via Cross-Domain\n  Interpretability", "comments": "Preprint for accepted paper at 25th International Conference on\n  Pattern Recognition (ICPR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training robust deep learning models for down-stream tasks is a critical\nchallenge. Research has shown that down-stream models can be easily fooled with\nadversarial inputs that look like the training data, but slightly perturbed, in\na way imperceptible to humans. Understanding the behavior of natural language\nmodels under these attacks is crucial to better defend these models against\nsuch attacks. In the black-box attack setting, where no access to model\nparameters is available, the attacker can only query the output information\nfrom the targeted model to craft a successful attack. Current black-box\nstate-of-the-art models are costly in both computational complexity and number\nof queries needed to craft successful adversarial examples. For real world\nscenarios, the number of queries is critical, where less queries are desired to\navoid suspicion towards an attacking agent. In this paper, we propose\nExplain2Attack, a black-box adversarial attack on text classification task.\nInstead of searching for important words to be perturbed by querying the target\nmodel, Explain2Attack employs an interpretable substitute model from a similar\ndomain to learn word importance scores. We show that our framework either\nachieves or out-performs attack rates of the state-of-the-art models, yet with\nlower queries cost and higher efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 04:56:41 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 08:48:37 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 04:10:17 GMT"}, {"version": "v4", "created": "Sat, 16 Jan 2021 09:08:01 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Hossam", "Mahmoud", ""], ["Le", "Trung", ""], ["Zhao", "He", ""], ["Phung", "Dinh", ""]]}, {"id": "2010.06834", "submitter": "Diksha Gupta", "authors": "Diksha Gupta, Jared Saia and Maxwell Young", "title": "Bankrupting Sybil Despite Churn", "comments": "41 pages, 6 figures. arXiv admin note: text overlap with\n  arXiv:2006.02893, arXiv:1911.06462", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Sybil attack occurs when an adversary pretends to be multiple identities\n(IDs). Limiting the number of Sybil (bad) IDs to a minority permits the use of\nwell-established tools for tolerating malicious behavior, such as protocols for\nByzantine consensus and secure multiparty computation. A popular technique for\nenforcing this minority is resource burning; that is, the verifiable\nconsumption of a network resource, such as computational power, bandwidth, or\nmemory.\n  Unfortunately, prior defenses require non-Sybil (good) IDs to consume at\nleast as many resources as the adversary, unless the rate of churn for good IDs\nis sufficiently low. Since many systems exhibit high churn, this is a\nsignificant barrier to deployment.\n  We present two algorithms that offer useful guarantees against Sybil\nadversary under a broadly-applicable model of churn. The first is GoodJEst,\nwhich estimates the number of good IDs that join the system over any window of\ntime, despite the adversary injecting bad IDs. GoodJEst applies to a broad\nrange of system settings, and we demonstrate its use in our second algorithm, a\nnew Sybil defense called ERGO. Even under high churn, ERGO guarantee (1) there\nis always a minority of bad IDs in the system; and (2) when the system is under\nattack, the good IDs burn resources at a total rate that is sublinear in the\nadversary's consumption.\n  To evaluate the impact of our theoretical results, we investigate the\nperformance of ERGO alongside prior defenses that employ resource burning.\nBased on our experiments, we design heuristics that further improve the\nperformance of ERGO by up to four orders of magnitude over these previous Sybil\ndefenses.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 23:38:50 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 19:35:27 GMT"}, {"version": "v3", "created": "Mon, 25 Jan 2021 16:09:08 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Gupta", "Diksha", ""], ["Saia", "Jared", ""], ["Young", "Maxwell", ""]]}, {"id": "2010.06850", "submitter": "Hanan Hindy", "authors": "Elochukwu Ukwandu, Mohamed Amine Ben Farah, Hanan Hindy, David\n  Brosset, Dimitris Kavallieros, Robert Atkinson, Christos Tachtatzis, Miroslav\n  Bures, Ivan Andonovic and Xavier Bellekens", "title": "A Review of Cyber-Ranges and Test-Beds: Current and Future Trends", "comments": "43 pages, 18 Figures, 8 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber situational awareness has been proven to be of value in forming a\ncomprehensive understanding of threats and vulnerabilities within\norganisations, as the degree of exposure is governed by the prevailing levels\nof cyber-hygiene and established processes. A more accurate assessment of the\nsecurity provision informs on the most vulnerable environments that necessitate\nmore diligent management. The rapid proliferation in the automation of\ncyber-attacks is reducing the gap between information and operational\ntechnologies and the need to review the current levels of robustness against\nnew sophisticated cyber-attacks, trends, technologies and mitigation\ncountermeasures has become pressing. A deeper characterisation is also the\nbasis with which to predict future vulnerabilities in turn guiding the most\nappropriate deployment technologies. Thus, refreshing established practices and\nthe scope of the training to support the decision making of users and\noperators. The foundation of the training provision is the use of Cyber-Ranges\n(CRs) and Test-Beds (TBs), platforms/tools that help inculcate a deeper\nunderstanding of the evolution of an attack and the methodology to deploy the\nmost impactful countermeasures to arrest breaches. In this paper, an evaluation\nof documented CR and TB platforms is evaluated. CRs and TBs are segmented by\ntype, technology, threat scenarios, applications and the scope of attainable\ntraining. To enrich the analysis of documented CR and TB research and cap the\nstudy, a taxonomy is developed to provide a broader comprehension of the future\nof CRs and TBs. The taxonomy elaborates on the CRs/TBs different dimensions, as\nwell as, highlighting a diminishing differentiation between application areas.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 07:25:17 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Ukwandu", "Elochukwu", ""], ["Farah", "Mohamed Amine Ben", ""], ["Hindy", "Hanan", ""], ["Brosset", "David", ""], ["Kavallieros", "Dimitris", ""], ["Atkinson", "Robert", ""], ["Tachtatzis", "Christos", ""], ["Bures", "Miroslav", ""], ["Andonovic", "Ivan", ""], ["Bellekens", "Xavier", ""]]}, {"id": "2010.06855", "submitter": "Hui Liu", "authors": "Hui Liu, Bo Zhao, Jiabao Guo, Yang An, Peng Liu", "title": "GreedyFool: Multi-Factor Imperceptibility and Its Application to\n  Designing Black-box Adversarial Example Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are inherently vulnerable to well-designed input\nsamples called adversarial examples. The adversary can easily fool DNNs by\nadding slight perturbations to the input. In this paper, we propose a novel\nblack-box adversarial example attack named GreedyFool, which synthesizes\nadversarial examples based on the differential evolution and the greedy\napproximation. The differential evolution is utilized to evaluate the effects\nof perturbed pixels on the confidence of the DNNs-based classifier. The greedy\napproximation is an approximate optimization algorithm to automatically get\nadversarial perturbations. Existing works synthesize the adversarial examples\nby leveraging simple metrics to penalize the perturbations, which lack\nsufficient consideration of the human visual system (HVS), resulting in\nnoticeable artifacts. In order to sufficient imperceptibility, we launch a lot\nof investigations into the HVS and design an integrated metric considering just\nnoticeable distortion (JND), Weber-Fechner law, texture masking and channel\nmodulation, which is proven to be a better metric to measure the perceptual\ndistance between the benign examples and the adversarial ones. The experimental\nresults demonstrate that the GreedyFool has several remarkable properties\nincluding black-box, 100% success rate, flexibility, automation and can\nsynthesize the more imperceptible adversarial examples than the\nstate-of-the-art pixel-wise methods.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 07:45:06 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 16:29:44 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2020 08:40:32 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Liu", "Hui", ""], ["Zhao", "Bo", ""], ["Guo", "Jiabao", ""], ["An", "Yang", ""], ["Liu", "Peng", ""]]}, {"id": "2010.06911", "submitter": "Chia-Wei Tsai", "authors": "Chia-Wei Tsai, Zong-Liang Zhang, Bo-Cheng Jian, Yao-Chung Chang", "title": "Lightweight Mediated Semi-Quantum Secret Sharing Protocol", "comments": "We proposes a improved protocol in this concept, so that we hope to\n  replace this paper by the new manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the exiting semi-quantum secret sharing protocol have two challenges\nincluding (1) the dealer must be the quantum user, and (2) the classical users\nmust equip with the Trojan Horse detectors, this study wants to propose a novel\nmediate semi-quantum secret sharing (MSQSS) protocol to let a classical dealer\ncan share his/her secrets to the classical agents with the help of a dishonest\nthird-party (TP). The proposed MSQSS protocol adopts the one-way quantum\ncommunication and thus it is free from the Trojan Horse attacks. Furthermore,\nthe security analysis is given for proving that the proposed protocol can be\nagainst the collective attack. Comparing to the exiting SQSS protocols, the\nproposed MSQSS protocol is more lightweight and more practical.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 09:50:32 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 02:14:09 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Tsai", "Chia-Wei", ""], ["Zhang", "Zong-Liang", ""], ["Jian", "Bo-Cheng", ""], ["Chang", "Yao-Chung", ""]]}, {"id": "2010.07013", "submitter": "Carlos Molina-Jimenez", "authors": "Carlos Molina-Jimenez and Hazem Danny Al Nakib and Linmao Song and\n  Ioannis Sfyrakis and Jon Crowcroft", "title": "A Case for a Currencyless Economy Based on Bartering with Smart\n  Contracts", "comments": "The document consists of 22 pages in total, including references and\n  two figures. The author list has five authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We suggest the re-introduction of bartering to create a cryptocurrencyless,\ncurrencyless, and moneyless economy segment. We contend that a barter economy\nwould benefit enterprises, individuals, governments and societies. For\ninstance, the availability of an online peer-to-peer barter marketplace would\nconvert ordinary individuals into potential traders of both tangible and\ndigital items and services. For example, they will be able to barter files and\ndata that they collect. Equally motivating, they will be able to barter and\nre-introduce to the economy items that they no longer need such as, books,\ngarden tools, and bikes which are normally kept and wasted in garages and\nsheds. We argue that most of the pieces of technology needed for building a\nbarter system are now available, including blockchains, smart contracts,\ncryptography, secure multiparty computations and fair exchange protocols.\nHowever, additional research is needed to refine and integrate the pieces\ntogether. We discuss potential research directions.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 22:02:38 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Molina-Jimenez", "Carlos", ""], ["Nakib", "Hazem Danny Al", ""], ["Song", "Linmao", ""], ["Sfyrakis", "Ioannis", ""], ["Crowcroft", "Jon", ""]]}, {"id": "2010.07016", "submitter": "Hamza Ahmad Madni Dr.", "authors": "Zain Mumtaz, Zeeshan Ilyas, Ahmed Sohaib, Saleem Ullah, Hamza Ahmad\n  Madni", "title": "Design and Implementation of User-Friendly and Low-Cost\n  Multiple-Application System for Smart City Using Microcontrollers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Our proposed system has seven main contributions, i.e., Smart street lights,\nSmart home, Bio-metric door and home security system, Intelligent traffic\nlights management and road security system, Private and smart parking,\nIntelligent accident management system and Smart information display/ notice\nboard system. Our prototypes / products employ Arduino UNO board, Node MCU,\nUltrasonic sensor, Fingerprint module, Servo motors, GSM, GPS, LEDs, Flame\nSensor, Bluetooth and Wi-Fi module etc. We are very confident that our proposed\nsystems are efficient, reliable, and cost-effective and can be easily tested\nand implemented on a large scale under real conditions.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 07:39:43 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Mumtaz", "Zain", ""], ["Ilyas", "Zeeshan", ""], ["Sohaib", "Ahmed", ""], ["Ullah", "Saleem", ""], ["Madni", "Hamza Ahmad", ""]]}, {"id": "2010.07041", "submitter": "Leandros Maglaras A", "authors": "Maria Papathanasaki, Georgios Dimitriou, Leandros Maglaras, Ismini\n  Vasileiou, Helge Janicke", "title": "From Cyber Terrorism to Cyber Peacekeeping: Are we there yet?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Cyberspace nowadays, there is a burst of information that everyone has\naccess. However, apart from the advantages the Internet offers, it also hides\nnumerous dangers for both people and nations. Cyberspace has a dark side,\nincluding terrorism, bullying, and other types of violence. Cyberwarfare is a\nkind of virtual war that causes the same destruction that a physical war would\nalso do. In this article, we discuss what Cyberterrorism is and how it can lead\nto Cyberwarfare.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 19:55:40 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Papathanasaki", "Maria", ""], ["Dimitriou", "Georgios", ""], ["Maglaras", "Leandros", ""], ["Vasileiou", "Ismini", ""], ["Janicke", "Helge", ""]]}, {"id": "2010.07057", "submitter": "Alisa Pankova", "authors": "Joosep J\\\"a\\\"ager and Alisa Pankova", "title": "PrivaLog: a privacy-aware logic programming language", "comments": "41 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logic Programming (LP) is a subcategory of declarative programming that is\nconsidered to be relatively simple for non-programmers. LP developers focus on\ndescribing facts and rules of a logical derivation, and do not need to think\nabout the algorithms actually implementing the derivation.\n  Secure multiparty computation (MPC) is a cryptographic technology that allows\nto perform computation on private data without actually seeing the data. In\nthis paper, we bring together the notions of MPC and LP, allowing users to\nwrite privacy-preserving applications in logic programming language.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 13:02:44 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 13:28:11 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["J\u00e4\u00e4ger", "Joosep", ""], ["Pankova", "Alisa", ""]]}, {"id": "2010.07094", "submitter": "Mathias Morbitzer", "authors": "Martin Radev and Mathias Morbitzer", "title": "Exploiting Interfaces of Secure Encrypted Virtual Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing is a convenient model for processing data remotely. However,\nusers must trust their cloud provider with the confidentiality and integrity of\nthe stored and processed data. To increase the protection of virtual machines,\nAMD introduced SEV, a hardware feature which aims to protect code and data in a\nvirtual machine. This allows to store and process sensitive data in cloud\nenvironments without the need to trust the cloud provider or the underlying\nsoftware. However, the virtual machine still depends on the hypervisor for\nperforming certain activities, such as the emulation of special CPU\ninstructions, or the emulation of devices. Yet, most code that runs in virtual\nmachines was not written with an attacker model which considers the hypervisor\nas malicious. In this work, we introduce a new class of attacks in which a\nmalicious hypervisor manipulates external interfaces of an SEV or SEV-ES\nvirtual machine to make it act against its own interests. We start by showing\nhow we can make use of virtual devices to extract encryption keys and secret\ndata of a virtual machine. We then show how we can reduce the entropy of\nprobabilistic kernel defenses in the virtual machine by carefully manipulating\nthe results of the CPUID and RDTSC instructions. We continue by showing an\napproach for secret data exfiltration and code injection based on the forgery\nof MMIO regions over the VM's address space. Finally, we show another attack\nwhich forces decryption of the VM's stack and uses Return Oriented Programming\nto execute arbitrary code inside the VM. While our approach is also applicable\nto traditional virtualization environments, its severity significantly\nincreases with the attacker model of SEV-ES, which aims to protect a virtual\nmachine from a benign but vulnerable hypervisor.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 13:52:20 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Radev", "Martin", ""], ["Morbitzer", "Mathias", ""]]}, {"id": "2010.07188", "submitter": "Ian Kennedy", "authors": "Ian Kennedy, Arosha Bandara, Blaine Price", "title": "Towards Increasing Trust In Expert Evidence Derived From Malware\n  Forensic Tools", "comments": "Article in press. Accepted by Journal of Digital Forensics, Security\n  and Law (JDFSL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following a series of high profile miscarriages of justice in the UK linked\nto questionable expert evidence, the post of the Forensic Science Regulator was\ncreated in 2008. The main objective of this role is to improve the standard of\npractitioner competences and forensic procedures. One of the key strategies\ndeployed to achieve this is the push to incorporate a greater level of\nscientific conduct in the various fields of forensic practice. Currently there\nis no statutory requirement for practitioners to become accredited to continue\nworking with the Criminal Justice System of England and Wales. However, the\nForensic Science Regulator is lobbying the UK Government to make this\nmandatory. This paper focuses upon the challenge of incorporating a scientific\nmethodology to digital forensic investigations where malicious software\n('malware') has been identified. One aspect of such a methodology is the\napproach followed to both select and evaluate the tools used to perform dynamic\nmalware analysis during an investigation. Based on the literature, legal,\nregulatory and practical needs we derive a set of requirements to address this\nchallenge. We present a framework, called the 'Malware Analysis Tool Evaluation\nFramework' (MATEF), to address this lack of methodology to evaluate software\ntools used to perform dynamic malware analysis during investigations involving\nmalware and discuss how it meets the derived requirements.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 16:01:53 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Kennedy", "Ian", ""], ["Bandara", "Arosha", ""], ["Price", "Blaine", ""]]}, {"id": "2010.07190", "submitter": "Tom D\\\"orr", "authors": "Tom D\\\"orr, Karla Markert, Nicolas M. M\\\"uller, Konstantin B\\\"ottinger", "title": "Towards Resistant Audio Adversarial Examples", "comments": null, "journal-ref": "SPAI 20: Proceedings of the 1st ACM Workshop on Security and\n  Privacy on Artificial IntelligenceOctober 2020 Pages 3-10", "doi": "10.1145/3385003.3410921", "report-no": null, "categories": "cs.SD cs.CR cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples tremendously threaten the availability and integrity of\nmachine learning-based systems. While the feasibility of such attacks has been\nobserved first in the domain of image processing, recent research shows that\nspeech recognition is also susceptible to adversarial attacks. However,\nreliably bridging the air gap (i.e., making the adversarial examples work when\nrecorded via a microphone) has so far eluded researchers. We find that due to\nflaws in the generation process, state-of-the-art adversarial example\ngeneration methods cause overfitting because of the binning operation in the\ntarget speech recognition system (e.g., Mozilla Deepspeech). We devise an\napproach to mitigate this flaw and find that our method improves generation of\nadversarial examples with varying offsets. We confirm the significant\nimprovement with our approach by empirical comparison of the edit distance in a\nrealistic over-the-air setting. Our approach states a significant step towards\nover-the-air attacks. We publish the code and an applicable implementation of\nour approach.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 16:04:02 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["D\u00f6rr", "Tom", ""], ["Markert", "Karla", ""], ["M\u00fcller", "Nicolas M.", ""], ["B\u00f6ttinger", "Konstantin", ""]]}, {"id": "2010.07194", "submitter": "Pascal Zimmer", "authors": "Pascal Zimmer, Roland Weinreich, Christian T. Zenger, Aydin Sezgin,\n  Christof Paar", "title": "Keys from the Sky: A First Exploration of Physical-Layer Security Using\n  Satellite Links", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate physical-layer security (PLS) methods for\nproximity-based group-key establishment and proof of location. Fields of\napplication include secure car-to-car communication, privacy-preserving and\nsecure distance evidence for healthcare or location-based feature activation.\nExisting technologies do not solve the problem satisfactorily, due to\ncommunication restrictions, e.g., ultra-wide band (UWB) based time of flight\nmeasurements, or trusted hardware, e.g., using global navigation satellite\nsystem (GNSS) positioning data.\n  We introduce PLS as a solution candidate. It is information theoretically\nsecure, which also means post-quantum resistant, and has the potential to run\non resource constrained devices with low latency. Furthermore, we use wireless\nchannel properties of satellite-to-Earth links, demonstrate the first\nfeasibility study using off-the-shelf hardware testbeds and present first\nevaluation results and future directions for research.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 16:07:25 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Zimmer", "Pascal", ""], ["Weinreich", "Roland", ""], ["Zenger", "Christian T.", ""], ["Sezgin", "Aydin", ""], ["Paar", "Christof", ""]]}, {"id": "2010.07230", "submitter": "Siwei Xiong", "authors": "Jiazhu Dai, Siwei Xiong", "title": "An Evasion Attack against Stacked Capsule Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capsule network is a type of neural network that uses the spatial\nrelationship between features to classify images. By capturing the poses and\nrelative positions between features, its ability to recognize affine\ntransformation is improved, and it surpasses traditional convolutional neural\nnetworks (CNNs) when handling translation, rotation and scaling. The Stacked\nCapsule Autoencoder (SCAE) is the state-of-the-art capsule network. The SCAE\nencodes an image as capsules, each of which contains poses of features and\ntheir correlations. The encoded contents are then input into the downstream\nclassifier to predict the categories of the images. Existing research mainly\nfocuses on the security of capsule networks with dynamic routing or EM routing,\nand little attention has been given to the security and robustness of the SCAE.\nIn this paper, we propose an evasion attack against the SCAE. After a\nperturbation is generated based on the output of the object capsules in the\nmodel, it is added to an image to reduce the contribution of the object\ncapsules related to the original category of the image so that the perturbed\nimage will be misclassified. We evaluate the attack using an image\nclassification experiment, and the experimental results indicate that the\nattack can achieve high success rates and stealthiness. It confirms that the\nSCAE has a security vulnerability whereby it is possible to craft adversarial\nsamples without changing the original structure of the image to fool the\nclassifiers. We hope that our work will make the community aware of the threat\nof this attack and raise the attention given to the SCAE's security.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 16:44:10 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 07:18:49 GMT"}, {"version": "v3", "created": "Tue, 9 Mar 2021 06:19:41 GMT"}, {"version": "v4", "created": "Thu, 6 May 2021 07:18:50 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Dai", "Jiazhu", ""], ["Xiong", "Siwei", ""]]}, {"id": "2010.07259", "submitter": "Stefan Zwaard S.L.W.", "authors": "Stefan Zwaard, Henk-Jan Boele, Hani Alers, Christos Strydis, Casey\n  Lew-Williams, and Zaid Al-Ars", "title": "Privacy-Preserving Object Detection & Localization Using Distributed\n  Machine Learning: A Case Study of Infant Eyeblink Conditioning", "comments": "This is a preprint version of \"Privacy-Preserving Object Detection &\n  Localization Using Distributed Machine Learning: A Case Study of Infant\n  Eyeblink Conditioning\". This work consists of 12 pages including refs and, 4\n  tables and 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed machine learning is becoming a popular model-training method due\nto privacy, computational scalability, and bandwidth capacities. In this work,\nwe explore scalable distributed-training versions of two algorithms commonly\nused in object detection. A novel distributed training algorithm using Mean\nWeight Matrix Aggregation (MWMA) is proposed for Linear Support Vector Machine\n(L-SVM) object detection based in Histogram of Orientated Gradients (HOG). In\naddition, a novel Weighted Bin Aggregation (WBA) algorithm is proposed for\ndistributed training of Ensemble of Regression Trees (ERT) landmark\nlocalization. Both algorithms do not restrict the location of model aggregation\nand allow custom architectures for model distribution. For this work, a\nPool-Based Local Training and Aggregation (PBLTA) architecture for both\nalgorithms is explored. The application of both algorithms in the medical field\nis examined using a paradigm from the fields of psychology and neuroscience -\neyeblink conditioning with infants - where models need to be trained on facial\nimages while protecting participant privacy. Using distributed learning, models\ncan be trained without sending image data to other nodes. The custom software\nhas been made available for public use on GitHub:\nhttps://github.com/SLWZwaard/DMT. Results show that the aggregation of models\nfor the HOG algorithm using MWMA not only preserves the accuracy of the model\nbut also allows for distributed learning with an accuracy increase of 0.9%\ncompared with traditional learning. Furthermore, WBA allows for ERT model\naggregation with an accuracy increase of 8% when compared to single-node\nmodels.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 17:33:28 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Zwaard", "Stefan", ""], ["Boele", "Henk-Jan", ""], ["Alers", "Hani", ""], ["Strydis", "Christos", ""], ["Lew-Williams", "Casey", ""], ["Al-Ars", "Zaid", ""]]}, {"id": "2010.07288", "submitter": "Nikita Johnson", "authors": "Nikita Johnson and Youcef Gheraibia and Tim Kelly", "title": "Independent Co-Assurance using the Safety-Security Assurance Framework\n  (SSAF): A Bayesian Belief Network Implementation for IEC 61508 and Common\n  Criteria", "comments": null, "journal-ref": "In Proceedings of the Safety-Critical Systems Club Symposium\n  (SSS'20). February 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Safety Security Assurance Framework applied to two standards IEC 61508 and\nCommon Criteria - ISO 15408\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2020 23:35:44 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Johnson", "Nikita", ""], ["Gheraibia", "Youcef", ""], ["Kelly", "Tim", ""]]}, {"id": "2010.07352", "submitter": "Markus Nissl", "authors": "Markus Nissl, Emanuel Sallinger, Stefan Schulte and Michael Borkowski", "title": "Towards Cross-Blockchain Smart Contracts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, manifold blockchain protocols have been proposed by\nresearchers and industrial companies alike. This has led to a very\nheterogeneous blockchain landscape. Accordingly, it would be desirable if\nblockchains could interact with each other. However, current blockchain\ntechnologies offer only limited support for interoperability, thus preventing\ntokens or smart contracts from leaving the scope of a particular blockchain.\n  As a first step towards a solution for cross-chain smart contract\ninteractions, we introduce a framework which allows to invoke a smart contract\nfrom another blockchain. We offer support for continuing a smart contract after\nreceiving a result from a different blockchain, and for calling smart contracts\nrecursively across blockchains. We provide a reference implementation for\nEthereum-based blockchains using Solidity and evaluate the performance\nregarding time and cost overheads.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 18:39:52 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 14:27:26 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Nissl", "Markus", ""], ["Sallinger", "Emanuel", ""], ["Schulte", "Stefan", ""], ["Borkowski", "Michael", ""]]}, {"id": "2010.07363", "submitter": "Debarnab Mitra", "authors": "Debarnab Mitra, Lev Tauz, Lara Dolecek", "title": "Concentrated Stopping Set Design for Coded Merkle Tree: Improving\n  Security Against Data Availability Attacks in Blockchain Systems", "comments": "6 pages, 5 figures, To appear in Information Theory Workshop (ITW)\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In certain blockchain systems, light nodes are clients that download only a\nsmall portion of the block. Light nodes are vulnerable to data availability\n(DA) attacks where a malicious node hides an invalid portion of the block from\nthe light nodes. Recently, a technique based on erasure codes called Coded\nMerkle Tree (CMT) was proposed by Yu et al. that enables light nodes to detect\na DA attack with high probability. The CMT is constructed using LDPC codes for\nfast decoding but can fail to detect a DA attack if a malicious node hides a\nsmall stopping set of the code. To combat this, Yu et al. used well-studied\ntechniques to design random LDPC codes with high minimum stopping set size.\nAlthough effective, these codes are not necessarily optimal for this\napplication. In this paper, we demonstrate a more specialized LDPC code design\nto improve the security against DA attacks. We achieve this goal by providing a\ndeterministic LDPC code construction that focuses on concentrating stopping\nsets to a small group of variable nodes rather than only eliminating stopping\nsets. We design these codes by modifying the Progressive Edge Growth algorithm\ninto a technique called the entropy-constrained PEG (EC-PEG) algorithm. This\nnew method demonstrates a higher probability of detecting DA attacks and allows\nfor good codes at short lengths.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 18:56:18 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 23:16:41 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Mitra", "Debarnab", ""], ["Tauz", "Lev", ""], ["Dolecek", "Lara", ""]]}, {"id": "2010.07427", "submitter": "Mustafa Ozdayi", "authors": "Harsh Bimal Desai, Mustafa Safa Ozdayi, Murat Kantarcioglu", "title": "BlockFLA: Accountable Federated Learning via Hybrid Blockchain\n  Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) is a distributed, and decentralized machine learning\nprotocol. By executing FL, a set of agents can jointly train a model without\nsharing their datasets with each other, or a third-party. This makes FL\nparticularly suitable for settings where data privacy is desired.\n  At the same time, concealing training data gives attackers an opportunity to\ninject backdoors into the trained model. It has been shown that an attacker can\ninject backdoors to the trained model during FL, and then can leverage the\nbackdoor to make the model misclassify later. Several works tried to alleviate\nthis threat by designing robust aggregation functions. However, given more\nsophisticated attacks are developed over time, which by-pass the existing\ndefenses, we approach this problem from a complementary angle in this work.\nParticularly, we aim to discourage backdoor attacks by detecting, and punishing\nthe attackers, possibly after the end of training phase.\n  To this end, we develop a hybrid blockchain-based FL framework that uses\nsmart contracts to automatically detect, and punish the attackers via monetary\npenalties. Our framework is general in the sense that, any aggregation\nfunction, and any attacker detection algorithm can be plugged into it. We\nconduct experiments to demonstrate that our framework preserves the\ncommunication-efficient nature of FL, and provide empirical results to\nillustrate that it can successfully penalize attackers by leveraging our novel\nattacker detection algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2020 22:43:39 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Desai", "Harsh Bimal", ""], ["Ozdayi", "Mustafa Safa", ""], ["Kantarcioglu", "Murat", ""]]}, {"id": "2010.07444", "submitter": "Jaouhar Fattahi", "authors": "Jaouhar Fattahi, Mohamed Mejri", "title": "SpaML: a Bimodal Ensemble Learning Spam Detector based on NLP Techniques", "comments": "This paper was accepted, on October 13, 2020, for pulication and oral\n  presentation at the 2021 IEEE 5th International Conference on Cryptography,\n  Security and Privacy (CSP 2021) to be held in Zhuhai, China during January\n  8-10, 2021 and hosted by Beijing Normal University (Zhuhai)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we put forward a new tool, called SpaML, for spam detection\nusing a set of supervised and unsupervised classifiers, and two techniques\nimbued with Natural Language Processing (NLP), namely Bag of Words (BoW) and\nTerm Frequency-Inverse Document Frequency (TF-IDF). We first present the NLP\ntechniques used. Then, we present our classifiers and their performance on each\nof these techniques. Then, we present our overall Ensemble Learning classifier\nand the strategy we are using to combine them. Finally, we present the\ninteresting results shown by SpaML in terms of accuracy and precision.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 00:14:44 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 04:33:30 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Fattahi", "Jaouhar", ""], ["Mejri", "Mohamed", ""]]}, {"id": "2010.07493", "submitter": "Ali Dorri", "authors": "Zahra Jadidi, Ali Dorri, Raja Jurdak, and Colin Fidge", "title": "Securing Manufacturing Using Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the rise of Industrial Control Systems (ICSs) cyber-attacks in the\nrecent decade, various security frameworks have been designed for anomaly\ndetection. While advanced ICS attacks use sequential phases to launch their\nfinal attacks, existing anomaly detection methods can only monitor a single\nsource of data. Therefore, analysis of multiple security data can provide\ncomprehensive and system-wide anomaly detection in industrial networks. In this\npaper, we propose an anomaly detection framework for ICSs that consists of two\nstages: i) blockchain-based log management where the logs of ICS devices are\ncollected in a secure and distributed manner, and ii) multi-source anomaly\ndetection where the blockchain logs are analysed using multi-source deep\nlearning which in turn provides a system wide anomaly detection method.\n  We validated our framework using two ICS datasets: a factory automation\ndataset and a Secure Water Treatment (SWAT) dataset. These datasets contain\nphysical and network level normal and abnormal traffic. The performance of our\nnew framework is compared with single-source machine learning methods. The\nprecision of our framework is 95% which is comparable with single-source\nanomaly detectors.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 03:26:18 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Jadidi", "Zahra", ""], ["Dorri", "Ali", ""], ["Jurdak", "Raja", ""], ["Fidge", "Colin", ""]]}, {"id": "2010.07542", "submitter": "Patrick Bas", "authors": "Beno\\^it Bonnet, Teddy Furon, Patrick Bas (CRIStAL)", "title": "Adversarial Images through Stega Glasses", "comments": "Submitted to IEEE WIFS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.IV eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the connection between steganography and adversarial\nimages. On the one hand, ste-ganalysis helps in detecting adversarial\nperturbations. On the other hand, steganography helps in forging adversarial\nperturbations that are not only invisible to the human eye but also\nstatistically undetectable. This work explains how to use these information\nhiding tools for attacking or defending computer vision image classification.\nWe play this cat and mouse game with state-of-art classifiers, steganalyzers,\nand steganographic embedding schemes. It turns out that steganography helps\nmore the attacker than the defender.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 06:30:07 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Bonnet", "Beno\u00eet", "", "CRIStAL"], ["Furon", "Teddy", "", "CRIStAL"], ["Bas", "Patrick", "", "CRIStAL"]]}, {"id": "2010.07555", "submitter": "YongJie Ye", "authors": "Yongjie Ye, Weigang Wu", "title": "Garou: An Efficient and Secure Off-Blockchain Multi-Party Payment Hub", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To mitigate the scalability problem of decentralized cryptocurrencies such as\nBitcoin and Ethereum, the payment channel, which allows two parties to perform\nsecure coin transfers without involving the blockchain, has been proposed. The\npayment channel increases the transaction throughput of two parties to a level\nthat is only limited by their network bandwidth. Recent proposals focus on\nextending the two-party payment channel to the N-party payment hub.\nUnfortunately, none of them can achieve efficiency, flexibility in the absence\nof a trusted third-party. In this paper, we propose Garou, a secure N-party\npayment hub that allows multiple parties to perform secure off-chain coin\ntransfers. Except in the case of disputes, participants within the payment hub\ncan make concurrent and direct coin transfers with each other without the\ninvolvement of the blockchain or any third-party intermediaries. This allows\nGarou to achieve both high-performance and flexibility. Garou also guarantees\nthat an honest party always maintains its balance security against strong\nadversarial capabilities. To demonstrate the feasibility of the Garou protocol,\nwe develop a proof of concept prototype for the Ethereum network. Our\nevaluation results show that the maximum transaction throughput of Garou is 20\ntimes higher than that of state-of-art payment hubs.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 07:09:06 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Ye", "Yongjie", ""], ["Wu", "Weigang", ""]]}, {"id": "2010.07754", "submitter": "Dorjan Hitaj", "authors": "Fabio De Gaspari, Dorjan Hitaj, Giulio Pagnotta, Lorenzo De Carli,\n  Luigi V. Mancini", "title": "EnCoD: Distinguishing Compressed and Encrypted File Fragments", "comments": "19 pages, 6 images, 2 tables. Accepted for publication at the 14th\n  International Conference on Network and System Security (NSS2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliable identification of encrypted file fragments is a requirement for\nseveral security applications, including ransomware detection, digital\nforensics, and traffic analysis. A popular approach consists of estimating high\nentropy as a proxy for randomness. However, many modern content types (e.g.\noffice documents, media files, etc.) are highly compressed for storage and\ntransmission efficiency. Compression algorithms also output high-entropy data,\nthus reducing the accuracy of entropy-based encryption detectors. Over the\nyears, a variety of approaches have been proposed to distinguish encrypted file\nfragments from high-entropy compressed fragments. However, these approaches are\ntypically only evaluated over a few, select data types and fragment sizes,\nwhich makes a fair assessment of their practical applicability impossible. This\npaper aims to close this gap by comparing existing statistical tests on a\nlarge, standardized dataset. Our results show that current approaches cannot\nreliably tell apart encryption and compression, even for large fragment sizes.\nTo address this issue, we design EnCoD, a learning-based classifier which can\nreliably distinguish compressed and encrypted data, starting with fragments as\nsmall as 512 bytes. We evaluate EnCoD against current approaches over a large\ndataset of different data types, showing that it outperforms current\nstate-of-the-art for most considered fragment sizes and data types.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 13:55:55 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["De Gaspari", "Fabio", ""], ["Hitaj", "Dorjan", ""], ["Pagnotta", "Giulio", ""], ["De Carli", "Lorenzo", ""], ["Mancini", "Luigi V.", ""]]}, {"id": "2010.07788", "submitter": "Yanghao Zhang", "authors": "Yanghao Zhang, Wenjie Ruan, Fu Wang, Xiaowei Huang", "title": "Generalizing Universal Adversarial Attacks Beyond Additive Perturbations", "comments": "A short version of this work will appear in the ICDM 2020 conference\n  proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The previous study has shown that universal adversarial attacks can fool deep\nneural networks over a large set of input images with a single human-invisible\nperturbation. However, current methods for universal adversarial attacks are\nbased on additive perturbation, which cause misclassification when the\nperturbation is directly added to the input images. In this paper, for the\nfirst time, we show that a universal adversarial attack can also be achieved\nvia non-additive perturbation (e.g., spatial transformation). More importantly,\nto unify both additive and non-additive perturbations, we propose a novel\nunified yet flexible framework for universal adversarial attacks, called GUAP,\nwhich is able to initiate attacks by additive perturbation, non-additive\nperturbation, or the combination of both. Extensive experiments are conducted\non CIFAR-10 and ImageNet datasets with six deep neural network models including\nGoogleLeNet, VGG16/19, ResNet101/152, and DenseNet121. The empirical\nexperiments demonstrate that GUAP can obtain up to 90.9% and 99.24% successful\nattack rates on CIFAR-10 and ImageNet datasets, leading to over 15% and 19%\nimprovements respectively than current state-of-the-art universal adversarial\nattacks. The code for reproducing the experiments in this paper is available at\nhttps://github.com/TrustAI/GUAP.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 14:25:58 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 18:20:21 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Zhang", "Yanghao", ""], ["Ruan", "Wenjie", ""], ["Wang", "Fu", ""], ["Huang", "Xiaowei", ""]]}, {"id": "2010.07808", "submitter": "Raouf Kerkouche", "authors": "Raouf Kerkouche, Gergely \\'Acs and Claude Castelluccia", "title": "Federated Learning in Adversarial Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning enables entities to collaboratively learn a shared\nprediction model while keeping their training data locally. It prevents data\ncollection and aggregation and, therefore, mitigates the associated privacy\nrisks. However, it still remains vulnerable to various security attacks where\nmalicious participants aim at degrading the generated model, inserting\nbackdoors, or inferring other participants' training data. This paper presents\na new federated learning scheme that provides different trade-offs between\nrobustness, privacy, bandwidth efficiency, and model accuracy. Our scheme uses\nbiased quantization of model updates and hence is bandwidth efficient. It is\nalso robust against state-of-the-art backdoor as well as model degradation\nattacks even when a large proportion of the participant nodes are malicious. We\npropose a practical differentially private extension of this scheme which\nprotects the whole dataset of participating entities. We show that this\nextension performs as efficiently as the non-private but robust scheme, even\nwith stringent privacy requirements but are less robust against model\ndegradation and backdoor attacks. This suggests a possible fundamental\ntrade-off between Differential Privacy and robustness.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 14:57:02 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Kerkouche", "Raouf", ""], ["\u00c1cs", "Gergely", ""], ["Castelluccia", "Claude", ""]]}, {"id": "2010.07818", "submitter": "Kommy Weldemariam Dr", "authors": "Andrew Kinai, Fred Otieno, Nelson Bore, Komminist Weldemariam", "title": "Multi-factor authentication for users of non-internet based applications\n  of blockchain-based platforms", "comments": "7 papes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Attacks targeting several millions of non-internet based application users\nare on the rise. These applications such as SMS and USSD typically do not\nbenefit from existing multi-factor authentication methods due to the nature of\ntheir interaction interfaces and mode of operations. To address this problem,\nwe propose an approach that augments blockchain with multi-factor\nauthentication based on evidence from blockchain transactions combined with\nrisk analysis. A profile of how a user performs transactions is built overtime\nand is used to analyse the risk level of each new transaction. If a transaction\nis flagged as high risk, we generate n-factor layers of authentication using\npast endorsed blockchain transactions. A demonstration of how we used the\nproposed approach to authenticate critical financial transactions in a\nblockchain-based asset financing platform is also discussed.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 15:19:36 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Kinai", "Andrew", ""], ["Otieno", "Fred", ""], ["Bore", "Nelson", ""], ["Weldemariam", "Komminist", ""]]}, {"id": "2010.08002", "submitter": "Paul Hriljac", "authors": "Paul Hriljac", "title": "Fully Homomorphic Encryption via Affine Automorphisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Homomorphic encryption is a method used in cryptopgraphy to create programs\nthat can interact with encrypted data without ever leaving the data in the\nclear. This has many potential applications in cybersecurity. This paper uses\nautomorphisms of affine space to create a form of homomorphic encryption for\nstraight line programs. The encryption method used for the data is known as\nmultivariate encryption. This gives a potentially powerful new method in cyber\nsecurity based on techniques from algebraic geometry.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 20:03:26 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Hriljac", "Paul", ""]]}, {"id": "2010.08138", "submitter": "Anh Tran", "authors": "Anh Nguyen and Anh Tran", "title": "Input-Aware Dynamic Backdoor Attack", "comments": "Accepted to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, neural backdoor attack has been considered to be a potential\nsecurity threat to deep learning systems. Such systems, while achieving the\nstate-of-the-art performance on clean data, perform abnormally on inputs with\npredefined triggers. Current backdoor techniques, however, rely on uniform\ntrigger patterns, which are easily detected and mitigated by current defense\nmethods. In this work, we propose a novel backdoor attack technique in which\nthe triggers vary from input to input. To achieve this goal, we implement an\ninput-aware trigger generator driven by diversity loss. A novel cross-trigger\ntest is applied to enforce trigger nonreusablity, making backdoor verification\nimpossible. Experiments show that our method is efficient in various attack\nscenarios as well as multiple datasets. We further demonstrate that our\nbackdoor can bypass the state of the art defense methods. An analysis with a\nfamous neural network inspector again proves the stealthiness of the proposed\nattack. Our code is publicly available at\nhttps://github.com/VinAIResearch/input-aware-backdoor-attack-release.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 03:57:12 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Nguyen", "Anh", ""], ["Tran", "Anh", ""]]}, {"id": "2010.08154", "submitter": "Soubhik Deb", "authors": "Soubhik Deb, Sreeram Kannan, David Tse", "title": "PoSAT: Proof-of-Work Availability and Unpredictability, without the Work", "comments": "arXiv admin note: text overlap with arXiv:2005.10484", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important feature of Proof-of-Work (PoW) blockchains is full dynamic\navailability, allowing miners to go online and offline while requiring only 50%\nof the online miners to be honest.\n  Existing Proof-of-stake (PoS), Proof-of-Space and related protocols are able\nto achieve this property only partially, either putting the additional\nassumption that adversary nodes to be online from the beginning and no new\nadversary nodes come online afterwards, or use additional trust assumptions for\nnewly joining nodes.We propose a new PoS protocol PoSAT which can provably\nachieve dynamic availability fully without any additional assumptions. The\nprotocol is based on the longest chain and uses a Verifiable Delay Function for\nthe block proposal lottery to provide an arrow of time. The security analysis\nof the protocol draws on the recently proposed technique of Nakamoto blocks as\nwell as the theory of branching random walks. An additional feature of PoSAT is\nthe complete unpredictability of who will get to propose a block next, even by\nthe winner itself. This unpredictability is at the same level of PoW protocols,\nand is stronger than that of existing PoS protocols using Verifiable Random\nFunctions.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 17:55:50 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 03:41:51 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Deb", "Soubhik", ""], ["Kannan", "Sreeram", ""], ["Tse", "David", ""]]}, {"id": "2010.08176", "submitter": "Omid Ardakanian", "authors": "Leepakshi Bindra, Kalvin Eng, Omid Ardakanian, Eleni Stroulia", "title": "Flexible, Decentralized Access Control for Smart Buildings with Smart\n  Contracts", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large commercial buildings are complex cyber-physical systems containing\nexpensive and critical equipment that ensure the safety and comfort of their\nnumerous occupants. Yet occupant and visitor access to spaces and equipment\nwithin these buildings are still managed through unsystematic, inefficient, and\nhuman-intensive processes. As a standard practice, long-term building occupants\nare given access privileges to rooms and equipment based on their\norganizational roles, while visitors have to be escorted by their hosts. This\napproach is conservative and inflexible. In this paper, we describe a\nmethodology that can flexibly and securely manage building access privileges\nfor long-term occupants and short-term visitors alike, taking into account the\nrisk associated with accessing each space within the building. Our methodology\nrelies on blockchain smart contracts to describe, grant, audit, and revoke\nfine-grained permissions for building occupants and visitors, in a\ndecentralized fashion. The smart contracts are specified through a process that\nleverages the information compiled from Brick and BOT models of the building.\nWe illustrate the proposed method through a typical application scenario in the\ncontext of a real office building and argue that it can greatly reduce the\nadministration overhead, while, at the same time, providing fine-grained,\nauditable access control.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 05:35:29 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Bindra", "Leepakshi", ""], ["Eng", "Kalvin", ""], ["Ardakanian", "Omid", ""], ["Stroulia", "Eleni", ""]]}, {"id": "2010.08238", "submitter": "Takao Murakami", "authors": "Takao Murakami and Kenta Takahashi", "title": "Toward Evaluating Re-identification Risks in the Local Privacy Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LDP (Local Differential Privacy) has recently attracted much attention as a\nmetric of data privacy that prevents the inference of personal data from\nobfuscated data in the local model. However, there are scenarios in which the\nadversary wants to perform re-identification attacks to link the obfuscated\ndata to users in this model. LDP can cause excessive obfuscation and destroy\nthe utility in these scenarios because it is not designed to directly prevent\nre-identification. In this paper, we propose a measure of reidentification\nrisks, which we call PIE (Personal Information Entropy). The PIE is designed so\nthat it directly prevents re-identification attacks in the local model. It\nlower-bounds the lowest possible re-identification error probability (i.e.,\nBayes error probability) of the adversary. We analyze the relation between LDP\nand the PIE, and analyze the PIE and utility in distribution estimation for two\nobfuscation mechanisms providing LDP. Through experiments, we show that when we\nconsider re-identification as a privacy risk, LDP can cause excessive\nobfuscation and destroy the utility. Then we show that the PIE can be used to\nguarantee low re-identification risks for the local obfuscation mechanisms\nwhile keeping high utility.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 08:38:39 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 23:58:03 GMT"}, {"version": "v3", "created": "Wed, 10 Feb 2021 11:46:42 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Murakami", "Takao", ""], ["Takahashi", "Kenta", ""]]}, {"id": "2010.08274", "submitter": "Alessandro Sorniotti PhD", "authors": "Elli Androulaki, Angelo De Caro, Kaoutar Elkhiyaoui, Christian\n  Gorenflo, Alessandro Sorniotti and Marko Vukolic", "title": "Multi-Shard Private Transactions for Permissioned Blockchains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, blockchain systems involve sharing transaction information\nacross all blockchain network participants. Clearly, this introduces barriers\nto the adoption of the technology by the enterprise world, where preserving the\nprivacy of the business data is a necessity. Previous efforts to bring privacy\nand blockchains together either still leak partial information, are restricted\nin their functionality or use costly mechanisms like zk-SNARKs. In this paper,\nwe propose the Multi-Shard Private Transaction (MSPT) protocol, a novel\nprivacy-preserving protocol for permissioned blockchains, which relies only on\nsimple cryptographic primitives and targeted dissemination of information to\nachieve atomicity and high performances.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 09:48:19 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Androulaki", "Elli", ""], ["De Caro", "Angelo", ""], ["Elkhiyaoui", "Kaoutar", ""], ["Gorenflo", "Christian", ""], ["Sorniotti", "Alessandro", ""], ["Vukolic", "Marko", ""]]}, {"id": "2010.08281", "submitter": "Wei Huang", "authors": "Wei Huang, Xingyu Zhao and Xiaowei Huang", "title": "Embedding and Extraction of Knowledge in Tree Ensemble Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The embedding and extraction of useful knowledge is a recent trend in machine\nlearning applications, e.g., to supplement existing datasets that are small.\nWhilst, as the increasing use of machine learning models in security-critical\napplications, the embedding and extraction of malicious knowledge are\nequivalent to the notorious backdoor attack and its defence, respectively. This\npaper studies the embedding and extraction of knowledge in tree ensemble\nclassifiers, and focuses on knowledge expressible with a generic form of\nBoolean formulas, e.g., robustness properties and backdoor attacks. For the\nembedding, it is required to be preservative(the original performance of the\nclassifier is preserved), verifiable(the knowledge can be attested), and\nstealthy(the embedding cannot be easily detected). To facilitate this, we\npropose two novel, and effective, embedding algorithms, one of which is for\nblack-box settings and the other for white-box settings.The embedding can be\ndone in PTIME. Beyond the embedding, we develop an algorithm to extract the\nembedded knowledge, by reducing the problem to be solvable with an SMT\n(satisfiability modulo theories) solver. While this novel algorithm can\nsuccessfully extract knowledge, the reduction leads to an NP computation.\nTherefore, if applying embedding as backdoor attacks and extraction as defence,\nour results suggest a complexity gap (P vs. NP) between the attack and defence\nwhen working with tree ensemble classifiers. We apply our algorithms toa\ndiverse set of datasets to validate our conclusion extensively.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 10:09:01 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 06:12:04 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Huang", "Wei", ""], ["Zhao", "Xingyu", ""], ["Huang", "Xiaowei", ""]]}, {"id": "2010.08311", "submitter": "Wei Huang", "authors": "Wei Huang, Yifan Zhou, Youcheng Sun, Alec Banks, Jie Meng, James\n  Sharp, Simon Maskell and Xiaowei Huang", "title": "Formal Verification of Robustness and Resilience of Learning-Enabled\n  State Estimation Systems for Robotics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a formal verification guided approach for a principled\ndesign and implementation of robust and resilient learning-enabled systems. We\nfocus on learning-enabled state estimation systems (LE-SESs), which have been\nwidely used in robotics applications to determine the current state (e.g.,\nlocation, speed, direction, etc.) of a complex system. The LE-SESs are\nnetworked systems composed of a set of connected components including Bayes\nfilters for localisation, and neural networks for processing sensory input. We\nstudy LE-SESs from the perspective of formal verification, which determines the\nsatisfiability of a system model against the specified properties. Over\nLE-SESs, we investigate two key properties - robustness and resilience - and\nprovide their formal definitions. To enable formal verification, we reduce the\nLE-SESs to a novel class of labelled transition systems, named {PO}2-LTS in the\npaper, and formally express the properties as constrained optimisation\nobjectives. We prove that the robustness verification is NP-complete. Based on\n{PO}2-LTS and the optimisation objectives, practical verification algorithms\nare developed to check the satisfiability of the properties on the LE-SESs. As\na major case study, we interrogate a real-world dynamic tracking system which\nuses a single Kalman Filter (KF) - a special case of Bayes filter - to localise\nand track a ground vehicle. Its perception system, based on convolutional\nneural networks, processes a high-resolution Wide Area Motion Imagery (WAMI)\ndata stream. Experimental results show that our algorithms can not only verify\nthe properties of the WAMI tracking system but also provide representative\nexamples, the latter of which inspired us to take an enhanced LE-SESs design\nwhere runtime monitors or joint-KFs are required. Experimental results confirm\nthe improvement of the robustness of the enhanced design.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 11:06:50 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Huang", "Wei", ""], ["Zhou", "Yifan", ""], ["Sun", "Youcheng", ""], ["Banks", "Alec", ""], ["Meng", "Jie", ""], ["Sharp", "James", ""], ["Maskell", "Simon", ""], ["Huang", "Xiaowei", ""]]}, {"id": "2010.08316", "submitter": "Matthias Grundmann", "authors": "Matthias Grundmann, Hannes Hartenstein", "title": "Fundamental Properties of the Layer Below a Payment Channel Network\n  (Extended Version)", "comments": "Extended version of short paper published at 4th International\n  Workshop on Cryptocurrencies and Blockchain Technology - CBT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Payment channel networks are a highly discussed approach for improving\nscalability of cryptocurrencies such as Bitcoin. As they allow processing\ntransactions off-chain, payment channel networks are referred to as second\nlayer technology, while the blockchain is the first layer. We uncouple payment\nchannel networks from blockchains and look at them as first-class citizens.\nThis brings up the question what model payment channel networks require as\nfirst layer. In response, we formalize a model (called RFL Model) for a first\nlayer below a payment channel network. While transactions are globally made\navailable by a blockchain, the RFL Model only provides the reduced property\nthat a transaction is delivered to the users being affected by a transaction.\nWe show that the reduced model's properties still suffice to implement payment\nchannels. By showing that the RFL Model can not only be instantiated by the\nBitcoin blockchain but also by trusted third parties like banks, we show that\nthe reduction widens the design space for the first layer. Further, we show\nthat the stronger property provided by blockchains allows for optimizations\nthat can be used to reduce the time for locking collateral during payments over\nmultiple hops in a payment channel network.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 11:13:30 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Grundmann", "Matthias", ""], ["Hartenstein", "Hannes", ""]]}, {"id": "2010.08440", "submitter": "Shweta Shinde", "authors": "Zhijingcheng Yu and Shweta Shinde and Trevor E. Carlson and Prateek\n  Saxena", "title": "Elasticlave: An Efficient Memory Model for Enclaves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trusted-execution environments (TEE), like Intel SGX, isolate user-space\napplications into secure enclaves without trusting the OS. Thus, TEEs reduce\nthe trusted computing base, but add one to two orders of magnitude slow-down.\nThe performance cost stems from a strict memory model, which we call the\nspatial isolation model, where enclaves cannot share memory regions with each\nother. In this work, we present Elasticlave---a new TEE memory model that\nallows enclaves to selectively and temporarily share memory with other enclaves\nand the OS. Elasticlave eliminates the need for expensive data copy operations,\nwhile offering the same level of application-desired security as possible with\nthe spatial model. We prototype Elasticlave design on an RTL-designed\ncycle-level RISC-V core and observe 1 to 2 orders of magnitude performance\nimprovements over the spatial model implemented with the same processor\nconfiguration. Elasticlave has a small TCB. We find that its performance\ncharacteristics and hardware area footprint scale well with the number of\nshared memory regions it is configured to support.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 15:12:49 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Yu", "Zhijingcheng", ""], ["Shinde", "Shweta", ""], ["Carlson", "Trevor E.", ""], ["Saxena", "Prateek", ""]]}, {"id": "2010.08453", "submitter": "Martin Rosso", "authors": "Martin Rosso, Michele Campobasso, Ganduulga Gankhuyag, Luca Allodi", "title": "SAIBERSOC: Synthetic Attack Injection to Benchmark and Evaluate the\n  Performance of Security Operation Centers", "comments": "To be published in Annual Computer Security Applications Conference\n  (ACSAC 2020), December 7-11, 2020, Austin, USA. ACM, New York, NY, USA, 13\n  pages. https://doi.org/10.1145/3427228.3427233, ISBN: 978-1-4503-8858-0/20/12\n  Artifact repository: https://gitlab.tue.nl/saibersoc/acsac2020-artifacts", "journal-ref": null, "doi": "10.1145/3427228.3427233", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce SAIBERSOC, a tool and methodology enabling\nsecurity researchers and operators to evaluate the performance of deployed and\noperational Security Operation Centers (SOCs) (or any other security monitoring\ninfrastructure). The methodology relies on the MITRE ATT&CK Framework to define\na procedure to generate and automatically inject synthetic attacks in an\noperational SOC to evaluate any output metric of interest (e.g., detection\naccuracy, time-to-investigation, etc.). To evaluate the effectiveness of the\nproposed methodology, we devise an experiment with $n=124$ students playing the\nrole of SOC analysts. The experiment relies on a real SOC infrastructure and\nassigns students to either a BADSOC or a GOODSOC experimental condition. Our\nresults show that the proposed methodology is effective in identifying\nvariations in SOC performance caused by (minimal) changes in SOC configuration.\nWe release the SAIBERSOC tool implementation as free and open source software.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 15:30:35 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Rosso", "Martin", ""], ["Campobasso", "Michele", ""], ["Gankhuyag", "Ganduulga", ""], ["Allodi", "Luca", ""]]}, {"id": "2010.08460", "submitter": "Philipp Jeitner", "authors": "Philipp Jeitner, Haya Shulman, Michael Waidner", "title": "Pitfalls of Provably Secure Systems in Internet The Case of Chronos-NTP", "comments": null, "journal-ref": "2020 50th Annual IEEE-IFIP International Conference on Dependable\n  Systems and Networks-Supplemental Volume (DSN-S), Valencia, Spain, 2020, pp.\n  49-50", "doi": "10.1109/DSN-S50200.2020.00027", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The critical role that Network Time Protocol (NTP) plays in the Internet led\nto multiple efforts to secure it against time-shifting attacks. A recent\nproposal for enhancing the security of NTP with Chronos against on-path\nattackers seems the most promising one and is on a standardisation track of the\nIETF. In this work we demonstrate off-path attacks against Chronos enhanced NTP\nclients. The weak link is a central security feature of Chronos: The server\npool generation mechanism using DNS. We show that the insecurity of DNS allows\nto subvert the security of Chronos making the time-shifting attacks against\nChronos-NTP even easier than attacks against plain NTP.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 15:55:40 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Jeitner", "Philipp", ""], ["Shulman", "Haya", ""], ["Waidner", "Michael", ""]]}, {"id": "2010.08466", "submitter": "Poonam Yadav Dr", "authors": "Poonam Yadav and Angelo Feraudo and Budi Arief and Siamak F.\n  Shahandashti and Vassilios G. Vassilakis", "title": "Position paper: A systematic framework for categorising IoT device\n  fingerprinting mechanisms", "comments": "7 pages, 2 figures, Accepted in ACM/IEEE AIChallengeIoT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The popularity of the Internet of Things (IoT) devices makes it increasingly\nimportant to be able to fingerprint them, for example in order to detect if\nthere are misbehaving or even malicious IoT devices in one's network. The aim\nof this paper is to provide a systematic categorisation of machine learning\naugmented techniques that can be used for fingerprinting IoT devices. This can\nserve as a baseline for comparing various IoT fingerprinting mechanisms, so\nthat network administrators can choose one or more mechanisms that are\nappropriate for monitoring and maintaining their network. We carried out an\nextensive literature review of existing papers on fingerprinting IoT devices --\npaying close attention to those with machine learning features. This is\nfollowed by an extraction of important and comparable features among the\nmechanisms outlined in those papers. As a result, we came up with a key set of\nterminologies that are relevant both in the fingerprinting context and in the\nIoT domain. This enabled us to construct a framework called IDWork, which can\nbe used for categorising existing IoT fingerprinting mechanisms in a way that\nwill facilitate a coherent and fair comparison of these mechanisms. We found\nthat the majority of the IoT fingerprinting mechanisms take a passive approach\n-- mainly through network sniffing -- instead of being intrusive and\ninteractive with the device of interest. Additionally, a significant number of\nthe surveyed mechanisms employ both static and dynamic approaches, in order to\nbenefit from complementary features that can be more robust against certain\nattacks such as spoofing and replay attacks.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 16:08:36 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 14:41:27 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Yadav", "Poonam", ""], ["Feraudo", "Angelo", ""], ["Arief", "Budi", ""], ["Shahandashti", "Siamak F.", ""], ["Vassilakis", "Vassilios G.", ""]]}, {"id": "2010.08502", "submitter": "Yan Ke", "authors": "Yan Ke, Minqing Zhang, Xinpeng Zhang, Jia Liu, Tingting Su, and\n  Xiaoyuan Yang", "title": "A Reversible Data hiding Scheme in Encrypted Domain for Secret Image\n  Sharing based on Chinese Remainder Theorem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reversible data hiding in encrypted domain (RDH-ED) schemes based on\nsymmetric or public key encryption are mainly applied to the security of\nend-to-end communication. Aimed at providing reliable technical supports for\nmulti-party security scenarios, a separable RDH-ED scheme for secret image\nsharing based on Chinese remainder theorem (CRT) is presented. In the\napplication of (t, n) secret image sharing, the image is first shared into n\ndifferent shares of ciphertext. Only when not less than t shares obtained, can\nthe original image be reconstructed. In our scheme, additional data could be\nembedded into the image shares. To realize data extraction from the image\nshares and the reconstructed image separably, two data hiding methods are\nproposed: one is homomorphic difference expansion in encrypted domain (HDE-ED)\nthat supports data extraction from the reconstructed image by utilizing the\naddition homomorphism of CRT secret sharing; the other is difference expansion\nin image shares (DE-IS) that supports the data extraction from the marked\nshares before image reconstruction. Experimental results demonstrate that the\nproposed scheme could not only maintain the security and the threshold function\nof secret sharing system, but also obtain a better reversibility and efficiency\ncompared with most existing RDH-ED algorithms. The maximum embedding rate of\nHDE-ED could reach 0.5000 bits per pixel and the average embedding rate of\nDE-IS is 0.0545 bits per bit of ciphertext.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 15:20:08 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Ke", "Yan", ""], ["Zhang", "Minqing", ""], ["Zhang", "Xinpeng", ""], ["Liu", "Jia", ""], ["Su", "Tingting", ""], ["Yang", "Xiaoyuan", ""]]}, {"id": "2010.08521", "submitter": "Nour Moustafa", "authors": "Nour Moustafa, Mohiuddin Ahmed, Sherif Ahmed", "title": "Data Analytics-enabled Intrusion Detection: Evaluations of ToN_IoT Linux\n  Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  With the widespread of Artificial Intelligence (AI)- enabled security\napplications, there is a need for collecting heterogeneous and scalable data\nsources for effectively evaluating the performances of security applications.\nThis paper presents the description of new datasets, named ToN IoT datasets\nthat include distributed data sources collected from Telemetry datasets of\nInternet of Things (IoT) services, Operating systems datasets of Windows and\nLinux, and datasets of Network traffic. The paper aims to describe the new\ntestbed architecture used to collect Linux datasets from audit traces of hard\ndisk, memory and process. The architecture was designed in three distributed\nlayers of edge, fog, and cloud. The edge layer comprises IoT and network\nsystems, the fog layer includes virtual machines and gateways, and the cloud\nlayer includes data analytics and visualization tools connected with the other\ntwo layers. The layers were programmatically controlled using Software-Defined\nNetwork (SDN) and Network-Function Virtualization (NFV) using the VMware NSX\nand vCloud NFV platform. The Linux ToN IoT datasets would be used to train and\nvalidate various new federated and distributed AI-enabled security solutions\nsuch as intrusion detection, threat intelligence, privacy preservation and\ndigital forensics. Various Data analytical and machine learning methods are\nemployed to determine the fidelity of the datasets in terms of examining\nfeature engineering, statistics of legitimate and security events, and\nreliability of security events. The datasets can be publicly accessed from [1].\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 10:42:14 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Moustafa", "Nour", ""], ["Ahmed", "Mohiuddin", ""], ["Ahmed", "Sherif", ""]]}, {"id": "2010.08522", "submitter": "Nour Moustafa", "authors": "Nour Moustafa, Marwa Keshk, Essam Debie, and Helge Janicke", "title": "Federated TON_IoT Windows Datasets for Evaluating AI-based Security\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Existing cyber security solutions have been basically developed using\nknowledge-based models that often cannot trigger new cyber-attack families.\nWith the boom of Artificial Intelligence (AI), especially Deep Learning (DL)\nalgorithms, those security solutions have been plugged-in with AI models to\ndiscover, trace, mitigate or respond to incidents of new security events. The\nalgorithms demand a large number of heterogeneous data sources to train and\nvalidate new security systems. This paper presents the description of new\ndatasets, the so-called ToN_IoT, which involve federated data sources collected\nfrom telemetry datasets of IoT services, operating system datasets of Windows\nand Linux, and datasets of network traffic. The paper introduces the testbed\nand description of TON_IoT datasets for Windows operating systems. The testbed\nwas implemented in three layers: edge, fog and cloud. The edge layer involves\nIoT and network devices, the fog layer contains virtual machines and gateways,\nand the cloud layer involves cloud services, such as data analytics, linked to\nthe other two layers. These layers were dynamically managed using the platforms\nof software-Defined Network (SDN) and Network-Function Virtualization (NFV)\nusing the VMware NSX and vCloud NFV platform. The Windows datasets were\ncollected from audit traces of memories, processors, networks, processes and\nhard disks. The datasets would be used to evaluate various AI-based cyber\nsecurity solutions, including intrusion detection, threat intelligence and\nhunting, privacy preservation and digital forensics. This is because the\ndatasets have a wide range of recent normal and attack features and\nobservations, as well as authentic ground truth events. The datasets can be\npublicly accessed from this link [1].\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 07:56:30 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Moustafa", "Nour", ""], ["Keshk", "Marwa", ""], ["Debie", "Essam", ""], ["Janicke", "Helge", ""]]}, {"id": "2010.08542", "submitter": "Adrian de Wynter", "authors": "Adrian de Wynter", "title": "Mischief: A Simple Black-Box Attack Against Transformer Architectures", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce Mischief, a simple and lightweight method to produce a class of\nhuman-readable, realistic adversarial examples for language models. We perform\nexhaustive experimentations of our algorithm on four transformer-based\narchitectures, across a variety of downstream tasks, as well as under varying\nconcentrations of said examples. Our findings show that the presence of\nMischief-generated adversarial samples in the test set significantly degrades\n(by up to $20\\%$) the performance of these models with respect to their\nreported baselines. Nonetheless, we also demonstrate that, by including similar\nexamples in the training set, it is possible to restore the baseline scores on\nthe adversarial test set. Moreover, for certain tasks, the models trained with\nMischief set show a modest increase on performance with respect to their\noriginal, non-adversarial baseline.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 17:52:06 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["de Wynter", "Adrian", ""]]}, {"id": "2010.08607", "submitter": "Mohit Sewak", "authors": "Mohit Sewak, Sanjay K. Sahay and Hemant Rathore", "title": "DeepIntent: ImplicitIntent based Android IDS with E2E Deep Learning\n  architecture", "comments": null, "journal-ref": null, "doi": "10.1109/PIMRC48278.2020.9217188", "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Intent in Android plays an important role in inter-process and\nintra-process communications. The implicit Intent that an application could\naccept are declared in its manifest and are amongst the easiest feature to\nextract from an apk. Implicit Intents could even be extracted online and in\nreal-time. So far neither the feasibility of developing an Intrusion Detection\nSystem solely on implicit Intent has been explored, nor are any benchmarks\navailable of a malware classifier that is based on implicit Intent alone. We\ndemonstrate that despite Intent is implicit and well declared, it can provide\nvery intuitive insights to distinguish malicious from non-malicious\napplications. We conducted exhaustive experiments with over 40 different\nend-to-end Deep Learning configurations of Auto-Encoders and\nMulti-Layer-Perceptron to create a benchmark for a malware classifier that\nworks exclusively on implicit Intent. Using the results from the experiments we\ncreate an intrusion detection system using only the implicit Intents and\nend-to-end Deep Learning architecture. We obtained an area-under-curve\nstatistic of 0.81, and accuracy of 77.2% along with false-positive-rate of 0.11\non Drebin dataset.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 19:56:50 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Sewak", "Mohit", ""], ["Sahay", "Sanjay K.", ""], ["Rathore", "Hemant", ""]]}, {"id": "2010.08608", "submitter": "Mohit Sewak", "authors": "Mohit Sewak, Sanjay K. Sahay and Hemant Rathore", "title": "DOOM: A Novel Adversarial-DRL-Based Op-Code Level Metamorphic Malware\n  Obfuscator for the Enhancement of IDS", "comments": null, "journal-ref": null, "doi": "10.1145/3410530.3414411", "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We designed and developed DOOM (Adversarial-DRL based Opcode level Obfuscator\nto generate Metamorphic malware), a novel system that uses adversarial deep\nreinforcement learning to obfuscate malware at the op-code level for the\nenhancement of IDS. The ultimate goal of DOOM is not to give a potent weapon in\nthe hands of cyber-attackers, but to create defensive-mechanisms against\nadvanced zero-day attacks. Experimental results indicate that the obfuscated\nmalware created by DOOM could effectively mimic multiple-simultaneous zero-day\nattacks. To the best of our knowledge, DOOM is the first system that could\ngenerate obfuscated malware detailed to individual op-code level. DOOM is also\nthe first-ever system to use efficient continuous action control based deep\nreinforcement learning in the area of malware generation and defense.\nExperimental results indicate that over 67% of the metamorphic malware\ngenerated by DOOM could easily evade detection from even the most potent IDS.\nThis achievement gains significance, as with this, even IDS augment with\nadvanced routing sub-system can be easily evaded by the malware generated by\nDOOM.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 19:57:06 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Sewak", "Mohit", ""], ["Sahay", "Sanjay K.", ""], ["Rathore", "Hemant", ""]]}, {"id": "2010.08688", "submitter": "Takao Murakami", "authors": "Jacob Imola and Takao Murakami and Kamalika Chaudhuri", "title": "Locally Differentially Private Analysis of Graph Statistics", "comments": "This is a full version of the paper accepted at USENIX Security 2021;\n  The first and second authors made equal contributions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentially private analysis of graphs is widely used for releasing\nstatistics from sensitive graphs while still preserving user privacy. Most\nexisting algorithms however are in a centralized privacy model, where a trusted\ndata curator holds the entire graph. As this model raises a number of privacy\nand security issues -- such as, the trustworthiness of the curator and the\npossibility of data breaches, it is desirable to consider algorithms in a more\ndecentralized local model where no server holds the entire graph.\n  In this work, we consider a local model, and present algorithms for counting\nsubgraphs -- a fundamental task for analyzing the connection patterns in a\ngraph -- with LDP (Local Differential Privacy). For triangle counts, we present\nalgorithms that use one and two rounds of interaction, and show that an\nadditional round can significantly improve the utility. For $k$-star counts, we\npresent an algorithm that achieves an order optimal estimation error in the\nnon-interactive local model. We provide new lower-bounds on the estimation\nerror for general graph statistics including triangle counts and $k$-star\ncounts. Finally, we perform extensive experiments on two real datasets, and\nshow that it is indeed possible to accurately estimate subgraph counts in the\nlocal differential privacy model.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 01:18:31 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 06:31:35 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Imola", "Jacob", ""], ["Murakami", "Takao", ""], ["Chaudhuri", "Kamalika", ""]]}, {"id": "2010.08730", "submitter": "Ziyao Liu", "authors": "Jiale Guo, Ziyao Liu, Kwok-Yan Lam, Jun Zhao, Yiqiang Chen, Chaoping\n  Xing", "title": "Secure Weighted Aggregation for Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pervasive adoption of Internet-connected digital services has led to a\ngrowing concern in the personal data privacy of their customers. On the other\nhand, machine learning (ML) techniques have been widely adopted by digital\nservice providers to improve operational productivity and customer\nsatisfaction. ML inevitably accesses and processes users' personal data, which\ncould potentially breach the relevant privacy protection regulations if not\nperformed carefully. The situation is exacerbated by the cloud-based\nimplementation of digital services when user data are captured and stored in\ndistributed locations, hence aggregation of the user data for ML could be a\nserious breach of privacy regulations. In this backdrop, Federated Learning\n(FL) is an emerging area that allows ML on distributed data without the data\nleaving their stored location. However, depending on the nature of the digital\nservices, data captured at different locations may carry different significance\nto the business operation, hence a weighted aggregation will be highly\ndesirable for enhancing the quality of the FL-learned model. Furthermore, to\nprevent leakage of user data from the aggregated gradients, cryptographic\nmechanisms are needed to allow secure aggregation of FL. In this paper, we\npropose a privacy-enhanced FL scheme for supporting secure weighted\naggregation. Besides, by devising a verification protocol based on\nZero-Knowledge Proof (ZKP), the proposed scheme is capable of guarding against\nfraudulent messages from FL participants. Experimental results show that our\nscheme is practical and secure. Compared to existing FL approaches, our scheme\nachieves secure weighted aggregation with an additional security guarantee\nagainst fraudulent messages with an affordable 1.2 times runtime overheads and\n1.3 times communication costs.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 07:13:06 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 18:42:30 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Guo", "Jiale", ""], ["Liu", "Ziyao", ""], ["Lam", "Kwok-Yan", ""], ["Zhao", "Jun", ""], ["Chen", "Yiqiang", ""], ["Xing", "Chaoping", ""]]}, {"id": "2010.08762", "submitter": "Fan Mo", "authors": "Fan Mo, Anastasia Borovykh, Mohammad Malekzadeh, Hamed Haddadi,\n  Soteris Demetriou", "title": "Layer-wise Characterization of Latent Information Leakage in Federated\n  Learning", "comments": "9 pages, at ICLR workshop (Distributed and Private Machine Learning)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks via federated learning allows clients to share,\ninstead of the original data, only the model trained on their data. Prior work\nhas demonstrated that in practice a client's private information, unrelated to\nthe main learning task, can be discovered from the model's gradients, which\ncompromises the promised privacy protection. However, there is still no formal\napproach for quantifying the leakage of private information via the shared\nupdated model or gradients. In this work, we analyze property inference attacks\nand define two metrics based on (i) an adaptation of the empirical\n$\\mathcal{V}$-information, and (ii) a sensitivity analysis using Jacobian\nmatrices allowing us to measure changes in the gradients with respect to latent\ninformation. We show the applicability of our proposed metrics in localizing\nprivate latent information in a layer-wise manner and in two settings where (i)\nwe have or (ii) we do not have knowledge of the attackers' capabilities. We\nevaluate the proposed metrics for quantifying information leakage on three\nreal-world datasets using three benchmark models.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 10:49:14 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 11:49:14 GMT"}, {"version": "v3", "created": "Wed, 20 Jan 2021 20:35:58 GMT"}, {"version": "v4", "created": "Sat, 29 May 2021 11:10:58 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Mo", "Fan", ""], ["Borovykh", "Anastasia", ""], ["Malekzadeh", "Mohammad", ""], ["Haddadi", "Hamed", ""], ["Demetriou", "Soteris", ""]]}, {"id": "2010.08769", "submitter": "Behrooz Khadem", "authors": "Behrooz Khadem, Amin Masoumi, M. S. Farash", "title": "A Key-Agreement Protocol Based on Static Parameters and Hash Functions", "comments": "13 pages,7 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless Body Sensor Network (WBSN) is a developing technology with\nconstraints in energy consumption, coverage radius, communication reliability.\nAlso, communications between nodes contain very sensitive personal information\nin which sometimes due to the presence of hostile environments, there are a\nwide range of security risks. As such, designing authenticated key agreement\n(AKA) protocols is an important challenge in these networks. Recently, Li et\nal. proposed a lightweight scheme using the hash and XOR functions which is\nmuch more efficient compared with similar schemes based on elliptic curve.\nHowever, the investigations revealed that the claim concerning the\nunlinkability between the sessions of a sensor node is NOT true. The present\npaper considers the security issues of the scheme proposed by Li et al. and\nsome of its new extensions in order to propose a new AKA scheme with anonymity\nand unlinkability of the sensor node sessions. The results of theoretical\nanalysis compared with similar schemes indicate that the proposed scheme\nreduces average energy consumption and average computation time by 61 percent\nwhile reduces the average communication cost by 41 percent. Further, it has\nbeen shown by formal and informal analysis that, Besides the two anonymity and\nunlinkability features, the other main features of the security in the proposed\nscheme are comparable and similar to the recent similar schemes.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 11:29:52 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Khadem", "Behrooz", ""], ["Masoumi", "Amin", ""], ["Farash", "M. S.", ""]]}, {"id": "2010.08852", "submitter": "Panagiotis Eustratiadis", "authors": "Panagiotis Eustratiadis, Henry Gouk, Da Li, Timothy Hospedales", "title": "Weight-Covariance Alignment for Adversarially Robust Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Neural Networks (SNNs) that inject noise into their hidden layers\nhave recently been shown to achieve strong robustness against adversarial\nattacks. However, existing SNNs are usually heuristically motivated, and often\nrely on adversarial training, which is computationally costly. We propose a new\nSNN that achieves state-of-the-art performance without relying on adversarial\ntraining, and enjoys solid theoretical justification. Specifically, while\nexisting SNNs inject learned or hand-tuned isotropic noise, our SNN learns an\nanisotropic noise distribution to optimize a learning-theoretic bound on\nadversarial robustness. We evaluate our method on a number of popular\nbenchmarks, show that it can be applied to different architectures, and that it\nprovides robustness to a variety of white-box and black-box attacks, while\nbeing simple and fast to train compared to existing alternatives.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 19:28:35 GMT"}, {"version": "v2", "created": "Mon, 24 May 2021 17:31:04 GMT"}, {"version": "v3", "created": "Wed, 26 May 2021 10:16:14 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Eustratiadis", "Panagiotis", ""], ["Gouk", "Henry", ""], ["Li", "Da", ""], ["Hospedales", "Timothy", ""]]}, {"id": "2010.08855", "submitter": "Aref Asvadishirehjini", "authors": "Aref Asvadishirehjini (1), Murat Kantarcioglu (1), Bradley Malin (2)\n  ((1) University of Texas at Dallas, (2) Vanderbilt University)", "title": "GOAT: GPU Outsourcing of Deep Learning Training With Asynchronous\n  Probabilistic Integrity Verification Inside Trusted Execution Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models based on Deep Neural Networks (DNNs) are increasingly\ndeployed in a wide range of applications ranging from self-driving cars to\nCOVID-19 treatment discovery. To support the computational power necessary to\nlearn a DNN, cloud environments with dedicated hardware support have emerged as\ncritical infrastructure. However, there are many integrity challenges\nassociated with outsourcing computation. Various approaches have been developed\nto address these challenges, building on trusted execution environments (TEE).\nYet, no existing approach scales up to support realistic integrity-preserving\nDNN model training for heavy workloads (deep architectures and millions of\ntraining examples) without sustaining a significant performance hit. To\nmitigate the time gap between pure TEE (full integrity) and pure GPU (no\nintegrity), we combine random verification of selected computation steps with\nsystematic adjustments of DNN hyper-parameters (e.g., a narrow gradient\nclipping range), hence limiting the attacker's ability to shift the model\nparameters significantly provided that the step is not selected for\nverification during its training phase. Experimental results show the new\napproach achieves 2X to 20X performance improvement over pure TEE based\nsolution while guaranteeing a very high probability of integrity (e.g., 0.999)\nwith respect to state-of-the-art DNN backdoor attacks.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 20:09:05 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Asvadishirehjini", "Aref", "", "University of Texas at Dallas"], ["Kantarcioglu", "Murat", "", "University of Texas at Dallas"], ["Malin", "Bradley", "", "Vanderbilt University"]]}, {"id": "2010.08901", "submitter": "Tien Vo-Huu", "authors": "Tien D. Vo-Huu, Triet D. Vo-Huu, Guevara Noubir", "title": "Spectrum-Flexible Secure Broadcast Ranging", "comments": "correct function name in figure 1; add protocol diagram in appendix;\n  move appendix to the end of paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secure ranging is poised to play a critical role in several emerging\napplications such as self-driving cars, unmanned aerial systems, wireless IoT\ndevices, and augmented reality. In this paper, we propose a design of a secure\nbroadcast ranging systems with unique features and techniques. Its\nspectral-flexibility, and low-power short ranging bursts enable co-existence\nwith existing systems such as in the 2.4GHz ISM band. We exploit a set of RF\ntechniques such as upsampling and successive interference cancellation to\nachieve high accuracy and scalability to tens of reflectors even when operating\nover narrow bands of spectrum. We demonstrate that it can be implemented on\npopular SDR platforms FPGA and/or hosts (with minimal FPGA modifications). The\nprotocol design, and cryptographically generated/detected signals, and\nrandomized timing of transmissions, provide stealth and security against denial\nof service, sniffing, and distance manipulation attacks. Through extensive\nexperimental evaluations (and simulations for scalability to over 100\nreflectors) we demonstrate an accuracy below 20cm on a wide range of SNR (as\nlow as 0dB), spectrum 25MHz-100MHz, with bursts as short as 5us.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 02:11:48 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 20:16:22 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Vo-Huu", "Tien D.", ""], ["Vo-Huu", "Triet D.", ""], ["Noubir", "Guevara", ""]]}, {"id": "2010.08915", "submitter": "Shiya Liu", "authors": "Shiya Liu, Yue Yao, Chaoyue Xing, and Tom Gedeon", "title": "Disguising Personal Identity Information in EEG Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a need to protect the personal identity information in public EEG\ndatasets. However, it is challenging to remove such information that has\ninfinite classes (open set). We propose an approach to disguise the identity\ninformation in EEG signals with dummy identities, while preserving the key\nfeatures. The dummy identities are obtained by applying grand average on EEG\nspectrums across the subjects within a group that have common attributes. The\npersonal identity information in original EEGs are transformed into disguised\nones with a CycleGANbased EEG disguising model. With the constraints added to\nthe model, the features of interest in EEG signals can be preserved. We\nevaluate the model by performing classification tasks on both the original and\nthe disguised EEG and compare the results. For evaluation, we also experiment\nwith ResNet classifiers, which perform well especially on the identity\nrecognition task with an accuracy of 98.4%. The results show that our EEG\ndisguising model can hide about 90% of personal identity information and can\npreserve most of the other key features.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 03:55:38 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Liu", "Shiya", ""], ["Yao", "Yue", ""], ["Xing", "Chaoyue", ""], ["Gedeon", "Tom", ""]]}, {"id": "2010.08958", "submitter": "Wen Huang", "authors": "Wen Huang, Shijie Zhou, Yongjian Liao", "title": "Unexpected Information Leakage of Differential Privacy Due to Linear\n  Property of Queries", "comments": "14 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The differential privacy is a widely accepted conception of privacy\npreservation and the Laplace mechanism is a famous instance of differential\nprivacy mechanisms to deal with numerical data. In this paper, we find that the\ndifferential privacy does not take liner property of queries into account,\nresulting in unexpected information leakage. In specific, the linear property\nmakes it possible to divide one query into two queries such as\n$q(D)=q(D_1)+q(D_2)$ if $D=D_1\\cup D_2$ and $D_1\\cap D_2=\\emptyset$. If\nattackers try to obtain an answer of $q(D)$, they not only can issue the query\n$q(D)$, but also can issue the $q(D_1)$ and calculate the $q(D_2)$ by\nthemselves as long as they know $D_2$. By different divisions of one query,\nattackers can obtain multiple different answers for the query from differential\nprivacy mechanisms. However, from attackers' perspective and from differential\nprivacy mechanisms' perspective, the totally consumed privacy budget is\ndifferent if divisions are delicately designed. The difference leads to\nunexpected information leakage because the privacy budget is the key parameter\nto control the amount of legally released information from differential privacy\nmechanisms. In order to demonstrate the unexpected information leakage, we\npresent a membership inference attacks against the Laplace mechanism.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 10:53:31 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Huang", "Wen", ""], ["Zhou", "Shijie", ""], ["Liao", "Yongjian", ""]]}, {"id": "2010.09063", "submitter": "Gautam Kamath", "authors": "Pranav Subramani, Nicholas Vadivelu, Gautam Kamath", "title": "Enabling Fast Differentially Private SGD via Just-in-Time Compilation\n  and Vectorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common pain point in differentially private machine learning is the\nsignificant runtime overhead incurred when executing Differentially Private\nStochastic Gradient Descent (DPSGD), which may be as large as two orders of\nmagnitude. We thoroughly demonstrate that by exploiting powerful language\nprimitives, including vectorization, just-in-time compilation, and static graph\noptimization, one can dramatically reduce these overheads, in many cases nearly\nmatching the best non-private running times. These gains are realized in two\nframeworks: JAX and TensorFlow. JAX provides rich support for these primitives\nas core features of the language through the XLA compiler. We also rebuild core\nparts of TensorFlow Privacy, integrating features from TensorFlow 2 as well as\nXLA compilation, granting significant memory and runtime improvements over the\ncurrent release version. These approaches allow us to achieve up to 50x\nspeedups in comparison to the best alternatives. Our code is available at\nhttps://github.com/TheSalon/fast-dpsgd.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 18:45:04 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Subramani", "Pranav", ""], ["Vadivelu", "Nicholas", ""], ["Kamath", "Gautam", ""]]}, {"id": "2010.09080", "submitter": "Mingjie Sun", "authors": "Mingjie Sun, Siddhant Agarwal, J. Zico Kolter", "title": "Poisoned classifiers are not only backdoored, they are fundamentally\n  broken", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under a commonly-studied \"backdoor\" poisoning attack against classification\nmodels, an attacker adds a small \"trigger\" to a subset of the training data,\nsuch that the presence of this trigger at test time causes the classifier to\nalways predict some target class. It is often implicitly assumed that the\npoisoned classifier is vulnerable exclusively to the adversary who possesses\nthe trigger. In this paper, we show empirically that this view of backdoored\nclassifiers is fundamentally incorrect. We demonstrate that anyone with access\nto the classifier, even without access to any original training data or\ntrigger, can construct several alternative triggers that are as effective or\nmore so at eliciting the target class at test time. We construct these\nalternative triggers by first generating adversarial examples for a smoothed\nversion of the classifier, created with a recent process called Denoised\nSmoothing, and then extracting colors or cropped portions of adversarial\nimages. We demonstrate the effectiveness of our attack through extensive\nexperiments on ImageNet and TrojAI datasets, including a user study which\ndemonstrates that our method allows users to easily determine the existence of\nsuch backdoors in existing poisoned classifiers. Furthermore, we demonstrate\nthat our alternative triggers can in fact look entirely different from the\noriginal trigger, highlighting that the backdoor actually learned by the\nclassifier differs substantially from the trigger image itself. Thus, we argue\nthat there is no such thing as a \"secret\" backdoor in poisoned classifiers:\npoisoning a classifier invites attacks not just by the party that possesses the\ntrigger, but from anyone with access to the classifier. Code is available at\nhttps://github.com/locuslab/breaking-poisoned-classifier.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 19:42:44 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Sun", "Mingjie", ""], ["Agarwal", "Siddhant", ""], ["Kolter", "J. Zico", ""]]}, {"id": "2010.09099", "submitter": "Paritosh Ramanan", "authors": "Paritosh Ramanan, Murat Yildirim, Nagi Gebraeel, Edmond Chow", "title": "Decentralized and Secure Generation Maintenance with Differential\n  Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized methods are gaining popularity for data-driven models in power\nsystems as they offer significant computational scalability while guaranteeing\nfull data ownership by utility stakeholders. However, decentralized methods\nstill require sharing information about network flow estimates over public\nfacing communication channels, which raises privacy concerns. In this paper we\npropose a differential privacy driven approach geared towards decentralized\nformulations of mixed integer operations and maintenance optimization problems\nthat protects network flow estimates. We prove strong privacy guarantees by\nleveraging the linear relationship between the phase angles and the flow. To\naddress the challenges associated with the mixed integer and dynamic nature of\nthe problem, we introduce an exponential moving average based consensus\nmechanism to enhance convergence, coupled with a control chart based\nconvergence criteria to improve stability. Our experimental results obtained on\nthe IEEE 118 bus case demonstrate that our privacy preserving approach yields\nsolution qualities on par with benchmark methods without differential privacy.\nTo demonstrate the computational robustness of our method, we conduct\nexperiments using a wide range of noise levels and operational scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 20:45:14 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Ramanan", "Paritosh", ""], ["Yildirim", "Murat", ""], ["Gebraeel", "Nagi", ""], ["Chow", "Edmond", ""]]}, {"id": "2010.09112", "submitter": "Ivan Homoliak Ph.D.", "authors": "Sarad Venugopalan, Ivan Homoliak, Zengpeng Li, Pawel Szalachowski", "title": "BBB-Voting: 1-out-of-k Blockchain-Based Boardroom Voting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voting is a means to agree on a collective decision based on available\nchoices (e.g., candidates), where participants (voters) agree to abide by their\noutcome. To improve some features of e-voting, decentralized solutions based on\na blockchain can be employed, where the blockchain represents a public bulletin\nboard that in contrast to a centralized bulletin board provides $100\\%$\navailability and censorship resistance. A blockchain ensures that all entities\nin the voting system have the same view of the actions made by others due to\nits immutable and append-only log. The existing blockchain-based boardroom\nvoting solution called Open Voting Network (OVN) provides the privacy of votes\nand perfect ballot secrecy, but it supports only two candidates. We present\nBBB-Voting, an equivalent blockchain-based approach for decentralized voting\nthan OVN, but in contrast to it, BBB-Voting supports 1-out-of-$k$ choices and\nprovides a fault tolerance mechanism that enables recovery from stalling\nparticipants. We provide a cost-optimized implementation using Ethereum, which\nwe compare with OVN and show that our work decreases the costs for voters by\n$13.5\\%$ in terms of gas consumption. Next, we outline the extension of our\nimplementation scaling to magnitudes higher number of participants than in a\nboardroom voting, while preserving the costs paid by the authority and\nparticipants -- we made proof-of-concept experiments with up to 1000\nparticipants.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 21:34:58 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 20:51:18 GMT"}, {"version": "v3", "created": "Thu, 15 Jul 2021 14:21:12 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Venugopalan", "Sarad", ""], ["Homoliak", "Ivan", ""], ["Li", "Zengpeng", ""], ["Szalachowski", "Pawel", ""]]}, {"id": "2010.09212", "submitter": "Jiangnan Li", "authors": "Jiangnan Li, Yingyuan Yang, Jinyuan Stella Sun", "title": "Exploiting Vulnerabilities of Deep Learning-based Energy Theft Detection\n  in AMI through Adversarial Attacks", "comments": "arXiv admin note: text overlap with arXiv:2006.03504", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective detection of energy theft can prevent revenue losses of utility\ncompanies and is also important for smart grid security. In recent years,\nenabled by the massive fine-grained smart meter data, deep learning (DL)\napproaches are becoming popular in the literature to detect energy theft in the\nadvanced metering infrastructure (AMI). However, as neural networks are shown\nto be vulnerable to adversarial examples, the security of the DL models is of\nconcern.\n  In this work, we study the vulnerabilities of DL-based energy theft detection\nthrough adversarial attacks, including single-step attacks and iterative\nattacks. From the attacker's point of view, we design the\n\\textit{SearchFromFree} framework that consists of 1) a randomly adversarial\nmeasurement initialization approach to maximize the stolen profit and 2) a\nstep-size searching scheme to increase the performance of black-box iterative\nattacks. The evaluation based on three types of neural networks shows that the\nadversarial attacker can report extremely low consumption measurements to the\nutility without being detected by the DL models. We finally discuss the\npotential defense mechanisms against adversarial attacks in energy theft\ndetection.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 02:25:40 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Li", "Jiangnan", ""], ["Yang", "Yingyuan", ""], ["Sun", "Jinyuan Stella", ""]]}, {"id": "2010.09246", "submitter": "Asaf Shabtai", "authors": "Elior Nehemya and Yael Mathov and Asaf Shabtai and Yuval Elovici", "title": "When Bots Take Over the Stock Market: Evasion Attacks Against\n  Algorithmic Traders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, machine learning has become prevalent in numerous tasks,\nincluding algorithmic trading. Stock market traders utilize learning models to\npredict the market's behavior and execute an investment strategy accordingly.\nHowever, learning models have been shown to be susceptible to input\nmanipulations called adversarial examples. Yet, the trading domain remains\nlargely unexplored in the context of adversarial learning. This is mainly\nbecause of the rapid changes in the market which impair the attacker's ability\nto create a real-time attack. In this study, we present a realistic scenario in\nwhich an attacker gains control of an algorithmic trading bots by manipulating\nthe input data stream in real-time. The attacker creates an universal\nperturbation that is agnostic to the target model and time of use, while also\nremaining imperceptible. We evaluate our attack on a real-world market data\nstream and target three different trading architectures. We show that our\nperturbation can fool the model at future unseen data points, in both white-box\nand black-box settings. We believe these findings should serve as an alert to\nthe finance community about the threats in this area and prompt further\nresearch on the risks associated with using automated learning models in the\nfinance domain.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 06:28:05 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Nehemya", "Elior", ""], ["Mathov", "Yael", ""], ["Shabtai", "Asaf", ""], ["Elovici", "Yuval", ""]]}, {"id": "2010.09293", "submitter": "Razane Tajeddine", "authors": "Razane Tajeddine, Joonas J\\\"alk\\\"o, Samuel Kaski, and Antti Honkela", "title": "Privacy-preserving Data Sharing on Vertically Partitioned Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we present a method for differentially private data sharing by\ntraining a mixture model on vertically partitioned data, where each party holds\ndifferent features for the same set of individuals. We use secure multi-party\ncomputation (MPC) to combine the contribution of the data from the parties to\ntrain the model. We apply the differentially private variational inference\n(DPVI) for learning the model. Assuming the mixture components contain no\ndependencies across different parties, the objective function can be factorized\ninto a sum of products of individual components of each party. Therefore, each\nparty can calculate its shares on its own without the use of MPC. Then MPC is\nonly needed to get the product between the different shares and add the noise.\nApplying the method to demographic data from the US Census, we obtain\ncomparable accuracy to the non-partitioned case with approximately 20-fold\nincrease in computing time.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 08:10:34 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Tajeddine", "Razane", ""], ["J\u00e4lk\u00f6", "Joonas", ""], ["Kaski", "Samuel", ""], ["Honkela", "Antti", ""]]}, {"id": "2010.09303", "submitter": "Letterio Galletta", "authors": "Andrea Canidio and Gabriele Costa and Letterio Galletta", "title": "Private-Yet-Verifiable Contact Tracing", "comments": "Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose PrYVeCT, a private-yet-verifiable contact tracing system. PrYVeCT\nworks also as an authorization framework allowing for the definition of\nfine-grained policies, which a certain facility can define and apply to better\nmodel its own access rules. Users are authorized to access the facility only\nwhen they exhibit a contact trace that complies with the policy. The policy\nevaluation process is carried out without disclosing the personal data of the\nuser. At the same time, each user can prove to a third party (e.g., a public\nauthority) that she received a certain authorization. PrYVeCT takes advantage\nof oblivious automata evaluation to implement a privacy-preserving policy\nenforcement mechanism.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 08:24:21 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Canidio", "Andrea", ""], ["Costa", "Gabriele", ""], ["Galletta", "Letterio", ""]]}, {"id": "2010.09331", "submitter": "Philipp Jeitner", "authors": "Philipp Jeitner, Haya Shulman, Michael Waidner", "title": "Secure Consensus Generation with Distributed DoH", "comments": null, "journal-ref": "2020 50th Annual IEEE-IFIP International Conference on Dependable\n  Systems and Networks-Supplemental Volume (DSN-S), Valencia, Spain, 2020, pp.\n  41-42", "doi": "10.1109/DSN-S50200.2020.00023", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications and protocols depend on the ability to generate a pool of\nservers to conduct majority-based consensus mechanisms and often this is done\nby doing plain DNS queries. A recent off-path attack [1] against NTP and\nsecurity enhanced NTP with Chronos [2] showed that relying on DNS for\ngenerating the pool of NTP servers introduces a weak link. In this work, we\npropose a secure, backward-compatible address pool generation method using\ndistributed DNS-over-HTTPS (DoH) resolvers which is aimed to prevent such\nattacks against server pool generation.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 09:15:20 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Jeitner", "Philipp", ""], ["Shulman", "Haya", ""], ["Waidner", "Michael", ""]]}, {"id": "2010.09338", "submitter": "Philipp Jeitner", "authors": "Philipp Jeitner, Haya Shulman, Michael Waidner", "title": "The Impact of DNS Insecurity on Time", "comments": null, "journal-ref": "2020 50th Annual IEEE/IFIP International Conference on Dependable\n  Systems and Networks (DSN)", "doi": "10.1109/DSN48063.2020.00043", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate the first practical off-path time shifting attacks against NTP\nas well as against Man-in-the-Middle (MitM) secure Chronos-enhanced NTP. Our\nattacks exploit the insecurity of DNS allowing us to redirect the NTP clients\nto attacker controlled servers. We perform large scale measurements of the\nattack surface in NTP clients and demonstrate the threats to NTP due to\nvulnerable DNS.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 09:20:14 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Jeitner", "Philipp", ""], ["Shulman", "Haya", ""], ["Waidner", "Michael", ""]]}, {"id": "2010.09393", "submitter": "Yusuke Kawamoto", "authors": "Natasha Fernandes, Yusuke Kawamoto, Takao Murakami", "title": "Locality Sensitive Hashing with Extended Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.IR cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extended differential privacy, a generalization of standard differential\nprivacy (DP) using a general metric, has been widely studied to provide\nrigorous privacy guarantees while keeping high utility. However, existing works\non extended DP are limited to few metrics such as the Euclidean metric.\nConsequently, they have only a small number of applications such as\nlocation-based services and document processing. In this paper, we propose a\ncouple of mechanisms providing extended DP with a different metric: angular\ndistance (or cosine distance). Our mechanisms are based on locality sensitive\nhashing (LSH), which can be applied to the angular distance and work well for\npersonal data in a high-dimensional space. We theoretically analyze the privacy\nproperties of our mechanisms, and prove extended DP for input data by taking\ninto account that LSH preserves the original metric only approximately. We\napply our mechanisms to friend matching based on high-dimensional personal data\nwith angular distance in the local model, and evaluate our mechanisms using two\nreal datasets. We show that LDP requires a very large privacy budget and that\nRAPPOR does not work in this application. Then we show that our mechanisms\nenable friend matching with high utility and rigorous privacy guarantees based\non extended DP.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 11:30:51 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 13:35:28 GMT"}, {"version": "v3", "created": "Sun, 1 Nov 2020 03:26:13 GMT"}, {"version": "v4", "created": "Wed, 12 May 2021 12:58:24 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Fernandes", "Natasha", ""], ["Kawamoto", "Yusuke", ""], ["Murakami", "Takao", ""]]}, {"id": "2010.09410", "submitter": "Kotaro Matsuoka", "authors": "Kotaro Matsuoka, Ryotaro Banno, Naoki Matsumoto, Takashi Sato, Song\n  Bian", "title": "Virtual Secure Platform: A Five-Stage Pipeline Processor over TFHE", "comments": "Accepted in USENIX Security '21. This is a long version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present Virtual Secure Platform (VSP), the first comprehensive platform\nthat implements a multi-opcode general-purpose sequential processor over Fully\nHomomorphic Encryption (FHE) for Secure Multi-Party Computation (SMPC). VSP\nprotects both the data and functions on which the data are evaluated from the\nadversary in a secure computation offloading situation like cloud computing. We\nproposed a complete processor architecture with a five-stage pipeline, which\nimproves the performance of the VSP by providing more parallelism in circuit\nevaluation. In addition, we also designed a custom Instruction Set Architecture\n(ISA) to reduce the gate count of our processor, along with an entire set of\ntoolchains to ensure that arbitrary C programs can be compiled into our custom\nISA. In order to speed up instruction evaluation over VSP, CMUX Memory based\nROM and RAM constructions over FHE are also proposed. Our experiments show that\nboth the pipelined architecture and the CMUX Memory technique are effective in\nimproving the performance of the proposed processor. We provide an open-source\nimplementation of VSP which achieves a per-instruction latency of less than 1\nsecond. We demonstrate that compared to the best existing processor over FHE,\nour implementation runs nearly 1,600$\\times$ faster.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 12:13:08 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Matsuoka", "Kotaro", ""], ["Banno", "Ryotaro", ""], ["Matsumoto", "Naoki", ""], ["Sato", "Takashi", ""], ["Bian", "Song", ""]]}, {"id": "2010.09427", "submitter": "Gang Luo", "authors": "James Jin Kang, Mahdi Dibaei, Gang Luo, Wencheng Yang and Xi Zheng", "title": "A Privacy-Preserving Data Inference Framework for Internet of Health\n  Things Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy protection in electronic healthcare applications is an important\nconsideration due to the sensitive nature of personal health data. Internet of\nHealth Things (IoHT) networks have privacy requirements within a healthcare\nsetting. However, these networks have unique challenges and security\nrequirements (integrity, authentication, privacy and availability) must also be\nbalanced with the need to maintain efficiency in order to conserve battery\npower, which can be a significant limitation in IoHT devices and networks. Data\nare usually transferred without undergoing filtering or optimization, and this\ntraffic can overload sensors and cause rapid battery consumption when\ninteracting with IoHT networks. This consequently poses restrictions on the\npractical implementation of these devices. As a solution to address the issues,\nthis paper proposes a privacy-preserving two-tier data inference framework,\nthis can conserve battery consumption by reducing the data size required to\ntransmit through inferring the sensed data and can also protect the sensitive\ndata from leakage to adversaries. Results from experimental evaluations on\nprivacy show the validity of the proposed scheme as well as significant data\nsavings without compromising the accuracy of the data transmission, which\ncontributes to energy efficiency of IoHT sensor devices.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 12:40:04 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Kang", "James Jin", ""], ["Dibaei", "Mahdi", ""], ["Luo", "Gang", ""], ["Yang", "Wencheng", ""], ["Zheng", "Xi", ""]]}, {"id": "2010.09470", "submitter": "Daniel Arp", "authors": "Daniel Arp, Erwin Quiring, Feargus Pendlebury, Alexander Warnecke,\n  Fabio Pierazzi, Christian Wressnegger, Lorenzo Cavallaro, Konrad Rieck", "title": "Dos and Don'ts of Machine Learning in Computer Security", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing processing power of computing systems and the increasing\navailability of massive datasets, machine learning algorithms have led to major\nbreakthroughs in many different areas. This development has influenced computer\nsecurity, spawning a series of work on learning-based security systems, such as\nfor malware detection, vulnerability discovery, and binary code analysis.\nDespite great potential, machine learning in security is prone to subtle\npitfalls that undermine its performance and render learning-based systems\npotentially unsuitable for security tasks and practical deployment. In this\npaper, we look at this problem with critical eyes. First, we identify common\npitfalls in the design, implementation, and evaluation of learning-based\nsecurity systems. We conduct a longitudinal study of 30 papers from top-tier\nsecurity conferences within the past 10 years, confirming that these pitfalls\nare widespread in the current security literature. In an empirical analysis, we\nfurther demonstrate how individual pitfalls can lead to unrealistic performance\nand interpretations, obstructing the understanding of the security problem at\nhand. As a remedy, we derive a list of actionable recommendations to support\nresearchers and our community in avoiding pitfalls, promoting a sound design,\ndevelopment, evaluation, and deployment of learning-based systems for computer\nsecurity.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 13:09:31 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Arp", "Daniel", ""], ["Quiring", "Erwin", ""], ["Pendlebury", "Feargus", ""], ["Warnecke", "Alexander", ""], ["Pierazzi", "Fabio", ""], ["Wressnegger", "Christian", ""], ["Cavallaro", "Lorenzo", ""], ["Rieck", "Konrad", ""]]}, {"id": "2010.09512", "submitter": "David Goltzsche", "authors": "David Goltzsche, Tim Siebels, Lennard Golsch, R\\\"udiger Kapitza", "title": "Hector: Using Untrusted Browsers to Provision Web Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web applications are on the rise and rapidly evolve into more and more mature\nreplacements for their native counterparts. This disruptive trend is mainly\ndriven by the attainment of platform-independence and instant deployability. On\ntop of this, web browsers offer the opportunity for seamless browser-to-browser\ncommunication for distributed interaction.\n  In this paper, we present Hector, a novel web application framework that\ntransforms web browsers into a distributed application-centric computing\nplatform. Hector enables offloading application logic to users, thereby\nimproving user experience with lower latencies while generating less costs for\nservice providers. Following the programming paradigm of Function-as-a-Service,\napplications are decomposed into functions so they can be managed efficiently\nand deployed in a responsive, scalable and lightweight fashion. In case of\nclient-side resource shortage or unresponsive clients, execution falls back to\na traditional cloud-based infrastructure. Hector combines WebAssembly for\nmulti-language computations at near-native speed, WebRTC for browser-to-browser\ncommunication and trusted execution as provided by the Intel Software Guard\nExtensions so browsers can trust each other's computations. We evaluate Hector\nby implementing a digital assistant as well as a recommendation system. Our\nevaluation shows that Hector achieves lower end-user latencies while generating\nless costs than traditional deployments. Additionally, we show that Hector\nscales linearly with increasing client numbers and can cope well with\nunresponsive clients.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 13:46:32 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Goltzsche", "David", ""], ["Siebels", "Tim", ""], ["Golsch", "Lennard", ""], ["Kapitza", "R\u00fcdiger", ""]]}, {"id": "2010.09527", "submitter": "\\'Etienne Andr\\'e", "authors": "\\'Etienne Andr\\'e and Aleksander Kryukov", "title": "Parametric non-interference in timed automata", "comments": "This is the author version of the manuscript of the same name\n  published in the proceedings of the 25th International Conference on\n  Engineering of Complex Computer Systems (ICECCS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a notion of non-interference for timed automata (TAs) that allows\nto quantify the frequency of an attack; that is, we infer values of the minimal\ntime between two consecutive actions of the attacker, so that (s)he disturbs\nthe set of reachable locations. We also synthesize valuations for the timing\nconstants of the TA (seen as parameters) guaranteeing non-interference. We show\nthat this can reduce to reachability synthesis in parametric timed automata. We\napply our method to a model of the Fischer mutual exclusion protocol and obtain\npreliminary results.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 13:58:16 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Andr\u00e9", "\u00c9tienne", ""], ["Kryukov", "Aleksander", ""]]}, {"id": "2010.09569", "submitter": "Erwin Quiring", "authors": "Erwin Quiring, Lukas Pirch, Michael Reimsbach, Daniel Arp, Konrad\n  Rieck", "title": "Against All Odds: Winning the Defense Challenge in an Evasion\n  Competition with Diversification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning-based systems for malware detection operate in a hostile\nenvironment. Consequently, adversaries will also target the learning system and\nuse evasion attacks to bypass the detection of malware. In this paper, we\noutline our learning-based system PEberus that got the first place in the\ndefender challenge of the Microsoft Evasion Competition, resisting a variety of\nattacks from independent attackers. Our system combines multiple, diverse\ndefenses: we address the semantic gap, use various classification models, and\napply a stateful defense. This competition gives us the unique opportunity to\nexamine evasion attacks under a realistic scenario. It also highlights that\nexisting machine learning methods can be hardened against attacks by thoroughly\nanalyzing the attack surface and implementing concepts from adversarial\nlearning. Our defense can serve as an additional baseline in the future to\nstrengthen the research on secure learning.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 14:53:06 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Quiring", "Erwin", ""], ["Pirch", "Lukas", ""], ["Reimsbach", "Michael", ""], ["Arp", "Daniel", ""], ["Rieck", "Konrad", ""]]}, {"id": "2010.09642", "submitter": "Simone Raponi", "authors": "Muhammad Usman, Simone Raponi, Marwa Qaraqe, Gabriele Oligeri", "title": "KaFHCa: Key-establishment via Frequency Hopping Collisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The massive deployment of IoT devices being utilized by home automation,\nindustrial and military scenarios demands for high security and privacy\nstandards to be achieved through innovative solutions. This paper proposes\nKaFHCa, a crypto-less protocol that generates shared secret keys by combining\nrandom frequency hopping collisions and source indistinguishability\nindependently of the radio channel status. While other solutions tie the secret\nbit rate generation to the current radio channel conditions, thus becoming\nunpractical in static environments, KaFHCa guarantees almost the same secret\nbitrate independently of the channel conditions. KaFHCa generates shared\nsecrets through random collisions of the transmitter and the receiver in the\nradio spectrum, and leverages on the fading phenomena to achieve source\nindistinguishability, thus preventing unauthorized eavesdroppers from inferring\nthe key. The proposed solution is (almost) independent of the adversary\nposition, works under the conservative assumption of channel fading ({\\sigma} =\n8dB), and is capable of generating a secret key of 128 bits with less than 564\ntransmissions.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 16:36:27 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 08:45:18 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Usman", "Muhammad", ""], ["Raponi", "Simone", ""], ["Qaraqe", "Marwa", ""], ["Oligeri", "Gabriele", ""]]}, {"id": "2010.09670", "submitter": "Maksym Andriushchenko", "authors": "Francesco Croce, Maksym Andriushchenko, Vikash Sehwag, Edoardo\n  Debenedetti, Nicolas Flammarion, Mung Chiang, Prateek Mittal, Matthias Hein", "title": "RobustBench: a standardized adversarial robustness benchmark", "comments": "Version 2: 90+ evaluations, 60+ models, 5 leaderboards (Linf, L2,\n  common corruptions), significantly expanded analysis part (calibration,\n  fairness, privacy leakage, smoothness, transferability)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a research community, we are still lacking a systematic understanding of\nthe progress on adversarial robustness, which often makes it hard to identify\nthe most promising ideas in training robust models. A key challenge in\nbenchmarking robustness is that its evaluation is often error-prone, leading to\noverestimation of the true robustness of models. While adaptive attacks\ndesigned for a particular defense are a potential solution, they have to be\nhighly customized for particular models, which makes it difficult to compare\ndifferent methods. Our goal is to instead establish a standardized benchmark of\nadversarial robustness, which as accurately as possible reflects the robustness\nof the considered models within a reasonable computational budget. To evaluate\nthe robustness of models for our benchmark, we consider AutoAttack, an ensemble\nof white- and black-box attacks which was recently shown in a large-scale study\nto improve almost all robustness evaluations compared to the original\npublications. We also impose some restrictions on the admitted models to rule\nout defenses that only make gradient-based attacks ineffective without\nimproving actual robustness. Our leaderboard, hosted at\nhttps://robustbench.github.io/, contains evaluations of 90+ models and aims at\nreflecting the current state of the art on a set of well-defined tasks in\n$\\ell_\\infty$- and $\\ell_2$-threat models and on common corruptions, with\npossible extensions in the future. Additionally, we open-source the library\nhttps://github.com/RobustBench/robustbench that provides unified access to 60+\nrobust models to facilitate their downstream applications. Finally, based on\nthe collected models, we analyze the impact of robustness on the performance on\ndistribution shifts, calibration, out-of-distribution detection, fairness,\nprivacy leakage, smoothness, and transferability.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 17:06:18 GMT"}, {"version": "v2", "created": "Sat, 12 Jun 2021 13:50:59 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Croce", "Francesco", ""], ["Andriushchenko", "Maksym", ""], ["Sehwag", "Vikash", ""], ["Debenedetti", "Edoardo", ""], ["Flammarion", "Nicolas", ""], ["Chiang", "Mung", ""], ["Mittal", "Prateek", ""], ["Hein", "Matthias", ""]]}, {"id": "2010.09680", "submitter": "Ehsan Nowroozi", "authors": "Ehsan Nowroozi, Ali Dehghantanha, Reza M. Parizi, Kim-Kwang Raymond\n  Choo", "title": "A Survey of Machine Learning Techniques in Adversarial Image Forensics", "comments": "37 pages, 24 figures, Accepted to the Journal Computer and Security\n  (Elsevier)", "journal-ref": "2020", "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image forensic plays a crucial role in both criminal investigations (e.g.,\ndissemination of fake images to spread racial hate or false narratives about\nspecific ethnicity groups) and civil litigation (e.g., defamation).\nIncreasingly, machine learning approaches are also utilized in image forensics.\nHowever, there are also a number of limitations and vulnerabilities associated\nwith machine learning-based approaches, for example how to detect adversarial\n(image) examples, with real-world consequences (e.g., inadmissible evidence, or\nwrongful conviction). Therefore, with a focus on image forensics, this paper\nsurveys techniques that can be used to enhance the robustness of machine\nlearning-based binary manipulation detectors in various adversarial scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 17:16:38 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Nowroozi", "Ehsan", ""], ["Dehghantanha", "Ali", ""], ["Parizi", "Reza M.", ""], ["Choo", "Kim-Kwang Raymond", ""]]}, {"id": "2010.09767", "submitter": "Amani Abu Jabal", "authors": "Amani Abu Jabal, Elisa Bertino, Jorge Lobo, Dinesh Verma, Seraphin\n  Calo, Alessandra Russo", "title": "FLAP -- A Federated Learning Framework for Attribute-based Access\n  Control Policies", "comments": "Presented at AAAI FSS-20: Artificial Intelligence in Government and\n  Public Sector, Washington, DC, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technology advances in areas such as sensors, IoT, and robotics, enable new\ncollaborative applications (e.g., autonomous devices). A primary requirement\nfor such collaborations is to have a secure system which enables information\nsharing and information flow protection. Policy-based management system is a\nkey mechanism for secure selective sharing of protected resources. However,\npolicies in each party of such a collaborative environment cannot be static as\nthey have to adapt to different contexts and situations. One advantage of\ncollaborative applications is that each party in the collaboration can take\nadvantage of knowledge of the other parties for learning or enhancing its own\npolicies. We refer to this learning mechanism as policy transfer. The design of\na policy transfer framework has challenges, including policy conflicts and\nprivacy issues. Policy conflicts typically arise because of differences in the\nobligations of the parties, whereas privacy issues result because of data\nsharing constraints for sensitive data. Hence, the policy transfer framework\nshould be able to tackle such challenges by considering minimal sharing of data\nand support policy adaptation to address conflict. In the paper we propose a\nframework that aims at addressing such challenges. We introduce a formal\ndefinition of the policy transfer problem for attribute-based policies. We then\nintroduce the transfer methodology that consists of three sequential steps.\nFinally we report experimental results.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 18:12:58 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 20:59:56 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Jabal", "Amani Abu", ""], ["Bertino", "Elisa", ""], ["Lobo", "Jorge", ""], ["Verma", "Dinesh", ""], ["Calo", "Seraphin", ""], ["Russo", "Alessandra", ""]]}, {"id": "2010.09843", "submitter": "Sruti Bhagavatula", "authors": "Sruti Bhagavatula, Lujo Bauer, Apu Kapadia", "title": "What breach? Measuring online awareness of security incidents by\n  studying real-world browsing behavior", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Awareness about security and privacy risks is important for developing good\nsecurity habits. Learning about real-world security incidents and data breaches\ncan alert people to the ways in which their information is vulnerable online,\nthus playing a significant role in encouraging safe security behavior. This\npaper examines 1) how often people read about security incidents online, 2) of\nthose people, whether and to what extent they follow up with an action, e.g.,\nby trying to read more about the incident, and 3) what influences the\nlikelihood that they will read about an incident and take some action. We study\nthis by quantitatively examining real-world internet-browsing data from 303\nparticipants.\n  Our findings present a bleak view of awareness of security incidents. Only\n16% of participants visited any web pages related to six widely publicized\nlarge-scale security incidents; few read about one even when an incident was\nlikely to have affected them (e.g., the Equifax breach almost universally\naffected people with Equifax credit reports). We further found that more severe\nincidents as well as articles that constructively spoke about the incident\ninspired more action. We conclude with recommendations for specific future\nresearch and for enabling useful security incident information to reach more\npeople.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 20:34:19 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 01:35:29 GMT"}, {"version": "v3", "created": "Thu, 5 Nov 2020 00:16:26 GMT"}, {"version": "v4", "created": "Thu, 27 May 2021 18:36:25 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Bhagavatula", "Sruti", ""], ["Bauer", "Lujo", ""], ["Kapadia", "Apu", ""]]}, {"id": "2010.09853", "submitter": "Sruti Bhagavatula", "authors": "Sruti Bhagavatula, Lujo Bauer, Apu Kapadia", "title": "(How) Do people change their passwords after a breach?", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To protect against misuse of passwords compromised in a breach, consumers\nshould promptly change affected passwords and any similar passwords on other\naccounts. Ideally, affected companies should strongly encourage this behavior\nand have mechanisms in place to mitigate harm. In order to make recommendations\nto companies about how to help their users perform these and other\nsecurity-enhancing actions after breaches, we must first have some\nunderstanding of the current effectiveness of companies' post-breach practices.\nTo study the effectiveness of password-related breach notifications and\npractices enforced after a breach, we examine---based on real-world password\ndata from 249 participants---whether and how constructively participants\nchanged their passwords after a breach announcement.\n  Of the 249 participants, 63 had accounts on breached domains; only 33% of the\n63 changed their passwords and only 13% (of 63) did so within three months of\nthe announcement. New passwords were on average 1.3x stronger than old\npasswords (when comparing log10-transformed strength), though most were weaker\nor of equal strength. Concerningly, new passwords were overall more similar to\nparticipants' other passwords, and participants rarely changed passwords on\nother sites even when these were the same or similar to their password on the\nbreached domain. Our results highlight the need for more rigorous\npassword-changing requirements following a breach and more effective breach\nnotifications that deliver comprehensive advice.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 20:44:25 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Bhagavatula", "Sruti", ""], ["Bauer", "Lujo", ""], ["Kapadia", "Apu", ""]]}, {"id": "2010.09929", "submitter": "Gautam Kamath", "authors": "Ishaq Aden-Ali, Hassan Ashtiani, Gautam Kamath", "title": "On the Sample Complexity of Privately Learning Unbounded\n  High-Dimensional Gaussians", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.DS cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide sample complexity upper bounds for agnostically learning\nmultivariate Gaussians under the constraint of approximate differential\nprivacy. These are the first finite sample upper bounds for general Gaussians\nwhich do not impose restrictions on the parameters of the distribution. Our\nbounds are near-optimal in the case when the covariance is known to be the\nidentity, and conjectured to be near-optimal in the general case. From a\ntechnical standpoint, we provide analytic tools for arguing the existence of\nglobal \"locally small\" covers from local covers of the space. These are\nexploited using modifications of recent techniques for differentially private\nhypothesis selection. Our techniques may prove useful for privately learning\nother distribution classes which do not possess a finite cover.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 23:55:03 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Aden-Ali", "Ishaq", ""], ["Ashtiani", "Hassan", ""], ["Kamath", "Gautam", ""]]}, {"id": "2010.09968", "submitter": "Farhad Farokhi", "authors": "Farhad Farokhi and Girish Nair", "title": "Non-Stochastic Private Function Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider private function evaluation to provide query responses based on\nprivate data of multiple untrusted entities in such a way that each cannot\nlearn something substantially new about the data of others. First, we introduce\nperfect non-stochastic privacy in a two-party scenario. Perfect privacy amounts\nto conditional unrelatedness of the query response and the private uncertain\nvariable of other individuals conditioned on the uncertain variable of a given\nentity. We show that perfect privacy can be achieved for queries that are\nfunctions of the common uncertain variable, a generalization of the common\nrandom variable. We compute the closest approximation of the queries that do\nnot take this form. To provide a trade-off between privacy and utility, we\nrelax the notion of perfect privacy. We define almost perfect privacy and show\nthat this new definition equates to using conditional disassociation instead of\nconditional unrelatedness in the definition of perfect privacy. Then, we\ngeneralize the definitions to multi-party function evaluation (more than two\ndata entities). We prove that uniform quantization of query responses, where\nthe quantization resolution is a function of privacy budget and sensitivity of\nthe query (cf., differential privacy), achieves function evaluation privacy.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 02:34:36 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Farokhi", "Farhad", ""], ["Nair", "Girish", ""]]}, {"id": "2010.10002", "submitter": "Tzonelih Hwang", "authors": "Jun Gu and Tzonelih Hwang", "title": "Collusion attack and counterattack on the quantum key agreement via\n  non-maximally entangled cluster states", "comments": null, "journal-ref": null, "doi": "10.1007/s10773-020-04695-8", "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Li et al. (Int J Theor Phys: DOI: 10.1007/s10773-020-04588-w, 2020)\nproposed a multiparty quantum key agreement protocol via non-maximally\nentangled cluster states. They claimed that the proposed protocol can help all\nthe involved participants have equal influence on the final shared key.\nHowever, this study points out a loophole that makes Li et al.'s protocol\nsuffer from a collusion attack, i.e. several dishonest participants can\nconspire to manipulate the final shared key without being detected by others.\nTo avoid this loophole, an improvement is proposed here.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 04:21:01 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Gu", "Jun", ""], ["Hwang", "Tzonelih", ""]]}, {"id": "2010.10088", "submitter": "Platon Kotzias", "authors": "Platon Kotzias, Juan Caballero, Leyla Bilge", "title": "How Did That Get In My Phone? Unwanted App Distribution on Android\n  Devices", "comments": "17 pages, 3 figures, to be published at 42nd IEEE Symposium on\n  Security and Privacy, 23-27 May 2021, San Fransisco, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Android is the most popular operating system with billions of active devices.\nUnfortunately, its popularity and openness makes it attractive for unwanted\napps, i.e., malware and potentially unwanted programs (PUP). In Android, app\ninstallations typically happen via the official and alternative markets, but\nalso via other smaller and less understood alternative distribution vectors\nsuch as Web downloads, pay-per-install (PPI) services, backup restoration,\nbloatware, and IM tools. This work performs a thorough investigation on\nunwanted app distribution by quantifying and comparing distribution through\ndifferent vectors. At the core of our measurements are reputation logs of a\nlarge security vendor, which include 7.9M apps observed in 12M devices between\nJune and September 2019. As a first step, we measure that between 10% and 24%\nof users devices encounter at least one unwanted app, and compare the\nprevalence of malware and PUP. An analysis of the who-installs-who\nrelationships between installers and child apps reveals that the Play market is\nthe main app distribution vector, responsible for 87% of all installs and 67%\nof unwanted app installs, but it also has the best defenses against unwanted\napps. Alternative markets distribute instead 5.7% of all apps, but over 10% of\nunwanted apps. Bloatware is also a significant unwanted app distribution vector\nwith 6% of those installs. And, backup restoration is an unintentional\ndistribution vector that may even allow unwanted apps to survive users' phone\nreplacement. We estimate unwanted app distribution via PPI to be smaller than\non Windows. Finally, we observe that Web downloads are rare, but provide a\nriskier proposition even compared to alternative markets.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 07:28:15 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Kotzias", "Platon", ""], ["Caballero", "Juan", ""], ["Bilge", "Leyla", ""]]}, {"id": "2010.10139", "submitter": "Radhakrishna Achanta", "authors": "Mathilde Raynal and Radhakrishna Achanta and Mathias Humbert", "title": "Image Obfuscation for Privacy-Preserving Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy becomes a crucial issue when outsourcing the training of machine\nlearning (ML) models to cloud-based platforms offering machine-learning\nservices. While solutions based on cryptographic primitives have been\ndeveloped, they incur a significant loss in accuracy or training efficiency,\nand require modifications to the backend architecture. A key challenge we\ntackle in this paper is the design of image obfuscation schemes that provide\nenough privacy without significantly degrading the accuracy of the ML model and\nthe efficiency of the training process. In this endeavor, we address another\nchallenge that has persisted so far: quantifying the degree of privacy provided\nby visual obfuscation mechanisms. We compare the ability of state-of-the-art\nfull-reference quality metrics to concur with human subjects in terms of the\ndegree of obfuscation introduced by a range of techniques. By relying on user\nsurveys and two image datasets, we show that two existing image quality metrics\nare also well suited to measure the level of privacy in accordance with human\nsubjects as well as AI-based recognition, and can therefore be used for\nquantifying privacy resulting from obfuscation. With the ability to quantify\nprivacy, we show that we can provide adequate privacy protection to the\ntraining image set at the cost of only a few percentage points loss in\naccuracy.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 09:11:21 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Raynal", "Mathilde", ""], ["Achanta", "Radhakrishna", ""], ["Humbert", "Mathias", ""]]}, {"id": "2010.10140", "submitter": "Dazhuang Liu", "authors": "Ru Zhang (1), Sheng Zou (1), Jianyi Liu (1), Bingjie Lin (2) and\n  Dazhuang Liu (1) ((1) Beijing University of Posts and Telecommunications, (2)\n  State Grid Information & Telecommunication Branch)", "title": "Constructing feature variation coefficients to evaluate feature learning\n  capabilities of convolutional layers in steganographic detection algorithms\n  of spatial domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional steganalysis methods generally include two steps: feature\nextraction and classification.A variety of steganalysis algorithms based on CNN\n(Convolutional Neural Network) have appeared in recent years. Among them, the\nconvolutional layer of the CNN model is usually used to extract steganographic\nfeatures, and the fully connected layer is used for classification. Because the\neffectiveness of feature extraction seriously influences the accuracy of\nclassification, designers generally improve the accuracy of steganographic\ndetection by improving the convolutional layer. For example, common optimizing\nmethods in convolutional layer include the improvement of convolution kernel,\nactivation functions, pooling functions, network structures, etc. However, due\nto the complexity and unexplainability of convolutional layers, it is difficult\nto quantitatively analyze and compare the effectiveness of feature extraction.\nTherefore, this paper proposes the variation coefficient to evaluate the\nfeature learning ability of convolutional layers. We select four typical image\nsteganalysis models based CNN in spatial domain, such as Ye-Net, Yedroudj-Net,\nZhu-Net, and SR-Net as use cases, and verify the validity of the variation\ncoefficient through experiments. Moreover, according to the variation\ncoefficient , a features modification layer is used to optimize the features\nbefore the fully connected layer of the CNN model , and the experimental\nresults show that the detection accuracy of the four algorithms were improved\ndifferently.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 09:11:33 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Zhang", "Ru", ""], ["Zou", "Sheng", ""], ["Liu", "Jianyi", ""], ["Lin", "Bingjie", ""], ["Liu", "Dazhuang", ""]]}, {"id": "2010.10170", "submitter": "Eman Alashwali", "authors": "Eman Salem Alashwali and Pawel Szalachowski and Andrew Martin", "title": "Exploring HTTPS Security Inconsistencies: A Cross-Regional Perspective", "comments": null, "journal-ref": "Computers & Security, vol. 97, no. 101975, 2020", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If two or more identical HTTPS clients, located at different geographic\nlocations (regions), make an HTTPS request to the same domain (e.g.\nexample.com), on the same day, will they receive the same HTTPS security\nguarantees in response? Our results give evidence that this is not always the\ncase. We conduct scans for the top 250,000 most visited domains on the\nInternet, from clients located at five different regions: Australia, Brazil,\nIndia, the UK, and the US. Our scans gather data from both application (URLs\nand HTTP headers) and transport (servers' selected TLS version, ciphersuite,\nand certificate) layers. Overall, we find that HTTPS inconsistencies at the\napplication layer are higher than those at the transport layer. We also find\nthat HTTPS security inconsistencies are strongly related to URLs and IPs\ndiversity among regions, and to a lesser extent to the presence of\nredirections. Further manual inspection shows that there are several reasons\nbehind URLs diversity among regions such as downgrading to the plain-HTTP\nprotocol, using different subdomains, different TLDs, or different home page\ndocuments. Furthermore, we find that downgrading to plain-HTTP is related to\nwebsites' regional blocking. We also provide attack scenarios that show how an\nattacker can benefit from HTTPS security inconsistencies, and introduce a new\nattack scenario which we call the \"region confusion\" attack. Finally, based on\nour analysis and observations, we provide discussion, which include some\nrecommendations such as the need for testing tools for domain administrators\nand users that help to mitigate and detect regional domains' inconsistencies,\nstandardising regional domains format with the same-origin policy (of domains)\nin mind, standardising secure URL redirections, and avoid redirections whenever\npossible.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 10:06:19 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Alashwali", "Eman Salem", ""], ["Szalachowski", "Pawel", ""], ["Martin", "Andrew", ""]]}, {"id": "2010.10236", "submitter": "Tzonelih Hwang", "authors": "Jun Gu and Tzonelih Hwang", "title": "On the lightweight authenticated semi-quantum key distribution protocol\n  without Trojan horse attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Tsai et al. (Laser Phys. Lett. 17, 075202, 2020) proposed a\nlightweight authenticated semi-quantum key distribution protocol for a quantum\nparticipant to share a secret key with a classical participant. However, this\nstudy points out that an attacker can use a modification attack to make both\nparticipants share a wrong key without being detected. To avoid this problem,\nan improvement is proposed here.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 12:58:47 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Gu", "Jun", ""], ["Hwang", "Tzonelih", ""]]}, {"id": "2010.10285", "submitter": "Pankaj Khatiwada", "authors": "Ayan Chatterjee, Ali Shahaab, Martin W. Gerdes, Santiago Martinez, and\n  Pankaj Khatiwada", "title": "Leveraging Technology for Healthcare and Retaining Access to Personal\n  Health Data to Enhance Personal Health and Well-being", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Health data is a sensitive category of personal data. It might result in a\nhigh risk to individual and health information handling rights and\nopportunities unless there is a palatable defense. Reasonable security\nstandards are needed to protect electronic health records (EHR). All personal\ndata handling needs adequate explanation. Maintaining access to medical data\neven in the developing world would favor health and well-being across the\nworld. Unfortunately, there are still countries that hinder the portability of\nmedical records. Numerous occurrences have shown that it still takes weeks for\nthe medical data to be ported from one general physician (GP) to another. Cross\nborder portability is nearly impossible due to the lack of technical\ninfrastructure and standardization. We demonstrate the difficulty of the\nportability of medical records with some example case studies as a\ncollaborative engagement exercise through a data mapping process to describe\nhow different people and datapoints interact and evaluate EHR portability\ntechniques. We then propose a blockchain-based EHR system that allows secure,\nand cross border sharing of medical data. The ethical and technical challenges\naround having such a system have also been discussed in this study.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 13:56:15 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Chatterjee", "Ayan", ""], ["Shahaab", "Ali", ""], ["Gerdes", "Martin W.", ""], ["Martinez", "Santiago", ""], ["Khatiwada", "Pankaj", ""]]}, {"id": "2010.10294", "submitter": "Vasilios Mavroudis Mr", "authors": "Vasilios Mavroudis, Jamie Hayes", "title": "Adaptive Traffic Fingerprinting: Large-scale Inference under Realistic\n  Assumptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread adoption of encrypted communications (e.g., the TLS protocol,\nthe Tor anonymity network) fixed several critical security flaws and shielded\nthe end-users from adversaries intercepting their transmitted data. While these\nprotocols are very effective in protecting the confidentiality of the users'\ndata (e.g., credit card numbers), it has been shown that they are prone (to\ndifferent degrees) to adversaries aiming to breach the users' privacy. Traffic\nfingerprinting attacks allow an adversary to infer the webpage or the website\nloaded by a user based only on patterns in the user's encrypted traffic. In\nfact, many recent works managed to achieve a very high classification accuracy\nunder optimal conditions for the adversary.\n  This paper revisits the optimality assumptions made by those works and\ndiscusses various additional parameters that should be considered when\nevaluating a fingerprinting model. We propose three realistic scenarios\nsimulating non-optimal fingerprinting conditions where various factors could\naffect the adversary's performance or operation. We then introduce a novel\nadaptive fingerprinting adversary and experimentally evaluate its accuracy and\noperation. Our experiments show that adaptive adversaries can reliably uncover\nthe webpage visited by a user among several thousand potential pages, even\nunder considerable distributional shift (e.g., the webpage contents change\nsignificantly over time). Such adversaries could infer the products a user\nbrowses on shopping websites or log the browsing habits of state dissidents on\nonline forums and encyclopedias. Our technique achieves ~90% accuracy in a\ntop-15 setting where the model distinguishes the article visited out of 6,000\nWikipedia webpages, while the same model achieves ~80% accuracy in a dataset of\n13,000 classes that were not included in the training set.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 15:13:07 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Mavroudis", "Vasilios", ""], ["Hayes", "Jamie", ""]]}, {"id": "2010.10334", "submitter": "Spyridon Mastorakis", "authors": "Spyridon Mastorakis, Xin Zhong, Pei-Chi Huang, Reza Tourani", "title": "DLWIoT: Deep Learning-based Watermarking for Authorized IoT Onboarding", "comments": "7 pages. This paper has been accepted for publication by the 18th\n  IEEE Annual Consumer Communications & Networking Conference (CCNC). The\n  copyright is with the IEEE. arXiv admin note: text overlap with\n  arXiv:2007.02460", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The onboarding of IoT devices by authorized users constitutes both a\nchallenge and a necessity in a world, where the number of IoT devices and the\ntampering attacks against them continuously increase. Commonly used onboarding\ntechniques today include the use of QR codes, pin codes, or serial numbers.\nThese techniques typically do not protect against unauthorized device access-a\nQR code is physically printed on the device, while a pin code may be included\nin the device packaging. As a result, any entity that has physical access to a\ndevice can onboard it onto their network and, potentially, tamper it\n(e.g.,install malware on the device). To address this problem, in this paper,\nwe present a framework, called Deep Learning-based Watermarking for authorized\nIoT onboarding (DLWIoT), featuring a robust and fully automated image\nwatermarking scheme based on deep neural networks. DLWIoT embeds user\ncredentials into carrier images (e.g., QR codes printed on IoT devices), thus\nenables IoT onboarding only by authorized users. Our experimental results\ndemonstrate the feasibility of DLWIoT, indicating that authorized users can\nonboard IoT devices with DLWIoT within 2.5-3sec.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 03:47:36 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Mastorakis", "Spyridon", ""], ["Zhong", "Xin", ""], ["Huang", "Pei-Chi", ""], ["Tourani", "Reza", ""]]}, {"id": "2010.10370", "submitter": "Jean-Fran\\c{c}ois Determe", "authors": "Jean-Fran\\c{c}ois Determe and Sophia Azzagnuni and Utkarsh Singh and\n  Fran\\c{c}ois Horlin and Philippe De Doncker", "title": "Monitoring Large Crowds With WiFi: A Privacy-Preserving Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AR cs.CR cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a crowd monitoring system based on the passive detection\nof probe requests. The system meets strict privacy requirements and is suited\nto monitoring events or buildings with a least a few hundreds of attendees. We\npresent our counting process and an associated mathematical model. From this\nmodel, we derive a concentration inequality that highlights the accuracy of our\ncrowd count estimator. Then, we describe our system. We present and discuss our\nsensor hardware, our computing system architecture, and an efficient\nimplementation of our counting algorithm---as well as its space and time\ncomplexity. We also show how our system ensures the privacy of people in the\nmonitored area. Finally, we validate our system using nine weeks of data from a\npublic library endowed with a camera-based counting system, which generates\ncounts against which we compare those of our counting system. This comparison\nempirically quantifies the accuracy of our counting system, thereby showing it\nto be suitable for monitoring public areas. Similarly, the concentration\ninequality provides a theoretical validation of the system.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 15:23:30 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Determe", "Jean-Fran\u00e7ois", ""], ["Azzagnuni", "Sophia", ""], ["Singh", "Utkarsh", ""], ["Horlin", "Fran\u00e7ois", ""], ["De Doncker", "Philippe", ""]]}, {"id": "2010.10387", "submitter": "Milad Rezaee", "authors": "Milad Rezaee, Dave Singelee, Bart Preneel", "title": "A Novel Demodulation Scheme for Secure and Reliable UWB Distance\n  Bounding", "comments": "This work needs some discussions and more references and also some\n  comparisons with some prior works in the literature", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relay attacks pose an important threat in wireless ranging and authentication\nsystems. Distance bounding protocols have been proposed as an effective\ncountermeasure against these attacks and allow a verifier and a prover to\nestablish an upper bound on the distance between them. However, secure distance\nbounding protocols are hard to realize in practice due to stringent\nimplementation requirements. In this paper, we look into a yet unexplored\nresearch area and show how the security strength of Ultra Wide Band (UWB)\ndistance bounding protocols can be significantly increased by imposing several\nadditional security constraints during demodulation and decoding at the\nreceiver. We demonstrate that for equal reliability metrics as in\nstate-of-the-art UWB distance bounding protocols, our solution achieves a\nreduction of the success probability of a relay attack by a factor of 40.\nMoreover, we also argue that our security solution only needs to be combined\nwith pulse masking and a distance commitment to achieve these security bounds\nand there is no need to have pulse reordering in our modulation.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 15:51:55 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 16:15:07 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Rezaee", "Milad", ""], ["Singelee", "Dave", ""], ["Preneel", "Bart", ""]]}, {"id": "2010.10416", "submitter": "Moritz Schneider", "authors": "Moritz Schneider, Aritra Dhar, Ivan Puddu, Kari Kostiainen, Srdjan\n  Capkun", "title": "PIE: A Platform-wide TEE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While modern computing architectures rely on specialized hardware such as\naccelerators to provide performance and functionality, trusted execution\nenvironments (TEEs), one of the most promising recent developments in security,\ncan only protect code confined in the CPU, limiting TEEs potential and\napplicability to a handful of applications. We observe that the TEEs' hardware\ntrusted computing base (TCB) is fixed at design time, forcing users to rely on\n(mostly untrustworthy) software to allow peripherals into the TEE. Based on\nthis observation, we propose PIE, a secure platform design with a configurable\nhardware and software TCB, which allows us to support specialized hardware\nwhile ensuring the least privilege principle. We introduce two new security\nproperties relevant to such systems: platform-wide attestation and platform\nawareness. Platform-wide attestation allows to remotely verify the platform's\ncurrent state, including the state of specialized hardware devices and how they\nare connected with each other, whereas platform awareness defines how the\nenclave reacts upon a change in connected devices. Together, these allow to\nattest to the hardware configuration of a system and check that only the\ntrusted hardware with the right version of its firmware is part of the TCB\n(platform-wide attestation) and will stay part of the TCB for the whole\nexecution (platform awareness). Finally, we present a prototype of PIE based on\nRISC-V's Keystone to show that such systems are feasible with only around 600\nlines added to the software TCB, without compromising performance.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 16:27:23 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 10:06:10 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Schneider", "Moritz", ""], ["Dhar", "Aritra", ""], ["Puddu", "Ivan", ""], ["Kostiainen", "Kari", ""], ["Capkun", "Srdjan", ""]]}, {"id": "2010.10447", "submitter": "Joachim Neu", "authors": "Joachim Neu, Ertem Nusret Tas, David Tse", "title": "Snap-and-Chat Protocols: System Aspects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The availability-finality dilemma says that blockchain protocols cannot be\nboth available under dynamic participation and safe under network partition.\nSnap-and-chat protocols have recently been proposed as a resolution to this\ndilemma. A snap-and-chat protocol produces an always available ledger\ncontaining a finalized prefix ledger which is always safe and catches up with\nthe available ledger whenever network conditions permit. In contrast to\nexisting handcrafted finality gadget based designs like Ethereum 2.0's\nconsensus protocol Gasper, snap-and-chat protocols are constructed as a\nblack-box composition of off-the-shelf BFT and longest chain protocols. In this\npaper, we consider system aspects of snap-and-chat protocols and show how they\ncan provide two important features: 1) accountability, 2) support of light\nclients. Through this investigation, a deeper understanding of the strengths\nand challenges of snap-and-chat protocols is gained.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 17:02:58 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Neu", "Joachim", ""], ["Tas", "Ertem Nusret", ""], ["Tse", "David", ""]]}, {"id": "2010.10572", "submitter": "Yupeng Jiang", "authors": "Yupeng Jiang, Yong Li, Yipeng Zhou and Xi Zheng", "title": "Mitigating Sybil Attacks on Differential Privacy based Federated\n  Learning", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In federated learning, machine learning and deep learning models are trained\nglobally on distributed devices. The state-of-the-art privacy-preserving\ntechnique in the context of federated learning is user-level differential\nprivacy. However, such a mechanism is vulnerable to some specific model\npoisoning attacks such as Sybil attacks. A malicious adversary could create\nmultiple fake clients or collude compromised devices in Sybil attacks to mount\ndirect model updates manipulation. Recent works on novel defense against model\npoisoning attacks are difficult to detect Sybil attacks when differential\nprivacy is utilized, as it masks clients' model updates with perturbation. In\nthis work, we implement the first Sybil attacks on differential privacy based\nfederated learning architectures and show their impacts on model convergence.\nWe randomly compromise some clients by manipulating different noise levels\nreflected by the local privacy budget epsilon of differential privacy on the\nlocal model updates of these Sybil clients such that the global model\nconvergence rates decrease or even leads to divergence. We apply our attacks to\ntwo recent aggregation defense mechanisms, called Krum and Trimmed Mean. Our\nevaluation results on the MNIST and CIFAR-10 datasets show that our attacks\neffectively slow down the convergence of the global models. We then propose a\nmethod to keep monitoring the average loss of all participants in each round\nfor convergence anomaly detection and defend our Sybil attacks based on the\nprediction cost reported from each client. Our empirical study demonstrates\nthat our defense approach effectively mitigates the impact of our Sybil attacks\non model convergence.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 19:17:25 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Jiang", "Yupeng", ""], ["Li", "Yong", ""], ["Zhou", "Yipeng", ""], ["Zheng", "Xi", ""]]}, {"id": "2010.10639", "submitter": "Eleonora Losiouk", "authors": "Marco Alecci, Riccardo Cestaro, Mauro Conti, Ketan Kanishka, Eleonora\n  Losiouk", "title": "Mascara: A Novel Attack Leveraging Android Virtualization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Android virtualization enables an app to create a virtual environment, in\nwhich other apps can run. Originally designed to overcome the limitations of\nmobile apps dimensions, malicious developers soon started exploiting this\ntechnique to design novel attacks. As a consequence, researchers proposed new\ndefence mechanisms that enable apps to detect whether they are running in a\nvirtual environment. In this paper, we propose Mascara, the first attack that\nexploits the virtualization technique in a new way, achieving the full\nfeasibility against any Android app and proving the ineffectiveness of existing\ncountermeasures. Mascara is executed by a malicious app, that looks like the\nadd-on of the victim app. As for any other add-on, our malicious one can be\ninstalled as a standard Android app, but, after the installation, it launches\nMascara against the victim app. The malicious add-on is generated by Mascarer,\nthe framework we designed and developed to automate the whole process.\nConcerning Mascara, we evaluated its effectiveness against three popular apps\n(i.e., Telegram, Amazon Music and Alamo) and its capability to bypass existing\nmechanisms for virtual environments detection. We analyzed the efficiency of\nour attack by measuring the overhead introduced at runtime by the\nvirtualization technique and the compilation time required by Mascarer to\ngenerate 100 malicious add-ons (i.e., less than 10 sec). Finally, we designed a\nrobust approach that detects virtual environments by inspecting the fields\nvalues of ArtMethod data structures in the Android Runtime (ART) environment.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 21:46:57 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Alecci", "Marco", ""], ["Cestaro", "Riccardo", ""], ["Conti", "Mauro", ""], ["Kanishka", "Ketan", ""], ["Losiouk", "Eleonora", ""]]}, {"id": "2010.10640", "submitter": "Andreea Alexandru", "authors": "Andreea B. Alexandru and George J. Pappas", "title": "Private Weighted Sum Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As large amounts of data are circulated both from users to a cloud server and\nbetween users, there is a critical need for privately aggregating the shared\ndata. This paper considers the problem of private weighted sum aggregation with\nsecret weights, where an aggregator wants to compute the weighted sum of the\nlocal data of some agents. Depending on the privacy requirements posed on the\nweights, there are different secure multi-party computation schemes exploiting\nthe information structure. First, when each agent has a local private value and\na local private weight, we review private sum aggregation schemes. Second, we\ndiscuss how to extend the previous schemes for when the agents have a local\nprivate value, but the aggregator holds the corresponding weights. Third, we\ntreat a more general case where the agents have their local private values, but\nthe weights are known neither by the agents nor by the aggregator; they are\ngenerated by a system operator, who wants to keep them private. We give a\nsolution where aggregator obliviousness is achieved, even under collusion\nbetween the participants, and we show how to obtain a more efficient\ncommunication and computation strategy for multi-dimensional data, by batching\nthe data into fewer ciphertexts. Finally, we implement our schemes and discuss\nthe numerical results and efficiency improvements.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 21:50:10 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Alexandru", "Andreea B.", ""], ["Pappas", "George J.", ""]]}, {"id": "2010.10664", "submitter": "David Darais", "authors": "Phillip Nguyen, Alex Silence, David Darais, Joseph P. Near", "title": "DuetSGX: Differential Privacy with Secure Hardware", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy offers a formal privacy guarantee for individuals, but\nmany deployments of differentially private systems require a trusted third\nparty (the data curator). We propose DuetSGX, a system that uses secure\nhardware (Intel's SGX) to eliminate the need for a trusted data curator. Data\nowners submit encrypted data that can be decrypted only within a secure enclave\nrunning the DuetSGX system, ensuring that sensitive data is never available to\nthe data curator. Analysts submit queries written in the Duet language, which\nis specifically designed for verifying that programs satisfy differential\nprivacy; DuetSGX uses the Duet typechecker to verify that each query satisfies\ndifferential privacy before running it. DuetSGX therefore provides the benefits\nof local differential privacy and central differential privacy simultaneously:\nnoise is only added to final results, and there is no trusted third party. We\nhave implemented a proof-of-concept implementation of DuetSGX and we release it\nas open-source.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 23:08:03 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Nguyen", "Phillip", ""], ["Silence", "Alex", ""], ["Darais", "David", ""], ["Near", "Joseph P.", ""]]}, {"id": "2010.10682", "submitter": "Hojjat Aghakhani", "authors": "Hojjat Aghakhani, Thorsten Eisenhofer, Lea Sch\\\"onherr, Dorothea\n  Kolossa, Thorsten Holz, Christopher Kruegel, and Giovanni Vigna", "title": "VENOMAVE: Clean-Label Poisoning Against Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CR cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, we observed a wide adoption of practical systems that\nuse Automatic Speech Recognition (ASR) systems to improve human-machine\ninteraction. Modern ASR systems are based on neural networks and prior research\ndemonstrated that these systems are susceptible to adversarial examples, i.e.,\nmalicious audio inputs that lead to misclassification by the victim's network\nduring the system's run time. The research question if ASR systems are also\nvulnerable to data poisoning attacks is still unanswered. In such an attack, a\nmanipulation happens during the training phase of the neural network: an\nadversary injects malicious inputs into the training set such that the neural\nnetwork's integrity and performance are compromised. In this paper, we present\nthe first data poisoning attack in the audio domain, called VENOMAVE. Prior\nwork in the image domain demonstrated several types of data poisoning attacks,\nbut they cannot be applied to the audio domain. The main challenge is that we\nneed to attack a time series of inputs. To enforce a targeted misclassification\nin an ASR system, we need to carefully generate a specific sequence of\ndisturbed inputs for the target utterance, which will eventually be decoded to\nthe desired sequence of words. More specifically, the adversarial goal is to\nproduce a series of misclassification tasks and in each of them, we need to\npoison the system to misrecognize each frame of the target file. To demonstrate\nthe practical feasibility of our attack, we evaluate VENOMAVE on an ASR system\nthat detects sequences of digits from 0 to 9. When poisoning only 0.94% of the\ndataset on average, we achieve an attack success rate of 83.33%. We conclude\nthat data poisoning attacks against ASR systems represent a real threat that\nneeds to be considered.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 00:30:08 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Aghakhani", "Hojjat", ""], ["Eisenhofer", "Thorsten", ""], ["Sch\u00f6nherr", "Lea", ""], ["Kolossa", "Dorothea", ""], ["Holz", "Thorsten", ""], ["Kruegel", "Christopher", ""], ["Vigna", "Giovanni", ""]]}, {"id": "2010.10712", "submitter": "Fanhua Shang", "authors": "Hongying Liu, Zhenyu Zhou, Fanhua Shang, Xiaoyu Qi, Yuanyuan Liu,\n  Licheng Jiao", "title": "Boosting Gradient for White-Box Adversarial Attacks", "comments": "9 pages,6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are playing key roles in various artificial\nintelligence applications such as image classification and object recognition.\nHowever, a growing number of studies have shown that there exist adversarial\nexamples in DNNs, which are almost imperceptibly different from original\nsamples, but can greatly change the network output. Existing white-box attack\nalgorithms can generate powerful adversarial examples. Nevertheless, most of\nthe algorithms concentrate on how to iteratively make the best use of gradients\nto improve adversarial performance. In contrast, in this paper, we focus on the\nproperties of the widely-used ReLU activation function, and discover that there\nexist two phenomena (i.e., wrong blocking and over transmission) misleading the\ncalculation of gradients in ReLU during the backpropagation. Both issues\nenlarge the difference between the predicted changes of the loss function from\ngradient and corresponding actual changes, and mislead the gradients which\nresults in larger perturbations. Therefore, we propose a universal adversarial\nexample generation method, called ADV-ReLU, to enhance the performance of\ngradient based white-box attack algorithms. During the backpropagation of the\nnetwork, our approach calculates the gradient of the loss function versus\nnetwork input, maps the values to scores, and selects a part of them to update\nthe misleading gradients. Comprehensive experimental results on \\emph{ImageNet}\ndemonstrate that our ADV-ReLU can be easily integrated into many\nstate-of-the-art gradient-based white-box attack algorithms, as well as\ntransferred to black-box attack attackers, to further decrease perturbations in\nthe ${\\ell _2}$-norm.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 02:13:26 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Liu", "Hongying", ""], ["Zhou", "Zhenyu", ""], ["Shang", "Fanhua", ""], ["Qi", "Xiaoyu", ""], ["Liu", "Yuanyuan", ""], ["Jiao", "Licheng", ""]]}, {"id": "2010.10747", "submitter": "Jiaying Zhou", "authors": "Jiaying Zhou, Xun Xian, Na Li, Jie Ding", "title": "ASCII: ASsisted Classification with Ignorance Interchange", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid development in data collecting devices and computation platforms\nproduces an emerging number of agents, each equipped with a unique data\nmodality over a particular population of subjects. While the predictive\nperformance of an agent may be enhanced by transmitting other data to it, this\nis often unrealistic due to intractable transmission costs and security\nconcerns. While the predictive performance of an agent may be enhanced by\ntransmitting other data to it, this is often unrealistic due to intractable\ntransmission costs and security concerns. In this paper, we propose a method\nnamed ASCII for an agent to improve its classification performance through\nassistance from other agents. The main idea is to iteratively interchange an\nignorance value between 0 and 1 for each collated sample among agents, where\nthe value represents the urgency of further assistance needed. The method is\nnaturally suitable for privacy-aware, transmission-economical, and\ndecentralized learning scenarios. The method is also general as it allows the\nagents to use arbitrary classifiers such as logistic regression, ensemble tree,\nand neural network, and they may be heterogeneous among agents. We demonstrate\nthe proposed method with extensive experimental studies.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 03:57:36 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Zhou", "Jiaying", ""], ["Xian", "Xun", ""], ["Li", "Na", ""], ["Ding", "Jie", ""]]}, {"id": "2010.10788", "submitter": "Dan Su", "authors": "Dan Su, Jiqiang Liu, Sencun Zhu, Xiaoyang Wang, and Wei Wang", "title": "\"Are you home alone?\" \"Yes\" Disclosing Security and Privacy\n  Vulnerabilities in Alexa Skills", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The home voice assistants such as Amazon Alexa have become increasingly\npopular due to many interesting voice-activated services provided through\nspecial applications called skills. These skills, though useful, have also\nintroduced new security and privacy challenges. Prior work has verified that\nAlexa is vulnerable to multiple types of voice attacks, but the security and\nprivacy risk of using skills has not been fully investigated. In this work, we\nstudy an adversary model that covers three severe privacy-related\nvulnerabilities, namely,over-privileged resource access, hidden\ncode-manipulation and hidden content-manipulation. By exploiting these\nvulnerabilities, malicious skills can not only bypass the security tests in the\nvetting process, but also surreptitiously change their original functions in an\nattempt to steal users' personal information. What makes the situation even\nworse is that the attacks can be extended from virtual networks to the physical\nworld. We systematically study the security issues from the feasibility and\nimplementation of the attacks to the design of countermeasures. We also made a\ncomprehensive survey study of 33,744 skills in Alex Skills Store.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 07:01:32 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Su", "Dan", ""], ["Liu", "Jiqiang", ""], ["Zhu", "Sencun", ""], ["Wang", "Xiaoyang", ""], ["Wang", "Wei", ""]]}, {"id": "2010.10799", "submitter": "Vamoua Yachongka Mr.", "authors": "Vamoua Yachongka, Hideki Yagi, and Yasutada Oohama", "title": "Biometric Identification Systems With Noisy Enrollment for Gaussian\n  Source", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present paper, we investigate the fundamental trade-off of\nidentification, secrecy, storage, and privacy-leakage rates in biometric\nidentification systems for hidden or remote Gaussian sources. We introduce a\ntechnique for deriving the capacity region of these rates by converting the\nsystem to one where the data flow is in one-way direction. Also, we provide\nnumerical calculations of three different examples for the generated-secret\nmodel. The numerical results imply that it seems hard to achieve both high\nsecrecy and small privacy-leakage rates simultaneously. In addition, as special\ncases, the characterization coincides with several known results in previous\nstudies.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 07:34:20 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Yachongka", "Vamoua", ""], ["Yagi", "Hideki", ""], ["Oohama", "Yasutada", ""]]}, {"id": "2010.10805", "submitter": "Jianlei Chi", "authors": "Jianlei Chi, Yu Qu, Ting Liu, Qinghua Zheng, Heng Yin", "title": "SeqTrans: Automatic Vulnerability Fix via Sequence to Sequence Learning", "comments": "20 pages, 18 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software vulnerabilities are now reported at an unprecedented speed due to\nthe recent development of automated vulnerability hunting tools. However,\nfixing vulnerabilities still mainly depends on programmers' manual efforts.\nDevelopers need to deeply understand the vulnerability and try to affect the\nsystem's functions as little as possible.\n  In this paper, with the advancement of Neural Machine Translation (NMT)\ntechniques, we provide a novel approach called SeqTrans to exploit historical\nvulnerability fixes to provide suggestions and automatically fix the source\ncode. To capture the contextual information around the vulnerable code, we\npropose to leverage data flow dependencies to construct code sequences and fed\nthem into the state-of-the-art transformer model. The fine-tuning strategy has\nbeen introduced to overcome the small sample size problem. We evaluate SeqTrans\non a dataset containing 1,282 commits that fix 624 vulnerabilities in 205 Java\nprojects. Results show that the accuracy of SeqTrans outperforms the latest\ntechniques and achieves 23.3% in statement-level fix and 25.3% in CVE-level\nfix. In the meantime, we look deep inside the result and observe that NMT model\nperforms very well in certain kinds of vulnerabilities like CWE-287 (Improper\nAuthentication) and CWE-863 (Incorrect Authorization).\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 07:49:08 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 06:17:30 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Chi", "Jianlei", ""], ["Qu", "Yu", ""], ["Liu", "Ting", ""], ["Zheng", "Qinghua", ""], ["Yin", "Heng", ""]]}, {"id": "2010.10858", "submitter": "Befekadu Gebraselase", "authors": "Befekadu G. Gebraselase, Bjarne E. Helvik, Yuming Jiang", "title": "Transaction Characteristics of Bitcoin", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blockchain has been considered as an important technique to enable secure\nmanagement of virtual network functions and network slices. To understand such\ncapabilities of a blockchain, e.g. transaction confirmation time, demands a\nthorough study on the transaction characteristics of the blockchain. This paper\npresents a comprehensive study on the transaction characteristics of Bitcoin --\nthe first blockchain application, focusing on the underlying fundamental\nprocesses. A set of results and findings are obtained, which provide new\ninsight into understanding the transaction and traffic characteristics of\nBitcoin. As a highlight, the validity of several hypotheses/assumptions used in\nthe literature is examined with measurement for the first time.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 09:35:36 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Gebraselase", "Befekadu G.", ""], ["Helvik", "Bjarne E.", ""], ["Jiang", "Yuming", ""]]}, {"id": "2010.10872", "submitter": "James Pavur", "authors": "James Pavur and Ivan Martinovic", "title": "SOK: Building a Launchpad for Impactful Satellite Cyber-Security\n  Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the space industry approaches a period of rapid change, securing both\nemerging and legacy satellite missions will become vital. However, space\ntechnology has been largely overlooked by the systems security community. This\nsystematization of knowledge paper seeks to understand why this is the case and\nto offer a starting point for technical security researchers seeking impactful\ncontributions beyond the Earth's mesosphere.\n  The paper begins with a cross-disciplinary synthesis of relevant threat\nmodels from a diverse array of fields, ranging from legal and policy studies to\naerospace engineering. This is presented as a \"threat matrix toolbox\" which\nsecurity researchers may leverage to motivate technical research into given\nattack vectors and defenses. We subsequently apply this model to an original\nchronology of more than 100 significant satellite hacking incidents spanning\nthe previous 60 years. Together, these are used to assess the state-of-the-art\nin satellite security across four sub-domains: satellite radio-link security,\nspace hardware security, ground station security, and operational/mission\nsecurity. In each area, we note significant findings and unresolved questions\nlingering in other disciplines which the systems security community is aptly\npoised to tackle. By consolidating this research, we present the case that\nsatellite systems security researchers can build on strong, but disparate,\nacademic foundations and rise to meet an urgent need for future space missions.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 09:58:00 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Pavur", "James", ""], ["Martinovic", "Ivan", ""]]}, {"id": "2010.10881", "submitter": "Josep Domingo-Ferrer", "authors": "Josep Domingo-Ferrer and Jordi Soria-Comas", "title": "Multi-Dimensional Randomized Response", "comments": "IEEE Transactions on Knowledge and Data Engineering, to appear.\n  (First version submitted on May 8, 2019 as TKDE-2019-05-0430; first revision\n  submitted on July 13, 2020 as TKDE-2019-05-0430.R1; second revision submitted\n  on Nov. 5, 2020 as TKDE-2019-05-0430.R2 and accepted without changes on Dec.\n  16, 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our data world, a host of not necessarily trusted controllers gather data\non individual subjects. To preserve her privacy and, more generally, her\ninformational self-determination, the individual has to be empowered by giving\nher agency on her own data. Maximum agency is afforded by local anonymization,\nthat allows each individual to anonymize her own data before handing them to\nthe data controller. Randomized response (RR) is a local anonymization approach\nable to yield multi-dimensional full sets of anonymized microdata that are\nvalid for exploratory analysis and machine learning. This is so because an\nunbiased estimate of the distribution of the true data of individuals can be\nobtained from their pooled randomized data. Furthermore, RR offers rigorous\nprivacy guarantees. The main weakness of RR is the curse of dimensionality when\napplied to several attributes: as the number of attributes grows, the accuracy\nof the estimated true data distribution quickly degrades. We propose several\ncomplementary approaches to mitigate the dimensionality problem. First, we\npresent two basic protocols, separate RR on each attribute and joint RR for all\nattributes, and discuss their limitations. Then we introduce an algorithm to\nform clusters of attributes so that attributes in different clusters can be\nviewed as independent and joint RR can be performed within each cluster. After\nthat, we introduce an adjustment algorithm for the randomized data set that\nrepairs some of the accuracy loss due to assuming independence between\nattributes when using RR separately on each attribute or due to assuming\nindependence between clusters in cluster-wise RR. We also present empirical\nwork to illustrate the proposed methods.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 10:24:27 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 09:40:11 GMT"}, {"version": "v3", "created": "Sat, 19 Dec 2020 18:26:12 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Domingo-Ferrer", "Josep", ""], ["Soria-Comas", "Jordi", ""]]}, {"id": "2010.10981", "submitter": "Laura Graves", "authors": "Laura Graves, Vineel Nagisetty, Vijay Ganesh", "title": "Amnesiac Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Right to be Forgotten is part of the recently enacted General Data\nProtection Regulation (GDPR) law that affects any data holder that has data on\nEuropean Union residents. It gives EU residents the ability to request deletion\nof their personal data, including training records used to train machine\nlearning models. Unfortunately, Deep Neural Network models are vulnerable to\ninformation leaking attacks such as model inversion attacks which extract class\ninformation from a trained model and membership inference attacks which\ndetermine the presence of an example in a model's training data. If a malicious\nparty can mount an attack and learn private information that was meant to be\nremoved, then it implies that the model owner has not properly protected their\nuser's rights and their models may not be compliant with the GDPR law. In this\npaper, we present two efficient methods that address this question of how a\nmodel owner or data holder may delete personal data from models in such a way\nthat they may not be vulnerable to model inversion and membership inference\nattacks while maintaining model efficacy. We start by presenting a real-world\nthreat model that shows that simply removing training data is insufficient to\nprotect users. We follow that up with two data removal methods, namely\nUnlearning and Amnesiac Unlearning, that enable model owners to protect\nthemselves against such attacks while being compliant with regulations. We\nprovide extensive empirical analysis that show that these methods are indeed\nefficient, safe to apply, effectively remove learned information about\nsensitive data from trained models while maintaining model efficacy.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 13:14:17 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Graves", "Laura", ""], ["Nagisetty", "Vineel", ""], ["Ganesh", "Vijay", ""]]}, {"id": "2010.10987", "submitter": "Jungang Yang", "authors": "Jungang Yang, Liyao Xiang, Ruidong Chen, Yukun Wang, Wei Wang, Xinbing\n  Wang", "title": "Certified Distributional Robustness on Smoothed Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The robustness of deep neural networks (DNNs) against adversarial example\nattacks has raised wide attention. For smoothed classifiers, we propose the\nworst-case adversarial loss over input distributions as a robustness\ncertificate. Compared with previous certificates, our certificate better\ndescribes the empirical performance of the smoothed classifiers. By exploiting\nduality and the smoothness property, we provide an easy-to-compute upper bound\nas a surrogate for the certificate. We adopt a noisy adversarial learning\nprocedure to minimize the surrogate loss to improve model robustness. We show\nthat our training method provides a theoretically tighter bound over the\ndistributional robust base classifiers. Experiments on a variety of datasets\nfurther demonstrate superior robustness performance of our method over the\nstate-of-the-art certified or heuristic methods.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 13:22:25 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 07:24:47 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Yang", "Jungang", ""], ["Xiang", "Liyao", ""], ["Chen", "Ruidong", ""], ["Wang", "Yukun", ""], ["Wang", "Wei", ""], ["Wang", "Xinbing", ""]]}, {"id": "2010.10996", "submitter": "Yifan Hu", "authors": "Yifan Hu, Yuhang Zhou, Jun Xiao, Chao Wu", "title": "GFL: A Decentralized Federated Learning Framework Based On Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning(FL) is a rapidly growing field and many centralized and\ndecentralized FL frameworks have been proposed. However, it is of great\nchallenge for current FL frameworks to improve communication performance and\nmaintain the security and robustness under malicious node attacks. In this\npaper, we propose Galaxy Federated Learning Framework(GFL), a decentralized FL\nframework based on blockchain. GFL introduces the consistent hashing algorithm\nto improve communication performance and proposes a novel ring decentralized FL\nalgorithm(RDFL) to improve decentralized FL performance and bandwidth\nutilization. In addition, GFL introduces InterPlanetary File System(IPFS) and\nblockchain to further improve communication efficiency and FL security. Our\nexperiments show that GFL improves communication performance and decentralized\nFL performance under the data poisoning of malicious nodes and non-independent\nand identically distributed(Non-IID) datasets.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 13:36:59 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 12:45:14 GMT"}, {"version": "v3", "created": "Tue, 13 Apr 2021 14:05:31 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Hu", "Yifan", ""], ["Zhou", "Yuhang", ""], ["Xiao", "Jun", ""], ["Wu", "Chao", ""]]}, {"id": "2010.11079", "submitter": "Dalton Hahn", "authors": "Dalton A. Hahn, Drew Davidson, and Alexandru G. Bardas", "title": "Security Issues and Challenges in Service Meshes -- An Extended Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Service meshes have emerged as an attractive DevOps solution for collecting,\nmanaging, and coordinating microservice deployments. However, current service\nmeshes leave fundamental security mechanisms missing or incomplete. The\nsecurity burden means service meshes may actually cause additional workload and\noverhead for administrators over traditional monolithic systems. By assessing\nthe effectiveness and practicality of service mesh tools, this work provides\nnecessary insights into the available security of service meshes. We evaluate\nservice meshes from two perspectives: skilled system administrators (who deploy\noptimal configurations of available security mechanisms) and default\nconfigurations. Under these two models, we consider a comprehensive set of\nadversarial scenarios and uncover important design flaws with contradicting\ngoals, as well as the limitations and challenges encountered in employing\nservice mesh tools for operational environments.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 15:40:28 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Hahn", "Dalton A.", ""], ["Davidson", "Drew", ""], ["Bardas", "Alexandru G.", ""]]}, {"id": "2010.11082", "submitter": "Di Wang", "authors": "Di Wang and Hanshen Xiao and Srini Devadas and Jinhui Xu", "title": "On Differentially Private Stochastic Convex Optimization with\n  Heavy-tailed Data", "comments": "Published in ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of designing Differentially Private\n(DP) algorithms for Stochastic Convex Optimization (SCO) on heavy-tailed data.\nThe irregularity of such data violates some key assumptions used in almost all\nexisting DP-SCO and DP-ERM methods, resulting in failure to provide the DP\nguarantees. To better understand this type of challenges, we provide in this\npaper a comprehensive study of DP-SCO under various settings. First, we\nconsider the case where the loss function is strongly convex and smooth. For\nthis case, we propose a method based on the sample-and-aggregate framework,\nwhich has an excess population risk of $\\tilde{O}(\\frac{d^3}{n\\epsilon^4})$\n(after omitting other factors), where $n$ is the sample size and $d$ is the\ndimensionality of the data. Then, we show that with some additional assumptions\non the loss functions, it is possible to reduce the \\textit{expected} excess\npopulation risk to $\\tilde{O}(\\frac{ d^2}{ n\\epsilon^2 })$. To lift these\nadditional conditions, we also provide a gradient smoothing and trimming based\nscheme to achieve excess population risks of $\\tilde{O}(\\frac{\nd^2}{n\\epsilon^2})$ and\n$\\tilde{O}(\\frac{d^\\frac{2}{3}}{(n\\epsilon^2)^\\frac{1}{3}})$ for strongly\nconvex and general convex loss functions, respectively, \\textit{with high\nprobability}. Experiments suggest that our algorithms can effectively deal with\nthe challenges caused by data irregularity.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 15:45:27 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Wang", "Di", ""], ["Xiao", "Hanshen", ""], ["Devadas", "Srini", ""], ["Xu", "Jinhui", ""]]}, {"id": "2010.11096", "submitter": "Ramesh Pattarkudi Narasimman", "authors": "Ramesh Narasimman and Izzat Alsmadi", "title": "RBAC for Healthcare-Infrastructure and data storage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Role based Access control (RBAC) is the cornerstone of security for any\nmodern organization. In this report, we defined a health-care access control\nstructure based on RBAC. We used Alloy formal logic modeling tool to model and\nvalidate system functions. We modeled system static and dynamic or temporal\nbehaviours. We focused on evaluating properties such as integrity, conformance\nand progress.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 20:05:10 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Narasimman", "Ramesh", ""], ["Alsmadi", "Izzat", ""]]}, {"id": "2010.11097", "submitter": "Amr Alanwar", "authors": "Amr Alanwar, Victor Gassmann, Xingkang He, Hazem Said, Henrik\n  Sandberg, Karl Henrik Johansson, Matthias Althoff", "title": "Privacy Preserving Set-Based Estimation Using Partially Homomorphic\n  Encryption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Set-based estimation has gained a lot of attention due to its ability to\nguarantee state enclosures for safety-critical systems. However, it requires\ncomputationally expensive operations, which in turn often requires outsourcing\nof these operations to cloud-computing platforms. Consequently, this raises\nsome concerns with regard to sharing sensitive information and measurements.\nThis paper presents the first privacy-preserving set-based estimation protocols\nusing partially homomorphic encryption in which we preserve the privacy of the\nset of all possible estimates and the measurements. We consider a linear\ndiscrete-time dynamical system with bounded modeling and measurement\nuncertainties without any other statistical assumptions. We represent sets by\nzonotopes and constrained zonotopes as they can compactly represent\nhigh-dimensional sets and are closed under linear maps and Minkowski addition.\nBy selectively encrypting some parameters of the used set representations, we\nare able to intersect sets in the encrypted domain, which enables guaranteed\nstate estimation while ensuring the privacy goals. In particular, we show that\nour protocols achieve computational privacy using formal cryptographic\ndefinitions of computational indistinguishability. We demonstrate the\nefficiency of our approach by localizing a mobile quadcopter using custom\nultra-wideband wireless devices. Our code and data are available online.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2020 15:54:16 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Alanwar", "Amr", ""], ["Gassmann", "Victor", ""], ["He", "Xingkang", ""], ["Said", "Hazem", ""], ["Sandberg", "Henrik", ""], ["Johansson", "Karl Henrik", ""], ["Althoff", "Matthias", ""]]}, {"id": "2010.11127", "submitter": "Gokcen Yilmaz Dayanikli", "authors": "Gokcen Y. Dayanikli, Rees R. Hatch, Ryan M. Gerdes, Hongjie Wang,\n  Regan Zane", "title": "Electromagnetic Sensor and Actuator Attacks on Power Converters for\n  Electric Vehicles", "comments": "Accepted by IEEE S&P Workshop on the Internet of Safe Things 2020", "journal-ref": null, "doi": "10.1109/SPW50608.2020.00032", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alleviating range anxiety for electric vehicles (i.e., whether such vehicles\ncan be relied upon to travel long distances in a timely manner) is critical for\nsustainable transportation. Extremely fast charging (XFC), whereby electric\nvehicles (EV) can be quickly recharged in the time frame it takes to refuel an\ninternal combustion engine, has been proposed to alleviate this concern. A\ncritical component of these chargers is the efficient and proper operation of\npower converters that convert AC to DC power and otherwise regulate power\ndelivery to vehicles. These converters rely on the integrity of sensor and\nactuation signals. In this work the operation of state-of-the art XFC\nconverters is assessed in adversarial conditions, specifically against\nIntentional Electromagnetic Interference Attacks (IEMI). The targeted system is\nanalyzed with the goal of determining possible weak points for IEMI, viz.\nvoltage and current sensor outputs and gate control signals. This work\ndemonstrates that, with relatively low power levels, an adversary is able to\nmanipulate the voltage and current sensor outputs necessary to ensure the\nproper operation of the converters. Furthermore, in the first attack of its\nkind, it is shown that the gate signal that controls the converter switches can\nbe manipulated, to catastrophic effect; i.e., it is possible for an attacker to\ncontrol the switching state of individual transistors to cause irreparable\ndamage to the converter and associated systems. Finally, a discussion of\ncountermeasures for hardware designers to mitigate IEMI-based attacks is\nprovided.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 16:38:24 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Dayanikli", "Gokcen Y.", ""], ["Hatch", "Rees R.", ""], ["Gerdes", "Ryan M.", ""], ["Wang", "Hongjie", ""], ["Zane", "Regan", ""]]}, {"id": "2010.11143", "submitter": "Zejian Luo", "authors": "Ling Wang, Cheng Zhang, Zejian Luo, Chenguang Liu, Jie Liu, Xi Zheng,\n  and Athanasios Vasilakos", "title": "Progressive Defense Against Adversarial Attacks for Deep Learning as a\n  Service in Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, Deep Learning as a service can be deployed in Internet of Things\n(IoT) to provide smart services and sensor data processing. However, recent\nresearch has revealed that some Deep Neural Networks (DNN) can be easily misled\nby adding relatively small but adversarial perturbations to the input (e.g.,\npixel mutation in input images). One challenge in defending DNN against these\nattacks is to efficiently identifying and filtering out the adversarial pixels.\nThe state-of-the-art defense strategies with good robustness often require\nadditional model training for specific attacks. To reduce the computational\ncost without loss of generality, we present a defense strategy called a\nprogressive defense against adversarial attacks (PDAAA) for efficiently and\neffectively filtering out the adversarial pixel mutations, which could mislead\nthe neural network towards erroneous outputs, without a-priori knowledge about\nthe attack type. We evaluated our progressive defense strategy against various\nattack methods on two well-known datasets. The result shows it outperforms the\nstate-of-the-art while reducing the cost of model training by 50% on average.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 06:40:53 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Wang", "Ling", ""], ["Zhang", "Cheng", ""], ["Luo", "Zejian", ""], ["Liu", "Chenguang", ""], ["Liu", "Jie", ""], ["Zheng", "Xi", ""], ["Vasilakos", "Athanasios", ""]]}, {"id": "2010.11186", "submitter": "Takashi Yamakawa", "authors": "Fuyuki Kitagawa, Ryo Nishimaki, Takashi Yamakawa", "title": "Secure Software Leasing from Standard Assumptions", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secure software leasing (SSL) is a quantum cryptographic primitive that\nenables users to execute software only during the software is leased. It\nprevents users from executing leased software after they return the leased\nsoftware to its owner. SSL can make software distribution more flexible and\ncontrollable. Although SSL is an attractive cryptographic primitive, the\nexisting SSL scheme is based on public key quantum money, which is not\ninstantiated with standard cryptographic assumptions so far. Moreover, the\nexisting SSL scheme only supports a subclass of evasive functions. In this\nwork, we present SSL schemes based on the learning with errors assumption\n(LWE). Specifically, our contributions consist of the following.\n  - We construct an SSL scheme for pseudorandom functions from the LWE\nassumption against quantum adversaries.\n  - We construct an SSL scheme for a subclass of evasive functions from the LWE\nassumption against sub-exponential quantum adversaries.\n  - We construct SSL schemes for the functionalities above with classical\ncommunication from the LWE assumption against (sub-exponential) quantum\nadversaries. SSL with classical communication means that entities exchange only\nclassical information though they run quantum computation locally.\n  Our crucial tool is two-tier quantum lightning, which is introduced in this\nwork and a relaxed version of quantum lighting. In two-tier quantum lightning\nschemes, we have a public verification algorithm called semi-verification and a\nprivate verification algorithm called full-verification. An adversary cannot\ngenerate possibly entangled two quantum states whose serial numbers are the\nsame such that one passes the semi-verification, and the other also passes the\nfull-verification. We show that we can construct a two-tier quantum lightning\nscheme from the LWE assumption.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 17:59:36 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 17:46:23 GMT"}, {"version": "v3", "created": "Mon, 8 Mar 2021 03:03:21 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Kitagawa", "Fuyuki", ""], ["Nishimaki", "Ryo", ""], ["Yamakawa", "Takashi", ""]]}, {"id": "2010.11242", "submitter": "Anna-Katharina Wickert", "authors": "Johannes Lauinger (1), Lars Baumg\\\"artner (1), Anna-Katharina Wickert\n  (1), Mira Mezini (1) ((1) Technische Universit\\\"at Darmstadt)", "title": "Uncovering the Hidden Dangers: Finding Unsafe Go Code in the Wild", "comments": "This is a copy of the accepted version at The 19th IEEE International\n  Conference on Trust, Security and Privacy in Computing and Communications\n  (TrustCom 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Go programming language aims to provide memory and thread safety through\nmeasures such as automated memory management with garbage collection and a\nstrict type system. However, it also offers a way of circumventing this safety\nnet through the use of the unsafe package. While there are legitimate use cases\nfor unsafe, developers must exercise caution to avoid introducing\nvulnerabilities like buffer overflows or memory corruption in general. Using\ngo-geiger, we conducted a study on the usage of unsafe in the top 500 most\npopular open-source Go projects on GitHub, including a manual analysis of 1,400\ncode samples on how unsafe is used. From the projects using Go's module system,\n38% directly contain at least one unsafe usage, and 91% contain at least one\nunsafe usage in the project itself or one of its transitive dependencies. Based\non the usage patterns found, we present possible exploit vectors in different\nscenarios. Finally, we present go-safer, a novel static analysis tool to\nidentify dangerous and common usage patterns that were previously undetected\nwith existing tools.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 18:55:15 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Lauinger", "Johannes", "", "Technische Universit\u00e4t Darmstadt"], ["Baumg\u00e4rtner", "Lars", "", "Technische Universit\u00e4t Darmstadt"], ["Wickert", "Anna-Katharina", "", "Technische Universit\u00e4t Darmstadt"], ["Mezini", "Mira", "", "Technische Universit\u00e4t Darmstadt"]]}, {"id": "2010.11352", "submitter": "Alessandro Lameiras Koerich", "authors": "Mohammad Esmaeilpour, Patrick Cardinal, Alessandro Lameiras Koerich", "title": "Class-Conditional Defense GAN Against End-to-End Speech Attacks", "comments": "5 pages", "journal-ref": "46th IEEE International Conference on Acoustics, Speech, & Signal\n  Processing (ICASSP), 2021", "doi": null, "report-no": null, "categories": "cs.SD cs.CR cs.CV cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel defense approach against end-to-end\nadversarial attacks developed to fool advanced speech-to-text systems such as\nDeepSpeech and Lingvo. Unlike conventional defense approaches, the proposed\napproach does not directly employ low-level transformations such as\nautoencoding a given input signal aiming at removing potential adversarial\nperturbation. Instead of that, we find an optimal input vector for a class\nconditional generative adversarial network through minimizing the relative\nchordal distance adjustment between a given test input and the generator\nnetwork. Then, we reconstruct the 1D signal from the synthesized spectrogram\nand the original phase information derived from the given input signal. Hence,\nthis reconstruction does not add any extra noise to the signal and according to\nour experimental results, our defense-GAN considerably outperforms conventional\ndefense algorithms both in terms of word error rate and sentence level\nrecognition accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 00:02:02 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 02:51:55 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Esmaeilpour", "Mohammad", ""], ["Cardinal", "Patrick", ""], ["Koerich", "Alessandro Lameiras", ""]]}, {"id": "2010.11425", "submitter": "Abhimanyu Dubey", "authors": "Abhimanyu Dubey and Alex Pentland", "title": "Differentially-Private Federated Linear Bandits", "comments": "22 pages. Camera-ready for NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid proliferation of decentralized learning systems mandates the need\nfor differentially-private cooperative learning. In this paper, we study this\nin context of the contextual linear bandit: we consider a collection of agents\ncooperating to solve a common contextual bandit, while ensuring that their\ncommunication remains private. For this problem, we devise \\textsc{FedUCB}, a\nmultiagent private algorithm for both centralized and decentralized\n(peer-to-peer) federated learning. We provide a rigorous technical analysis of\nits utility in terms of regret, improving several results in cooperative bandit\nlearning, and provide rigorous privacy guarantees as well. Our algorithms\nprovide competitive performance both in terms of pseudoregret bounds and\nempirical benchmark performance in various multi-agent settings.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 03:58:39 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Dubey", "Abhimanyu", ""], ["Pentland", "Alex", ""]]}, {"id": "2010.11441", "submitter": "Longjiang Li", "authors": "Longjiang Li, Bingchuan Ma, Jianjun Yang, Yonggang Li, Yuming Mao", "title": "Fusing Keys for Secret Communications: Towards Information-Theoretic\n  Security", "comments": "7 pages, 5 figures, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern cryptography is essential to communication and information security\nfor performing all kinds of security actions, such as encryption,\nauthentication, and signature. However, the exposure possibility of keys poses\na great threat to almost all modern cryptography. This article proposes a\nkey-fusing framework, which enables a high resilience to key exposure by fusing\nmultiple imperfect keys. The correctness of the scheme is strictly verified\nthrough a toy model that is general enough to abstract the physical-layer key\ngeneration (PLKG) mechanisms. Analysis and results demonstrate that the\nproposed scheme can dramatically reduce secret outage probability, so that key\nsources with even high exposure probability can be practically beneficial for\nactual secret communication. Our framework paves the way for achieving\ninformation-theoretic security by integrating various key sources, such as\nphysical layer key generation, lattice-based cryptography, and quantum\ncryptography.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 04:46:33 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 07:14:13 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Li", "Longjiang", ""], ["Ma", "Bingchuan", ""], ["Yang", "Jianjun", ""], ["Li", "Yonggang", ""], ["Mao", "Yuming", ""]]}, {"id": "2010.11453", "submitter": "Ayush Kumar", "authors": "Ayush Kumar, Mrinalini Shridhar, Sahithya Swaminathan, Teng Joon Lim", "title": "Machine Learning-Based Early Detection of IoT Botnets Using Network-Edge\n  Traffic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a lightweight IoT botnet detection solution, EDIMA,\nwhich is designed to be deployed at the edge gateway installed in home networks\nand targets early detection of botnets prior to the launch of an attack. EDIMA\nincludes a novel two-stage Machine Learning (ML)-based detector developed\nspecifically for IoT bot detection at the edge gateway. The ML-based bot\ndetector first employs ML algorithms for aggregate traffic classification and\nsubsequently Autocorrelation Function (ACF)-based tests to detect individual\nbots. The EDIMA architecture also comprises a malware traffic database, a\npolicy engine, a feature extractor and a traffic parser. Performance evaluation\nresults show that EDIMA achieves high bot scanning and bot-CnC traffic\ndetection accuracies with very low false positive rates. The detection\nperformance is also shown to be robust to an increase in the number of IoT\ndevices connected to the edge gateway where EDIMA is deployed. Further, the\nruntime performance analysis of a Python implementation of EDIMA deployed on a\nRaspberry Pi reveals low bot detection delays and low RAM consumption. EDIMA is\nalso shown to outperform existing detection techniques for bot scanning traffic\nand bot-CnC server communication.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 05:29:48 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Kumar", "Ayush", ""], ["Shridhar", "Mrinalini", ""], ["Swaminathan", "Sahithya", ""], ["Lim", "Teng Joon", ""]]}, {"id": "2010.11461", "submitter": "Yangxia Hu", "authors": "Yangxia Hu, Maode Ma, Wenhuan Lu, Neal N. Xiong, Jianguo Wei", "title": "Selection of the optimal embedding positions of digital audio\n  watermarking in wavelet domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work studied embedding positions of digital audio watermarking in\nwavelet domain, to make beginners understand the nature of watermarking in a\nshort time. Based on the theory of wavelet transform, this paper analyzed\nstatistical distributions of each level after transformation and the features\nof watermark embedded in different transform levels. Through comparison and\nanalysis, we found that watermark was suitable for embedding into the\ncoefficients of the first four levels of wavelet transform. In current\nstate-of-art approaches, the embedding algorithms were always to replace the\ncoefficient values of the embedded positions. In contrast this paper proposed\nan embedding algorithm of selfadaptive interpolation to achieve a better\nimperceptibility. In order to reduce the computational complexity, we took a\npseudo random sequence with a length of 31 bits as the watermark. In the\nexperiments, watermark was embedded in different locations, including different\ntransform levels, high-frequency coefficients and low-frequency coefficients,\nhigh-energy regions and low-frequency regions. Results showed that the\nimperceptibility was better than traditional embedding algorithms. The bit\nerror rates of the extracted watermark were calculated and we analyzed the\nrobustness and fragility of each embedded signal. At last we concluded the best\nembedding positions of watermark for different applications and our future\nwork.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 05:56:51 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Hu", "Yangxia", ""], ["Ma", "Maode", ""], ["Lu", "Wenhuan", ""], ["Xiong", "Neal N.", ""], ["Wei", "Jianguo", ""]]}, {"id": "2010.11463", "submitter": "Xiaoxiao Li", "authors": "Xiaoxiao Li, Yangsibo Huang, Binghui Peng, Zhao Song, Kai Li", "title": "MixCon: Adjusting the Separability of Data Representations for Harder\n  Data Recovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To address the issue that deep neural networks (DNNs) are vulnerable to model\ninversion attacks, we design an objective function, which adjusts the\nseparability of the hidden data representations, as a way to control the\ntrade-off between data utility and vulnerability to inversion attacks. Our\nmethod is motivated by the theoretical insights of data separability in neural\nnetworking training and results on the hardness of model inversion.\nEmpirically, by adjusting the separability of data representation, we show that\nthere exist sweet-spots for data separability such that it is difficult to\nrecover data during inference while maintaining data utility.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 06:02:44 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Li", "Xiaoxiao", ""], ["Huang", "Yangsibo", ""], ["Peng", "Binghui", ""], ["Song", "Zhao", ""], ["Li", "Kai", ""]]}, {"id": "2010.11607", "submitter": "Yiming Li", "authors": "Tongqing Zhai, Yiming Li, Ziqi Zhang, Baoyuan Wu, Yong Jiang, Shu-Tao\n  Xia", "title": "Backdoor Attack against Speaker Verification", "comments": "Accepted by the ICASSP 2021. The first two authors contributed\n  equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker verification has been widely and successfully adopted in many\nmission-critical areas for user identification. The training of speaker\nverification requires a large amount of data, therefore users usually need to\nadopt third-party data ($e.g.$, data from the Internet or third-party data\ncompany). This raises the question of whether adopting untrusted third-party\ndata can pose a security threat. In this paper, we demonstrate that it is\npossible to inject the hidden backdoor for infecting speaker verification\nmodels by poisoning the training data. Specifically, we design a\nclustering-based attack scheme where poisoned samples from different clusters\nwill contain different triggers ($i.e.$, pre-defined utterances), based on our\nunderstanding of verification tasks. The infected models behave normally on\nbenign samples, while attacker-specified unenrolled triggers will successfully\npass the verification even if the attacker has no information about the\nenrolled speaker. We also demonstrate that existing backdoor attacks cannot be\ndirectly adopted in attacking speaker verification. Our approach not only\nprovides a new perspective for designing novel attacks, but also serves as a\nstrong baseline for improving the robustness of verification methods. The code\nfor reproducing main results is available at\n\\url{https://github.com/zhaitongqing233/Backdoor-attack-against-speaker-verification}.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 11:10:08 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 01:17:48 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2021 00:17:25 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Zhai", "Tongqing", ""], ["Li", "Yiming", ""], ["Zhang", "Ziqi", ""], ["Wu", "Baoyuan", ""], ["Jiang", "Yong", ""], ["Xia", "Shu-Tao", ""]]}, {"id": "2010.11627", "submitter": "Kumail Raza", "authors": "Syed Muhammad Kumail Raza and Juan Caballero", "title": "Malware Traffic Classification: Evaluation of Algorithms and an\n  Automated Ground-truth Generation Pipeline", "comments": "Submission to arxiv was not authorized by one of the authors. They\n  request removal of the document. Suspected plagiarised work without proper\n  acknowledgement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying threats in a network traffic flow which is encrypted is uniquely\nchallenging. On one hand it is extremely difficult to simply decrypt the\ntraffic due to modern encryption algorithms. On the other hand, passing such an\nencrypted stream through pattern matching algorithms is useless because\nencryption ensures there aren't any. Moreover, evaluating such models is also\ndifficult due to lack of labeled benign and malware datasets. Other approaches\nhave tried to tackle this problem by employing observable meta-data gathered\nfrom the flow. We try to augment this approach by extending it to a\nsemi-supervised malware classification pipeline using these observable\nmeta-data. To this end, we explore and test different kind of clustering\napproaches which make use of unique and diverse set of features extracted from\nthis observable meta-data. We also, propose an automated packet data-labeling\npipeline to generate ground-truth data which can serve as a base-line to\nevaluate the classifiers mentioned above in particular, or any other detection\nmodel in general.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 11:48:51 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 11:51:07 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Raza", "Syed Muhammad Kumail", ""], ["Caballero", "Juan", ""]]}, {"id": "2010.11658", "submitter": "Yu-Hsuan Huang", "authors": "Kai-Min Chung, Serge Fehr, Yu-Hsuan Huang, Tai-Ning Liao", "title": "On the Compressed-Oracle Technique, and Post-Quantum Security of Proofs\n  of Sequential Work", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the so-called compressed oracle technique, introduced by Zhandry\nfor analyzing quantum algorithms in the quantum random oracle model (QROM). To\nstart off with, we offer a concise exposition of the technique, which easily\nextends to the parallel-query QROM, where in each query-round the considered\nalgorithm may make several queries to the QROM in parallel. This variant of the\nQROM allows for a more fine-grained query-complexity analysis.\n  Our main technical contribution is a framework that simplifies the use of\n(the parallel-query generalization of) the compressed oracle technique for\nproving query complexity results. With our framework in place, whenever\napplicable, it is possible to prove quantum query complexity lower bounds by\nmeans of purely classical reasoning. More than that, for typical examples the\ncrucial classical observations that give rise to the classical bounds are\nsufficient to conclude the corresponding quantum bounds.\n  We demonstrate this on a few examples, recovering known results (like the\noptimality of parallel Grover), but also obtaining new results (like the\noptimality of parallel BHT collision search). Our main target is the hardness\nof finding a $q$-chain with fewer than $q$ parallel queries, i.e., a sequence\n$x_0, x_1,\\ldots, x_q$ with $x_i = H(x_{i-1})$ for all $1 \\leq i \\leq q$.\n  The above problem of finding a hash chain is of fundamental importance in the\ncontext of proofs of sequential work. Indeed, as a concrete cryptographic\napplication of our techniques, we prove that the \"Simple Proofs of Sequential\nWork\" proposed by Cohen and Pietrzak remains secure against quantum attacks.\nSuch an analysis is not simply a matter of plugging in our new bound; the\nentire protocol needs to be analyzed in the light of a quantum attack. Thanks\nto our framework, this can now be done with purely classical reasoning.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 12:44:08 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 12:00:18 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 17:34:03 GMT"}, {"version": "v4", "created": "Fri, 9 Jul 2021 09:06:07 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Chung", "Kai-Min", ""], ["Fehr", "Serge", ""], ["Huang", "Yu-Hsuan", ""], ["Liao", "Tai-Ning", ""]]}, {"id": "2010.11722", "submitter": "Sagar Dasgupta", "authors": "Sagar Dasgupta, Mizanur Rahman, Mhafuzul Islam, Mashrur Chowdhury", "title": "Prediction-Based GNSS Spoofing Attack Detection for Autonomous Vehicles", "comments": "16 pages, 9 figures, paper accepted for the presentation at the\n  Transportation Research Board 100th Annual Meeting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global Navigation Satellite System (GNSS) provides Positioning, Navigation,\nand Timing (PNT) services for autonomous vehicles (AVs) using satellites and\nradio communications. Due to the lack of encryption, open-access of the coarse\nacquisition (C/A) codes, and low strength of the signal, GNSS is vulnerable to\nspoofing attacks compromising the navigational capability of the AV. A spoofed\nattack is difficult to detect as a spoofer (attacker who performs spoofing\nattack) can mimic the GNSS signal and transmit inaccurate location coordinates\nto an AV. In this study, we have developed a prediction-based spoofing attack\ndetection strategy using the long short-term memory (LSTM) model, a recurrent\nneural network model. The LSTM model is used to predict the distance traveled\nbetween two consecutive locations of an autonomous vehicle. In order to develop\nthe LSTM prediction model, we have used a publicly available real-world\ncomma2k19 driving dataset. The training dataset contains different features\n(i.e., acceleration, steering wheel angle, speed, and distance traveled between\ntwo consecutive locations) extracted from the controlled area network (CAN),\nGNSS, and inertial measurement unit (IMU) sensors of AVs. Based on the\npredicted distance traveled between the current location and the immediate\nfuture location of an autonomous vehicle, a threshold value is established\nusing the positioning error of the GNSS device and prediction error (i.e.,\nmaximum absolute error) related to distance traveled between the current\nlocation and the immediate future location. Our analysis revealed that the\nprediction-based spoofed attack detection strategy can successfully detect the\nattack in real-time.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2020 18:26:59 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Dasgupta", "Sagar", ""], ["Rahman", "Mizanur", ""], ["Islam", "Mhafuzul", ""], ["Chowdhury", "Mashrur", ""]]}, {"id": "2010.11742", "submitter": "Jiancheng Yang", "authors": "Jiancheng Yang, Yangzhou Jiang, Xiaoyang Huang, Bingbing Ni, Chenglong\n  Zhao", "title": "Learning Black-Box Attackers with Transferable Priors and Query Feedback", "comments": "NeurIPS 2020. Code is available at\n  https://github.com/TrustworthyDL/LeBA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper addresses the challenging black-box adversarial attack problem,\nwhere only classification confidence of a victim model is available. Inspired\nby consistency of visual saliency between different vision models, a surrogate\nmodel is expected to improve the attack performance via transferability. By\ncombining transferability-based and query-based black-box attack, we propose a\nsurprisingly simple baseline approach (named SimBA++) using the surrogate\nmodel, which significantly outperforms several state-of-the-art methods.\nMoreover, to efficiently utilize the query feedback, we update the surrogate\nmodel in a novel learning scheme, named High-Order Gradient Approximation\n(HOGA). By constructing a high-order gradient computation graph, we update the\nsurrogate model to approximate the victim model in both forward and backward\npass. The SimBA++ and HOGA result in Learnable Black-Box Attack (LeBA), which\nsurpasses previous state of the art by considerable margins: the proposed LeBA\nsignificantly reduces queries, while keeping higher attack success rates close\nto 100% in extensive ImageNet experiments, including attacking vision\nbenchmarks and defensive models. Code is open source at\nhttps://github.com/TrustworthyDL/LeBA.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 05:43:11 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Yang", "Jiancheng", ""], ["Jiang", "Yangzhou", ""], ["Huang", "Xiaoyang", ""], ["Ni", "Bingbing", ""], ["Zhao", "Chenglong", ""]]}, {"id": "2010.11754", "submitter": "Aniruddha Biswas", "authors": "Aniruddha Biswas and Palash Sarkar", "title": "Separation Results for Boolean Function Classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show (almost) separation between certain important classes of Boolean\nfunctions. The technique that we use is to show that the total influence of\nfunctions in one class is less than the total influence of functions in the\nother class. In particular, we show (almost) separation of several classes of\nBoolean functions which have been studied in the coding theory and cryptography\nfrom classes which have been studied in combinatorics and complexity theory.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 14:16:54 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Biswas", "Aniruddha", ""], ["Sarkar", "Palash", ""]]}, {"id": "2010.11782", "submitter": "Eric Balkanski", "authors": "Eric Balkanski, Harrison Chase, Kojin Oshiba, Alexander Rilee, Yaron\n  Singer, Richard Wang", "title": "Adversarial Attacks on Binary Image Recognition Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the study of adversarial attacks on models for binary (i.e. black\nand white) image classification. Although there has been a great deal of work\non attacking models for colored and grayscale images, little is known about\nattacks on models for binary images. Models trained to classify binary images\nare used in text recognition applications such as check processing, license\nplate recognition, invoice processing, and many others. In contrast to colored\nand grayscale images, the search space of attacks on binary images is extremely\nrestricted and noise cannot be hidden with minor perturbations in each pixel.\nThus, the optimization landscape of attacks on binary images introduces new\nfundamental challenges.\n  In this paper we introduce a new attack algorithm called SCAR, designed to\nfool classifiers of binary images. We show that SCAR significantly outperforms\nexisting $L_0$ attacks applied to the binary setting and use it to demonstrate\nthe vulnerability of real-world text recognition systems. SCAR's strong\nperformance in practice contrasts with the existence of classifiers that are\nprovably robust to large perturbations. In many cases, altering a single pixel\nis sufficient to trick Tesseract, a popular open-source text recognition\nsystem, to misclassify a word as a different word in the English dictionary. We\nalso license software from providers of check processing systems to most of the\nmajor US banks and demonstrate the vulnerability of check recognitions for\nmobile deposits. These systems are substantially harder to fool since they\nclassify both the handwritten amounts in digits and letters, independently.\nNevertheless, we generalize SCAR to design attacks that fool state-of-the-art\ncheck processing systems using unnoticeable perturbations that lead to\nmisclassification of deposit amounts. Consequently, this is a powerful method\nto perform financial fraud.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 14:57:42 GMT"}], "update_date": "2020-10-24", "authors_parsed": [["Balkanski", "Eric", ""], ["Chase", "Harrison", ""], ["Oshiba", "Kojin", ""], ["Rilee", "Alexander", ""], ["Singer", "Yaron", ""], ["Wang", "Richard", ""]]}, {"id": "2010.11796", "submitter": "Bo Feng", "authors": "Bo Feng, Qian Lou, Lei Jiang, and Geoffrey C. Fox", "title": "CryptoGRU: Low Latency Privacy-Preserving Text Analysis With GRU", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Billions of text analysis requests containing private emails, personal text\nmessages, and sensitive online reviews, are processed by recurrent neural\nnetworks (RNNs) deployed on public clouds every day. Although prior secure\nnetworks combine homomorphic encryption (HE) and garbled circuit (GC) to\npreserve users' privacy, naively adopting the HE and GC hybrid technique to\nimplement RNNs suffers from long inference latency due to slow activation\nfunctions. In this paper, we present a HE and GC hybrid gated recurrent unit\n(GRU) network, CryptoGRU, for low-latency secure inferences. CryptoGRU replaces\ncomputationally expensive GC-based $tanh$ with fast GC-based $ReLU$, and then\nquantizes $sigmoid$ and $ReLU$ with a smaller bit length to accelerate\nactivations in a GRU. We evaluate CryptoGRU with multiple GRU models trained on\n4 public datasets. Experimental results show CryptoGRU achieves top-notch\naccuracy and improves the secure inference latency by up to $138\\times$ over\none of state-of-the-art secure networks on the Penn Treebank dataset.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 15:20:54 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Feng", "Bo", ""], ["Lou", "Qian", ""], ["Jiang", "Lei", ""], ["Fox", "Geoffrey C.", ""]]}, {"id": "2010.11947", "submitter": "Zekun Xu", "authors": "Zekun Xu, Abhinav Aggarwal, Oluwaseyi Feyisetan, Nathanael Teissier", "title": "A Differentially Private Text Perturbation Method Using a Regularized\n  Mahalanobis Metric", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Balancing the privacy-utility tradeoff is a crucial requirement of many\npractical machine learning systems that deal with sensitive customer data. A\npopular approach for privacy-preserving text analysis is noise injection, in\nwhich text data is first mapped into a continuous embedding space, perturbed by\nsampling a spherical noise from an appropriate distribution, and then projected\nback to the discrete vocabulary space. While this allows the perturbation to\nadmit the required metric differential privacy, often the utility of downstream\ntasks modeled on this perturbed data is low because the spherical noise does\nnot account for the variability in the density around different words in the\nembedding space. In particular, words in a sparse region are likely unchanged\neven when the noise scale is large. %Using the global sensitivity of the\nmechanism can potentially add too much noise to the words in the dense regions\nof the embedding space, causing a high utility loss, whereas using local\nsensitivity can leak information through the scale of the noise added.\n  In this paper, we propose a text perturbation mechanism based on a carefully\ndesigned regularized variant of the Mahalanobis metric to overcome this\nproblem. For any given noise scale, this metric adds an elliptical noise to\naccount for the covariance structure in the embedding space. This heterogeneity\nin the noise scale along different directions helps ensure that the words in\nthe sparse region have sufficient likelihood of replacement without sacrificing\nthe overall utility. We provide a text-perturbation algorithm based on this\nmetric and formally prove its privacy guarantees. Additionally, we empirically\nshow that our mechanism improves the privacy statistics to achieve the same\nlevel of utility as compared to the state-of-the-art Laplace mechanism.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 23:06:44 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Xu", "Zekun", ""], ["Aggarwal", "Abhinav", ""], ["Feyisetan", "Oluwaseyi", ""], ["Teissier", "Nathanael", ""]]}, {"id": "2010.12026", "submitter": "Niklas K\\\"uhl", "authors": "Niklas K\\\"uhl, Dominik Martin, Clemens Wolff, Melanie Volkamer", "title": "\"Healthy surveillance\": Designing a concept for privacy-preserving mask\n  recognition AI in the age of pandemics", "comments": "54th Annual Hawaii International Conference on System Sciences\n  (HICSS-54)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The obligation to wear masks in times of pandemics reduces the risk of\nspreading viruses. In case of the COVID-19 pandemic in 2020, many governments\nrecommended or even obligated their citizens to wear masks as an effective\ncountermeasure. In order to continuously monitor the compliance of this policy\nmeasure in public spaces like restaurants or tram stations by public\nauthorities, one scalable and automatable option depicts the application of\nsurveillance systems, i.e., CCTV. However, large-scale monitoring of mask\nrecognition does not only require a well-performing Artificial Intelligence,\nbut also ensure that no privacy issues are introduced, as surveillance is a\ndeterrent for citizens and regulations like General Data Protection Regulation\n(GDPR) demand strict regulations of such personal data. In this work, we show\nhow a privacy-preserving mask recognition artifact could look like, demonstrate\ndifferent options for implementation and evaluate performances. Our conceptual\ndeep-learning based Artificial Intelligence is able to achieve detection\nperformances between 95% and 99% in a privacy-friendly setting. On that basis,\nwe elaborate on the trade-off between the level of privacy preservation and\nArtificial Intelligence performance, i.e. the \"price of privacy\".\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 14:00:04 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["K\u00fchl", "Niklas", ""], ["Martin", "Dominik", ""], ["Wolff", "Clemens", ""], ["Volkamer", "Melanie", ""]]}, {"id": "2010.12078", "submitter": "Anindya Maiti", "authors": "Mohd Sabra, Anindya Maiti, Murtuza Jadliwala", "title": "Zoom on the Keystrokes: Exploiting Video Calls for Keystroke Inference\n  Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Due to recent world events, video calls have become the new norm for both\npersonal and professional remote communication. However, if a participant in a\nvideo call is not careful, he/she can reveal his/her private information to\nothers in the call. In this paper, we design and evaluate an attack framework\nto infer one type of such private information from the video stream of a call\n-- keystrokes, i.e., text typed during the call. We evaluate our video-based\nkeystroke inference framework using different experimental settings and\nparameters, including different webcams, video resolutions, keyboards,\nclothing, and backgrounds. Our relatively high keystroke inference accuracies\nunder commonly occurring and realistic settings highlight the need for\nawareness and countermeasures against such attacks. Consequently, we also\npropose and evaluate effective mitigation techniques that can automatically\nprotect users when they type during a video call.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 21:38:17 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Sabra", "Mohd", ""], ["Maiti", "Anindya", ""], ["Jadliwala", "Murtuza", ""]]}, {"id": "2010.12080", "submitter": "Edward Raff", "authors": "Edward Raff, Bobby Filar, James Holt", "title": "Getting Passive Aggressive About False Positives: Patching Deployed\n  Malware Detectors", "comments": "to appear in IEEE International Conference on Data Mining Workshop\n  (ICDM) on Deep Learning for Cyber Threat Intelligence (DL-CTI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  False positives (FPs) have been an issue of extreme importance for anti-virus\n(AV) systems for decades. As more security vendors turn to machine learning,\nalert deluge has hit critical mass with over 20% of all alerts resulting in FPs\nand, in some organizations, the number reaches half of all alerts. This\nincrease has resulted in fatigue, frustration, and, worst of all, neglect from\nsecurity workers on SOC teams. A foundational cause for FPs is that vendors\nmust build one global system to try and satisfy all customers, but have no\nmethod to adjust to individual local environments. This leads to outrageous,\nalbeit technically correct, characterization of their platforms being 99.9%\neffective. Once these systems are deployed the idiosyncrasies of individual,\nlocal environments expose blind spots that lead to FPs and uncertainty.\n  We propose a strategy for fixing false positives in production after a model\nhas already been deployed. For too long the industry has tried to combat these\nproblems with inefficient, and at times, dangerous allowlist techniques and\nexcessive model retraining which is no longer enough. We propose using a\ntechnique called passive-aggressive learning to alter a malware detection model\nto an individual's environment, eliminating false positives without sharing any\ncustomer sensitive information. We will show how to use passive-aggressive\nlearning to solve a collection of notoriously difficult false positives from a\nproduction environment without compromising the malware model's accuracy,\nreducing the total number of FP alerts by an average of 23x.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 21:40:50 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Raff", "Edward", ""], ["Filar", "Bobby", ""], ["Holt", "James", ""]]}, {"id": "2010.12112", "submitter": "Simon Oya", "authors": "Thomas Humphries, Matthew Rafuse, Lindsey Tulloch, Simon Oya, Ian\n  Goldberg, Urs Hengartner, Florian Kerschbaum", "title": "Differentially Private Learning Does Not Bound Membership Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training machine learning models on privacy-sensitive data has become a\npopular practice, driving innovation in ever-expanding fields. This has opened\nthe door to a series of new attacks, such as Membership Inference Attacks\n(MIAs), that exploit vulnerabilities in ML models in order to expose the\nprivacy of individual training samples. A growing body of literature holds up\nDifferential Privacy (DP) as an effective defense against such attacks, and\ncompanies like Google and Amazon include this privacy notion in their\nmachine-learning-as-a-service products. However, little scrutiny has been given\nto how underlying correlations or bias within the datasets used for training\nthese models can impact the privacy guarantees provided by DP. In this work, we\nchallenge prior findings that suggest DP provides a strong defense against\nMIAs. We provide theoretical and experimental evidence for cases where the\ntheoretical bounds of DP are violated by MIAs using the same attacks described\nin prior work. We first show this empirically, with real-world datasets\ncarefully split to create a distinction between member and non-member samples,\nand then we study the reason why the theoretical DP bounds break when members\nand non-members are not independent and identically distributed. Our findings\nsuggest that certain properties of datasets, such as bias or data correlation,\nplay a critical role in determining the effectiveness of DP as a privacy\npreserving mechanism against MIAs.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 00:16:46 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 22:48:46 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Humphries", "Thomas", ""], ["Rafuse", "Matthew", ""], ["Tulloch", "Lindsey", ""], ["Oya", "Simon", ""], ["Goldberg", "Ian", ""], ["Hengartner", "Urs", ""], ["Kerschbaum", "Florian", ""]]}, {"id": "2010.12134", "submitter": "Arash Shaghaghi", "authors": "Edoardo Puggioni, Arash Shaghaghi, Robin Doss, Salil S. Kanhere", "title": "Towards Decentralized IoT Updates Delivery Leveraging Blockchain and\n  Zero-Knowledge Proofs", "comments": "This is a copy of the accepted version at The 19th IEEE International\n  Symposium on Network Computing and Applications (NCA 2020) [Core Rank: A].\n  The final version appearing in the conference proceedings will have additions\n  and changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose CrowdPatching, a blockchain-based decentralized protocol, allowing\nInternet of Things (IoT) manufacturers to delegate the delivery of software\nupdates to self-interested distributors in exchange for cryptocurrency.\nManufacturers announce updates by deploying a smart contract (SC), which in\nturn will issue cryptocurrency payments to any distributor who provides an\nunforgeable proof-of-delivery. The latter is provided by IoT devices\nauthorizing the SC to issue payment to a distributor when the required\nconditions are met. These conditions include the requirement for a distributor\nto generate a zero-knowledge proof, generated with a novel proving system\ncalled zk-SNARKs. Compared with related work, CrowdPatching protocol offers\nthree main advantages. First, the number of distributors can scale indefinitely\nby enabling the addition of new distributors at any time after the initial\ndistribution by manufacturers (i.e., redistribution among the distributor\nnetwork). The latter is not possible in existing protocols and is not account\nfor. Secondly, we leverage the recent common integration of gateway or Hub in\nIoT deployments in our protocol to make CrowdPatching feasible even for the\nmore constraint IoT devices. Thirdly, the trustworthiness of distributors is\nconsidered in our protocol, rewarding the honest distributors' engagements. We\nprovide both informal and formal security analysis of CrowdPatching using\nTamarin Prover.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 02:30:54 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Puggioni", "Edoardo", ""], ["Shaghaghi", "Arash", ""], ["Doss", "Robin", ""], ["Kanhere", "Salil S.", ""]]}, {"id": "2010.12149", "submitter": "Xiaogang Zhu", "authors": "Xiaogang Zhu, Shigang Liu, Xian Li, Sheng Wen, Jun Zhang, Camtepe\n  Seyit, Yang Xiang", "title": "DeFuzz: Deep Learning Guided Directed Fuzzing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzing is one of the most effective technique to identify potential software\nvulnerabilities. Most of the fuzzers aim to improve the code coverage, and\nthere is lack of directedness (e.g., fuzz the specified path in a software). In\nthis paper, we proposed a deep learning (DL) guided directed fuzzing for\nsoftware vulnerability detection, named DeFuzz. DeFuzz includes two main\nschemes: (1) we employ a pre-trained DL prediction model to identify the\npotentially vulnerable functions and the locations (i.e., vulnerable\naddresses). Precisely, we employ Bidirectional-LSTM (BiLSTM) to identify\nattention words, and the vulnerabilities are associated with these attention\nwords in functions. (2) then we employ directly fuzzing to fuzz the potential\nvulnerabilities by generating inputs that tend to arrive the predicted\nlocations. To evaluate the effectiveness and practical of the proposed DeFuzz\ntechnique, we have conducted experiments on real-world data sets. Experimental\nresults show that our DeFuzz can discover coverage more and faster than AFL.\nMoreover, DeFuzz exposes 43 more bugs than AFL on real-world applications.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 03:44:03 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Zhu", "Xiaogang", ""], ["Liu", "Shigang", ""], ["Li", "Xian", ""], ["Wen", "Sheng", ""], ["Zhang", "Jun", ""], ["Seyit", "Camtepe", ""], ["Xiang", "Yang", ""]]}, {"id": "2010.12168", "submitter": "Sabah Suhail", "authors": "Sabah Suhail, Rasheed Hussain, Raja Jurdak, Choong Seon Hong", "title": "Trustworthy Digital Twins in the Industrial Internet of Things with\n  Blockchain", "comments": null, "journal-ref": null, "doi": "10.1109/MIC.2021.3059320", "report-no": "1089-7801", "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industrial processes rely on sensory data for critical decision-making\nprocesses. Extracting actionable insights from the collected data calls for an\ninfrastructure that can ensure the trustworthiness of data. To this end, we\nenvision a blockchain-based framework for the Industrial Internet of Things\n(IIoT) to address the issues of data management and security. Once the data\ncollected from trustworthy sources are recorded in the blockchain, product\nlifecycle events can be fed into data-driven systems for process monitoring,\ndiagnostics, and optimized control. In this regard, we leverage Digital Twins\n(DTs) that can draw intelligent conclusions from data by identifying the faults\nand recommending precautionary measures ahead of critical events. Furthermore,\nwe discuss the integration of DTs and blockchain to target key challenges of\ndisparate data repositories, untrustworthy data dissemination, and fault\ndiagnosis. Finally, we identify outstanding challenges faced by the IIoT and\nfuture research directions while leveraging blockchain and DTs.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 05:20:28 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Suhail", "Sabah", ""], ["Hussain", "Rasheed", ""], ["Jurdak", "Raja", ""], ["Hong", "Choong Seon", ""]]}, {"id": "2010.12171", "submitter": "Shiyi Yang", "authors": "Shiyi Yang, Peilun Wu, Hui Guo", "title": "DualNet: Locate Then Detect Effective Payload with Deep Attention\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network intrusion detection (NID) is an essential defense strategy that is\nused to discover the trace of suspicious user behaviour in large-scale\ncyberspace, and machine learning (ML), due to its capability of automation and\nintelligence, has been gradually adopted as a mainstream hunting method in\nrecent years. However, traditional ML based network intrusion detection systems\n(NIDSs) are not effective to recognize unknown threats and their high detection\nrate often comes with the cost of high false alarms, which leads to the problem\nof alarm fatigue. To address the above problems, in this paper, we propose a\nnovel neural network based detection system, DualNet, which is constructed with\na general feature extraction stage and a crucial feature learning stage.\nDualNet can rapidly reuse the spatial-temporal features in accordance with\ntheir importance to facilitate the entire learning process and simultaneously\nmitigate several optimization problems occurred in deep learning (DL). We\nevaluate the DualNet on two benchmark cyber attack datasets, NSL-KDD and\nUNSW-NB15. Our experiment shows that DualNet outperforms classical ML based\nNIDSs and is more effective than existing DL methods for NID in terms of\naccuracy, detection rate and false alarm rate.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 05:32:21 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Yang", "Shiyi", ""], ["Wu", "Peilun", ""], ["Guo", "Hui", ""]]}, {"id": "2010.12252", "submitter": "Dabao Wang", "authors": "Dabao Wang, Siwei Wu, Ziling Lin, Lei Wu, Xingliang Yuan, Yajin Zhou,\n  Haoyu Wang, Kui Ren", "title": "Towards A First Step to Understand Flash Loan and Its Applications in\n  DeFi Ecosystem", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": "10.1145/3457977.3460301", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flash Loan, as an emerging service in the decentralized finance ecosystem,\nallows users to request a non-collateral loan. While providing convenience, it\nalso enables attackers to launch malicious operations with a large amount of\nasset that they do not have. Though there exist spot media reports of attacks\nthat leverage Flash Loan, there lacks a comprehensive understanding of existing\nFlash Loan services. In this work, we take the first step to study the Flash\nLoan service provided by three popular platforms. Specifically, we first\nillustrate the interactions between Flash Loan providers and users. Then, we\ndesign three patterns to identify Flash Loan transactions. Based on the\npatterns, 76, 303 transactions are determined. The evaluation results show that\nthe Flash Loan services get more popular over time. At last, we present four\nFlash Loan applications with real-world examples and propose two potential\nresearch directions.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 09:31:15 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 04:30:17 GMT"}, {"version": "v3", "created": "Wed, 21 Apr 2021 01:31:36 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Wang", "Dabao", ""], ["Wu", "Siwei", ""], ["Lin", "Ziling", ""], ["Wu", "Lei", ""], ["Yuan", "Xingliang", ""], ["Zhou", "Yajin", ""], ["Wang", "Haoyu", ""], ["Ren", "Kui", ""]]}, {"id": "2010.12269", "submitter": "Dario Pasquini", "authors": "Dario Pasquini, Marco Cianfriglia, Giuseppe Ateniese, Massimo\n  Bernaschi", "title": "Reducing Bias in Modeling Real-world Password Strength via Deep Learning\n  and Dynamic Dictionaries", "comments": "To appear in the proceedings of the 30th USENIX Security Symposium\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Password security hinges on an in-depth understanding of the techniques\nadopted by attackers. Unfortunately, real-world adversaries resort to pragmatic\nguessing strategies such as dictionary attacks that are inherently difficult to\nmodel in password security studies. In order to be representative of the actual\nthreat, dictionary attacks must be thoughtfully configured and tuned. However,\nthis process requires a domain-knowledge and expertise that cannot be easily\nreplicated. The consequence of inaccurately calibrating dictionary attacks is\nthe unreliability of password security analyses, impaired by a severe\nmeasurement bias.\n  In the present work, we introduce a new generation of dictionary attacks that\nis consistently more resilient to inadequate configurations. Requiring no\nsupervision or domain-knowledge, this technique automatically approximates the\nadvanced guessing strategies adopted by real-world attackers. To achieve this:\n(1) We use deep neural networks to model the proficiency of adversaries in\nbuilding attack configurations. (2) Then, we introduce dynamic guessing\nstrategies within dictionary attacks. These mimic experts' ability to adapt\ntheir guessing strategies on the fly by incorporating knowledge on their\ntargets.\n  Our techniques enable more robust and sound password strength estimates\nwithin dictionary attacks, eventually reducing overestimation in modeling\nreal-world threats in password security. Code available:\nhttps://github.com/TheAdamProject/adams\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 09:53:44 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 10:13:31 GMT"}, {"version": "v3", "created": "Sat, 12 Dec 2020 11:39:18 GMT"}, {"version": "v4", "created": "Wed, 24 Feb 2021 21:09:33 GMT"}, {"version": "v5", "created": "Fri, 26 Feb 2021 08:41:28 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Pasquini", "Dario", ""], ["Cianfriglia", "Marco", ""], ["Ateniese", "Giuseppe", ""], ["Bernaschi", "Massimo", ""]]}, {"id": "2010.12280", "submitter": "Raha Motaghi", "authors": "Z. Motaqy, N.Yazdani and B. Bahrak", "title": "A Collaboration Framework Based On Incentive Compatible Mechanisms In\n  The Blockchain Model", "comments": "The body needs more writing polish too", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In agreements among anonymous users, smart contract eliminate the need for a\ntrusted intermediary and enforce its terms when the conditions set by the\nparties are met. Smart contracts can also have access to real-world data\nthrough oracle services, an emerging feature of smart contract systems. This\nmeans that anonymous users can bet on an event and the financial benefit gives\nthem the incentive to contribute to that event occurrence. More specifically, a\nsmart contract stimulates new forms of trustless collaboration through betting.\nThis encourages collaborative work in the context of distributed digital\nservice, e.g., content distribution or file storage but it can be used for\ncollaborative attacks (e.g., DDoS) since users need neither trust anybody nor\nreveal their identity. In this paper, we present a collaboration framework\nbased on an incentive mechanism implemented in a smart contract. To explore the\nfeasibility of malicious collaboration, we the case of a collaborative\ndistributed denial of service attack in which multiple minibotnet bet on a\nsponsored DDoS attack. The attackers' interaction is formulated as a game and\nit's shown that the attackers will collaborate in proportion to the amount of\ntheir bets. There is a possibility that a user pretends to be several parties,\nit is hard to know the exact number of bidding users or the amount of their\nbids, which are essential for predicting the attack result. We model the\nproposed smart contract as an incentive mechanism and prove that users will not\nmisrepresent the amount of their bets. So based on each user's amount of bet\nand the attack result (reported by the oracle), each user's share of reward is\ncalculated. The numerical simulations show that if the attack-target uses the\nattack details to prepare and defend, by increasing the cost of producing\neffective attack traffic, they can change the result and so prevent such\nattack.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 10:21:53 GMT"}, {"version": "v2", "created": "Sun, 11 Apr 2021 08:04:20 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Motaqy", "Z.", ""], ["Yazdani", "N.", ""], ["Bahrak", "B.", ""]]}, {"id": "2010.12346", "submitter": "Chong Xiao Wang", "authors": "Chong Xiao Wang and Wee Peng Tay", "title": "Data-driven Regularized Inference Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data is used widely by service providers as input to inference systems to\nperform decision making for authorized tasks. The raw data however allows a\nservice provider to infer other sensitive information it has not been\nauthorized for. We propose a data-driven inference privacy preserving framework\nto sanitize data so as to prevent leakage of sensitive information that is\npresent in the raw data, while ensuring that the sanitized data is still\ncompatible with the service provider's legacy inference system. We develop an\ninference privacy framework based on the variational method and include maximum\nmean discrepancy and domain adaption as techniques to regularize the domain of\nthe sanitized data to ensure its legacy compatibility. However, the variational\nmethod leads to weak privacy in cases where the underlying data distribution is\nhard to approximate. It may also face difficulties when handling continuous\nprivate variables. To overcome this, we propose an alternative formulation of\nthe privacy metric using maximal correlation and we present empirical methods\nto estimate it. Finally, we develop a deep learning model as an example of the\nproposed inference privacy framework. Numerical experiments verify the\nfeasibility of our approach.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2020 08:42:59 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Wang", "Chong Xiao", ""], ["Tay", "Wee Peng", ""]]}, {"id": "2010.12400", "submitter": "Yajin Zhou", "authors": "Yuan Chen, Jiaqi Li, Guorui Xu, Yajin Zhou, Zhi Wang, Cong Wang, Kui\n  Ren", "title": "Towards Efficiently Establishing Mutual Distrust Between Host\n  Application and Enclave for SGX", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since its debut, SGX has been used in many applications, e.g., secure data\nprocessing. However, previous systems usually assume a trusted enclave and\nignore the security issues caused by an untrusted enclave. For instance, a\nvulnerable (or even malicious) third-party enclave can be exploited to attack\nthe host application and the rest of the system. In this paper, we propose an\nefficient mechanism to confine an untrusted enclave's behaviors. The threats of\nan untrusted enclave come from the enclave-host asymmetries. They can be abused\nto access arbitrary memory regions of its host application, jump to any code\nlocation after leaving the enclave and forge the stack register to manipulate\nthe saved context. Our solution breaks such asymmetries and establishes mutual\ndistrust between the host application and the enclave. It leverages Intel MPK\nfor efficient memory isolation and the x86 single-step debugging mechanism to\ncapture the event when an enclave is existing. It then performs the integrity\ncheck for the jump target and the stack pointer. We have solved two practical\nchallenges and implemented a prototype system. The evaluation with multiple\nmicro-benchmarks and representative real-world applications demonstrated the\nefficiency of our system, with less than 4% performance overhead.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 13:43:45 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Chen", "Yuan", ""], ["Li", "Jiaqi", ""], ["Xu", "Guorui", ""], ["Zhou", "Yajin", ""], ["Wang", "Zhi", ""], ["Wang", "Cong", ""], ["Ren", "Kui", ""]]}, {"id": "2010.12415", "submitter": "Juergen Schatzmann", "authors": "J\\\"urgen E. Schatzmann and Bernhard Haslhofer", "title": "Bitcoin Trading is Irrational! An Analysis of the Disposition Effect in\n  Bitcoin", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.CR q-fin.EC q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Investors tend to sell their winning investments and hold onto their losers.\nThis phenomenon, known as the \\emph{disposition effect} in the field of\nbehavioural finance, is well-known and its prevalence has been shown in a\nnumber of existing markets. But what about new atypical markets like\ncryptocurrencies? Do investors act as irrationally as in traditional markets?\nOne might suspect this and hypothesise that cryptocurrency sells occur more\nfrequently in positive market conditions and less frequently in negative market\nconditions. However, there is still no empirical evidence to support this. In\nthis paper, we expand on existing research and empirically investigate the\nprevalence of the disposition effect in Bitcoin by testing this hypothesis. Our\nresults show that investors are indeed subject to the disposition effect,\ntending to sell their winning positions too soon and holding on to their losing\nposition for too long. This effect is very prominently evident from the boom\nand bust year 2017 onwards, confirmed via most of the applied technical\nindicators. In this study, we show that Bitcoin traders act just as\nirrationally as traders in other, more established markets.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 14:06:19 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Schatzmann", "J\u00fcrgen E.", ""], ["Haslhofer", "Bernhard", ""]]}, {"id": "2010.12502", "submitter": "Gonzalo Seco-Granados", "authors": "Gonzalo Seco-Granados, David Gomez-Casco, Jose A. Lopez-Salcedo,\n  Ignacio Fernandez-Hernandez", "title": "Detection of Replay Attacks to GNSS based on Partial Correlations and\n  Authentication Data Unpredictability", "comments": null, "journal-ref": "GPS Solutions, 2021", "doi": "10.1007/s10291-020-01049-z", "report-no": null, "categories": "cs.CR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intentional interference, and in particular GNSS spoofing, is currently one\nof the most significant concerns of the Positioning, Navigation and Timing\n(PNT) community. With the adoption of Open Service Navigation Message\nAuthentication (OSNMA) in Galileo, the E1B signal component will continuously\nbroadcast unpredictable cryptographic data. This allows GNSS receivers not only\nto ensure the authenticity of data origin but also to detect replay spoofing\nattacks for receivers already tracking real signals with relatively good\nvisibility conditions. Since the spoofer needs to estimate the unpredictable\nbits introduced by OSNMA with almost zero delay in order to perform a Security\nCode Estimation and Replay (SCER) attack, the spoofer unavoidably introduces a\nslight distortion into the signal, which can be the basis of a spoofing\ndetector. In this work, we propose five detectors based on partial correlations\nof GNSS signals obtained over predictable and unpredictable parts of the\nsignals. We evaluate them in a wide set of test cases, including different\ntypes of receiver and spoofing conditions. The results show that one of the\ndetectors is consistently superior to the others, and it is able to detect SCER\nattacks with a high probability even in favorable conditions for the spoofer.\nFinally, we discuss some practical considerations for implementing the proposed\ndetector in receivers, in particular when the Galileo OSNMA message structure\nis used.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 16:09:17 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 19:57:27 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Seco-Granados", "Gonzalo", ""], ["Gomez-Casco", "David", ""], ["Lopez-Salcedo", "Jose A.", ""], ["Fernandez-Hernandez", "Ignacio", ""]]}, {"id": "2010.12577", "submitter": "Hansjoerg Albrecher", "authors": "Hansjoerg Albrecher and Pierre-Olivier Goffard", "title": "On the profitability of selfish blockchain mining under consideration of\n  ruin", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.OC math.PR q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining blocks on a blockchain equipped with a proof of work consensus\nprotocol is well-known to be resource-consuming. A miner bears the operational\ncost, mainly electricity consumption and IT gear, of mining, and is compensated\nby a capital gain when a block is discovered. This paper aims at quantifying\nthe profitability of mining when the possible event of ruin is also considered.\nThis is done by formulating a tractable stochastic model and using tools from\napplied probability and analysis, including the explicit solution of a certain\ntype of advanced functional differential equation. The expected profit at a\nfuture time point is determined for the situation when the miner follows the\nprotocol as well as when he/she withholds blocks. The obtained explicit\nexpressions allow to analyze the sensitivity with respect to the different\nmodel ingredients and to identify conditions under which selfish mining is a\nstrategic advantage.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 15:21:45 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Albrecher", "Hansjoerg", ""], ["Goffard", "Pierre-Olivier", ""]]}, {"id": "2010.12603", "submitter": "Ryan McKenna", "authors": "Ryan McKenna and Daniel Sheldon", "title": "Permute-and-Flip: A new mechanism for differentially private selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of differentially private selection. Given a finite\nset of candidate items and a quality score for each item, our goal is to design\na differentially private mechanism that returns an item with a score that is as\nhigh as possible. The most commonly used mechanism for this task is the\nexponential mechanism. In this work, we propose a new mechanism for this task\nbased on a careful analysis of the privacy constraints. The expected score of\nour mechanism is always at least as large as the exponential mechanism, and can\noffer improvements up to a factor of two. Our mechanism is simple to implement\nand runs in linear time.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 18:20:26 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["McKenna", "Ryan", ""], ["Sheldon", "Daniel", ""]]}, {"id": "2010.12640", "submitter": "Ibrahim Yilmaz", "authors": "ibrahim Yilmaz and Ambareen Siraj", "title": "Avoiding Occupancy Detection from Smart Meter using Adversarial Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More and more conventional electromechanical meters are being replaced with\nsmart meters because of their substantial benefits such as providing faster\nbi-directional communication between utility services and end users, enabling\ndirect load control for demand response, energy saving, and so on. However, the\nfine-grained usage data provided by smart meter brings additional\nvulnerabilities from users to companies. Occupancy detection is one such\nexample which causes privacy violation of smart meter users. Detecting the\noccupancy of a home is straightforward with time of use information as there is\na strong correlation between occupancy and electricity usage. In this work, our\nmajor contributions are twofold. First, we validate the viability of an\noccupancy detection attack based on a machine learning technique called Long\nShort Term Memory (LSTM) method and demonstrate improved results. In addition,\nwe introduce an Adversarial Machine Learning Occupancy Detection Avoidance\n(AMLODA) framework as a counter attack in order to prevent abuse of energy\nconsumption. Essentially, the proposed privacy-preserving framework is designed\nto mask real-time or near real-time electricity usage information using\ncalculated optimum noise without compromising users' billing systems\nfunctionality. Our results show that the proposed privacy-aware billing\ntechnique upholds users' privacy strongly.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 20:02:48 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Yilmaz", "ibrahim", ""], ["Siraj", "Ambareen", ""]]}, {"id": "2010.12641", "submitter": "Eleonora Losiouk", "authors": "Marco Casagrande, Mauro Conti, Eleonora Losiouk", "title": "Contact Tracing Made Un-relay-able", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated contact tracing is a key solution to control the spread of airborne\ntransmittable diseases: it traces contacts among individuals in order to alert\npeople about their potential risk of being infected. The current SARS-CoV-2\npandemic put a heavy strain on the healthcare system of many countries.\nGovernments chose different approaches to face the spread of the virus and the\ncontact tracing apps were considered the most effective ones. In particular, by\nleveraging on the Bluetooth Low-Energy technology, mobile apps allow to achieve\na privacy-preserving contact tracing of citizens. While researchers proposed\nseveral contact tracing approaches, each government developed its own national\ncontact tracing app.\n  In this paper, we demonstrate that many popular contact tracing apps (e.g.,\nthe ones promoted by the Italian, French, Swiss government) are vulnerable to\nrelay attacks. Through such attacks people might get misleadingly diagnosed as\npositive to SARS-CoV-2, thus being enforced to quarantine and eventually\nleading to a breakdown of the healthcare system. To tackle this vulnerability,\nwe propose a novel and lightweight solution that prevents relay attacks, while\nproviding the same privacy-preserving features as the current approaches. To\nevaluate the feasibility of both the relay attack and our novel defence\nmechanism, we developed a proof of concept against the Italian contact tracing\napp (i.e., Immuni). The design of our defence allows it to be integrated into\nany contact tracing app.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 20:03:31 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 16:56:56 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Casagrande", "Marco", ""], ["Conti", "Mauro", ""], ["Losiouk", "Eleonora", ""]]}, {"id": "2010.12704", "submitter": "Ashkan Vakil", "authors": "Ashkan Vakil, Farzad Niknia, Ali Mirzaeian, Avesta Sasan, Naghmeh\n  Karimi", "title": "Learning Assisted Side Channel Delay Test for Detection of Recycled ICs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the outsourcing of design flow, ensuring the security and\ntrustworthiness of integrated circuits has become more challenging. Among the\nsecurity threats, IC counterfeiting and recycled ICs have received a lot of\nattention due to their inferior quality, and in turn, their negative impact on\nthe reliability and security of the underlying devices. Detecting recycled ICs\nis challenging due to the effect of process variations and process drift\noccurring during the chip fabrication. Moreover, relying on a golden chip as a\nbasis for comparison is not always feasible. Accordingly, this paper presents a\nrecycled IC detection scheme based on delay side-channel testing. The proposed\nmethod relies on the features extracted during the design flow and the sample\ndelays extracted from the target chip to build a Neural Network model using\nwhich the target chip can be truly identified as new or recycled. The proposed\nmethod classifies the timing paths of the target chip into two groups based on\ntheir vulnerability to aging using the information collected from the design\nand detects the recycled ICs based on the deviation of the delay of these two\nsets from each other.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 23:13:16 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Vakil", "Ashkan", ""], ["Niknia", "Farzad", ""], ["Mirzaeian", "Ali", ""], ["Sasan", "Avesta", ""], ["Karimi", "Naghmeh", ""]]}, {"id": "2010.12751", "submitter": "Bang Wu", "authors": "Bang Wu, Xiangwen Yang, Shirui Pan, Xingliang Yuan", "title": "Model Extraction Attacks on Graph Neural Networks: Taxonomy and\n  Realization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have been widely used to analyze the\ngraph-structured data in various application domains, e.g., social networks,\nmolecular biology, and anomaly detection. With great power, the GNN models,\nusually as valuable Intellectual Properties of their owners, also become\nattractive targets of the attacker. Recent studies show that machine learning\nmodels are facing a severe threat called Model Extraction Attacks, where a\nwell-trained private model owned by a service provider can be stolen by the\nattacker pretending as a client. Unfortunately, existing works focus on the\nmodels trained on the Euclidean space, e.g., images and texts, while how to\nextract a GNN model that contains a graph structure and node features is yet to\nbe explored. In this paper, we explore and develop model extraction attacks\nagainst GNN models. Given only black-box access to a target GNN model, the\nattacker aims to reconstruct a duplicated one via several nodes he obtained\n(called attacker nodes). We first systematically formalise the threat modeling\nin the context of GNN model extraction and classify the adversarial threats\ninto seven categories by considering different background knowledge of the\nattacker, e.g., attributes and/or neighbor connectives of the attacker nodes.\nThen we present the detailed methods which utilize the accessible knowledge in\neach threat to implement the attacks. By evaluating over three real-world\ndatasets, our attacks are shown to extract duplicated models effectively, i.e.,\nmore than 89% inputs in the target domain have the same output predictions as\nthe victim model.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 03:09:37 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Wu", "Bang", ""], ["Yang", "Xiangwen", ""], ["Pan", "Shirui", ""], ["Yuan", "Xingliang", ""]]}, {"id": "2010.12799", "submitter": "Bryan Kian Hsiang Low", "authors": "Dmitrii Kharkovskii, Zhongxiang Dai, Bryan Kian Hsiang Low", "title": "Private Outsourced Bayesian Optimization", "comments": "37th International Conference on Machine Learning (ICML 2020),\n  Extended version with proofs, 27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the private-outsourced-Gaussian process-upper confidence\nbound (PO-GP-UCB) algorithm, which is the first algorithm for\nprivacy-preserving Bayesian optimization (BO) in the outsourced setting with a\nprovable performance guarantee. We consider the outsourced setting where the\nentity holding the dataset and the entity performing BO are represented by\ndifferent parties, and the dataset cannot be released non-privately. For\nexample, a hospital holds a dataset of sensitive medical records and outsources\nthe BO task on this dataset to an industrial AI company. The key idea of our\napproach is to make the BO performance of our algorithm similar to that of\nnon-private GP-UCB run using the original dataset, which is achieved by using a\nrandom projection-based transformation that preserves both privacy and the\npairwise distances between inputs. Our main theoretical contribution is to show\nthat a regret bound similar to that of the standard GP-UCB algorithm can be\nestablished for our PO-GP-UCB algorithm. We empirically evaluate the\nperformance of our PO-GP-UCB algorithm with synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 06:30:45 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Kharkovskii", "Dmitrii", ""], ["Dai", "Zhongxiang", ""], ["Low", "Bryan Kian Hsiang", ""]]}, {"id": "2010.12809", "submitter": "Asaf Shabtai", "authors": "Tal Ben Senior and Yael Mathov and Asaf Shabtai and Yuval Elovici", "title": "Stop Bugging Me! Evading Modern-Day Wiretapping Using Adversarial\n  Perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CR cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mass surveillance systems for voice over IP (VoIP) conversations pose a huge\nrisk to privacy. These automated systems use learning models to analyze\nconversations, and upon detecting calls that involve specific topics, route\nthem to a human agent. In this study, we present an adversarial learning-based\nframework for privacy protection for VoIP conversations. We present a novel\nalgorithm that finds a universal adversarial perturbation (UAP), which, when\nadded to the audio stream, prevents an eavesdropper from automatically\ndetecting the conversation's topic. As shown in our experiments, the UAP is\nagnostic to the speaker or audio length, and its volume can be changed in\nreal-time, as needed. In a real-world demonstration, we use a Teensy\nmicrocontroller that acts as an external microphone and adds the UAP to the\naudio in real-time. We examine different speakers, VoIP applications (Skype,\nZoom), audio lengths, and speech-to-text models (Deep Speech, Kaldi). Our\nresults in the real world suggest that our approach is a feasible solution for\nprivacy protection.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 06:56:35 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Senior", "Tal Ben", ""], ["Mathov", "Yael", ""], ["Shabtai", "Asaf", ""], ["Elovici", "Yuval", ""]]}, {"id": "2010.12816", "submitter": "Sebastian Perez-Salazar", "authors": "Sebastian Perez-Salazar, Rachel Cummings", "title": "Differentially Private Online Submodular Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we consider the problem of online submodular maximization under\na cardinality constraint with differential privacy (DP). A stream of $T$\nsubmodular functions over a common finite ground set $U$ arrives online, and at\neach time-step the decision maker must choose at most $k$ elements of $U$\nbefore observing the function. The decision maker obtains a payoff equal to the\nfunction evaluated on the chosen set, and aims to learn a sequence of sets that\nachieves low expected regret. In the full-information setting, we develop an\n$(\\varepsilon,\\delta)$-DP algorithm with expected $(1-1/e)$-regret bound of\n$\\mathcal{O}\\left( \\frac{k^2\\log |U|\\sqrt{T \\log k/\\delta}}{\\varepsilon}\n\\right)$. This algorithm contains $k$ ordered experts that learn the best\nmarginal increments for each item over the whole time horizon while maintaining\nprivacy of the functions. In the bandit setting, we provide an\n$(\\varepsilon,\\delta+ O(e^{-T^{1/3}}))$-DP algorithm with expected\n$(1-1/e)$-regret bound of $\\mathcal{O}\\left( \\frac{\\sqrt{\\log\nk/\\delta}}{\\varepsilon} (k (|U| \\log |U|)^{1/3})^2 T^{2/3} \\right)$. Our\nalgorithms contains $k$ ordered experts that learn the best marginal item to\nselect given the items chosen her predecessors, while maintaining privacy of\nthe functions. One challenge for privacy in this setting is that the payoff and\nfeedback of expert $i$ depends on the actions taken by her $i-1$ predecessors.\nThis particular type of information leakage is not covered by post-processing,\nand new analysis is required. Our techniques for maintaining privacy with\nfeedforward may be of independent interest.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 07:23:30 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Perez-Salazar", "Sebastian", ""], ["Cummings", "Rachel", ""]]}, {"id": "2010.12847", "submitter": "Abdelhakim Hannousse", "authors": "Abdelhakim Hannousse and Salima Yahiouche", "title": "Towards Benchmark Datasets for Machine Learning Based Website Phishing\n  Detection: An experimental study", "comments": null, "journal-ref": "Engineering Applications of Artificial Intelligence 104C (2021)\n  104347", "doi": "10.1016/j.engappai.2021.104347", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a general scheme for building reproducible and\nextensible datasets for website phishing detection. The aim is to (1) enable\ncomparison of systems using different features, (2) overtake the short-lived\nnature of phishing websites, and (3) keep track of the evolution of phishing\ntactics. For experimenting the proposed scheme, we start by adopting a refined\nclassification of website phishing features and we systematically select a\ntotal of 87 commonly recognized ones, we classify them, and we made them\nsubjects for relevance and runtime analysis. We use the collected set of\nfeatures to build a dataset in light of the proposed scheme. Thereafter, we use\na conceptual replication approach to check the genericity of former findings\nfor the built dataset. Specifically, we evaluate the performance of classifiers\non individual classes and on combinations of classes, we investigate different\ncombinations of models, and we explore the effects of filter and wrapper\nmethods on the selection of discriminative features. The results show that\nRandom Forest is the most predictive classifier. Features gathered from\nexternal services are found the most discriminative where features extracted\nfrom web page contents are found less distinguishing. Besides external service\nbased features, some web page content features are found time consuming and not\nsuitable for runtime detection. The use of hybrid features provided the best\naccuracy score of 96.61%. By investigating different feature selection methods,\nfilter-based ranking together with incremental removal of less important\nfeatures improved the performance up to 96.83% better than wrapper methods.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 09:21:33 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Hannousse", "Abdelhakim", ""], ["Yahiouche", "Salima", ""]]}, {"id": "2010.12862", "submitter": "Mustafa Kishk", "authors": "Ainur Zhaikhan, Mustafa A. Kishk, Hesham ElSawy, and Mohamed-Slim\n  Alouini", "title": "Safeguarding the IoT from Malware Epidemics: A Percolation Theory\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The upcoming Internet of things (IoT) is foreseen to encompass massive\nnumbers of connected devices, smart objects, and cyber-physical systems. Due to\nthe large-scale and massive deployment of devices, it is deemed infeasible to\nsafeguard 100% of the devices with state-of-the-art security countermeasures.\nHence, large-scale IoT has inevitable loopholes for network intrusion and\nmalware infiltration. Even worse, exploiting the high density of devices and\ndirect wireless connectivity, malware infection can stealthily propagate\nthrough susceptible (i.e., unsecured) devices and form an epidemic outbreak\nwithout being noticed to security administration. A malware outbreak enables\nadversaries to compromise large population of devices, which can be exploited\nto launch versatile cyber and physical malicious attacks. In this context, we\nutilize spatial firewalls, to safeguard the IoT from malware outbreak. In\nparticular, spatial firewalls are computationally capable devices equipped with\nstate-of-the-art security and anti-malware programs that are spatially deployed\nacross the network to filter the wireless traffic in order to detect and thwart\nmalware propagation. Using tools from percolation theory, we prove that there\nexists a critical density of spatial firewalls beyond which malware outbreak is\nimpossible. This, in turns, safeguards the IoT from malware epidemics\nregardless of the infection/treatment rates. To this end, a tractable upper\nbound for the critical density of spatial firewalls is obtained. Furthermore,\nwe characterize the relative communications ranges of the spatial firewalls and\nIoT devices to ensure secure network connectivity. The percentage of devices\nsecured by the firewalls is also characterized.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 10:33:25 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Zhaikhan", "Ainur", ""], ["Kishk", "Mustafa A.", ""], ["ElSawy", "Hesham", ""], ["Alouini", "Mohamed-Slim", ""]]}, {"id": "2010.12980", "submitter": "Carlos Luna Dr.", "authors": "Fernanda Molina, Gustavo Betarte, Carlos Luna", "title": "A Blockchain based and GDPR-compliant design of a system for digital\n  education certificates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain is an incipient technology that offers many strengths compared to\ntraditional systems, such as decentralization, transparency and traceability.\nHowever, if the technology is to be used for processing personal data,\ncomplementary mechanisms must be identified that provide support for building\nsystems that meet security and data protection requirements. We study the\nintegration of off-chain capabilities in blockchain-based solutions moving data\nor computational operations outside the core blockchain network. We develop a\nthorough analysis of the European data protection regulation and discuss the\nweaknesses and strengths, regarding the security and privacy requirements\nestablished by that regulation, of solutions built using blockchain technology.\nWe also put forward a methodological framework that helps systems designers in\ncombining operational off-chain constructs with traditional blockchain\nfunctionalities in order to build more secure and privacy aware solutions. We\nillustrate the use of that framework presenting and discussing the design of a\nsystem that provides services to handle, store and validate digital academic\ncertificates.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 20:46:16 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Molina", "Fernanda", ""], ["Betarte", "Gustavo", ""], ["Luna", "Carlos", ""]]}, {"id": "2010.12981", "submitter": "Carlos Molina-Jimenez", "authors": "Carlos Molina-Jimenez and Ioannis Sfyrakis and Linmao Song and Hazem\n  Danny Al Nakib and Jon Crowcroft", "title": "The Benefits of Deploying Smart Contracts on Trusted Third Parties", "comments": "The document consists of 14 pages and includes four figures, one\n  table and 76 references. It the work of five authors. Carlos Molina-Jimenez\n  is the corresponding and responsible author", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hype about Bitcoin has overrated the potential of smart contracts\ndeployed on-blockchains (on-chains) and underrated the potential of smart\ncontracts deployed on-Trusted Third Parties (on-TTPs). As a result, current\nresearch and development in this field is focused mainly on smart contract\napplications that use on-chain smart contracts. We argue that there is a large\nclass of smart contract applications where on-TTP smart contracts are a better\nalternative. The problem with on-chain smart contracts is that the fully\ndecentralised model and indelible append-only data model followed by\nblockchains introduces several engineering problems that are hard to solve. In\nthese situations, the inclusion of a TTP (assuming that the application can\ntolerate its inconveniences) instead of a blockchain to host the smart contract\nsimplifies the problems and offers pragmatic solutions. The intention and\ncontribution of this paper is to shed some light on this issue. We use a\nhypothetical use case of a car insurance application to illustrate technical\nproblems that are easier to solve with on-TTP smart contracts than with\non-chain smart contracts.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 20:49:13 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Molina-Jimenez", "Carlos", ""], ["Sfyrakis", "Ioannis", ""], ["Song", "Linmao", ""], ["Nakib", "Hazem Danny Al", ""], ["Crowcroft", "Jon", ""]]}, {"id": "2010.12989", "submitter": "Huimin Zeng", "authors": "Huimin Zeng, Chen Zhu, Tom Goldstein, Furong Huang", "title": "Are Adversarial Examples Created Equal? A Learnable Weighted Minimax\n  Risk for Robustness under Non-uniform Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial Training is proved to be an efficient method to defend against\nadversarial examples, being one of the few defenses that withstand strong\nattacks. However, traditional defense mechanisms assume a uniform attack over\nthe examples according to the underlying data distribution, which is apparently\nunrealistic as the attacker could choose to focus on more vulnerable examples.\nWe present a weighted minimax risk optimization that defends against\nnon-uniform attacks, achieving robustness against adversarial examples under\nperturbed test data distributions. Our modified risk considers importance\nweights of different adversarial examples and focuses adaptively on harder\nexamples that are wrongly classified or at higher risk of being classified\nincorrectly. The designed risk allows the training process to learn a strong\ndefense through optimizing the importance weights. The experiments show that\nour model significantly improves state-of-the-art adversarial accuracy under\nnon-uniform attacks without a significant drop under uniform attacks.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 21:20:35 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Zeng", "Huimin", ""], ["Zhu", "Chen", ""], ["Goldstein", "Tom", ""], ["Huang", "Furong", ""]]}, {"id": "2010.13048", "submitter": "Edith Cohen", "authors": "Edith Cohen, Ofir Geri, Tamas Sarlos, Uri Stemmer", "title": "Differentially Private Weighted Sampling", "comments": "38 pages, 9 figures", "journal-ref": "AISTATS 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common datasets have the form of elements with keys (e.g., transactions and\nproducts) and the goal is to perform analytics on the aggregated form of key\nand frequency pairs. A weighted sample of keys by (a function of) frequency is\na highly versatile summary that provides a sparse set of representative keys\nand supports approximate evaluations of query statistics. We propose private\nweighted sampling (PWS): A method that ensures element-level differential\nprivacy while retaining, to the extent possible, the utility of a respective\nnon-private weighted sample. PWS maximizes the reporting probabilities of keys\nand estimation quality of a broad family of statistics. PWS improves over the\nstate of the art also for the well-studied special case of private histograms,\nwhen no sampling is performed. We empirically demonstrate significant\nperformance gains compared with prior baselines: 20%-300% increase in key\nreporting for common Zipfian frequency distributions and accuracy for $\\times\n2$-$ 8$ lower frequencies in estimation tasks. Moreover, PWS is applied as a\nsimple post-processing of a non-private sample, without requiring the original\ndata. This allows for seamless integration with existing implementations of\nnon-private schemes and retaining the efficiency of schemes designed for\nresource-constrained settings such as massive distributed or streamed data. We\nbelieve that due to practicality and performance, PWS may become a method of\nchoice in applications where privacy is desired.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 06:54:09 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 06:24:54 GMT"}, {"version": "v3", "created": "Wed, 31 Mar 2021 16:55:09 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Cohen", "Edith", ""], ["Geri", "Ofir", ""], ["Sarlos", "Tamas", ""], ["Stemmer", "Uri", ""]]}, {"id": "2010.13070", "submitter": "Asaf Shabtai", "authors": "Shahar Hoory and Tzvika Shapira and Asaf Shabtai and Yuval Elovici", "title": "Dynamic Adversarial Patch for Evading Object Detection Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research shows that neural networks models used for computer vision\n(e.g., YOLO and Fast R-CNN) are vulnerable to adversarial evasion attacks. Most\nof the existing real-world adversarial attacks against object detectors use an\nadversarial patch which is attached to the target object (e.g., a carefully\ncrafted sticker placed on a stop sign). This method may not be robust to\nchanges in the camera's location relative to the target object; in addition, it\nmay not work well when applied to nonplanar objects such as cars. In this\nstudy, we present an innovative attack method against object detectors applied\nin a real-world setup that addresses some of the limitations of existing\nattacks. Our method uses dynamic adversarial patches which are placed at\nmultiple predetermined locations on a target object. An adversarial learning\nalgorithm is applied in order to generate the patches used. The dynamic attack\nis implemented by switching between optimized patches dynamically, according to\nthe camera's position (i.e., the object detection system's position). In order\nto demonstrate our attack in a real-world setup, we implemented the patches by\nattaching flat screens to the target object; the screens are used to present\nthe patches and switch between them, depending on the current camera location.\nThus, the attack is dynamic and adjusts itself to the situation to achieve\noptimal results. We evaluated our dynamic patch approach by attacking the\nYOLOv2 object detector with a car as the target object and succeeded in\nmisleading it in up to 90% of the video frames when filming the car from a wide\nviewing angle range. We improved the attack by generating patches that consider\nthe semantic distance between the target object and its classification. We also\nexamined the attack's transferability among different car models and were able\nto mislead the detector 71% of the time.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 08:55:40 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Hoory", "Shahar", ""], ["Shapira", "Tzvika", ""], ["Shabtai", "Asaf", ""], ["Elovici", "Yuval", ""]]}, {"id": "2010.13155", "submitter": "Shayan Mohammed", "authors": "Mohammed Shayan, Kanad Basu, Ramesh Karri", "title": "Security Assessment of Interposer-based Chiplet Integration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With transistor scaling reaching its limits, interposer-based integration of\ndies (chiplets) is gaining traction. Such an interposer-based integration\nenables finer and tighter interconnect pitch than traditional\nsystem-on-packages and offers two key benefits: 1. It reduces design-to-market\ntime by bypassing the time-consuming process of verification and fabrication.\n2. It reduces the design cost by reusing chiplets. While black-boxing of the\nslow design stages cuts down the design time, it raises significant security\nconcerns. We study the security implications of the emerging interposer-based\nintegration methodology. The black-boxed design stages deploy security measures\nagainst hardware Trojans, reverse engineering, and intellectual property piracy\nin traditional systems-on-chip (SoC) designs and hence are not suitable for\ninterposer-based integration. We propose using functionally diverse chiplets to\ndetect and thwart hardware Trojans and use the inherent logic redundancy to\nshore up anti-piracy measures. Our proposals do not rely on access to the\nblack-box design stages. We evaluate the security, time and cost benefits of\nour plan by implementing a MIPS processor, a DCT core, and an AES core using\nvarious IPs from the Xilinx CORE GENERATOR IP catalog, on an interposer-based\nXilinx FPGA.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 16:29:47 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Shayan", "Mohammed", ""], ["Basu", "Kanad", ""], ["Karri", "Ramesh", ""]]}, {"id": "2010.13191", "submitter": "Ethan Cecchetti", "authors": "Andrew K. Hirsch and Ethan Cecchetti", "title": "Giving Semantics to Program-Counter Labels via Secure Effects", "comments": null, "journal-ref": "Proceedings of the ACM on Programming Languages 5, POPL, Article\n  35 (January 2021)", "doi": "10.1145/3434316", "report-no": null, "categories": "cs.PL cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Type systems designed for information-flow control commonly use a\nprogram-counter label to track the sensitivity of the context and rule out data\nleakage arising from effectful computation in a sensitive context. Currently,\ntype-system designers reason about this label informally except in security\nproofs, where they use ad-hoc techniques. We develop a framework based on\nmonadic semantics for effects to give semantics to program-counter labels. This\nframework leads to three results about program-counter labels. First, we\ndevelop a new proof technique for noninterference, the core security theorem\nfor information-flow control in effectful languages. Second, we unify notions\nof security for different types of effects, including state, exceptions, and\nnontermination. Finally, we formalize the folklore that program-counter labels\nare a lower bound on effects. We show that, while not universally true, this\nfolklore has a good semantic foundation.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 19:02:35 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 18:07:30 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Hirsch", "Andrew K.", ""], ["Cecchetti", "Ethan", ""]]}, {"id": "2010.13216", "submitter": "Ayaz Akram", "authors": "Ayaz Akram, Anna Giannakou, Venkatesh Akella, Jason Lowe-Power, Sean\n  Peisert", "title": "Performance Analysis of Scientific Computing Workloads on Trusted\n  Execution Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific computing sometimes involves computation on sensitive data.\nDepending on the data and the execution environment, the HPC (high-performance\ncomputing) user or data provider may require confidentiality and/or integrity\nguarantees. To study the applicability of hardware-based trusted execution\nenvironments (TEEs) to enable secure scientific computing, we deeply analyze\nthe performance impact of AMD SEV and Intel SGX for diverse HPC benchmarks\nincluding traditional scientific computing, machine learning, graph analytics,\nand emerging scientific computing workloads. We observe three main findings: 1)\nSEV requires careful memory placement on large scale NUMA machines\n(1$\\times$$-$3.4$\\times$ slowdown without and 1$\\times$$-$1.15$\\times$ slowdown\nwith NUMA aware placement), 2) virtualization$-$a prerequisite for\nSEV$-$results in performance degradation for workloads with irregular memory\naccesses and large working sets (1$\\times$$-$4$\\times$ slowdown compared to\nnative execution for graph applications) and 3) SGX is inappropriate for HPC\ngiven its limited secure memory size and inflexible programming model\n(1.2$\\times$$-$126$\\times$ slowdown over unsecure execution). Finally, we\ndiscuss forthcoming new TEE designs and their potential impact on scientific\ncomputing.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 20:46:25 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Akram", "Ayaz", ""], ["Giannakou", "Anna", ""], ["Akella", "Venkatesh", ""], ["Lowe-Power", "Jason", ""], ["Peisert", "Sean", ""]]}, {"id": "2010.13244", "submitter": "Akshay Agarwal", "authors": "Mehak Gupta, Vishal Singh, Akshay Agarwal, Mayank Vatsa, and Richa\n  Singh", "title": "Generalized Iris Presentation Attack Detection Algorithm under\n  Cross-Database Settings", "comments": "ICPR 2020, 8 pages, 7 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Presentation attacks are posing major challenges to most of the biometric\nmodalities. Iris recognition, which is considered as one of the most accurate\nbiometric modality for person identification, has also been shown to be\nvulnerable to advanced presentation attacks such as 3D contact lenses and\ntextured lens. While in the literature, several presentation attack detection\n(PAD) algorithms are presented; a significant limitation is the\ngeneralizability against an unseen database, unseen sensor, and different\nimaging environment. To address this challenge, we propose a generalized deep\nlearning-based PAD network, MVANet, which utilizes multiple representation\nlayers. It is inspired by the simplicity and success of hybrid algorithm or\nfusion of multiple detection networks. The computational complexity is an\nessential factor in training deep neural networks; therefore, to reduce the\ncomputational complexity while learning multiple feature representation layers,\na fixed base model has been used. The performance of the proposed network is\ndemonstrated on multiple databases such as IIITD-WVU MUIPA and IIITD-CLI\ndatabases under cross-database training-testing settings, to assess the\ngeneralizability of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 22:42:27 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Gupta", "Mehak", ""], ["Singh", "Vishal", ""], ["Agarwal", "Akshay", ""], ["Vatsa", "Mayank", ""], ["Singh", "Richa", ""]]}, {"id": "2010.13246", "submitter": "Akshay Agarwal", "authors": "Nilay Sanghvi, Sushant Kumar Singh, Akshay Agarwal, Mayank Vatsa, and\n  Richa Singh", "title": "MixNet for Generalized Face Presentation Attack Detection", "comments": "ICPR 2020, 8 pages, 6 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The non-intrusive nature and high accuracy of face recognition algorithms\nhave led to their successful deployment across multiple applications ranging\nfrom border access to mobile unlocking and digital payments. However, their\nvulnerability against sophisticated and cost-effective presentation attack\nmediums raises essential questions regarding its reliability. In the\nliterature, several presentation attack detection algorithms are presented;\nhowever, they are still far behind from reality. The major problem with\nexisting work is the generalizability against multiple attacks both in the seen\nand unseen setting. The algorithms which are useful for one kind of attack\n(such as print) perform unsatisfactorily for another type of attack (such as\nsilicone masks). In this research, we have proposed a deep learning-based\nnetwork termed as \\textit{MixNet} to detect presentation attacks in\ncross-database and unseen attack settings. The proposed algorithm utilizes\nstate-of-the-art convolutional neural network architectures and learns the\nfeature mapping for each attack category. Experiments are performed using\nmultiple challenging face presentation attack databases such as SMAD and Spoof\nIn the Wild (SiW-M) databases. Extensive experiments and comparison with\nexisting state of the art algorithms show the effectiveness of the proposed\nalgorithm.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 23:01:13 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Sanghvi", "Nilay", ""], ["Singh", "Sushant Kumar", ""], ["Agarwal", "Akshay", ""], ["Vatsa", "Mayank", ""], ["Singh", "Richa", ""]]}, {"id": "2010.13247", "submitter": "Akshay Agarwal", "authors": "Saheb Chhabra, Akshay Agarwal, Richa Singh, and Mayank Vatsa", "title": "Attack Agnostic Adversarial Defense via Visual Imperceptible Bound", "comments": "ICPR 2020, 8 pages, 5 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The high susceptibility of deep learning algorithms against structured and\nunstructured perturbations has motivated the development of efficient\nadversarial defense algorithms. However, the lack of generalizability of\nexisting defense algorithms and the high variability in the performance of the\nattack algorithms for different databases raises several questions on the\neffectiveness of the defense algorithms. In this research, we aim to design a\ndefense model that is robust within a certain bound against both seen and\nunseen adversarial attacks. This bound is related to the visual appearance of\nan image, and we termed it as \\textit{Visual Imperceptible Bound (VIB)}. To\ncompute this bound, we propose a novel method that uses the database\ncharacteristics. The VIB is further used to measure the effectiveness of attack\nalgorithms. The performance of the proposed defense model is evaluated on the\nMNIST, CIFAR-10, and Tiny ImageNet databases on multiple attacks that include\nC\\&W ($l_2$) and DeepFool. The proposed defense model is not only able to\nincrease the robustness against several attacks but also retain or improve the\nclassification accuracy on an original clean test set. The proposed algorithm\nis attack agnostic, i.e. it does not require any knowledge of the attack\nalgorithm.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 23:14:26 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Chhabra", "Saheb", ""], ["Agarwal", "Akshay", ""], ["Singh", "Richa", ""], ["Vatsa", "Mayank", ""]]}, {"id": "2010.13264", "submitter": "Hao Wang", "authors": "Qing Yang, Hao Wang", "title": "Blockchain-Empowered Socially Optimal Transactive Energy System:\n  Framework and Implementation", "comments": null, "journal-ref": "IEEE Transactions on Industrial Informatics, 2020", "doi": "10.1109/TII.2020.3027577", "report-no": null, "categories": "eess.SY cs.CR cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transactive energy plays a key role in the operation and energy management of\nfuture power systems. However, the conventional operational mechanism, which\nfollows a centralized design, is often less secure, vulnerable to malicious\nbehaviors, and suffers from privacy leakage. In this work, we introduce\nblockchain technology in transactive energy to address these challenges.\nSpecifically, we develop a novel blockchain-based transactive energy framework\nfor prosumers and design a decentralized energy trading algorithm that matches\nthe operation of the underlying blockchain system. We prove that the trading\nalgorithm improves the individual benefit and guarantees the socially optimal\nperformance, and thus incentivizes prosumers to join the transactive energy\nplatform. Moreover, we evaluate the feasibility of the transactive energy\nplatform throughout the implementation of a small-scale network of Internet of\nThings (IoT) devices and extensive simulations using real-world data. Our\nresults show that this blockchain-based transactive energy platform is feasible\nin practice, and the decentralized trading algorithm reduces the user's\nindividual cost by up to 77% and lowers the overall cost by 24%.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 00:41:27 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Yang", "Qing", ""], ["Wang", "Hao", ""]]}, {"id": "2010.13356", "submitter": "Xudong Pan", "authors": "Xudong Pan, Mi Zhang, Yifan Yan, Jiaming Zhu, Min Yang", "title": "Theory-Oriented Deep Leakage from Gradients via Linear Equation Solver", "comments": "Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we take a theory-oriented approach to systematically study the\nprivacy properties of gradients from a broad class of neural networks with\nrectified linear units (ReLU), probably the most popular activation function\nused in current deep learning practices. By utilizing some intrinsic properties\nof neural networks with ReLU, we prove the existence of exclusively activated\nneurons is critical to the separability of the activation patterns of different\nsamples. Intuitively, an activation pattern is like the fingerprint of the\ncorresponding sample during the training process. With the separated activation\npatterns, we for the first time show the equivalence of data reconstruction\nattacks with a sparse linear equation system.\n  In practice, we propose a novel data reconstruction attack on fully-connected\nneural networks and extend the attack to more commercial convolutional neural\nnetwork architectures. Our systematic evaluations cover more than $10$\nrepresentative neural network architectures (e.g., GoogLeNet, VGGNet and $6$\nmore), on various real-world scenarios related with healthcare, medical\nimaging, location, face recognition and shopping behaviors. In the majority of\ntest cases, our proposed attack is able to infer ground-truth labels in the\ntraining batch with near $100\\%$ accuracy, reconstruct the input data to\nfully-connected neural networks with lower than $10^{-6}$ MSE error, and\nprovide better reconstruction results on both shallow and deep convolutional\nneural networks than previous attacks.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 05:54:47 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Pan", "Xudong", ""], ["Zhang", "Mi", ""], ["Yan", "Yifan", ""], ["Zhu", "Jiaming", ""], ["Yang", "Min", ""]]}, {"id": "2010.13381", "submitter": "Fumiyuki Kato", "authors": "Fumiyuki Kato, Yang Cao, Masatoshi Yoshikawa", "title": "Secure and Efficient Trajectory-Based Contact Tracing using Trusted\n  Hardware", "comments": "Accepted by 7th International Workshop on Privacy and Security of Big\n  Data (PSBD 2020) in conjunction with 2020 IEEE International Conference on\n  Big Data (IEEE BigData 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic has prompted technological measures to control the\nspread of the disease. Private contact tracing (PCT) is one of the promising\ntechniques for the purpose. However, the recently proposed Bluetooth-based PCT\nhas several limitations in terms of functionality and flexibility. The existing\nsystems are only able to detect direct contact (i.e., human-human contact), but\ncannot detect indirect contact (i.e., human-object, such as the disease\ntransmission through surface). Moreover, the rule of risky contact cannot be\nflexibly changed with the environmental situation and the nature of the virus.\nIn this paper, we propose a secure and efficient trajectory-based PCT system\nusing trusted hardware. We formalize trajectory-based PCT as a generalization\nof the well-studied Private Set Intersection (PSI), which is mostly based on\ncryptographic primitives and thus insufficient. We solve the problem by\nleveraging trusted hardware such as Intel SGX and designing a novel algorithm\nto achieve a secure, efficient and flexible PCT system. Our experiments on\nreal-world data show that the proposed system can achieve high performance and\nscalability. Specifically, our system (one single machine with Intel SGX) can\nprocess thousands of queries on 100 million records of trajectory data in a few\nseconds.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 07:22:56 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 07:42:41 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Kato", "Fumiyuki", ""], ["Cao", "Yang", ""], ["Yoshikawa", "Masatoshi", ""]]}, {"id": "2010.13449", "submitter": "Shun Takagi", "authors": "Shun Takagi and Yang Cao and Yasuhito Asano and Masatoshi Yoshikawa", "title": "Geo-Graph-Indistinguishability: Location Privacy on Road Networks Based\n  on Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, concerns about location privacy are increasing with the\nspread of location-based services (LBSs). Many methods to protect location\nprivacy have been proposed in the past decades. Especially, perturbation\nmethods based on Geo-Indistinguishability (Geo-I), which randomly perturb a\ntrue location to a pseudolocation, are getting attention due to its strong\nprivacy guarantee inherited from differential privacy. However, Geo-I is based\non the Euclidean plane even though many LBSs are based on road networks (e.g.\nride-sharing services). This causes unnecessary noise and thus an insufficient\ntradeoff between utility and privacy for LBSs on road networks. To address this\nissue, we propose a new privacy notion, Geo-Graph-Indistinguishability (GG-I),\nfor locations on a road network to achieve a better tradeoff. We propose\nGraph-Exponential Mechanism (GEM), which satisfies GG-I. Moreover, we formalize\nthe optimization problem to find the optimal GEM in terms of the tradeoff.\nHowever, the computational complexity of a naive method to find the optimal\nsolution is prohibitive, so we propose a greedy algorithm to find an\napproximate solution in an acceptable amount of time. Finally, our experiments\nshow that our proposed mechanism outperforms a Geo-I's mechanism with respect\nto the tradeoff.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 09:39:18 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Takagi", "Shun", ""], ["Cao", "Yang", ""], ["Asano", "Yasuhito", ""], ["Yoshikawa", "Masatoshi", ""]]}, {"id": "2010.13457", "submitter": "Henry Turner", "authors": "Henry Turner, Giulio Lovisotto and Ivan Martinovic", "title": "Speaker Anonymization with Distribution-Preserving X-Vector Generation\n  for the VoicePrivacy Challenge 2020", "comments": "5 pages Replacement: A small processing bug led to slightly incorrect\n  results. Conclusions remain the same", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.CR eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a Distribution-Preserving Voice Anonymization\ntechnique, as our submission to the VoicePrivacy Challenge 2020. We observe\nthat the challenge baseline system generates fake X-vectors which are very\nsimilar to each other, significantly more so than those extracted from organic\nspeakers. This difference arises from averaging many X-vectors from a pool of\nspeakers in the anonymization process, causing a loss of information. We\npropose a new method to generate fake X-vectors which overcomes these\nlimitations by preserving the distributional properties of X-vectors and their\nintra-similarity. We use population data to learn the properties of the\nX-vector space, before fitting a generative model which we use to sample fake\nX-vectors. We show how this approach generates X-vectors that more closely\nfollow the expected intra-similarity distribution of organic speaker X-vectors.\nOur method can be easily integrated with others as the anonymization component\nof the system and removes the need to distribute a pool of speakers to use\nduring the anonymization. Our approach leads to an increase in EER of up to\n$19.4\\%$ in males and $11.1\\%$ in females in scenarios where enrollment and\ntrial utterances are anonymized versus the baseline solution, demonstrating the\ndiversity of our generated voices.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 09:53:56 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 16:11:35 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Turner", "Henry", ""], ["Lovisotto", "Giulio", ""], ["Martinovic", "Ivan", ""]]}, {"id": "2010.13462", "submitter": "Qiang Tang", "authors": "Qiang Tang", "title": "Another Look at Privacy-Preserving Automated Contact Tracing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the current COVID-19 pandemic, manual contact tracing has been proven very\nhelpful to reach close contacts of infected users and slow down virus\nspreading. To improve its scalability, a number of automated contact tracing\n(ACT) solutions have proposed and some of them have been deployed. Despite the\ndedicated efforts, security and privacy issues of these solutions are still\nopen and under intensive debate. In this paper, we examine the ACT concept from\na broader perspective, by focusing on not only security and privacy issues but\nalso functional issues such as interface, usability and coverage. We first\nelaborate on these issues and particularly point out the inevitable privacy\nleakages in existing BLE-based ACT solutions. Then, we propose a venue-based\nACT concept, which only monitors users' contacting history in\nvirus-spreading-prone venues and is able to incorporate different location\ntracking technologies such as BLE and WIFI. Finally, we instantiate the\nvenue-based ACT concept and show that our instantiation can mitigate most of\nthe issues we have identified in our analysis.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 09:59:15 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Tang", "Qiang", ""]]}, {"id": "2010.13520", "submitter": "Di Wang", "authors": "Di Wang and Jiahao Ding and Lijie Hu and Zejun Xie and Miao Pan and\n  Jinhui Xu", "title": "Differentially Private (Gradient) Expectation Maximization Algorithm\n  with Statistical Guarantees", "comments": "Submiited. arXiv admin note: text overlap with arXiv:2010.09576", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  (Gradient) Expectation Maximization (EM) is a widely used algorithm for\nestimating the maximum likelihood of mixture models or incomplete data\nproblems. A major challenge facing this popular technique is how to effectively\npreserve the privacy of sensitive data. Previous research on this problem has\nalready lead to the discovery of some Differentially Private (DP) algorithms\nfor (Gradient) EM. However, unlike in the non-private case, existing techniques\nare not yet able to provide finite sample statistical guarantees. To address\nthis issue, we propose in this paper the first DP version of (Gradient) EM\nalgorithm with statistical guarantees. Moreover, we apply our general framework\nto three canonical models: Gaussian Mixture Model (GMM), Mixture of Regressions\nModel (MRM) and Linear Regression with Missing Covariates (RMC). Specifically,\nfor GMM in the DP model, our estimation error is near optimal in some cases.\nFor the other two models, we provide the first finite sample statistical\nguarantees. Our theory is supported by thorough numerical experiments.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 03:41:19 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 17:33:38 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Wang", "Di", ""], ["Ding", "Jiahao", ""], ["Hu", "Lijie", ""], ["Xie", "Zejun", ""], ["Pan", "Miao", ""], ["Xu", "Jinhui", ""]]}, {"id": "2010.13539", "submitter": "Markus Dahlmanns", "authors": "Markus Dahlmanns, Johannes Lohm\\\"oller, Ina Berenice Fink, Jan\n  Pennekamp, Klaus Wehrle, Martin Henze", "title": "Easing the Conscience with OPC UA: An Internet-Wide Study on Insecure\n  Deployments", "comments": "10 pages, 7 figures", "journal-ref": "In Proceedings of the ACM Internet Measurement Conference 2020\n  (IMC '20). Association for Computing Machinery, New York, NY, USA, 101-110", "doi": "10.1145/3419394.3423666", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to increasing digitalization, formerly isolated industrial networks,\ne.g., for factory and process automation, move closer and closer to the\nInternet, mandating secure communication. However, securely setting up OPC UA,\nthe prime candidate for secure industrial communication, is challenging due to\na large variety of insecure options. To study whether Internet-facing OPC UA\nappliances are configured securely, we actively scan the IPv4 address space for\npublicly reachable OPC UA systems and assess the security of their\nconfigurations. We observe problematic security configurations such as missing\naccess control (on 24% of hosts), disabled security functionality (24%), or use\nof deprecated cryptographic primitives (25%) on in total 92% of the reachable\ndeployments. Furthermore, we discover several hundred devices in multiple\nautonomous systems sharing the same security certificate, opening the door for\nimpersonation attacks. Overall, in this paper, we highlight commonly found\nsecurity misconfigurations and underline the importance of appropriate\nconfiguration for security-featuring protocols.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 12:48:20 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Dahlmanns", "Markus", ""], ["Lohm\u00f6ller", "Johannes", ""], ["Fink", "Ina Berenice", ""], ["Pennekamp", "Jan", ""], ["Wehrle", "Klaus", ""], ["Henze", "Martin", ""]]}, {"id": "2010.13555", "submitter": "Andrea Tesei Mr", "authors": "Andrea Tesei, Domenico Lattuca, Paolo Pagano, Marco Luise, Joaquim\n  Ferreira, Paulo C. Bartolomeu", "title": "A Transparent Distributed Ledger-based Certificate Revocation Scheme for\n  VANETs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among the available communication systems, vehicular networks are emerging as\none of the most promising and yet most challenging instantiations of mobile\nad-hoc network technologies. The deployment of such networks in large scale\nrequires the enforcement of stringent security mechanisms that need to abide by\nthe technical, societal, legal, and economical requirements of Intelligent\nTransportation Systems. Authentication is an effective process for validating\nuser identity in vehicular netoworks. However, it cannot guarantee the network\nsecurity by itself. Available industrial standards do not consider methods to\npromptly revoke misbehaving vehicles. The only available protection consists on\nthe \\textit{revocation by expiry}, which tolerates the misbehaving vehicle to\nremain trusted in the system for a long time (e.g. 3 months with certificate\npre-loading according to EU security policy). This poses a huge yet dangerous\nlimitation to the security of the vehicular ecosystem. In this work we propose\na Distributed Ledger-based Certificate Revocation Scheme for Vehicular Ad-hoc\nNetworks (VANETs) that harnesses the advantages of the underlying Distributed\nLedger Technology (DLT) to implement a privacy-aware revocation process that is\nfully transparent to all participating entities and meets the critical message\nprocessing times defined by EU and US standards. An experimental validation and\nanalysis demonstrates the effectiveness and efficiency of the proposed scheme,\nwhere the DLT streamlines the revocation operation overhead and delivers an\neconomic solution against cyber-attacks in vehicular systems.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 15:12:07 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Tesei", "Andrea", ""], ["Lattuca", "Domenico", ""], ["Pagano", "Paolo", ""], ["Luise", "Marco", ""], ["Ferreira", "Joaquim", ""], ["Bartolomeu", "Paulo C.", ""]]}, {"id": "2010.13637", "submitter": "Peng Gao", "authors": "Peng Gao, Fei Shao, Xiaoyuan Liu, Xusheng Xiao, Zheng Qin, Fengyuan\n  Xu, Prateek Mittal, Sanjeev R. Kulkarni, Dawn Song", "title": "Enabling Efficient Cyber Threat Hunting With Cyber Threat Intelligence", "comments": "Accepted paper at ICDE 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Log-based cyber threat hunting has emerged as an important solution to\ncounter sophisticated attacks. However, existing approaches require non-trivial\nefforts of manual query construction and have overlooked the rich external\nthreat knowledge provided by open-source Cyber Threat Intelligence (OSCTI). To\nbridge the gap, we propose ThreatRaptor, a system that facilitates threat\nhunting in computer systems using OSCTI. Built upon system auditing frameworks,\nThreatRaptor provides (1) an unsupervised, light-weight, and accurate NLP\npipeline that extracts structured threat behaviors from unstructured OSCTI\ntext, (2) a concise and expressive domain-specific query language, TBQL, to\nhunt for malicious system activities, (3) a query synthesis mechanism that\nautomatically synthesizes a TBQL query for hunting, and (4) an efficient query\nexecution engine to search the big audit logging data. Evaluations on a broad\nset of attack cases demonstrate the accuracy and efficiency of ThreatRaptor in\npractical threat hunting.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 14:54:01 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 06:20:46 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Gao", "Peng", ""], ["Shao", "Fei", ""], ["Liu", "Xiaoyuan", ""], ["Xiao", "Xusheng", ""], ["Qin", "Zheng", ""], ["Xu", "Fengyuan", ""], ["Mittal", "Prateek", ""], ["Kulkarni", "Sanjeev R.", ""], ["Song", "Dawn", ""]]}, {"id": "2010.13707", "submitter": "Dami\\'an Aparicio S\\'anchez", "authors": "Dami\\'an Aparicio-S\\'anchez, Santiago Escobar, Catherine Meadows, Jose\n  Meseguer, Julia Sapi\\~na", "title": "Protocol Analysis with Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework suited to the analysis of cryptographic protocols that\nmake use of time in their execution. We provide a process algebra syntax that\nmakes time information available to processes, and a transition semantics that\ntakes account of fundamental properties of time. Additional properties can be\nadded by the user if desirable. This timed protocol framework can be\nimplemented either as a simulation tool or as a symbolic analysis tool in which\ntime references are represented by logical variables, and in which the\nproperties of time are implemented as constraints on those time logical\nvariables. These constraints are carried along the symbolic execution of the\nprotocol. The satisfiability of these constraints can be evaluated as the\nanalysis proceeds, so attacks that violate the laws of physics can be rejected\nas impossible. We demonstrate the feasibility of our approach by using the\nMaude-NPA protocol analyzer together with an SMT solver that is used to\nevaluate the satisfiability of timing constraints. We provide a sound and\ncomplete protocol transformation from our timed process algebra to the\nMaude-NPA syntax and semantics, and we prove its soundness and completeness. We\nthen use the tool to analyze Mafia fraud and distance hijacking attacks on a\nsuite of distance-bounding protocols.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 16:48:07 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Aparicio-S\u00e1nchez", "Dami\u00e1n", ""], ["Escobar", "Santiago", ""], ["Meadows", "Catherine", ""], ["Meseguer", "Jose", ""], ["Sapi\u00f1a", "Julia", ""]]}, {"id": "2010.13711", "submitter": "Suryanarayana Sankagiri", "authors": "Suryanarayana Sankagiri, Xuechao Wang, Sreeram Kannan, Pramod\n  Viswanath", "title": "Blockchain CAP Theorem Allows User-Dependent Adaptivity and Finality", "comments": "40 pages, 9 figures. This is the full version of the paper with the\n  same title, which appeared in Financial Cryptography, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Longest-chain blockchain protocols, such as Bitcoin, guarantee liveness even\nwhen the number of actively participating users is variable, i.e., they are\nadaptive. However, they are not safe under network partitions, i.e., they do\nnot guarantee finality. On the other hand, classical blockchain protocols, like\nPBFT, achieve finality but not adaptivity. Indeed, the CAP theorem in the\ncontext of blockchains asserts that no protocol can simultaneously offer both\nadaptivity and finality.\n  We propose a new blockchain protocol, called the checkpointed longest chain,\nthat offers individual users the choice between finality and adaptivity instead\nof imposing it at a system-wide level. This protocol's salient feature is that\nit supports two distinct confirmation rules: one that guarantees adaptivity and\nthe other finality. The more optimistic adaptive rule always confirms blocks\nthat are marked as finalized by the more conservative rule, and may possibly\nconfirm more blocks during variable participation levels. Clients (users) make\na local choice between the confirmation rules as per their personal preference,\nwhile miners follow a fixed block proposal rule that is consistent with both\nconfirmation rules. The proposed protocol has the additional benefit of\nintrinsic validity: the finalized blocks always lie on a single blockchain, and\ntherefore miners can attest to the validity of transactions while proposing\nblocks. Our protocol builds on the notion of a finality gadget, a popular\ntechnique for adding finality to longest-chain protocols.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 16:53:28 GMT"}, {"version": "v2", "created": "Fri, 2 Apr 2021 06:22:15 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Sankagiri", "Suryanarayana", ""], ["Wang", "Xuechao", ""], ["Kannan", "Sreeram", ""], ["Viswanath", "Pramod", ""]]}, {"id": "2010.13725", "submitter": "Nata\\v{s}a Trkulja", "authors": "Nata\\v{s}a Trkulja, David Starobinski, Randall A. Berry", "title": "Denial-of-Service Attacks on C-V2X Networks", "comments": "10 pages, 19 figures. The paper has been submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cellular Vehicle-to-Everything (C-V2X) networks are increasingly adopted by\nautomotive original equipment manufacturers (OEMs). C-V2X, as defined in 3GPP\nRelease 14 Mode 4, allows vehicles to self-manage the network in absence of a\ncellular base-station. Since C-V2X networks convey safety-critical messages, it\nis crucial to assess their security posture. This work contributes a novel set\nof Denial-of-Service (DoS) attacks on C-V2X networks operating in Mode 4. The\nattacks are caused by adversarial resource block selection and vary in\nsophistication and efficiency. In particular, we consider \"oblivious\"\nadversaries that ignore recent transmission activity on resource blocks,\n\"smart\" adversaries that do monitor activity on each resource block, and\n\"cooperative\" adversaries that work together to ensure they attack different\ntargets. We analyze and simulate these attacks to showcase their effectiveness.\nAssuming a fixed number of attackers, we show that at low vehicle density,\nsmart and cooperative attacks can significantly impact network performance,\nwhile at high vehicle density, oblivious attacks are almost as effective as the\nmore sophisticated attacks.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 17:08:08 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Trkulja", "Nata\u0161a", ""], ["Starobinski", "David", ""], ["Berry", "Randall A.", ""]]}, {"id": "2010.13751", "submitter": "Jinyuan Jia", "authors": "Jinyuan Jia, Binghui Wang, Neil Zhenqiang Gong", "title": "Robust and Verifiable Information Embedding Attacks to Deep Neural\n  Networks via Error-Correcting Codes", "comments": "Accepted by AsiaCCS'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of deep learning, a user often leverages a third-party machine\nlearning tool to train a deep neural network (DNN) classifier and then deploys\nthe classifier as an end-user software product or a cloud service. In an\ninformation embedding attack, an attacker is the provider of a malicious\nthird-party machine learning tool. The attacker embeds a message into the DNN\nclassifier during training and recovers the message via querying the API of the\nblack-box classifier after the user deploys it. Information embedding attacks\nhave attracted growing attention because of various applications such as\nwatermarking DNN classifiers and compromising user privacy. State-of-the-art\ninformation embedding attacks have two key limitations: 1) they cannot verify\nthe correctness of the recovered message, and 2) they are not robust against\npost-processing of the classifier.\n  In this work, we aim to design information embedding attacks that are\nverifiable and robust against popular post-processing methods. Specifically, we\nleverage Cyclic Redundancy Check to verify the correctness of the recovered\nmessage. Moreover, to be robust against post-processing, we leverage Turbo\ncodes, a type of error-correcting codes, to encode the message before embedding\nit to the DNN classifier. We propose to recover the message via adaptively\nquerying the classifier to save queries. Our adaptive recovery strategy\nleverages the property of Turbo codes that supports error correcting with a\npartial code. We evaluate our information embedding attacks using simulated\nmessages and apply them to three applications, where messages have semantic\ninterpretations. We consider 8 popular methods to post-process the classifier.\nOur results show that our attacks can accurately and verifiably recover the\nmessages in all considered scenarios, while state-of-the-art attacks cannot\naccurately recover the messages in many scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 17:42:42 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Jia", "Jinyuan", ""], ["Wang", "Binghui", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "2010.13752", "submitter": "Rishabh Poddar", "authors": "Rishabh Poddar, Sukrit Kalra, Avishay Yanai, Ryan Deng, Raluca Ada\n  Popa, Joseph M. Hellerstein", "title": "Senate: A Maliciously-Secure MPC Platform for Collaborative Analytics", "comments": "USENIX Security 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many organizations stand to benefit from pooling their data together in order\nto draw mutually beneficial insights -- e.g., for fraud detection across banks,\nbetter medical studies across hospitals, etc. However, such organizations are\noften prevented from sharing their data with each other by privacy concerns,\nregulatory hurdles, or business competition. We present Senate, a system that\nallows multiple parties to collaboratively run analytical SQL queries without\nrevealing their individual data to each other. Unlike prior works on secure\nmulti-party computation (MPC) that assume that all parties are semi-honest,\nSenate protects the data even in the presence of malicious adversaries. At the\nheart of Senate lies a new MPC decomposition protocol that decomposes the\ncryptographic MPC computation into smaller units, some of which can be executed\nby subsets of parties and in parallel, while preserving its security\nguarantees. Senate then provides a new query planning algorithm that decomposes\nand plans the cryptographic computation effectively, achieving a performance of\nup to 145$\\times$ faster than the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 17:43:22 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Poddar", "Rishabh", ""], ["Kalra", "Sukrit", ""], ["Yanai", "Avishay", ""], ["Deng", "Ryan", ""], ["Popa", "Raluca Ada", ""], ["Hellerstein", "Joseph M.", ""]]}, {"id": "2010.13858", "submitter": "Ivan De Oliveira Nunes", "authors": "Ivan De Oliveira Nunes, Xuhua Ding, Gene Tsudik", "title": "On the Root of Trust Identification Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Root of Trust Identification (RTI) refers to determining whether a given\nsecurity service or task is being performed by the particular root of trust\n(e.g., a TEE) within a specific physical device. Despite its importance, this\nproblem has been mostly overlooked. We formalize the RTI problem and argue that\nsecurity of RTI protocols is especially challenging due to local adversaries,\ncuckoo adversaries, and the combination thereof. To cope with this problem we\npropose a simple and effective protocol based on biometrics. Unlike\nbiometric-based user authentication, our approach is not concerned with\nverifying user identity, and requires neither pre-enrollment nor persistent\nstorage for biometric templates. Instead, it takes advantage of the difficulty\nof cloning a biometric in real-time to securely identify the root of trust of a\ngiven physical device, by using the biometric as a challenge. Security of the\nproposed protocol is analyzed in the combined Local and Cuckoo adversarial\nmodel. Also, a prototype implementation is used to demonstrate the protocol's\nfeasibility and practicality. We further propose a Proxy RTI protocol, wherein\na previously identified RoT assists a remote verifier in identifying new RoTs.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 19:21:27 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Nunes", "Ivan De Oliveira", ""], ["Ding", "Xuhua", ""], ["Tsudik", "Gene", ""]]}, {"id": "2010.13860", "submitter": "Sam Ganzfried", "authors": "Sam Ganzfried", "title": "Computing Nash Equilibria in Multiplayer DAG-Structured Stochastic Games\n  with Persistent Imperfect Information", "comments": "Added experimental results for a smaller game that demonstrate\n  algorithm convergence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.CR cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many important real-world settings contain multiple players interacting over\nan unknown duration with probabilistic state transitions, and are naturally\nmodeled as stochastic games. Prior research on algorithms for stochastic games\nhas focused on two-player zero-sum games, games with perfect information, and\ngames with imperfect-information that is local and does not extend between game\nstates. We present an algorithm for approximating Nash equilibrium in\nmultiplayer general-sum stochastic games with persistent imperfect information\nthat extends throughout game play. We experiment on a 4-player\nimperfect-information naval strategic planning scenario. Using a new procedure,\nwe are able to demonstrate that our algorithm computes a strategy that closely\napproximates Nash equilibrium in this game.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 19:27:26 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 02:38:24 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Ganzfried", "Sam", ""]]}, {"id": "2010.13970", "submitter": "Tristan Glatard", "authors": "Bhupinder Kaur, Mathieu Dugr\\'e, Aiman Hanna, Tristan Glatard", "title": "An Analysis of Security Vulnerabilities in Container Images for\n  Scientific Data Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Software containers greatly facilitate the deployment and reproducibility of\nscientific data analyses in various platforms. However, container images often\ncontain outdated or unnecessary software packages, which increases the number\nof security vulnerabilities in the images, widens the attack surface in the\ncontainer host, and creates substantial security risks for computing\ninfrastructures at large. This paper presents a vulnerability analysis of\ncontainer images for scientific data analysis. We compare results obtained with\nfour vulnerability scanners, focusing on the use case of neuroscience data\nanalysis, and quantifying the effect of image update and minification on the\nnumber of vulnerabilities. We find that container images used for neuroscience\ndata analysis contain hundreds of vulnerabilities, that software updates remove\nabout two thirds of these vulnerabilities, and that removing unused packages is\nalso effective. We conclude with recommendations on how to build container\nimages with a reduced amount of vulnerabilities.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 00:41:49 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 15:49:33 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Kaur", "Bhupinder", ""], ["Dugr\u00e9", "Mathieu", ""], ["Hanna", "Aiman", ""], ["Glatard", "Tristan", ""]]}, {"id": "2010.13978", "submitter": "Dazhuang Liu", "authors": "Ru Zhang (1), Wenxin Sun (1), Jianyi Liu (1), Jingwen Li (1), Guan Lei\n  (2), Han Guo (3) ((1) Beijing University of Posts and Telecommunications,\n  China, (2) Tsinghua University, School of Electrical Engineering, China, (3)\n  State Grid Information & Telecommunication Branch, China)", "title": "Construction of Two Statistical Anomaly Features for Small-Sample APT\n  Attack Traffic Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced Persistent Threat (APT) attack, also known as directed threat\nattack, refers to the continuous and effective attack activities carried out by\nan organization on a specific object. They are covert, persistent and targeted,\nwhich are difficult to capture by traditional intrusion detection system(IDS).\nThe traffic generated by the APT organization, which is the organization that\nlaunch the APT attack, has a high similarity, especially in the Command and\nControl(C2) stage. The addition of features for APT organizations can\neffectively improve the accuracy of traffic detection for APT attacks. This\npaper analyzes the DNS and TCP traffic of the APT attack, and constructs two\nnew features, C2Load_fluct (response packet load fluctuation) and Bad_rate (bad\npacket rate). The analysis showed APT attacks have obvious statistical laws in\nthese two features. This article combines two new features with common features\nto classify APT attack traffic. Aiming at the problem of data loss and boundary\nsamples, we improve the Adaptive Synthetic(ADASYN) Sampling Approach and\npropose the PADASYN algorithm to achieve data balance. A traffic classification\nscheme is designed based on the AdaBoost algorithm. Experiments show that the\nclassification accuracy of APT attack traffic is improved after adding new\nfeatures to the two datasets so that 10 DNS features, 11 TCP and HTTP/HTTPS\nfeatures are used to construct a Features set. On the two datasets, F1-score\ncan reach above 0.98 and 0.94 respectively, which proves that the two new\nfeatures in this paper are effective for APT traffic detection.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 01:18:40 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Zhang", "Ru", ""], ["Sun", "Wenxin", ""], ["Liu", "Jianyi", ""], ["Li", "Jingwen", ""], ["Lei", "Guan", ""], ["Guo", "Han", ""]]}, {"id": "2010.13981", "submitter": "Ryan Rogers", "authors": "Ryan Rogers, Adrian Rivera Cardoso, Koray Mancuhan, Akash Kaura,\n  Nikhil Gahlawat, Neha Jain, Paul Ko, Parvez Ahammad", "title": "A Members First Approach to Enabling LinkedIn's Labor Market Insights at\n  Scale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the privatization method used in reporting labor market insights\nfrom LinkedIn's Economic Graph, including the differentially private algorithms\nused to protect member's privacy. The reports show who are the top employers,\nas well as what are the top jobs and skills in a given country/region and\nindustry. We hope this data will help governments and citizens track labor\nmarket trends during the COVID-19 pandemic while also protecting the privacy of\nour members.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 01:29:34 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Rogers", "Ryan", ""], ["Cardoso", "Adrian Rivera", ""], ["Mancuhan", "Koray", ""], ["Kaura", "Akash", ""], ["Gahlawat", "Nikhil", ""], ["Jain", "Neha", ""], ["Ko", "Paul", ""], ["Ahammad", "Parvez", ""]]}, {"id": "2010.14006", "submitter": "Junjie Yan", "authors": "Junjie Yan, Kevin Huang, Kyle Lindgren, Tamara Bonaci, Howard Jay\n  Chizeck", "title": "Continuous Operator Authentication for Teleoperated Systems Using Hidden\n  Markov Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel approach for continuous operator\nauthentication in teleoperated robotic processes based on Hidden Markov Models\n(HMM). While HMMs were originally developed and widely used in speech\nrecognition, they have shown great performance in human motion and activity\nmodeling. We make an analogy between human language and teleoperated robotic\nprocesses (i.e. words are analogous to a teleoperator's gestures, sentences are\nanalogous to the entire teleoperated task or process) and implement HMMs to\nmodel the teleoperated task. To test the continuous authentication performance\nof the proposed method, we conducted two sets of analyses. We built a virtual\nreality (VR) experimental environment using a commodity VR headset (HTC Vive)\nand haptic feedback enabled controller (Sensable PHANToM Omni) to simulate a\nreal teleoperated task. An experimental study with 10 subjects was then\nconducted. We also performed simulated continuous operator authentication by\nusing the JHU-ISI Gesture and Skill Assessment Working Set (JIGSAWS). The\nperformance of the model was evaluated based on the continuous (real-time)\noperator authentication accuracy as well as resistance to a simulated\nimpersonation attack. The results suggest that the proposed method is able to\nachieve 70% (VR experiment) and 81% (JIGSAW dataset) continuous classification\naccuracy with as short as a 1-second sample window. It is also capable of\ndetecting the impersonation attack in real-time.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 02:33:10 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 04:49:46 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Yan", "Junjie", ""], ["Huang", "Kevin", ""], ["Lindgren", "Kyle", ""], ["Bonaci", "Tamara", ""], ["Chizeck", "Howard Jay", ""]]}, {"id": "2010.14007", "submitter": "Junjie Yan", "authors": "Junjie Yan, Tamara Bonaci, Howard Jay Chizeck", "title": "Your signature is your password: Haptic Passwords on Mobile Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a new behavioral biometric password based on haptic\ninteraction is described. This \"haptic password\" system is built on a device\nthat has a force-sensitive screen. The user authentication process leverages\nmaximal overlap discrete wavelet transform (MODWT) based feature extraction\nalong with a customized classifier as well as an adaptive template scheme to\naccommodate users' variations over time. An experimental study was conducted\nwith 29 subjects and we investigated the authentication performance with\nmultiple user postures under simulated forgery attacks. The performance of the\nmodel is evaluated based on authentication accuracies. The results suggest that\nthis proposed haptic password system achieves robust high authentication\naccuracy and scalability, as well as forgery-proof performance.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 02:33:32 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Yan", "Junjie", ""], ["Bonaci", "Tamara", ""], ["Chizeck", "Howard Jay", ""]]}, {"id": "2010.14023", "submitter": "Seng Pei Liew", "authors": "Seng Pei Liew and Tsubasa Takahashi", "title": "FaceLeaks: Inference Attacks against Transfer Learning Models via\n  Black-box Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning is a useful machine learning framework that allows one to\nbuild task-specific models (student models) without significantly incurring\ntraining costs using a single powerful model (teacher model) pre-trained with a\nlarge amount of data. The teacher model may contain private data, or interact\nwith private inputs. We investigate if one can leak or infer such private\ninformation without interacting with the teacher model directly. We describe\nsuch inference attacks in the context of face recognition, an application of\ntransfer learning that is highly sensitive to personal privacy.\n  Under black-box and realistic settings, we show that existing inference\ntechniques are ineffective, as interacting with individual training instances\nthrough the student models does not reveal information about the teacher. We\nthen propose novel strategies to infer from aggregate-level information.\nConsequently, membership inference attacks on the teacher model are shown to be\npossible, even when the adversary has access only to the student models.\n  We further demonstrate that sensitive attributes can be inferred, even in the\ncase where the adversary has limited auxiliary information. Finally, defensive\nstrategies are discussed and evaluated. Our extensive study indicates that\ninformation leakage is a real privacy threat to the transfer learning framework\nwidely used in real-life situations.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 03:02:40 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Liew", "Seng Pei", ""], ["Takahashi", "Tsubasa", ""]]}, {"id": "2010.14032", "submitter": "Robert Sison", "authors": "Robert Sison (1 and 2 and 3), Toby Murray (1) ((1) University of\n  Melbourne, (2) CSIRO's Data61, (3) UNSW Sydney)", "title": "Verified Secure Compilation for Mixed-Sensitivity Concurrent Programs", "comments": "Submitted to the Journal of Functional Programming Special Issue on\n  Secure Compilation. Some errors in the submitted manuscript's description of\n  Lemma 5.25 have been corrected. This paper expands on its conference version\n  arXiv:1907.00713. For supplement material, see http://covern.org/jfpsc.html", "journal-ref": null, "doi": "10.1017/S0956796821000162", "report-no": null, "categories": "cs.PL cs.CR cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Proving only over source code that programs do not leak sensitive data leaves\na gap between reasoning and reality that can only be filled by accounting for\nthe behaviour of the compiler. Furthermore, software does not always have the\nluxury of limiting itself to single-threaded computation with resources\nstatically dedicated to each user to ensure the confidentiality of their data.\nThis results in mixed-sensitivity concurrent programs, which might reuse memory\nshared between their threads to hold data of different sensitivity levels at\ndifferent times; for such programs, a compiler must preserve the\nvalue-dependent coordination of such mixed-sensitivity reuse despite the impact\nof concurrency.\n  Here we demonstrate, using Isabelle/HOL, that it is feasible to verify that a\ncompiler preserves noninterference, the strictest kind of confidentiality\nproperty, for mixed-sensitivity concurrent programs. First, we present notions\nof refinement that preserve a concurrent value-dependent notion of\nnoninterference that we have designed to support such programs. As proving\nnoninterference-preserving refinement can be considerably more complex than the\nstandard refinements typically used to verify semantics -- preserving\ncompilation, our notions include a decomposition principle that separates the\nsemantics -- from the security-preservation concerns. Second, we demonstrate\nthat these refinement notions are applicable to verified secure compilation, by\nexercising them on a single-pass compiler for mixed-sensitivity concurrent\nprograms that synchronise using mutex locks, from a generic imperative language\nto a generic RISC-style assembly language. Finally, we execute our compiler on\na nontrivial mixed-sensitivity concurrent program modelling a real-world use\ncase, thus preserving its source-level noninterference properties down to an\nassembly-level model automatically.\n  (See paper for complete abstract.)\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 03:24:05 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Sison", "Robert", "", "1 and 2 and 3"], ["Murray", "Toby", ""]]}, {"id": "2010.14037", "submitter": "Wanxin Li", "authors": "Wanxin Li, Collin Meese, Hao Guo and Mark Nejad", "title": "Blockchain-enabled Identity Verification for Safe Ridesharing Leveraging\n  Zero-Knowledge Proof", "comments": "This paper has been accepted at IEEE International Conference on Hot\n  Information-Centric Networking (IEEE HotICN), Hefei, China, December 12-14,\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The on-demand mobility market, including ridesharing, is becoming\nincreasingly important with e-hailing fares growing at a rate of approximately\n130% per annum since 2013. By increasing utilization of existing vehicles and\nempty seats, ridesharing can provide many benefits including reduced traffic\ncongestion and environmental impact from vehicle usage and production. However,\nthe safety of riders and drivers has become of paramount concern and a method\nfor privacy-preserving identity verification between untrusted parties is\nessential for protecting users. To this end, we propose a novel\nprivacy-preserving identity verification system, extending zero-knowledge proof\n(ZKP) and blockchain for use in ridesharing applications. We design a\npermissioned blockchain network to perform the ZKP verification of a driver's\nidentity, which also acts as an immutable ledger to store ride logs and ZKP\nrecords. For the ZKP module, we design a protocol to facilitate user\nverification without requiring the exchange of any private information. We\nprototype the proposed system on the Hyperledger Fabric platform, with the\nHyperledger Ursa cryptography library, and conduct extensive experimentation.\nTo measure the prototype's performance, we utilize the Hyperledger Caliper\nbenchmark tool to perform extensive analysis and the results show that our\nsystem is suitable for use in real-world ridesharing applications.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 03:43:39 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 00:44:56 GMT"}, {"version": "v3", "created": "Sun, 1 Nov 2020 14:06:48 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Li", "Wanxin", ""], ["Meese", "Collin", ""], ["Guo", "Hao", ""], ["Nejad", "Mark", ""]]}, {"id": "2010.14077", "submitter": "Dung Hoang Duong", "authors": "Giang L. D. Nguyen, Willy Susilo, Dung Hoang Duong, Huy Quoc Le,\n  Fuchun Guo", "title": "Lattice-based IBE with Equality Test Supporting Flexible Authorization\n  in the Standard Model", "comments": "To appear in IndoCrypt 2020. arXiv admin note: text overlap with\n  arXiv:2005.03178", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identity-based encryption with equality test supporting flexible\nauthorization (IBEET-FA) allows the equality test of underlying messages of two\nciphertexts while strengthens privacy protection by allowing users (identities)\nto control the comparison of their ciphertexts with others. IBEET by itself has\na wide range of useful applicable domain such as keyword search on encrypted\ndata, database partitioning for efficient encrypted data management, personal\nhealth record systems, and spam filtering in encrypted email systems. The\nflexible authorization will enhance privacy protection of IBEET. In this paper,\nwe propose an efficient construction of IBEET-FA system based on the hardness\nof learning with error (LWE) problem. Our security proof holds in the standard\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 10:55:50 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Nguyen", "Giang L. D.", ""], ["Susilo", "Willy", ""], ["Duong", "Dung Hoang", ""], ["Le", "Huy Quoc", ""], ["Guo", "Fuchun", ""]]}, {"id": "2010.14417", "submitter": "Daniele Lain", "authors": "Anders Dalskov, Daniele Lain, Enis Ulqinaku, Kari Kostiainen, Srdjan\n  Capkun", "title": "2FE: Two-Factor Encryption for Cloud Storage", "comments": "18 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Encrypted cloud storage services are steadily increasing in popularity, with\nmany commercial solutions currently available. In such solutions, the cloud\nstorage is trusted for data availability, but not for confidentiality.\nAdditionally, the user's device is considered secure, and the user is expected\nto behave correctly.\n  We argue that such assumptions are not met in reality: e.g., users routinely\nforget passwords and fail to make backups, and users' devices get stolen or\nbecome infected with malware. Therefore, we consider a more extensive threat\nmodel, where users' devices are susceptible to attacks and common human errors\nare possible. Given this model, we analyze 10 popular commercial services and\nshow that none of them provides good confidentiality and data availability.\n  Motivated by the lack of adequate solutions in the market, we design a novel\nscheme called Two-Factor Encryption (2FE) that draws inspiration from\ntwo-factor authentication and turns file encryption and decryption into an\ninteractive process where two user devices, like a laptop and a smartphone,\nmust interact. 2FE provides strong confidentiality and availability guarantees,\nas it withstands compromised cloud storage, one stolen or compromised user\ndevice at a time, and various human errors. 2FE achieves this by leveraging\nsecret sharing with additional techniques such as oblivious pseudorandom\nfunctions and zero-knowledge proofs. We evaluate 2FE experimentally and show\nthat its performance overhead is small. Finally, we explain how our approach\ncan be adapted to other related use cases such as cryptocurrency wallets.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 16:25:58 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Dalskov", "Anders", ""], ["Lain", "Daniele", ""], ["Ulqinaku", "Enis", ""], ["Kostiainen", "Kari", ""], ["Capkun", "Srdjan", ""]]}, {"id": "2010.14445", "submitter": "James Scheibner", "authors": "James Scheibner, Jean Louis Raisaro, Juan Ram\\'on Troncoso-Pastoriza,\n  Marcello Ienca, Jacques Fellay, Effy Vayena, Jean-Pierre Hubaux", "title": "Revolutionizing Medical Data Sharing Using Advanced Privacy Enhancing\n  Technologies: Technical, Legal and Ethical Synthesis", "comments": "19 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multisite medical data sharing is critical in modern clinical practice and\nmedical research. The challenge is to conduct data sharing that preserves\nindividual privacy and data usability. The shortcomings of traditional\nprivacy-enhancing technologies mean that institutions rely on bespoke data\nsharing contracts. These contracts increase the inefficiency of data sharing\nand may disincentivize important clinical treatment and medical research. This\npaper provides a synthesis between two novel advanced privacy enhancing\ntechnologies (PETs): Homomorphic Encryption and Secure Multiparty Computation\n(defined together as Multiparty Homomorphic Encryption or MHE). These PETs\nprovide a mathematical guarantee of privacy, with MHE providing a performance\nadvantage over separately using HE or SMC. We argue MHE fulfills legal\nrequirements for medical data sharing under the General Data Protection\nRegulation (GDPR) which has set a global benchmark for data protection.\nSpecifically, the data processed and shared using MHE can be considered\nanonymized data. We explain how MHE can reduce the reliance on customized\ncontractual measures between institutions. The proposed approach can accelerate\nthe pace of medical research whilst offering additional incentives for\nhealthcare and research institutes to employ common data interoperability\nstandards.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 17:03:28 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Scheibner", "James", ""], ["Raisaro", "Jean Louis", ""], ["Troncoso-Pastoriza", "Juan Ram\u00f3n", ""], ["Ienca", "Marcello", ""], ["Fellay", "Jacques", ""], ["Vayena", "Effy", ""], ["Hubaux", "Jean-Pierre", ""]]}, {"id": "2010.14457", "submitter": "Miroslav Mitev", "authors": "Miroslav Mitev, Mahdi Shekiba-Herfeh, Arsenia Chorti, Martin Reed", "title": "Multi-factor Physical Layer Security Authentication in Short Blocklength\n  Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lightweight and low latency security schemes at the physical layer that have\nrecently attracted a lot of attention include: (i) physical unclonable\nfunctions (PUFs), (ii) localization based authentication, and, (iii) secret key\ngeneration (SKG) from wireless fading coefficients. In this paper, we focus on\nshort blocklengths and propose a fast, privacy preserving, multi-factor\nauthentication protocol that uniquely combines PUFs, proximity estimation and\nSKG. We focus on delay constrained applications and demonstrate the performance\nof the SKG scheme in the short blocklength by providing a numerical comparison\nof three families of channel codes, including half rate low density parity\ncheck codes (LDPC), Bose Chaudhuri Hocquenghem (BCH), and, Polar Slepian Wolf\ncodes for n=512, 1024. The SKG keys are incorporated in a zero-round-trip-time\nresumption protocol for fast re-authentication. All schemes of the proposed\nmutual authentication protocol are shown to be secure through formal proofs\nusing Burrows, Abadi and Needham (BAN) and Mao and Boyd (MB) logic as well as\nthe Tamarin-prover.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 17:17:13 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 14:54:00 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Mitev", "Miroslav", ""], ["Shekiba-Herfeh", "Mahdi", ""], ["Chorti", "Arsenia", ""], ["Reed", "Martin", ""]]}, {"id": "2010.14503", "submitter": "Jean De Dieu Mutangana", "authors": "Jean de Dieu Mutangana, Ravi Tandon", "title": "Topological Interference Management with Confidential Messages", "comments": "Submitted to IEEE Transactions on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The topological interference management (TIM) problem refers to the study of\nthe K-user partially connected interference networks with no channel state\ninformation at the transmitters (CSIT), except for the knowledge of network\ntopology. In this paper, we study the TIM problem with confidential messages\n(TIM-CM), where message confidentiality must be satisfied in addition to\nreliability constraints. In particular, each transmitted message must be\ndecodable at its intended receiver and remain confidential at the remaining\n(K-1) receivers.\n  Our main contribution is to present a comprehensive set of results for the\nTIM-CM problem by studying the symmetric secure degrees of freedom (SDoF). To\nthis end, we first characterize necessary and sufficient conditions for\nfeasibility of positive symmetric SDoF for any arbitrary topology. We next\npresent two achievable schemes for the TIM-CM problem: For the first scheme, we\nuse the concept of secure partition and, for the second one, we use the concept\nof secure maximal independent sets. We also present outer bounds on symmetric\nSDoF for any arbitrary network topology. Using these bounds, we characterize\nthe optimal symmetric SDoF of all K=2-user and K=3-user network topologies.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 17:59:07 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Mutangana", "Jean de Dieu", ""], ["Tandon", "Ravi", ""]]}, {"id": "2010.14658", "submitter": "Arun Ganesh", "authors": "Arun Ganesh, Kunal Talwar", "title": "Faster Differentially Private Samplers via R\\'enyi Divergence Analysis\n  of Discretized Langevin MCMC", "comments": "Appeared in NeurIPS 2020. Fixed a typo in the proof of Theorem 15", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various differentially private algorithms instantiate the exponential\nmechanism, and require sampling from the distribution $\\exp(-f)$ for a suitable\nfunction $f$. When the domain of the distribution is high-dimensional, this\nsampling can be computationally challenging. Using heuristic sampling schemes\nsuch as Gibbs sampling does not necessarily lead to provable privacy. When $f$\nis convex, techniques from log-concave sampling lead to polynomial-time\nalgorithms, albeit with large polynomials. Langevin dynamics-based algorithms\noffer much faster alternatives under some distance measures such as statistical\ndistance. In this work, we establish rapid convergence for these algorithms\nunder distance measures more suitable for differential privacy. For smooth,\nstrongly-convex $f$, we give the first results proving convergence in R\\'enyi\ndivergence. This gives us fast differentially private algorithms for such $f$.\nOur techniques and simple and generic and apply also to underdamped Langevin\ndynamics.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 22:52:45 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 07:21:58 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Ganesh", "Arun", ""], ["Talwar", "Kunal", ""]]}, {"id": "2010.14747", "submitter": "Donghyun Yu", "authors": "Donghyun Yu, Ruei-Hau Hsu, Jemin Lee", "title": "EC-SVC: Secure CAN Bus In-Vehicle Communications with Fine-grained\n  Access Control Based on Edge Computing", "comments": "13 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In-vehicle communications are not designed for message exchange between the\nvehicles and outside systems originally. Thus, the security design of message\nprotection is insufficient. Moreover, the internal devices do not have enough\nresources to process the additional security operations. Nonetheless, due to\nthe characteristic of the in-vehicle network in which messages are broadcast,\nsecure message transmission to specific receivers must be ensured. With\nconsideration of the facts aforementioned, this work addresses resource\nproblems by offloading secure operations to high-performance devices, and uses\nattribute-based access control to ensure the confidentiality of messages from\nattackers and unauthorized users. In addition, we reconfigure existing access\ncontrol based cryptography to address new vulnerabilities arising from the use\nof edge computing and attribute-based access control. Thus, this paper proposes\nan edge computing-based security protocol with fine-grained attribute-based\nencryption using a hash function, symmetric-based cryptography, and\nreconfigured cryptographic scheme. In addition, this work formally proves the\nreconfigured cryptographic scheme and security protocol, and evaluates the\nfeasibility of the proposed security protocol in various aspects using the\nCANoe software.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 04:50:38 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Yu", "Donghyun", ""], ["Hsu", "Ruei-Hau", ""], ["Lee", "Jemin", ""]]}, {"id": "2010.14927", "submitter": "Amit Daniely", "authors": "Amit Daniely and Hadas Schacham", "title": "Most ReLU Networks Suffer from $\\ell^2$ Adversarial Perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider ReLU networks with random weights, in which the dimension\ndecreases at each layer. We show that for most such networks, most examples $x$\nadmit an adversarial perturbation at an Euclidean distance of\n$O\\left(\\frac{\\|x\\|}{\\sqrt{d}}\\right)$, where $d$ is the input dimension.\nMoreover, this perturbation can be found via gradient flow, as well as gradient\ndescent with sufficiently small steps. This result can be seen as an\nexplanation to the abundance of adversarial examples, and to the fact that they\nare found via gradient descent.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 12:42:22 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Daniely", "Amit", ""], ["Schacham", "Hadas", ""]]}, {"id": "2010.15070", "submitter": "Federico Franzoni", "authors": "Federico Franzoni, Vanesa Daza", "title": "Improving Bitcoin Transaction Propagation by Leveraging Unreachable\n  Nodes", "comments": "16 pages, 1 figure, Published in \"IEEE Blockchain 2020\" conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bitcoin P2P network is at the core of all communications between clients.\nThe reachable part of this network has been explored and analyzed by numerous\nstudies. Unreachable nodes, however, are, in most part, overlooked.\nNonetheless, they are a relevant part of the network and play an essential role\nin the propagation of messages. In this paper, we focus on transaction\npropagation and show that increasing the participation of unreachable nodes can\npotentially improve the robustness and efficiency of the network. In order to\ndo that, we propose a few changes to the network protocol. Additionally, we\ndesign a novel transaction propagation protocol that explicitly involves\nunreachable nodes to provide better protection against deanonymization attacks.\nOur solutions are simple to implement and can effectively bring immediate\nbenefits to the Bitcoin network.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 16:28:16 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Franzoni", "Federico", ""], ["Daza", "Vanesa", ""]]}, {"id": "2010.15082", "submitter": "Cuneyt Gurcan Akcora", "authors": "Cuneyt G. Akcora, Sudhanva Purusotham, Yulia R. Gel, Mitchell\n  Krawiec-Thayer, Murat Kantarcioglu", "title": "How to Not Get Caught When You Launder Money on Blockchain?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of blockchain users has tremendously grown in recent years. As an\nunintended consequence, e-crime transactions on blockchains has been on the\nrise. Consequently, public blockchains have become a hotbed of research for\ndeveloping AI tools to detect and trace users and transactions that are related\nto e-crime.\n  We argue that following a few select strategies can make money laundering on\nblockchain virtually undetectable with most of the existing tools and\nalgorithms. As a result, the effective combating of e-crime activities\ninvolving cryptocurrencies requires the development of novel analytic\nmethodology in AI.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 02:12:15 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Akcora", "Cuneyt G.", ""], ["Purusotham", "Sudhanva", ""], ["Gel", "Yulia R.", ""], ["Krawiec-Thayer", "Mitchell", ""], ["Kantarcioglu", "Murat", ""]]}, {"id": "2010.15103", "submitter": "Alex B. Grilo", "authors": "Alex B. Grilo and Kathrin H\\\"ovelmanns and Andreas H\\\"ulsing and\n  Christian Majenz", "title": "Tight adaptive reprogramming in the QROM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The random oracle model (ROM) enjoys widespread popularity, mostly because it\ntends to allow for tight and conceptually simple proofs where provable security\nin the standard model is elusive or costly. While being the adequate\nreplacement of the ROM in the post-quantum security setting, the\nquantum-accessible random oracle model (QROM) has thus far failed to provide\nthese advantages in many settings. In this work, we focus on adaptive\nreprogrammability, a feature of the ROM enabling tight and simple proofs in\nmany settings. We show that the straightforward quantum-accessible\ngeneralization of adaptive reprogramming is feasible by proving a bound on the\nadversarial advantage in distinguishing whether a random oracle has been\nreprogrammed or not. We show that our bound is tight by providing a matching\nattack. We go on to demonstrate that our technique recovers the mentioned\nadvantages of the ROM in three QROM applications: 1) We give a tighter proof of\nsecurity of the message compression routine as used by XMSS. 2) We show that\nthe standard ROM proof of chosen-message security for Fiat-Shamir signatures\ncan be lifted to the QROM, straightforwardly, achieving a tighter reduction\nthan previously known. 3) We give the first QROM proof of security against\nfault injection and nonce attacks for the hedged Fiat-Shamir transform.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 17:38:25 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 13:27:39 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Grilo", "Alex B.", ""], ["H\u00f6velmanns", "Kathrin", ""], ["H\u00fclsing", "Andreas", ""], ["Majenz", "Christian", ""]]}, {"id": "2010.15232", "submitter": "Hesam Hamledari", "authors": "Hesam Hamledari and Martin Fischer", "title": "Construction Payment Automation Using Blockchain-Enabled Smart Contracts\n  and Reality Capture Technologies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a smart contract-based solution for autonomous\nadministration of construction progress payments. It bridges the gap between\npayments (cash flow) and the progress assessments at job sites (product flow)\nenabled by reality capture technologies and building information modeling\n(BIM). The approach eliminates the reliance on the centralized and heavily\nintermediated mechanisms of existing payment applications. The construction\nprogress is stored in a distributed manner using content addressable file\nsharing; it is broadcasted to a smart contract which automates the on-chain\npayment settlements and the transfer of lien rights. The method was\nsuccessfully used for processing payments to 7 subcontractors in two commercial\nconstruction projects where progress monitoring was performed using a\ncamera-equipped unmanned aerial vehicle (UAV) and an unmanned ground vehicle\n(UGV) equipped with a laser scanner. The results show promise for the method's\npotential for increasing the frequency, granularity, and transparency of\npayments. The paper is concluded with a discussion of implications for project\nmanagement, introducing a new model of project as a singleton state machine.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 21:04:47 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 15:27:43 GMT"}, {"version": "v3", "created": "Tue, 2 Mar 2021 17:19:56 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Hamledari", "Hesam", ""], ["Fischer", "Martin", ""]]}, {"id": "2010.15329", "submitter": "Abdulrahman Alaql", "authors": "Abdulrahman Alaql, Swarup Bhunia", "title": "Scalable Attack-Resistant Obfuscation of Logic Circuits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware IP protection has been one of the most critical areas of research in\nthe past years. Recently, attacks on hardware IPs (such as reverse engineering\nor cloning) have evolved as attackers have developed sophisticated techniques.\nTherefore, hardware obfuscation has been introduced as a powerful tool to\nprotect IPs against piracy attacks. However, many recent attempts to break\nexisting obfuscation methods have been successful in unlocking the IP and\nrestoring its functionality. In this paper, we propose SARO, a Scalable\nAttack-Resistant Obfuscation that provides a robust functional and structural\ndesign transformation process. SARO treats the target circuit as a graph, and\nperforms a partitioning algorithm to produce a set of sub-graphs, then applies\nour novel Truth Table Transformation (T3) process to each partition. We also\npropose the $T3_{metric}$, which is developed to quantify the structural and\nfunctional design transformation level caused by the obfuscation process. We\nevaluate SARO on ISCAS85 and EPFL benchmarks, and provide full security and\nperformance analysis of our proposed framework.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 02:59:50 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Alaql", "Abdulrahman", ""], ["Bhunia", "Swarup", ""]]}, {"id": "2010.15394", "submitter": "Leandros Maglaras A", "authors": "Fraser Hall, Leandros Maglaras, Theodoros Aivaliotis, Loukas\n  Xagoraris, Ioanna Kantzavelou", "title": "Smart Homes: Security Challenges and Privacy Concerns", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Development and growth of Internet of Things (IoT) technology has\nexponentially increased over the course of the last 10 years since its\ninception, and as a result has directly influenced the popularity and size of\nsmart homes. In this article we present the main technologies and applications\nthat constitute a smart home, we identify the main security and privacy\nchallenges that smart home face and we provide good practices to mitigate those\nthreats.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 07:31:39 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Hall", "Fraser", ""], ["Maglaras", "Leandros", ""], ["Aivaliotis", "Theodoros", ""], ["Xagoraris", "Loukas", ""], ["Kantzavelou", "Ioanna", ""]]}, {"id": "2010.15561", "submitter": "Sudipan Saha", "authors": "Sudipan Saha and Tahir Ahmad", "title": "Federated Transfer Learning: concept and applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Development of Artificial Intelligence (AI) is inherently tied to the\ndevelopment of data. However, in most industries data exists in form of\nisolated islands, with limited scope of sharing between different\norganizations. This is an hindrance to the further development of AI. Federated\nlearning has emerged as a possible solution to this problem in the last few\nyears without compromising user privacy. Among different variants of the\nfederated learning, noteworthy is federated transfer learning (FTL) that allows\nknowledge to be transferred across domains that do not have many overlapping\nfeatures and users. In this work we provide a comprehensive survey of the\nexisting works on this topic. In more details, we study the background of FTL\nand its different existing applications. We further analyze FTL from privacy\nand machine learning perspective.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 19:46:07 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 18:07:42 GMT"}, {"version": "v3", "created": "Sat, 6 Mar 2021 10:20:25 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Saha", "Sudipan", ""], ["Ahmad", "Tahir", ""]]}, {"id": "2010.15668", "submitter": "Arjun Anand V", "authors": "Arjun Anand V, Buvanasri A K, Meenakshi R, Dr. Karthika S, Ashok Kumar\n  Mohan", "title": "PeopleXploit -- A hybrid tool to collect public data", "comments": "8 pages, 3 images, ICCCSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the concept of Open Source Intelligence (OSINT) as an\nimportant application in intelligent profiling of individuals. With a variety\nof tools available, significant data shall be obtained on an individual as a\nconsequence of analyzing his/her internet presence but all of this comes at the\ncost of low relevance. To increase the relevance score in profiling,\nPeopleXploit is being introduced. PeopleXploit is a hybrid tool which helps in\ncollecting the publicly available information that is reliable and relevant to\nthe given input. This tool is used to track and trace the given target with\ntheir digital footprints like Name, Email, Phone Number, User IDs etc. and the\ntool will scan & search other associated data from public available records\nfrom the internet and create a summary report against the target. PeopleXploit\nprofiles a person using authorship analysis and finds the best matching guess.\nAlso, the type of analysis performed (professional/matrimonial/criminal entity)\nvaries with the requirement of the user.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 07:08:52 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Anand", "Arjun", "V"], ["K", "Buvanasri A", ""], ["R", "Meenakshi", ""], ["S", "Dr. Karthika", ""], ["Mohan", "Ashok Kumar", ""]]}, {"id": "2010.15678", "submitter": "Herv\\'e Tal\\'e Kalachi", "authors": "Herve Tale Kalachi", "title": "On the Failure of the Smart Approach of the GPT Cryptosystem", "comments": "Accepted to Cryptologia. arXiv admin note: text overlap with\n  arXiv:1602.08549", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new algorithm for breaking the smart approach of the\nGPT cryptosystem. We show that by puncturing the public code several times on\nspecific positions, we get a public code on which applying the Frobenius\noperator appropriately allows to build an alternative secret key.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 11:31:09 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Kalachi", "Herve Tale", ""]]}, {"id": "2010.15697", "submitter": "Yash Samtani", "authors": "Yash Samtani, Jesse Elwell", "title": "Generalized Insider Attack Detection Implementation using NetFlow Data", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Insider Attack Detection in commercial networks is a critical problem that\ndoes not have any good solutions at this current time. The problem is\nchallenging due to the lack of visibility into live networks and a lack of a\nstandard feature set to distinguish between different attacks. In this paper,\nwe study an approach centered on using network data to identify attacks. Our\nwork builds on unsupervised machine learning techniques such as One-Class SVM\nand bi-clustering as weak indicators of insider network attacks. We combine\nthese techniques to limit the number of false positives to an acceptable level\nrequired for real-world deployments by using One-Class SVM to check for\nanomalies detected by the proposed Bi-clustering algorithm. We present a\nprototype implementation in Python and associated results for two different\nreal-world representative data sets. We show that our approach is a promising\ntool for insider attack detection in realistic settings.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 14:00:31 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Samtani", "Yash", ""], ["Elwell", "Jesse", ""]]}, {"id": "2010.15711", "submitter": "Jaehyeok Han", "authors": "Jaehyeok Han, Jieon Kim, Sangjin Lee", "title": "5W1H-based Expression for the Effective Sharing of Information in\n  Digital Forensic Investigations", "comments": "This paper was presented at the Sixteenth Annual IFIP WG 11.9\n  International Conference on Digital Forensics, Delhi, India, in January 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital forensic investigation is used in various areas related to digital\ndevices including the cyber crime. This is an investigative process using many\ntechniques, which have implemented as tools. The types of files covered by the\ndigital forensic investigation are wide and varied, however, there is no way to\nexpress the results into a standardized format. The standardization are\ndifferent by types of device, file system, or application. Different outputs\nmake it time-consuming and difficult to share information and to implement\nintegration. In addition, it could weaken cyber security. Thus, it is important\nto define normalization and to present data in the same format. In this paper,\na 5W1H-based expression for information sharing for effective digital forensic\ninvestigation is proposed to analyze digital forensic information using six\nquestions--what, who, where, when, why and how. Based on the 5W1H-based\nexpression, digital information from different types of files is converted and\nrepresented in the same format of outputs. As the 5W1H is the basic writing\nprinciple, application of the 5W1H-based expression on the case studies shows\nthat this expression enhances clarity and correctness for information sharing.\nFurthermore, in the case of security incidents, this expression has an\nadvantage in being compatible with STIX.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 00:44:09 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Han", "Jaehyeok", ""], ["Kim", "Jieon", ""], ["Lee", "Sangjin", ""]]}, {"id": "2010.15718", "submitter": "Jia Qian", "authors": "Jia Qian, Hiba Nassar, Lars Kai Hansen", "title": "Minimal conditions analysis of gradient-based reconstruction in\n  Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The input data from a neural network may be reconstructed using knowledge of\nthe gradients of that network, as demonstrated by \\cite{zhu2019deep}. By\nimposing prior information and utilising a uniform initialization we\ndemonstrate faster and more accurate image reconstruction. Exploring the\ntheoretical limits of reconstruction, we show that a single input may be\nreconstructed, regardless of network depth using a fully-connected neural\nnetwork with one hidden node. Then we generalize this result to a gradient\naveraged over mini-batches of size $B$. In this case, the full mini-batch can\nbe reconstructed if the number of hidden units exceeds $B$, with an\northogonality regularizer to improve the precision. For a Convolutional Neural\nNetwork, the required number of filters in the first convolutional layer is\ndecided by multiple factors (e.g., padding, kernel and stride size). Therefore,\nwe require the number of filters, $h\\geq (\\frac{d}{d^{'}})^2C$, where $d$ is\ninput width, $d^{'}$ is output width after convolution kernel, and $C$ is\nchannel number of input. Finally, we validate our theoretical analysis and\nimprovements using bio-medical (fMRI) and benchmark data (MNIST,\nKuzushiji-MNIST, CIFAR100, ImageNet and face images).\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 16:05:45 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 15:50:14 GMT"}, {"version": "v3", "created": "Thu, 25 Mar 2021 10:03:16 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Qian", "Jia", ""], ["Nassar", "Hiba", ""], ["Hansen", "Lars Kai", ""]]}, {"id": "2010.15773", "submitter": "Akshay Agarwal", "authors": "Divyam Anshumaan, Akshay Agarwal, Mayank Vatsa, and Richa Singh", "title": "WaveTransform: Crafting Adversarial Examples via Input Decomposition", "comments": "ECCV Workshop Adversarial Robustness in the Real World 2020, 17\n  pages, 3 Tables, 6 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frequency spectrum has played a significant role in learning unique and\ndiscriminating features for object recognition. Both low and high frequency\ninformation present in images have been extracted and learnt by a host of\nrepresentation learning techniques, including deep learning. Inspired by this\nobservation, we introduce a novel class of adversarial attacks, namely\n`WaveTransform', that creates adversarial noise corresponding to low-frequency\nand high-frequency subbands, separately (or in combination). The frequency\nsubbands are analyzed using wavelet decomposition; the subbands are corrupted\nand then used to construct an adversarial example. Experiments are performed\nusing multiple databases and CNN models to establish the effectiveness of the\nproposed WaveTransform attack and analyze the importance of a particular\nfrequency component. The robustness of the proposed attack is also evaluated\nthrough its transferability and resiliency against a recent adversarial defense\nalgorithm. Experiments show that the proposed attack is effective against the\ndefense algorithm and is also transferable across CNNs.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 17:16:59 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Anshumaan", "Divyam", ""], ["Agarwal", "Akshay", ""], ["Vatsa", "Mayank", ""], ["Singh", "Richa", ""]]}, {"id": "2010.15862", "submitter": "Carlos Pedroso", "authors": "Carlos Pedroso, Aldri Santos, Michele Nogueira", "title": "Detecting FDI Attack on Dense IoT Network with Distributed Filtering\n  Collaboration and Consensus", "comments": "This work has been accept to the IEEE LATINCOM2020. Copyright\n  978-1-7281-8903-1/20/$31.00 \\c{opyright}2020 IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of IoT has made possible the development of %increasingly\npersonalized services, like industrial services that often deal with massive\namounts of data. However, as IoT grows, its threats are even greater. The false\ndata injection (FDI) attack stands out as being one of the most harmful to data\nnetworks like IoT. The majority of current systems to handle this attack do not\ntake into account the data validation, especially on the data clustering\nservice. This work introduces CONFINIT, an intrusion detection system against\nFDI attacks on the data dissemination service into dense IoT. It combines\nwatchdog surveillance and collaborative consensus among IoT devices for getting\nthe swift detection of attackers. CONFINIT was evaluated in the NS-3 simulator\ninto a dense industrial IoT and it has gotten detection rates of 99%, 3.2% of\nfalse negative and 3.6% of false positive rates, adding up to 35% in clustering\nwithout FDI attackers.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 18:08:08 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Pedroso", "Carlos", ""], ["Santos", "Aldri", ""], ["Nogueira", "Michele", ""]]}, {"id": "2010.15866", "submitter": "Emmanuel Stapf", "authors": "Raad Bahmani, Ferdinand Brasser, Ghada Dessouky, Patrick Jauernig,\n  Matthias Klimmek, Ahmad-Reza Sadeghi, Emmanuel Stapf", "title": "CURE: A Security Architecture with CUstomizable and Resilient Enclaves", "comments": "Accepted to be published in the proceedings of the 30th USENIX\n  Security Symposium (USENIX Security '21 )", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security architectures providing Trusted Execution Environments (TEEs) have\nbeen an appealing research subject for a wide range of computer systems, from\nlow-end embedded devices to powerful cloud servers. The goal of these\narchitectures is to protect sensitive services in isolated execution contexts,\ncalled enclaves. Unfortunately, existing TEE solutions suffer from significant\ndesign shortcomings. First, they follow a one-size-fits-all approach offering\nonly a single enclave type, however, different services need flexible enclaves\nthat can adjust to their demands. Second, they cannot efficiently support\nemerging applications (e.g., Machine Learning as a Service), which require\nsecure channels to peripherals (e.g., accelerators), or the computational power\nof multiple cores. Third, their protection against cache side-channel attacks\nis either an afterthought or impractical, i.e., no fine-grained mapping between\ncache resources and individual enclaves is provided.\n  In this work, we propose CURE, the first security architecture, which tackles\nthese design challenges by providing different types of enclaves: (i) sub-space\nenclaves provide vertical isolation at all execution privilege levels, (ii)\nuser-space enclaves provide isolated execution to unprivileged applications,\nand (iii) self-contained enclaves allow isolated execution environments that\nspan multiple privilege levels. Moreover, CURE enables the exclusive assignment\nof system resources, e.g., peripherals, CPU cores, or cache resources to single\nenclaves. CURE requires minimal hardware changes while significantly improving\nthe state of the art of hardware-assisted security architectures. We\nimplemented CURE on a RISC-V-based SoC and thoroughly evaluated our prototype\nin terms of hardware and performance overhead. CURE imposes a geometric mean\nperformance overhead of 15.33% on standard benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 18:11:14 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Bahmani", "Raad", ""], ["Brasser", "Ferdinand", ""], ["Dessouky", "Ghada", ""], ["Jauernig", "Patrick", ""], ["Klimmek", "Matthias", ""], ["Sadeghi", "Ahmad-Reza", ""], ["Stapf", "Emmanuel", ""]]}, {"id": "2010.15867", "submitter": "Xavier Salleras", "authors": "Xavier Salleras and Vanesa Daza", "title": "SANS: Self-sovereign Authentication for Network Slices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  5G communications proposed significant improvements over 4G in terms of\nefficiency and security. Among these novelties, the 5G Network Slicing seems to\nhave a prominent role: deploy multiple virtual network slices, each providing a\ndifferent service with different needs and features. Like this, a Slice\nOperator (SO) ruling a specific slice may want to offer a service for users\nmeeting some requirements. It is of paramount importance to provide a robust\nauthentication protocol, able to ensure that users meet the requirements, but\nproviding at the same time a privacy-by-design architecture. This makes even\nmore sense having a growing density of Internet of Things (IoT) devices\nexchanging private information over the network. In this paper, we improve the\n5G network slicing authentication using a Self-Sovereign Identity (SSI) scheme:\ngranting users full control over their data. We introduce an approach to allow\na user to prove his right to access a specific service without leaking any\ninformation about him. Such an approach is SANS, a protocol that provides\nnon-linkable protection for any issued information, preventing an SO or an\neavesdropper from tracking users' activity and relating it with their real\nidentities. Furthermore, our protocol is scalable and can be taken as a\nframework for improving related technologies in similar scenarios, like\nauthentication in the 5G Radio Access Network (RAN) or other wireless networks\nand services. Such features can be achieved using cryptographic primitives\ncalled Zero-Knowledge Proofs (ZKP). Upon implementing our solution using a\nstate-of-the-art ZKP library and performing several experiments, we provide\nbenchmarks demonstrating that our approach is affordable in speed and memory\nconsumption.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 18:12:43 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Salleras", "Xavier", ""], ["Daza", "Vanesa", ""]]}, {"id": "2010.15974", "submitter": "Jose Oramas", "authors": "Roger Granda, Tinne Tuytelaars, Jose Oramas", "title": "Can the state of relevant neurons in a deep neural networks serve as\n  indicators for detecting adversarial attacks?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for adversarial attack detection based on the inspection\nof a sparse set of neurons. We follow the hypothesis that adversarial attacks\nintroduce imperceptible perturbations in the input and that these perturbations\nchange the state of neurons relevant for the concepts modelled by the attacked\nmodel. Therefore, monitoring the status of these neurons would enable the\ndetection of adversarial attacks. Focusing on the image classification task,\nour method identifies neurons that are relevant for the classes predicted by\nthe model. A deeper qualitative inspection of these sparse set of neurons\nindicates that their state changes in the presence of adversarial samples.\nMoreover, quantitative results from our empirical evaluation indicate that our\nmethod is capable of recognizing adversarial samples, produced by\nstate-of-the-art attack methods, with comparable accuracy to that of\nstate-of-the-art detectors.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 22:31:42 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Granda", "Roger", ""], ["Tuytelaars", "Tinne", ""], ["Oramas", "Jose", ""]]}, {"id": "2010.15985", "submitter": "Kunjal Panchal", "authors": "Kunjal Panchal", "title": "Differential Privacy and Natural Language Processing to Generate\n  Contextually Similar Decoy Messages in Honey Encryption Scheme", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Honey Encryption is an approach to encrypt the messages using low min-entropy\nkeys, such as weak passwords, OTPs, PINs, credit card numbers. The ciphertext\nis produces, when decrypted with any number of incorrect keys, produces\nplausible-looking but bogus plaintext called \"honey messages\". But the current\ntechniques used in producing the decoy plaintexts do not model human language\nentirely. A gibberish, random assortment of words is not enough to fool an\nattacker; that will not be acceptable and convincing, whether or not the\nattacker knows some information of the genuine source.\n  In this paper, I focus on the plaintexts which are some non-numeric\ninformative messages. In order to fool the attacker into believing that the\ndecoy message can actually be from a certain source, we need to capture the\nempirical and contextual properties of the language. That is, there should be\nno linguistic difference between real and fake message, without revealing the\nstructure of the real message. I employ natural language processing and\ngeneralized differential privacy to solve this problem. Mainly I focus on\nmachine learning methods like keyword extraction, context classification,\nbags-of-words, word embeddings, transformers for text processing to model\nprivacy for text documents. Then I prove the security of this approach with\ne-differential privacy.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 23:02:32 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Panchal", "Kunjal", ""]]}, {"id": "2010.16024", "submitter": "Ryotaro Nakata", "authors": "Ryotaro Nakata and Akira Otsuka", "title": "Evaluation of vulnerability reproducibility in container-based Cyber\n  Range", "comments": "14 pages, 7 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A cyber range, a practical and highly educational information security\nexercise system, is difficult to implement in educational institutions because\nof the high cost of implementing and maintaining it. Therefore, there is a need\nfor a cyber range that can be adopted and maintained at a low cost. Recently,\ncontainer type virtualization is gaining attention as it can create a\nhigh-speed and high-density exercise environment. However, existing researches\nhave not clearly shown the advantages of container virtualization for building\nexercise environments. And it is not clear whether the sufficient\nvulnerabilities are reproducible, which is required to conduct incident\nscenarios in cyber range. In this paper, we compare container virtualization\nwith existing virtualization type and confirm that the amount of memory, CPU,\nand storage consumption can be reduced to less than 1/10 of the conventional\nvirtualization methods. We also compare and verify the reproducibility of the\nvulnerabilities used in common exercise scenarios and confirm that 99.3% of the\nvulnerabilities are reproducible. The container-based cyber range can be used\nas a new standard to replace existing methods.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 02:22:21 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 23:29:41 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Nakata", "Ryotaro", ""], ["Otsuka", "Akira", ""]]}, {"id": "2010.16034", "submitter": "Xiangyu Wang", "authors": "Xiangyu Wang, Ting Yang, Yu Wang", "title": "State sharding model on the blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain is an incrementally updated ledger maintained by distributed nodes\nrather than centralized organizations. The current blockchain technology faces\nscalability issues, which include two aspects: low transaction throughput and\nhigh storage capacity costs. This paper studies the blockchain structure based\non state sharding technology, and mainly solves the problem of non-scalability\nof block chain storage. This paper designs and implements the blockchain state\nsharding scheme, proposes a specific state sharding data structure and\nalgorithm implementation, and realizes a complete blockchain structure so that\nthe blockchain has the advantages of high throughput, processing a large number\nof transactions and saving storage costs. Experimental results show that a\nblockchain network with more than 100,000 nodes can be divided into 1024\nshards. A blockchain network with this structure can process 500,000\ntransactions in about 5 seconds. If the consensus time of the blockchain is\nabout 10 seconds, and the block generation time of the blockchain system of the\nsharding mechanism is 15 seconds, the transaction throughput can reach 33,000\ntx/sec. Experimental results show that the throughput of the proposed protocol\nincreases with the increase of the network node size. This confirms the\nscalability of the blockchain structure based on sharding technology.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 02:55:19 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Wang", "Xiangyu", ""], ["Yang", "Ting", ""], ["Wang", "Yu", ""]]}, {"id": "2010.16045", "submitter": "Fabr\\'icio Ceschin", "authors": "Fabr\\'icio Ceschin and Heitor Murilo Gomes and Marcus Botacin and\n  Albert Bifet and Bernhard Pfahringer and Luiz S. Oliveira and Andr\\'e\n  Gr\\'egio", "title": "Machine Learning (In) Security: A Stream of Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) has been widely applied to cybersecurity, and is\ncurrently considered state-of-the-art for solving many of the field's open\nissues. However, it is very difficult to evaluate how good the produced\nsolutions are, since the challenges faced in security may not appear in other\nareas (at least not in the same way). One of these challenges is the concept\ndrift, that actually creates an arms race between attackers and defenders,\ngiven that any attacker may create novel, different threats as time goes by (to\novercome defense solutions) and this \"evolution\" is not always considered in\nmany works. Due to this type of issue, it is fundamental to know how to\ncorrectly build and evaluate a ML-based security solution. In this work, we\nlist, detail, and discuss some of the challenges of applying ML to\ncybersecurity, including concept drift, concept evolution, delayed labels, and\nadversarial machine learning. We also show how existing solutions fail and, in\nsome cases, we propose possible solutions to fix them.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 03:40:10 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Ceschin", "Fabr\u00edcio", ""], ["Gomes", "Heitor Murilo", ""], ["Botacin", "Marcus", ""], ["Bifet", "Albert", ""], ["Pfahringer", "Bernhard", ""], ["Oliveira", "Luiz S.", ""], ["Gr\u00e9gio", "Andr\u00e9", ""]]}, {"id": "2010.16108", "submitter": "Ahmed Bensaoud", "authors": "Ahmed Bensaoud, Nawaf Abudawaood, Jugal Kalita", "title": "Classifying Malware Images with Convolutional Neural Network Models", "comments": "12 pages, 11 Figures", "journal-ref": "Vol.22, No.6, PP.1022-1031, Nov. 2020", "doi": "10.6633/IJNS.202011_22(6).17", "report-no": null, "categories": "cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to increasing threats from malicious software (malware) in both number\nand complexity, researchers have developed approaches to automatic detection\nand classification of malware, instead of analyzing methods for malware files\nmanually in a time-consuming effort. At the same time, malware authors have\ndeveloped techniques to evade signature-based detection techniques used by\nantivirus companies. Most recently, deep learning is being used in malware\nclassification to solve this issue. In this paper, we use several convolutional\nneural network (CNN) models for static malware classification. In particular,\nwe use six deep learning models, three of which are past winners of the\nImageNet Large-Scale Visual Recognition Challenge. The other three models are\nCNN-SVM, GRU-SVM and MLP-SVM, which enhance neural models with support vector\nmachines (SVM). We perform experiments using the Malimg dataset, which has\nmalware images that were converted from Portable Executable malware binaries.\nThe dataset is divided into 25 malware families. Comparisons show that the\nInception V3 model achieves a test accuracy of 99.24%, which is better than the\naccuracy of 98.52% achieved by the current state-of-the-art system called the\nM-CNN model.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 07:39:30 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Bensaoud", "Ahmed", ""], ["Abudawaood", "Nawaf", ""], ["Kalita", "Jugal", ""]]}, {"id": "2010.16204", "submitter": "Dorjan Hitaj", "authors": "Dorjan Hitaj, Briland Hitaj, Sushil Jajodia, Luigi V. Mancini", "title": "Capture the Bot: Using Adversarial Examples to Improve CAPTCHA\n  Robustness to Bot Attacks", "comments": "17 pages, 4 figures. Accepted for publication on IEEE Intelligent\n  Systems magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To this date, CAPTCHAs have served as the first line of defense preventing\nunauthorized access by (malicious) bots to web-based services, while at the\nsame time maintaining a trouble-free experience for human visitors. However,\nrecent work in the literature has provided evidence of sophisticated bots that\nmake use of advancements in machine learning (ML) to easily bypass existing\nCAPTCHA-based defenses. In this work, we take the first step to address this\nproblem. We introduce CAPTURE, a novel CAPTCHA scheme based on adversarial\nexamples. While typically adversarial examples are used to lead an ML model\nastray, with CAPTURE, we attempt to make a \"good use\" of such mechanisms. Our\nempirical evaluations show that CAPTURE can produce CAPTCHAs that are easy to\nsolve by humans while at the same time, effectively thwarting ML-based bot\nsolvers.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 11:39:04 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 07:53:16 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Hitaj", "Dorjan", ""], ["Hitaj", "Briland", ""], ["Jajodia", "Sushil", ""], ["Mancini", "Luigi V.", ""]]}, {"id": "2010.16274", "submitter": "Yajin Zhou", "authors": "Lei Wu, Yufeng Hu, Yajin Zhou, Haoyu Wang, Xiaopu Luo, Zhi Wang, Fan\n  Zhang and Kui Ren", "title": "Towards Understanding and Demystifying Bitcoin Mixing Services", "comments": null, "journal-ref": null, "doi": "10.1145/3442381.3449880", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One reason for the popularity of Bitcoin is due to its anonymity. Although\nseveral heuristics have been used to break the anonymity, new approaches are\nproposed to enhance its anonymity at the same time. One of them is the mixing\nservice. Unfortunately, mixing services have been abused to facilitate criminal\nactivities, e.g., money laundering. As such, there is an urgent need to\nsystematically understand Bitcoin mixing services.\n  In this paper, we take the first step to understand state-of-the-art Bitcoin\nmixing services. Specifically, we propose a generic abstraction model for\nmixing services and observe that there are two mixing mechanisms in the wild,\ni.e. {swapping} and {obfuscating}. Based on this model, we conduct a\ntransaction-based analysis and successfully reveal the mixing mechanisms of\nfour representative services. Besides, we propose a method to identify mixing\ntransactions that leverage the obfuscating mechanism. The proposed approach is\nable to identify over $92$\\% of the mixing transactions. Based on identified\ntransactions, we then estimate the profit of mixing services and provide a case\nstudy of tracing the money flow of stolen Bitcoins.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 13:52:24 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 06:24:53 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Wu", "Lei", ""], ["Hu", "Yufeng", ""], ["Zhou", "Yajin", ""], ["Wang", "Haoyu", ""], ["Luo", "Xiaopu", ""], ["Wang", "Zhi", ""], ["Zhang", "Fan", ""], ["Ren", "Kui", ""]]}, {"id": "2010.16323", "submitter": "Asaf Shabtai", "authors": "Tzvika Shapira and David Berend and Ishai Rosenberg and Yang Liu and\n  Asaf Shabtai and Yuval Elovici", "title": "Being Single Has Benefits. Instance Poisoning to Deceive Malware\n  Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of a machine learning-based malware classifier depends on the\nlarge and updated training set used to induce its model. In order to maintain\nan up-to-date training set, there is a need to continuously collect benign and\nmalicious files from a wide range of sources, providing an exploitable target\nto attackers. In this study, we show how an attacker can launch a sophisticated\nand efficient poisoning attack targeting the dataset used to train a malware\nclassifier. The attacker's ultimate goal is to ensure that the model induced by\nthe poisoned dataset will be unable to detect the attacker's malware yet\ncapable of detecting other malware. As opposed to other poisoning attacks in\nthe malware detection domain, our attack does not focus on malware families but\nrather on specific malware instances that contain an implanted trigger,\nreducing the detection rate from 99.23% to 0% depending on the amount of\npoisoning. We evaluate our attack on the EMBER dataset with a state-of-the-art\nclassifier and malware samples from VirusTotal for end-to-end validation of our\nwork. We propose a comprehensive detection approach that could serve as a\nfuture sophisticated defense against this newly discovered severe threat.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 15:27:44 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Shapira", "Tzvika", ""], ["Berend", "David", ""], ["Rosenberg", "Ishai", ""], ["Liu", "Yang", ""], ["Shabtai", "Asaf", ""], ["Elovici", "Yuval", ""]]}, {"id": "2010.16388", "submitter": "Xavier De Carn\\'e De Carnavalet", "authors": "Xavier de Carn\\'e de Carnavalet and Paul C. van Oorschot", "title": "A survey and analysis of TLS interception mechanisms and motivations", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  TLS is an end-to-end protocol designed to provide confidentiality and\nintegrity guarantees that improve end-user security and privacy. While TLS\nhelps defend against pervasive surveillance of intercepted unencrypted traffic,\nit also hinders several common beneficial operations typically performed by\nmiddleboxes on the network traffic. This issue has resulted in some parties\nproposing various methods that \"bypass\" the confidentiality goals of TLS by\nplaying with keys and certificates essentially in a man-in-the-middle solution,\nand leads to new proposals that extend the protocol to accommodate third\nparties, delegation schemes to trusted middleboxes, and fine-grained control\nand verification mechanisms. To better understand the underlying motivation of\nsuch research proposals, we first review the use cases expecting plain HTTP\ntraffic and discuss the extent to which TLS hinders these operations. We retain\n19 scenarios where access to unencrypted traffic is still relevant and evaluate\nthe incentives of the stakeholders involved. Second, we survey techniques and\nproposals by which TLS no longer delivers end-to-end security, and by which the\nnotion of an \"end\" changes. We therefore include endpoint-side middleboxes and\nmid-path caching middleboxes such as Content Delivery Networks (CDNs), alike.\nFinally, we compare each scheme based on deployability and security\ncharacteristics, and evaluate their compatibility with the stakeholders'\nincentives. Our analysis leads to a number of findings and observations that we\nbelieve will be of interest to practitioners, policy makers and researchers.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 17:32:19 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["de Carnavalet", "Xavier de Carn\u00e9", ""], ["van Oorschot", "Paul C.", ""]]}]