[{"id": "2101.00008", "submitter": "Farah Shamout", "authors": "Munachiso Nwadike, Takumi Miyawaki, Esha Sarkar, Michail Maniatakos,\n  Farah Shamout", "title": "Explainability Matters: Backdoor Attacks on Medical Imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been shown to be vulnerable to backdoor attacks,\nwhich could be easily introduced to the training set prior to model training.\nRecent work has focused on investigating backdoor attacks on natural images or\ntoy datasets. Consequently, the exact impact of backdoors is not yet fully\nunderstood in complex real-world applications, such as in medical imaging where\nmisdiagnosis can be very costly. In this paper, we explore the impact of\nbackdoor attacks on a multi-label disease classification task using chest\nradiography, with the assumption that the attacker can manipulate the training\ndataset to execute the attack. Extensive evaluation of a state-of-the-art\narchitecture demonstrates that by introducing images with few-pixel\nperturbations into the training set, an attacker can execute the backdoor\nsuccessfully without having to be involved with the training procedure. A\nsimple 3$\\times$3 pixel trigger can achieve up to 1.00 Area Under the Receiver\nOperating Characteristic (AUROC) curve on the set of infected images. In the\nset of clean images, the backdoored neural network could still achieve up to\n0.85 AUROC, highlighting the stealthiness of the attack. As the use of deep\nlearning based diagnostic systems proliferates in clinical practice, we also\nshow how explainability is indispensable in this context, as it can identify\nspatially localized backdoors in inference time.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 09:41:19 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Nwadike", "Munachiso", ""], ["Miyawaki", "Takumi", ""], ["Sarkar", "Esha", ""], ["Maniatakos", "Michail", ""], ["Shamout", "Farah", ""]]}, {"id": "2101.00084", "submitter": "Denis Kolegov", "authors": "Denis Kolegov, Yulia Khalniyazova, Denis Varlakov", "title": "Towards Threshold Key Exchange Protocols", "comments": "10 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Threshold schemes exist for many cryptographic primitives like signatures,\nkey derivation functions, and ciphers. At the same time, practical key exchange\nprotocols based on Diffie-Hellman (DH) or ECDSA primitives are not designed or\nimplemented in a threshold setting. In this paper, we implement popular key\nexchange protocols in a threshold manner and show that this approach can be\nused in practice. First, we introduce two basic threshold DH key agreement\nschemes that provide enhanced security features in comparison with the classic\nDH primitive: dealerless distributed key generation, threshold shared key\ncomputation, and private key shares refreshing. We implemented the proposed DH\nschemes within WireGuard protocol to demonstrate its effectiveness, efficiency,\nand usability in practice. The open question is the security of the proposed\nschemes and their instantiation from the elliptic curves used in key agreement\nprotocols: NIST curves, Russian GOST curves, and Curve25519. Second, we propose\nan idea of implementing TLS in a threshold setting that can be used instead of\nKeyless SSL/TLS technology, and provide the measurements of TLS key exchanges\nbased on threshold ECDSA. Even if we don't provide any formal definitions,\nsecurity analysis, and mathematical proofs, we believe that the ideas and\nmechanisms suggested in this paper can be interesting and useful. The main\nintention of the paper is to start discussions and raise awareness of the\nchallenges and problems arising when moving to threshold key exchange\nprotocols.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2020 07:56:26 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Kolegov", "Denis", ""], ["Khalniyazova", "Yulia", ""], ["Varlakov", "Denis", ""]]}, {"id": "2101.00157", "submitter": "Jing Lin", "authors": "Jing Lin, Ryan Luley, and Kaiqi Xiong", "title": "Active Learning Under Malicious Mislabeling and Poisoning Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep neural networks usually require large labeled datasets for training to\nachieve the start-of-the-art performance in many tasks, such as image\nclassification and natural language processing. Though a lot of data is created\neach day by active Internet users through various distributed systems across\nthe world, most of these data are unlabeled and are vulnerable to data\npoisoning attacks. In this paper, we develop an efficient active learning\nmethod that requires fewer labeled instances and incorporates the technique of\nadversarial retraining in which additional labeled artificial data are\ngenerated without increasing the labeling budget. The generated adversarial\nexamples also provide a way to measure the vulnerability of the model. To check\nthe performance of the proposed method under an adversarial setting, i.e.,\nmalicious mislabeling and data poisoning attacks, we perform an extensive\nevaluation on the reduced CIFAR-10 dataset, which contains only two classes:\n'airplane' and 'frog' by using the private cloud on campus. Our experimental\nresults demonstrate that the proposed active learning method is efficient for\ndefending against malicious mislabeling and data poisoning attacks.\nSpecifically, whereas the baseline active learning method based on the random\nsampling strategy performs poorly (about 50%) under a malicious mislabeling\nattack, the proposed active learning method can achieve the desired accuracy of\n89% using only one-third of the dataset on average.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2021 03:43:36 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 01:07:29 GMT"}, {"version": "v3", "created": "Sun, 16 May 2021 20:06:13 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Lin", "Jing", ""], ["Luley", "Ryan", ""], ["Xiong", "Kaiqi", ""]]}, {"id": "2101.00292", "submitter": "Hossein Pirayesh", "authors": "Hossein Pirayesh and Huacheng Zeng", "title": "Jamming Attacks and Anti-Jamming Strategies in Wireless Networks: A\n  Comprehensive Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless networks are a key component of the telecommunications\ninfrastructure in our society, and wireless services become increasingly\nimportant as the applications of wireless devices have penetrated every aspect\nof our lives. Although wireless technologies have significantly advanced in the\npast decades, most wireless networks are still vulnerable to radio jamming\nattacks due to the openness nature of wireless channels, and the progress in\nthe design of jamming-resistant wireless networking systems remains limited.\nThis stagnation can be attributed to the lack of practical physical-layer\nwireless technologies that can efficiently decode data packets in the presence\nof jamming attacks. This article surveys existing jamming attacks and\nanti-jamming strategies in wireless local area networks (WLANs), cellular\nnetworks, cognitive radio networks (CRNs), ZigBee networks, Bluetooth networks,\nvehicular networks, LoRa networks, RFID networks, and GPS system, with the\nobjective of offering a comprehensive knowledge landscape of existing\njamming/anti-jamming strategies and stimulating more research efforts to secure\nwireless networks against jamming attacks. Different from prior survey papers,\nthis article conducts a comprehensive, in-depth review on jamming and\nanti-jamming strategies, casting insights on the design of jamming-resilient\nwireless networking systems. An outlook on promising antijamming techniques is\noffered at the end of this article to delineate important research directions.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2021 18:46:44 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Pirayesh", "Hossein", ""], ["Zeng", "Huacheng", ""]]}, {"id": "2101.00310", "submitter": "Fang Liu", "authors": "Fang Liu and Dong Wang and Zhengquan Xu", "title": "Privacy-preserving Travel Time Prediction with Uncertainty Using GPS\n  Trace Data", "comments": null, "journal-ref": "IEEE Transactions on Mobile Computing, 2021", "doi": "10.1109/TMC.2021.3074865", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth of GPS technology and mobile devices has led to a massive\naccumulation of location data, bringing considerable benefits to individuals\nand society. One of the major usages of such data is travel time prediction, a\ntypical service provided by GPS navigation devices and apps. Meanwhile, the\nconstant collection and analysis of the individual location data also pose\nunprecedented privacy threats. We leverage the notion of\ngeo-indistinguishability, an extension of differential privacy to the location\nprivacy setting, and propose a procedure for privacy-preserving travel time\nprediction without collecting actual individual GPS trace data. We propose new\nconcepts to examine the impact of geo-indistinguishability-based sanitization\non the usefulness of GPS traces and provide analytical and experimental utility\nanalysis for privacy-preserving travel time prediction. We also propose new\nmetrics to measure the adversary error in learning individual GPS traces from\nthe collected sanitized data. Our experiment results suggest that the proposed\nprocedure provides travel time prediction with satisfactory accuracy at\nreasonably small privacy costs.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2021 20:08:23 GMT"}, {"version": "v2", "created": "Fri, 7 May 2021 05:36:06 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Liu", "Fang", ""], ["Wang", "Dong", ""], ["Xu", "Zhengquan", ""]]}, {"id": "2101.00311", "submitter": "Fang Liu", "authors": "Fang Liu and Xingyuan Zhao", "title": "Disclosure Risk from Homogeneity Attack in Differentially Private\n  Frequency Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy (DP) provides a robust model to achieve privacy\nguarantees for released information. We examine the protection potency of\nsanitized multi-dimensional frequency distributions via DP randomization\nmechanisms against homogeneity attack (HA). HA allows adversaries to obtain the\nexact values on sensitive attributes for their targets without having to\nidentify them from the released data. We propose measures for disclosure risk\nfrom HA and derive closed-form relationships between the privacy loss\nparameters in DP and the disclosure risk from HA. The availability of the\nclosed-form relationships assists understanding the abstract concepts of DP and\nprivacy loss parameters by putting them in the context of a concrete privacy\nattack and offers a perspective for choosing privacy loss parameters when\nemploying DP mechanisms in information sanitization and release in practice. We\napply the closed-form mathematical relationships in real-life datasets to\ndemonstrate the assessment of disclosure risk due to HA on differentially\nprivate sanitized frequency distributions at various privacy loss parameters.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2021 20:10:25 GMT"}, {"version": "v2", "created": "Sun, 14 Feb 2021 08:12:50 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 04:35:13 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Liu", "Fang", ""], ["Zhao", "Xingyuan", ""]]}, {"id": "2101.00328", "submitter": "Mitziu Echeverria", "authors": "Mitziu Echeverria, Zeeshan Ahmed, Bincheng Wang, M. Fareed Arif, Syed\n  Rafiul Hussain, Omar Chowdhury", "title": "PHOENIX: Device-Centric Cellular Network Protocol Monitoring using\n  Runtime Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-user-devices in the current cellular ecosystem are prone to many\ndifferent vulnerabilities across different generations and protocol layers.\nFixing these vulnerabilities retrospectively can be expensive, challenging, or\njust infeasible. A pragmatic approach for dealing with such a diverse set of\nvulnerabilities would be to identify attack attempts at runtime on the device\nside, and thwart them with mitigating and corrective actions. Towards this\ngoal, in the paper we propose a general and extendable approach called Phoenix\nfor identifying n-day cellular network control-plane vulnerabilities as well as\ndangerous practices of network operators from the device vantage point. Phoenix\nmonitors the device-side cellular network traffic for performing\nsignature-based unexpected behavior detection through lightweight runtime\nverification techniques. Signatures in Phoenix can be manually-crafted by a\ncellular network security expert or can be automatically synthesized using an\noptional component of Phoenix, which reduces the signature synthesis problem to\nthe language learning from the informant problem. Based on the corrective\nactions that are available to Phoenix when an undesired behavior is detected,\ndifferent instantiations of Phoenix are possible: a full-fledged defense when\ndeployed inside a baseband processor; a user warning system when deployed as a\nmobile application; a probe for identifying attacks in the wild. One such\ninstantiation of Phoenix was able to identify all 15 representative n-day\nvulnerabilities and unsafe practices of 4G LTE networks considered in our\nevaluation with a high packet processing speed (~68000 packets/second) while\ninducing only a moderate amount of energy overhead (~4mW).\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2021 22:38:54 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Echeverria", "Mitziu", ""], ["Ahmed", "Zeeshan", ""], ["Wang", "Bincheng", ""], ["Arif", "M. Fareed", ""], ["Hussain", "Syed Rafiul", ""], ["Chowdhury", "Omar", ""]]}, {"id": "2101.00330", "submitter": "Muhammad Saad", "authors": "Muhammad Saad, Zhan Qin, Kui Ren, DaeHun Nyang, David Mohaisen", "title": "e-PoS: Making Proof-of-Stake Decentralized and Fair", "comments": null, "journal-ref": "IEEE Transactions on Parallel and Distributed Systems, 2021", "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain applications that rely on the Proof-of-Work (PoW) have\nincreasingly become energy inefficient with a staggering carbon footprint. In\ncontrast, energy-efficient alternative consensus protocols such as\nProof-of-Stake (PoS) may cause centralization and unfairness in the blockchain\nsystem. To address these challenges, we propose a modular version of PoS-based\nblockchain systems called epos that resists the centralization of network\nresources by extending mining opportunities to a wider set of stakeholders.\nMoreover, epos leverages the in-built system operations to promote fair mining\npractices by penalizing malicious entities. We validate epos's achievable\nobjectives through theoretical analysis and simulations. Our results show that\nepos ensures fairness and decentralization, and can be applied to existing\nblockchain applications.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2021 22:43:27 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Saad", "Muhammad", ""], ["Qin", "Zhan", ""], ["Ren", "Kui", ""], ["Nyang", "DaeHun", ""], ["Mohaisen", "David", ""]]}, {"id": "2101.00378", "submitter": "Wang Taotao", "authors": "Lihao Zhang, Taotao Wang, and Soung Chang Liew", "title": "Speeding up Block Propagation in Blockchain Network: Uncoded and Coded\n  Designs", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design and validate new block propagation protocols for the peer-to-peer\n(P2P) network of the Bitcoin blockchain. Despite its strong protection for\nsecurity and privacy, the current Bitcoin blockchain can only support a low\nnumber of transactions per second (TPS). In this work, we redesign the current\nBitcoin's networking protocol to increase TPS without changing vital components\nin its consensus-building protocol. In particular, we improve the compact-block\nrelaying protocol to enable the propagation of blocks containing a massive\nnumber of transactions without inducing extra propagation latencies. Our\nimprovements consist of (i) replacing the existing store-and-forward\ncompact-block relaying scheme with a cut-through compact-block relaying scheme;\n(ii) exploiting rateless erasure codes for P2P networks to increase\nblock-propagation efficiency. Since our protocols only need to rework the\ncurrent Bitcoin's networking protocol and does not modify the data structures\nand crypto-functional components, they can be seamlessly incorporated into the\nexisting Bitcoin blockchain. To validate our designs, we perform analysis on\nour protocols and implement a Bitcoin network simulator on NS3 to run different\nblock propagation protocols. The analysis and experimental results confirm that\nour new block propagation protocols could increase the TPS of the Bitcoin\nblockchain by 100x without compromising security and consensus-building.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jan 2021 05:43:59 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Zhang", "Lihao", ""], ["Wang", "Taotao", ""], ["Liew", "Soung Chang", ""]]}, {"id": "2101.00521", "submitter": "Ibrahim Yilmaz", "authors": "Ibrahim Yilmaz, Ambareen Siraj, Denis Ulybyshev", "title": "Improving DGA-Based Malicious Domain Classifiers for Malware Defense\n  with Adversarial Machine Learning", "comments": "10 pages, 6 figures , 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain Generation Algorithms (DGAs) are used by adversaries to establish\nCommand and Control (C\\&C) server communications during cyber attacks.\nBlacklists of known/identified C\\&C domains are often used as one of the\ndefense mechanisms. However, since blacklists are static and generated by\nsignature-based approaches, they can neither keep up nor detect\nnever-seen-before malicious domain names. Due to this shortcoming of blacklist\ndomain checking, machine learning algorithms have been used to address the\nproblem to some extent. However, when training is performed with limited\ndatasets, the algorithms are likely to fail in detecting new DGA variants. To\nmitigate this weakness, we successfully applied a DGA-based malicious domain\nclassifier using the Long Short-Term Memory (LSTM) method with a novel feature\nengineering technique. Our model's performance shows a higher level of accuracy\ncompared to a previously reported model from prior research. Additionally, we\npropose a new method using adversarial machine learning to generate\nnever-before-seen malware-related domain families that can be used to\nillustrate the shortcomings of machine learning algorithms in this regard.\nNext, we augment the training dataset with new samples such that it makes\ntraining of the machine learning models more effective in detecting\nnever-before-seen malicious domain name variants. Finally, to protect\nblacklists of malicious domain names from disclosure and tampering, we devise\nsecure data containers that store blacklists and guarantee their protection\nagainst adversarial access and modifications.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jan 2021 22:04:22 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Yilmaz", "Ibrahim", ""], ["Siraj", "Ambareen", ""], ["Ulybyshev", "Denis", ""]]}, {"id": "2101.00522", "submitter": "Mohammad Rostami", "authors": "Serban Stan, Mohammad Rostami", "title": "Privacy Preserving Domain Adaptation for Semantic Segmentation of\n  Medical Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Convolutional neural networks (CNNs) have led to significant improvements in\ntasks involving semantic segmentation of images. CNNs are vulnerable in the\narea of biomedical image segmentation because of distributional gap between two\nsource and target domains with different data modalities which leads to domain\nshift. Domain shift makes data annotations in new modalities necessary because\nmodels must be retrained from scratch. Unsupervised domain adaptation (UDA) is\nproposed to adapt a model to new modalities using solely unlabeled target\ndomain data. Common UDA algorithms require access to data points in the source\ndomain which may not be feasible in medical imaging due to privacy concerns. In\nthis work, we develop an algorithm for UDA in a privacy-constrained setting,\nwhere the source domain data is inaccessible. Our idea is based on encoding the\ninformation from the source samples into a prototypical distribution that is\nused as an intermediate distribution for aligning the target domain\ndistribution with the source domain distribution. We demonstrate the\neffectiveness of our algorithm by comparing it to state-of-the-art medical\nimage semantic segmentation approaches on two medical image semantic\nsegmentation datasets.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jan 2021 22:12:42 GMT"}, {"version": "v2", "created": "Sun, 11 Jul 2021 02:58:49 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Stan", "Serban", ""], ["Rostami", "Mohammad", ""]]}, {"id": "2101.00606", "submitter": "Jizhe Zhou", "authors": "Jizhe Zhou, Chi-Man Pun, Yu Tong", "title": "News Image Steganography: A Novel Architecture Facilitates the Fake News\n  Identification", "comments": null, "journal-ref": null, "doi": "10.1109/VCIP49819.2020.9301846", "report-no": null, "categories": "cs.CV cs.CR cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A larger portion of fake news quotes untampered images from other sources\nwith ulterior motives rather than conducting image forgery. Such elaborate\nengraftments keep the inconsistency between images and text reports stealthy,\nthereby, palm off the spurious for the genuine. This paper proposes an\narchitecture named News Image Steganography (NIS) to reveal the aforementioned\ninconsistency through image steganography based on GAN. Extractive\nsummarization about a news image is generated based on its source texts, and a\nlearned steganographic algorithm encodes and decodes the summarization of the\nimage in a manner that approaches perceptual invisibility. Once an encoded\nimage is quoted, its source summarization can be decoded and further presented\nas the ground truth to verify the quoting news. The pairwise encoder and\ndecoder endow images of the capability to carry along their imperceptible\nsummarization. Our NIS reveals the underlying inconsistency, thereby, according\nto our experiments and investigations, contributes to the identification\naccuracy of fake news that engrafts untampered images.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2021 11:12:23 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Zhou", "Jizhe", ""], ["Pun", "Chi-Man", ""], ["Tong", "Yu", ""]]}, {"id": "2101.00612", "submitter": "Yiru Zhao", "authors": "Yiru Zhao, Ruiheng Shi, Lei Zhao and Yueqiang Cheng", "title": "AlphaFuzz: Evolutionary Mutation-based Fuzzing as Monte Carlo Tree\n  Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzing is becoming more and more popular in the field of vulnerability\ndetection. In the process of fuzzing, seed selection strategy plays an\nimportant role in guiding the evolution direction of fuzzing. However, the SOTA\nfuzzers only focus on individual uncertainty, neglecting the multi-factor\nuncertainty caused by both randomization and evolution. In this paper, we\nconsider seed selection in fuzzing as a large-scale online planning problem\nunder uncertainty. We propose \\mytool which is a new intelligent seed selection\nstrategy. In Alpha-Fuzz, we leverage the MCTS algorithm to deal with the\neffects of the uncertainty of randomization and evolution of fuzzing.\nEspecially, we analyze the role of the evolutionary relationship between seeds\nin the process of fuzzing, and propose a new tree policy and a new default\npolicy to make the MCTS algorithm better adapt to the fuzzing. We compared\n\\mytool with four state-of-the-art fuzzers in 12 real-world applications and\nLAVA-M data set. The experimental results show that \\mytool could find more\nbugs on lava-M and outperforms other tools in terms of code coverage and number\nof bugs discovered in the real-world applications. In addition, we tested the\ncompatibility of \\mytool, and the results showed that \\mytool could improve the\nperformance of existing tools such as MOPT and QSYM.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2021 12:07:19 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Zhao", "Yiru", ""], ["Shi", "Ruiheng", ""], ["Zhao", "Lei", ""], ["Cheng", "Yueqiang", ""]]}, {"id": "2101.00676", "submitter": "Muhammad Usama", "authors": "Bilal Yousaf, Muhammad Usama, Waqas Sultani, Arif Mahmood, Junaid\n  Qadir", "title": "Fake Visual Content Detection Using Two-Stream Convolutional Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Rapid progress in adversarial learning has enabled the generation of\nrealistic-looking fake visual content. To distinguish between fake and real\nvisual content, several detection techniques have been proposed. The\nperformance of most of these techniques however drops off significantly if the\ntest and the training data are sampled from different distributions. This\nmotivates efforts towards improving the generalization of fake detectors. Since\ncurrent fake content generation techniques do not accurately model the\nfrequency spectrum of the natural images, we observe that the frequency\nspectrum of the fake visual data contains discriminative characteristics that\ncan be used to detect fake content. We also observe that the information\ncaptured in the frequency spectrum is different from that of the spatial\ndomain. Using these insights, we propose to complement frequency and spatial\ndomain features using a two-stream convolutional neural network architecture\ncalled TwoStreamNet. We demonstrate the improved generalization of the proposed\ntwo-stream network to several unseen generation architectures, datasets, and\ntechniques. The proposed detector has demonstrated significant performance\nimprovement compared to the current state-of-the-art fake content detectors and\nfusing the frequency and spatial domain streams has also improved\ngeneralization of the detector.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2021 18:05:07 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Yousaf", "Bilal", ""], ["Usama", "Muhammad", ""], ["Sultani", "Waqas", ""], ["Mahmood", "Arif", ""], ["Qadir", "Junaid", ""]]}, {"id": "2101.00845", "submitter": "Daniel Menasche", "authors": "Felipe Ribas Coutinho and Victor Pires and Claudio Miceli and Daniel\n  Sadoc Menasche", "title": "Crypto-Hotwire: Illegal Blockchain Mining at Zero Cost Using Public\n  Infrastructures", "comments": null, "journal-ref": "Symposium on Cryptocurrency Analysis (SOCCA) 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blockchains and cryptocurrencies disrupted the conversion of energy into a\nmedium of exchange. Numerous applications for blockchains and cryptocurrencies\nare now envisioned for purposes ranging from inventory control to banking\napplications. Naturally, in order to mine in an economically viable way,\nregions where energy is plentiful and cheap, e.g., close to hydroelectric\nplants, are sought. The possibility of converting energy into cash, however,\nalso opens up opportunities for a new kind of cyber attack aimed at illegally\nmining cryptocurrencies by stealing energy. In this work, we indicate, using\ndata from January and February of 2018 from our university, that such a threat\nis real, and present a projection of the gains derived from these attacks.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 09:34:51 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Coutinho", "Felipe Ribas", ""], ["Pires", "Victor", ""], ["Miceli", "Claudio", ""], ["Menasche", "Daniel Sadoc", ""]]}, {"id": "2101.00848", "submitter": "Wei Wang Dr.", "authors": "Yong Huang, Xiang Li, Wei Wang, Tao Jiang, Qian Zhang", "title": "Towards Cross-Modal Forgery Detection and Localization on Live\n  Surveillance Videos", "comments": "Accepted by IEEE International Conference on Computer Communications\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The cybersecurity breaches render surveillance systems vulnerable to video\nforgery attacks, under which authentic live video streams are tampered to\nconceal illegal human activities under surveillance cameras. Traditional video\nforensics approaches can detect and localize forgery traces in each video frame\nusing computationally-expensive spatial-temporal analysis, while falling short\nin real-time verification of live video feeds. The recent work correlates\ntime-series camera and wireless signals to recognize replayed surveillance\nvideos using event-level timing information but it cannot realize fine-grained\nforgery detection and localization on each frame. To fill this gap, this paper\nproposes Secure-Pose, a novel cross-modal forgery detection and localization\nsystem for live surveillance videos using WiFi signals near the camera spot. We\nobserve that coexisting camera and WiFi signals convey common human semantic\ninformation and the presence of forgery attacks on video frames will decouple\nsuch information correspondence. Secure-Pose extracts effective human pose\nfeatures from synchronized multi-modal signals and detects and localizes\nforgery traces under both inter-frame and intra-frame attacks in each frame. We\nimplement Secure-Pose using a commercial camera and two Intel 5300 NICs and\nevaluate it in real-world environments. Secure-Pose achieves a high detection\naccuracy of 95.1% and can effectively localize tampered objects under different\nforgery attacks.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 09:39:19 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 13:41:26 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Huang", "Yong", ""], ["Li", "Xiang", ""], ["Wang", "Wei", ""], ["Jiang", "Tao", ""], ["Zhang", "Qian", ""]]}, {"id": "2101.00851", "submitter": "Daniel Menasche", "authors": "Jefferson E. Simoes and Eduardo Ferreira and Daniel S. Menasche and\n  Carlos A. V. Campos", "title": "Blockchain Privacy Through Merge Avoidance and Mixing Services: a\n  Hardness and an Impossibility Result", "comments": null, "journal-ref": "Symposium on Cryptocurrency Analysis (SOCCA) 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cryptocurrencies typically aim at preserving the privacy of their users.\nDifferent cryptocurrencies preserve privacy at various levels, some of them\nrequiring users to rely on strategies to raise the privacy level to their\nneeds. Among those strategies, we focus on two of them: merge avoidance and\nmixing services. Such strategies may be adopted on top of virtually any\nblockchain-based cryptocurrency. In this paper, we show that whereas optimal\nmerge avoidance leads to an NP-hard optimization problem, incentive-compatible\nmixing services are subject to a certain class of impossibility results.\nTogether, our results contribute to the body of work on fundamental limits of\nprivacy mechanisms in blockchain-based cryptocurrencies.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 09:45:35 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Simoes", "Jefferson E.", ""], ["Ferreira", "Eduardo", ""], ["Menasche", "Daniel S.", ""], ["Campos", "Carlos A. V.", ""]]}, {"id": "2101.00897", "submitter": "Mohammad AL-Mousa Dr", "authors": "Sana Haimour, Mohammad Rasmi AL-Mousa, Rashiq R. Marie", "title": "Using Chaotic Stream Cipher to Enhance Data Hiding in Digital Images", "comments": "7 pages", "journal-ref": "International Journal of Advanced Trends in Computer Science and\n  Engineering, 2020", "doi": "10.30534/ijatcse/2020/153942020", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The growing potential of modern communications needs the use of secure means\nto protect information from unauthorized access and use during transmission. In\ngeneral, encryption a message using cryptography techniques and then hidden a\nmessage with a steganography methods provides an additional layer of\nprotection. Furthermore, using these combination reduces the chance of finding\nthe hidden message. This paper proposed a system which combines schemes of\ncryptography with steganography for hiding secret messages and to add more\ncomplexity for steganography. The proposed system secret message encoded with\nchaotic stream cipher and afterwards the encoded data is hidden behind an RGB\nor Gray cover image by modifying the kth least significant bits (k-LSB) of\ncover image pixels. The resultant stego-image less distorters. After which can\nbe used by the recipient to extract that bit-plane of the image. In fact, the\nschemes of encryption/decryption and embedding/ extracting in the proposed\nsystem depends upon two shred secret keys between the sender and the receiver.\nAn experiment shows that using an unauthorized secret keys between the sender\nand the receiver have totally different messages from the original ones which\nimprove the confidentiality of the images.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 11:28:23 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Haimour", "Sana", ""], ["AL-Mousa", "Mohammad Rasmi", ""], ["Marie", "Rashiq R.", ""]]}, {"id": "2101.00919", "submitter": "Benjamin Smith", "authors": "Enric Florit (UB), Benjamin Smith (GRACE)", "title": "Automorphisms and isogeny graphs of abelian varieties, with applications\n  to the superspecial Richelot isogeny graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate special structures due to automorphisms in isogeny graphs of\nprincipally polarized abelian varieties, and abelian surfaces in particular. We\ngive theoretical and experimental results on the spectral and statistical\nproperties of (2, 2)-isogeny graphs of superspecial abelian surfaces, including\nstationary distributions for random walks, bounds on eigenvalues and diameters,\nand a proof of the connectivity of the Jacobian subgraph of the (2, 2)-isogeny\ngraph. Our results improve our understanding of the performance and security of\nsome recently-proposed cryptosystems, and are also a concrete step towards a\nbetter understanding of general superspecial isogeny graphs in arbitrary\ndimension.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 12:27:32 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 11:42:20 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Florit", "Enric", "", "UB"], ["Smith", "Benjamin", "", "GRACE"]]}, {"id": "2101.00961", "submitter": "Justin Hsu", "authors": "Subhajit Roy, Justin Hsu, Aws Albarghouthi", "title": "Learning Differentially Private Mechanisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy is a formal, mathematical definition of data privacy\nthat has gained traction in academia, industry, and government. The task of\ncorrectly constructing differentially private algorithms is non-trivial, and\nmistakes have been made in foundational algorithms. Currently, there is no\nautomated support for converting an existing, non-private program into a\ndifferentially private version. In this paper, we propose a technique for\nautomatically learning an accurate and differentially private version of a\ngiven non-private program. We show how to solve this difficult program\nsynthesis problem via a combination of techniques: carefully picking\nrepresentative example inputs, reducing the problem to continuous optimization,\nand mapping the results back to symbolic expressions. We demonstrate that our\napproach is able to learn foundational algorithms from the differential privacy\nliterature and significantly outperforms natural program synthesis baselines.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 13:33:57 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Roy", "Subhajit", ""], ["Hsu", "Justin", ""], ["Albarghouthi", "Aws", ""]]}, {"id": "2101.00973", "submitter": "Adil Karjauv", "authors": "Chaoning Zhang, Adil Karjauv, Philipp Benz, In So Kweon", "title": "Towards Robust Data Hiding Against (JPEG) Compression: A\n  Pseudo-Differentiable Deep Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CR cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data hiding is one widely used approach for protecting authentication and\nownership. Most multimedia content like images and videos are transmitted or\nsaved in the compressed form. This kind of lossy compression, such as JPEG, can\ndestroy the hidden data, which raises the need of robust data hiding. It is\nstill an open challenge to achieve the goal of data hiding that can be against\nthese compressions. Recently, deep learning has shown large success in data\nhiding, while non-differentiability of JPEG makes it challenging to train a\ndeep pipeline for improving robustness against lossy compression. The existing\nSOTA approaches replace the non-differentiable parts with differentiable\nmodules that perform similar operations. Multiple limitations exist: (a) large\nengineering effort; (b) requiring a white-box knowledge of compression attacks;\n(c) only works for simple compression like JPEG. In this work, we propose a\nsimple yet effective approach to address all the above limitations at once.\nBeyond JPEG, our approach has been shown to improve robustness against various\nimage and video lossy compression algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 12:30:09 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Zhang", "Chaoning", ""], ["Karjauv", "Adil", ""], ["Benz", "Philipp", ""], ["Kweon", "In So", ""]]}, {"id": "2101.01015", "submitter": "Anandharaju Durai Raju", "authors": "Anandharaju Durai Raju, Ke Wang", "title": "Echelon: Two-Tier Malware Detection for Raw Executables to Reduce False\n  Alarms", "comments": "12 pages, 8 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing malware detection approaches suffer from a simplistic trade-off\nbetween false positive rate (FPR) and true positive rate (TPR) due to a single\ntier classification approach, where the two measures adversely affect one\nanother. The practical implication for malware detection is that FPR must be\nkept at an acceptably low level while TPR remains high. To this end, we propose\na two-tiered learning, called ``Echelon\", from raw byte data with no need for\nhand-crafted features. The first tier locks FPR at a specified target level,\nwhereas the second tier improves TPR while maintaining the locked FPR. The core\nof Echelon lies at extracting activation information of the hidden layers of\nfirst tier model for constructing a stronger second tier model. Echelon is a\nframework in that it allows any existing CNN based model to be adapted in both\ntiers. We present experimental results of evaluating Echelon by adapting the\nstate-of-the-art malware detection model ``Malconv\" in the first and second\ntiers.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 14:54:20 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Raju", "Anandharaju Durai", ""], ["Wang", "Ke", ""]]}, {"id": "2101.01032", "submitter": "Tao Xiang", "authors": "Tao Xiang, Hangcheng Liu, Shangwei Guo, Tianwei Zhang, Xiaofeng Liao", "title": "Local Black-box Adversarial Attacks: A Query Efficient Approach", "comments": "This work has been submitted to the IEEE for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Adversarial attacks have threatened the application of deep neural networks\nin security-sensitive scenarios. Most existing black-box attacks fool the\ntarget model by interacting with it many times and producing global\nperturbations. However, global perturbations change the smooth and\ninsignificant background, which not only makes the perturbation more easily be\nperceived but also increases the query overhead. In this paper, we propose a\nnovel framework to perturb the discriminative areas of clean examples only\nwithin limited queries in black-box attacks. Our framework is constructed based\non two types of transferability. The first one is the transferability of model\ninterpretations. Based on this property, we identify the discriminative areas\nof a given clean example easily for local perturbations. The second is the\ntransferability of adversarial examples. It helps us to produce a local\npre-perturbation for improving query efficiency. After identifying the\ndiscriminative areas and pre-perturbing, we generate the final adversarial\nexamples from the pre-perturbed example by querying the targeted model with two\nkinds of black-box attack techniques, i.e., gradient estimation and random\nsearch. We conduct extensive experiments to show that our framework can\nsignificantly improve the query efficiency during black-box perturbing with a\nhigh attack success rate. Experimental results show that our attacks outperform\nstate-of-the-art black-box attacks under various system settings.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 15:32:16 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Xiang", "Tao", ""], ["Liu", "Hangcheng", ""], ["Guo", "Shangwei", ""], ["Zhang", "Tianwei", ""], ["Liao", "Xiaofeng", ""]]}, {"id": "2101.01077", "submitter": "Billy Bob Brumley", "authors": "Alejandro Cabrera Aldaya, Billy Bob Brumley", "title": "HyperDegrade: From GHz to MHz Effective CPU Frequencies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Performance degradation techniques are an important complement to\nside-channel attacks. In this work, we propose HyperDegrade -- a combination of\nprevious approaches and the use of simultaneous multithreading (SMT)\narchitectures. In addition to the new technique, we investigate the root causes\nof performance degradation using cache eviction, discovering a previously\nunknown slowdown origin. The slowdown produced is significantly higher than\nprevious approaches, which translates into an increased time granularity for\nFlush+Reload attacks. We evaluate HyperDegrade on different Intel\nmicroarchitectures, yielding significant slowdowns that achieve, in some cases,\nthree orders of magnitude improvement over state-of-the-art. To evaluate the\nefficacy of performance degradation in side-channel amplification, we propose\nand evaluate leakage assessment metrics. The results evidence that HyperDegrade\nincreases time granularity without a meaningful impact on trace quality.\nAdditionally, we designed a fair experiment that compares three performance\ndegradation strategies when coupled with Flush+Reload from a practical\nperspective. We developed an attack on an unexploited vulnerability in OpenSSL\nin which HyperDegrade excels -- reducing by three times the number of required\nFlush+Reload traces to succeed. Regarding cryptography contributions, we\nrevisit the recently proposed Raccoon attack on TLS-DH key exchanges,\ndemonstrating its application to other protocols beyond legacy TLS cipher\nsuites. Using HyperDegrade we developed an end-to-end attack that shows how a\nRaccoon-like attack can succeed in practice, filling a missing gap from\nprevious research.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 16:36:09 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Aldaya", "Alejandro Cabrera", ""], ["Brumley", "Billy Bob", ""]]}, {"id": "2101.01269", "submitter": "Brian LaMacchia", "authors": "Matt Campagna, Brian LaMacchia, and David Ott", "title": "Post Quantum Cryptography: Readiness Challenges and the Approaching\n  Storm", "comments": "A Computing Community Consortium (CCC) white paper, 5 pages", "journal-ref": null, "doi": null, "report-no": "ccc2020whitepaper_14", "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While advances in quantum computing promise new opportunities for scientific\nadvancement (e.g., material science and machine learning), many people are not\naware that they also threaten the widely deployed cryptographic algorithms that\nare the foundation of today's digital security and privacy. From mobile\ncommunications to online banking to personal data privacy, literally billions\nof Internet users rely on cryptography every day to ensure that private\ncommunications and data stay private. Indeed, the emergence and growth of the\npublic Internet and electronic commerce was arguably enabled by the invention\nof public-key cryptography. The key advantage offered by public-key\ncryptography is that it allows two parties who have never communicated\npreviously to nevertheless establish a secure, private, communication channel\nover a non-private network (e.g., the Internet).\n  Recent advances in quantum computing signal that we are on the cusp of our\nnext cryptographic algorithm transition, and this transition to post-quantum\ncryptography will be more complicated and impact many more systems and\nstakeholders, than any of the prior migrations. This transition represents a\nmajor disruption within the IT industry and will broadly impact nearly every\ndomain of our digital lives, from global commerce to social media to government\nand more. Cryptographic algorithm transitions take time and involve an\nextensive coordination effort across many stakeholders who are involved in\nbuilding and operating the world's compute infrastructure. By preparing now for\nthe upcoming transition to these new algorithms, we can ensure a more orderly,\nless costly, and minimally disruptive changeover.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 22:55:15 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Campagna", "Matt", ""], ["LaMacchia", "Brian", ""], ["Ott", "David", ""]]}, {"id": "2101.01289", "submitter": "Do Le Quoc", "authors": "Wojciech Ozga and Do Le Quoc and Christof Fetzer", "title": "A practical approach for updating an integrity-enforced operating system", "comments": null, "journal-ref": null, "doi": "10.1145/3423211.3425674", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Trusted computing defines how to securely measure, store, and verify the\nintegrity of software controlling a computer. One of the major challenges that\nmake them hard to be applied in practice is the issue with software updates.\nSpecifically, an operating system update causes the integrity violation because\nit changes the well-known initial state trusted by remote verifiers, such as\nintegrity monitoring systems. Consequently, the integrity monitoring of remote\ncomputers becomes unreliable due to the high amount of false positives. We\naddress this problem by adding an extra level of indirection between the\noperating system and software repositories. We propose a trusted software\nrepository (TSR), a secure proxy that overcomes the shortcomings of previous\napproaches by sanitizing software packages. Sanitization consists of modifying\nunsafe installation scripts and adding digital signatures in a way software\npackages can be installed in the operating system without violating its\nintegrity. TSR leverages shielded execution, i.e., Intel SGX, to achieve\nconfidentiality and integrity guarantees of the sanitization process. TSR is\ntransparent to package managers, and requires no changes in the software\npackages building and distributing processes. Our evaluation shows that running\nTSR inside SGX is practical; since it induces only ~1.18X performance overhead\nduring package sanitization compared to the native execution without SGX. TSR\nsupports 99.76% of packages available in the main and community repositories of\nAlpine Linux while increasing the total repository size by 3.6%.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 00:09:01 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Ozga", "Wojciech", ""], ["Quoc", "Do Le", ""], ["Fetzer", "Christof", ""]]}, {"id": "2101.01306", "submitter": "Yihua Liu", "authors": "Guangquan Xu, Yihua Liu, Jun Xing, Tao Luo, Yonghao Gu, Shaoying Liu,\n  Xi Zheng, Athanasios V. Vasilakos", "title": "SG-PBFT: a Secure and Highly Efficient Blockchain PBFT Consensus\n  Algorithm for Internet of Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Vehicles (IoV) is an application of the Internet of things\n(IoT). It faces two main security problems: (1) the central server of the IoV\nmay not be powerful enough to support the centralized authentication of the\nrapidly increasing connected vehicles, (2) the IoV itself may not be robust\nenough to single-node attacks. To solve these problems, this paper proposes\nSG-PBFT: a secure and highly efficient PBFT consensus algorithm for Internet of\nVehicles, which is based on a distributed blockchain structure. The distributed\nstructure can reduce the pressure on the central server and decrease the risk\nof single-node attacks. The SG-PBFT consensus algorithm improves the\ntraditional PBFT consensus algorithm by using a score grouping mechanism to\nachieve a higher consensus efficiency. The experimental result shows that our\nmethod can greatly improve the consensus efficiency and prevent single-node\nattacks. Specifically, when the number of consensus nodes reaches 1000, the\nconsensus time of our algorithm is only about 27% of what is required for the\nstate-of-the-art consensus algorithm (PBFT). Our proposed SG-PBFT is versatile\nand can be used in other application scenarios which require high consensus\nefficiency.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 01:30:10 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Xu", "Guangquan", ""], ["Liu", "Yihua", ""], ["Xing", "Jun", ""], ["Luo", "Tao", ""], ["Gu", "Yonghao", ""], ["Liu", "Shaoying", ""], ["Zheng", "Xi", ""], ["Vasilakos", "Athanasios V.", ""]]}, {"id": "2101.01341", "submitter": "Bo Hui", "authors": "Bo Hui, Yuchen Yang, Haolin Yuan, Philippe Burlina, Neil Zhenqiang\n  Gong and Yinzhi Cao", "title": "Practical Blind Membership Inference Attack via Differential Comparisons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Membership inference (MI) attacks affect user privacy by inferring whether\ngiven data samples have been used to train a target learning model, e.g., a\ndeep neural network. There are two types of MI attacks in the literature, i.e.,\nthese with and without shadow models. The success of the former heavily depends\non the quality of the shadow model, i.e., the transferability between the\nshadow and the target; the latter, given only blackbox probing access to the\ntarget model, cannot make an effective inference of unknowns, compared with MI\nattacks using shadow models, due to the insufficient number of qualified\nsamples labeled with ground truth membership information.\n  In this paper, we propose an MI attack, called BlindMI, which probes the\ntarget model and extracts membership semantics via a novel approach, called\ndifferential comparison. The high-level idea is that BlindMI first generates a\ndataset with nonmembers via transforming existing samples into new samples, and\nthen differentially moves samples from a target dataset to the generated,\nnon-member set in an iterative manner. If the differential move of a sample\nincreases the set distance, BlindMI considers the sample as non-member and vice\nversa.\n  BlindMI was evaluated by comparing it with state-of-the-art MI attack\nalgorithms. Our evaluation shows that BlindMI improves F1-score by nearly 20%\nwhen compared to state-of-the-art on some datasets, such as Purchase-50 and\nBirds-200, in the blind setting where the adversary does not know the target\nmodel's architecture and the target dataset's ground truth labels. We also show\nthat BlindMI can defeat state-of-the-art defenses.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 04:07:15 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 02:24:04 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Hui", "Bo", ""], ["Yang", "Yuchen", ""], ["Yuan", "Haolin", ""], ["Burlina", "Philippe", ""], ["Gong", "Neil Zhenqiang", ""], ["Cao", "Yinzhi", ""]]}, {"id": "2101.01395", "submitter": "Mohammad AL-Mousa Dr", "authors": "Mohammad Rasmi Al-Mousa", "title": "Analyzing Cyber-Attack Intention for Digital Forensics Using Case-Based\n  Reasoning", "comments": "6 pages", "journal-ref": "International Journal of Advanced Trends in Computer Science and\n  Engineering, 2020", "doi": "10.30534/ijatcse/2019/92862019", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cyber-attacks are increasing and varying dramatically day by day. It has\nbecome challenging to control cyber-attacks and to identify the perpetrators\nand their intentions. In general, the analysis of the intentions of\ncyber-attacks is one of the main challenges in digital forensics. In many cases\nof cyber-attacks, the analysis of the intent of the attacks determines the\nstrategy and tools used in the attack, thus facilitating the process of\nidentifying the perpetrator of the attack with greater accuracy. In this paper\na model will be proposed to analyze the intentions of cyber-attacks. In this\nproposal, a set of steps will be conceived by linking them with a case-based\nreasoning methodology. This model will be examined by analyzing the intent of\nattacks for some cases and comparing the results with other methods of\nanalyzing the intent of attacks. Hopefully the results will determine the\nintent of cyber-attacks more accurately.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 08:00:48 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Al-Mousa", "Mohammad Rasmi", ""]]}, {"id": "2101.01399", "submitter": "Mohammad AL-Mousa Dr", "authors": "Khaled AL-Qawasmi, Mohammad AL-Mousa, Mohammad yousef", "title": "Proposed E-payment Process Model to Enhance Quality of Service through\n  Maintaining the Trust of Availability", "comments": "5 pages", "journal-ref": "International Journal of Emerging Trends in Engineering Research,\n  2020", "doi": "10.30534/ijeter/2020/16862020", "report-no": null, "categories": "cs.CR cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The use of the Internet has become an urgent necessity in various fields and\nactivities. One of such important fields could be electronic business\n(E-Business). E-business includes all operations and activities related to\nInternet commerce, including e-commerce, e-marketing, eservices, e-payment, and\nelectronic transfer. This proposal focuses on two perspectives that are under\ne-commerce umbrella where many e-payment process models suffer from the lack of\nclarity in the special procedures of the verification of the quality of\nservices. This proposal, therefore, proposes a new E-payment process model to\nenhance the quality of service through maintaining availability. The proposed\nmodel focuses on the concepts of electronic payment model dimensions, which\nincludes integrity, non-repudiation, authenticity, confidentiality, privacy,\nand availability. Accordingly, the proposed model implements the availability\ndimension in order to improve the quality of services that are provided to the\nconsumer.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 08:07:39 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["AL-Qawasmi", "Khaled", ""], ["AL-Mousa", "Mohammad", ""], ["yousef", "Mohammad", ""]]}, {"id": "2101.01401", "submitter": "Mohammad AL-Mousa Dr", "authors": "Ahmad Nabot, Firas Omar, Mohammed Almousa", "title": "Perceptions of Smartphone Users Acceptance and Adoption of Mobile\n  Commerce (MC) The Case of Jordan", "comments": "11 pages", "journal-ref": "Journal of Computer Science, 2020", "doi": "10.3844/jcssp.2020.532.542", "report-no": null, "categories": "cs.HC cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study investigates smartphone users perceptions of adopting and\naccepting Mobile Commerce (MC) based on users perceived adoption under the\nextended Technology Acceptance Model (TAM2) and Innovation Diffusion Theory\n(IDT) by providing research constructs for the domain of MC. Also, testing them\nwith reliability and validity and demonstrating their distinctiveness with\nhypothesis testing. The results show that consumer intention to adopt MC on a\nsmartphone was primarily influenced by Uncertainty Avoidance (UA), User\nExperience (UX), Perceived Ease Of Use (PEOU), Perceived Usefulness (PU) and\nCompatibility (CMP) as well as other constructs that positively determine\nattitude toward using a smartphone. For researchers, this study shows the\nbenefits of adapting TAM constructs into MC acceptance on a smartphone. The\nperceptions of MC adoption on a smartphone in this study investigated based on\na survey of specific people. For more reliability, a comprehensive study is\nneeded to show the attitudes of people from different environments.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 08:16:28 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Nabot", "Ahmad", ""], ["Omar", "Firas", ""], ["Almousa", "Mohammed", ""]]}, {"id": "2101.01421", "submitter": "Valdemar \\v{S}v\\'abensk\\'y", "authors": "Valdemar \\v{S}v\\'abensk\\'y, Pavel \\v{C}eleda, Jan Vykopal, Silvia\n  Bri\\v{s}\\'akov\\'a", "title": "Cybersecurity Knowledge and Skills Taught in Capture the Flag Challenges", "comments": "Published in Elsevier Computers & Security, see\n  https://www.sciencedirect.com/science/article/pii/S0167404820304272 (first\n  available online on December 27, 2020). The article has 32 pages (in the\n  preprint template), 9 figures, and 4 tables", "journal-ref": null, "doi": "10.1016/j.cose.2020.102154", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Capture the Flag challenges are a popular form of cybersecurity education,\nwhere students solve hands-on tasks in an informal, game-like setting. The\ntasks feature diverse assignments, such as exploiting websites, cracking\npasswords, and breaching unsecured networks. However, it is unclear how the\nskills practiced by these challenges match formal cybersecurity curricula\ndefined by security experts. We explain the significance of Capture the Flag\nchallenges in cybersecurity training and analyze their 15,963 textual solutions\ncollected since 2012. Based on keywords in the solutions, we map them to\nwell-established ACM/IEEE curricular guidelines to understand which skills the\nchallenges teach. We study the distribution of cybersecurity topics, their\nvariance in different challenge formats, and their development over the past\nyears. The analysis showed the prominence of technical knowledge about\ncryptography and network security, but human aspects, such as social\nengineering and cybersecurity awareness, are neglected. We discuss the\nimplications of these results and relate them to contemporary literature. Our\nresults indicate that future Capture the Flag challenges should include\nnon-technical aspects to address the current advanced cyber threats and attract\na broader audience to cybersecurity.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 09:12:48 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["\u0160v\u00e1bensk\u00fd", "Valdemar", ""], ["\u010celeda", "Pavel", ""], ["Vykopal", "Jan", ""], ["Bri\u0161\u00e1kov\u00e1", "Silvia", ""]]}, {"id": "2101.01450", "submitter": "Sen Zhang", "authors": "Sen Zhang, Weiwei Ni, Nan Fu", "title": "Community Preserved Social Graph Publishing with Node Differential\n  Privacy", "comments": "Accepted by the 2020 IEEE International Conference on Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of privacy-preserving social graph publishing is to protect\nindividual privacy while preserving data utility. Community structure, which is\nan important global pattern of nodes, is a crucial data utility as it serves as\nfundamental operations for many graph analysis tasks. Yet, most existing\nmethods with differential privacy (DP) commonly fall in edge-DP to sacrifice\nsecurity in exchange for utility. Moreover, they reconstruct graphs from the\nlocal feature-extraction of nodes, resulting in poor community preservation.\nMotivated by this, we propose PrivCom, a strict node-DP graph publishing\nalgorithm to maximize the utility on the community structure while maintaining\na higher level of privacy. Specifically, to reduce the huge sensitivity, we\ndevise a Katz index-based private graph feature extraction method, which can\ncapture global graph structure features while greatly reducing the global\nsensitivity via a sensitivity regulation strategy. Yet, with a fixed\nsensitivity, the feature captured by Katz index, which is presented in matrix\nform, requires privacy budget splits. As a result, plenty of noise is injected,\nthereby mitigating global structural utility. To this end, we design a private\nOja algorithm approximating eigen-decomposition, which yields the noisy Katz\nmatrix via privately estimating eigenvectors and eigenvalues from extracted\nlow-dimensional vectors. Experimental results confirm our theoretical findings\nand the efficacy of PrivCom.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 11:01:01 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Zhang", "Sen", ""], ["Ni", "Weiwei", ""], ["Fu", "Nan", ""]]}, {"id": "2101.01495", "submitter": "Marc Chaumont", "authors": "Hugo Ruiz, Mehdi Yedroudj, Marc Chaumont, Fr\\'ed\\'eric Comby, G\\'erard\n  Subsol", "title": "LSSD: a Controlled Large JPEG Image Database for Deep-Learning-based\n  Steganalysis \"into the Wild\"", "comments": "ICPR'2021, International Conference on Pattern Recognition,\n  MMForWILD'2021, Workshop on MultiMedia FORensics in the WILD, Lecture Notes\n  in Computer Science, LNCS, Springer. January 10-15, 2021, Virtual Conference\n  due to Covid (formerly Milan, Italy). Version of December 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For many years, the image databases used in steganalysis have been relatively\nsmall, i.e. about ten thousand images. This limits the diversity of images and\nthus prevents large-scale analysis of steganalysis algorithms.\n  In this paper, we describe a large JPEG database composed of 2 million colour\nand grey-scale images. This database, named LSSD for Large Scale Steganalysis\nDatabase, was obtained thanks to the intensive use of \\enquote{controlled}\ndevelopment procedures. LSSD has been made publicly available, and we aspire it\ncould be used by the steganalysis community for large-scale experiments.\n  We introduce the pipeline used for building various image database versions.\nWe detail the general methodology that can be used to redevelop the entire\ndatabase and increase even more the diversity. We also discuss computational\ncost and storage cost in order to develop images.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 13:14:41 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Ruiz", "Hugo", ""], ["Yedroudj", "Mehdi", ""], ["Chaumont", "Marc", ""], ["Comby", "Fr\u00e9d\u00e9ric", ""], ["Subsol", "G\u00e9rard", ""]]}, {"id": "2101.01536", "submitter": "Arsenia (Ersi) Chorti", "authors": "Arsenia Chorti, Andre Noll Barreto, Stefan Kopsell, Marco Zoli, Marwa\n  Chafii, Philippe Sehier, Gerhard Fettweis, H. Vincent Poor", "title": "Context-Aware Security for 6G Wireless The Role of Physical Layer\n  Security", "comments": "arXiv admin note: text overlap with arXiv:2011.07323", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sixth generation systems are expected to face new security challenges, while\nopening up new frontiers towards context awareness in the wireless edge. The\nworkhorse behind this projected technological leap will be a whole new set of\nsensing capabilities predicted for 6G devices, in addition to the ability to\nachieve high precision localization. The combination of these enhanced traits\ncan give rise to a new breed of context-aware security protocols, following the\nquality of security (QoSec) paradigm. In this framework, physical layer\nsecurity solutions emerge as competitive candidates for low complexity,\nlow-delay and low-footprint, adaptive, flexible and context aware security\nschemes, leveraging the physical layer of the communications in genuinely\ncross-layer protocols, for the first time.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 14:29:39 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Chorti", "Arsenia", ""], ["Barreto", "Andre Noll", ""], ["Kopsell", "Stefan", ""], ["Zoli", "Marco", ""], ["Chafii", "Marwa", ""], ["Sehier", "Philippe", ""], ["Fettweis", "Gerhard", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2101.01856", "submitter": "Stephen MacDonell", "authors": "Awais Tanveer, Roopak Sinha, Stephen G. MacDonell, Paulo Leitao and\n  Valeriy Vyatkin", "title": "Designing Actively Secure, Highly Available Industrial Automation\n  Applications", "comments": "Conference, 7 pages, 9 figures", "journal-ref": "Proceedings of the 17th International Conference on Industrial\n  Informatics (INDIN2019). Helsinki-Espoo, Finland, IEEE Computer Society\n  Press, pp.374-379", "doi": "10.1109/INDIN41052.2019.8972262", "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programmable Logic Controllers (PLCs) execute critical control software that\ndrives Industrial Automation and Control Systems (IACS). PLCs can become easy\ntargets for cyber-adversaries as they are resource-constrained and are usually\nbuilt using legacy, less-capable security measures. Security attacks can\nsignificantly affect system availability, which is an essential requirement for\nIACS. We propose a method to make PLC applications more security-aware. Based\non the well-known IEC 61499 function blocks standard for developing IACS\nsoftware, our method allows designers to annotate critical parts of an\napplication during design time. On deployment, these parts of the application\nare automatically secured using appropriate security mechanisms to detect and\nprevent attacks. We present a summary of availability attacks on distributed\nIACS applications that can be mitigated by our proposed method. Security\nmechanisms are achieved using IEC 61499 Service-Interface Function Blocks\n(SIFBs) embedding Intrusion Detection and Prevention System (IDPS), added to\nthe application at compile time. This method is more amenable to providing\nactive security protection from attacks on previously unknown (zero-day)\nvulnerabilities. We test our solution on an IEC 61499 application executing on\nWago PFC200 PLCs. Experiments show that we can successfully log and prevent\nattacks at the application level as well as help the application to gracefully\ndegrade into safe mode, subsequently improving availability.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 03:46:44 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Tanveer", "Awais", ""], ["Sinha", "Roopak", ""], ["MacDonell", "Stephen G.", ""], ["Leitao", "Paulo", ""], ["Vyatkin", "Valeriy", ""]]}, {"id": "2101.01872", "submitter": "Wenxue Cui", "authors": "Wenxue Cui, Shaohui Liu, Feng Jiang, Yongliang Liu, Debin Zhao", "title": "Multi-Stage Residual Hiding for Image-into-Audio Steganography", "comments": "ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The widespread application of audio communication technologies has speeded up\naudio data flowing across the Internet, which made it a popular carrier for\ncovert communication. In this paper, we present a cross-modal steganography\nmethod for hiding image content into audio carriers while preserving the\nperceptual fidelity of the cover audio. In our framework, two multi-stage\nnetworks are designed: the first network encodes the decreasing multilevel\nresidual errors inside different audio subsequences with the corresponding\nstage sub-networks, while the second network decodes the residual errors from\nthe modified carrier with the corresponding stage sub-networks to produce the\nfinal revealed results. The multi-stage design of proposed framework not only\nmake the controlling of payload capacity more flexible, but also make hiding\neasier because of the gradual sparse characteristic of residual errors.\nQualitative experiments suggest that modifications to the carrier are\nunnoticeable by human listeners and that the decoded images are highly\nintelligible.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 05:01:45 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Cui", "Wenxue", ""], ["Liu", "Shaohui", ""], ["Jiang", "Feng", ""], ["Liu", "Yongliang", ""], ["Zhao", "Debin", ""]]}, {"id": "2101.01898", "submitter": "Mingxi Wu", "authors": "Mingxi Wu, Xi Chen", "title": "Connecting The Dots To Combat Collective Fraud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern fraudsters write malicious programs to coordinate a group of accounts\nto commit collective fraud for illegal profits in online platforms. These\nprograms have access to a set of finite resources - a set of IPs, devices, and\naccounts etc. and sometime manipulate fake accounts to collaboratively attack\nthe target system. Inspired by these observations, we share our experience in\nbuilding two real-time risk control systems to detect collective fraud. We show\nthat with TigerGraph, a powerful graph database, and its innovative query\nlanguage - GSQL, data scientists and fraud experts can conveniently implement\nand deploy an end-to-end risk control system as a graph database application.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 07:28:23 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Wu", "Mingxi", ""], ["Chen", "Xi", ""]]}, {"id": "2101.01917", "submitter": "Tai D. Nguyen", "authors": "Tai D. Nguyen, Long H. Pham, Jun Sun", "title": "sGUARD: Towards Fixing Vulnerable Smart Contracts Automatically", "comments": "Published in IEEE S&P 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Smart contracts are distributed, self-enforcing programs executing on top of\nblockchain networks. They have the potential to revolutionize many industries\nsuch as financial institutes and supply chains. However, smart contracts are\nsubject to code-based vulnerabilities, which casts a shadow on its\napplications. As smart contracts are unpatchable (due to the immutability of\nblockchain), it is essential that smart contracts are guaranteed to be free of\nvulnerabilities. Unfortunately, smart contract languages such as Solidity are\nTuring-complete, which implies that verifying them statically is infeasible.\nThus, alternative approaches must be developed to provide the guarantee. In\nthis work, we develop an approach which automatically transforms smart\ncontracts so that they are provably free of 4 common kinds of vulnerabilities.\nThe key idea is to apply runtime verification in an efficient and provably\ncorrect manner. Experiment results with 5000 smart contracts show that our\napproach incurs minor run-time overhead in terms of time (i.e., 14.79%) and gas\n(i.e., 0.79%).\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 08:26:10 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Nguyen", "Tai D.", ""], ["Pham", "Long H.", ""], ["Sun", "Jun", ""]]}, {"id": "2101.01950", "submitter": "Iraklis Symeonidis", "authors": "Iraklis Symeonidis, Dragos Rotaru, Mustafa A. Mustafa, Bart Mennink,\n  Bart Preneel, and Panos Papadimitratos", "title": "HERMES: Scalable, Secure, and Privacy-Enhancing Vehicle Access System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose HERMES, a scalable, secure, and privacy-enhancing system for users\nto share and access vehicles. HERMES securely outsources operations of vehicle\naccess token generation to a set of untrusted servers. It builds on an earlier\nproposal, namely SePCAR [1], and extends the system design for improved\nefficiency and scalability. To cater to system and user needs for secure and\nprivate computations, HERMES utilizes and combines several cryptographic\nprimitives with secure multiparty computation efficiently. It conceals secret\nkeys of vehicles and transaction details from the servers, including vehicle\nbooking details, access token information, and user and vehicle identities. It\nalso provides user accountability in case of disputes. Besides, we provide\nsemantic security analysis and prove that HERMES meets its security and privacy\nrequirements. Last but not least, we demonstrate that HERMES is efficient and,\nin contrast to SePCAR, scales to a large number of users and vehicles, making\nit practical for real-world deployments. We build our evaluations with two\ndifferent multiparty computation protocols: HtMAC-MiMC and CBC-MAC-AES. Our\nresults demonstrate that HERMES with HtMAC-MiMC requires only approx 1,83 ms\nfor generating an access token for a single-vehicle owner and approx 11,9 ms\nfor a large branch of rental companies with over a thousand vehicles. It\nhandles 546 and 84 access token generations per second, respectively. This\nresults in HERMES being 696 (with HtMAC-MiMC) and 42 (with CBC-MAC-AES) times\nfaster compared to in SePCAR for a single-vehicle owner access token\ngeneration. Furthermore, we show that HERMES is practical on the vehicle side,\ntoo, as access token operations performed on a prototype vehicle on-board unit\ntake only approx 62,087 ms.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 10:19:13 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 17:29:36 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Symeonidis", "Iraklis", ""], ["Rotaru", "Dragos", ""], ["Mustafa", "Mustafa A.", ""], ["Mennink", "Bart", ""], ["Preneel", "Bart", ""], ["Papadimitratos", "Panos", ""]]}, {"id": "2101.02069", "submitter": "Hailong Hu", "authors": "Hailong Hu, Jun Pang", "title": "Model Extraction and Defenses on Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model extraction attacks aim to duplicate a machine learning model through\nquery access to a target model. Early studies mainly focus on discriminative\nmodels. Despite the success, model extraction attacks against generative models\nare less well explored. In this paper, we systematically study the feasibility\nof model extraction attacks against generative adversarial networks (GANs).\nSpecifically, we first define accuracy and fidelity on model extraction attacks\nagainst GANs. Then we study model extraction attacks against GANs from the\nperspective of accuracy extraction and fidelity extraction, according to the\nadversary's goals and background knowledge. We further conduct a case study\nwhere an adversary can transfer knowledge of the extracted model which steals a\nstate-of-the-art GAN trained with more than 3 million images to new domains to\nbroaden the scope of applications of model extraction attacks. Finally, we\npropose effective defense techniques to safeguard GANs, considering a trade-off\nbetween the utility and security of GAN models.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 14:36:21 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Hu", "Hailong", ""], ["Pang", "Jun", ""]]}, {"id": "2101.02102", "submitter": "Daniel Schneider", "authors": "Daniel Schneider, Daniel Fraunholz, Daniel Krohmer", "title": "A Qualitative Empirical Analysis of Human Post-Exploitation Behavior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Honeypots are a well-studied defensive measure in network security. This work\nproposes an effective low-cost honeypot that is easy to deploy and maintain.\nThe honeypot introduced in this work is able to handle commands in a\nnon-standard way by blocking them or replying with an insult to the attacker.\nTo determine the most efficient defense strategy, the interaction between\nattacker and defender is modeled as a Bayesian two-player game. For the\nempirical analysis, three honeypot instances were deployed, each with a slight\nvariation in its configuration. In total, over 200 distinct sessions were\ncaptured, which allows for qualitative evaluation of post-exploitation\nbehavior. The findings show that attackers react to insults and blocked\ncommands in different ways, ranging from ignoring to sending insults\nthemselves. The main contribution of this work lies in the proposed framework,\nwhich offers a low-cost alternative to more technically sophisticated and\nresource-intensive approaches.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 15:46:43 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Schneider", "Daniel", ""], ["Fraunholz", "Daniel", ""], ["Krohmer", "Daniel", ""]]}, {"id": "2101.02147", "submitter": "Faisal Hussain", "authors": "Syed Ghazanfar Abbas, Shahzaib Zahid, Faisal Hussain, Ghalib A. Shah,\n  Muhammad Husnain", "title": "A Threat Modelling Approach to Analyze and Mitigate Botnet Attacks in\n  Smart Home Use Case", "comments": "Accepted in IEEE TrustCom 2020, 7 Pages, 4 Figures, 3 Tables", "journal-ref": null, "doi": "10.1109/BigDataSE50710.2020.00024", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the surging development and utilization of IoT devices, the security\nof IoT devices is still in infancy. The security pitfalls of IoT devices have\nmade it easy for hackers to take over IoT devices and use them for malicious\nactivities like botnet attacks. With the rampant emergence of IoT devices,\nbotnet attacks are surging. The botnet attacks are not only catastrophic for\nIoT device users but also for the rest of the world. Therefore, there is a\ncrucial need to identify and mitigate the possible threats in IoT devices\nduring the design phase. Threat modelling is a technique that is used to\nidentify the threats in the earlier stages of the system design activity. In\nthis paper, we propose a threat modelling approach to analyze and mitigate the\nbotnet attacks in an IoT smart home use case. The proposed methodology\nidentifies the development-level and application-level threats in smart home\nuse case using STRIDE and VAST threat modelling methods. Moreover, we\nreticulate the identified threats with botnet attacks. Finally, we propose the\nmitigation techniques for all identified threats including the botnet threats.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 17:28:12 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Abbas", "Syed Ghazanfar", ""], ["Zahid", "Shahzaib", ""], ["Hussain", "Faisal", ""], ["Shah", "Ghalib A.", ""], ["Husnain", "Muhammad", ""]]}, {"id": "2101.02159", "submitter": "Damian Straszak", "authors": "Daniel Kane and Andreas Fackler and Adam G\\k{a}gol and Damian Straszak", "title": "Highway: Efficient Consensus with Flexible Finality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been recently a lot of progress in designing efficient partially\nsynchronous BFT consensus protocols that are meant to serve as core consensus\nengines for Proof of Stake blockchain systems. While the state-of-the-art\nsolutions attain virtually optimal performance under this theoretical model,\nthere is still room for improvement, as several practical aspects of such\nsystems are not captured by this model. Most notably, during regular execution,\ndue to financial incentives in such systems, one expects an overwhelming\nfraction of nodes to honestly follow the protocol rules and only few of them to\nbe faulty, most likely due to temporary network issues. Intuitively, the fact\nthat almost all nodes behave honestly should result in stronger confidence in\nblocks finalized in such periods, however it is not the case under the\nclassical model, where finality is binary.\n  We propose Highway, a new consensus protocol that is safe and live in the\nclassical partially synchronous BFT model, while at the same time offering\npractical improvements over existing solutions. Specifically, block finality in\nHighway is not binary but is expressed by fraction of nodes that would need to\nbreak the protocol rules in order for a block to be reverted. During periods of\nhonest participation finality of blocks might reach well beyond 1/3 (as what\nwould be the maximum for classical protocols), up to even 1 (complete\ncertainty). Having finality defined this way, Highway offers flexibility with\nrespect to the configuration of security thresholds among nodes running the\nprotocol, allowing nodes with lower thresholds to reach finality faster than\nthe ones requiring higher levels of confidence.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 17:51:54 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 09:12:02 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Kane", "Daniel", ""], ["Fackler", "Andreas", ""], ["G\u0105gol", "Adam", ""], ["Straszak", "Damian", ""]]}, {"id": "2101.02281", "submitter": "Duc Thien Nguyen", "authors": "Thien Duc Nguyen, Phillip Rieger, Hossein Yalame, Helen M\\\"ollering,\n  Hossein Fereidooni, Samuel Marchal, Markus Miettinen, Azalia Mirhoseini,\n  Ahmad-Reza Sadeghi, Thomas Schneider, Shaza Zeitouni", "title": "FLGUARD: Secure and Private Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, a number of backdoor attacks against Federated Learning (FL) have\nbeen proposed. In such attacks, an adversary injects poisoned model updates\ninto the federated model aggregation process with the goal of manipulating the\naggregated model to provide false predictions on specific adversary-chosen\ninputs. A number of defenses have been proposed; but none of them can\neffectively protect the FL process also against so-called multi-backdoor\nattacks in which multiple different backdoors are injected by the adversary\nsimultaneously without severely impacting the benign performance of the\naggregated model. To overcome this challenge, we introduce FLGUARD, a poisoning\ndefense framework that is able to defend FL against state-of-the-art backdoor\nattacks while simultaneously maintaining the benign performance of the\naggregated model. Moreover, FL is also vulnerable to inference attacks, in\nwhich a malicious aggregator can infer information about clients' training data\nfrom their model updates. To thwart such attacks, we augment FLGUARD with\nstate-of-the-art secure computation techniques that securely evaluate the\nFLGUARD algorithm. We provide formal argumentation for the effectiveness of our\nFLGUARD and extensively evaluate it against known backdoor attacks on several\ndatasets and applications (including image classification, word prediction, and\nIoT intrusion detection), demonstrating that FLGUARD can entirely remove\nbackdoors with a negligible effect on accuracy. We also show that private\nFLGUARD achieves practical runtimes.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 21:49:27 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 15:30:17 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Nguyen", "Thien Duc", ""], ["Rieger", "Phillip", ""], ["Yalame", "Hossein", ""], ["M\u00f6llering", "Helen", ""], ["Fereidooni", "Hossein", ""], ["Marchal", "Samuel", ""], ["Miettinen", "Markus", ""], ["Mirhoseini", "Azalia", ""], ["Sadeghi", "Ahmad-Reza", ""], ["Schneider", "Thomas", ""], ["Zeitouni", "Shaza", ""]]}, {"id": "2101.02325", "submitter": "Pengfei Xia", "authors": "Pengfei Xia, Ziqiang Li, Hongjing Niu and Bin Li", "title": "Understanding the Error in Evaluating Adversarial Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are easily misled by adversarial examples. Although lots\nof defense methods are proposed, many of them are demonstrated to lose\neffectiveness when against properly performed adaptive attacks. How to evaluate\nthe adversarial robustness effectively is important for the realistic\ndeployment of deep models, but yet still unclear. To provide a reasonable\nsolution, one of the primary things is to understand the error (or gap) between\nthe true adversarial robustness and the evaluated one, what is it and why it\nexists. Several works are done in this paper to make it clear. Firstly, we\nintroduce an interesting phenomenon named gradient traps, which lead to\nincompetent adversaries and are demonstrated to be a manifestation of\nevaluation error. Then, we analyze the error and identify that there are three\ncomponents. Each of them is caused by a specific compromise. Moreover, based on\nthe above analysis, we present our evaluation suggestions. Experiments on\nadversarial training and its variations indicate that: (1) the error does exist\nempirically, and (2) these defenses are still vulnerable. We hope these\nanalyses and results will help the community to develop more powerful defenses.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 01:59:00 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Xia", "Pengfei", ""], ["Li", "Ziqiang", ""], ["Niu", "Hongjing", ""], ["Li", "Bin", ""]]}, {"id": "2101.02334", "submitter": "Hanlin Zhang", "authors": "Hanlin Zhang, Peng Gao, Jia Yu, Jie Lin, and Neal N. Xiong", "title": "Machine Learning on Cloud with Blockchain: A Secure, Verifiable and Fair\n  Approach to Outsource the Linear Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear Regression (LR) is a classical machine learning algorithm which has\nmany applications in the cyber physical social systems (CPSS) to shape and\nsimplify the way we live, work and communicate. This paper focuses on the data\nanalysis for CPSS when the Linear Regression is applied. The training process\nof LR is time-consuming since it involves complex matrix operations, especially\nwhen it gets a large scale training dataset In the CPSS. Thus, how to enable\ndevices to efficiently perform the training process of the Linear Regression is\nof significant importance. To address this issue, in this paper, we present a\nsecure, verifiable and fair approach to outsource LR to an untrustworthy\ncloud-server. In the proposed scheme, computation inputs/outputs are obscured\nso that the privacy of sensitive information is protected against cloud-server.\nMeanwhile, computation result from cloud-server is verifiable. Also, fairness\nis guaranteed by the blockchain, which ensures that the cloud gets paid only if\nhe correctly performed the outsourced workload. Based on the presented\napproach, we exploited the fair, secure outsourcing system on the Ethereum\nblockchain. We analysed our presented scheme on theoretical and experimental,\nall of which indicate that the presented scheme is valid, secure and efficient.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 02:32:32 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Zhang", "Hanlin", ""], ["Gao", "Peng", ""], ["Yu", "Jia", ""], ["Lin", "Jie", ""], ["Xiong", "Neal N.", ""]]}, {"id": "2101.02341", "submitter": "Hanlin Zhang", "authors": "Hanlin Zhang, Le Tong, Jia Yu, Jie Lin", "title": "Blockchain Aided Privacy-Preserving Outsourcing Algorithms of Bilinear\n  Pairings for Internet of Things Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bilinear pairing is a fundamental operation that is widely used in\ncryptographic algorithms (e.g., identity-based cryptographic algorithms) to\nsecure IoT applications. Nonetheless, the time complexity of bilinear pairing\nis $O(n^3)$, making it a very time-consuming operation, especially for\nresource-constrained IoT devices. Secure outsourcing of bilinear pairing has\nbeen studied in recent years to enable computationally weak devices to securely\noutsource the bilinear pairing to untrustworthy cloud servers. However, the\nstate-of-art algorithms often require to pre-compute and store some values,\nwhich results in storage burden for devices. In the Internet of Things, devices\nare generally with very limited storage capacity. Thus, the existing algorithms\ndo not fit the IoT well. In this paper, we propose a secure outsourcing\nalgorithm of bilinear pairings, which does not require pre-computations. In the\nproposed algorithm, the outsourcer side's efficiency is significantly improved\ncompared with executing the original bilinear pairing operation. At the same\ntime, the privacy of the input and output is ensured. Also, we apply the\nEthereum blockchain in our outsourcing algorithm to enable fair payments, which\nensures that the cloud server gets paid only when he correctly accomplished the\noutsourced work. The theoretical analysis and experimental results show that\nthe proposed algorithm is efficient and secure.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 02:59:40 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Zhang", "Hanlin", ""], ["Tong", "Le", ""], ["Yu", "Jia", ""], ["Lin", "Jie", ""]]}, {"id": "2101.02377", "submitter": "Naoto Yanai", "authors": "Nami Ashizawa, Naoto Yanai, Jason Paul Cruz, Shingo Okamura", "title": "Eth2Vec: Learning Contract-Wide Code Representations for Vulnerability\n  Detection on Ethereum Smart Contracts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ethereum smart contracts are programs that run on the Ethereum blockchain,\nand many smart contract vulnerabilities have been discovered in the past\ndecade. Many security analysis tools have been created to detect such\nvulnerabilities, but their performance decreases drastically when codes to be\nanalyzed are being rewritten. In this paper, we propose Eth2Vec, a\nmachine-learning-based static analysis tool for vulnerability detection, with\nrobustness against code rewrites in smart contracts. Existing\nmachine-learning-based static analysis tools for vulnerability detection need\nfeatures, which analysts create manually, as inputs. In contrast, Eth2Vec\nautomatically learns features of vulnerable Ethereum Virtual Machine (EVM)\nbytecodes with tacit knowledge through a neural network for language\nprocessing. Therefore, Eth2Vec can detect vulnerabilities in smart contracts by\ncomparing the code similarity between target EVM bytecodes and the EVM\nbytecodes it already learned. We conducted experiments with existing open\ndatabases, such as Etherscan, and our results show that Eth2Vec outperforms the\nexisting work in terms of well-known metrics, i.e., precision, recall, and\nF1-score. Moreover, Eth2Vec can detect vulnerabilities even in rewritten codes.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 05:28:26 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 09:57:47 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Ashizawa", "Nami", ""], ["Yanai", "Naoto", ""], ["Cruz", "Jason Paul", ""], ["Okamura", "Shingo", ""]]}, {"id": "2101.02392", "submitter": "Yicheng Guo", "authors": "Yicheng Guo, Yujin Wen, Congwei Jiang, Yixin Lian, Yi Wan", "title": "Detecting Log Anomalies with Multi-Head Attention (LAMA)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is a crucial and challenging subject that has been studied\nwithin diverse research areas. In this work, we explore the task of log anomaly\ndetection (especially computer system logs and user behavior logs) by analyzing\nlogs' sequential information. We propose LAMA, a multi-head attention based\nsequential model to process log streams as template activity (event) sequences.\n  A next event prediction task is applied to train the model for anomaly\ndetection. Extensive empirical studies demonstrate that our new model\noutperforms existing log anomaly detection methods including statistical and\ndeep learning methodologies, which validate the effectiveness of our proposed\nmethod in learning sequence patterns of log data.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 06:15:59 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Guo", "Yicheng", ""], ["Wen", "Yujin", ""], ["Jiang", "Congwei", ""], ["Lian", "Yixin", ""], ["Wan", "Yi", ""]]}, {"id": "2101.02552", "submitter": "Sohail Ahmed Khan", "authors": "Sohail Ahmed Khan and Wasiq Khan and Abir Hussain", "title": "Phishing Attacks and Websites Classification Using Machine Learning and\n  Multiple Datasets (A Comparative Analysis)", "comments": null, "journal-ref": "In: Huang DS., Premaratne P. (eds) Intelligent Computing\n  Methodologies. ICIC 2020. Lecture Notes in Computer Science, vol 12465.\n  Springer, Cham", "doi": "10.1007/978-3-030-60796-8_26", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Phishing attacks are the most common type of cyber-attacks used to obtain\nsensitive information and have been affecting individuals as well as\norganisations across the globe. Various techniques have been proposed to\nidentify the phishing attacks specifically, deployment of machine intelligence\nin recent years. However, the deployed algorithms and discriminating factors\nare very diverse in existing works. In this study, we present a comprehensive\nanalysis of various machine learning algorithms to evaluate their performances\nover multiple datasets. We further investigate the most significant features\nwithin multiple datasets and compare the classification performance with the\nreduced dimensional datasets. The statistical results indicate that random\nforest and artificial neural network outperform other classification\nalgorithms, achieving over 97% accuracy using the identified features.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 08:23:43 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Khan", "Sohail Ahmed", ""], ["Khan", "Wasiq", ""], ["Hussain", "Abir", ""]]}, {"id": "2101.02556", "submitter": "Rohan Iyer", "authors": "Rohan Iyer, Regina Rex, Kevin P. McPherson, Darshan Gandhi, Aryan\n  Mahindra, Abhishek Singh, Ramesh Raskar", "title": "Spatial K-anonymity: A Privacy-preserving Method for COVID-19 Related\n  Geospatial Technologies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing need for spatial privacy considerations in the many\ngeo-spatial technologies that have been created as solutions for\nCOVID-19-related issues. Although effective geo-spatial technologies have\nalready been rolled out, most have significantly sacrificed privacy for\nutility. In this paper, we explore spatial k-anonymity, a privacy-preserving\nmethod that can address this unnecessary tradeoff by providing the best of both\nprivacy and utility. After evaluating its past implications in geo-spatial use\ncases, we propose applications of spatial k-anonymity in the data sharing and\nmanaging of COVID-19 contact tracing technologies as well as heat maps showing\na user's travel history. We then justify our propositions by comparing spatial\nk-anonymity with several other spatial privacy methods, including differential\nprivacy, geo-indistinguishability, and manual consent based redaction. Our hope\nis to raise awareness of the ever-growing risks associated with spatial privacy\nand how they can be solved with Spatial K-anonymity.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 22:36:26 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Iyer", "Rohan", ""], ["Rex", "Regina", ""], ["McPherson", "Kevin P.", ""], ["Gandhi", "Darshan", ""], ["Mahindra", "Aryan", ""], ["Singh", "Abhishek", ""], ["Raskar", "Ramesh", ""]]}, {"id": "2101.02559", "submitter": "Lois Orosa", "authors": "Muhammad Shafique, Mahum Naseer, Theocharis Theocharides, Christos\n  Kyrkou, Onur Mutlu, Lois Orosa, Jungwook Choi", "title": "Robust Machine Learning Systems: Challenges, Current Trends,\n  Perspectives, and the Road Ahead", "comments": "Final version appears in https://ieeexplore.ieee.org/document/8979377", "journal-ref": "IEEE Design and Test (Volume: 37, Issue: 2, April 2020): 30-57", "doi": "10.1109/MDAT.2020.2971217", "report-no": null, "categories": "cs.CR cs.AI cs.AR cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) techniques have been rapidly adopted by smart\nCyber-Physical Systems (CPS) and Internet-of-Things (IoT) due to their powerful\ndecision-making capabilities. However, they are vulnerable to various security\nand reliability threats, at both hardware and software levels, that compromise\ntheir accuracy. These threats get aggravated in emerging edge ML devices that\nhave stringent constraints in terms of resources (e.g., compute, memory,\npower/energy), and that therefore cannot employ costly security and reliability\nmeasures. Security, reliability, and vulnerability mitigation techniques span\nfrom network security measures to hardware protection, with an increased\ninterest towards formal verification of trained ML models.\n  This paper summarizes the prominent vulnerabilities of modern ML systems,\nhighlights successful defenses and mitigation techniques against these\nvulnerabilities, both at the cloud (i.e., during the ML training phase) and\nedge (i.e., during the ML inference stage), discusses the implications of a\nresource-constrained design on the reliability and security of the system,\nidentifies verification methodologies to ensure correct system behavior, and\ndescribes open research challenges for building secure and reliable ML systems\nat both the edge and the cloud.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 20:06:56 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Shafique", "Muhammad", ""], ["Naseer", "Mahum", ""], ["Theocharides", "Theocharis", ""], ["Kyrkou", "Christos", ""], ["Mutlu", "Onur", ""], ["Orosa", "Lois", ""], ["Choi", "Jungwook", ""]]}, {"id": "2101.02562", "submitter": "Zhanglongyuan Longyuan", "authors": "Jinyin Chen, Longyuan Zhang, Haibin Zheng, Xueke Wang and Zhaoyan Ming", "title": "DeepPoison: Feature Transfer Based Stealthy Poisoning Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Deep neural networks are susceptible to poisoning attacks by purposely\npolluted training data with specific triggers. As existing episodes mainly\nfocused on attack success rate with patch-based samples, defense algorithms can\neasily detect these poisoning samples. We propose DeepPoison, a novel\nadversarial network of one generator and two discriminators, to address this\nproblem. Specifically, the generator automatically extracts the target class'\nhidden features and embeds them into benign training samples. One discriminator\ncontrols the ratio of the poisoning perturbation. The other discriminator works\nas the target model to testify the poisoning effects. The novelty of DeepPoison\nlies in that the generated poisoned training samples are indistinguishable from\nthe benign ones by both defensive methods and manual visual inspection, and\neven benign test samples can achieve the attack. Extensive experiments have\nshown that DeepPoison can achieve a state-of-the-art attack success rate, as\nhigh as 91.74%, with only 7% poisoned samples on publicly available datasets\nLFW and CASIA. Furthermore, we have experimented with high-performance defense\nalgorithms such as autodecoder defense and DBSCAN cluster detection and showed\nthe resilience of DeepPoison.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 15:45:36 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 04:07:19 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Chen", "Jinyin", ""], ["Zhang", "Longyuan", ""], ["Zheng", "Haibin", ""], ["Wang", "Xueke", ""], ["Ming", "Zhaoyan", ""]]}, {"id": "2101.02573", "submitter": "Hazem Soliman", "authors": "Hazem M. Soliman, Geoff Salmon, Du\\v{s}an Sovilj, Mohan Rao", "title": "RANK: AI-assisted End-to-End Architecture for Detecting Persistent\n  Attacks in Enterprise Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Advanced Persistent Threats (APTs) are sophisticated multi-step attacks,\nplanned and executed by skilled adversaries targeting modern government and\nenterprise networks. Intrusion Detection Systems (IDSs) and User and Entity\nBehavior Analytics (UEBA) are commonly employed to aid a security analyst in\nthe detection of APTs. The prolonged nature of APTs, combined with the granular\nfocus of UEBA and IDS, results in overwhelming the analyst with an increasingly\nimpractical number of alerts. Consequent to this abundance of data, and\ntogether with the crucial importance of the problem as well as the high cost of\nthe skilled personnel involved, the problem of APT detection becomes a perfect\ncandidate for automation through Artificial Intelligence (AI). In this paper,\nwe provide, up to our knowledge, the first study and implementation of an\nend-to-end AI-assisted architecture for detecting APTs -- RANK. The goal of the\nsystem is not to replace the analyst, rather, it is to automate the complete\npipeline from data sources to a final set of incidents for analyst review. The\narchitecture is composed of four consecutive steps: 1) alert templating and\nmerging, 2) alert graph construction, 3) alert graph partitioning into\nincidents, and 4) incident scoring and ordering. We evaluate our architecture\nagainst the 2000 DARPA Intrusion Detection dataset, as well as a read-world\nprivate dataset from a medium-scale enterprise. Extensive results are provided\nshowing a three order of magnitude reduction in the amount of data to be\nreviewed by the analyst, innovative extraction of incidents and security-wise\nscoring of extracted incidents.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2021 15:59:51 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Soliman", "Hazem M.", ""], ["Salmon", "Geoff", ""], ["Sovilj", "Du\u0161an", ""], ["Rao", "Mohan", ""]]}, {"id": "2101.02577", "submitter": "Yuntao Liu", "authors": "Yuntao Liu, Michael Zuzak, Yang Xie, Abhishek Chakraborty, Ankur\n  Srivastava", "title": "Robust and Attack Resilient Logic Locking with a High Application-Level\n  Impact", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Logic locking is a hardware security technique to intellectual property (IP)\nagainst security threats in the IC supply chain, especially untrusted fabs.\nSuch techniques incorporate additional locking circuitry within an IC that\ninduces incorrect functionality when an incorrect key is provided. The amount\nof error induced is known as the effectiveness of the locking technique. \"SAT\nattacks\" provide a strong mathematical formulation to find the correct key of\nlocked circuits. In order to achieve high SAT resilience(i.e. complexity of SAT\nattacks), many conventional logic locking schemes fail to inject sufficient\nerror into the circuit. For example, in the case of SARLock and Anti-SAT, there\nare usually very few (or only one) input minterms that cause any error at the\ncircuit output. The state-of-the-art stripped functionality logic locking\n(SFLL) technique introduced a trade-off between SAT resilience and\neffectiveness. In this work, we prove that such a trade-off is universal in\nlogic locking. In order to attain high effectiveness of locking without\ncompromising SAT resilience, we propose a novel logic locking scheme, called\nStrong Anti-SAT (SAS). In addition to SAT attacks, removal-based attacks are\nalso popular against logic locking. Based on SAS, we propose Robust SAS (RSAS)\nwhich is resilient to removal attacks and maintains the same SAT resilience and\nas effectiveness as SAS. SAS and RSAS have the following significant\nimprovements over existing techniques. (1) SAT resilience of SAS and RSAS\nagainst SAT attack is not compromised by increase in effectiveness. (2) In\ncontrast to prior work focusing solely on the circuit-level locking impact, we\nintegrate SAS-locked modules into a processor and show that SAS has a high\napplication-level impact. (3) Our experiments show that SAS and RSAS exhibit\nbetter SAT resilience than SFLL and have similar effectiveness.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 15:01:31 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Liu", "Yuntao", ""], ["Zuzak", "Michael", ""], ["Xie", "Yang", ""], ["Chakraborty", "Abhishek", ""], ["Srivastava", "Ankur", ""]]}, {"id": "2101.02627", "submitter": "Majid Rafiei", "authors": "Majid Rafiei and Wil M.P. van der Aalst", "title": "Privacy-Preserving Data Publishing in Process Mining", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-58638-6_8", "report-no": null, "categories": "cs.CR cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Process mining aims to provide insights into the actual processes based on\nevent data. These data are often recorded by information systems and are widely\navailable. However, they often contain sensitive private information that\nshould be analyzed responsibly. Therefore, privacy issues in process mining are\nrecently receiving more attention. Privacy preservation techniques obviously\nneed to modify the original data, yet, at the same time, they are supposed to\npreserve the data utility. Privacy-preserving transformations of the data may\nlead to incorrect or misleading analysis results. Hence, new infrastructures\nneed to be designed for publishing the privacy-aware event data whose aim is to\nprovide metadata regarding the privacy-related transformations on event data\nwithout revealing details of privacy preservation techniques or the protected\ninformation. In this paper, we provide formal definitions for the main\nanonymization operations, used by privacy models in process mining. These are\nused to create an infrastructure for recording the privacy metadata. We\nadvocate the proposed privacy metadata in practice by designing a privacy\nextension for the XES standard and a general data structure for event data\nwhich are not in the form of standard event logs.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 15:03:28 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Rafiei", "Majid", ""], ["van der Aalst", "Wil M. P.", ""]]}, {"id": "2101.02631", "submitter": "Miroslav Bures", "authors": "Miroslav Bures, Matej Klima, Vaclav Rechtberger, Bestoun S. Ahmed,\n  Hanan Hindy, Xavier Bellekens", "title": "Review of Specific Features and Challenges in the Current Internet of\n  Things Systems Impacting their Security and Reliability", "comments": "Paper accepted at WorldCist'21 - 9th World Conference on Information\n  Systems and Technologies, Portugal, 30-31 March to 1-2 April 2021,\n  http://www.worldcist.org/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current development of the Internet of Things (IoT) technology poses\nsignificant challenges to researchers and industry practitioners. Among these\nchallenges, security and reliability particularly deserve attention. In this\npaper, we provide a consolidated analysis of the root causes of these\nchallenges, their relations, and their possible impacts on IoT systems' general\nquality characteristics. Further understanding of these challenges is useful\nfor IoT quality engineers when defining testing strategies for their systems\nand researchers to consider when discussing possible research directions. In\nthis study, twenty specific features of current IoT systems are discussed,\ndivided into five main categories: (1) Economic, managerial and organisational\naspects, (2) Infrastructural challenges, (3) Security and privacy challenges,\n(4) Complexity challenges and (5) Interoperability problems.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 20:30:14 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Bures", "Miroslav", ""], ["Klima", "Matej", ""], ["Rechtberger", "Vaclav", ""], ["Ahmed", "Bestoun S.", ""], ["Hindy", "Hanan", ""], ["Bellekens", "Xavier", ""]]}, {"id": "2101.02632", "submitter": "Juan Ignacio Iba\\~nez", "authors": "Juan Ignacio Iba\\~nez, Chris N. Bayer, Paolo Tasca, Jiahua Xu", "title": "Triple-entry Accounting, Blockchain and Next of Kin: Towards a\n  Standardization of Ledger Terminology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Triple-entry accounting (TEA) is one of the novelest notions in the\nblockchain world. However, the lack of a consistent and comprehensive set of\ncategories to give account of it impedes a proper apprehension of the concept,\nleading to contradictions and to overlooking its specificity. In order to\nclearly delineate the confines of TEA, we create a typology to distinguish\nbetween essential elements such as accounting and bookkeeping, as well as\nbetween decentralized systems, distributed ledgers and distributed journals.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2021 03:21:29 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2021 16:37:43 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Iba\u00f1ez", "Juan Ignacio", ""], ["Bayer", "Chris N.", ""], ["Tasca", "Paolo", ""], ["Xu", "Jiahua", ""]]}, {"id": "2101.02644", "submitter": "Hai Huang", "authors": "Hai Huang, Jiaming Mu, Neil Zhenqiang Gong, Qi Li, Bin Liu, Mingwei Xu", "title": "Data Poisoning Attacks to Deep Learning Based Recommender Systems", "comments": "To appear in NDSS 2021", "journal-ref": null, "doi": "10.14722/ndss.2021.24525", "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems play a crucial role in helping users to find their\ninterested information in various web services such as Amazon, YouTube, and\nGoogle News. Various recommender systems, ranging from neighborhood-based,\nassociation-rule-based, matrix-factorization-based, to deep learning based,\nhave been developed and deployed in industry. Among them, deep learning based\nrecommender systems become increasingly popular due to their superior\nperformance.\n  In this work, we conduct the first systematic study on data poisoning attacks\nto deep learning based recommender systems. An attacker's goal is to manipulate\na recommender system such that the attacker-chosen target items are recommended\nto many users. To achieve this goal, our attack injects fake users with\ncarefully crafted ratings to a recommender system. Specifically, we formulate\nour attack as an optimization problem, such that the injected ratings would\nmaximize the number of normal users to whom the target items are recommended.\nHowever, it is challenging to solve the optimization problem because it is a\nnon-convex integer programming problem. To address the challenge, we develop\nmultiple techniques to approximately solve the optimization problem. Our\nexperimental results on three real-world datasets, including small and large\ndatasets, show that our attack is effective and outperforms existing attacks.\nMoreover, we attempt to detect fake users via statistical analysis of the\nrating patterns of normal and fake users. Our results show that our attack is\nstill effective and outperforms existing attacks even if such a detector is\ndeployed.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 17:32:56 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 12:26:17 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Huang", "Hai", ""], ["Mu", "Jiaming", ""], ["Gong", "Neil Zhenqiang", ""], ["Li", "Qi", ""], ["Liu", "Bin", ""], ["Xu", "Mingwei", ""]]}, {"id": "2101.02780", "submitter": "Tanujay Saha", "authors": "Tanujay Saha, Najwa Aaraj, Neel Ajjarapu, Niraj K. Jha", "title": "SHARKS: Smart Hacking Approaches for RisK Scanning in Internet-of-Things\n  and Cyber-Physical Systems based on Machine Learning", "comments": "This article has been accepted in IEEE Transactions on Emerging\n  Topics in Computing. 17 pages, 12 figures, IEEE copyright", "journal-ref": "IEEE Transactions on Emerging Topics in Computing, 2021", "doi": "10.1109/TETC.2021.3050733", "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Cyber-physical systems (CPS) and Internet-of-Things (IoT) devices are\nincreasingly being deployed across multiple functionalities, ranging from\nhealthcare devices and wearables to critical infrastructures, e.g., nuclear\npower plants, autonomous vehicles, smart cities, and smart homes. These devices\nare inherently not secure across their comprehensive software, hardware, and\nnetwork stacks, thus presenting a large attack surface that can be exploited by\nhackers. In this article, we present an innovative technique for detecting\nunknown system vulnerabilities, managing these vulnerabilities, and improving\nincident response when such vulnerabilities are exploited. The novelty of this\napproach lies in extracting intelligence from known real-world CPS/IoT attacks,\nrepresenting them in the form of regular expressions, and employing machine\nlearning (ML) techniques on this ensemble of regular expressions to generate\nnew attack vectors and security vulnerabilities. Our results show that 10 new\nattack vectors and 122 new vulnerability exploits can be successfully generated\nthat have the potential to exploit a CPS or an IoT ecosystem. The ML\nmethodology achieves an accuracy of 97.4% and enables us to predict these\nattacks efficiently with an 87.2% reduction in the search space. We demonstrate\nthe application of our method to the hacking of the in-vehicle network of a\nconnected car. To defend against the known attacks and possible novel exploits,\nwe discuss a defense-in-depth mechanism for various classes of attacks and the\nclassification of data targeted by such attacks. This defense mechanism\noptimizes the cost of security measures based on the sensitivity of the\nprotected resource, thus incentivizing its adoption in real-world CPS/IoT by\ncybersecurity practitioners.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 22:01:30 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Saha", "Tanujay", ""], ["Aaraj", "Najwa", ""], ["Ajjarapu", "Neel", ""], ["Jha", "Niraj K.", ""]]}, {"id": "2101.02800", "submitter": "Kelly Ramsay", "authors": "Kelly Ramsay and Shoja'eddin Chenouri", "title": "Differentially private depth functions and their associated medians", "comments": "25 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CR stat.ME stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we investigate the differentially private estimation of data\ndepth functions and their associated medians. We introduce several methods for\nprivatizing depth values at a fixed point, and show that for some depth\nfunctions, when the depth is computed at an out of sample point, privacy can be\ngained for free when $n\\rightarrow \\infty$. We also present a method for\nprivately estimating the vector of sample point depth values. Additionally, we\nintroduce estimation methods for depth-based medians for both depth functions\nwith low global sensitivity and depth functions with only highly probable, low\nlocal sensitivity. We provide a general result (Lemma 1) which can be used to\nprove consistency of an estimator produced by the exponential mechanism,\nprovided the limiting cost function is sufficiently smooth at a unique\nminimizer. We also introduce a general algorithm to privately estimate a\nminimizer of a cost function which has, with high probability, low local\nsensitivity. This algorithm combines the propose-test-release algorithm with\nthe exponential mechanism. An application of this algorithm to generate\nconsistent estimates of the projection depth-based median is presented. Thus,\nfor these private depth-based medians, we show that it is possible for privacy\nto be obtained for free when $n\\rightarrow \\infty$.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2021 23:56:24 GMT"}, {"version": "v2", "created": "Sat, 30 Jan 2021 01:39:45 GMT"}, {"version": "v3", "created": "Wed, 7 Apr 2021 20:18:53 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Ramsay", "Kelly", ""], ["Chenouri", "Shoja'eddin", ""]]}, {"id": "2101.02826", "submitter": "Hanlin Zhang", "authors": "Haiyang Liu, Hanlin Zhang, Li Guo, Jia Yu, and Jie Lin", "title": "Privacy-Preserving Cloud-Aided Broad Learning System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of artificial intelligence and the advent of the\n5G era, deep learning has received extensive attention from researchers. Broad\nLearning System (BLS) is a new deep learning model proposed recently, which\nshows its effectiveness in many fields, such as image recognition and fault\ndetection. However, the training process still requires vast computations, and\ntherefore cannot be accomplished by some resource-constrained devices. To solve\nthis problem, the resource-constrained device can outsource the BLS algorithm\nto cloud servers. Nevertheless, some security challenges also follow with the\nuse of cloud computing, including the privacy of the data and the correctness\nof returned results. In this paper, we propose a secure, efficient, and\nverifiable outsourcing algorithm for BLS. This algorithm not only improves the\nefficiency of the algorithm on the client but also ensures that the clients\nsensitive information is not leaked to the cloud server. In addition, in our\nalgorithm, the client can verify the correctness of returned results with a\nprobability of almost 1. Finally, we analyze the security and efficiency of our\nalgorithm in theory and prove our algorithms feasibility through experiments.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 02:36:26 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Liu", "Haiyang", ""], ["Zhang", "Hanlin", ""], ["Guo", "Li", ""], ["Yu", "Jia", ""], ["Lin", "Jie", ""]]}, {"id": "2101.02834", "submitter": "Jianxiong Guo", "authors": "Jianxiong Guo, Weili Wu", "title": "Differential Privacy-Based Online Allocations towards Integrating\n  Blockchain and Edge Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the blockchain-based Internet of Things (IoT) has been\nresearched and applied widely, where each IoT device can act as a node in the\nblockchain. However, these lightweight nodes usually do not have enough\ncomputing power to complete the consensus or other computing-required tasks.\nEdge computing network gives a platform to provide computing power to IoT\ndevices. A fundamental problem is how to allocate limited edge servers to IoT\ndevices in a highly untrustworthy environment. In a fair competition\nenvironment, the allocation mechanism should be online, truthful, and privacy\nsafe. To address these three challenges, we propose an online multi-item double\nauction (MIDA) mechanism, where IoT devices are buyers and edge servers are\nsellers. In order to achieve the truthfulness, the participants' private\ninformation is at risk of being exposed by inference attack, which may lead to\nmalicious manipulation of the market by adversaries. Then, we improve our MIDA\nmechanism based on differential privacy to protect sensitive information from\nbeing leaked. It interferes with the auction results slightly but guarantees\nprivacy protection with high confidence. Besides, we upgrade our\nprivacy-preserving MIDA mechanism such that adapting to more complex and\nrealistic scenarios. In the end, the effectiveness and correctness of\nalgorithms are evaluated and verified by theoretical analysis and numerical\nsimulations.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 03:30:38 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Guo", "Jianxiong", ""], ["Wu", "Weili", ""]]}, {"id": "2101.02899", "submitter": "Josh Harguess", "authors": "Marissa Dotter, Sherry Xie, Keith Manville, Josh Harguess, Colin\n  Busho, Mikel Rodriguez", "title": "Adversarial Attack Attribution: Discovering Attributable Signals in\n  Adversarial ML Attacks", "comments": "Accepted to RSEML Workshop at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) models are known to be vulnerable to adversarial inputs\nand researchers have demonstrated that even production systems, such as\nself-driving cars and ML-as-a-service offerings, are susceptible. These systems\nrepresent a target for bad actors. Their disruption can cause real physical and\neconomic harm. When attacks on production ML systems occur, the ability to\nattribute the attack to the responsible threat group is a critical step in\nformulating a response and holding the attackers accountable. We pose the\nfollowing question: can adversarially perturbed inputs be attributed to the\nparticular methods used to generate the attack? In other words, is there a way\nto find a signal in these attacks that exposes the attack algorithm, model\narchitecture, or hyperparameters used in the attack? We introduce the concept\nof adversarial attack attribution and create a simple supervised learning\nexperimental framework to examine the feasibility of discovering attributable\nsignals in adversarial attacks. We find that it is possible to differentiate\nattacks generated with different attack algorithms, models, and hyperparameters\non both the CIFAR-10 and MNIST datasets.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 08:16:41 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Dotter", "Marissa", ""], ["Xie", "Sherry", ""], ["Manville", "Keith", ""], ["Harguess", "Josh", ""], ["Busho", "Colin", ""], ["Rodriguez", "Mikel", ""]]}, {"id": "2101.02957", "submitter": "Oliver Mason", "authors": "Aisling Mc Glinchey and Oliver Mason", "title": "Observations on the Bias of Nonnegative Mechanisms for Differential\n  Privacy", "comments": null, "journal-ref": "AIMS Foundations of Data Science, December 2020", "doi": "10.3934/fods.2020020", "report-no": null, "categories": "cs.CR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study two methods for differentially private analysis of bounded data and\nextend these to nonnegative queries. We first recall that for the Laplace\nmechanism, boundary inflated truncation (BIT) applied to nonnegative queries\nand truncation both lead to strictly positive bias. We then consider a\ngeneralization of BIT using translated ramp functions. We explicitly\ncharacterise the optimal function in this class for worst case bias. We show\nthat applying any square-integrable post-processing function to a Laplace\nmechanism leads to a strictly positive maximal absolute bias. A corresponding\nresult is also shown for a generalisation of truncation, which we refer to as\nrestriction. We also briefly consider an alternative approach based on\nmultiplicative mechanisms for positive data and show that, without additional\nrestrictions, these mechanisms can lead to infinite bias.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 10:58:25 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Glinchey", "Aisling Mc", ""], ["Mason", "Oliver", ""]]}, {"id": "2101.02975", "submitter": "Andreas Weinand", "authors": "Weinand Andreas, Andreu G. de la Fuente, Lipps Christoph, Karrenbauer\n  Michael", "title": "Physical Layer Security based Key Management for LoRaWAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within this the work applicability of Physical LayerSecurity (PHYSEC) based\nkey management within Long RangeWide Area Network (LoRaWAN) is proposed and\nevaluatedusing an experimental testbed. Since Internet of Things\n(IoT)technologies have been arising in past years, they have as wellattracted\nattention for possible cyber attacks. While LoRaWANalready provides many of the\nfeatures needed in order to ensuresecurity goals such as data confidentiality\nand integrity, it lacksin measures such as secure key management and\ndistributionschemes. Since conventional solutions are not feasible here,\ne.g.due to constraints on payload size and power consumption, wepropose the\nusage of PHYSEC based session key management,which can provide the respective\nmeasures in a more lightweightway. The results derived from our testbed show\nthat it can be apromising alternative approach.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 11:56:52 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Andreas", "Weinand", ""], ["de la Fuente", "Andreu G.", ""], ["Christoph", "Lipps", ""], ["Michael", "Karrenbauer", ""]]}, {"id": "2101.02997", "submitter": "Constance Beguier", "authors": "Constance Beguier, Jean Ogier du Terrail, Iqraa Meah, Mathieu Andreux,\n  Eric W. Tramel", "title": "Differentially Private Federated Learning for Cancer Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since 2014, the NIH funded iDASH (integrating Data for Analysis,\nAnonymization, SHaring) National Center for Biomedical Computing has hosted\nyearly competitions on the topic of private computing for genomic data. For one\ntrack of the 2020 iteration of this competition, participants were challenged\nto produce an approach to federated learning (FL) training of genomic cancer\nprediction models using differential privacy (DP), with submissions ranked\naccording to held-out test accuracy for a given set of DP budgets. More\nprecisely, in this track, we are tasked with training a supervised model for\nthe prediction of breast cancer occurrence from genomic data split between two\nvirtual centers while ensuring data privacy with respect to model transfer via\nDP. In this article, we present our 3rd place submission to this competition.\nDuring the competition, we encountered two main challenges discussed in this\narticle: i) ensuring correctness of the privacy budget evaluation and ii)\nachieving an acceptable trade-off between prediction performance and privacy\nbudget.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 13:12:40 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 12:47:01 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Beguier", "Constance", ""], ["Terrail", "Jean Ogier du", ""], ["Meah", "Iqraa", ""], ["Andreux", "Mathieu", ""], ["Tramel", "Eric W.", ""]]}, {"id": "2101.03022", "submitter": "AKM Bahalul Haque", "authors": "A K M Bahalul Haque, Sonia Tasmin", "title": "Security Threats and Research Challenges of IoT-A Review", "comments": "13 pages. 1 table", "journal-ref": "Journal of Engineering Advancements Vol. 01(04) 2020, pp 170-182", "doi": "10.38032/jea.2020.04.008", "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Internet of things (IoT) is the epitome of sustainable development. It has\nfacilitated the development of smart systems, industrialization, and the\nstate-of-the-art quality of life. IoT architecture is one of the essential\nbaselines of understanding the widespread adoption. Security issues are very\ncrucial for any technical infrastructure. Since IoT comprises heterogeneous\ndevices, its security issues are diverse too. Various security attacks can be\nresponsible for compromising confidentiality, integrity, and availability. In\nthis paper, at first, the IoT architecture is described briefly. After that,\nthe components of IoT are explained with perspective to various IoT based\napplications and services. Finally, various security issues, including\nrecommended solutions, are elaborately described and the potential research\nchallenges and future research directions.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 17:42:05 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Haque", "A K M Bahalul", ""], ["Tasmin", "Sonia", ""]]}, {"id": "2101.03042", "submitter": "Pulei Xiong", "authors": "Pulei Xiong, Scott Buffett, Shahrear Iqbal, Philippe Lamontagne,\n  Mohammad Mamun, and Heather Molyneaux", "title": "Towards a Robust and Trustworthy Machine Learning System Development", "comments": "40 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) technologies have been widely adopted in many mission\ncritical fields, such as cyber security, autonomous vehicle control,\nhealthcare, etc. to support intelligent decision-making. While ML has\ndemonstrated impressive performance over conventional methods in these\napplications, concerns arose with respect to system resilience against\nML-specific security attacks and privacy breaches as well as the trust that\nusers have in these systems. In this article, firstly we present our recent\nsystematic and comprehensive survey on the state-of-the-art ML robustness and\ntrustworthiness technologies from a security engineering perspective, which\ncovers all aspects of secure ML system development including threat modeling,\ncommon offensive and defensive technologies, privacy-preserving machine\nlearning, user trust in the context of machine learning, and empirical\nevaluation for ML model robustness. Secondly, we then push our studies forward\nabove and beyond a survey by describing a metamodel we created that represents\nthe body of knowledge in a standard and visualized way for ML practitioners. We\nfurther illustrate how to leverage the metamodel to guide a systematic threat\nanalysis and security design process in a context of generic ML system\ndevelopment, which extends and scales up the classic process. Thirdly, we\npropose future research directions motivated by our findings to advance the\ndevelopment of robust and trustworthy ML systems. Our work differs from\nexisting surveys in this area in that, to the best of our knowledge, it is the\nfirst of its kind of engineering effort to (i) explore the fundamental\nprinciples and best practices to support robust and trustworthy ML system\ndevelopment; and (ii) study the interplay of robustness and user trust in the\ncontext of ML systems.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 14:43:58 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Xiong", "Pulei", ""], ["Buffett", "Scott", ""], ["Iqbal", "Shahrear", ""], ["Lamontagne", "Philippe", ""], ["Mamun", "Mohammad", ""], ["Molyneaux", "Heather", ""]]}, {"id": "2101.03103", "submitter": "Omid Torki", "authors": "Omid Torki, Maede Ashouri-Talouki, Mojtaba Mahdavi", "title": "Blockchain for steganography: advantages, new algorithms and open\n  challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Steganography is a solution for covert communication and blockchain is a p2p\nnetwork for data transmission, so the benefits of blockchain can be used in\nsteganography. In this paper, we discuss the advantages of blockchain in\nsteganography, which include the ability to embed hidden data without manual\nchange in the original data, as well as the readiness of the blockchain\nplatform for data transmission and storage, which eliminates the need for the\nSteganographer to design and implement a new platform for data transmission and\nstorage. We have proposed two algorithms for steganography in blockchain, the\nfirst one is a high-capacity algorithm for the key and the steganography\nalgorithm exchange and switching, and the second one is a medium-capacity\nalgorithm for embedding hidden data. Also, by reviewing the previous three\nsteganography schemes in blockchain, we have examined their drawback and have\nshowed that none of them are practical schemes for steganography in blockchain.\nThen, we have explained the challenges of steganography in blockchain from the\nsteganographers and steganalyzers point of view.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 17:00:41 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Torki", "Omid", ""], ["Ashouri-Talouki", "Maede", ""], ["Mahdavi", "Mojtaba", ""]]}, {"id": "2101.03118", "submitter": "Fabio Massimo Zennaro", "authors": "Laszlo Erdodi, {\\AA}vald {\\AA}slaugson Sommervoll, Fabio Massimo\n  Zennaro", "title": "Simulating SQL Injection Vulnerability Exploitation Using Q-Learning\n  Reinforcement Learning Agents", "comments": "20 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a formalization of the process of exploitation of\nSQL injection vulnerabilities. We consider a simplification of the dynamics of\nSQL injection attacks by casting this problem as a security capture-the-flag\nchallenge. We model it as a Markov decision process, and we implement it as a\nreinforcement learning problem. We then deploy reinforcement learning agents\ntasked with learning an effective policy to perform SQL injection; we design\nour training in such a way that the agent learns not just a specific strategy\nto solve an individual challenge but a more generic policy that may be applied\nto perform SQL injection attacks against any system instantiated randomly by\nour problem generator. We analyze the results in terms of the quality of the\nlearned policy and in terms of convergence time as a function of the complexity\nof the challenge and the learning agent's complexity. Our work fits in the\nwider research on the development of intelligent agents for autonomous\npenetration testing and white-hat hacking, and our results aim to contribute to\nunderstanding the potential and the limits of reinforcement learning in a\nsecurity environment.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 17:19:21 GMT"}, {"version": "v2", "created": "Sat, 22 May 2021 09:23:19 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Erdodi", "Laszlo", ""], ["Sommervoll", "\u00c5vald \u00c5slaugson", ""], ["Zennaro", "Fabio Massimo", ""]]}, {"id": "2101.03141", "submitter": "Iqbal H. Sarker", "authors": "Rony Chowdhury Ripan, Iqbal H. Sarker, Md Musfique Anwar, Md. Hasan\n  Furhad, Fazle Rahat, Mohammed Moshiul Hoque and Muhammad Sarfraz", "title": "An Isolation Forest Learning Based Outlier Detection Approach for\n  Effectively Classifying Cyber Anomalies", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Cybersecurity has recently gained considerable interest in today's security\nissues because of the popularity of the Internet-of-Things (IoT), the\nconsiderable growth of mobile networks, and many related apps. Therefore,\ndetecting numerous cyber-attacks in a network and creating an effective\nintrusion detection system plays a vital role in today's security. In this\npaper, we present an Isolation Forest Learning-Based Outlier Detection Model\nfor effectively classifying cyber anomalies. In order to evaluate the efficacy\nof the resulting Outlier Detection model, we also use several conventional\nmachine learning approaches, such as Logistic Regression (LR), Support Vector\nMachine (SVM), AdaBoost Classifier (ABC), Naive Bayes (NB), and K-Nearest\nNeighbor (KNN). The effectiveness of our proposed Outlier Detection model is\nevaluated by conducting experiments on Network Intrusion Dataset with\nevaluation metrics such as precision, recall, F1-score, and accuracy.\nExperimental results show that the classification accuracy of cyber anomalies\nhas been improved after removing outliers.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 05:09:52 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Ripan", "Rony Chowdhury", ""], ["Sarker", "Iqbal H.", ""], ["Anwar", "Md Musfique", ""], ["Furhad", "Md. Hasan", ""], ["Rahat", "Fazle", ""], ["Hoque", "Mohammed Moshiul", ""], ["Sarfraz", "Muhammad", ""]]}, {"id": "2101.03209", "submitter": "Micha{\\l} Drozdowicz", "authors": "Micha{\\l} Drozdowicz, Maria Ganzha, Marcin Paprzycki", "title": "Semantic Access Control for Privacy Management of Personal Sensing in\n  Smart Cities", "comments": "in IEEE Transactions on Emerging Topics in Computing (Early Access),\n  2020", "journal-ref": null, "doi": "10.1109/TETC.2020.2996974", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personal and home sensors generate valuable information that could be used in\nSmart Cities. Unfortunately, typically, this data is locked out and used only\nby application/system developer. While vendors are to blame, one should\nconsider also the \"binary nature\" of data access. Specifically, either owner\nhas full control over her data (e.g. in a \"closed system\"), or she completely\nlooses control, when the data is \"opened\". In this context, we propose, a\nsemantic technologies-based, authorization and privacy control framework that\nenables user to maintain flexible, yet manageable data access control policies.\nThe proposed approach is described in detail, including implementation and\ntesting.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 20:28:27 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Drozdowicz", "Micha\u0142", ""], ["Ganzha", "Maria", ""], ["Paprzycki", "Marcin", ""]]}, {"id": "2101.03212", "submitter": "Roberto Mag\\'an-Carri\\'on Dr.", "authors": "Roberto Mag\\'an-Carri\\'on and Alberto Abell\\'an-Galera and Gabriel\n  Maci\\'a-Fern\\'andez and Pedro Garc\\'ia-Teodoro", "title": "Unveiling the I2P web structure: a connectivity analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web is a primary and essential service to share information among users and\norganizations at present all over the world. Despite the current significance\nof such a kind of traffic on the Internet, the so-called Surface Web traffic\nhas been estimated in just about 5% of the total. The rest of the volume of\nthis type of traffic corresponds to the portion of Web known as Deep Web. These\ncontents are not accessible by search engines because they are authentication\nprotected contents or pages that are only reachable through the well known as\ndarknets. To browse through darknets websites special authorization or specific\nsoftware and configurations are needed. Despite TOR is the most used darknet\nnowadays, there are other alternatives such as I2P or Freenet, which offer\ndifferent features for end users. In this work, we perform an analysis of the\nconnectivity of websites in the I2P network (named eepsites) aimed to discover\nif different patterns and relationships from those used in legacy web are\nfollowed in I2P, and also to get insights about its dimension and structure.\nFor that, a novel tool is specifically developed by the authors and deployed on\na distributed scenario. Main results conclude the decentralized nature of the\nI2P network, where there is a structural part of interconnected eepsites while\nother several nodes are isolated probably due to their intermittent presence in\nthe network.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 20:35:42 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Mag\u00e1n-Carri\u00f3n", "Roberto", ""], ["Abell\u00e1n-Galera", "Alberto", ""], ["Maci\u00e1-Fern\u00e1ndez", "Gabriel", ""], ["Garc\u00eda-Teodoro", "Pedro", ""]]}, {"id": "2101.03241", "submitter": "Jaap-Henk Hoepman", "authors": "Jaap-Henk Hoepman", "title": "Hansel and Gretel and the Virus: Privacy Conscious Contact Tracing", "comments": "29 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Digital contact tracing has been proposed to support the health authorities\nin fighting the current Covid-19 pandemic. In this paper we propose two\ncentralised protocols for digital contact tracing that, contrary to the common\nhypothesis that this is an inherent risk, do not allow (retroactive) tracking\nof the location of a device over time. The first protocol does not rely on\nsynchronised clocks. The second protocol does not require a handshake between\ntwo devices, at the expense of relying on real-time communication with a\ncentral server. We stress that digital contact tracing is a form of\ntechnological solutionism that should be used with care, especially given the\ninherent mass surveillance nature of such systems.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2021 22:43:03 GMT"}, {"version": "v2", "created": "Sun, 21 Feb 2021 21:46:54 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Hoepman", "Jaap-Henk", ""]]}, {"id": "2101.03300", "submitter": "Hang Chen", "authors": "Hang Chen, Syed Ali Asif, Jihong Park, Chien-Chung Shen, Mehdi Bennis", "title": "Robust Blockchained Federated Learning with Model Validation and\n  Proof-of-Stake Inspired Consensus", "comments": "8 pages, 7 figures, AAAI 2021 Workshop - Towards Robust, Secure and\n  Efficient Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a promising distributed learning solution that\nonly exchanges model parameters without revealing raw data. However, the\ncentralized architecture of FL is vulnerable to the single point of failure. In\naddition, FL does not examine the legitimacy of local models, so even a small\nfraction of malicious devices can disrupt global training. To resolve these\nrobustness issues of FL, in this paper, we propose a blockchain-based\ndecentralized FL framework, termed VBFL, by exploiting two mechanisms in a\nblockchained architecture. First, we introduced a novel decentralized\nvalidation mechanism such that the legitimacy of local model updates is\nexamined by individual validators. Second, we designed a dedicated\nproof-of-stake consensus mechanism where stake is more frequently rewarded to\nhonest devices, which protects the legitimate local model updates by increasing\ntheir chances of dictating the blocks appended to the blockchain. Together,\nthese solutions promote more federation within legitimate devices, enabling\nrobust FL. Our emulation results of the MNIST classification corroborate that\nwith 15% of malicious devices, VBFL achieves 87% accuracy, which is 7.4x higher\nthan Vanilla FL.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jan 2021 06:30:38 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Chen", "Hang", ""], ["Asif", "Syed Ali", ""], ["Park", "Jihong", ""], ["Shen", "Chien-Chung", ""], ["Bennis", "Mehdi", ""]]}, {"id": "2101.03403", "submitter": "Xiaoyang Gong", "authors": "Xiaoyang Gong, Dan Negrut", "title": "CryptoEmu: An Instruction Set Emulator for Computation Over Ciphers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fully homomorphic encryption (FHE) allows computations over encrypted data.\nThis technique makes privacy-preserving cloud computing a reality. Users can\nsend their encrypted sensitive data to a cloud server, get encrypted results\nreturned and decrypt them, without worrying about data breaches.\n  This project report presents a homomorphic instruction set emulator,\nCryptoEmu, that enables fully homomorphic computation over encrypted data. The\nsoftware-based instruction set emulator is built upon an open-source,\nstate-of-the-art homomorphic encryption library that supports gate-level\nhomomorphic evaluation. The instruction set architecture supports multiple\ninstructions that belong to the subset of ARMv8 instruction set architecture.\nThe instruction set emulator utilizes parallel computing techniques to emulate\nevery functional unit for minimum latency. This project report includes details\non design considerations, instruction set emulator architecture, and datapath\nand control unit implementation. We evaluated and demonstrated the instruction\nset emulator's performance and scalability on a 48-core workstation. CryptoEmu\nhas shown a significant speedup in homomorphic computation performance when\ncompared with HELib, a state-of-the-art homomorphic encryption library.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jan 2021 18:05:46 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Gong", "Xiaoyang", ""], ["Negrut", "Dan", ""]]}, {"id": "2101.03564", "submitter": "Hakan Kayan Mr.", "authors": "Hakan Kayan and Matthew Nunes and Omer Rana and Pete Burnap and\n  Charith Perera", "title": "Cybersecurity of Industrial Cyber-Physical Systems: A Review", "comments": "32 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industrial cyber-physical systems (ICPSs) manage critical infrastructures by\ncontrolling the processes based on the \"physics\" data gathered by edge sensor\nnetworks. Recent innovations in ubiquitous computing and communication\ntechnologies have prompted the rapid integration of highly interconnected\nsystems to ICPSs. Hence, the \"security by obscurity\" principle provided by\nair-gapping is no longer followed. As the interconnectivity in ICPSs increases,\nso does the attack surface. Industrial vulnerability assessment reports have\nshown that a variety of new vulnerabilities have occurred due to this\ntransition while the most common ones are related to weak boundary protection.\nAlthough there are existing surveys in this context, very little is mentioned\nregarding these reports. This paper bridges this gap by defining and reviewing\nICPSs from a cybersecurity perspective. In particular, multi-dimensional\nadaptive attack taxonomy is presented and utilized for evaluating real-life\nICPS cyber incidents. We also identify the general shortcomings and highlight\nthe points that cause a gap in existing literature while defining future\nresearch directions.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jan 2021 15:15:18 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Kayan", "Hakan", ""], ["Nunes", "Matthew", ""], ["Rana", "Omer", ""], ["Burnap", "Pete", ""], ["Perera", "Charith", ""]]}, {"id": "2101.03577", "submitter": "Nayana Das", "authors": "Nayana Das, Goutam Paul, Ritajit Majumdar", "title": "Quantum Secure Direct Communication with Mutual Authentication using a\n  Single Basis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new theoretical scheme for quantum secure direct\ncommunication (QSDC) with user authentication. Different from the previous QSDC\nprotocols, the present protocol uses only one orthogonal basis of single-qubit\nstates to encode the secret message. Moreover, this is a one-time and one-way\ncommunication protocol, which uses qubits prepared in a randomly chosen\narbitrary basis, to transmit the secret message. We discuss the security of the\nproposed protocol against some common attacks and show that no eaves-dropper\ncan get any information from the quantum and classical channels. We have also\nstudied the performance of this protocol under realistic device noise. We have\nexecuted the protocol in IBMQ Armonk device and proposed a repetition code\nbased protection scheme that requires minimal overhead.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jan 2021 16:32:42 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 11:27:55 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Das", "Nayana", ""], ["Paul", "Goutam", ""], ["Majumdar", "Ritajit", ""]]}, {"id": "2101.03715", "submitter": "Zhuolun Xiang", "authors": "Zhuolun Xiang, Dahlia Malkhi, Kartik Nayak, Ling Ren", "title": "Strengthened Fault Tolerance in Byzantine Fault Tolerant Replication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Byzantine fault tolerant (BFT) state machine replication (SMR) is an\nimportant building block for constructing permissioned blockchain systems. In\ncontrast to Nakamoto Consensus where any block obtains higher assurance as\nburied deeper in the blockchain, in BFT SMR, any committed block is secure has\na fixed resilience threshold. In this paper, we investigate strengthened fault\ntolerance (SFT) in BFT SMR under partial synchrony, which provides gradually\nincreased resilience guarantees (like Nakamoto Consensus) during an optimistic\nperiod when the network is synchronous and the number of Byzantine faults is\nsmall. Moreover, the committed blocks can tolerate more than one-third (up to\ntwo-thirds) corruptions even after the optimistic period. Compared to the prior\nbest solution Flexible BFT which requires quadratic message complexity, our\nsolution maintains the linear message complexity of state-of-the-art BFT SMR\nprotocols and requires only marginal bookkeeping overhead. We implement our\nsolution over the open-source Diem project, and give experimental results that\ndemonstrate its efficiency under real-world scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 05:55:44 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Xiang", "Zhuolun", ""], ["Malkhi", "Dahlia", ""], ["Nayak", "Kartik", ""], ["Ren", "Ling", ""]]}, {"id": "2101.03736", "submitter": "Maanak Gupta", "authors": "Maanak Gupta and Ravi Sandhu", "title": "Reachability Analysis for Attributes in ABAC with Group Hierarchy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribute-based access control (ABAC) models are widely used to provide\nfine-grained and adaptable authorization based on the attributes of users,\nresources, and other relevant entities. Hierarchial group and attribute based\naccess control (HGABAC) model was recently proposed which introduces the novel\nnotion of attribute inheritance through group membership. GURAG was\nsubsequently proposed to provide an administrative model for user attributes in\nHGABAC, building upon the ARBAC97 and GURA administrative models. The GURA\nmodel uses administrative roles to manage user attributes. The reachability\nproblem for the GURA model is to determine what attributes a particular user\ncan acquire, given a predefined set of administrative rules. This problem has\nbeen previously analyzed in the literature. In this paper, we study the user\nattribute reachability problem based on directly assigned attributes of the\nuser and attributes inherited via group memberships. We first define a\nrestricted form of GURAG, called rGURAG scheme, as a state transition system\nwith multiple instances having different preconditions and provide reachability\nanalysis for each of these schemes. In general, we show PSPACE-complete\ncomplexity for all rGURAG schemes. We further present polynomial time\nalgorithms to solve special instances of rGURAG schemes under restricted\nconditions.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 07:47:40 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Gupta", "Maanak", ""], ["Sandhu", "Ravi", ""]]}, {"id": "2101.03840", "submitter": "Hao Wang", "authors": "Qing Yang, Hao Wang", "title": "Privacy-Preserving Transactive Energy Management for IoT-aided Smart\n  Homes via Blockchain", "comments": null, "journal-ref": "IEEE Internet of Things Journal, 2021", "doi": "10.1109/JIOT.2021.3051323", "report-no": null, "categories": "eess.SY cs.CR cs.DC cs.SY math.OC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the booming of smart grid, The ubiquitously deployed smart meters\nconstitutes an energy internet of things. This paper develops a novel\nblockchain-based transactive energy management system for IoT-aided smart\nhomes. We consider a holistic set of options for smart homes to participate in\ntransactive energy. Smart homes can interact with the grid to perform vertical\ntransactions, e.g., feeding in extra solar energy to the grid and providing\ndemand response service to alleviate the grid load. Smart homes can also\ninteract with peer users to perform horizontal transactions, e.g., peer-to-peer\nenergy trading. However, conventional transactive energy management method\nsuffers from the drawbacks of low efficiency, privacy leakage, and single-point\nfailure. To address these challenges, we develop a privacy-preserving\ndistributed algorithm that enables users to optimally manage their energy\nusages in parallel via the smart contract on the blockchain. Further, we design\nan efficient blockchain system tailored for IoT devices and develop the smart\ncontract to support the holistic transactive energy management system. Finally,\nwe evaluate the feasibility and performance of the blockchain-based transactive\nenergy management system through extensive simulations and experiments. The\nresults show that the blockchain-based transactive energy management system is\nfeasible on practical IoT devices and reduces the overall cost by 25%.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 12:21:55 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 13:18:12 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Yang", "Qing", ""], ["Wang", "Hao", ""]]}, {"id": "2101.03844", "submitter": "Omar Javed Mr", "authors": "Omar Javed and Salman Toor", "title": "Understanding the Quality of Container Security Vulnerability Detection\n  Tools", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Virtualization enables information and communications technology industry to\nbetter manage computing resources. In this regard, improvements in\nvirtualization approaches together with the need for consistent runtime\nenvironment, lower overhead and smaller package size has led to the growing\nadoption of containers. This is a technology, which packages an application,\nits dependencies and Operating System (OS) to run as an isolated unit. However,\nthe pressing concern with the use of containers is its susceptibility to\nsecurity attacks. Consequently, a number of container scanning tools are\navailable for detecting container security vulnerabilities. Therefore, in this\nstudy, we investigate the quality of existing container scanning tools by\nproposing two metrics that reflects coverage and accuracy. We analyze 59\npopular public container images for Java applications hosted on DockerHub using\ndifferent container scanning tools (such as Clair, Anchore, and Microscanner).\nOur findings show that existing container scanning approach does not detect\napplication package vulnerabilities. Furthermore, existing tools do not have\nhigh accuracy, since 34% vulnerabilities are being missed by the best\nperforming tool. Finally, we also demonstrate quality of Docker images for Java\napplications hosted on DockerHub by assessing complete vulnerability landscape\ni.e., number of vulnerabilities detected in images.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 12:27:42 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Javed", "Omar", ""], ["Toor", "Salman", ""]]}, {"id": "2101.03965", "submitter": "Wenhao Fan Prof.", "authors": "Wenhao fan, Liang Zhao, Jiayang Wang, Ye Chen, Fan Wu, Yuan'an Liu", "title": "FamDroid: Learning-Based Android Malware Family Classification Using\n  Static Analysis", "comments": "This manuscript has been submitted to Neurocomputing and is currently\n  under its consideration for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Android is currently the most extensively used smartphone platform in the\nworld. Due to its popularity and open source nature, Android malware has been\nrapidly growing in recent years, and bringing great risks to users' privacy.\nThe malware applications in a malware family may have common features and\nsimilar behaviors, which are beneficial for malware detection and inspection.\nThus, classifying Android malware into their corresponding families is an\nimportant task in malware analysis. At present, the main problem of existing\nresearch works on Android malware family classification lies in that the\nextracted features are inadequate to represent the common behavior\ncharacteristics of the malware in malicious families, and leveraging a single\nclassifier or a static ensemble classifier is restricted to further improve the\naccuracy of classification. In this paper, we propose FamDroid, a\nlearning-based Android malware family classification scheme using static\nanalysis technology. In FamDroid, the explicit features including permissions,\nhardware components, app components, intent filters are extracted from the apk\nfiles of a malware application. Besides, a hidden feature generated from the\nextracted APIs is used to represents the API call relationship in the\napplication. Then, we design an adaptive weighted ensemble classifier, which\nconsiders the adaptability of the sample to each base classifier, to carry out\naccurate malware family classification. We conducted experiments on the Drebin\ndataset which contains 5560 Android malicious applications. The superiority of\nFamDroid is demonstrated through comparing it with 5 traditional machine\nlearning models and 4 state-of-the-art reference schemes. FamDroid can\ncorrectly classify 98.92% of malware samples into their families and achieve\n99.12% F1-Score.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 15:23:55 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 03:13:24 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["fan", "Wenhao", ""], ["Zhao", "Liang", ""], ["Wang", "Jiayang", ""], ["Chen", "Ye", ""], ["Wu", "Fan", ""], ["Liu", "Yuan'an", ""]]}, {"id": "2101.04163", "submitter": "Yipeng Zhou", "authors": "Yao Fu, Yipeng Zhou, Di Wu, Shui Yu, Yonggang Wen, Chao Li", "title": "On the Practicality of Differential Privacy in Federated Learning by\n  Tuning Iteration Times", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite that Federated Learning (FL) is well known for its privacy\nprotection when training machine learning models among distributed clients\ncollaboratively, recent studies have pointed out that the naive FL is\nsusceptible to gradient leakage attacks. In the meanwhile, Differential Privacy\n(DP) emerges as a promising countermeasure to defend against gradient leakage\nattacks. However, the adoption of DP by clients in FL may significantly\njeopardize the model accuracy. It is still an open problem to understand the\npracticality of DP from a theoretic perspective. In this paper, we make the\nfirst attempt to understand the practicality of DP in FL through tuning the\nnumber of conducted iterations. Based on the FedAvg algorithm, we formally\nderive the convergence rate with DP noises in FL. Then, we theoretically\nderive: 1) the conditions for the DP based FedAvg to converge as the number of\nglobal iterations (GI) approaches infinity; 2) the method to set the number of\nlocal iterations (LI) to minimize the negative influence of DP noises. By\nfurther substituting the Laplace and Gaussian mechanisms into the derived\nconvergence rate respectively, we show that: 3) The DP based FedAvg with the\nLaplace mechanism cannot converge, but the divergence rate can be effectively\nprohibited by setting the number of LIs with our method; 4) The learning error\nof the DP based FedAvg with the Gaussian mechanism can converge to a constant\nnumber finally if we use a fixed number of LIs per GI. To verify our\ntheoretical findings, we conduct extensive experiments using two real-world\ndatasets. The results not only validate our analysis results, but also provide\nuseful guidelines on how to optimize model accuracy when incorporating DP into\nFL\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 19:43:12 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Fu", "Yao", ""], ["Zhou", "Yipeng", ""], ["Wu", "Di", ""], ["Yu", "Shui", ""], ["Wen", "Yonggang", ""], ["Li", "Chao", ""]]}, {"id": "2101.04173", "submitter": "Reza Fotohi", "authors": "Monir Shaker, Fereidoon Shams Aliee and Reza Fotohi", "title": "Online rating system development using blockchain-based distributed\n  ledger technology", "comments": "25 figures, 5 tables, Journal Wireless Netw (2021)", "journal-ref": null, "doi": "10.1007/s11276-020-02514-w", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In most websites, the online rating system provides the ratings of products\nand services to users. Lack of trust in data integrity and its manipulation has\nhindered fulfilling user satisfaction. Since existing online rating systems\ndeal with a central server, all rating data is stored on the central server.\nTherefore, all rating data can be removed, modified, and manipulated by the\nsystem manager to change the ratings in favor of the service or product\nprovider. In this paper, an online rating system using distributed ledger\ntechnologies has been presented as the proposed system to solve all the\nweaknesses of current systems. Distributed ledger technologies are completely\ndecentralized and there is no centralization on them by any institution.\nDistributed ledger technologies have different variants. Among distributed\nledger technologies, blockchain technology has been used in the proposed rating\nsystem because of its support for smart contracts. In the proposed online\nrating system, the Ethereum platform has been chosen from different blockchain\nplatforms that have a public permission network. In this system, the raters\ncannot rate unless they submit a request to the system and be authorized to\ntake part in the online product rating process. The important feature of the\nEthereum platform is its support for smart contracts, which can be used to\nwrite the rating contract in the Solidity language. Also, using Proof of\nAuthority consensus mechanisms, all rating transactions are approved by the\nsurveyors. Since in the real Ethereum system, each rating transaction is sent\nto the network by the raters, some gas must be paid for each rating\ntransaction. However, since this method is expensive, TestNet blockchain can be\nused in the rating system. Finally, the proposed rating system was used for\nrating the restaurants of a website and its features were tested.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 20:23:05 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Shaker", "Monir", ""], ["Aliee", "Fereidoon Shams", ""], ["Fotohi", "Reza", ""]]}, {"id": "2101.04194", "submitter": "Jenn-Bing Ong", "authors": "Jenn-Bing Ong, Wee-Keong Ng, Ivan Tjuawinata, Chao Li, Jielin Yang,\n  Sai None Myne, Huaxiong Wang, Kwok-Yan Lam, C.-C. Jay Kuo", "title": "Protecting Big Data Privacy Using Randomized Tensor Network\n  Decomposition and Dispersed Tensor Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data privacy is an important issue for organizations and enterprises to\nsecurely outsource data storage, sharing, and computation on clouds / fogs.\nHowever, data encryption is complicated in terms of the key management and\ndistribution; existing secure computation techniques are expensive in terms of\ncomputational / communication cost and therefore do not scale to big data\ncomputation. Tensor network decomposition and distributed tensor computation\nhave been widely used in signal processing and machine learning for\ndimensionality reduction and large-scale optimization. However, the potential\nof distributed tensor networks for big data privacy preservation have not been\nconsidered before, this motivates the current study. Our primary intuition is\nthat tensor network representations are mathematically non-unique, unlinkable,\nand uninterpretable; tensor network representations naturally support a range\nof multilinear operations for compressed and distributed / dispersed\ncomputation. Therefore, we propose randomized algorithms to decompose big data\ninto randomized tensor network representations and analyze the privacy leakage\nfor 1D to 3D data tensors. The randomness mainly comes from the complex\nstructural information commonly found in big data; randomization is based on\ncontrolled perturbation applied to the tensor blocks prior to decomposition.\nThe distributed tensor representations are dispersed on multiple clouds / fogs\nor servers / devices with metadata privacy, this provides both distributed\ntrust and management to seamlessly secure big data storage, communication,\nsharing, and computation. Experiments show that the proposed randomization\ntechniques are helpful for big data anonymization and efficient for big data\nstorage and computation.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 22:14:52 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Ong", "Jenn-Bing", ""], ["Ng", "Wee-Keong", ""], ["Tjuawinata", "Ivan", ""], ["Li", "Chao", ""], ["Yang", "Jielin", ""], ["Myne", "Sai None", ""], ["Wang", "Huaxiong", ""], ["Lam", "Kwok-Yan", ""], ["Kuo", "C. -C. Jay", ""]]}, {"id": "2101.04244", "submitter": "Mohammed Bahutair Mr.", "authors": "Mohammed Bahutair, Athman Bouguettaya, and Azadeh Ghari Neiat", "title": "Multi-Perspective Trust Management Framework for Crowdsourced IoT\n  Services", "comments": "14 pages, accepted and to appear in IEEE Ttransactions on Services\n  Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel generic trust management framework for crowdsourced IoT\nservices. The framework exploits a multi-perspective trust model that captures\nthe inherent characteristics of crowdsourced IoT services. Each perspective is\ndefined by a set of attributes that contribute to the perspective's influence\non trust. The attributes are fed into a machine-learning-based algorithm to\ngenerate a trust model for crowdsourced services in IoT environments. We\ndemonstrate the effectiveness of our approach by conducting experiments on\nreal-world datasets.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 00:43:12 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Bahutair", "Mohammed", ""], ["Bouguettaya", "Athman", ""], ["Neiat", "Azadeh Ghari", ""]]}, {"id": "2101.04319", "submitter": "Alsharif Abuadbba Dr", "authors": "Alsharif Abuadbba, Hyoungshick Kim, Surya Nepal", "title": "DeepiSign: Invisible Fragile Watermark to Protect the Integrityand\n  Authenticity of CNN", "comments": "The 36th ACM SIGAPP Symposium on Applied Computing (ACM SAC)", "journal-ref": null, "doi": "10.1145/3412841.3441970", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Convolutional Neural Networks (CNNs) deployed in real-life applications such\nas autonomous vehicles have shown to be vulnerable to manipulation attacks,\nsuch as poisoning attacks and fine-tuning. Hence, it is essential to ensure the\nintegrity and authenticity of CNNs because compromised models can produce\nincorrect outputs and behave maliciously. In this paper, we propose a\nself-contained tamper-proofing method, called DeepiSign, to ensure the\nintegrity and authenticity of CNN models against such manipulation attacks.\nDeepiSign applies the idea of fragile invisible watermarking to securely embed\na secret and its hash value into a CNN model. To verify the integrity and\nauthenticity of the model, we retrieve the secret from the model, compute the\nhash value of the secret, and compare it with the embedded hash value. To\nminimize the effects of the embedded secret on the CNN model, we use a\nwavelet-based technique to transform weights into the frequency domain and\nembed the secret into less significant coefficients. Our theoretical analysis\nshows that DeepiSign can hide up to 1KB secret in each layer with minimal loss\nof the model's accuracy. To evaluate the security and performance of DeepiSign,\nwe performed experiments on four pre-trained models (ResNet18, VGG16, AlexNet,\nand MobileNet) using three datasets (MNIST, CIFAR-10, and Imagenet) against\nthree types of manipulation attacks (targeted input poisoning, output\npoisoning, and fine-tuning). The results demonstrate that DeepiSign is\nverifiable without degrading the classification accuracy, and robust against\nrepresentative CNN manipulation attacks.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 06:42:45 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Abuadbba", "Alsharif", ""], ["Kim", "Hyoungshick", ""], ["Nepal", "Surya", ""]]}, {"id": "2101.04338", "submitter": "Geong Sen Poh", "authors": "Geong Sen Poh, Dinil Mon Divakaran, Hoon Wei Lim, Jianting Ning,\n  Achintya Desai", "title": "A Survey of Privacy-Preserving Techniques for Encrypted Traffic\n  Inspection over Network Middleboxes", "comments": "17 pages, 8 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Middleboxes in a computer network system inspect and analyse network traffic\nto detect malicious communications, monitor system performance and provide\noperational services. However, encrypted traffic hinders the ability of\nmiddleboxes to perform such services. A common practice in addressing this\nissue is by employing a \"Man-in-the-Middle\" (MitM) approach, wherein an\nencrypted traffic flow between two endpoints is interrupted, decrypted and\nanalysed by the middleboxes. The MitM approach is straightforward and is used\nby many organisations, but there are both practical and privacy concerns. Due\nto the cost of the MitM appliances and the latency incurred in the\nencrypt-decrypt processes, enterprises continue to seek solutions that are less\ncostly. There were discussion on the many efforts required to configure MitM.\nBesides, MitM violates end-to-end privacy guarantee, raising privacy concerns\nand issues on compliance especially with the rising awareness on user privacy.\nFurthermore, some of the MitM implementations were found to be flawed.\nConsequently, new practical and privacy-preserving techniques for inspection\nover encrypted traffic were proposed. We examine them to compare their\nadvantages, limitations and challenges. We categorise them into four main\ncategories by defining a framework that consist of system architectures, use\ncases, trust and threat models. These are searchable encryption, access\ncontrol, machine learning and trusted hardware. We first discuss the\nman-in-the-middle approach as a baseline, then discuss in details each of them,\nand provide an in-depth comparisons of their advantages and limitations. By\ndoing so we describe practical constraints, advantages and pitfalls towards\nadopting the techniques. We also give insights on the gaps between research\nwork and industrial deployment, which leads us to the discussion on the\nchallenges and research directions.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 07:59:39 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Poh", "Geong Sen", ""], ["Divakaran", "Dinil Mon", ""], ["Lim", "Hoon Wei", ""], ["Ning", "Jianting", ""], ["Desai", "Achintya", ""]]}, {"id": "2101.04401", "submitter": "Yujin Huang", "authors": "Yujin Huang, Han Hu, Chunyang Chen", "title": "Robustness of on-device Models: Adversarial Attack to Deep Learning\n  Models on Android Apps", "comments": "Accepted to the 43rd International Conference on Software\n  Engineering, Software Engineering in Practice Track. This is a preprint\n  version, the copyright belongs to The Institute of Electrical and Electronics\n  Engineers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has shown its power in many applications, including object\ndetection in images, natural-language understanding, and speech recognition. To\nmake it more accessible to end users, many deep learning models are now\nembedded in mobile apps. Compared to offloading deep learning from smartphones\nto the cloud, performing machine learning on-device can help improve latency,\nconnectivity, and power consumption. However, most deep learning models within\nAndroid apps can easily be obtained via mature reverse engineering, while the\nmodels' exposure may invite adversarial attacks. In this study, we propose a\nsimple but effective approach to hacking deep learning models using adversarial\nattacks by identifying highly similar pre-trained models from TensorFlow Hub.\nAll 10 real-world Android apps in the experiment are successfully attacked by\nour approach. Apart from the feasibility of the model attack, we also carry out\nan empirical study that investigates the characteristics of deep learning\nmodels used by hundreds of Android apps on Google Play. The results show that\nmany of them are similar to each other and widely use fine-tuning techniques to\npre-trained models on the Internet.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 10:49:30 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 13:39:00 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Huang", "Yujin", ""], ["Hu", "Han", ""], ["Chen", "Chunyang", ""]]}, {"id": "2101.04427", "submitter": "Amoldeep Singh Mr.", "authors": "Amoldeep Singh, Kapal Dev, Harun Siljak, Hem Dutt Joshi and Maurizio\n  Magarini", "title": "Quantum Internet- Applications, Functionalities, Enabling Technologies,\n  Challenges, and Research Directions", "comments": "This survey paper is submitted in IEEE Communications Surveys and\n  Tutorials and revised on 27th May 2021. It includes 31 pages, 14 figures, and\n  5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The advanced notebooks, mobile phones, and internet applications in today's\nworld that we use are all entrenched in classical communication bits of zeros\nand ones. Classical internet has laid its foundation originating from the\namalgamation of mathematics and Claude Shannon's theory of information. But\ntoday's internet technology is a playground for eavesdroppers. This poses a\nserious challenge to various applications that relies on classical internet\ntechnology. This has motivated the researchers to switch to new technologies\nthat are fundamentally more secure. Exploring the quantum effects, researchers\npaved the way into quantum networks that provide security, privacy and range of\ncapabilities such as quantum computation, communication and metrology. The\nrealization of quantum internet requires quantum communication between various\nremote nodes through quantum channels guarded by quantum cryptographic\nprotocols. Such networks rely upon quantum bits (qubits) that can\nsimultaneously take the value of zeros and ones. Due to extraordinary\nproperties of qubits such as entanglement, teleportation and superposition, it\ngives an edge to quantum networks over traditional networks in many ways. But\nat the same time transmitting qubits over long distances is a formidable task\nand extensive research is going on quantum teleportation over such distances,\nwhich will become a breakthrough in physically realizing quantum internet in\nnear future. In this paper, quantum internet functionalities, technologies,\napplications and open challenges have been extensively surveyed to help readers\ngain a basic understanding of infrastructure required for the development of\nglobal quantum internet.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 11:57:04 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 17:03:20 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Singh", "Amoldeep", ""], ["Dev", "Kapal", ""], ["Siljak", "Harun", ""], ["Joshi", "Hem Dutt", ""], ["Magarini", "Maurizio", ""]]}, {"id": "2101.04535", "submitter": "Milad Nasr", "authors": "Milad Nasr, Shuang Song, Abhradeep Thakurta, Nicolas Papernot and\n  Nicholas Carlini", "title": "Adversary Instantiation: Lower Bounds for Differentially Private Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Differentially private (DP) machine learning allows us to train models on\nprivate data while limiting data leakage. DP formalizes this data leakage\nthrough a cryptographic game, where an adversary must predict if a model was\ntrained on a dataset D, or a dataset D' that differs in just one example.If\nobserving the training algorithm does not meaningfully increase the adversary's\nodds of successfully guessing which dataset the model was trained on, then the\nalgorithm is said to be differentially private. Hence, the purpose of privacy\nanalysis is to upper bound the probability that any adversary could\nsuccessfully guess which dataset the model was trained on.In our paper, we\ninstantiate this hypothetical adversary in order to establish lower bounds on\nthe probability that this distinguishing game can be won. We use this adversary\nto evaluate the importance of the adversary capabilities allowed in the privacy\nanalysis of DP training algorithms.For DP-SGD, the most common method for\ntraining neural networks with differential privacy, our lower bounds are tight\nand match the theoretical upper bound. This implies that in order to prove\nbetter upper bounds, it will be necessary to make use of additional\nassumptions. Fortunately, we find that our attacks are significantly weaker\nwhen additional (realistic)restrictions are put in place on the adversary's\ncapabilities.Thus, in the practical setting common to many real-world\ndeployments, there is a gap between our lower bounds and the upper bounds\nprovided by the analysis: differential privacy is conservative and adversaries\nmay not be able to leak as much information as suggested by the theoretical\nbound.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2021 18:47:11 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Nasr", "Milad", ""], ["Song", "Shuang", ""], ["Thakurta", "Abhradeep", ""], ["Papernot", "Nicolas", ""], ["Carlini", "Nicholas", ""]]}, {"id": "2101.04556", "submitter": "Manjesh Kumar Hanawal", "authors": "Vinod S. Khandkar and Manjesh K. Hanawal", "title": "Masking Host Identity on Internet: Encrypted TLS/SSL Handshake", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Network middle-boxes often classify the traffic flows on the Internet to\nperform traffic management or discriminate one traffic against the other. As\nthe widespread adoption of HTTPS protocol has made it difficult to classify the\ntraffic looking into the content field, one of the fields the middle-boxes look\nfor is Server Name Indicator (SNI), which goes in plain text. SNI field\ncontains information about the host and can, in turn, reveal the type of\ntraffic. This paper presents a method to mask the server host identity by\nencrypting the SNI. We develop a simple method that completes the SSL/TLS\nconnection establishment over two handshakes - the first handshake establishes\na secure channel without sharing SNI information, and the second handshake\nshares the encrypted SNI. Our method makes it mandatory for fronting servers to\nalways accept the handshake request without the SNI and respond with a valid\nSSL certificate.\n  As there is no modification in already proven SSL/TLS encryption mechanism\nand processing of handshake messages, the new method enjoys all security\nbenefits of existing secure channel establishment and needs no modification in\nexisting routers/middle-boxes. Using customized client-server over the live\nInternet, we demonstrate the feasibility of our method. Moreover, the impact\nanalysis shows that the method adheres to almost all SSL/TLS related Internet\nstandards requirements.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 15:48:36 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Khandkar", "Vinod S.", ""], ["Hanawal", "Manjesh K.", ""]]}, {"id": "2101.04575", "submitter": "Georgios Karopoulos", "authors": "Jos\\'e Luis Hern\\'andez-Ramos, Georgios Karopoulos, Dimitris\n  Geneiatakis, Tania Martin, Georgios Kambourakis, and Igor Nai Fovino", "title": "Sharing pandemic vaccination certificates through blockchain: Case study\n  and performance evaluation", "comments": "10 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a scalable, blockchain-based platform for the secure\nsharing of COVID-19 or other disease vaccination certificates. As an indicative\nuse case, we simulate a large-scale deployment by considering the countries of\nthe European Union. The proposed platform is evaluated through extensive\nsimulations in terms of computing resource usage, network response time and\nbandwidth. Based on the results, the proposed scheme shows satisfactory\nperformance across all major evaluation criteria, suggesting that it can set\nthe pace for real implementations. Vis-\\`a-vis the related work, the proposed\nplatform is novel, especially through the prism of a large-scale, full-fledged\nimplementation and its assessment.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 16:10:10 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Hern\u00e1ndez-Ramos", "Jos\u00e9 Luis", ""], ["Karopoulos", "Georgios", ""], ["Geneiatakis", "Dimitris", ""], ["Martin", "Tania", ""], ["Kambourakis", "Georgios", ""], ["Fovino", "Igor Nai", ""]]}, {"id": "2101.04645", "submitter": "Jan-Philipp Schulze", "authors": "J.-P. Schulze, P. Sperl, K. B\\\"ottinger", "title": "Double-Adversarial Activation Anomaly Detection: Adversarial\n  Autoencoders are Anomaly Generators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is a challenging task for machine learning algorithms due\nto the inherent class imbalance. It is costly and time-demanding to manually\nanalyse the observed data, thus usually only few known anomalies if any are\navailable. Inspired by generative models and the analysis of the hidden\nactivations of neural networks, we introduce a novel unsupervised anomaly\ndetection method called DA3D. Here, we use adversarial autoencoders to generate\nanomalous counterexamples based on the normal data only. These artificial\nanomalies used during training allow the detection of real, yet unseen\nanomalies. With our novel generative approach, we transform the unsupervised\ntask of anomaly detection to a supervised one, which is more tractable by\nmachine learning and especially deep learning methods. DA3D surpasses the\nperformance of state-of-the-art anomaly detection methods in a purely\ndata-driven way, where no domain knowledge is required.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 18:07:34 GMT"}, {"version": "v2", "created": "Sun, 4 Apr 2021 17:05:36 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Schulze", "J. -P.", ""], ["Sperl", "P.", ""], ["B\u00f6ttinger", "K.", ""]]}, {"id": "2101.04718", "submitter": "Kristopher Micinski", "authors": "Yihao Sun, Jeffrey Ching, Kristopher Micinski", "title": "Declarative Demand-Driven Reverse Engineering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary reverse engineering is a challenging task because it often\nnecessitates reasoning using both domain-specific knowledge (e.g.,\nunderstanding entrypoint idioms common to an ABI) and logical inference (e.g.,\nreconstructing interprocedural control flow). To help perform these tasks,\nreverse engineers often use toolkits (such as IDA Pro or Ghidra) that allow\nthem to interactively explicate properties of binaries. We argue that deductive\ndatabases serve as a natural abstraction for interfacing between\nvisualization-based binary analysis tools and high-performance logical\ninference engines that compute facts about binaries. In this paper, we present\na vision for the future in which reverse engineers use a visualization-based\ntool to understand binaries while simultaneously querying a logical-inference\nengine to perform arbitrarily-complex deductive inference tasks. We call our\nvision declarative demand-driven reverse engineering (D^3RE for short), and\nsketch a formal semantics whose goal is to mediate interaction between a\nlogical-inference engine (such Souffle) and a reverse engineering tool. We\ndescribe aprototype tool, d3re, which are using to explore the D^3RE vision.\nWhile still a prototype, we have used d3re to reimplement several common\nquerying tasks on binaries. Our evaluation demonstrates that d3re enables both\nbetter performance and more succinct implementation of these common RE tasks.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 19:41:45 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Sun", "Yihao", ""], ["Ching", "Jeffrey", ""], ["Micinski", "Kristopher", ""]]}, {"id": "2101.04766", "submitter": "Mahnush Movahedi", "authors": "Mahnush Movahedi, Benjamin M. Case, Andrew Knox, Li Li, Yiming Paul\n  Li, Sanjay Saravanan, Shubho Sengupta, Erik Taubeneck", "title": "Private Randomized Controlled Trials: A Protocol for Industry Scale\n  Deployment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we outline a way to deploy a privacy-preserving protocol for\nmultiparty Randomized Controlled Trials on the scale of 500 million rows of\ndata and more than a billion gates. Randomized Controlled Trials (RCTs) are\nwidely used to improve business and policy decisions in various sectors such as\nhealthcare, education, criminology, and marketing. A Randomized Controlled\nTrial is a scientifically rigorous method to measure the effectiveness of a\ntreatment. This is accomplished by randomly allocating subjects to two or more\ngroups, treating them differently, and then comparing the outcomes across\ngroups. In many scenarios, multiple parties hold different parts of the data\nfor conducting and analyzing RCTs. Given privacy requirements and expectations\nof each of these parties, it is often challenging to have a centralized store\nof data to conduct and analyze RCTs.\n  We accomplish this by a three-stage solution. The first stage uses the\nPrivate Secret Share Set Intersection (PS$^3$I) solution to create a joined set\nand establish secret shares without revealing membership, while discarding\nindividuals who were placed into more than one group. The second stage runs\nmultiple instances of a general purpose MPC over a sharded database to\naggregate statistics about each experimental group while discarding individuals\nwho took an action before they received treatment. The third stage adds\ndistributed and calibrated Differential Privacy (DP) noise to the aggregate\nstatistics and uncertainty measures, providing formal two-sided privacy\nguarantees.\n  We also evaluate the performance of multiple open source general purpose MPC\nlibraries for this task. We additionally demonstrate how we have used this to\ncreate a working ads effectiveness measurement product capable of measuring\nhundreds of millions of individuals per experiment.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 21:37:57 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Movahedi", "Mahnush", ""], ["Case", "Benjamin M.", ""], ["Knox", "Andrew", ""], ["Li", "Li", ""], ["Li", "Yiming Paul", ""], ["Saravanan", "Sanjay", ""], ["Sengupta", "Shubho", ""], ["Taubeneck", "Erik", ""]]}, {"id": "2101.04773", "submitter": "Yangyong Zhang", "authors": "Yangyong Zhang, Maliheh Shirvanian, Sunpreet S. Arora, Jianwei Huang,\n  and Guofei Gu", "title": "Practical Speech Re-use Prevention in Voice-driven Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.CR eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Voice-driven services (VDS) are being used in a variety of applications\nranging from smart home control to payments using digital assistants. The input\nto such services is often captured via an open voice channel, e.g., using a\nmicrophone, in an unsupervised setting. One of the key operational security\nrequirements in such setting is the freshness of the input speech. We present\nAEOLUS, a security overlay that proactively embeds a dynamic acoustic nonce at\nthe time of user interaction, and detects the presence of the embedded nonce in\nthe recorded speech to ensure freshness. We demonstrate that acoustic nonce can\n(i) be reliably embedded and retrieved, and (ii) be non-disruptive (and even\nimperceptible) to a VDS user. Optimal parameters (acoustic nonce's operating\nfrequency, amplitude, and bitrate) are determined for (i) and (ii) from a\npractical perspective. Experimental results show that AEOLUS yields 0.5% FRR at\n0% FAR for speech re-use prevention upto a distance of 4 meters in three\nreal-world environments with different background noise levels. We also conduct\na user study with 120 participants, which shows that the acoustic nonce does\nnot degrade overall user experience for 94.16% of speech samples, on average,\nin these environments. AEOLUS can therefore be used in practice to prevent\nspeech re-use and ensure the freshness of speech input.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 22:00:59 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Zhang", "Yangyong", ""], ["Shirvanian", "Maliheh", ""], ["Arora", "Sunpreet S.", ""], ["Huang", "Jianwei", ""], ["Gu", "Guofei", ""]]}, {"id": "2101.04829", "submitter": "Junyoung Byun", "authors": "Junyoung Byun, Hyojun Go, Changick Kim", "title": "Small Input Noise is Enough to Defend Against Query-based Black-box\n  Attacks", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep neural networks show unprecedented performance in various tasks,\nthe vulnerability to adversarial examples hinders their deployment in\nsafety-critical systems. Many studies have shown that attacks are also possible\neven in a black-box setting where an adversary cannot access the target model's\ninternal information. Most black-box attacks are based on queries, each of\nwhich obtains the target model's output for an input, and many recent studies\nfocus on reducing the number of required queries. In this paper, we pay\nattention to an implicit assumption of these attacks that the target model's\noutput exactly corresponds to the query input. If some randomness is introduced\ninto the model to break this assumption, query-based attacks may have\ntremendous difficulty in both gradient estimation and local search, which are\nthe core of their attack process. From this motivation, we observe even a small\nadditive input noise can neutralize most query-based attacks and name this\nsimple yet effective approach Small Noise Defense (SND). We analyze how SND can\ndefend against query-based black-box attacks and demonstrate its effectiveness\nagainst eight different state-of-the-art attacks with CIFAR-10 and ImageNet\ndatasets. Even with strong defense ability, SND almost maintains the original\nclean accuracy and computational speed. SND is readily applicable to\npre-trained models by adding only one line of code at the inference stage, so\nwe hope that it will be used as a baseline of defense against query-based\nblack-box attacks in the future.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 01:45:59 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Byun", "Junyoung", ""], ["Go", "Hyojun", ""], ["Kim", "Changick", ""]]}, {"id": "2101.04888", "submitter": "Rishiraj Bhattacharyya", "authors": "Rishiraj Bhattacharyya and Mridul Nandi and Anik Raychaudhuri", "title": "Crooked Indifferentiability Revisited", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In CRYPTO 2018, Russell et al introduced the notion of crooked\nindifferentiability to analyze the security of a hash function when the\nunderlying primitive is subverted. They showed that the $n$-bit to $n$-bit\nfunction implemented using enveloped XOR construction (\\textsf{EXor}) with\n$3n+1$ many $n$-bit functions and $3n^2$-bit random initial vectors (iv) can be\nproven secure asymptotically in the crooked indifferentiability setting.\n  -We identify several major issues and gaps in the proof by Russel et al, We\nshow that their proof can achieve security only when the adversary is\nrestricted to make queries related to a single message.\n  - We formalize new technique to prove crooked indifferentiability without\nsuch restrictions. Our technique can handle function dependent subversion. We\napply our technique to provide a revised proof for the \\textsf{EXor}\nconstruction.\n  - We analyze crooked indifferentiability of the classical sponge\nconstruction. We show, using a simple proof idea, the sponge construction is a\ncrooked-indifferentiable hash function using only $n$-bit random iv. This is a\nquadratic improvement over the {\\sf EXor} construction and solves the main open\nproblem of Russel et al.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 05:41:54 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 05:25:17 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Bhattacharyya", "Rishiraj", ""], ["Nandi", "Mridul", ""], ["Raychaudhuri", "Anik", ""]]}, {"id": "2101.04889", "submitter": "Yuzhou Lin", "authors": "Yuzhou Lin, Xiaolin Chang", "title": "Towards Interpretable Ensemble Learning for Image-based Malware\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) models for image-based malware detection have exhibited\ntheir capability in producing high prediction accuracy. But model\ninterpretability is posing challenges to their widespread application in\nsecurity and safety-critical application domains. This paper aims for designing\nan Interpretable Ensemble learning approach for image-based Malware Detection\n(IEMD). We first propose a Selective Deep Ensemble Learning-based (SDEL)\ndetector and then design an Ensemble Deep Taylor Decomposition (EDTD) approach,\nwhich can give the pixel-level explanation to SDEL detector outputs.\nFurthermore, we develop formulas for calculating fidelity, robustness and\nexpressiveness on pixel-level heatmaps in order to assess the quality of EDTD\nexplanation. With EDTD explanation, we develop a novel Interpretable Dropout\napproach (IDrop), which establishes IEMD by training SDEL detector. Experiment\nresults exhibit the better explanation of our EDTD than the previous\nexplanation methods for image-based malware detection. Besides, experiment\nresults indicate that IEMD achieves a higher detection accuracy up to 99.87%\nwhile exhibiting interpretability with high quality of prediction results.\nMoreover, experiment results indicate that IEMD interpretability increases with\nthe increasing detection accuracy during the construction of IEMD. This\nconsistency suggests that IDrop can mitigate the tradeoff between model\ninterpretability and detection accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 05:46:44 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Lin", "Yuzhou", ""], ["Chang", "Xiaolin", ""]]}, {"id": "2101.04898", "submitter": "Hanxun Huang", "authors": "Hanxun Huang, Xingjun Ma, Sarah Monazam Erfani, James Bailey, Yisen\n  Wang", "title": "Unlearnable Examples: Making Personal Data Unexploitable", "comments": "ICLR2021, In International Conference on Learning Representations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The volume of \"free\" data on the internet has been key to the current success\nof deep learning. However, it also raises privacy concerns about the\nunauthorized exploitation of personal data for training commercial models. It\nis thus crucial to develop methods to prevent unauthorized data exploitation.\nThis paper raises the question: \\emph{can data be made unlearnable for deep\nlearning models?} We present a type of \\emph{error-minimizing} noise that can\nindeed make training examples unlearnable. Error-minimizing noise is\nintentionally generated to reduce the error of one or more of the training\nexample(s) close to zero, which can trick the model into believing there is\n\"nothing\" to learn from these example(s). The noise is restricted to be\nimperceptible to human eyes, and thus does not affect normal data utility. We\nempirically verify the effectiveness of error-minimizing noise in both\nsample-wise and class-wise forms. We also demonstrate its flexibility under\nextensive experimental settings and practicability in a case study of face\nrecognition. Our work establishes an important first step towards making\npersonal data unexploitable to deep learning models.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 06:15:56 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 22:53:31 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Huang", "Hanxun", ""], ["Ma", "Xingjun", ""], ["Erfani", "Sarah Monazam", ""], ["Bailey", "James", ""], ["Wang", "Yisen", ""]]}, {"id": "2101.05037", "submitter": "Maximilian Ernst Tschuchnig", "authors": "Maximilian Ernst Tschuchnig and Dejan Radovanovic and Eduard Hirsch\n  and Anna-Maria Oberluggauer and Georg Sch\\\"afer", "title": "Immutable and Democratic Data in permissionless Peer-to-Peer Systems", "comments": null, "journal-ref": null, "doi": "10.1109/SDS.2019.8768645", "report-no": null, "categories": "cs.DB cs.CR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Conventional data storage methods like SQL and NoSQL offer a huge amount of\npossibilities with one major disadvantage, having to use a centralized\nauthority. This authority may be in the form of a centralized or decentralized\nmaster server or a permissioned peer-to-peer setting. This paper looks at\ndifferent technologies on how to persist data without using a central\nauthority, mainly looking at permissionless peer-to-peer networks, primarily\nDistributed Ledger Technologies (DLTs) and a combination of DLTs with\nconventional databases. Afterwards it is shown how a system like this might be\nimplemented in two prototypes which are then evaluated against conventional\ndatabases.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 12:56:25 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Tschuchnig", "Maximilian Ernst", ""], ["Radovanovic", "Dejan", ""], ["Hirsch", "Eduard", ""], ["Oberluggauer", "Anna-Maria", ""], ["Sch\u00e4fer", "Georg", ""]]}, {"id": "2101.05067", "submitter": "Gursel Serpen", "authors": "Zeinab Zoghi and Gursel Serpen", "title": "UNSW-NB15 Computer Security Dataset: Analysis through Visualization", "comments": "17 singled spaced pages, 2 tables and 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a visual analysis of the UNSW-NB25 computer network\nsecurity or intrusion detection dataset in order to detect any issues inherent\nto this dataset which may require researchers to address before employing this\ndataset for data-driven model development such as a machine learning\nclassifier. A number of data preprocessing algorithms are applied on the raw\ndata to address common issues such as elimination of redundant features,\nconversion of nominal features into numerical format and scaling. PCA, t-SNE\nand K-means clustering algorithms are employed for developing the graphs and\nplots for visualization. Consequent analysis through visualization identified\nand illustrated two major problems as class imbalance and class overlap for\nthis dataset. In conclusion, it is necessary to address these two problems of\nclass imbalance and class overlap prior to employing this dataset for any\nclassifier model development.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 13:56:44 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Zoghi", "Zeinab", ""], ["Serpen", "Gursel", ""]]}, {"id": "2101.05093", "submitter": "Brian Lee", "authors": "Brian Lee, Brandi Dupervil, Nicholas P. Deputy, Wil Duck, Stephen\n  Soroka, Lyndsay Bottichio, Benjamin Silk, Jason Price, Patricia Sweeney,\n  Jennifer Fuld, Todd Weber, Dan Pollock", "title": "Protecting Privacy and Transforming COVID-19 Case Surveillance Datasets\n  for Public Use", "comments": "19 pages, 4 figures, 1 table, 5 supplements", "journal-ref": null, "doi": "10.1177/00333549211026817", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Objectives: Federal open data initiatives that promote increased sharing of\nfederally collected data are important for transparency, data quality, trust,\nand relationships with the public and state, tribal, local, and territorial\n(STLT) partners. These initiatives advance understanding of health conditions\nand diseases by providing data to more researchers, scientists, and\npolicymakers for analysis, collaboration, and valuable use outside CDC\nresponders. This is particularly true for emerging conditions such as COVID-19\nwhere we have much to learn and have evolving data needs. Since the beginning\nof the outbreak, CDC has collected person-level, de-identified data from\njurisdictions and currently has over 8 million records, increasing each day.\nThis paper describes how CDC designed and produces two de-identified public\ndatasets from these collected data.\n  Materials and Methods: Data elements were included based on the usefulness,\npublic request, and privacy implications; specific field values were suppressed\nto reduce risk of reidentification and exposure of confidential information.\nDatasets were created and verified for privacy and confidentiality using data\nmanagement platform analytic tools as well as R scripts.\n  Results: Unrestricted data are available to the public through Data.CDC.gov\nand restricted data, with additional fields, are available with a data use\nagreement through a private repository on GitHub.com.\n  Practice Implications: Enriched understanding of the available public data,\nthe methods used to create these data, and the algorithms used to protect\nprivacy of de-identified individuals allow for improved data use. Automating\ndata generation procedures allows greater and more timely sharing of data.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 14:24:20 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Lee", "Brian", ""], ["Dupervil", "Brandi", ""], ["Deputy", "Nicholas P.", ""], ["Duck", "Wil", ""], ["Soroka", "Stephen", ""], ["Bottichio", "Lyndsay", ""], ["Silk", "Benjamin", ""], ["Price", "Jason", ""], ["Sweeney", "Patricia", ""], ["Fuld", "Jennifer", ""], ["Weber", "Todd", ""], ["Pollock", "Dan", ""]]}, {"id": "2101.05102", "submitter": "Roberto Natella", "authors": "Roberto Natella and Van-Thuan Pham", "title": "ProFuzzBench: A Benchmark for Stateful Protocol Fuzzing", "comments": "The source code of ProFuzzBench is available online on GitHub at:\n  https://github.com/profuzzbench/profuzzbench", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a new benchmark (ProFuzzBench) for stateful fuzzing of network\nprotocols. The benchmark includes a suite of representative open-source network\nservers for popular protocols, and tools to automate experimentation. We\ndiscuss challenges and potential directions for future research based on this\nbenchmark.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 14:36:48 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Natella", "Roberto", ""], ["Pham", "Van-Thuan", ""]]}, {"id": "2101.05105", "submitter": "ChuanPeng Guo", "authors": "Chuanpeng Guo, Wei Yang, Liusheng Huang", "title": "F3SNet: A Four-Step Strategy for QIM Steganalysis of Compressed Speech\n  Based on Hierarchical Attention Network", "comments": "There was a major error in the paper I submitted, which led to a\n  large error in the conclusion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional machine learning-based steganalysis methods on compressed speech\nhave achieved great success in the field of communication security. However,\nprevious studies lacked mathematical description and modeling of the\ncorrelation between codewords, and there is still room for improvement in\nsteganalysis for small-sized and low embedding rates sample. To deal with the\nchallenge, We use Bayesian networks to measure different types of correlations\nbetween codewords in linear prediction code and present F3SNet -- a four-step\nstrategy: Embedding, Encoding, Attention and Classification for quantizaition\nindex modulation steganalysis of compressed speech based on Hierarchical\nAttention Network. Among them, Embedding converts codewords into high-density\nnumerical vectors, Encoding uses the memory characteristics of LSTM to retain\nmore information by distributing it among all its vectors and Attention further\ndetermines which vectors have a greater impact on the final classification\nresult. To evaluate the performance of F3SNet, we make comprehensive comparison\nof F3SNet with existing steganography methods. Experimental results show that\nF3SNet surpasses the state-of-the-art methods, particularly for small-sized and\nlow embedding rate samples.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 14:41:01 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 15:11:40 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Guo", "Chuanpeng", ""], ["Yang", "Wei", ""], ["Huang", "Liusheng", ""]]}, {"id": "2101.05140", "submitter": "Yong Wang", "authors": "Yong Wang", "title": "Secure Process Algebra", "comments": "172 pages, 36 figures, 28 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on our previous work on truly concurrent process algebras APTC, we use\nit to verify the security protocols. This work (called Secure APTC, abbreviated\nSAPTC) have the following advantages in verifying security protocols: (1) It\nhas a firmly theoretic foundations, including equational logics, structured\noperational semantics, and axiomatizations between them; (2) It has rich\nexpressive powers to describe security protocols. Cryptographic operations are\nmodeled as atomic actions and can be extended, explicit parallelism and\ncommunication mechanism to modeling communication operations and principals,\nrich computational properties to describing computational logics in the\nsecurity protocols, including conditional guards, alternative composition,\nsequential composition, parallelism and communication, encapsulation and\ndeadlock, recursion, abstraction. (3) Especially by abstraction, it is\nconvenient and obvious to observe the relations between the inputs and outputs\nof a security protocols, including the relations without any attack, the\nrelations under each known attack, and the relations under unknown attacks if\nthe unknown attacks can be described.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 15:35:38 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 03:47:56 GMT"}, {"version": "v3", "created": "Fri, 26 Mar 2021 16:08:41 GMT"}, {"version": "v4", "created": "Thu, 1 Apr 2021 04:18:38 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Wang", "Yong", ""]]}, {"id": "2101.05259", "submitter": "Geoffrey Goodell", "authors": "Geoffrey Goodell, Hazem Danny Al-Nakib, Paolo Tasca", "title": "A Digital Currency Architecture for Privacy and Owner-Custodianship", "comments": "24 pages, 6 figures, 1 table. arXiv admin note: substantial text\n  overlap with arXiv:2006.03023", "journal-ref": "Future Internet 2021, 13(5), 130, 2021-05-14", "doi": "10.3390/fi13050130", "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, electronic retail payment mechanisms, especially e-commerce\nand card payments at the point of sale, have increasingly replaced cash in many\ndeveloped countries. As a result, societies are losing a critical public retail\npayment option, and retail consumers are losing important rights associated\nwith using cash. To address this concern, we propose an approach to digital\ncurrency that would allow people without banking relationships to transact\nelectronically and privately, including both internet purchases and\npoint-of-sale purchases that are required to be cashless. Our proposal\nintroduces a government-backed, privately-operated digital currency\ninfrastructure to ensure that every transaction is registered by a bank or\nmoney services business, and it relies upon non-custodial wallets backed by\nprivacy-enhancing technology such as blind signatures or zero-knowledge proofs\nto ensure that transaction counterparties are not revealed. Our approach to\ndigital currency can also facilitate more efficient and transparent clearing,\nsettlement, and management of systemic risk. We argue that our system can\nrestore and preserve the salient features of cash, including privacy,\nowner-custodianship, fungibility, and accessibility, while also preserving\nfractional reserve banking and the existing two-tiered banking system. We also\nshow that it is possible to introduce regulation of digital currency\ntransactions involving non-custodial wallets that unconditionally protect the\nprivacy of end-users.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 18:44:10 GMT"}, {"version": "v2", "created": "Mon, 22 Mar 2021 12:41:30 GMT"}, {"version": "v3", "created": "Thu, 29 Apr 2021 15:33:38 GMT"}, {"version": "v4", "created": "Tue, 4 May 2021 14:40:03 GMT"}, {"version": "v5", "created": "Wed, 5 May 2021 06:34:42 GMT"}, {"version": "v6", "created": "Thu, 27 May 2021 13:42:37 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Goodell", "Geoffrey", ""], ["Al-Nakib", "Hazem Danny", ""], ["Tasca", "Paolo", ""]]}, {"id": "2101.05371", "submitter": "Lukas Daniel Klausner", "authors": "Sebastian Eresheim, Lukas Daniel Klausner, Patrick Kochberger", "title": "Anomaly Detection Support Using Process Classification", "comments": "14 pages, 6 figures", "journal-ref": "Proceedings of the 5th International Conference on Software\n  Security and Assurance (ICSSA 2019), 2019, 27-40", "doi": "10.1109/ICSSA48308.2019.00011", "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection systems need to consider a lot of information when scanning\nfor anomalies. One example is the context of the process in which an anomaly\nmight occur, because anomalies for one process might not be anomalies for a\ndifferent one. Therefore data -- such as system events -- need to be assigned\nto the program they originate from. This paper investigates whether it is\npossible to infer from a list of system events the program whose behavior\ncaused the occurrence of these system events. To that end, we model transition\nprobabilities between non-equivalent events and apply the $k$-nearest neighbors\nalgorithm. This system is evaluated on non-malicious, real-world data using\nfour different evaluation scores. Our results suggest that the approach\nproposed in this paper is capable of correctly inferring program names from\nsystem events.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 22:22:03 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Eresheim", "Sebastian", ""], ["Klausner", "Lukas Daniel", ""], ["Kochberger", "Patrick", ""]]}, {"id": "2101.05405", "submitter": "Huseyin Inan", "authors": "Huseyin A. Inan, Osman Ramadan, Lukas Wutschitz, Daniel Jones, Victor\n  R\\\"uhle, James Withers, Robert Sim", "title": "Training Data Leakage Analysis in Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in neural network based language models lead to successful\ndeployments of such models, improving user experience in various applications.\nIt has been demonstrated that strong performance of language models comes along\nwith the ability to memorize rare training samples, which poses serious privacy\nthreats in case the model is trained on confidential user content. In this\nwork, we introduce a methodology that investigates identifying the user content\nin the training data that could be leaked under a strong and realistic threat\nmodel. We propose two metrics to quantify user-level data leakage by measuring\na model's ability to produce unique sentence fragments within training data.\nOur metrics further enable comparing different models trained on the same data\nin terms of privacy. We demonstrate our approach through extensive numerical\nstudies on both RNN and Transformer based models. We further illustrate how the\nproposed metrics can be utilized to investigate the efficacy of mitigations\nlike differentially private training or API hardening.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 00:57:32 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 23:53:08 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Inan", "Huseyin A.", ""], ["Ramadan", "Osman", ""], ["Wutschitz", "Lukas", ""], ["Jones", "Daniel", ""], ["R\u00fchle", "Victor", ""], ["Withers", "James", ""], ["Sim", "Robert", ""]]}, {"id": "2101.05495", "submitter": "Peter Hillmann", "authors": "Peter Hillmann, Marcus Kn\\\"upfer, Erik Heiland, Andreas Karcher", "title": "Selective Deletion in a Blockchain", "comments": null, "journal-ref": "International Workshop on Blockchain and Mobile Applications\n  (BlockApp 2020) during the International Conference on Distributed Computing\n  Systems (ICDCS 2020)", "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The constantly growing size of blockchains becomes a challenge with the\nincreasing usage. Especially the storage of unwanted data in a blockchain is an\nissue, because it cannot be removed naturally. In order to counteract this\nproblem, we present the first concept for the selective deletion of single\nentries in a blockchain. For this purpose, the general consensus algorithm is\nextended by the functionality of regularly creating summary blocks. Previous\ndata of the chain are summarized and stored again in a new block, leaving out\nunwanted information. With a shifting marker of the Genesis Block, data can be\ndeleted from the beginning of a blockchain. In this way, the technology of the\nblockchain becomes fully transactional. The concept is independent of a\nspecific block structure, network structure, or consensus algorithm. Moreover,\nthis functionality can be adapted to current blockchains to solve multiple\nproblems related to scalability. This approach enables the transfer of\nblockchain technology to further fields of application, among others in the\narea of Industry 4.0 and Product Life-cycle Management.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 08:06:37 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Hillmann", "Peter", ""], ["Kn\u00fcpfer", "Marcus", ""], ["Heiland", "Erik", ""], ["Karcher", "Andreas", ""]]}, {"id": "2101.05511", "submitter": "Kaihua Qin", "authors": "Kaihua Qin, Liyi Zhou and Arthur Gervais", "title": "Quantifying Blockchain Extractable Value: How dark is the forest?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Permissionless blockchains such as Bitcoin have excelled at financial\nservices. Yet, adversaries extract monetary value from the mesh of\ndecentralized finance (DeFi) smart contracts. Some have characterized the\nEthereum peer-to-peer network as a dark forest, wherein broadcast transactions\nrepresent prey, which are devoured by generalized trading bots.\n  While transaction (re)ordering and front-running are known to cause losses to\nusers, we quantify how much value was sourced from blockchain extractable value\n(BEV). We systematize a transaction ordering taxonomy to quantify the USD\nextracted from sandwich attacks, liquidations, and decentralized exchange\narbitrage. We estimate that over 2 years, those trading activities yielded\n28.80M USD in profit, divided among 5,084 unique addresses. While arbitrage and\nliquidations might appear benign, traders can front-run others, causing\nfinancial losses to competitors.\n  To provide an example of a generalized trading bot, we show a simple yet\neffective automated transaction replay algorithm capable of replacing\nunconfirmed transactions without the need to understand the victim\ntransactions' underlying logic. We estimate that our transaction replay\nalgorithm could have yielded a profit of 51,688.33 ETH (17.60M USD) over 2\nyears on past blockchain data.\n  We also find that miners do not broadcast 1.64% of their mined transactions\nand instead choose to mine them privately. Privately mined and non-shared\ntransactions, cannot be front-run by other traders or miners. We show that the\nlargest Ethereum mining pool performs arbitrage and seemingly tries to cloak\nits private transaction mining activities. We therefore provide evidence that\nminers already extract Miner Extractable Value (MEV), which could destabilize\nthe blockchain consensus security, as related work has shown.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 09:12:32 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 10:35:37 GMT"}, {"version": "v3", "created": "Fri, 22 Jan 2021 03:53:48 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Qin", "Kaihua", ""], ["Zhou", "Liyi", ""], ["Gervais", "Arthur", ""]]}, {"id": "2101.05538", "submitter": "Peter Hillmann", "authors": "Marcus Kn\\\"upfer, Tore Bierwirth, Lars Stiemert, Matthias Schopp,\n  Sebastian Seeber, Daniela P\\\"ohn, Peter Hillmann", "title": "Cyber Taxi: A Taxonomy of Interactive Cyber Training and Education\n  Systems", "comments": null, "journal-ref": "Model-driven Simulation and Training Environments for\n  Cybersecurity (MSTEC 2020)", "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of guided exercises and practical opportunities to learn about\ncybersecurity in a practical way makes it difficult for security experts to\nimprove their proficiency. Capture the Flag events and Cyber Ranges are ideal\nfor cybersecurity training. Thereby, the participants usually compete in teams\nagainst each other, or have to defend themselves in a specific scenario. As\norganizers of yearly events, we present a taxonomy for interactive cyber\ntraining and education. The proposed taxonomy includes different factors of the\ntechnical setup, audience, training environment, and training setup. By the\ncomprehensive taxonomy, different aspects of interactive training are\nconsidered. This can help trainings to improve and to be established\nsuccessfully. The provided taxonomy is extendable and can be used in further\napplication areas as research on new security technologies.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 10:26:46 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Kn\u00fcpfer", "Marcus", ""], ["Bierwirth", "Tore", ""], ["Stiemert", "Lars", ""], ["Schopp", "Matthias", ""], ["Seeber", "Sebastian", ""], ["P\u00f6hn", "Daniela", ""], ["Hillmann", "Peter", ""]]}, {"id": "2101.05543", "submitter": "Giorgia Azzurra Marson", "authors": "Orestis Alpos, Christian Cachin, Giorgia Azzurra Marson, Luca Zanolini", "title": "On the Synchronization Power of Token Smart Contracts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Modern blockchains support a variety of distributed applications beyond\ncryptocurrencies, including smart contracts -- which let users execute\narbitrary code in a distributed and decentralized fashion. Regardless of their\nintended application, blockchain platforms implicitly assume consensus for the\ncorrect execution of a smart contract, thus requiring that all transactions are\ntotally ordered. It was only recently recognized that consensus is not\nnecessary to prevent double-spending in a cryptocurrency (Guerraoui et al.,\nPODC'19), contrary to common belief. This result suggests that current\nimplementations may be sacrificing efficiency and scalability because they\nsynchronize transactions much more tightly than actually needed. In this work,\nwe study the synchronization requirements of Ethereum's ERC20 token contract,\none of the most widely adopted smart contacts. Namely, we model a\nsmart-contract token as a concurrent object and analyze its consensus number as\na measure of synchronization power. We show that the richer set of methods\nsupported by ERC20 tokens, compared to standard cryptocurrencies, results in\nstrictly stronger synchronization requirements. More surprisingly, the\nsynchronization power of ERC20 tokens depends on the object's state and can\nthus be modified by method invocations. To prove this result, we develop a\ndedicated framework to express how the object's state affects the needed\nsynchronization level. Our findings indicate that ERC20 tokens, as well as\nother token standards, are more powerful and versatile than plain\ncryptocurrencies, and are subject to dynamic requirements. Developing specific\nsynchronization protocols that exploit these dynamic requirements will pave the\nway towards more robust and scalable blockchain platforms.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 10:50:10 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Alpos", "Orestis", ""], ["Cachin", "Christian", ""], ["Marson", "Giorgia Azzurra", ""], ["Zanolini", "Luca", ""]]}, {"id": "2101.05560", "submitter": "Nayana Das", "authors": "Nayana Das, Goutam Paul", "title": "Secure Multi-Party Quantum Conference and Xor Computation", "comments": "Accepted in Quantum Information and Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum conference is a process of securely exchanging messages between three\nor more parties, using quantum resources. A Measurement Device Independent\nQuantum Dialogue (MDI-QD) protocol, which is secure against information\nleakage, has been proposed (Quantum Information Processing 16.12 (2017): 305)\nin 2017, is proven to be insecure against intercept-and-resend attack strategy.\nWe first modify this protocol and generalize this MDI-QD to a three-party\nquantum conference and then to a multi-party quantum conference. We also\npropose a protocol for quantum multi-party XOR computation. None of these three\nprotocols proposed here use entanglement as a resource and we prove the\ncorrectness and security of our proposed protocols.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 12:03:08 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Das", "Nayana", ""], ["Paul", "Goutam", ""]]}, {"id": "2101.05589", "submitter": "Benjamin Schlosser", "authors": "Hendrik Amler (1), Lisa Eckey (1), Sebastian Faust (1), Marcel Kaiser\n  (2), Philipp Sandner (2), Benjamin Schlosser (1) ((1) Technical University of\n  Darmstadt, (2) Frankfurt School of Finance and Management)", "title": "DeFi-ning DeFi: Challenges & Pathway", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The decentralized and trustless nature of cryptocurrencies and blockchain\ntechnology leads to a shift in the digital world. The possibility to execute\nsmall programs, called smart contracts, on cryptocurrencies like Ethereum\nopened doors to countless new applications. One particular exciting use case is\ndecentralized finance (DeFi), which aims to revolutionize traditional financial\nservices by founding them on a decentralized infrastructure. We show the\npotential of DeFi by analyzing its advantages compared to traditional finance.\nAdditionally, we survey the state-of-the-art of DeFi products and categorize\nexisting services. Since DeFi is still in its infancy, there are countless\nhurdles for mass adoption. We discuss the most prominent challenges and point\nout possible solutions. Finally, we analyze the economics behind DeFi products.\nBy carefully analyzing the state-of-the-art and discussing current challenges,\nwe give a perspective on how the DeFi space might develop in the near future.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 13:46:01 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Amler", "Hendrik", ""], ["Eckey", "Lisa", ""], ["Faust", "Sebastian", ""], ["Kaiser", "Marcel", ""], ["Sandner", "Philipp", ""], ["Schlosser", "Benjamin", ""]]}, {"id": "2101.05614", "submitter": "Prajoy Podder", "authors": "Prajoy Podder, M. Rubaiyat Hossain Mondal, Subrato Bharati, Pinto\n  Kumar Paul", "title": "Review on the Security Threats of Internet of Things", "comments": "9 Pages, 9 figures", "journal-ref": "International Journal of Computer Applications (IJCA), 2020", "doi": "10.5120/ijca2020920548", "report-no": null, "categories": "cs.CR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) is being considered as the growth engine for\nindustrial revolution 4.0. The combination of IoT, cloud computing and\nhealthcare can contribute in ensuring well-being of people. One important\nchallenge of IoT network is maintaining privacy and to overcome security\nthreats. This paper provides a systematic review of the security aspects of\nIoT. Firstly, the application of IoT in industrial and medical service\nscenarios are described, and the security threats are discussed for the\ndifferent layers of IoT healthcare architecture. Secondly, different types of\nexisting malware including spyware, viruses, worms, keyloggers, and trojan\nhorses are described in the context of IoT. Thirdly, some of the recent malware\nattacks such as Mirai, echobot and reaper are discussed. Next, a comparative\ndiscussion is presented on the effectiveness of different machine learning\nalgorithms in mitigating the security threats. It is found that the k-nearest\nneighbor (kNN) machine learning algorithm exhibits excellent accuracy in\ndetecting malware. This paper also reviews different tools for ransomware\ndetection, classification and analysis. Finally, a discussion is presented on\nthe existing security issues, open challenges and possible future scopes in\nensuring IoT security.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 08:48:16 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Podder", "Prajoy", ""], ["Mondal", "M. Rubaiyat Hossain", ""], ["Bharati", "Subrato", ""], ["Paul", "Pinto Kumar", ""]]}, {"id": "2101.05641", "submitter": "Jialiang Han", "authors": "Jialiang Han, Yun Ma", "title": "$C^3DRec$: Cloud-Client Cooperative Deep Learning for Temporal\n  Recommendation in the Post-GDPR Era", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile devices enable users to retrieve information at any time and any\nplace. Considering the occasional requirements and fragmentation usage pattern\nof mobile users, temporal recommendation techniques are proposed to improve the\nefficiency of information retrieval on mobile devices by means of accurately\nrecommending items via learning temporal interests with short-term user\ninteraction behaviors. However, the enforcement of privacy-preserving laws and\nregulations, such as GDPR, may overshadow the successful practice of temporal\nrecommendation. The reason is that state-of-the-art recommendation systems\nrequire to gather and process the user data in centralized servers but the\ninteraction behaviors data used for temporal recommendation are usually\nnon-transactional data that are not allowed to gather without the explicit\npermission of users according to GDPR. As a result, if users do not permit\nservices to gather their interaction behaviors data, the temporal\nrecommendation fails to work. To realize the temporal recommendation in the\npost-GDPR era, this paper proposes $C^3DRec$, a cloud-client cooperative deep\nlearning framework of mining interaction behaviors for recommendation while\npreserving user privacy. $C^3DRec$ constructs a global recommendation model on\ncentralized servers using data collected before GDPR and fine-tunes the model\ndirectly on individual local devices using data collected after GDPR. We design\ntwo modes to accomplish the recommendation, i.e. pull mode where candidate\nitems are pulled down onto the devices and fed into the local model to get\nrecommended items, and push mode where the output of the local model is pushed\nonto the server and combined with candidate items to get recommended ones.\nEvaluation results show that $C^3DRec$ achieves comparable recommendation\naccuracy to the centralized approaches, with minimal privacy concern.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2021 12:49:34 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Han", "Jialiang", ""], ["Ma", "Yun", ""]]}, {"id": "2101.05646", "submitter": "Cengiz Acart\\\"urk", "authors": "Cengiz Acarturk, Melih Sirlanci, Pinar Gurkan Balikcioglu, Deniz\n  Demirci, Nazenin Sahin, Ozge Acar Kucuk", "title": "Malicious Code Detection: Run Trace Output Analysis by LSTM", "comments": "11 pages, 5 figures, 5 tables, accepted to IEEE Access", "journal-ref": null, "doi": "10.1109/ACCESS.2021.3049200", "report-no": null, "categories": "cs.CR cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Malicious software threats and their detection have been gaining importance\nas a subdomain of information security due to the expansion of ICT applications\nin daily settings. A major challenge in designing and developing anti-malware\nsystems is the coverage of the detection, particularly the development of\ndynamic analysis methods that can detect polymorphic and metamorphic malware\nefficiently. In the present study, we propose a methodological framework for\ndetecting malicious code by analyzing run trace outputs by Long Short-Term\nMemory (LSTM). We developed models of run traces of malicious and benign\nPortable Executable (PE) files. We created our dataset from run trace outputs\nobtained from dynamic analysis of PE files. The obtained dataset was in the\ninstruction format as a sequence and was called Instruction as a Sequence Model\n(ISM). By splitting the first dataset into basic blocks, we obtained the second\none called Basic Block as a Sequence Model (BSM). The experiments showed that\nthe ISM achieved an accuracy of 87.51% and a false positive rate of 18.34%,\nwhile BSM achieved an accuracy of 99.26% and a false positive rate of 2.62%.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 15:00:42 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Acarturk", "Cengiz", ""], ["Sirlanci", "Melih", ""], ["Balikcioglu", "Pinar Gurkan", ""], ["Demirci", "Deniz", ""], ["Sahin", "Nazenin", ""], ["Kucuk", "Ozge Acar", ""]]}, {"id": "2101.05735", "submitter": "Markus Scherer", "authors": "Clara Schneidewind, Markus Scherer, Matteo Maffei", "title": "The Good, the Bad and the Ugly: Pitfalls and Best Practices in Automated\n  Sound Static Analysis of Ethereum Smart Contracts", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-61467-6_14", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ethereum smart contracts are distributed programs running on top of the\nEthereum blockchain. Since program flaws can cause significant monetary losses\nand can hardly be fixed due to the immutable nature of the blockchain, there is\na strong need of automated analysis tools which provide formal security\nguarantees. Designing such analyzers, however, proved to be challenging and\nerror-prone. We review the existing approaches to automated, sound, static\nanalysis of Ethereum smart contracts and highlight prevalent issues in the\nstate of the art. Finally, we overview eThor, a recent static analysis tool\nthat we developed following a principled design and implementation approach\nbased on rigorous semantic foundations to overcome the problems of past works.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 17:31:30 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Schneidewind", "Clara", ""], ["Scherer", "Markus", ""], ["Maffei", "Matteo", ""]]}, {"id": "2101.05781", "submitter": "Deborah Blevins", "authors": "Deborah H. Blevins (1), Pablo Moriano (2), Robert A. Bridges (2), Miki\n  E. Verma (2), Michael D. Iannacone (2), Samuel C Hollifield (2) ((1)\n  University of Kentucky, (2) Oak Ridge National Laboratory)", "title": "Time-Based CAN Intrusion Detection Benchmark", "comments": "7 pages, 2 figures", "journal-ref": "Workshop on Automotive and Autonomous Vehicle Security (AutoSec)\n  2021", "doi": "10.14722/autosec.2021.23013", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern vehicles are complex cyber-physical systems made of hundreds of\nelectronic control units (ECUs) that communicate over controller area networks\n(CANs). This inherited complexity has expanded the CAN attack surface which is\nvulnerable to message injection attacks. These injections change the overall\ntiming characteristics of messages on the bus, and thus, to detect these\nmalicious messages, time-based intrusion detection systems (IDSs) have been\nproposed. However, time-based IDSs are usually trained and tested on\nlow-fidelity datasets with unrealistic, labeled attacks. This makes difficult\nthe task of evaluating, comparing, and validating IDSs. Here we detail and\nbenchmark four time-based IDSs against the newly published ROAD dataset, the\nfirst open CAN IDS dataset with real (non-simulated) stealthy attacks with\nphysically verified effects. We found that methods that perform hypothesis\ntesting by explicitly estimating message timing distributions have lower\nperformance than methods that seek anomalies in a distribution-related\nstatistic. In particular, these \"distribution-agnostic\" based methods\noutperform \"distribution-based\" methods by at least 55% in area under the\nprecision-recall curve (AUC-PR). Our results expand the body of knowledge of\nCAN time-based IDSs by providing details of these methods and reporting their\nresults when tested on datasets with real advanced attacks. Finally, we develop\nan after-market plug-in detector using lightweight hardware, which can be used\nto deploy the best performing IDS method on nearly any vehicle.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 18:33:19 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Blevins", "Deborah H.", ""], ["Moriano", "Pablo", ""], ["Bridges", "Robert A.", ""], ["Verma", "Miki E.", ""], ["Iannacone", "Michael D.", ""], ["Hollifield", "Samuel C", ""]]}, {"id": "2101.06000", "submitter": "Mahdi Zamani", "authors": "Rongjian Lan and Ganesha Upadhyaya and Stephen Tse and Mahdi Zamani", "title": "Horizon: A Gas-Efficient, Trustless Bridge for Cross-Chain Transactions", "comments": "14 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the rise of digital currency systems that rely on blockchain to ensure\nledger security, the ability to perform cross-chain transactions is becoming a\ncrucial interoperability requirement. Such transactions allow not only funds to\nbe transferred from one blockchain to another (as done in atomic swaps), but\nalso a blockchain to verify the inclusion of any event on another blockchain.\nCross-chain bridges are protocols that allow on-chain exchange of\ncryptocurrencies, on-chain transfer of assets to sidechains, and cross-shard\nverification of events in sharded blockchains, many of which rely on Byzantine\nfault tolerance (BFT) for scalability. Unfortunately, existing bridge protocols\nthat can transfer funds from a BFT blockchain incur significant computation\noverhead on the destination blockchain, resulting in a high gas cost for smart\ncontract verification of events. In this paper, we propose Horizon, a\ngas-efficient, cross-chain bridge protocol to transfer assets from a BFT\nblockchain to another blockchain (e.g., Ethereum) that supports basic smart\ncontract execution.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 07:42:30 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Lan", "Rongjian", ""], ["Upadhyaya", "Ganesha", ""], ["Tse", "Stephen", ""], ["Zamani", "Mahdi", ""]]}, {"id": "2101.06039", "submitter": "Albert Cohen", "authors": "Son Tuan Vu, Albert Cohen, Karine Heydemann, Arnaud de Grandmaison,\n  Christophe Guillon", "title": "Secure Optimization Through Opaque Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Secure applications implement software protections against side-channel and\nphysical attacks. Such protections are meaningful at machine code or\nmicro-architectural level, but they typically do not carry observable semantics\nat source level. To prevent optimizing compilers from altering the protection,\nsecurity engineers embed input/output side-effects into the protection. These\nside-effects are error-prone and compiler-dependent, and the current practice\ninvolves analyzing the generated machine code to make sure security or privacy\nproperties are still enforced. Vu et al. recently demonstrated how to automate\nthe insertion of volatile side-effects in a compiler [52], but these may be too\nexpensive in fined-grained protections such as control-flow integrity. We\nintroduce observations of the program state that are intrinsic to the correct\nexecution of security protections, along with means to specify and preserve\nobservations across the compilation flow. Such observations complement the\ntraditional input/output-preservation contract of compilers. We show how to\nguarantee their preservation without modifying compilation passes and with as\nlittle performance impact as possible. We validate our approach on a range of\nbenchmarks, expressing the secure compilation of these applications in terms of\nobservations to be made at specific program points.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 10:02:18 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Vu", "Son Tuan", ""], ["Cohen", "Albert", ""], ["Heydemann", "Karine", ""], ["de Grandmaison", "Arnaud", ""], ["Guillon", "Christophe", ""]]}, {"id": "2101.06043", "submitter": "Lorenzo Veronese", "authors": "Lorenzo Veronese, Stefano Calzavara, Luca Compagna", "title": "Bulwark: Holistic and Verified Security Monitoring of Web Protocols", "comments": "Full version of the paper presented at ESORICS2020 (14-18 September\n  2020)", "journal-ref": "ESORICS 2020: Computer Security (2020) 23-41", "doi": "10.1007/978-3-030-58951-6_2", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern web applications often rely on third-party services to provide their\nfunctionality to users. The secure integration of these services is a\nnon-trivial task, as shown by the large number of attacks against Single Sign\nOn and Cashier-as-a-Service protocols. In this paper we present Bulwark, a new\nautomatic tool which generates formally verified security monitors from applied\npi-calculus specifications of web protocols. The security monitors generated by\nBulwark offer holistic protection, since they can be readily deployed both at\nthe client side and at the server side, thus ensuring full visibility of the\nattack surface against web protocols. We evaluate the effectiveness of Bulwark\nby testing it against a pool of vulnerable web applications that use the OAuth\n2.0 protocol or integrate the PayPal payment system.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 10:13:19 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Veronese", "Lorenzo", ""], ["Calzavara", "Stefano", ""], ["Compagna", "Luca", ""]]}, {"id": "2101.06124", "submitter": "Jason Gray", "authors": "Jason Gray, Daniele Sgandurra and Lorenzo Cavallaro", "title": "Identifying Authorship Style in Malicious Binaries: Techniques,\n  Challenges & Datasets", "comments": "31 pages, 3 figures, 10 tables; Modified table headings to make them\n  readable", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attributing a piece of malware to its creator typically requires threat\nintelligence. Binary attribution increases the level of difficulty as it mostly\nrelies upon the ability to disassemble binaries to identify authorship style.\nOur survey explores malicious author style and the adversarial techniques used\nby them to remain anonymous. We examine the adversarial impact on the\nstate-of-the-art methods. We identify key findings and explore the open\nresearch challenges. To mitigate the lack of ground truth datasets in this\ndomain, we publish alongside this survey the largest and most diverse\nmeta-information dataset of 15,660 malware labeled to 164 threat actor groups.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 14:07:18 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 12:45:34 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Gray", "Jason", ""], ["Sgandurra", "Daniele", ""], ["Cavallaro", "Lorenzo", ""]]}, {"id": "2101.06137", "submitter": "Jan Lauinger", "authors": "Jan Lauinger, Mudassar Aslam, Mohammad Hamad, Shahid Raza, Sebastian\n  Steinhorst", "title": "Quantitative System-Level Security Verification of the IoV\n  Infrastructure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Internet of Vehicles (IoV) equips vehicles with connectivity to the\nInternet and the Internet of Things (IoT) to support modern applications such\nas autonomous driving. However, the consolidation of complex computing domains\nof vehicles, the Internet, and the IoT limits the applicability of tailored\nsecurity solutions. In this paper, we propose a new methodology to\nquantitatively verify the security of single or system-level assets of the IoV\ninfrastructure. In detail, our methodology decomposes assets of the IoV\ninfrastructure with the help of reference sub-architectures and the 4+1 view\nmodel analysis to map identified assets into data, software, networking, and\nhardware categories. This analysis includes a custom threat modeling concept to\nperform parameterization of Common Vulnerability Scoring System (CVSS) scores\nper view model domain. As a result, our methodology is able to allocate assets\nfrom attack paths to view model domains. This equips assets of attack paths\nwith our IoV-driven CVSS scores. Our CVSS scores assess the attack likelihood\nwhich we use for Markov Chain transition probabilities. This way, we\nquantitatively verify system-level security among a set of IoV assets. Our\nresults show that our methodology applies to arbitrary IoV attack paths. Based\non our parameterization of CVSS scores and our selection of use cases, remote\nattacks are less likely to compromise location data compared to attacks from\nclose proximity for authorized and unauthorized attackers respectively.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 14:31:39 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Lauinger", "Jan", ""], ["Aslam", "Mudassar", ""], ["Hamad", "Mohammad", ""], ["Raza", "Shahid", ""], ["Steinhorst", "Sebastian", ""]]}, {"id": "2101.06148", "submitter": "Avani Dave", "authors": "Avani Dave, Nilanjan Banerjee and Chintan Patel", "title": "SRACARE: Secure Remote Attestation with Code Authentication and\n  Resilience Engine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent technological advancements have enabled proliferated use of small\nembedded and IoT devices for collecting, processing, and transferring the\nsecurity-critical information and user data. This exponential use has acted as\na catalyst in the recent growth of sophisticated attacks such as the replay,\nman-in-the-middle, and malicious code modification to slink, leak, tweak or\nexploit the security-critical information in malevolent activities. Therefore,\nsecure communication and software state assurance (at run-time and boot-time)\nof the device has emerged as open security problems. Furthermore, these devices\nneed to have an appropriate recovery mechanism to bring them back to the\nknown-good operational state. Previous researchers have demonstrated\nindependent methods for attack detection and safeguard. However, the majority\nof them lack in providing onboard system recovery and secure communication\ntechniques. To bridge this gap, this manuscript proposes SRACARE- a framework\nthat utilizes the custom lightweight, secure communication protocol that\nperforms remote/local attestation, and secure boot with an onboard resilience\nrecovery mechanism to protect the devices from the above-mentioned attacks. The\nprototype employs an efficient lightweight, low-power 32-bit RISC-V processor,\nsecure communication protocol, code authentication, and resilience engine\nrunning on the Artix 7 Field Programmable Gate Array(FPGA) board. This work\npresents the performance evaluation and state-of-the-art comparison results,\nwhich shows promising resilience to attacks and demonstrate the novel\nprotection mechanism with onboard recovery. The framework achieves these with\nonly 8 % performance overhead and a very small increase in hardware-software\nfootprint.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 14:46:21 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Dave", "Avani", ""], ["Banerjee", "Nilanjan", ""], ["Patel", "Chintan", ""]]}, {"id": "2101.06204", "submitter": "Christof Ferreira Torres", "authors": "Christof Ferreira Torres, Antonio Ken Iannillo, Arthur Gervais, Radu\n  State", "title": "The Eye of Horus: Spotting and Analyzing Attacks on Ethereum Smart\n  Contracts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Ethereum gained tremendously in popularity, growing from a\ndaily transaction average of 10K in January 2016 to an average of 500K in\nJanuary 2020. Similarly, smart contracts began to carry more value, making them\nappealing targets for attackers. As a result, they started to become victims of\nattacks, costing millions of dollars. In response to these attacks, both\nacademia and industry proposed a plethora of tools to scan smart contracts for\nvulnerabilities before deploying them on the blockchain. However, most of these\ntools solely focus on detecting vulnerabilities and not attacks, let alone\nquantifying or tracing the number of stolen assets. In this paper, we present\nHorus, a framework that empowers the automated detection and investigation of\nsmart contract attacks based on logic-driven and graph-driven analysis of\ntransactions. Horus provides quick means to quantify and trace the flow of\nstolen assets across the Ethereum blockchain. We perform a large-scale analysis\nof all the smart contracts deployed on Ethereum until May 2020. We identified\n1,888 attacked smart contracts and 8,095 adversarial transactions in the wild.\nOur investigation shows that the number of attacks did not necessarily decrease\nover the past few years, but for some vulnerabilities remained constant.\nFinally, we also demonstrate the practicality of our framework via an in-depth\nanalysis on the recent Uniswap and Lendf.me attacks.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 16:42:32 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Torres", "Christof Ferreira", ""], ["Iannillo", "Antonio Ken", ""], ["Gervais", "Arthur", ""], ["State", "Radu", ""]]}, {"id": "2101.06232", "submitter": "Yuzhou Lin", "authors": "Yuzhou Lin, Xiaolin Chang", "title": "Towards interpreting ML-based automated malware detection models: a\n  survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware is being increasingly threatening and malware detectors based on\ntraditional signature-based analysis are no longer suitable for current malware\ndetection. Recently, the models based on machine learning (ML) are developed\nfor predicting unknown malware variants and saving human strength. However,\nmost of the existing ML models are black-box, which made their pre-diction\nresults undependable, and therefore need further interpretation in order to be\neffectively deployed in the wild. This paper aims to examine and categorize the\nexisting researches on ML-based malware detector interpretability. We first\ngive a detailed comparison over the previous work on common ML model\ninter-pretability in groups after introducing the principles, attributes,\nevaluation indi-cators and taxonomy of common ML interpretability. Then we\ninvestigate the interpretation methods towards malware detection, by addressing\nthe importance of interpreting malware detectors, challenges faced by this\nfield, solutions for migitating these challenges, and a new taxonomy for\nclassifying all the state-of-the-art malware detection interpretability work in\nrecent years. The highlight of our survey is providing a new taxonomy towards\nmalware detection interpreta-tion methods based on the common taxonomy\nsummarized by previous re-searches in the common field. In addition, we are the\nfirst to evaluate the state-of-the-art approaches by interpretation method\nattributes to generate the final score so as to give insight to quantifying the\ninterpretability. By concluding the results of the recent researches, we hope\nour work can provide suggestions for researchers who are interested in the\ninterpretability on ML-based malware de-tection models.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 17:34:40 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Lin", "Yuzhou", ""], ["Chang", "Xiaolin", ""]]}, {"id": "2101.06291", "submitter": "Mahsa Moosavi", "authors": "Mahsa Moosavi and Jeremy Clark", "title": "Trading on-chain: How Feasible is Regulators' Worst-Case Scenario?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  When consumers trade financial products, they typically use well-identified\nservice providers that operate under government regulation. In theory,\ndecentralized platforms like Ethereum can offer trading services 'on-chain'\nwithout an obvious entry point for regulators. Fortunately for regulators, most\ntrading volume in blockchain-based assets is still on centralized service\nproviders for performance reasons. However this leaves the following research\nquestions we address in this paper: (i) is secure trading (i.e., resistant to\nfront-running and price manipulation) even feasible as a fully 'on-chain'\nservice on a public blockchain, (ii) what is its performance benchmark, and\n(iii) what is the performance impact of novel techniques (e.g., 'rollups') in\nclosing the performance gap? To answer these questions, we 'learn by doing' and\ncustom design an Ethereum-based call market (or batch auction) exchange, Lissy,\nwith favourable security properties.We conducta variety of optimizations and\nexperiments to demonstrate that this technology cannot expect to exceed a few\nhundred trade executions per block (i.e., 13s window of time). However this can\nbe scaled dramatically with off-chain execution that is not consumer-facing. We\nalso illustrate, with numerous examples throughout the paper, how blockchain\ndeployment is full of nuances that make it quite different from developing in\nbetter understood domains (e.g., cloud-based web applications).\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 20:16:37 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 12:49:42 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Moosavi", "Mahsa", ""], ["Clark", "Jeremy", ""]]}, {"id": "2101.06300", "submitter": "Avani Dave", "authors": "Avani Dave, Nilanjan Banerjee, Chintan Patel", "title": "CARE: Lightweight Attack Resilient Secure Boot Architecturewith Onboard\n  Recovery for RISC-V based SOC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent technological advancements have proliferated the use of small embedded\ndevices for collecting, processing, and transferring the security-critical\ninformation. The Internet of Things (IoT) has enabled remote access and control\nof these network-connected devices. Consequently, an attacker can exploit\nsecurity vulnerabilities and compromise these devices. In this context, the\nsecure boot becomes a useful security mechanism to verify the integrity and\nauthenticity of the software state of the devices. However, the current secure\nboot schemes focus on detecting the presence of potential malware on the device\nbut not on disinfecting and restoring the soft-ware to a benign state. This\nmanuscript presents CARE- the first secure boot framework that provides\ndetection, resilience, and onboard recovery mechanism for the com-promised\ndevices. The framework uses a prototype hybrid CARE: Code Authentication and\nResilience Engine to verify the software state and restore it to a benign\nstate. It uses Physical Memory Protection (PMP) and other security enchaining\ntechniques of RISC-V processor to pro-vide resilience from modern attacks. The\nstate-of-the-art comparison and performance analysis results indicate that the\nproposed secure boot framework provides a promising resilience and recovery\nmechanism with very little 8 % performance and resource overhead\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 21:09:57 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Dave", "Avani", ""], ["Banerjee", "Nilanjan", ""], ["Patel", "Chintan", ""]]}, {"id": "2101.06308", "submitter": "Ibrahim Yilmaz", "authors": "Ibrahim Yilmaz, Kavish Kapoor, Ambareen Siraj, Mahmoud Abouyoussef", "title": "Privacy Protection of Grid Users Data with Blockchain and Adversarial\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Utilities around the world are reported to invest a total of around 30\nbillion over the next few years for installation of more than 300 million smart\nmeters, replacing traditional analog meters [1]. By mid-decade, with full\ncountry wide deployment, there will be almost 1.3 billion smart meters in place\n[1]. Collection of fine grained energy usage data by these smart meters\nprovides numerous advantages such as energy savings for customers with use of\ndemand optimization, a billing system of higher accuracy with dynamic pricing\nprograms, bidirectional information exchange ability between end-users for\nbetter consumer-operator interaction, and so on. However, all these perks\nassociated with fine grained energy usage data collection threaten the privacy\nof users. With this technology, customers' personal data such as sleeping\ncycle, number of occupants, and even type and number of appliances stream into\nthe hands of the utility companies and can be subject to misuse. This research\npaper addresses privacy violation of consumers' energy usage data collected\nfrom smart meters and provides a novel solution for the privacy protection\nwhile allowing benefits of energy data analytics. First, we demonstrate the\nsuccessful application of occupancy detection attacks using a deep neural\nnetwork method that yields high accuracy results. We then introduce Adversarial\nMachine Learning Occupancy Detection Avoidance with Blockchain (AMLODA-B)\nframework as a counter-attack by deploying an algorithm based on the Long Short\nTerm Memory (LSTM) model into the standardized smart metering infrastructure to\nprevent leakage of consumers personal information. Our privacy-aware approach\nprotects consumers' privacy without compromising the correctness of billing and\npreserves operational efficiency without use of authoritative intermediaries.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 21:54:55 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Yilmaz", "Ibrahim", ""], ["Kapoor", "Kavish", ""], ["Siraj", "Ambareen", ""], ["Abouyoussef", "Mahmoud", ""]]}, {"id": "2101.06362", "submitter": "Avani Dave", "authors": "Avani Dave, Monty Wiseman and David Safford", "title": "SEDAT:Security Enhanced Device Attestation with TPM2.0", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Remote attestation is one of the ways to verify the state of an untrusted\ndevice. Earlier research has attempted remote verification of a devices' state\nusing hardware, software, or hybrid approaches. Majority of them have used\nAttestation Key as a hardware root of trust, which does not detect hardware\nmodification or counterfeit issues. In addition, they do not have a secure\ncommunication channel between verifier and prover, which makes them susceptible\nto modern security attacks. This paper presents SEDAT, a novel methodology for\nremote attestation of the device via a security enhanced communication channel.\nSEDAT performs hardware, firmware, and software attestation. SEDAT enhances the\ncommunication protocol security between verifier and prover by using the Single\nPacket Authorization (SPA) technique, which provides replay and Denial of\nService (DoS) protection. SEDAT provides a way for verifier to get on-demand\ndevice integrity and authenticity status via a secure channel. It also enables\nthe verifier to detect counterfeit hardware, change in firmware, and software\ncode on the device. SEDAT validates the manufacturers` root CA certificate,\nplatform certificate, endorsement certificate (EK), and attributes certificates\nto perform platform hardware attestation. SEDAT is the first known tool that\nrepresents firmware, and Integrity Measurement Authority (IMA) event logs in\nthe Canonical Event Logs (CEL) format (recommended by Trusted Computing Group).\nSEDAT is the first implementation, to the best of our knowledge, that showcases\nend to end hardware, firmware, and software remote attestation using Trusted\nPlatform Module (TPM2.0) which is resilient to DoS and replay attacks. SEDAT is\nthe first remote verifier that is capable of retrieving a TPM2.0 quote from\nprover and validate it after regeneration, using a software TPM2.0 quote check.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2021 03:41:01 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Dave", "Avani", ""], ["Wiseman", "Monty", ""], ["Safford", "David", ""]]}, {"id": "2101.06419", "submitter": "Deepak Kumaraswamy", "authors": "Deepak Kumaraswamy, Shyam Murthy, Srinivas Vivek", "title": "Revisiting Driver Anonymity in ORide", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ride Hailing Services (RHS) have become a popular means of transportation,\nand with its popularity comes the concerns of privacy of riders and drivers.\nORide is a privacy-preserving RHS proposed in 2017 and uses Somewhat\nHomomorphic Encryption (SHE). In their protocol, a rider and all drivers in a\nzone send their encrypted coordinates to the RHS Service Provider (SP) who\ncomputes the squared Euclidean distances between them and forwards them to the\nrider. The rider decrypts these and selects the optimal driver with least\nEuclidean distance. In this work, we demonstrate a location-harvesting attack\nwhere an honest-but-curious rider, making only a single ride request, can\ndetermine the exact coordinates of about half the number of responding drivers\neven when only the distance between the rider and drivers are given. The\nsignificance of our attack lies not in inferring location of the optimal driver\n(which is anyway sent to the rider in clear after ride establishment) but in\ninferring locations of other drivers in the zone, who aren't (supposed to be)\nrevealed to the rider as per the protocol. We validate our attack by running\nexperiments on zones of varying sizes in arbitrarily selected big cities. Our\nattack is based on enumerating lattice points on a circle of sufficiently small\nradius and eliminating solutions based on conditions imposed by the application\nscenario. Finally, we propose a modification to ORide aimed at thwarting our\nattack and show that this modification provides sufficient driver anonymity\nwhile preserving ride matching accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2021 10:05:04 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Kumaraswamy", "Deepak", ""], ["Murthy", "Shyam", ""], ["Vivek", "Srinivas", ""]]}, {"id": "2101.06454", "submitter": "Daoyuan Wu", "authors": "Mengjie Chen, Daoyuan Wu, Xiao Yi, Jianliang Xu", "title": "AGChain: A Blockchain-based Gateway for Permanent, Distributed, and\n  Secure App Delegation from Existing Mobile App Markets", "comments": "This is a technical report from The Chinese Chinese University of\n  Hong Kong", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile app markets are emerging with the popularity of smartphones. However,\nthey fall short in several aspects, including no transparent app listing, no\nworld-wide app access, and even insecure app downloading. To address these\nproblems, we propose a novel blockchain-based gateway, AGChain, to bridge end\nusers and app markets so that existing app markets could still provide services\nwhile users enjoy permanent, distributed, and secure app delegation from\nAGChain. To this end, we identify two previously under-estimated challenges and\npropose mechanisms to significantly reduce gas costs in our smart contract and\nmake IPFS (Inter-planetary File System) based file storage really distributed.\nWe also address three AGChain-specific system challenges to make it secure and\nsustainable. We have implemented an AGChain prototype\n(https://www.agchain.ltd/) on Ethereum. The evaluation shows that it achieves\nsecurity and decentralization with minimal gas costs and reasonable\nperformance.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2021 15:19:21 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Chen", "Mengjie", ""], ["Wu", "Daoyuan", ""], ["Yi", "Xiao", ""], ["Xu", "Jianliang", ""]]}, {"id": "2101.06485", "submitter": "Bohdan Trach", "authors": "Bohdan Trach (1), Rasha Faqeh (1), Oleksii Oleksenko (1), Wojciech\n  Ozga (1), Pramod Bhatotia (2), Christof Fetzer (1) ((1) TU Dresden, (2) TU\n  M\\\"unich)", "title": "T-Lease: A Trusted Lease Primitive for Distributed Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A lease is an important primitive for building distributed protocols, and it\nis ubiquitously employed in distributed systems. However, the scope of the\nclassic lease abstraction is restricted to the trusted computing\ninfrastructure. Unfortunately, this important primitive cannot be employed in\nthe untrusted computing infrastructure because the trusted execution\nenvironments (TEEs) do not provide a trusted time source. In the untrusted\nenvironment, an adversary can easily manipulate the system clock to violate the\ncorrectness properties of lease-based systems. We tackle this problem by\nintroducing trusted lease -- a lease that maintains its correctness properties\neven in the presence of a clock-manipulating attacker. To achieve these\nproperties, we follow a \"trust but verify\" approach for an untrusted timer, and\ntransform it into a trusted timing primitive by leveraging two\nhardware-assisted ISA extensions (Intel TSX and SGX) available in commodity\nCPUs. We provide a design and implementation of trusted lease in a system\ncalled T-Lease -- the first trusted lease system that achieves high security,\nperformance, and precision. For the application developers, T-Lease exposes an\neasy-to-use generic APIs that facilitate its usage to build a wide range of\ndistributed protocols.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2021 17:23:16 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Trach", "Bohdan", ""], ["Faqeh", "Rasha", ""], ["Oleksenko", "Oleksii", ""], ["Ozga", "Wojciech", ""], ["Bhatotia", "Pramod", ""], ["Fetzer", "Christof", ""]]}, {"id": "2101.06519", "submitter": "Gueltoum Bendiab", "authors": "Faisal Alsakran, Gueltoum Bendiab, Stavros Shiaeles, Nicholas\n  Kolokotronis", "title": "Intrusion Detection Systems for Smart Home IoT Devices: Experimental\n  Comparison Study", "comments": "7 pages, 4 figures, 2 tables", "journal-ref": "International Symposium on Security in Computing and\n  Communication. SSCC 2019: Security in Computing and Communications", "doi": "10.1007/978-981-15-4825-3_7", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Smart homes are one of the most promising applications of the emerging\nInternet of Things (IoT) technology. With the growing number of IoT related\ndevices such as smart thermostats, smart fridges, smart speaker, smart light\nbulbs and smart locks, smart homes promise to make our lives easier and more\ncomfortable. However, the increased deployment of such smart devices brings an\nincrease in potential security risks and home privacy breaches. In order to\novercome such risks, Intrusion Detection Systems are presented as pertinent\ntools that can provide network-level protection for smart devices deployed in\nhome environments. These systems monitor the network activities of the smart\nhome-connected de-vices and focus on alerting suspicious or malicious activity.\nThey also can deal with detected abnormal activities by hindering the impostors\nin accessing the victim devices. However, the employment of such systems in the\ncontext of a smart home can be challenging due to the devices hardware\nlimitations, which may restrict their ability to counter the existing and\nemerging attack vectors. Therefore, this paper proposes an experimental\ncomparison between the widely used open-source NIDSs namely Snort, Suricata and\nBro IDS to find the most appropriate one for smart homes in term of detection\naccuracy and resources consumption including CP and memory utilization.\nExperimental Results show that Suricata is the best performing NIDS for smart\nhomes\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2021 20:46:43 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Alsakran", "Faisal", ""], ["Bendiab", "Gueltoum", ""], ["Shiaeles", "Stavros", ""], ["Kolokotronis", "Nicholas", ""]]}, {"id": "2101.06560", "submitter": "James Tu", "authors": "James Tu, Tsunhsuan Wang, Jingkang Wang, Sivabalan Manivasagam, Mengye\n  Ren, Raquel Urtasun", "title": "Adversarial Attacks On Multi-Agent Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Growing at a very fast pace, modern autonomous systems will soon be deployed\nat scale, opening up the possibility for cooperative multi-agent systems. By\nsharing information and distributing workloads, autonomous agents can better\nperform their tasks and enjoy improved computation efficiency. However, such\nadvantages rely heavily on communication channels which have been shown to be\nvulnerable to security breaches. Thus, communication can be compromised to\nexecute adversarial attacks on deep learning models which are widely employed\nin modern systems. In this paper, we explore such adversarial attacks in a\nnovel multi-agent setting where agents communicate by sharing learned\nintermediate representations. We observe that an indistinguishable adversarial\nmessage can severely degrade performance, but becomes weaker as the number of\nbenign agents increase. Furthermore, we show that transfer attacks are more\ndifficult in this setting when compared to directly perturbing the inputs, as\nit is necessary to align the distribution of communication messages with domain\nadaptation. Finally, we show that low-budget online attacks can be achieved by\nexploiting the temporal consistency of streaming sensory inputs.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2021 00:35:26 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Tu", "James", ""], ["Wang", "Tsunhsuan", ""], ["Wang", "Jingkang", ""], ["Manivasagam", "Sivabalan", ""], ["Ren", "Mengye", ""], ["Urtasun", "Raquel", ""]]}, {"id": "2101.06565", "submitter": "Muhammad R. A. Khandaker PhD", "authors": "Christantus O. Nnamani, Muhammad R. A. Khandaker, Mathini Sellathurai", "title": "Joint Beamforming and Location Optimization for Secure Data Collection\n  in Wireless Sensor Networks with UAV-Carried Intelligent Reflecting Surface", "comments": "Submitted to IEEE Transactions on Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers unmanned aerial vehicle (UAV)-carried intelligent\nreflecting surface (IRS) for secure data collection in wireless sensor\nnetworks. An eavesdropper (Eve) lurks within the vicinity of the main receiver\n(Bob) while several randomly placed sensor nodes beamform collaboratively to\nthe UAV-carried IRS that reflects the signal to the main receiver (Bob). The\ndesign objective is to maximise the achievable secrecy rate in the noisy\ncommunication channel by jointly optimizing the collaborative beamforming\nweights of the sensor nodes, the trajectory of the UAV and the reflection\ncoefficients of the IRS elements. By designing the IRS reflection coefficients\nwith and without the knowledge of the eavesdropper's channel, we develop a\nnon-iterative sub-optimal solution for the secrecy rate maximization problem.\nIt has been shown analytically that the UAV flight time and the randomness in\nthe distribution of the sensor nodes, obtained by varying the sensor\ndistribution area, can greatly affect secrecy performance. In addition, the\nmaximum allowable number of IRS elements as well as a bound on the attainable\naverage secrecy rate of the IRS aided noisy communication channel have also\nbeen derived. Extensive simulation results demonstrate the superior performance\nof the proposed algorithms compared to the existing schemes.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2021 01:05:08 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Nnamani", "Christantus O.", ""], ["Khandaker", "Muhammad R. A.", ""], ["Sellathurai", "Mathini", ""]]}, {"id": "2101.06570", "submitter": "Iyiola E. Olatunji", "authors": "Iyiola E. Olatunji, Wolfgang Nejdl and Megha Khosla", "title": "Membership Inference Attack on Graph Neural Networks", "comments": "Relaxation of assumptions, reasons why models are robust to MI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph Neural Networks (GNNs), which generalize traditional deep neural\nnetworks or graph data, have achieved state-of-the-art performance on several\ngraph analytical tasks like node classification, link prediction, or graph\nclassification. We focus on how trained GNN models could leak information about\nthe \\emph{member} nodes that they were trained on. We introduce two realistic\ninductive settings for carrying out a membership inference (MI) attack on GNNs.\nWhile choosing the simplest possible attack model that utilizes the posteriors\nof the trained model, we thoroughly analyze the properties of GNNs which\ndictate the differences in their robustness towards MI attack. The surprising\nand worrying fact is that the attack is successful even if the target model\ngeneralizes well. While in traditional machine learning models, overfitting is\nconsidered the main cause of such leakage, we show that in GNNs the additional\nstructural information is the major contributing factor. We support our\nfindings by extensive experiments on four representative GNN models. On a\npositive note, we identify properties of certain models which make them less\nvulnerable to MI attacks than others.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2021 02:12:35 GMT"}, {"version": "v2", "created": "Mon, 22 Mar 2021 21:12:16 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Olatunji", "Iyiola E.", ""], ["Nejdl", "Wolfgang", ""], ["Khosla", "Megha", ""]]}, {"id": "2101.06676", "submitter": "Mohammad Shojafar", "authors": "Ali Shahidinejad, Mostafa Ghobaei-Arani, Alireza Souri, Mohammad\n  Shojafar, Saru Kumari", "title": "A Technical Report for Light-Edge: A Lightweight Authentication Protocol\n  for IoT Devices in an Edge-Cloud Environment", "comments": "5 pages, 13 figures, 5 tables, technical report of IEEE Consumer\n  Electronics Magazine paper (Light-Edge)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.IT math.IT", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Selected procedures in [1] and additional simulation results are presented in\ndetail in this report. We first present the IoT device registration in Section\nI, and we provide the details of fuzzy-based trust computation in Section II.\nIn the end, we show some additional simulation results for formal validation of\nthe Light-Edge under On-the-Fly Model Checker (OFMC) and Constraint-Logic-based\nATtack SEarcher (CLAtse) tools in Section III. See the original paper [1] for\nmore detail.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2021 14:00:08 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Shahidinejad", "Ali", ""], ["Ghobaei-Arani", "Mostafa", ""], ["Souri", "Alireza", ""], ["Shojafar", "Mohammad", ""], ["Kumari", "Saru", ""]]}, {"id": "2101.06704", "submitter": "Xingjun Ma", "authors": "Nodens Koren, Qiuhong Ke, Yisen Wang, James Bailey, Xingjun Ma", "title": "Adversarial Interaction Attack: Fooling AI to Misinterpret Human\n  Intentions", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the actions of both humans and artificial intelligence (AI)\nagents is important before modern AI systems can be fully integrated into our\ndaily life. In this paper, we show that, despite their current huge success,\ndeep learning based AI systems can be easily fooled by subtle adversarial noise\nto misinterpret the intention of an action in interaction scenarios. Based on a\ncase study of skeleton-based human interactions, we propose a novel adversarial\nattack on interactions, and demonstrate how DNN-based interaction models can be\ntricked to predict the participants' reactions in unexpected ways. From a\nbroader perspective, the scope of our proposed attack method is not confined to\nproblems related to skeleton data but can also be extended to any type of\nproblems involving sequential regressions. Our study highlights potential risks\nin the interaction loop with AI and humans, which need to be carefully\naddressed when deploying AI systems in safety-critical applications.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2021 16:23:20 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Koren", "Nodens", ""], ["Ke", "Qiuhong", ""], ["Wang", "Yisen", ""], ["Bailey", "James", ""], ["Ma", "Xingjun", ""]]}, {"id": "2101.06761", "submitter": "Peng Gao", "authors": "Peng Gao, Fei Shao, Xiaoyuan Liu, Xusheng Xiao, Haoyuan Liu, Zheng\n  Qin, Fengyuan Xu, Prateek Mittal, Sanjeev R. Kulkarni, Dawn Song", "title": "A System for Efficiently Hunting for Cyber Threats in Computer Systems\n  Using Threat Intelligence", "comments": "Accepted paper at ICDE 2021 demonstrations track. arXiv admin note:\n  substantial text overlap with arXiv:2010.13637", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Log-based cyber threat hunting has emerged as an important solution to\ncounter sophisticated cyber attacks. However, existing approaches require\nnon-trivial efforts of manual query construction and have overlooked the rich\nexternal knowledge about threat behaviors provided by open-source Cyber Threat\nIntelligence (OSCTI). To bridge the gap, we build ThreatRaptor, a system that\nfacilitates cyber threat hunting in computer systems using OSCTI. Built upon\nmature system auditing frameworks, ThreatRaptor provides (1) an unsupervised,\nlight-weight, and accurate NLP pipeline that extracts structured threat\nbehaviors from unstructured OSCTI text, (2) a concise and expressive\ndomain-specific query language, TBQL, to hunt for malicious system activities,\n(3) a query synthesis mechanism that automatically synthesizes a TBQL query\nfrom the extracted threat behaviors, and (4) an efficient query execution\nengine to search the big system audit logging data.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2021 19:44:09 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 06:39:48 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Gao", "Peng", ""], ["Shao", "Fei", ""], ["Liu", "Xiaoyuan", ""], ["Xiao", "Xusheng", ""], ["Liu", "Haoyuan", ""], ["Qin", "Zheng", ""], ["Xu", "Fengyuan", ""], ["Mittal", "Prateek", ""], ["Kulkarni", "Sanjeev R.", ""], ["Song", "Dawn", ""]]}, {"id": "2101.06847", "submitter": "Thulasi Tholeti", "authors": "Thulasi Tholeti, Sheetal Kalyani", "title": "On the Differentially Private Nature of Perturbed Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of empirical risk minimization given a database,\nusing the gradient descent algorithm. We note that the function to be optimized\nmay be non-convex, consisting of saddle points which impede the convergence of\nthe algorithm. A perturbed gradient descent algorithm is typically employed to\nescape these saddle points. We show that this algorithm, that perturbs the\ngradient, inherently preserves the privacy of the data. We then employ the\ndifferential privacy framework to quantify the privacy hence achieved. We also\nanalyze the change in privacy with varying parameters such as problem dimension\nand the distance between the databases.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 02:29:37 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Tholeti", "Thulasi", ""], ["Kalyani", "Sheetal", ""]]}, {"id": "2101.06855", "submitter": "Dunjie Zhang", "authors": "Jinyin Chen, Dunjie Zhang, Zhaoyan Ming and Kejie Huang", "title": "GraphAttacker: A General Multi-Task GraphAttack Framework", "comments": "13 pages,8 figeures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have been successfully exploited in graph\nanalysis tasks in many real-world applications. However, GNNs have been shown\nto have potential security issues imposed by adversarial samples generated by\nattackers, which achieved great attack performance with almost imperceptible\nperturbations. What limit the wide application of these attackers are their\nmethods' specificity on a certain graph analysis task, such as node\nclassification or link prediction. We thus propose GraphAttacker, a novel\ngeneric graph attack framework that can flexibly adjust the structures and the\nattack strategies according to the graph analysis tasks. Based on the\nGenerative Adversarial Network (GAN), GraphAttacker generates adversarial\nsamples through alternate training on three key components, the Multi-strategy\nAttack Generator (MAG), the Similarity Discriminator (SD), and the Attack\nDiscriminator(AD). Furthermore, to achieve attackers within perturbation\nbudget, we propose a novel Similarity Modification Rate (SMR) to quantify the\nsimilarity between nodes thus constrain the attack budget. We carry out\nextensive experiments and the results show that GraphAttacker can achieve\nstate-of-the-art attack performance on graph analysis tasks of node\nclassification, graph classification, and link prediction. Besides, we also\nanalyze the unique characteristics of each task and their specific response in\nthe unified attack framework. We will release GraphAttacker as an open-source\nsimulation platform for future attack researches.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 03:06:41 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Chen", "Jinyin", ""], ["Zhang", "Dunjie", ""], ["Ming", "Zhaoyan", ""], ["Huang", "Kejie", ""]]}, {"id": "2101.06896", "submitter": "Yuanchun Li", "authors": "Yuanchun Li, Jiayi Hua, Haoyu Wang, Chunyang Chen, Yunxin Liu", "title": "DeepPayload: Black-box Backdoor Attack on Deep Learning Models through\n  Neural Payload Injection", "comments": "ICSE 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning models are increasingly used in mobile applications as critical\ncomponents. Unlike the program bytecode whose vulnerabilities and threats have\nbeen widely-discussed, whether and how the deep learning models deployed in the\napplications can be compromised are not well-understood since neural networks\nare usually viewed as a black box. In this paper, we introduce a highly\npractical backdoor attack achieved with a set of reverse-engineering techniques\nover compiled deep learning models. The core of the attack is a neural\nconditional branch constructed with a trigger detector and several operators\nand injected into the victim model as a malicious payload. The attack is\neffective as the conditional logic can be flexibly customized by the attacker,\nand scalable as it does not require any prior knowledge from the original\nmodel. We evaluated the attack effectiveness using 5 state-of-the-art deep\nlearning models and real-world samples collected from 30 users. The results\ndemonstrated that the injected backdoor can be triggered with a success rate of\n93.5%, while only brought less than 2ms latency overhead and no more than 1.4%\naccuracy decrease. We further conducted an empirical study on real-world mobile\ndeep learning apps collected from Google Play. We found 54 apps that were\nvulnerable to our attack, including popular and security-critical ones. The\nresults call for the awareness of deep learning application developers and\nauditors to enhance the protection of deployed models.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 06:29:30 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Li", "Yuanchun", ""], ["Hua", "Jiayi", ""], ["Wang", "Haoyu", ""], ["Chen", "Chunyang", ""], ["Liu", "Yunxin", ""]]}, {"id": "2101.07078", "submitter": "Alexander Viand", "authors": "Alexander Viand, Patrick Jattke, Anwar Hithnawi", "title": "SoK: Fully Homomorphic Encryption Compilers", "comments": "13 pages, to appear in IEEE Symposium on Security and Privacy 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully Homomorphic Encryption (FHE) allows a third party to perform arbitrary\ncomputations on encrypted data, learning neither the inputs nor the computation\nresults. Hence, it provides resilience in situations where computations are\ncarried out by an untrusted or potentially compromised party. This powerful\nconcept was first conceived by Rivest et al. in the 1970s. However, it remained\nunrealized until Craig Gentry presented the first feasible FHE scheme in 2009.\n  The advent of the massive collection of sensitive data in cloud services,\ncoupled with a plague of data breaches, moved highly regulated businesses to\nincreasingly demand confidential and secure computing solutions. This demand,\nin turn, has led to a recent surge in the development of FHE tools. To\nunderstand the landscape of recent FHE tool developments, we conduct an\nextensive survey and experimental evaluation to explore the current state of\nthe art and identify areas for future development.\n  In this paper, we survey, evaluate, and systematize FHE tools and compilers.\nWe perform experiments to evaluate these tools' performance and usability\naspects on a variety of applications. We conclude with recommendations for\ndevelopers intending to develop FHE-based applications and a discussion on\nfuture directions for FHE tools development.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 13:52:44 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Viand", "Alexander", ""], ["Jattke", "Patrick", ""], ["Hithnawi", "Anwar", ""]]}, {"id": "2101.07113", "submitter": "Markus Wurzenberger", "authors": "Markus Wurzenberger, Florian Skopik, Roman Fiedler, Wolfgang Kastner", "title": "Applying High-Performance Bioinformatics Tools for Outlier Detection in\n  Log Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of today's security solutions, such as security information and event\nmanagement (SIEM) and signature based IDS, require the operator to evaluate\npotential attack vectors and update detection signatures and rules in a timely\nmanner. However, today's sophisticated and tailored advanced persistent threats\n(APT), malware, ransomware and rootkits, can be so complex and diverse, and\noften use zero day exploits, that a pure signature-based blacklisting approach\nwould not be sufficient to detect them. Therefore, we could observe a major\nparadigm shift towards anomaly-based detection mechanisms, which try to\nestablish a system behavior baseline -- either based on netflow data or system\nlogging data -- and report any deviations from this baseline. While these\napproaches look promising, they usually suffer from scalability issues. As the\namount of log data generated during IT operations is exponentially growing,\nhigh-performance analysis methods are required that can handle this huge amount\nof data in real-time. In this paper, we demonstrate how high-performance\nbioinformatics tools can be applied to tackle this issue. We investigate their\napplication to log data for outlier detection to timely reveal anomalous system\nbehavior that points to cyber attacks. Finally, we assess the detection\ncapability and run-time performance of the proposed approach.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 15:13:11 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Wurzenberger", "Markus", ""], ["Skopik", "Florian", ""], ["Fiedler", "Roman", ""], ["Kastner", "Wolfgang", ""]]}, {"id": "2101.07223", "submitter": "Simon Pietro Romano", "authors": "Diego Antonelli, Roberta Cascella, Gaetano Perrone, Simon Pietro\n  Romano, Antonio Schiano", "title": "Leveraging AI to optimize website structure discovery during Penetration\n  Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Dirbusting is a technique used to brute force directories and file names on\nweb servers while monitoring HTTP responses, in order to enumerate server\ncontents. Such a technique uses lists of common words to discover the hidden\nstructure of the target website. Dirbusting typically relies on response codes\nas discovery conditions to find new pages. It is widely used in web application\npenetration testing, an activity that allows companies to detect websites\nvulnerabilities. Dirbusting techniques are both time and resource consuming and\ninnovative approaches have never been explored in this field. We hence propose\nan advanced technique to optimize the dirbusting process by leveraging\nArtificial Intelligence. More specifically, we use semantic clustering\ntechniques in order to organize wordlist items in different groups according to\ntheir semantic meaning. The created clusters are used in an ad-hoc implemented\nnext-word intelligent strategy. This paper demonstrates that the usage of\nclustering techniques outperforms the commonly used brute force methods.\nPerformance is evaluated by testing eight different web applications. Results\nshow a performance increase that is up to 50% for each of the conducted\nexperiments.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 18:21:42 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Antonelli", "Diego", ""], ["Cascella", "Roberta", ""], ["Perrone", "Gaetano", ""], ["Romano", "Simon Pietro", ""], ["Schiano", "Antonio", ""]]}, {"id": "2101.07292", "submitter": "Rainer Rehak", "authors": "Kirsten Bock, Christian R. K\\\"uhne, Rainer M\\\"uhlhoff, M\\v{e}to R.\n  Ost, J\\\"org Pohle, Rainer Rehak", "title": "Data Protection Impact Assessment for the Corona App", "comments": "97 pages, German version here: https://www.fiff.de/dsfa-corona", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since SARS-CoV-2 started spreading in Europe in early 2020, there has been a\nstrong call for technical solutions to combat or contain the pandemic, with\ncontact tracing apps at the heart of the debates. The EU's General Daten\nProtection Regulation (GDPR) requires controllers to carry out a data\nprotection impact assessment (DPIA) where their data processing is likely to\nresult in a high risk to the rights and freedoms (Art. 35 GDPR). A DPIA is a\nstructured risk analysis that identifies and evaluates possible consequences of\ndata processing relevant to fundamental rights and describes the measures\nenvisaged to address these risks or expresses the inability to do so. Based on\nthe Standard Data Protection Model (SDM), we present a scientific DPIA which\nthoroughly examines three published contact tracing app designs that are\nconsidered to be the most \"privacy-friendly\": PEPP-PT, DP-3T and a concept\nsummarized by Chaos Computer Club member Linus Neumann, all of which process\npersonal health data. The DPIA starts with an analysis of the processing\ncontext and some expected use cases. Then, the processing activities are\ndescribed by defining a realistic processing purpose. This is followed by the\nlegal assessment and threshold analysis. Finally, we analyse the weak points,\nthe risks and determine appropriate protective measures. We show that even\ndecentralized implementations involve numerous serious weaknesses and risks.\nLegally, consent is unfit as legal ground hence data must be processed based on\na law. We also found that measures to realize the rights of data subjects and\naffected people are not sufficient. Last but not least, we show that\nanonymization must be understood as a continuous process, which aims at\nseparating the personal reference and is based on a mix of legal,\norganizational and technical measures. All currently available proposals lack\nsuch an explicit separation process.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 19:23:30 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Bock", "Kirsten", ""], ["K\u00fchne", "Christian R.", ""], ["M\u00fchlhoff", "Rainer", ""], ["Ost", "M\u011bto R.", ""], ["Pohle", "J\u00f6rg", ""], ["Rehak", "Rainer", ""]]}, {"id": "2101.07328", "submitter": "Mohsen Ahmadi", "authors": "Mohsen Ahmadi, Kevin Leach, Ryan Dougherty, Stephanie Forrest, and\n  Westley Weimer", "title": "MIMOSA: Reducing Malware Analysis Overhead with Coverings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There is a growing body of malware samples that evade automated analysis and\ndetection tools. Malware may measure fingerprints (\"artifacts\") of the\nunderlying analysis tool or environment and change their behavior when\nartifacts are detected. While analysis tools can mitigate artifacts to reduce\nexposure, such concealment is expensive. However, not every sample checks for\nevery type of artifact-analysis efficiency can be improved by mitigating only\nthose artifacts most likely to be used by a sample. Using that insight, we\npropose MIMOSA, a system that identifies a small set of \"covering\" tool\nconfigurations that collectively defeat most malware samples with increased\nefficiency. MIMOSA identifies a set of tool configurations that maximize\nanalysis throughput and detection accuracy while minimizing manual effort,\nenabling scalable automation to analyze stealthy malware. We evaluate our\napproach against a benchmark of 1535 labeled stealthy malware samples. Our\napproach increases analysis throughput over state of the art on over 95% of\nthese samples. We also investigate cost-benefit tradeoffs between the fraction\nof successfully-analyzed samples and computing resources required. MIMOSA\nprovides a practical, tunable method for efficiently deploying analysis\nresources.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 21:06:52 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Ahmadi", "Mohsen", ""], ["Leach", "Kevin", ""], ["Dougherty", "Ryan", ""], ["Forrest", "Stephanie", ""], ["Weimer", "Westley", ""]]}, {"id": "2101.07365", "submitter": "Rafael Dowsley", "authors": "Amanda Resende, Davis Railsback, Rafael Dowsley, Anderson C. A.\n  Nascimento, Diego F. Aranha", "title": "Fast Privacy-Preserving Text Classification based on Secure Multiparty\n  Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a privacy-preserving Naive Bayes classifier and apply it to the\nproblem of private text classification. In this setting, a party (Alice) holds\na text message, while another party (Bob) holds a classifier. At the end of the\nprotocol, Alice will only learn the result of the classifier applied to her\ntext input and Bob learns nothing. Our solution is based on Secure Multiparty\nComputation (SMC). Our Rust implementation provides a fast and secure solution\nfor the classification of unstructured text. Applying our solution to the case\nof spam detection (the solution is generic, and can be used in any other\nscenario in which the Naive Bayes classifier can be employed), we can classify\nan SMS as spam or ham in less than 340ms in the case where the dictionary size\nof Bob's model includes all words (n = 5200) and Alice's SMS has at most m =\n160 unigrams. In the case with n = 369 and m = 8 (the average of a spam SMS in\nthe database), our solution takes only 21ms.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 23:08:12 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 06:26:21 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Resende", "Amanda", ""], ["Railsback", "Davis", ""], ["Dowsley", "Rafael", ""], ["Nascimento", "Anderson C. A.", ""], ["Aranha", "Diego F.", ""]]}, {"id": "2101.07377", "submitter": "Sanchari Das", "authors": "Sanchari Das and Robert S. Gutzwiller and Rod D. Roscoe and Prashanth\n  Rajivan and Yang Wang and L. Jean Camp and Roberto Hoyle", "title": "Panel: Humans and Technology for Inclusive Privacy and Security", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Computer security and user privacy are critical issues and concerns in the\ndigital era due to both increasing users and threats to their data. Separate\nissues arise between generic cybersecurity guidance (i.e., protect all user\ndata from malicious threats) and the individualistic approach of privacy (i.e.,\nspecific to users and dependent on user needs and risk perceptions). Research\nhas shown that several security- and privacy-focused vulnerabilities are\ntechnological (e.g., software bugs (Streiff, Kenny, Das, Leeth, & Camp, 2018),\ninsecure authentication (Das, Wang, Tingle, & Camp, 2019)), or behavioral\n(e.g., sharing passwords (Das, Dingman, & Camp, 2018); and compliance (Das,\nDev, & Srinivasan, 2018) (Dev, Das, Rashidi, & Camp, 2019)). This panel\nproposal addresses a third category of sociotechnical vulnerabilities that can\nand sometimes do arise from non-inclusive design of security and privacy. In\nthis panel, we will address users' needs and desires for privacy. The panel\nwill engage in in-depth discussions about value-sensitive design while focusing\non potentially vulnerable populations, such as older adults, teens, persons\nwith disabilities, and others who are not typically emphasized in general\nsecurity and privacy concerns. Human factors have a stake in and ability to\nfacilitate improvements in these areas.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 23:35:42 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Das", "Sanchari", ""], ["Gutzwiller", "Robert S.", ""], ["Roscoe", "Rod D.", ""], ["Rajivan", "Prashanth", ""], ["Wang", "Yang", ""], ["Camp", "L. Jean", ""], ["Hoyle", "Roberto", ""]]}, {"id": "2101.07750", "submitter": "Hua Sun", "authors": "Yizhou Zhao, Hua Sun", "title": "Information Theoretic Secure Aggregation with User Dropouts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the robust secure aggregation problem, a server wishes to learn and only\nlearn the sum of the inputs of a number of users while some users may drop out\n(i.e., may not respond). The identity of the dropped users is not known a\npriori and the server needs to securely recover the sum of the remaining\nsurviving users. We consider the following minimal two-round model of secure\naggregation. Over the first round, any set of no fewer than $U$ users out of\n$K$ users respond to the server and the server wants to learn the sum of the\ninputs of all responding users. The remaining users are viewed as dropped. Over\nthe second round, any set of no fewer than $U$ users of the surviving users\nrespond (i.e., dropouts are still possible over the second round) and from the\ninformation obtained from the surviving users over the two rounds, the server\ncan decode the desired sum. The security constraint is that even if the server\ncolludes with any $T$ users and the messages from the dropped users are\nreceived by the server (e.g., delayed packets), the server is not able to infer\nany additional information beyond the sum in the information theoretic sense.\nFor this information theoretic secure aggregation problem, we characterize the\noptimal communication cost. When $U \\leq T$, secure aggregation is not\nfeasible, and when $U > T$, to securely compute one symbol of the sum, the\nminimum number of symbols sent from each user to the server is $1$ over the\nfirst round, and $1/(U-T)$ over the second round.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 17:43:48 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Zhao", "Yizhou", ""], ["Sun", "Hua", ""]]}, {"id": "2101.07769", "submitter": "Peng Gao", "authors": "Peng Gao, Xiaoyuan Liu, Edward Choi, Bhavna Soman, Chinmaya Mishra,\n  Kate Farris, Dawn Song", "title": "A System for Automated Open-Source Threat Intelligence Gathering and\n  Management", "comments": "Accepted paper at SIGMOD 2021 demonstrations track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To remain aware of the fast-evolving cyber threat landscape, open-source\nCyber Threat Intelligence (OSCTI) has received growing attention from the\ncommunity. Commonly, knowledge about threats is presented in a vast number of\nOSCTI reports. Despite the pressing need for high-quality OSCTI, existing OSCTI\ngathering and management platforms, however, have primarily focused on\nisolated, low-level Indicators of Compromise. On the other hand, higher-level\nconcepts (e.g., adversary tactics, techniques, and procedures) and their\nrelationships have been overlooked, which contain essential knowledge about\nthreat behaviors that is critical to uncovering the complete threat scenario.\nTo bridge the gap, we propose SecurityKG, a system for automated OSCTI\ngathering and management. SecurityKG collects OSCTI reports from various\nsources, uses a combination of AI and NLP techniques to extract high-fidelity\nknowledge about threat behaviors, and constructs a security knowledge graph.\nSecurityKG also provides a UI that supports various types of interactivity to\nfacilitate knowledge graph exploration.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 18:31:35 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 20:50:51 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Gao", "Peng", ""], ["Liu", "Xiaoyuan", ""], ["Choi", "Edward", ""], ["Soman", "Bhavna", ""], ["Mishra", "Chinmaya", ""], ["Farris", "Kate", ""], ["Song", "Dawn", ""]]}, {"id": "2101.07841", "submitter": "Meghan Cowan", "authors": "Meghan Cowan, Deeksha Dangwal, Armin Alaghi, Caroline Trippel, Vincent\n  T. Lee, Brandon Reagen", "title": "Porcupine: A Synthesizing Compiler for Vectorized Homomorphic Encryption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Homomorphic encryption (HE) is a privacy-preserving technique that enables\ncomputation directly on encrypted data. Despite its promise, HE has seen\nlimited use due to performance overheads and compilation challenges. Recent\nwork has made significant advances to address the performance overheads but\nautomatic compilation of efficient HE kernels remains relatively unexplored.\n  This paper presents Porcupine, an optimizing compiler, and HE DSL named Quill\nto automatically generate HE code using program synthesis. HE poses three major\ncompilation challenges: it only supports a limited set of SIMD-like operators,\nit uses long-vector operands, and decryption can fail if ciphertext noise\ngrowth is not managed properly. Quill captures the underlying HE operator\nbehavior that enables Porcupine to reason about the complex trade-offs imposed\nby the challenges and generate optimized, verified HE kernels. To improve\nsynthesis time, we propose a series of optimizations including a sketch design\ntailored to HE and instruction restriction to narrow the program search space.\nWe evaluate Procupine using a set of kernels and show speedups of up to 51%\n(11% geometric mean) compared to heuristic-driven hand-optimized kernels.\nAnalysis of Porcupine's synthesized code reveals that optimal solutions are not\nalways intuitive, underscoring the utility of automated reasoning in this\ndomain.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 20:06:33 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Cowan", "Meghan", ""], ["Dangwal", "Deeksha", ""], ["Alaghi", "Armin", ""], ["Trippel", "Caroline", ""], ["Lee", "Vincent T.", ""], ["Reagen", "Brandon", ""]]}, {"id": "2101.07897", "submitter": "Vikram Sharma Mailthody", "authors": "Vikram Sharma Mailthody and James Wei and Nicholas Chen and Mohammad\n  Behnia and Ruihao Yao and Qihao Wang and Vedant Agrawal and Churan He and\n  Lijian Wang and Leihao Chen and Amit Agarwal and Edward Richter and Wen-Mei\n  Hwu and Christopher W. Fletcher and Jinjun Xiong and Andrew Miller and Sanjay\n  Patel", "title": "Safer Illinois and RokWall: Privacy Preserving University Health Apps\n  for COVID-19", "comments": "Appears in the Workshop on Secure IT Technologies against\n  COVID-19(CoronaDef) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  COVID-19 has fundamentally disrupted the way we live. Government bodies,\nuniversities, and companies worldwide are rapidly developing technologies to\ncombat the COVID-19 pandemic and safely reopen society. Essential analytics\ntools such as contact tracing, super-spreader event detection, and exposure\nmapping require collecting and analyzing sensitive user information. The\nincreasing use of such powerful data-driven applications necessitates a secure,\nprivacy-preserving infrastructure for computation on personal data. In this\npaper, we analyze two such computing infrastructures under development at the\nUniversity of Illinois at Urbana-Champaign to track and mitigate the spread of\nCOVID-19. First, we present Safer Illinois, a system for decentralized health\nanalytics supporting two applications currently deployed with widespread\nadoption: digital contact tracing and COVID-19 status cards. Second, we\nintroduce the RokWall architecture for privacy-preserving centralized data\nanalytics on sensitive user data. We discuss the architecture of these systems,\ndesign choices, threat models considered, and the challenges we experienced in\ndeveloping production-ready systems for sensitive data analysis.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 23:36:14 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 16:06:19 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Mailthody", "Vikram Sharma", ""], ["Wei", "James", ""], ["Chen", "Nicholas", ""], ["Behnia", "Mohammad", ""], ["Yao", "Ruihao", ""], ["Wang", "Qihao", ""], ["Agrawal", "Vedant", ""], ["He", "Churan", ""], ["Wang", "Lijian", ""], ["Chen", "Leihao", ""], ["Agarwal", "Amit", ""], ["Richter", "Edward", ""], ["Hwu", "Wen-Mei", ""], ["Fletcher", "Christopher W.", ""], ["Xiong", "Jinjun", ""], ["Miller", "Andrew", ""], ["Patel", "Sanjay", ""]]}, {"id": "2101.07912", "submitter": "Johannes Klick", "authors": "Johannes Klick, Robert Koch and Thomas Brandstetter", "title": "Epidemic? The Attack Surface of German Hospitals during the COVID-19\n  Pandemic", "comments": "Preprint for NATO CCDCOE Annual International Conference on Cyber\n  Conflict (CyCon) [Paper submitted to Peer Review Process]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our paper we analyze the attack surface of German hospitals and healthcare\nproviders in 2020 during the COVID-19 Pandemic. The analysis looked at the\npublicly visible attack surface utilizing a Distributed Cyber Recon System,\nutilizing distributed Internet scanning, Big Data methods and scan data of\n1,483 GB from more than 89 different global Internet scans. From the 1,555\nidentified German clinical entities, security posture analysis was conducted by\nlooking at more than 13,000 service banners for version identification and\nsubsequent CVE-based vulnerability identification. Primary analysis shows that\n32 percent of the analyzed services were determined as vulnerable to various\ndegrees and 36 percent of all hospitals showed numerous vulnerabilities.\nFurther resulting vulnerability statistics were mapped against size of\norganization and hospital bed count.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 00:45:02 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Klick", "Johannes", ""], ["Koch", "Robert", ""], ["Brandstetter", "Thomas", ""]]}, {"id": "2101.07922", "submitter": "Valeriia Cherepanova", "authors": "Valeriia Cherepanova, Micah Goldblum, Harrison Foley, Shiyuan Duan,\n  John Dickerson, Gavin Taylor, Tom Goldstein", "title": "LowKey: Leveraging Adversarial Attacks to Protect Social Media Users\n  from Facial Recognition", "comments": "Published as a conference paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facial recognition systems are increasingly deployed by private corporations,\ngovernment agencies, and contractors for consumer services and mass\nsurveillance programs alike. These systems are typically built by scraping\nsocial media profiles for user images. Adversarial perturbations have been\nproposed for bypassing facial recognition systems. However, existing methods\nfail on full-scale systems and commercial APIs. We develop our own adversarial\nfilter that accounts for the entire image processing pipeline and is\ndemonstrably effective against industrial-grade pipelines that include face\ndetection and large scale databases. Additionally, we release an easy-to-use\nwebtool that significantly degrades the accuracy of Amazon Rekognition and the\nMicrosoft Azure Face Recognition API, reducing the accuracy of each to below\n1%.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 01:40:06 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 04:23:22 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Cherepanova", "Valeriia", ""], ["Goldblum", "Micah", ""], ["Foley", "Harrison", ""], ["Duan", "Shiyuan", ""], ["Dickerson", "John", ""], ["Taylor", "Gavin", ""], ["Goldstein", "Tom", ""]]}, {"id": "2101.07931", "submitter": "Rohan Sukumaran", "authors": "Joseph Bae, Rohan Sukumaran, Sheshank Shankar, Saurish Srivastava,\n  Rohan Iyer, Aryan Mahindra, Qamil Mirza, Maurizio Arseni, Anshuman Sharma,\n  Saras Agrawal, Orna Mukhopadhyay, Colin Kang, Priyanshi Katiyar, Apurv\n  Shekhar, Sifat Hasan, Krishnendu Dasgupta, Darshan Gandhi, Sethuramen TV,\n  Parth Patwa, Ishaan Singh, Abhishek Singh and Ramesh Raskar", "title": "MIT SafePaths Card (MiSaCa): Augmenting Paper Based Vaccination Cards\n  with Printed Codes", "comments": "8 pages, 4 Figures, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this early draft, we describe a user-centric, card-based system for\nvaccine distribution. Our system makes use of digitally signed QR codes and\ntheir use for phased vaccine distribution, vaccine\nadministration/record-keeping, immunization verification, and follow-up symptom\nreporting. Furthermore, we propose and describe a complementary scanner app\nsystem to be used by vaccination clinics, public health officials, and\nimmunization verification parties to effectively utilize card-based framework.\nWe believe that the proposed system provides a privacy-preserving and efficient\nframework for vaccine distribution in both developed and developing regions.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 02:22:56 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 16:55:23 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Bae", "Joseph", ""], ["Sukumaran", "Rohan", ""], ["Shankar", "Sheshank", ""], ["Srivastava", "Saurish", ""], ["Iyer", "Rohan", ""], ["Mahindra", "Aryan", ""], ["Mirza", "Qamil", ""], ["Arseni", "Maurizio", ""], ["Sharma", "Anshuman", ""], ["Agrawal", "Saras", ""], ["Mukhopadhyay", "Orna", ""], ["Kang", "Colin", ""], ["Katiyar", "Priyanshi", ""], ["Shekhar", "Apurv", ""], ["Hasan", "Sifat", ""], ["Dasgupta", "Krishnendu", ""], ["Gandhi", "Darshan", ""], ["TV", "Sethuramen", ""], ["Patwa", "Parth", ""], ["Singh", "Ishaan", ""], ["Singh", "Abhishek", ""], ["Raskar", "Ramesh", ""]]}, {"id": "2101.07981", "submitter": "Cl\\'ement Canonne", "authors": "Jayadev Acharya, Cl\\'ement L. Canonne, Cody Freitag, Ziteng Sun,\n  Himanshu Tyagi", "title": "Inference under Information Constraints III: Local Privacy Constraints", "comments": "To appear in the Special Issue on Privacy and Security of Information\n  Systems of the IEEE Journal on Selected Areas in Information Theory (JSAIT),\n  2021. Journal version of the AISTATS'19 paper \"Test without Trust: Optimal\n  Locally Private Distribution Testing\" (arXiv:1808.02174), which it extends\n  and supersedes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.DM math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study goodness-of-fit and independence testing of discrete distributions\nin a setting where samples are distributed across multiple users. The users\nwish to preserve the privacy of their data while enabling a central server to\nperform the tests. Under the notion of local differential privacy, we propose\nsimple, sample-optimal, and communication-efficient protocols for these two\nquestions in the noninteractive setting, where in addition users may or may not\nshare a common random seed. In particular, we show that the availability of\nshared (public) randomness greatly reduces the sample complexity. Underlying\nour public-coin protocols are privacy-preserving mappings which, when applied\nto the samples, minimally contract the distance between their respective\nprobability distributions.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 06:07:49 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Acharya", "Jayadev", ""], ["Canonne", "Cl\u00e9ment L.", ""], ["Freitag", "Cody", ""], ["Sun", "Ziteng", ""], ["Tyagi", "Himanshu", ""]]}, {"id": "2101.08030", "submitter": "Francesco Cartella", "authors": "Francesco Cartella, Orlando Anunciacao, Yuki Funabiki, Daisuke\n  Yamaguchi, Toru Akishita, Olivier Elshocht", "title": "Adversarial Attacks for Tabular Data: Application to Fraud Detection and\n  Imbalanced Data", "comments": "Will be published on Proceedings of the Workshop on Artificial\n  Intelligence Safety (SafeAI 2021) co-located with 35th AAAI Conference on\n  Artificial Intelligence (AAAI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Guaranteeing the security of transactional systems is a crucial priority of\nall institutions that process transactions, in order to protect their\nbusinesses against cyberattacks and fraudulent attempts. Adversarial attacks\nare novel techniques that, other than being proven to be effective to fool\nimage classification models, can also be applied to tabular data. Adversarial\nattacks aim at producing adversarial examples, in other words, slightly\nmodified inputs that induce the Artificial Intelligence (AI) system to return\nincorrect outputs that are advantageous for the attacker. In this paper we\nillustrate a novel approach to modify and adapt state-of-the-art algorithms to\nimbalanced tabular data, in the context of fraud detection. Experimental\nresults show that the proposed modifications lead to a perfect attack success\nrate, obtaining adversarial examples that are also less perceptible when\nanalyzed by humans. Moreover, when applied to a real-world production system,\nthe proposed techniques shows the possibility of posing a serious threat to the\nrobustness of advanced AI-based fraud detection procedures.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 08:58:29 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Cartella", "Francesco", ""], ["Anunciacao", "Orlando", ""], ["Funabiki", "Yuki", ""], ["Yamaguchi", "Daisuke", ""], ["Akishita", "Toru", ""], ["Elshocht", "Olivier", ""]]}, {"id": "2101.08132", "submitter": "Chris Mitchell", "authors": "Chris J Mitchell", "title": "The (in)security of some recently proposed lightweight key distribution\n  schemes", "comments": "This version adds a brief critique of a related paper on secure\n  multiparty computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two recently published papers propose some very simple key distribution\nschemes designed to enable two or more parties to establish a shared secret key\nwith the aid of a third party. Unfortunately, as we show, most of the schemes\nare inherently insecure and all are incompletely specified - moreover, claims\nthat the schemes are inherently lightweight are shown to be highly misleading.\nWe also briefly critique a somewhat related very recent paper by the same\nauthors that uses similar techniques to achieve what are claimed to be secure\nmultiparty computations.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 13:57:48 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 16:55:05 GMT"}, {"version": "v3", "created": "Sat, 13 Mar 2021 12:21:58 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Mitchell", "Chris J", ""]]}, {"id": "2101.08177", "submitter": "Ximing Qiao", "authors": "Ximing Qiao, Yuhua Bai, Siping Hu, Ang Li, Yiran Chen, Hai Li", "title": "On Provable Backdoor Defense in Collaborative Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As collaborative learning allows joint training of a model using multiple\nsources of data, the security problem has been a central concern. Malicious\nusers can upload poisoned data to prevent the model's convergence or inject\nhidden backdoors. The so-called backdoor attacks are especially difficult to\ndetect since the model behaves normally on standard test data but gives wrong\noutputs when triggered by certain backdoor keys. Although Byzantine-tolerant\ntraining algorithms provide convergence guarantee, provable defense against\nbackdoor attacks remains largely unsolved. Methods based on randomized\nsmoothing can only correct a small number of corrupted pixels or labels;\nmethods based on subset aggregation cause a severe drop in classification\naccuracy due to low data utilization. We propose a novel framework that\ngeneralizes existing subset aggregation methods. The framework shows that the\nsubset selection process, a deciding factor for subset aggregation methods, can\nbe viewed as a code design problem. We derive the theoretical bound of data\nutilization ratio and provide optimal code construction. Experiments on non-IID\nversions of MNIST and CIFAR-10 show that our method with optimal codes\nsignificantly outperforms baselines using non-overlapping partition and random\nselection. Additionally, integration with existing coding theory results shows\nthat special codes can track the location of the attackers. Such capability\nprovides new countermeasures to backdoor attacks.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2021 14:39:32 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Qiao", "Ximing", ""], ["Bai", "Yuhua", ""], ["Hu", "Siping", ""], ["Li", "Ang", ""], ["Chen", "Yiran", ""], ["Li", "Hai", ""]]}, {"id": "2101.08204", "submitter": "Do Le Quoc", "authors": "Do Le Quoc, Franz Gregor, Sergei Arnautov, Roland Kunkel, Pramod\n  Bhatotia, Christof Fetzer", "title": "secureTF: A Secure TensorFlow Framework", "comments": "arXiv admin note: text overlap with arXiv:1902.04413", "journal-ref": "Pages 44-59, 2020", "doi": "10.1145/3423211.3425687", "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data-driven intelligent applications in modern online services have become\nubiquitous. These applications are usually hosted in the untrusted cloud\ncomputing infrastructure. This poses significant security risks since these\napplications rely on applying machine learning algorithms on large datasets\nwhich may contain private and sensitive information.\n  To tackle this challenge, we designed secureTF, a distributed secure machine\nlearning framework based on Tensorflow for the untrusted cloud infrastructure.\nsecureTF is a generic platform to support unmodified TensorFlow applications,\nwhile providing end-to-end security for the input data, ML model, and\napplication code. secureTF is built from ground-up based on the security\nproperties provided by Trusted Execution Environments (TEEs). However, it\nextends the trust of a volatile memory region (or secure enclave) provided by\nthe single node TEE to secure a distributed infrastructure required for\nsupporting unmodified stateful machine learning applications running in the\ncloud.\n  The paper reports on our experiences about the system design choices and the\nsystem deployment in production use-cases. We conclude with the lessons learned\nbased on the limitations of our commercially available platform, and discuss\nopen research problems for the future work.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 16:36:53 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Quoc", "Do Le", ""], ["Gregor", "Franz", ""], ["Arnautov", "Sergei", ""], ["Kunkel", "Roland", ""], ["Bhatotia", "Pramod", ""], ["Fetzer", "Christof", ""]]}, {"id": "2101.08254", "submitter": "Jingtao Li", "authors": "Jingtao Li, Adnan Siraj Rakin, Zhezhi He, Deliang Fan, Chaitali\n  Chakrabarti", "title": "RADAR: Run-time Adversarial Weight Attack Detection and Accuracy\n  Recovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adversarial attacks on Neural Network weights, such as the progressive\nbit-flip attack (PBFA), can cause a catastrophic degradation in accuracy by\nflipping a very small number of bits. Furthermore, PBFA can be conducted at run\ntime on the weights stored in DRAM main memory. In this work, we propose RADAR,\na Run-time adversarial weight Attack Detection and Accuracy Recovery scheme to\nprotect DNN weights against PBFA. We organize weights that are interspersed in\na layer into groups and employ a checksum-based algorithm on weights to derive\na 2-bit signature for each group. At run time, the 2-bit signature is computed\nand compared with the securely stored golden signature to detect the bit-flip\nattacks in a group. After successful detection, we zero out all the weights in\na group to mitigate the accuracy drop caused by malicious bit-flips. The\nproposed scheme is embedded in the inference computation stage. For the\nResNet-18 ImageNet model, our method can detect 9.6 bit-flips out of 10 on\naverage. For this model, the proposed accuracy recovery scheme can restore the\naccuracy from below 1% caused by 10 bit flips to above 69%. The proposed method\nhas extremely low time and storage overhead. System-level simulation on gem5\nshows that RADAR only adds <1% to the inference time, making this scheme highly\nsuitable for run-time attack detection and mitigation.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 18:55:51 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Li", "Jingtao", ""], ["Rakin", "Adnan Siraj", ""], ["He", "Zhezhi", ""], ["Fan", "Deliang", ""], ["Chakrabarti", "Chaitali", ""]]}, {"id": "2101.08423", "submitter": "Yue Li", "authors": "Wenqi Zhao, Hui Li, Yuming Yuan", "title": "Understand Volatility of Algorithmic Stablecoin: Modeling, Verification\n  and Empirical Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An algorithmic stablecoin is a type of cryptocurrency managed by algorithms\n(i.e., smart contracts) to dynamically minimize the volatility of its price\nrelative to a specific form of asset, e.g., US dollar. As algorithmic\nstablecoins have been growing rapidly in recent years, they become much more\nvolatile than expected. In this paper, we took a deep dive into the core of\nalgorithmic stablecoins and shared our answer to two fundamental research\nquestions, i.e., Are algorithmic stablecoins volatile by design? Are they\nvolatile in practice? Specifically, we introduced an in-depth study on three\npopular types of algorithmic stablecoins and developed a modeling framework to\nformalize their key design protocols. Through formal verification, the\nframework can identify critical conditions under which stablecoins might become\nvolatile. Furthermore, we performed a systematic empirical analysis on real\ntransaction activities of the Basis Cash stablecoin to relate theoretical\npossibilities to market observations. Lastly, we highlighted key design\ndecisions for future development of algorithmic stablecoins.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 03:39:18 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Zhao", "Wenqi", ""], ["Li", "Hui", ""], ["Yuan", "Yuming", ""]]}, {"id": "2101.08428", "submitter": "Joshua Tobkin", "authors": "Joshua D. Tobkin", "title": "Introducing the Unitychain Structure: A novel blockchain-like structure\n  that enables greater parallel processing, security, and performance for\n  networks that leverage distributed key generation and classical consensus\n  protocols", "comments": "16 pages, 7 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A Unitychain is a novel blockchain-like structure that drastically improves\ntransaction scalability and security while maintaining ongoing network\nperformance, even if participating nodes are required to perform a new\nDistributed Key Generation procedure for security purposes. The Unitychain\nstructure, furthermore, enables greater parallel processing by the assignment\nof different network node configurations for various database and compute\nranges into multiple strands of blockchains that intersect, creating a\nmulti-helix structure, which we call a Unitychain. This thereby enables the\nnetwork to further bifurcate the roles of nodes into arbitrary yet\ndeterministic network responsibilities in order to maximize the global compute\npotential.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 03:57:41 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Tobkin", "Joshua D.", ""]]}, {"id": "2101.08429", "submitter": "Zahid Akhtar", "authors": "Zahid Akhtar", "title": "Malware Detection and Analysis: Challenges and Research Opportunities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Malwares are continuously growing in sophistication and numbers. Over the\nlast decade, remarkable progress has been achieved in anti-malware mechanisms.\nHowever, several pressing issues (e.g., unknown malware samples detection)\nstill need to be addressed adequately. This article first presents a concise\noverview of malware along with anti-malware and then summarizes various\nresearch challenges. This is a theoretical and perspective article that is\nhoped to complement earlier articles and works.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 03:59:19 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Akhtar", "Zahid", ""]]}, {"id": "2101.08478", "submitter": "Pierre Champion", "authors": "Pierre Champion (MULTISPEECH), Denis Jouvet (MULTISPEECH), Anthony\n  Larcher (LIUM)", "title": "A Study of F0 Modification for X-Vector Based Speech Pseudonymization\n  Across Gender", "comments": null, "journal-ref": "The Second AAAI Workshop on Privacy-Preserving Artificial\n  Intelligence, Feb 2021, Nancy, France", "doi": null, "report-no": null, "categories": "eess.AS cs.CR cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech pseudonymization aims at altering a speech signal to map the\nidentifiable personal characteristics of a given speaker to another identity.\nIn other words, it aims to hide the source speaker identity while preserving\nthe intelligibility of the spoken content. This study takes place in the\nVoicePrivacy 2020 challenge framework, where the baseline system performs\npseudonymization by modifying x-vector information to match a target speaker\nwhile keeping the fundamental frequency (F0) unchanged. We propose to alter\nother paralin-guistic features, here F0, and analyze the impact of this\nmodification across gender. We found that the proposed F0 modification always\nimproves pseudonymization We observed that both source and target speaker\ngenders affect the performance gain when modifying the F0.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 07:33:07 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Champion", "Pierre", "", "MULTISPEECH"], ["Jouvet", "Denis", "", "MULTISPEECH"], ["Larcher", "Anthony", "", "LIUM"]]}, {"id": "2101.08658", "submitter": "Ofer Mendelevitch", "authors": "Ofer Mendelevitch, Michael D. Lesh", "title": "Fidelity and Privacy of Synthetic Medical Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The digitization of medical records ushered in a new era of big data to\nclinical science, and with it the possibility that data could be shared, to\nmultiply insights beyond what investigators could abstract from paper records.\nThe need to share individual-level medical data to accelerate innovation in\nprecision medicine continues to grow, and has never been more urgent, as\nscientists grapple with the COVID-19 pandemic. However, enthusiasm for the use\nof big data has been tempered by a fully appropriate concern for patient\nautonomy and privacy. That is, the ability to extract private or confidential\ninformation about an individual, in practice, renders it difficult to share\ndata, since significant infrastructure and data governance must be established\nbefore data can be shared. Although HIPAA provided de-identification as an\napproved mechanism for data sharing, linkage attacks were identified as a major\nvulnerability. A variety of mechanisms have been established to avoid leaking\nprivate information, such as field suppression or abstraction, strictly\nlimiting the amount of information that can be shared, or employing\nmathematical techniques such as differential privacy. Another approach, which\nwe focus on here, is creating synthetic data that mimics the underlying data.\nFor synthetic data to be a useful mechanism in support of medical innovation\nand a proxy for real-world evidence, one must demonstrate two properties of the\nsynthetic dataset: (1) any analysis on the real data must be matched by\nanalysis of the synthetic data (statistical fidelity) and (2) the synthetic\ndata must preserve privacy, with minimal risk of re-identification (privacy\nguarantee). In this paper we propose a framework for quantifying the\nstatistical fidelity and privacy preservation properties of synthetic datasets\nand demonstrate these metrics for synthetic data generated by Syntegra\ntechnology.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 23:01:27 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 04:41:17 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Mendelevitch", "Ofer", ""], ["Lesh", "Michael D.", ""]]}, {"id": "2101.08675", "submitter": "Izzat Alsmadi", "authors": "Izzat Alsmadi", "title": "Adversarial Machine Learning in Text Analysis and Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research field of adversarial machine learning witnessed a significant\ninterest in the last few years. A machine learner or model is secure if it can\ndeliver main objectives with acceptable accuracy, efficiency, etc. while at the\nsame time, it can resist different types and/or attempts of adversarial\nattacks. This paper focuses on studying aspects and research trends in\nadversarial machine learning specifically in text analysis and generation. The\npaper summarizes main research trends in the field such as GAN algorithms,\nmodels, types of attacks, and defense against those attacks.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2021 04:37:52 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Alsmadi", "Izzat", ""]]}, {"id": "2101.08677", "submitter": "Andrea Vandin", "authors": "Maurice H. ter Beek, Axel Legay, Alberto Lluch Lafuente, Andrea Vandin", "title": "Quantitative Security Risk Modeling and Analysis with RisQFLan", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain-specific quantitative modeling and analysis approaches are fundamental\nin scenarios in which qualitative approaches are inappropriate or unfeasible.\nIn this paper, we present a tool-supported approach to quantitative graph-based\nsecurity risk modeling and analysis based on attack-defense trees. Our approach\nis based on QFLan, a successful domain-specific approach to support\nquantitative modeling and analysis of highly configurable systems, whose\ndomain-specific components have been decoupled to facilitate the instantiation\nof the QFLan approach in the domain of graph-based security risk modeling and\nanalysis. Our approach incorporates distinctive features from three popular\nkinds of attack trees, namely enhanced attack trees, capabilities-based attack\ntrees and attack countermeasure trees, into the domain-specific modeling\nlanguage. The result is a new framework, called RisQFLan, to support\nquantitative security risk modeling and analysis based on attack-defense\ndiagrams. By offering either exact or statistical verification of probabilistic\nattack scenarios, RisQFLan constitutes a significant novel contribution to the\nexisting toolsets in that domain. We validate our approach by highlighting the\nadditional features offered by RisQFLan in three illustrative case studies from\nseminal approaches to graph-based security risk modeling analysis based on\nattack trees.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 15:44:37 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["ter Beek", "Maurice H.", ""], ["Legay", "Axel", ""], ["Lafuente", "Alberto Lluch", ""], ["Vandin", "Andrea", ""]]}, {"id": "2101.08717", "submitter": "Jacson Rodrigues Correia-Silva", "authors": "Jacson Rodrigues Correia-Silva, Rodrigo F. Berriel, Claudine Badue,\n  Alberto F. De Souza, Thiago Oliveira-Santos", "title": "Copycat CNN: Are Random Non-Labeled Data Enough to Steal Knowledge from\n  Black-box Models?", "comments": "The code is available at https://github.com/jeiks/Stealing_DL_Models", "journal-ref": "Pattern Recognition 113 (2021) 107830", "doi": "10.1016/j.patcog.2021.107830", "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Convolutional neural networks have been successful lately enabling companies\nto develop neural-based products, which demand an expensive process, involving\ndata acquisition and annotation; and model generation, usually requiring\nexperts. With all these costs, companies are concerned about the security of\ntheir models against copies and deliver them as black-boxes accessed by APIs.\nNonetheless, we argue that even black-box models still have some\nvulnerabilities. In a preliminary work, we presented a simple, yet powerful,\nmethod to copy black-box models by querying them with natural random images. In\nthis work, we consolidate and extend the copycat method: (i) some constraints\nare waived; (ii) an extensive evaluation with several problems is performed;\n(iii) models are copied between different architectures; and, (iv) a deeper\nanalysis is performed by looking at the copycat behavior. Results show that\nnatural random images are effective to generate copycats for several problems.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 16:55:14 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Correia-Silva", "Jacson Rodrigues", ""], ["Berriel", "Rodrigo F.", ""], ["Badue", "Claudine", ""], ["De Souza", "Alberto F.", ""], ["Oliveira-Santos", "Thiago", ""]]}, {"id": "2101.08754", "submitter": "Behnam Ghavami", "authors": "Farzane Khajuyi, Behnam Ghavami, Human Nikmehr", "title": "An Efficient Communication Protocol for FPGA IP Protection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We introduce a protection-based IP security scheme to protect soft and firm\nIP cores which are used on FPGA devices. The scheme is based on Finite State\nMachin (FSM) obfuscation and exploits Physical Unclonable Function (PUF) for\nFPGA unique identification (ID) generation which help pay-per-device licensing.\nWe introduce a communication protocol to protect the rights of parties in this\nmarket. On standard benchmark circuits, the experimental results show that our\nscheme is secure, attack-resilient and can be implemented with low area, power\nand delay overheads.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 18:09:51 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Khajuyi", "Farzane", ""], ["Ghavami", "Behnam", ""], ["Nikmehr", "Human", ""]]}, {"id": "2101.08778", "submitter": "Sam Werner", "authors": "Sam M. Werner, Daniel Perez, Lewis Gudgeon, Ariah Klages-Mundt,\n  Dominik Harz, William J. Knottenbelt", "title": "SoK: Decentralized Finance (DeFi)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized Finance (DeFi), a blockchain powered peer-to-peer financial\nsystem, is mushrooming. One year ago the total value locked in DeFi systems was\napproximately 700m USD, now, as of April 2021, it stands at around 51bn USD.\nThe frenetic evolution of the ecosystem makes it challenging for newcomers to\ngain an understanding of its basic features. In this Systematization of\nKnowledge (SoK), we delineate the DeFi ecosystem along its principal axes.\nFirst, we provide an overview of the DeFi primitives. Second, we classify DeFi\nprotocols according to the type of operation they provide. We then go on to\nconsider in detail the technical and economic security of DeFi protocols,\ndrawing particular attention to the issues that emerge specifically in the DeFi\nsetting. Finally, we outline the open research challenges in the ecosystem.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 18:58:43 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 17:16:55 GMT"}, {"version": "v3", "created": "Fri, 30 Apr 2021 10:11:59 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Werner", "Sam M.", ""], ["Perez", "Daniel", ""], ["Gudgeon", "Lewis", ""], ["Klages-Mundt", "Ariah", ""], ["Harz", "Dominik", ""], ["Knottenbelt", "William J.", ""]]}, {"id": "2101.08879", "submitter": "Anisa Halimi", "authors": "Anisa Halimi, Leonard Dervishi, Erman Ayday, Apostolos Pyrgelis, Juan\n  Ramon Troncoso-Pastoriza, Jean-Pierre Hubaux, Xiaoqian Jiang, Jaideep Vaidya", "title": "Privacy-Preserving and Efficient Verification of the Outcome in\n  Genome-Wide Association Studies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing provenance in scientific workflows is essential for reproducibility\nand auditability purposes. Workflow systems model and record provenance\ndescribing the steps performed to obtain the final results of a computation. In\nthis work, we propose a framework that verifies the correctness of the\nstatistical test results that are conducted by a researcher while protecting\nindividuals' privacy in the researcher's dataset. The researcher publishes the\nworkflow of the conducted study, its output, and associated metadata. They keep\nthe research dataset private while providing, as part of the metadata, a\npartial noisy dataset (that achieves local differential privacy). To check the\ncorrectness of the workflow output, a verifier makes use of the workflow, its\nmetadata, and results of another statistical study (using publicly available\ndatasets) to distinguish between correct statistics and incorrect ones. We use\ncase the proposed framework in the genome-wide association studies (GWAS), in\nwhich the goal is to identify highly associated point mutations (variants) with\na given phenotype. For evaluation, we use real genomic data and show that the\ncorrectness of the workflow output can be verified with high accuracy even when\nthe aggregate statistics of a small number of variants are provided. We also\nquantify the privacy leakage due to the provided workflow and its associated\nmetadata in the GWAS use-case and show that the additional privacy risk due to\nthe provided metadata does not increase the existing privacy risk due to\nsharing of the research results. Thus, our results show that the workflow\noutput (i.e., research results) can be verified with high confidence in a\nprivacy-preserving way. We believe that this work will be a valuable step\ntowards providing provenance in a privacy-preserving way while providing\nguarantees to the users about the correctness of the results.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 23:03:06 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 17:46:50 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Halimi", "Anisa", ""], ["Dervishi", "Leonard", ""], ["Ayday", "Erman", ""], ["Pyrgelis", "Apostolos", ""], ["Troncoso-Pastoriza", "Juan Ramon", ""], ["Hubaux", "Jean-Pierre", ""], ["Jiang", "Xiaoqian", ""], ["Vaidya", "Jaideep", ""]]}, {"id": "2101.08919", "submitter": "Peter Wu", "authors": "Peter Wu, Paul Pu Liang, Ruslan Salakhutdinov, Louis-Philippe Morency", "title": "Understanding the Tradeoffs in Client-Side Privacy for Speech\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CR cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing approaches to ensuring privacy of user speech data primarily focus\non server-side approaches. While improving server-side privacy reduces certain\nsecurity concerns, users still do not retain control over whether privacy is\nensured on the client-side. In this paper, we define, evaluate, and explore\ntechniques for client-side privacy in speech recognition, where the goal is to\npreserve privacy on raw speech data before leaving the client's device. We\nfirst formalize several tradeoffs in ensuring client-side privacy between\nperformance, compute requirements, and privacy. Using our tradeoff analysis, we\nperform a large-scale empirical study on existing approaches and find that they\nfall short on at least one metric. Our results call for more research in this\ncrucial area as a step towards safer real-world deployment of speech\nrecognition systems at scale across mobile devices.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 02:05:19 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Wu", "Peter", ""], ["Liang", "Paul Pu", ""], ["Salakhutdinov", "Ruslan", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "2101.08969", "submitter": "Yuzhou Lin", "authors": "Yuzhou Lin", "title": "A novel DL approach to PE malware detection: exploring Glove\n  vectorization, MCC_RCNN and feature fusion", "comments": "Some errors made in paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, malware becomes more threatening. Concerning the increasing\nmalware variants, there comes Machine Learning (ML)-based and Deep Learning\n(DL)-based approaches for heuristic detection. Nevertheless, the prediction\naccuracy of both needs to be improved. In response to the above issues in the\nPE malware domain, we propose the DL-based approaches for detection and use\nstatic-based features fed up into models. The contributions are as follows: we\nrecapitulate existing malware detection methods. That is, we propose a\nvec-torized representation model of the malware instruction layer and semantic\nlayer based on Glove. We implement a neural network model called MCC_RCNN\n(Malware Detection and Recurrent Convolutional Neural Network), comprising of\nthe combination with CNN and RNN. Moreover, we provide a description of feature\nfusion in static behavior levels. With the numerical results generated from\nseveral comparative experiments towards evaluating the Glove-based\nvectoriza-tion, MCC_RCNN-based classification methodology and feature fusion\nstages, our proposed classification methods can obtain a higher prediction\naccuracy than the other baseline methods.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 07:08:10 GMT"}, {"version": "v2", "created": "Sun, 31 Jan 2021 06:25:38 GMT"}, {"version": "v3", "created": "Thu, 4 Feb 2021 09:06:02 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Lin", "Yuzhou", ""]]}, {"id": "2101.08997", "submitter": "Nicolas Six", "authors": "Nicolas Six (CRI), Claudia Negri Ribalta (CRI), Nicolas Herbaut (CRI),\n  Camille Salinesi (CRI)", "title": "A blockchain-based pattern for confidential and pseudo-anonymous\n  contract enforcement", "comments": null, "journal-ref": "2020 IEEE 19th International Conference on Trust, Security and\n  Privacy in Computing and Communications (TrustCom), Dec 2020, Guangzhou,\n  China", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain has been praised for its capacity to hold data in a decentralized\nand tamper-proof way. It also supports the execution of code through\nblockchain's smart contracts, adding automation of actions to the network with\nhigh trustability. However, as smart contracts are visible by anybody on the\nnetwork, the business data and logic may be at risk, thus companies could be\nreluctant to use such technology. This paper aims to propose a pattern that\nallows the execution of automatable legal contract clauses, where its execution\nstates are stored in an on-chain smart-contract and the logic needed to enforce\nit wraps it off-chain. An engine completes this pattern by running a business\nprocess that corresponds to the legal contract. We then propose a pattern-based\nsolution based on a real-life use case: transportation of refrigerated goods.\nWe argue that this pattern guarantees companies pseudonymity and data\nconfidentiality while ensuring that an audit trail can be reconstituted through\nthe blockchain smart-contract to identify misbehavior or errors. This paper\npaves the way for a future possible implementation of the solution described,\nas well as its evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 08:32:21 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Six", "Nicolas", "", "CRI"], ["Ribalta", "Claudia Negri", "", "CRI"], ["Herbaut", "Nicolas", "", "CRI"], ["Salinesi", "Camille", "", "CRI"]]}, {"id": "2101.08998", "submitter": "Nicolas Six", "authors": "Nicolas Six (CRI)", "title": "Decision process for blockchain architectures based on requirements", "comments": null, "journal-ref": "CAiSE (Doctoral Consortium), 2020, Jun 2020, Grenoble, France.\n  pp.53", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, blockchain has grown in popularity due to its singular\nattributes, enabling the development of new innovative decentralized\napplications. But when companies consider leveraging blockchain for their\napplications, the plethora of possible choices and the difficulty of\nintegrating blockchain into architectures can hinder its adoption. Our research\nproject aims to ease the adoption of blockchain into companies, notably with\nthe construction of an automated decision process to solve this issue in which\nrequirements are first-class citizens, a knowledge base containing\narchitectural patterns and blockchains refined over time, and an architecture\ngenerator able to process outputs into architectural stubs. This paper will\nalso present our current progression on this decision process, by introducing\nthe preliminary version that is able to choose the most suitable blockchain\nbetween multiple choices and our process-driven benchmarking tool.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 08:34:06 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Six", "Nicolas", "", "CRI"]]}, {"id": "2101.09041", "submitter": "Seunghoan Song", "authors": "Seunghoan Song and Masahito Hayashi", "title": "Quantum Private Information Retrieval for Quantum Messages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum private information retrieval (QPIR) for quantum messages is the\nprotocol in which a user retrieves one of the multiple quantum states from one\nor multiple servers without revealing which state is retrieved. We consider\nQPIR in two different settings: the blind setting, in which the servers contain\none copy of the message states, and the visible setting, in which the servers\ncontain the description of the message states. One trivial solution in both\nsettings is downloading all states from the servers and the main goal of this\npaper is to find more efficient QPIR protocols. First, we prove that the\ntrivial solution is optimal for one-server QPIR in the blind setting. In\none-round protocols, the same optimality holds even in the visible setting. On\nthe other hand, when the user and the server share entanglement, we prove that\nthere exists an efficient one-server QPIR protocol in the blind setting.\nFurthermore, in the visible setting, we prove that it is possible to construct\nsymmetric QPIR protocols in which the user obtains no information of the\nnon-targeted messages. We construct three two-server symmetric QPIR protocols\nfor pure states. Note that symmetric classical PIR is impossible without shared\nrandomness unknown to the user.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 10:28:32 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Song", "Seunghoan", ""], ["Hayashi", "Masahito", ""]]}, {"id": "2101.09054", "submitter": "Yuval Dagan", "authors": "Noga Alon, Omri Ben-Eliezer, Yuval Dagan, Shay Moran, Moni Naor, Eylon\n  Yogev", "title": "Adversarial Laws of Large Numbers and Optimal Regret in Online\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Laws of large numbers guarantee that given a large enough sample from some\npopulation, the measure of any fixed sub-population is well-estimated by its\nfrequency in the sample. We study laws of large numbers in sampling processes\nthat can affect the environment they are acting upon and interact with it.\nSpecifically, we consider the sequential sampling model proposed by Ben-Eliezer\nand Yogev (2020), and characterize the classes which admit a uniform law of\nlarge numbers in this model: these are exactly the classes that are\n\\emph{online learnable}. Our characterization may be interpreted as an online\nanalogue to the equivalence between learnability and uniform convergence in\nstatistical (PAC) learning.\n  The sample-complexity bounds we obtain are tight for many parameter regimes,\nand as an application, we determine the optimal regret bounds in online\nlearning, stated in terms of \\emph{Littlestone's dimension}, thus resolving the\nmain open question from Ben-David, P\\'al, and Shalev-Shwartz (2009), which was\nalso posed by Rakhlin, Sridharan, and Tewari (2015).\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 11:15:19 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Alon", "Noga", ""], ["Ben-Eliezer", "Omri", ""], ["Dagan", "Yuval", ""], ["Moran", "Shay", ""], ["Naor", "Moni", ""], ["Yogev", "Eylon", ""]]}, {"id": "2101.09085", "submitter": "Jaap-Henk Hoepman", "authors": "Jaap-Henk Hoepman", "title": "Privacy Friendly E-Ticketing For Public Transport", "comments": "31 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper studies how to implement a privacy friendly form of ticketing for\npublic transport in practice. The protocols described are inspired by current\n(privacy invasive) public transport ticketing systems used around the world.\nThe first protocol emulates paper based tickets. The second protocol implements\na pay-as-you-go approach, with fares determined when users check-in and\ncheck-out. Both protocols assume the use of a smart phone as the main user\ndevice to store tickets or travel credit. We see this research as a step\ntowards investigating how to design commonly used infrastructure in a privacy\nfriendly manner in practice, paying particular attention to how to deal with\nfailures.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 12:38:34 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Hoepman", "Jaap-Henk", ""]]}, {"id": "2101.09139", "submitter": "Milan Lopuha\\\"a-Zwakenberg", "authors": "Milan Lopuha\\\"a-Zwakenberg and Jasper Goseling", "title": "The Privacy-Utility Tradeoff of Robust Local Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider data release protocols for data $X=(S,U)$, where $S$ is\nsensitive; the released data $Y$ contains as much information about $X$ as\npossible, measured as $\\operatorname{I}(X;Y)$, without leaking too much about\n$S$. We introduce the Robust Local Differential Privacy (RLDP) framework to\nmeasure privacy. This framework relies on the underlying distribution of the\ndata, which needs to be estimated from available data. Robust privacy\nguarantees are ensuring privacy for all distributions in a given set\n$\\mathcal{F}$, for which we study two cases: when $\\mathcal{F}$ is the set of\nall distributions, and when $\\mathcal{F}$ is a confidence set arising from a\n$\\chi^2$ test on a publicly available dataset. In the former case we introduce\na new release protocol which we prove to be optimal in the low privacy regime.\nIn the latter case we present four algorithms that construct RLDP protocols\nfrom a given dataset. One of these approximates $\\mathcal{F}$ by a polytope and\nuses results from robust optimisation to yield high utility release protocols.\nHowever, this algorithm relies on vertex enumeration and becomes\ncomputationally inaccessible for large input spaces. The other three algorithms\nare low-complexity and build on randomised response. Experiments verify that\nall four algorithms offer significantly improved utility over regular LDP.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 15:00:32 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Lopuha\u00e4-Zwakenberg", "Milan", ""], ["Goseling", "Jasper", ""]]}, {"id": "2101.09162", "submitter": "Elias Iosif", "authors": "Elias Iosif and Klitos Christodoulou and Andreas Vlachos", "title": "A Robust Blockchain Readiness Index Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the blockchain ecosystem gets more mature many businesses, investors, and\nentrepreneurs are seeking opportunities on working with blockchain systems and\ncryptocurrencies. A critical challenge for these actors is to identify the most\nsuitable environment to start or evolve their businesses. In general, the\nquestion is to identify which countries are offering the most suitable\nconditions to host their blockchain-based activities and implement their\ninnovative projects. The Blockchain Readiness Index (BRI) provides a numerical\nmetric (referred to as the blockchain readiness score) in measuring the\nmaturity/readiness levels of a country in adopting blockchain and\ncryptocurrencies. In doing so, BRI leverages on techniques from information\nretrieval to algorithmically derive an index ranking for a set of countries.\nThe index considers a range of indicators organized under five pillars:\nGovernment Regulation, Research, Technology, Industry, and User Engagement. In\nthis paper, we further extent BRI with the capability of deriving the index -\nat the country level - even in the presence of missing information for the\nindicators. In doing so, we are proposing two weighting schemes namely, linear\nand sigmoid weighting for refining the initial estimates for the indicator\nvalues. A classification framework was employed to evaluate the effectiveness\nof the developed techniques which yielded to a significant classification\naccuracy.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 16:14:33 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Iosif", "Elias", ""], ["Christodoulou", "Klitos", ""], ["Vlachos", "Andreas", ""]]}, {"id": "2101.09317", "submitter": "Chien-Chung Chan", "authors": "Arvind Srinivasan, Chien-Chung Chan", "title": "Short Secret Sharing Using Repeatable Random Sequence Generators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We present a new secret sharing algorithm that provides the storage\nefficiency of an Information Dispersal Algorithm (IDA) while providing perfect\nsecret sharing. We achieve this by mixing the input message with random bytes\ngenerated using Repeatable Random Sequence Generator (RRSG). We also use the\ndata from the RRSG to provide random polynomial evaluation points and\noptionally compute the polynomials on random isomorphic fields rather than a\nsingle fixed field.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 20:19:31 GMT"}, {"version": "v2", "created": "Sun, 21 Feb 2021 22:49:50 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Srinivasan", "Arvind", ""], ["Chan", "Chien-Chung", ""]]}, {"id": "2101.09324", "submitter": "Hadi Zanddizari", "authors": "Hadi Zanddizari and J. Morris Chang", "title": "Generating Black-Box Adversarial Examples in Sparse Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Applications of machine learning (ML) models and convolutional neural\nnetworks (CNNs) have been rapidly increased. Although ML models provide high\naccuracy in many applications, recent investigations show that such networks\nare highly vulnerable to adversarial attacks. The black-box adversarial attack\nis one type of attack that the attacker does not have any knowledge about the\nmodel or the training dataset. In this paper, we propose a novel approach to\ngenerate a black-box attack in sparse domain whereas the most important\ninformation of an image can be observed. Our investigation shows that large\nsparse components play a critical role in the performance of the image\nclassifiers. Under this presumption, to generate adversarial example, we\ntransfer an image into a sparse domain and put a threshold to choose only k\nlargest components. In contrast to the very recent works that randomly perturb\nk low frequency (LoF) components, we perturb k largest sparse (LaS)components\neither randomly (query-based) or in the direction of the most correlated sparse\nsignal from a different class. We show that LaS components contain some middle\nor higher frequency components information which can help us fool the\nclassifiers with a fewer number of queries. We also demonstrate the\neffectiveness of this approach by fooling the TensorFlow Lite (TFLite) model of\nGoogle Cloud Vision platform. Mean squared error (MSE) and peak signal to noise\nratio (PSNR) are used as quality metrics. We present a theoretical proof to\nconnect these metrics to the level of perturbation in the sparse domain. We\ntested our adversarial examples to the state-of-the-art CNNs and support vector\nmachine (SVM) classifiers on color and grayscale image datasets. The results\nshow the proposed method can highly increase the misclassification rate of the\nclassifiers.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 20:45:33 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Zanddizari", "Hadi", ""], ["Chang", "J. Morris", ""]]}, {"id": "2101.09365", "submitter": "Vasudevan Nagendra", "authors": "Vasudevan Nagendra, Abhishek Pokala, Arani Bhattacharya, Samir Das", "title": "MAVERICK: Proactively detecting network control plane bugs using\n  structural outlierness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proactive detection of network configuration bugs is important to ensure its\nproper functioning and reduce cost of network administrator. In this research,\nwe propose to build the control plane verification engine MAVERICK that detects\nthe bugs in the network control plane i.e., network device configurations and\ncontrol plane states. MAVERICK automatically infers signatures for the control\nplane configurations (e.g., ACLs, route-maps, route-policies and so on) and\nstates that allows administrators to automatically detect bugs with minimal\nhuman intervention. MAVERICK achieves this by effectively leveraging any\nstructural deviation i.e., outliers in the network configurations that is\norganized as simple or complexly nested key-value pairs. The outliers that are\ncalculated using signature-based outlier detection mechanism are further\ncharacterized for its severity and ranked or re-prioritized according to their\ncriticality. We consider a wide set of heuristics and domain expertise factors\nfor effectively to reduce both false positives and false negatives.Our\nevaluation on four medium to large-scale enterprise networks show that MAVERICK\ncan automatically detect the bugs present in the network with approximately 75%\naccuracy. Further-more, With minimal administrator input i.e., with a few\nminutes of signature re-tuning, MAVERICK allows the administrators to\neffectively detect approximately 94 - 100% of the bugs present in the network,\nthereby ranking down less severe bugs and removing false positives.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 22:23:31 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Nagendra", "Vasudevan", ""], ["Pokala", "Abhishek", ""], ["Bhattacharya", "Arani", ""], ["Das", "Samir", ""]]}, {"id": "2101.09378", "submitter": "Bianca Trov\\`o", "authors": "Bianca Trov\\`o and Nazzareno Massari", "title": "Ants-Review: a Protocol for Incentivized Open Peer-Reviews on Ethereum", "comments": "8 pages, 1 figure, to appear as \"B. Trov\\`o, N. Massari\n  (forthcoming). Ants-Review: a Protocol for Incentivized Open Peer-Reviews on\n  Ethereum. In: Bartosz Balis, Dora B. Heras et al. (eds) Euro-Par 2020:\n  Parallel Processing Workshops. Euro-Par 2020. Lecture Notes in Computer\n  Science, Springer, Cham.\"", "journal-ref": null, "doi": "10.1007/978-3-030-71593-9_2", "report-no": null, "categories": "cs.DL cs.CR cs.CY cs.DC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peer-review is a necessary and essential quality control step for scientific\npublications but lacks proper incentives. Indeed, the process, which is very\ncostly in terms of time and intellectual investment, not only is not\nremunerated by the journals but is also not openly recognized by the academic\ncommunity as a relevant scientific output for a researcher. Therefore,\nscientific dissemination is affected in timeliness, quality, and fairness.\nHere, to solve this issue, we propose a blockchain-based incentive system that\nrewards scientists for peer-reviewing other scientists' work and that builds up\ntrust and reputation. We designed a privacy-oriented protocol of smart\ncontracts called Ants-Review that allows authors to issue a bounty for open\nanonymous peer-reviews on Ethereum. If requirements are met, peer-reviews will\nbe accepted and paid by the approver proportionally to their assessed quality.\nTo promote ethical behavior and inclusiveness the system implements a gamified\nmechanism that allows the whole community to evaluate the peer-reviews and vote\nfor the best ones.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 23:32:41 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Trov\u00f2", "Bianca", ""], ["Massari", "Nazzareno", ""]]}, {"id": "2101.09381", "submitter": "Ruizhong Wei", "authors": "Sai Swaroop Madugula and Ruizhong Wei", "title": "An Enhanced Passkey Entry Protocol for Secure Simple Pairing in\n  Bluetooth", "comments": "13 pages, 5 figures, original paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a simple enhancement for the passkey entry protocol\nin the authentication stage 1 of Secure Simple Pairing using preexisting\ncryptographic hash functions and random integer generation present in the\nprotocol. The new protocol is more secure and efficient than previous known\nprotocols. Our research mainly focuses on strengthening the passkey entry\nprotocol and protecting the devices against passive eavesdropping and active\nMan-in-the-middle (MITM) attacks in both Bluetooth Basic Rate/Enhanced Data\nRate (BR/EDR) and Bluetooth Low Energy (Bluetooth LE). This method can be used\nfor any device which uses the passkey entry protocol.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 23:36:22 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Madugula", "Sai Swaroop", ""], ["Wei", "Ruizhong", ""]]}, {"id": "2101.09387", "submitter": "Changhao Shi", "authors": "Changhao Shi, Chester Holtz and Gal Mishne", "title": "Online Adversarial Purification based on Self-Supervision", "comments": "Accepted to ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks are known to be vulnerable to adversarial examples,\nwhere a perturbation in the input space leads to an amplified shift in the\nlatent network representation. In this paper, we combine canonical supervised\nlearning with self-supervised representation learning, and present\nSelf-supervised Online Adversarial Purification (SOAP), a novel defense\nstrategy that uses a self-supervised loss to purify adversarial examples at\ntest-time. Our approach leverages the label-independent nature of\nself-supervised signals and counters the adversarial perturbation with respect\nto the self-supervised tasks. SOAP yields competitive robust accuracy against\nstate-of-the-art adversarial training and purification methods, with\nconsiderably less training complexity. In addition, our approach is robust even\nwhen adversaries are given knowledge of the purification defense strategy. To\nthe best of our knowledge, our paper is the first that generalizes the idea of\nusing self-supervised signals to perform online test-time purification.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2021 00:19:52 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Shi", "Changhao", ""], ["Holtz", "Chester", ""], ["Mishne", "Gal", ""]]}, {"id": "2101.09416", "submitter": "Hadi Zanddizari", "authors": "Hadi Zanddizari, Sreeraman Rajan, Hassan Rabah, Houman Zarrabi", "title": "Privacy Assured Recovery of Compressively Sensed ECG signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Cloud computing for storing data and running complex algorithms have been\nsteadily increasing. As connected IoT devices such as wearable ECG recorders\ngenerally have less storage and computational capacity, acquired signals get\nsent to a remote center for storage and possible analysis on demand. Recently,\ncompressive sensing (CS) has been used as secure, energy-efficient method of\nsignal sampling in such recorders. In this paper, we propose a secure procedure\nto outsource the total recovery of CS measurement to the cloud and introduce a\nprivacy-assured signal recovery technique in the cloud. We present a fast, and\nlightweight encryption for secure CS recovery outsourcing that can be used in\nwearable devices, such as ECG Holter monitors. In the proposed technique,\ninstead of full recovery of CS-compressed ECG signal in the cloud, to preserve\nprivacy, an encrypted version of ECG signal is recovered by using a randomly\nbipolar permuted measurement matrix. The user with a key, decrypts the\nencrypted ECG from the cloud to obtain the original ECG signal. We demonstrate\nour proposed method using the ECG signals available in the MITBIH Arrhythmia\nDatabase. We also demonstrate the strength of the proposed method against\npartial exposure of the key.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2021 04:46:06 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Zanddizari", "Hadi", ""], ["Rajan", "Sreeraman", ""], ["Rabah", "Hassan", ""], ["Zarrabi", "Houman", ""]]}, {"id": "2101.09451", "submitter": "Shao-Yuan Lo", "authors": "Shao-Yuan Lo and Vishal M. Patel", "title": "Error Diffusion Halftoning Against Adversarial Examples", "comments": "Accepted at IEEE International Conference on Image Processing (ICIP)\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples contain carefully crafted perturbations that can fool\ndeep neural networks (DNNs) into making wrong predictions. Enhancing the\nadversarial robustness of DNNs has gained considerable interest in recent\nyears. Although image transformation-based defenses were widely considered at\nan earlier time, most of them have been defeated by adaptive attacks. In this\npaper, we propose a new image transformation defense based on error diffusion\nhalftoning, and combine it with adversarial training to defend against\nadversarial examples. Error diffusion halftoning projects an image into a 1-bit\nspace and diffuses quantization error to neighboring pixels. This process can\nremove adversarial perturbations from a given image while maintaining\nacceptable image quality in the meantime in favor of recognition. Experimental\nresults demonstrate that the proposed method is able to improve adversarial\nrobustness even under advanced adaptive attacks, while most of the other image\ntransformation-based defenses do not. We show that a proper image\ntransformation can still be an effective defense approach. Code:\nhttps://github.com/shaoyuanlo/Halftoning-Defense\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2021 07:55:02 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 23:03:02 GMT"}, {"version": "v3", "created": "Sat, 24 Jul 2021 06:59:58 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Lo", "Shao-Yuan", ""], ["Patel", "Vishal M.", ""]]}, {"id": "2101.09477", "submitter": "Dushyant Behl", "authors": "Dushyant Behl, Palanivel Kodeswaran, Venkatraman Ramakrishna,\n  Sayandeep Sen, Dhinakaran Vinayagamurthy", "title": "Trusted Data Notifications from Private Blockchains", "comments": "9 pages", "journal-ref": "IEEE International Conference on Blockchain, Blockchain 2020,\n  Rhodes Island, Greece, November 2-6, 2020, pages {53--61}", "doi": "10.1109/Blockchain50366.2020.00015", "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Private blockchain networks are used by enterprises to manage decentralized\nprocesses without trusted mediators and without exposing their assets publicly\non an open network like Ethereum. Yet external parties that cannot join such\nnetworks may have a compelling need to be informed about certain data items on\ntheir shared ledgers along with certifications of data authenticity; e.g., a\nmortgage bank may need to know about the sale of a mortgaged property from a\nnetwork managing property deeds. These parties are willing to compensate the\nnetworks in exchange for privately sharing information with proof of\nauthenticity and authorization for external use. We have devised a novel and\ncryptographically secure protocol to effect a fair exchange between rational\nnetwork members and information recipients using a public blockchain and atomic\nswap techniques. Using our protocol, any member of a private blockchain can\natomically reveal private blockchain data with proofs in exchange for a\nmonetary reward to an external party if and only if the external party is a\nvalid recipient. The protocol preserves confidentiality of data for the\nrecipient, and in addition, allows it to mount a challenge if the data turns\nout to be inauthentic. We also formally analyze the security and privacy of\nthis protocol, which can be used in a wide array of practical scenarios\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2021 10:45:52 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Behl", "Dushyant", ""], ["Kodeswaran", "Palanivel", ""], ["Ramakrishna", "Venkatraman", ""], ["Sen", "Sayandeep", ""], ["Vinayagamurthy", "Dhinakaran", ""]]}, {"id": "2101.09494", "submitter": "Omar Khadir", "authors": "Leila Zahhafi and Omar Khadir", "title": "A DSA-like digital signature protocol", "comments": null, "journal-ref": "JDMSC, 2020", "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we propose a new digital signature protocol inspired by the DSA\nalgorithm. The security and the complexity are analyzed. Our method constitutes\nan alternative if the classical scheme DSA is broken.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2021 12:48:34 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Zahhafi", "Leila", ""], ["Khadir", "Omar", ""]]}, {"id": "2101.09653", "submitter": "Zhe Peng", "authors": "Zhe Peng, Jinbin Huang, Haixin Wang, Shihao Wang, Xiaowen Chu, Xinzhi\n  Zhang, Li Chen, Xin Huang, Xiaoyi Fu, Yike Guo, Jianliang Xu", "title": "BU-Trace: A Permissionless Mobile System for Privacy-Preserving\n  Intelligent Contact Tracing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The coronavirus disease 2019 (COVID-19) pandemic has caused an unprecedented\nhealth crisis for the global. Digital contact tracing, as a transmission\nintervention measure, has shown its effectiveness on pandemic control. Despite\nintensive research on digital contact tracing, existing solutions can hardly\nmeet users' requirements on privacy and convenience. In this paper, we propose\nBU-Trace, a novel permissionless mobile system for privacy-preserving\nintelligent contact tracing based on QR code and NFC technologies. First, a\nuser study is conducted to investigate and quantify the user acceptance of a\nmobile contact tracing system. Second, a decentralized system is proposed to\nenable contact tracing while protecting user privacy. Third, an intelligent\nbehavior detection algorithm is designed to ease the use of our system. We\nimplement BU-Trace and conduct extensive experiments in several real-world\nscenarios. The experimental results show that BU-Trace achieves a\nprivacy-preserving and intelligent mobile system for contact tracing without\nrequesting location or other privacy-related permissions.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2021 06:11:09 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Peng", "Zhe", ""], ["Huang", "Jinbin", ""], ["Wang", "Haixin", ""], ["Wang", "Shihao", ""], ["Chu", "Xiaowen", ""], ["Zhang", "Xinzhi", ""], ["Chen", "Li", ""], ["Huang", "Xin", ""], ["Fu", "Xiaoyi", ""], ["Guo", "Yike", ""], ["Xu", "Jianliang", ""]]}, {"id": "2101.09712", "submitter": "Dongyang Xu", "authors": "Dongyang Xu and Pinyi Ren", "title": "Quantum Learning Based Nonrandom Superimposed Coding for Secure Wireless\n  Access in 5G URLLC", "comments": "Accepted by IEEE TIFS", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secure wireless access in ultra-reliable low-latency communications (URLLC),\nwhich is a critical aspect of 5G security, has become increasingly important\ndue to its potential support of grant-free configuration. In grant-free URLLC,\nprecise allocation of different pilot resources to different users that share\nthe same time-frequency resource is essential for the next generation NodeB\n(gNB) to exactly identify those users under access collision and to maintain\nprecise channel estimation required for reliable data transmission. However,\nthis process easily suffers from attacks on pilots. We in this paper propose a\nquantum learning based nonrandom superimposed coding method to encode and\ndecode pilots on multidimensional resources, such that the uncertainty of\nattacks can be learned quickly and eliminated precisely. Particularly,\nmultiuser pilots for uplink access are encoded as distinguishable subcarrier\nactivation patterns (SAPs) and gNB decodes pilots of interest from observed\nSAPs, a superposition of SAPs from access users, by joint design of attack mode\ndetection and user activity detection though a quantum learning network (QLN).\nWe found that the uncertainty lies in the identification process of codeword\ndigits from the attacker, which can be always modelled as a black-box model,\nresolved by a quantum learning algorithm and quantum circuit. Novel analytical\nclosed-form expressions of failure probability are derived to characterize the\nreliability of this URLLC system with short packet transmission. Simulations\nhow that our method can bring ultra-high reliability and low latency despite\nattacks on pilots.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2021 13:00:35 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Xu", "Dongyang", ""], ["Ren", "Pinyi", ""]]}, {"id": "2101.09725", "submitter": "Hareesh Mandalapu", "authors": "Hareesh Mandalapu, P N Aravinda Reddy, Raghavendra Ramachandra, K\n  Sreenivasa Rao, Pabitra Mitra, S R Mahadeva Prasanna, Christoph Busch", "title": "Audio-Visual Biometric Recognition and Presentation Attack Detection: A\n  Comprehensive Survey", "comments": null, "journal-ref": "in IEEE Access, vol. 9, pp. 37431-37455, 2021", "doi": "10.1109/ACCESS.2021.3063031", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Biometric recognition is a trending technology that uses unique\ncharacteristics data to identify or verify/authenticate security applications.\nAmidst the classically used biometrics, voice and face attributes are the most\npropitious for prevalent applications in day-to-day life because they are easy\nto obtain through restrained and user-friendly procedures. The pervasiveness of\nlow-cost audio and face capture sensors in smartphones, laptops, and tablets\nhas made the advantage of voice and face biometrics more exceptional when\ncompared to other biometrics. For many years, acoustic information alone has\nbeen a great success in automatic speaker verification applications. Meantime,\nthe last decade or two has also witnessed a remarkable ascent in face\nrecognition technologies. Nonetheless, in adverse unconstrained environments,\nneither of these techniques achieves optimal performance. Since audio-visual\ninformation carries correlated and complementary information, integrating them\ninto one recognition system can increase the system's performance. The\nvulnerability of biometrics towards presentation attacks and audio-visual data\nusage for the detection of such attacks is also a hot topic of research. This\npaper made a comprehensive survey on existing state-of-the-art audio-visual\nrecognition techniques, publicly available databases for benchmarking, and\nPresentation Attack Detection (PAD) algorithms. Further, a detailed discussion\non challenges and open problems is presented in this field of biometrics.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2021 14:38:47 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 09:52:28 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Mandalapu", "Hareesh", ""], ["Reddy", "P N Aravinda", ""], ["Ramachandra", "Raghavendra", ""], ["Rao", "K Sreenivasa", ""], ["Mitra", "Pabitra", ""], ["Prasanna", "S R Mahadeva", ""], ["Busch", "Christoph", ""]]}, {"id": "2101.09834", "submitter": "Jeffrey Murray Jr", "authors": "Jeffrey Murray Jr, Afra Mashhadi, Brent Lagesse, Michael Stiber", "title": "Privacy Preserving Techniques Applied to CPNI Data: Analysis and\n  Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With mobile phone penetration rates reaching 90%, Consumer Proprietary\nNetwork Information (CPNI) can offer extremely valuable information to\ndifferent sectors, including policymakers. Indeed, as part of CPNI, Call Detail\nRecords have been successfully used to provide real-time traffic information,\nto improve our understanding of the dynamics of people's mobility and so to\nallow prevention and measures in fighting infectious diseases, and to offer\npopulation statistics. While there is no doubt of the usefulness of CPNI data,\nprivacy concerns regarding sharing individuals' data have prevented it from\nbeing used to its full potential. Traditional de-anonymization measures, such\nas pseudonymization and standard de-identification, have been shown to be\ninsufficient to protect privacy. This has been specifically shown on mobile\nphone datasets. As an example, researchers have shown that with only four data\npoints of approximate place and time information of a user, 95% of users could\nbe re-identified in a dataset of 1.5 million mobile phone users. In this\nlandscape paper, we will discuss the state-of-the-art anonymization techniques\nand their shortcomings.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 00:33:04 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Murray", "Jeffrey", "Jr"], ["Mashhadi", "Afra", ""], ["Lagesse", "Brent", ""], ["Stiber", "Michael", ""]]}, {"id": "2101.09841", "submitter": "Leslie Tiong", "authors": "Leslie Ching Ow Tiong and HeeJeong Jasmine Lee", "title": "E-cheating Prevention Measures: Detection of Cheating at Online\n  Examinations Using Deep Learning Approach -- A Case Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study addresses the current issues in online assessments, which are\nparticularly relevant during the Covid-19 pandemic. Our focus is on academic\ndishonesty associated with online assessments. We investigated the prevalence\nof potential e-cheating using a case study and propose preventive measures that\ncould be implemented. We have utilised an e-cheating intelligence agent as a\nmechanism for detecting the practices of online cheating, which is composed of\ntwo major modules: the internet protocol (IP) detector and the behaviour\ndetector. The intelligence agent monitors the behaviour of the students and has\nthe ability to prevent and detect any malicious practices. It can be used to\nassign randomised multiple-choice questions in a course examination and be\nintegrated with online learning programs to monitor the behaviour of the\nstudents. The proposed method was tested on various data sets confirming its\neffectiveness. The results revealed accuracies of 68% for the deep neural\nnetwork (DNN); 92% for the long-short term memory (LSTM); 95% for the\nDenseLSTM; and, 86% for the recurrent neural network (RNN).\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 01:09:54 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Tiong", "Leslie Ching Ow", ""], ["Lee", "HeeJeong Jasmine", ""]]}, {"id": "2101.09930", "submitter": "Yixiang Wang", "authors": "Yixiang Wang, Jiqiang Liu, Xiaolin Chang", "title": "Generalizing Adversarial Examples by AdaBelief Optimizer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has proved that deep neural networks (DNNs) are vulnerable to\nadversarial examples, the legitimate input added with imperceptible and\nwell-designed perturbations can fool DNNs easily in the testing stage. However,\nmost of the existing adversarial attacks are difficult to fool adversarially\ntrained models. To solve this issue, we propose an AdaBelief iterative Fast\nGradient Sign Method (AB-FGSM) to generalize adversarial examples. By\nintegrating AdaBelief optimization algorithm to I-FGSM, we believe that the\ngeneralization of adversarial examples will be improved, relying on the strong\ngeneralization of AdaBelief optimizer. To validate the effectiveness and\ntransferability of adversarial examples generated by our proposed AB-FGSM, we\nconduct the white-box and black-box attacks on various single models and\nensemble models. Compared with state-of-the-art attack methods, our proposed\nmethod can generate adversarial examples effectively in the white-box setting,\nand the transfer rate is 7%-21% higher than latest attack methods.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 07:39:16 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Wang", "Yixiang", ""], ["Liu", "Jiqiang", ""], ["Chang", "Xiaolin", ""]]}, {"id": "2101.10008", "submitter": "Michele La Manna", "authors": "Michele La Manna, Pericle Perazzo, Gianluca Dini", "title": "SEA-BREW: A Scalable Attribute-Based Encryption Scheme for Low-Bitrate\n  IoT Wireless Networks", "comments": null, "journal-ref": null, "doi": "10.1016/j.jisa.2020.102692", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Attribute-Based Encryption (ABE) is an emerging cryptographic technique that\nallows one to embed a fine-grained access control mechanism into encrypted\ndata. In this paper we propose a novel ABE scheme called SEA-BREW (Scalable and\nEfficient Abe with Broadcast REvocation for Wireless networks), which is suited\nfor Internet of Things (IoT) and Industrial IoT (IIoT) applications. In\ncontrast to state-of-the-art ABE schemes, ours is capable of securely\nperforming key revocations with a single short broadcast message, instead of a\nnumber of unicast messages that is linear with the number of nodes. This is\ndesirable for low-bitrate Wireless Sensor and Actuator Networks (WSANs) which\noften are the heart of (I)IoT systems. In SEA-BREW, sensors, actuators, and\nusers can exchange encrypted data via a cloud server, or directly via wireless\nif they belong to the same WSAN. We formally prove that our scheme is secure\nalso in case of an untrusted cloud server that colludes with a set of users,\nunder the generic bilinear group model. We show by simulations that our scheme\nrequires a constant computational overhead on the cloud server with respect to\nthe complexity of the access control policies. This is in contrast to\nstate-of-the-art solutions, which require instead a linear computational\noverhead.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 11:00:08 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["La Manna", "Michele", ""], ["Perazzo", "Pericle", ""], ["Dini", "Gianluca", ""]]}, {"id": "2101.10011", "submitter": "Sebastian K\\\"ohler", "authors": "Sebastian K\\\"ohler, Giulio Lovisotto, Simon Birnbach, Richard Baker,\n  Ivan Martinovic", "title": "They See Me Rollin': Inherent Vulnerability of the Rolling Shutter in\n  CMOS Image Sensors", "comments": "13 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cameras have become a fundamental component of vision-based intelligent\nsystems. As a balance between production costs and image quality, most modern\ncameras use Complementary Metal-Oxide Semiconductor image sensors that\nimplement an electronic rolling shutter mechanism, where image rows are\ncaptured consecutively rather than all-at-once.\n  In this paper, we describe how the electronic rolling shutter can be\nexploited using a bright, modulated light source (e.g., an inexpensive,\noff-the-shelf laser), to inject fine-grained image disruptions. These\ndisruptions substantially affect camera-based computer vision systems, where\nhigh-frequency data is crucial in extracting informative features from objects.\n  We study the fundamental factors affecting a rolling shutter attack, such as\nenvironmental conditions, angle of the incident light, laser to camera\ndistance, and aiming precision. We demonstrate how these factors affect the\nintensity of the injected distortion and how an adversary can take them into\naccount by modeling the properties of the camera. We introduce a general\npipeline of a practical attack, which consists of: (i) profiling several\nproperties of the target camera and (ii) partially simulating the attack to\nfind distortions that satisfy the adversary's goal. Then, we instantiate the\nattack to the scenario of object detection, where the adversary's goal is to\nmaximally disrupt the detection of objects in the image. We show that the\nadversary can modulate the laser to hide up to 75% of objects perceived by\nstate-of-the-art detectors while controlling the amount of perturbation to keep\nthe attack inconspicuous. Our results indicate that rolling shutter attacks can\nsubstantially reduce the performance and reliability of vision-based\nintelligent systems.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 11:14:25 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["K\u00f6hler", "Sebastian", ""], ["Lovisotto", "Giulio", ""], ["Birnbach", "Simon", ""], ["Baker", "Richard", ""], ["Martinovic", "Ivan", ""]]}, {"id": "2101.10048", "submitter": "Stefan Marksteiner", "authors": "Stefan Marksteiner, Nadja Marko, Andre Smulders, Stelios Karagiannis,\n  Florian Stahl, Hayk Hamazaryan, Rupert Schlick, Stefan Kraxberger, Alexandr\n  Vasenev", "title": "A Process to Facilitate Automated Automotive Cybersecurity Testing", "comments": "7 pages, 2 figures paper presented at IEEE VTC2021-Spring. Full\n  published version at https://ieeexplore.ieee.org/document/9448913", "journal-ref": "IEEE 93rd Vehicular Technology Conference (VTC2021-Spring), 2021,\n  pp. 1-7", "doi": "10.1109/VTC2021-Spring51267.2021.9448913", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern vehicles become increasingly digitalized with advanced information\ntechnology-based solutions like advanced driving assistance systems and\nvehicle-to-x communications. These systems are complex and interconnected.\nRising complexity and increasing outside exposure has created a steadily rising\ndemand for more cyber-secure systems. Thus, also standardization bodies and\nregulators issued standards and regulations to prescribe more secure\ndevelopment processes. This security, however, also has to be validated and\nverified. In order to keep pace with the need for more thorough, quicker and\ncomparable testing, today's generally manual testing processes have to be\nstructured and optimized. Based on existing and emerging standards for\ncybersecurity engineering, this paper therefore outlines a structured testing\nprocess for verifying and validating automotive cybersecurity, for which there\nis no standardized method so far. Despite presenting a commonly structured\nframework, the process is flexible in order to allow implementers to utilize\ntheir own, accustomed toolsets.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 12:58:28 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 09:05:04 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Marksteiner", "Stefan", ""], ["Marko", "Nadja", ""], ["Smulders", "Andre", ""], ["Karagiannis", "Stelios", ""], ["Stahl", "Florian", ""], ["Hamazaryan", "Hayk", ""], ["Schlick", "Rupert", ""], ["Kraxberger", "Stefan", ""], ["Vasenev", "Alexandr", ""]]}, {"id": "2101.10063", "submitter": "Mantun Chen", "authors": "Mantun Chen, Yongjun Wang, Zhiquan Qin, Xiatian Zhu", "title": "Few-Shot Website Fingerprinting Attack", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This work introduces a novel data augmentation method for few-shot website\nfingerprinting (WF) attack where only a handful of training samples per website\nare available for deep learning model optimization. Moving beyond earlier WF\nmethods relying on manually-engineered feature representations, more advanced\ndeep learning alternatives demonstrate that learning feature representations\nautomatically from training data is superior. Nonetheless, this advantage is\nsubject to an unrealistic assumption that there exist many training samples per\nwebsite, which otherwise will disappear. To address this, we introduce a\nmodel-agnostic, efficient, and Harmonious Data Augmentation (HDA) method that\ncan improve deep WF attacking methods significantly. HDA involves both\nintra-sample and inter-sample data transformations that can be used in\nharmonious manner to expand a tiny training dataset to an arbitrarily large\ncollection, therefore effectively and explicitly addressing the intrinsic data\nscarcity problem. We conducted expensive experiments to validate our HDA for\nboosting state-of-the-art deep learning WF attack models in both closed-world\nand open-world attacking scenarios, at absence and presence of strong defense.\n{For instance, in the more challenging and realistic evaluation scenario with\nWTF-PAD based defense, our HDA method surpasses the previous state-of-the-art\nresults by more than 4% in absolute classification accuracy in the 20-shot\nlearning case.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 13:24:32 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 08:37:07 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Chen", "Mantun", ""], ["Wang", "Yongjun", ""], ["Qin", "Zhiquan", ""], ["Zhu", "Xiatian", ""]]}, {"id": "2101.10121", "submitter": "Mu Zhu", "authors": "Mu Zhu, Ahmed H. Anwar, Zelin Wan, Jin-Hee Cho, Charles Kamhoua, and\n  Munindar P. Singh", "title": "Game-Theoretic and Machine Learning-based Approaches for Defensive\n  Deception: A Survey", "comments": "37 pages, 184 citations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Defensive deception is a promising approach for cyber defense. Via defensive\ndeception, the defender can anticipate attacker actions; it can mislead or lure\nattacker, or hide real resources. Although defensive deception is increasingly\npopular in the research community, there has not been a systematic\ninvestigation of its key components, the underlying principles, and its\ntradeoffs in various problem settings. This survey paper focuses on defensive\ndeception research centered on game theory and machine learning, since these\nare prominent families of artificial intelligence approaches that are widely\nemployed in defensive deception. This paper brings forth insights, lessons, and\nlimitations from prior work. It closes with an outline of some research\ndirections to tackle major gaps in current defensive deception research.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 21:55:43 GMT"}, {"version": "v2", "created": "Sat, 8 May 2021 18:57:26 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Zhu", "Mu", ""], ["Anwar", "Ahmed H.", ""], ["Wan", "Zelin", ""], ["Cho", "Jin-Hee", ""], ["Kamhoua", "Charles", ""], ["Singh", "Munindar P.", ""]]}, {"id": "2101.10181", "submitter": "Yongxin Liu", "authors": "Yongxin Liu, Jian Wang, Jianqiang Li, Shuteng Niu, Houbing Song", "title": "Machine Learning for the Detection and Identification of Internet of\n  Things (IoT) Devices: A Survey", "comments": "This paper is currently under revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Internet of Things (IoT) is becoming an indispensable part of everyday\nlife, enabling a variety of emerging services and applications. However, the\npresence of rogue IoT devices has exposed the IoT to untold risks with severe\nconsequences. The first step in securing the IoT is detecting rogue IoT devices\nand identifying legitimate ones. Conventional approaches use cryptographic\nmechanisms to authenticate and verify legitimate devices' identities. However,\ncryptographic protocols are not available in many systems. Meanwhile, these\nmethods are less effective when legitimate devices can be exploited or\nencryption keys are disclosed. Therefore, non-cryptographic IoT device\nidentification and rogue device detection become efficient solutions to secure\nexisting systems and will provide additional protection to systems with\ncryptographic protocols. Non-cryptographic approaches require more effort and\nare not yet adequately investigated. In this paper, we provide a comprehensive\nsurvey on machine learning technologies for the identification of IoT devices\nalong with the detection of compromised or falsified ones from the viewpoint of\npassive surveillance agents or network operators. We classify the IoT device\nidentification and detection into four categories: device-specific pattern\nrecognition, Deep Learning enabled device identification, unsupervised device\nidentification, and abnormal device detection. Meanwhile, we discuss various\nML-related enabling technologies for this purpose. These enabling technologies\ninclude learning algorithms, feature engineering on network traffic traces and\nwireless signals, continual learning, and abnormality detection.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 15:51:04 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Liu", "Yongxin", ""], ["Wang", "Jian", ""], ["Li", "Jianqiang", ""], ["Niu", "Shuteng", ""], ["Song", "Houbing", ""]]}, {"id": "2101.10198", "submitter": "Ioannis Zografopoulos", "authors": "Ioannis Zografopoulos, Juan Ospina, XiaoRui Liu, Charalambos\n  Konstantinou", "title": "Cyber-Physical Energy Systems Security: Threat Modeling, Risk\n  Assessment, Resources, Metrics, and Case Studies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-physical systems (CPS) are interconnected architectures that employ\nanalog, digital, and communication resources for their interaction with the\nphysical environment. CPS are the backbone of enterprise, industrial, and\ncritical infrastructure. Thus, their vital importance makes them prominent\ntargets for malicious attacks aiming to disrupt their operations. Attacks\ntargeting cyber-physical energy systems (CPES), given their mission-critical\nnature, can have disastrous consequences. The security of CPES can be enhanced\nleveraging testbed capabilities to replicate power system operations, discover\nvulnerabilities, develop security countermeasures, and evaluate grid operation\nunder fault-induced or maliciously constructed scenarios. In this paper, we\nprovide a comprehensive overview of the CPS security landscape with emphasis on\nCPES. Specifically, we demonstrate a threat modeling methodology to accurately\nrepresent the CPS elements, their interdependencies, as well as the possible\nattack entry points and system vulnerabilities. Leveraging the threat model\nformulation, we present a CPS framework designed to delineate the hardware,\nsoftware, and modeling resources required to simulate the CPS and construct\nhigh-fidelity models which can be used to evaluate the system's performance\nunder adverse scenarios. The system performance is assessed using\nscenario-specific metrics, while risk assessment enables system vulnerability\nprioritization factoring the impact on the system operation. The overarching\nframework for modeling, simulating, assessing, and mitigating attacks in a CPS\nis illustrated using four representative attack scenarios targeting CPES. The\nkey objective of this paper is to demonstrate a step-by-step process that can\nbe used to enact in-depth cybersecurity analyses, thus leading to more\nresilient and secure CPS.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 16:07:10 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 13:37:27 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Zografopoulos", "Ioannis", ""], ["Ospina", "Juan", ""], ["Liu", "XiaoRui", ""], ["Konstantinou", "Charalambos", ""]]}, {"id": "2101.10293", "submitter": "Nikolaos Athanasios Anagnostopoulos", "authors": "Nikolaos Athanasios Anagnostopoulos", "title": "The Role of Cost in the Integration of Security Features in Integrated\n  Circuits for Smart Cards", "comments": "Submission to Research Topics in University of Twente under the\n  auspices of the EIT ICT Labs Master School in the academic year 2013-14", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM cs.CR econ.GN q-fin.EC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This essay investigates the role of cost in the development and production of\nsecure integrated circuits. Initially, I make a small introduction on hardware\nattacks on smart cards and some of the reasons behind them. Subsequently, I\nintroduce the production phases of chips that are integrated to smart cards and\ntry to identify the costs affecting each one of them. I proceed to identify how\nadding security features on such integrated circuits may affect the costs of\ntheir development and production. I then make a more thorough investigation on\nthe costs of developing a hardware attack for such chips and try to estimate\nthe potential damages and losses of such an attack. I also go on to examine\npotential ways of reducing the cost of production for secure chips, while\nidentifying the difficulties in adopting them.\n  This essay ends with the conclusion that adding security features to chips\nmeant to be used for secure applications is well worth it, because the costs of\ndeveloping attacks are of comparable amounts to the costs of developing and\nproducing a chip and the potential damages and losses caused by such attacks\ncan be way higher than these costs. Therefore, although the production and\ndevelopment of integrated circuits come at a certain cost and security\nintroduces further additional costs, security is inherently unavoidable in such\nchips. Finally, I additionally identify that security is an evolving concept\nand does not aim to make a chip totally impenetrable, as this may be\nimpossible, but to lower the potential risks, including that of being\ncompromised, to acceptable levels. Thus, a balance needs be found between the\nlevel of security and the levels of cost and risk.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 18:22:12 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Anagnostopoulos", "Nikolaos Athanasios", ""]]}, {"id": "2101.10374", "submitter": "Wenjie Bai", "authors": "Wenjie Bai, Jeremiah Blocki", "title": "DAHash: Distribution Aware Tuning of Password Hashing Costs", "comments": "25 pages, 15 figures, Financial Crypto 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.GT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An attacker who breaks into an authentication server and steals all of the\ncryptographic password hashes is able to mount an offline-brute force attack\nagainst each user's password. Offline brute-force attacks against passwords are\nincreasingly commonplace and the danger is amplified by the well documented\nhuman tendency to select low-entropy password and/or reuse these passwords\nacross multiple accounts. Moderately hard password hashing functions are often\ndeployed to help protect passwords against offline attacks by increasing the\nattacker's guessing cost. However, there is a limit to how \"hard\" one can make\nthe password hash function as authentication servers are resource constrained\nand must avoid introducing substantial authentication delay. Observing that\nthere is a wide gap in the strength of passwords selected by different users we\nintroduce DAHash (Distribution Aware Password Hashing) a novel mechanism which\nreduces the number of passwords that an attacker will crack. Our key insight\nishat a resource-constrained authentication server can dynamically tune the\nhardness parameters of a password hash function based on the (estimated)\nstrength of the user's password. We introduce a Stackelberg game to model the\ninteraction between a defender (authentication server) and an offline attacker.\nOur model allows the defender to optimize the parameters of DAHash e.g.,\nspecify how much effort is spent to hash weak/moderate/high strength passwords.\nWe use several large scale password frequency datasets to empirically evaluate\nthe effectiveness of our differentiated cost password hashing mechanism. We\nfind that the defender who uses our mechanism can reduce the fraction of\npasswords that would be cracked by a rational offline attacker by around 15%.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 19:45:39 GMT"}, {"version": "v2", "created": "Sat, 30 Jan 2021 05:15:07 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Bai", "Wenjie", ""], ["Blocki", "Jeremiah", ""]]}, {"id": "2101.10386", "submitter": "Fatemeh Tehranipoor", "authors": "Michael Yue and Fatemeh Tehranipoor", "title": "ProbLock: Probability-based Logic Locking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Integrated circuit (IC) piracy and overproduction are serious issues that\nthreaten the security and integrity of a system. Logic locking is a type of\nhardware obfuscation technique where additional key gates are inserted into the\ncircuit. Only the correct key can unlock the functionality of that circuit\notherwise the system produces the wrong output. In an effort to hinder these\nthreats on ICs, we have developed a probability-based logic locking technique\nto protect the design of a circuit. Our proposed technique called \"ProbLock\"\ncan be applied to combinational and sequential circuits through a critical\nselection process. We used a filtering process to select the best location of\nkey gates based on various constraints. Each step in the filtering process\ngenerates a subset of nodes for each constraint. We also analyzed the\ncorrelation between each constraint and adjusted the strength of the\nconstraints before inserting key gates. We have tested our algorithm on 40\nbenchmarks from the ISCAS '85 and ISCAS '89 suite.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 20:15:06 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Yue", "Michael", ""], ["Tehranipoor", "Fatemeh", ""]]}, {"id": "2101.10412", "submitter": "Bakheet Aljedaani", "authors": "Bakheet Aljedaani, Aakash Ahmad, Mansooreh Zahedi, M. Ali Babar", "title": "End-Users' Knowledge and Perception about Security of Mobile Health\n  Apps: An Empirical Study", "comments": "This research is 22 pages. It has 10 figures, and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Mobile health applications (mHealth apps for short) are being increasingly\nadopted in the healthcare sector, enabling stakeholders such as governments,\nhealth units, medics, and patients, to utilize health services in a pervasive\nmanner. Despite having several known benefits, mHealth apps entail significant\nsecurity and privacy challenges that can lead to data breaches with serious\nsocial, legal, and financial consequences. This research presents an empirical\ninvestigation about security awareness of end-users of mHealth apps that are\navailable on major mobile platforms, including Android and iOS. We collaborated\nwith two mHealth providers in Saudi Arabia to survey 101 end-users,\ninvestigating their security awareness about (i) existing and desired security\nfeatures, (ii) security related issues, and (iii) methods to improve security\nknowledge. Findings indicate that majority of the end-users are aware of the\nexisting security features provided by the apps (e.g., restricted app\npermissions); however, they desire usable security (e.g., biometric\nauthentication) and are concerned about privacy of their health information\n(e.g., data anonymization). End-users suggested that protocols such as session\ntimeout or Two-factor authentication (2FA) positively impact security but\ncompromise usability of the app. Security-awareness via social media, peer\nguidance, or training from app providers can increase end-users trust in\nmHealth apps. This research investigates human-centric knowledge based on\nempirical evidence and provides a set of guidelines to develop secure and\nusable mHealth apps.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 20:54:44 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 00:23:32 GMT"}, {"version": "v3", "created": "Thu, 4 Mar 2021 15:31:37 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Aljedaani", "Bakheet", ""], ["Ahmad", "Aakash", ""], ["Zahedi", "Mansooreh", ""], ["Babar", "M. Ali", ""]]}, {"id": "2101.10464", "submitter": "Mirko Zichichi", "authors": "Mirko Zichichi, Stefano Ferretti, Gabriele D'Angelo, V\\'ictor\n  Rodr\\'iguez-Doncel", "title": "Personal Data Access Control Through Distributed Authorization", "comments": null, "journal-ref": "2020 IEEE 19th International Symposium on Network Computing and\n  Applications (NCA)", "doi": "10.1109/NCA51143.2020.9306721", "report-no": null, "categories": "cs.CR cs.DC cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an architecture of a Personal Information Management\nSystem, in which individuals can define the access to their personal data by\nmeans of smart contracts. These smart contracts, running on the Ethereum\nblockchain, implement access control lists and grant immutability, traceability\nand verifiability of the references to personal data, which is stored itself in\na (possibly distributed) file system. A distributed authorization mechanism is\ndevised, where trust from multiple network nodes is necessary to grant the\naccess to the data. To this aim, two possible alternatives are described: a\nSecret Sharing scheme and Threshold Proxy Re-Encryption scheme. The performance\nof these alternatives is experimentally compared in terms of execution time.\nThreshold Proxy Re-Encryption appears to be faster in different scenarios, in\nparticular when increasing message size, number of nodes and the threshold\nvalue, i.e. number of nodes needed to grant the data disclosure.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 22:34:41 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Zichichi", "Mirko", ""], ["Ferretti", "Stefano", ""], ["D'Angelo", "Gabriele", ""], ["Rodr\u00edguez-Doncel", "V\u00edctor", ""]]}, {"id": "2101.10474", "submitter": "Frederico Araujo", "authors": "Teryl Taylor and Frederico Araujo and Xiaokui Shu", "title": "Towards an Open Format for Scalable System Telemetry", "comments": "To be published in 2020 IEEE International Conference on Big Data\n  (Big Data)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A data representation for system behavior telemetry for scalable big data\nsecurity analytics is presented, affording telemetry consumers comprehensive\nvisibility into workloads at reduced storage and processing overheads. The new\nabstraction, SysFlow, is a compact open data format that lifts the\nrepresentation of system activities into a flow-centric, object-relational\nmapping that records how applications interact with their environment, relating\nprocesses to file accesses, network activities, and runtime information. The\ntelemetry format supports single-event and volumetric flow representations of\nprocess control flows, file interactions, and network communications.\nEvaluation on enterprise-grade benchmarks shows that SysFlow facilitates deeper\nintrospection into attack kill chains while yielding traces orders of magnitude\nsmaller than current state-of-the-art system telemetry approaches --\ndrastically reducing storage requirements and enabling feature-filled system\nanalytics, process-level provenance tracking, and long-term data archival for\ncyber threat discovery and forensic analysis on historical data.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 23:39:35 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Taylor", "Teryl", ""], ["Araujo", "Frederico", ""], ["Shu", "Xiaokui", ""]]}, {"id": "2101.10522", "submitter": "Haotian Chi", "authors": "Haotian Chi, Qiang Zeng, Xiaojiang Du, Lannan Luo", "title": "PFirewall: Semantics-Aware Customizable Data Flow Control for Smart Home\n  Privacy Protection", "comments": "A new version of a previous submission with arXiv identifier\n  arXiv:1910.07987. This version cannot be merged to the previous submission\n  due to a title change", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) platforms enable users to deploy home automation\napplications. Meanwhile, privacy issues arise as large amounts of sensitive\ndevice data flow out to IoT platforms. Most of the data flowing out to a\nplatform actually do not trigger automation actions, while homeowners currently\nhave no control once devices are bound to the platform. We present PFirewall, a\ncustomizable data-flow control system to enhance the privacy of IoT platform\nusers. PFirewall automatically generates data-minimization policies, which only\ndisclose minimum amount of data to fulfill automation. In addition, PFirewall\nprovides interfaces for homeowners to customize individual privacy preferences\nby defining user-specified policies. To enforce these policies, PFirewall\ntransparently intervenes and mediates the communication between IoT devices and\nthe platform, without modifying the platform, IoT devices, or hub. Evaluation\nresults on four real-world testbeds show that PFirewall reduces IoT data sent\nto the platform by 97% without impairing home automation, and effectively\nmitigates user-activity inference/tracking attacks and other privacy risks.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 02:36:57 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 05:24:03 GMT"}, {"version": "v3", "created": "Wed, 7 Apr 2021 02:37:07 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Chi", "Haotian", ""], ["Zeng", "Qiang", ""], ["Du", "Xiaojiang", ""], ["Luo", "Lannan", ""]]}, {"id": "2101.10540", "submitter": "Nikolaos Athanasios Anagnostopoulos", "authors": "Nikolaos Athanasios Anagnostopoulos", "title": "Ear Recognition", "comments": "Submission to Biometrics in University of Twente under the auspices\n  of the EIT ICT Labs Master School in the academic year 2013-14", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ear recognition can be described as a revived scientific field. Ear\nbiometrics were long believed to not be accurate enough and held a secondary\nplace in scientific research, being seen as only complementary to other types\nof biometrics, due to difficulties in measuring correctly the ear\ncharacteristics and the potential occlusion of the ear by hair, clothes and ear\njewellery. However, recent research has reinstated them as a vivid research\nfield, after having addressed these problems and proven that ear biometrics can\nprovide really accurate identification and verification results. Several 2D and\n3D imaging techniques, as well as acoustical techniques using sound emission\nand reflection, have been developed and studied for ear recognition, while\nthere have also been significant advances towards a fully automated recognition\nof the ear. Furthermore, ear biometrics have been proven to be mostly\nnon-invasive, adequately permanent and accurate, and hard to spoof and\ncounterfeit. Moreover, different ear recognition techniques have proven to be\nas effective as face recognition ones, thus providing the opportunity for ear\nrecognition to be used in identification and verification applications.\nFinally, even though some issues still remain open and require further\nresearch, the scientific field of ear biometrics has proven to be not only\nviable, but really thriving.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 03:26:00 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Anagnostopoulos", "Nikolaos Athanasios", ""]]}, {"id": "2101.10569", "submitter": "Bin Jiang", "authors": "Bin Jiang, Jianqiang Li, Guanghui Yue, Houbing Song", "title": "Differential Privacy for Industrial Internet of Things: Opportunities,\n  Applications and Challenges", "comments": "22 pages, 8 figures, accepted by IEEE Internet of Things Journal", "journal-ref": null, "doi": "10.1109/JIOT.2021.3057419", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of Internet of Things (IoT) brings new changes to various\nfields. Particularly, industrial Internet of Things (IIoT) is promoting a new\nround of industrial revolution. With more applications of IIoT, privacy\nprotection issues are emerging. Specially, some common algorithms in IIoT\ntechnology such as deep models strongly rely on data collection, which leads to\nthe risk of privacy disclosure. Recently, differential privacy has been used to\nprotect user-terminal privacy in IIoT, so it is necessary to make in-depth\nresearch on this topic. In this paper, we conduct a comprehensive survey on the\nopportunities, applications and challenges of differential privacy in IIoT. We\nfirstly review related papers on IIoT and privacy protection, respectively.\nThen we focus on the metrics of industrial data privacy, and analyze the\ncontradiction between data utilization for deep models and individual privacy\nprotection. Several valuable problems are summarized and new research ideas are\nput forward. In conclusion, this survey is dedicated to complete comprehensive\nsummary and lay foundation for the follow-up researches on industrial\ndifferential privacy.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 05:34:24 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 04:08:50 GMT"}, {"version": "v3", "created": "Thu, 27 May 2021 14:18:25 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Jiang", "Bin", ""], ["Li", "Jianqiang", ""], ["Yue", "Guanghui", ""], ["Song", "Houbing", ""]]}, {"id": "2101.10570", "submitter": "Charalambos Konstantinou", "authors": "Charalambos Konstantinou", "title": "Towards a Secure and Resilient All-Renewable Energy Grid for Smart\n  Cities", "comments": "Accepted to IEEE Consumer Electronics Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CR cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of smart cities is driven by the need to enhance citizens'\nquality of life. It is estimated that 70% of the world population will live in\nurban areas by 2050. The electric grid is the energy backbone of smart city\ndeployments. An electric energy system immune to adverse events, both cyber and\nphysical risks, and able to support the integration of renewable sources will\ndrive a transformational development approach for future smart cities. This\narticle describes how the future electric energy system with 100% electricity\nsupply from renewable energy sources requires the \"birth of security and\nresiliency\" incorporated with its ecosystem.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 05:34:47 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Konstantinou", "Charalambos", ""]]}, {"id": "2101.10572", "submitter": "Shuaicheng Ma", "authors": "Shuaicheng Ma, Yang Cao, Li Xiong", "title": "Transparent Contribution Evaluation for Secure Federated Learning on\n  Blockchain", "comments": null, "journal-ref": "2021 IEEE 37th International Conference on Data Engineering\n  Workshops (ICDEW)", "doi": "10.1109/ICDEW53142.2021.00023", "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning is a promising machine learning paradigm when multiple\nparties collaborate to build a high-quality machine learning model.\nNonetheless, these parties are only willing to participate when given enough\nincentives, such as a fair reward based on their contributions. Many studies\nexplored Shapley value based methods to evaluate each party's contribution to\nthe learned model. However, they commonly assume a semi-trusted server to train\nthe model and evaluate the data owners' model contributions, which lacks\ntransparency and may hinder the success of federated learning in practice. In\nthis work, we propose a blockchain-based federated learning framework and a\nprotocol to transparently evaluate each participant's contribution. Our\nframework protects all parties' privacy in the model building phase and\ntransparently evaluates contributions based on the model updates. The\nexperiment with the handwritten digits dataset demonstrates that the proposed\nmethod can effectively evaluate the contributions.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 05:49:59 GMT"}, {"version": "v2", "created": "Sat, 24 Apr 2021 04:23:37 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Ma", "Shuaicheng", ""], ["Cao", "Yang", ""], ["Xiong", "Li", ""]]}, {"id": "2101.10578", "submitter": "Tajuddin Manhar Mohammed", "authors": "Tajuddin Manhar Mohammed, Lakshmanan Nataraj, Satish Chikkagoudar,\n  Shivkumar Chandrasekaran, B.S. Manjunath", "title": "Malware Detection Using Frequency Domain-Based Image Visualization and\n  Deep Learning", "comments": "Submitted version - Proceedings of the 54th Hawaii International\n  Conference on System Sciences (HICSS) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a novel method to detect and visualize malware through image\nclassification. The executable binaries are represented as grayscale images\nobtained from the count of N-grams (N=2) of bytes in the Discrete Cosine\nTransform (DCT) domain and a neural network is trained for malware detection. A\nshallow neural network is trained for classification, and its accuracy is\ncompared with deep-network architectures such as ResNet that are trained using\ntransfer learning. Neither dis-assembly nor behavioral analysis of malware is\nrequired for these methods. Motivated by the visual similarity of these images\nfor different malware families, we compare our deep neural network models with\nstandard image features like GIST descriptors to evaluate the performance. A\njoint feature measure is proposed to combine different features using error\nanalysis to get an accurate ensemble model for improved classification\nperformance. A new dataset called MaleX which contains around 1 million malware\nand benign Windows executable samples is created for large-scale malware\ndetection and classification experiments. Experimental results are quite\npromising with 96% binary classification accuracy on MaleX. The proposed model\nis also able to generalize well on larger unseen malware samples and the\nresults compare favorably with state-of-the-art static analysis-based malware\ndetection algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 06:07:46 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Mohammed", "Tajuddin Manhar", ""], ["Nataraj", "Lakshmanan", ""], ["Chikkagoudar", "Satish", ""], ["Chandrasekaran", "Shivkumar", ""], ["Manjunath", "B. S.", ""]]}, {"id": "2101.10621", "submitter": "Tsz Wai Wu", "authors": "Ningchen Ying, Tsz Wai Wu", "title": "xLumi: Payment Channel Protocol and Off-chain Payment in Blockchain\n  Contract Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce Super Luminal (\"xLumi\"), a new payment channel\nprotocol for blockchain systems. xLumi is a simple unidirectional payment\nchannel that can be extended to a bidirectional payment channel or a complete\nnetwork. xLumi guarantees the security of the payment channel's funds by using\na simple set of mathematical rules that can be easily implemented on any\nblockchain with the necessary infrastructure. We also give the detailed\nimplementation methods of this idea using V Systems contract systems in this\npaper.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 08:22:20 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Ying", "Ningchen", ""], ["Wu", "Tsz Wai", ""]]}, {"id": "2101.10631", "submitter": "Andreas Peter", "authors": "Amina Bassit (1), Florian Hahn (1), Joep Peeters (1), Tom Kevenaar\n  (2), Raymond N.J. Veldhuis (1), Andreas Peter (1) ((1) University of Twente,\n  (2) GenKey Netherlands B.V.)", "title": "Biometric Verification Secure Against Malicious Adversaries", "comments": "This is a complete reworking and major expansion of our paper\n  arXiv:1705.09936 * Reworking of original semi-honest protocol and its\n  security proof * Major expansions: tailored zero-knowledge proofs; efficient\n  variant of original protocol that we prove secure against malicious\n  adversaries; extensive experimental evaluation using three different\n  datasets; in-depth comparison with related work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biometric verification has been widely deployed in current authentication\nsolutions as it proves the physical presence of individuals. To protect the\nsensitive biometric data in such systems, several solutions have been developed\nthat provide security against honest-but-curious (semi-honest) attackers.\nHowever, in practice attackers typically do not act honestly and multiple\nstudies have shown drastic biometric information leakage in such\nhonest-but-curious solutions when considering dishonest, malicious attackers.\n  In this paper, we propose a provably secure biometric verification protocol\nto withstand malicious attackers and prevent biometric data from any sort of\nleakage. The proposed protocol is based on a homomorphically encrypted log\nlikelihood-ratio-based (HELR) classifier that supports any biometric modality\n(e.g. face, fingerprint, dynamic signature, etc.) encoded as a fixed-length\nreal-valued feature vector and performs an accurate and fast biometric\nrecognition. Our protocol, that is secure against malicious adversaries, is\ndesigned from a protocol secure against semi-honest adversaries enhanced by\nzero-knowledge proofs. We evaluate both protocols for various security levels\nand record a sub-second speed (between $0.37$s and $0.88$s) for the protocol\nagainst semi-honest adversaries and between $0.95$s and $2.50$s for the\nprotocol secure against malicious adversaries.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 08:42:01 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Bassit", "Amina", ""], ["Hahn", "Florian", ""], ["Peeters", "Joep", ""], ["Kevenaar", "Tom", ""], ["Veldhuis", "Raymond N. J.", ""], ["Peter", "Andreas", ""]]}, {"id": "2101.10681", "submitter": "Stephan Wiefling", "authors": "Stephan Wiefling, Markus D\\\"urmuth, Luigi Lo Iacono", "title": "What's in Score for Website Users: A Data-driven Long-term Study on\n  Risk-based Authentication Characteristics", "comments": "23 pages, 4 figures, 5 tables", "journal-ref": "25th International Conference on Financial Cryptography and Data\n  Security (FC '21). March 01-05, 2021", "doi": null, "report-no": null, "categories": "cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Risk-based authentication (RBA) aims to strengthen password-based\nauthentication rather than replacing it. RBA does this by monitoring and\nrecording additional features during the login process. If feature values at\nlogin time differ significantly from those observed before, RBA requests an\nadditional proof of identification. Although RBA is recommended in the NIST\ndigital identity guidelines, it has so far been used almost exclusively by\nmajor online services. This is partly due to a lack of open knowledge and\nimplementations that would allow any service provider to roll out RBA\nprotection to its users.\n  To close this gap, we provide a first in-depth analysis of RBA\ncharacteristics in a practical deployment. We observed N=780 users with 247\nunique features on a real-world online service for over 1.8 years. Based on our\ncollected data set, we provide (i) a behavior analysis of two RBA\nimplementations that were apparently used by major online services in the wild,\n(ii) a benchmark of the features to extract a subset that is most suitable for\nRBA use, (iii) a new feature that has not been used in RBA before, and (iv)\nfactors which have a significant effect on RBA performance. Our results show\nthat RBA needs to be carefully tailored to each online service, as even small\nconfiguration adjustments can greatly impact RBA's security and usability\nproperties. We provide insights on the selection of features, their weightings,\nand the risk classification in order to benefit from RBA after a minimum number\nof login attempts.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 10:14:59 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Wiefling", "Stephan", ""], ["D\u00fcrmuth", "Markus", ""], ["Iacono", "Luigi Lo", ""]]}, {"id": "2101.10699", "submitter": "Chao Li", "authors": "Qinwei Lin, Chao Li, Xifeng Zhao and Xianhai Chen", "title": "Measuring Decentralization in Bitcoin and Ethereum using Multiple\n  Metrics and Granularities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralization has been widely acknowledged as a core virtue of\nblockchains. However, in the past, there have been few measurement studies on\nmeasuring and comparing the actual level of decentralization between existing\nblockchains using multiple metrics and granularities. This paper presents a new\ncomparison study of the degree of decentralization in Bitcoin and Ethereum, the\ntwo most prominent blockchains, with various decentralization metrics and\ndifferent granularities within the time dimension. Specifically, we measure the\ndegree of decentralization in the two blockchains during 2019 by computing the\ndistribution of mining power with three metrics (Gini coefficient, Shannon\nentropy, and Nakamoto coefficient) as well as three granularities (days, weeks,\nand months). Our measurement results with different metrics and granularities\nreveal the same trend that, compared with each other, the degree of\ndecentralization in Bitcoin is higher, while the degree of decentralization in\nEthereum is more stable. To obtain the cross-interval information missed in the\nfixed window based measurements, we propose the sliding window based\nmeasurement approach. The corresponding results demonstrate that the use of\nsliding windows could reveal additional cross-interval information overlooked\nby the fixed window based measurements, thus enhancing the effectiveness of\nmeasuring decentralization in terms of continuous trends and abnormal\nsituations. We believe that the methodologies and findings in this paper can\nfacilitate future studies of decentralization in blockchains.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 10:45:06 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 03:56:56 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Lin", "Qinwei", ""], ["Li", "Chao", ""], ["Zhao", "Xifeng", ""], ["Chen", "Xianhai", ""]]}, {"id": "2101.10729", "submitter": "Hyoungsung Kim", "authors": "Hyoungsung Kim, Jehyuk Jang, Sangjun Park, Heung-no Lee", "title": "Ethereum ECCPoW", "comments": "It is under the review of IEEE Access", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The error-correction code based proof-of-work (ECCPoW) algorithm is based on\na low-density parity-check (LDPC) code. The ECCPoW is possible to impair ASIC\nwith its time-varying capability of the parameters of LDPC code. Previous\nresearches on the ECCPoW algorithm have presented its theory and implementation\non Bitcoin. But they do not discuss how stable the block generation time is. A\nfinite mean block generation time (BGT) and none heavy-tail BGT distribution\nare the ones of the focus in this study. In the ECCPoW algorithm, BGT may show\na long-tailed distribution due to time-varying cryptographic puzzles. Thus, it\nis of interest to see if the BGT distribution is not heavy-tailed and if it\nshows a finite mean. If the distribution is heavy-tailed, then confirmation of\na transaction cannot be guaranteed. We present implementation, simulation, and\nvalidation of ECCPoW Ethereum. In implementation, we explain how the ECCPoW\nalgorithm is integrated into Ethereum 1.0 as a new consensus algorithm. In the\nsimulation, we perform a multinode simulation to show that the ECCPoW Ethereum\nworks well with automatic difficulty change. In the validation, we present the\nstatistical results of the two-sample Anderson-Darling test to show that the\ndistribution of BGT satisfies the necessary condition of the exponential\ndistribution. Our implementation is downloadable at\nhttps://github.com/cryptoecc/ETH-ECC.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 11:50:06 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Kim", "Hyoungsung", ""], ["Jang", "Jehyuk", ""], ["Park", "Sangjun", ""], ["Lee", "Heung-no", ""]]}, {"id": "2101.10792", "submitter": "Nicolas Michael M\\\"uller", "authors": "Nicolas M. M\\\"uller, Konstantin B\\\"ottinger", "title": "Adversarial Vulnerability of Active Transfer Learning", "comments": "Accepted for publication at IDA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two widely used techniques for training supervised machine learning models on\nsmall datasets are Active Learning and Transfer Learning. The former helps to\noptimally use a limited budget to label new data. The latter uses large\npre-trained models as feature extractors and enables the design of complex,\nnon-linear models even on tiny datasets. Combining these two approaches is an\neffective, state-of-the-art method when dealing with small datasets.\n  In this paper, we share an intriguing observation: Namely, that the\ncombination of these techniques is particularly susceptible to a new kind of\ndata poisoning attack: By adding small adversarial noise on the input, it is\npossible to create a collision in the output space of the transfer learner. As\na result, Active Learning algorithms no longer select the optimal instances,\nbut almost exclusively the ones injected by the attacker. This allows an\nattacker to manipulate the active learner to select and include arbitrary\nimages into the data set, even against an overwhelming majority of unpoisoned\nsamples. We show that a model trained on such a poisoned dataset has a\nsignificantly deteriorated performance, dropping from 86\\% to 34\\% test\naccuracy. We evaluate this attack on both audio and image datasets and support\nour findings empirically. To the best of our knowledge, this weakness has not\nbeen described before in literature.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 14:07:09 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["M\u00fcller", "Nicolas M.", ""], ["B\u00f6ttinger", "Konstantin", ""]]}, {"id": "2101.10852", "submitter": "Hao Xu", "authors": "Lei Zhang, Hao Xu, Oluwakayode Onireti, Muhammad Ali Imran and Bin Cao", "title": "How Much Communication Resource is Needed to Run a Wireless Blockchain\n  Network?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain is built on a peer-to-peer network that relies on frequent\ncommunications among the distributively located nodes. In particular, the\nconsensus mechanisms (CMs), which play a pivotal role in blockchain, are\ncommunication resource-demanding and largely determines blockchain security\nbound and other key performance metrics such as transaction throughput, latency\nand scalability. Most blockchain systems are designed in a stable wired\ncommunication network running in advanced devices under the assumption of\nsufficient communication resource provision. However, it is envisioned that the\nmajority of the blockchain node peers will be connected through the wireless\nnetwork in the future. Constrained by the highly dynamic wireless channel and\nscarce frequency spectrum, communication can significantly affect blockchain's\nkey performance metrics. Hence, in this paper, we present wireless blockchain\nnetworks (WBN) under various commonly used CMs and we answer the question of\nhow much communication resource is needed to run such a network. We first\npresent the role of communication in the four stages of the blockchain\nprocedure. We then discuss the relationship between the communication resource\nprovision and the WBNs performance, for three of the most used blockchain CMs\nnamely, Proof-of-Work (PoW), practical Byzantine Fault Tolerant (PBFT) and\nRaft. Finally, we provide analytical and simulated results to show the impact\nof the communication resource provision on blockchain performance.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2021 13:03:00 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Zhang", "Lei", ""], ["Xu", "Hao", ""], ["Onireti", "Oluwakayode", ""], ["Imran", "Muhammad Ali", ""], ["Cao", "Bin", ""]]}, {"id": "2101.10856", "submitter": "Hao Xu", "authors": "Hao Xu, Lei Zhang, Yunqing Sun, and Chih-Lin I", "title": "BE-RAN: Blockchain-enabled Open RAN with Decentralized Identity\n  Management and Privacy-Preserving Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radio Access Networks (RAN) tends to be more distributed in the 5G and\nbeyond, in order to provide low latency and flexible on-demanding services. In\nthis paper, Blockchain-enabled Radio Access Networks (BE-RAN) is proposed as a\nnovel decentralized RAN architecture to facilitate enhanced security and\nprivacy on identification and authentication. It can offer user-centric\nidentity management for User Equipment (UE) and RAN elements, and enable mutual\nauthentication to all entities while enabling on-demand point-to-point\ncommunication with accountable billing service add-on on public network. Also,\na potential operating model with thorough decentralization of RAN is\nenvisioned. The paper also proposed a distributed privacy-preserving P2P\ncommunication approach, as one of the core use cases for future mobile\nnetworks, is presented as an essential complement to the existing core\nnetwork-based security and privacy management. The results show that BE-RAN\nsignificantly improves communication and computation overheads compared to the\nexisting communication authentication protocols.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 15:24:22 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2021 19:43:45 GMT"}, {"version": "v3", "created": "Sat, 29 May 2021 12:24:26 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Xu", "Hao", ""], ["Zhang", "Lei", ""], ["Sun", "Yunqing", ""], ["I", "Chih-Lin", ""]]}, {"id": "2101.10865", "submitter": "Jonathan Spring", "authors": "Jonathan M. Spring and April Galyardt and Allen D. Householder and\n  Nathan VanHoudnos", "title": "On managing vulnerabilities in AI/ML systems", "comments": "16 pages. New Security Paradigms Workshop", "journal-ref": null, "doi": "10.1145/3442167.3442177", "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores how the current paradigm of vulnerability management\nmight adapt to include machine learning systems through a thought experiment:\nwhat if flaws in machine learning (ML) were assigned Common Vulnerabilities and\nExposures (CVE) identifiers (CVE-IDs)? We consider both ML algorithms and model\nobjects. The hypothetical scenario is structured around exploring the changes\nto the six areas of vulnerability management: discovery, report intake,\nanalysis, coordination, disclosure, and response. While algorithm flaws are\nwell-known in the academic research community, there is no apparent clear line\nof communication between this research community and the operational\ncommunities that deploy and manage systems that use ML. The thought experiments\nidentify some ways in which CVE-IDs may establish some useful lines of\ncommunication between these two communities. In particular, it would start to\nintroduce the research community to operational security concepts, which\nappears to be a gap left by existing efforts.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 21:59:44 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Spring", "Jonathan M.", ""], ["Galyardt", "April", ""], ["Householder", "Allen D.", ""], ["VanHoudnos", "Nathan", ""]]}, {"id": "2101.10868", "submitter": "Jiaqi Wang", "authors": "Jiaqi Wang", "title": "An In-depth Review of Privacy Concerns Raised by the COVID-19 Pandemic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  COVID-19 has hugely changed our lives, work, and interactions with people.\nWith more and more online activities, people are easily exposed to privacy\nthreats. In this paper, we explore how users self-disclose on social media and\nprivacy concerns raised from these behaviors. Based on recent news, techniques,\nand research, we indicate three increasing privacy threats caused by the\nCOVID-19 pandemic. After that, we provide a systematic analysis of potential\nprivacy issues related to the COVID pandemic. Furthermore, we propose a series\nof research directions about online user self-disclosure and privacy issues for\nfuture work as well as possible solutions.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2021 06:58:40 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Wang", "Jiaqi", ""]]}, {"id": "2101.10893", "submitter": "Raisa Dzhamtyrova PhD", "authors": "Raisa Dzhamtyrova and Carsten Maple", "title": "Dynamic cyber risk estimation with Competitive Quantile Autoregression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing value of data held in enterprises makes it an attractive\ntarget to attackers. The increasing likelihood and impact of a cyber attack\nhave highlighted the importance of effective cyber risk estimation. We propose\ntwo methods for modelling Value-at-Risk (VaR) which can be used for any\ntime-series data. The first approach is based on Quantile Autoregression (QAR),\nwhich can estimate VaR for different quantiles, i.e. confidence levels. The\nsecond method, we term Competitive Quantile Autoregression (CQAR), dynamically\nre-estimates cyber risk as soon as new data becomes available. This method\nprovides a theoretical guarantee that it asymptotically performs as well as any\nQAR at any time point in the future. We show that these methods can predict the\nsize and inter-arrival time of cyber hacking breaches by running coverage\ntests. The proposed approaches allow to model a separate stochastic process for\neach significance level and therefore provide more flexibility compared to\npreviously proposed techniques. We provide a fully reproducible code used for\nconducting the experiments.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 16:52:27 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 10:06:10 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Dzhamtyrova", "Raisa", ""], ["Maple", "Carsten", ""]]}, {"id": "2101.10904", "submitter": "Ranwa Al Mallah", "authors": "Ranwa Al Mallah, David Lopez, Bilal Farooq", "title": "Untargeted Poisoning Attack Detection in Federated Learning via Behavior\n  Attestation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) is a paradigm in Machine Learning (ML) that addresses\ndata privacy, security, access rights and access to heterogeneous information\nissues by training a global model using distributed nodes. Despite its\nadvantages, there is an increased potential for cyberattacks on FL-based ML\ntechniques that can undermine the benefits. Model-poisoning attacks on FL\ntarget the availability of the model. The adversarial objective is to disrupt\nthe training. We propose attestedFL, a defense mechanism that monitors the\ntraining of individual nodes through state persistence in order to detect a\nmalicious worker. A fine-grained assessment of the history of the worker\npermits the evaluation of its behavior in time and results in innovative\ndetection strategies. We present three lines of defense that aim at assessing\nif the worker is reliable by observing if the node is really training,\nadvancing towards a goal. Our defense exposes an attacker's malicious behavior\nand removes unreliable nodes from the aggregation process so that the FL\nprocess converge faster. Through extensive evaluations and against various\nadversarial settings, attestedFL increased the accuracy of the model between\n12% to 58% under different scenarios such as attacks performed at different\nstages of convergence, attackers colluding and continuous attacks.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2021 20:52:55 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 14:50:24 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Mallah", "Ranwa Al", ""], ["Lopez", "David", ""], ["Farooq", "Bilal", ""]]}, {"id": "2101.10920", "submitter": "Nguyen Truong", "authors": "Nguyen Truong, Gyu Myoung Lee, Kai Sun, Florian Guitton, Yike Guo", "title": "A Blockchain-based Trust System for Decentralised Applications: When\n  trustless needs trust", "comments": "14 pages, 8 figures, submitted to Elsevier Future Generation Computer\n  Systems jornal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blockchain technology has been envisaged to commence an era of decentralised\napplications and services (DApps) without the need for a trusted intermediary.\nSuch DApps open a marketplace in which services are delivered to end-users by\ncontributors which are then incentivised by cryptocurrencies in an automated,\npeer-to-peer, and trustless fashion. However, blockchain, consolidated by smart\ncontracts, only ensures on-chain data security, autonomy and integrity of the\nbusiness logic execution defined in smart contracts. It cannot guarantee the\nquality of service of DApps, which entirely depends on the services'\nperformance. Thus, there is a critical need for a trust system to reduce the\nrisk of dealing with fraudulent counterparts in a blockchain network. These\nreasons motivate us to develop a fully decentralised trust framework deployed\non top of a blockchain platform, operating along with DApps in the marketplace\nto demoralise deceptive entities while encouraging trustworthy ones. The trust\nsystem works as an underlying decentralised service providing a feedback\nmechanism for end-users and maintaining trust relationships among them in the\necosystem accordingly. We believe this research fortifies the DApps ecosystem\nby introducing an universal trust middleware for DApps as well as shedding\nlight on the implementation of a decentralised trust system.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 16:41:01 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Truong", "Nguyen", ""], ["Lee", "Gyu Myoung", ""], ["Sun", "Kai", ""], ["Guitton", "Florian", ""], ["Guo", "Yike", ""]]}, {"id": "2101.10921", "submitter": "Sunil Singh", "authors": "Sunil Kumar Singh, Sumit Kumar", "title": "Blockchain Technology: Introduction, Integration and Security Issues\n  with IoT", "comments": "21 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Blockchain was mainly introduced for secure transactions in connection with\nthe mining of cryptocurrency Bitcoin. This article discusses the fundamental\nconcepts of blockchain technology and its components, such as block header,\ntransaction, smart contracts, etc. Blockchain uses the distributed databases,\nso this article also explains the advantages of distributed Blockchain over a\ncentrally located database. Depending on the application, Blockchain is broadly\ncategorized into two categories; Permissionless and Permissioned. This article\nelaborates on these two categories as well. Further, it covers the consensus\nmechanism and its working along with an overview of the Ethereum platform.\nBlockchain technology has been proved to be one of the remarkable techniques to\nprovide security to IoT devices. An illustration of how Blockchain will be\nuseful for IoT devices has been given. A few applications are also illustrated\nto explain the working of Blockchain with IoT.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 16:41:49 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Singh", "Sunil Kumar", ""], ["Kumar", "Sumit", ""]]}, {"id": "2101.11060", "submitter": "Xinwei Zhao", "authors": "Xinwei Zhao and Matthew C. Stamm", "title": "Defenses Against Multi-Sticker Physical Domain Attacks on Classifiers", "comments": null, "journal-ref": "This paper is published on European Conference on Computer Vision\n  2020, page 202-219, Springer", "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, physical domain adversarial attacks have drawn significant\nattention from the machine learning community. One important attack proposed by\nEykholt et al. can fool a classifier by placing black and white stickers on an\nobject such as a road sign. While this attack may pose a significant threat to\nvisual classifiers, there are currently no defenses designed to protect against\nthis attack. In this paper, we propose new defenses that can protect against\nmulti-sticker attacks. We present defensive strategies capable of operating\nwhen the defender has full, partial, and no prior information about the attack.\nBy conducting extensive experiments, we show that our proposed defenses can\noutperform existing defenses against physical attacks when presented with a\nmulti-sticker attack.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 19:59:28 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Zhao", "Xinwei", ""], ["Stamm", "Matthew C.", ""]]}, {"id": "2101.11073", "submitter": "Saeed Mahloujifar", "authors": "Melissa Chase, Esha Ghosh, Saeed Mahloujifar", "title": "Property Inference From Poisoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Property inference attacks consider an adversary who has access to the\ntrained model and tries to extract some global statistics of the training data.\nIn this work, we study property inference in scenarios where the adversary can\nmaliciously control part of the training data (poisoning data) with the goal of\nincreasing the leakage.\n  Previous work on poisoning attacks focused on trying to decrease the accuracy\nof models either on the whole population or on specific sub-populations or\ninstances. Here, for the first time, we study poisoning attacks where the goal\nof the adversary is to increase the information leakage of the model. Our\nfindings suggest that poisoning attacks can boost the information leakage\nsignificantly and should be considered as a stronger threat model in sensitive\napplications where some of the data sources may be malicious.\n  We describe our \\emph{property inference poisoning attack} that allows the\nadversary to learn the prevalence in the training data of any property it\nchooses. We theoretically prove that our attack can always succeed as long as\nthe learning algorithm used has good generalization properties.\n  We then verify the effectiveness of our attack by experimentally evaluating\nit on two datasets: a Census dataset and the Enron email dataset. We were able\nto achieve above $90\\%$ attack accuracy with $9-10\\%$ poisoning in all of our\nexperiments.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 20:35:28 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Chase", "Melissa", ""], ["Ghosh", "Esha", ""], ["Mahloujifar", "Saeed", ""]]}, {"id": "2101.11081", "submitter": "Xinwei Zhao", "authors": "Xinwei Zhao and Matthew C. Stamm", "title": "The Effect of Class Definitions on the Transferability of Adversarial\n  Attacks Against Forensic CNNs", "comments": null, "journal-ref": "Published at Electronic Imaging, Media Watermarking, Security, and\n  Forensics 2020, pp. 119-1-119-7(7)", "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, convolutional neural networks (CNNs) have been widely used\nby researchers to perform forensic tasks such as image tampering detection. At\nthe same time, adversarial attacks have been developed that are capable of\nfooling CNN-based classifiers. Understanding the transferability of adversarial\nattacks, i.e. an attacks ability to attack a different CNN than the one it was\ntrained against, has important implications for designing CNNs that are\nresistant to attacks. While attacks on object recognition CNNs are believed to\nbe transferrable, recent work by Barni et al. has shown that attacks on\nforensic CNNs have difficulty transferring to other CNN architectures or CNNs\ntrained using different datasets. In this paper, we demonstrate that\nadversarial attacks on forensic CNNs are even less transferrable than\npreviously thought even between virtually identical CNN architectures! We show\nthat several common adversarial attacks against CNNs trained to identify image\nmanipulation fail to transfer to CNNs whose only difference is in the class\ndefinitions (i.e. the same CNN architectures trained using the same data). We\nnote that all formulations of class definitions contain the unaltered class.\nThis has important implications for the future design of forensic CNNs that are\nrobust to adversarial and anti-forensic attacks.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 20:59:37 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Zhao", "Xinwei", ""], ["Stamm", "Matthew C.", ""]]}, {"id": "2101.11144", "submitter": "Akira Imakura", "authors": "Akira Imakura, Anna Bogdanova, Takaya Yamazoe, Kazumasa Omote, Tetsuya\n  Sakurai", "title": "Accuracy and Privacy Evaluations of Collaborative Data Analysis", "comments": "16 pages; 2 figures; 1 table", "journal-ref": "To be presented at The Second AAAI Workshop on Privacy-Preserving\n  Artificial Intelligence (PPAI-21) (2021)", "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed data analysis without revealing the individual data has recently\nattracted significant attention in several applications. A collaborative data\nanalysis through sharing dimensionality reduced representations of data has\nbeen proposed as a non-model sharing-type federated learning. This paper\nanalyzes the accuracy and privacy evaluations of this novel framework. In the\naccuracy analysis, we provided sufficient conditions for the equivalence of the\ncollaborative data analysis and the centralized analysis with dimensionality\nreduction. In the privacy analysis, we proved that collaborative users' private\ndatasets are protected with a double privacy layer against insider and external\nattacking scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 00:38:47 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Imakura", "Akira", ""], ["Bogdanova", "Anna", ""], ["Yamazoe", "Takaya", ""], ["Omote", "Kazumasa", ""], ["Sakurai", "Tetsuya", ""]]}, {"id": "2101.11194", "submitter": "Seunghoan Song", "authors": "Seunghoan Song and Masahito Hayashi", "title": "Equivalence of Non-Perfect Secret Sharing and Symmetric Private\n  Information Retrieval with General Access Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the equivalence between non-perfect secret sharing (NSS) and\nsymmetric private information retrieval (SPIR) with arbitrary response and\ncollusion patterns. NSS and SPIR are defined with an access structure, which\ncorresponds to the authorized/forbidden sets for NSS and the response/collusion\npatterns for SPIR. We prove the equivalence between NSS and SPIR in the\nfollowing two senses. 1) Given any SPIR protocol with an access structure, an\nNSS protocol is constructed with the same access structure and the same rate.\n2) Given any linear NSS protocol with an access structure, a linear SPIR\nprotocol is constructed with the same access structure and the same rate. We\nprove the first relation even if the SPIR protocol has imperfect correctness\nand secrecy. From the first relation, we derive an upper bound of the SPIR\ncapacity for arbitrary response and collusion patterns. For the special case of\n$\\mathsf{n}$-server SPIR with $\\mathsf{r}$ responsive and $\\mathsf{t}$\ncolluding servers, this upper bound proves that the SPIR capacity is\n$(\\mathsf{r}-\\mathsf{t})/\\mathsf{n}$. From the second relation, we prove that a\nSPIR protocol exists for any response and collusion patterns.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 04:20:39 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 15:28:30 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Song", "Seunghoan", ""], ["Hayashi", "Masahito", ""]]}, {"id": "2101.11404", "submitter": "Zain Ul Abideen", "authors": "Malik Imran and Zain Ul Abideen and Samuel Pagliarini", "title": "An Open-source Library of Large Integer Polynomial Multipliers", "comments": "This paper has been accepted for conference proceeding in DDECS 2021\n  - April 7-9 2021 Vienna, Austria", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Polynomial multiplication is a bottleneck in most of the public-key\ncryptography protocols, including Elliptic-curve cryptography and several of\nthe post-quantum cryptography algorithms presently being studied. In this\npaper, we present a library of various large integer polynomial multipliers to\nbe used in hardware cryptocores. Our library contains both digitized and\nnon-digitized multiplier flavours for circuit designers to choose from. The\nlibrary is supported by a C++ generator that automatically produces the\nmultipliers' logic in Verilog HDL that is amenable for FPGA and ASIC designs.\nMoreover, for ASICs, it also generates configurable and parameterizable\nsynthesis scripts. The features of the generator allow for a quick generation\nand assessment of several architectures at the same time, thus allowing a\ndesigner to easily explore the (complex) optimization search space of\npolynomial multiplication.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 13:57:09 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 09:40:05 GMT"}, {"version": "v3", "created": "Mon, 29 Mar 2021 09:10:43 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Imran", "Malik", ""], ["Abideen", "Zain Ul", ""], ["Pagliarini", "Samuel", ""]]}, {"id": "2101.11502", "submitter": "Boel Nelson", "authors": "Boel Nelson", "title": "Randori: Local Differential Privacy for All", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Polls are a common way of collecting data, including product reviews and\nfeedback forms. However, few data collectors give upfront privacy guarantees.\nAdditionally, when privacy guarantees are given upfront, they are often vague\nclaims about 'anonymity'. Instead, we propose giving quantifiable privacy\nguarantees through the statistical notion of differential privacy.\nNevertheless, privacy does not come for free. At the heart of differential\nprivacy lies an inherent trade-off between accuracy and privacy that needs to\nbe balanced. Thus, it is vital to properly adjust the accuracy-privacy\ntrade-off before setting out to collect data. Altogether, getting started with\ndifferentially private data collection can be challenging. Ideally, a data\nanalyst should not have to be concerned about all the details of differential\nprivacy, but rather get differential privacy by design. Still, to the best of\nour knowledge, no tools for gathering poll data under differential privacy\nexists.\n  Motivated by the lack of tools to gather poll data under differential\nprivacy, we set out to engineer our own tool. Specifically, to make local\ndifferential privacy accessible for all, in this systems paper we present\nRandori, a set of novel open source tools for differentially private poll data\ncollection. Randori is intended to help data analysts keep their focus on what\ndata their poll is collecting, as opposed to how they should collect it. Our\ntools also allow the data analysts to analytically predict the accuracy of\ntheir poll. Furthermore, we show that differential privacy alone is not enough\nto achieve end-to-end privacy in a server-client setting. Consequently, we also\ninvestigate and mitigate implicit data leaks in Randori.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 15:57:30 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Nelson", "Boel", ""]]}, {"id": "2101.11574", "submitter": "Weihua Li", "authors": "Jiaqi Wu, Weihua Li, Quan Bai, Takayuki Ito, Ahmed Moustafa", "title": "Privacy Information Classification: A Hybrid Approach", "comments": "IJCAI 2019 Workshop. The 4th International Workshop on Smart\n  Simulation and Modelling for Complex Systems", "journal-ref": null, "doi": null, "report-no": "SSMCS2019-11", "categories": "cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A large amount of information has been published to online social networks\nevery day. Individual privacy-related information is also possibly disclosed\nunconsciously by the end-users. Identifying privacy-related data and protecting\nthe online social network users from privacy leakage turn out to be\nsignificant. Under such a motivation, this study aims to propose and develop a\nhybrid privacy classification approach to detect and classify privacy\ninformation from OSNs. The proposed hybrid approach employs both deep learning\nmodels and ontology-based models for privacy-related information extraction.\nExtensive experiments are conducted to validate the proposed hybrid approach,\nand the empirical results demonstrate its superiority in assisting online\nsocial network users against privacy leakage.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 18:03:18 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Wu", "Jiaqi", ""], ["Li", "Weihua", ""], ["Bai", "Quan", ""], ["Ito", "Takayuki", ""], ["Moustafa", "Ahmed", ""]]}, {"id": "2101.11611", "submitter": "Wenhui Zhang", "authors": "Wenhui Zhang, Trent Jaeger, Peng Liu", "title": "Analyzing the Overhead of Filesystem Protection Using Linux Security\n  Modules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the years, the complexity of the Linux Security Module (LSM) is keeping\nincreasing, and the count of the authorization hooks is nearly doubled. It is\nimportant to provide up-to-date measurement results of LSM for system\npractitioners so that they can make prudent trade-offs between security and\nperformance. This work evaluates the overhead of LSM for file accesses on Linux\nv5.3.0. We build a performance evaluation framework for LSM. It has two parts,\nan extension of LMBench2.5 to evaluate the overhead of file operations for\ndifferent security modules, and a security module with tunable latency for\npolicy enforcement to study the impact of the latency of policy enforcement on\nthe end-to-end latency of file operations. In our evaluation, we find opening a\nfile would see about 87% (Linux v5.3) performance drop when the kernel is\nintegrated with SELinux hooks (policy enforcement disabled) than without, while\nthe figure was 27% (Linux v2.4.2). We found that performance of the above\ndowngrade is affected by two parts, policy enforcement and hook placement. To\nfurther investigate the impact of policy enforcement and hook placement\nrespectively, we build a Policy Testing Module, which reuses hook placements of\nLSM, while alternating latency of policy enforcement. With this module, we are\nable to quantitatively estimate the impact of the latency of policy enforcement\non the end-to-end latency of file operations by using a multiple linear\nregression model and count policy authorization frequencies for each syscall.\nWe then discuss and justify the evaluation results with static analysis on our\nenhanced syscalls' call graphs.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 20:06:45 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Zhang", "Wenhui", ""], ["Jaeger", "Trent", ""], ["Liu", "Peng", ""]]}, {"id": "2101.11693", "submitter": "Mohammad Malekzadeh", "authors": "Mohammad Malekzadeh, Burak Hasircioglu, Nitish Mital, Kunal Katarya,\n  Mehmet Emre Ozfatura, Deniz G\\\"und\\\"uz", "title": "Dopamine: Differentially Private Federated Learning on Medical Data", "comments": "The Second AAAI Workshop on Privacy-Preserving Artificial\n  Intelligence (PPAI-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While rich medical datasets are hosted in hospitals distributed across the\nworld, concerns on patients' privacy is a barrier against using such data to\ntrain deep neural networks (DNNs) for medical diagnostics. We propose Dopamine,\na system to train DNNs on distributed datasets, which employs federated\nlearning (FL) with differentially-private stochastic gradient descent (DPSGD),\nand, in combination with secure aggregation, can establish a better trade-off\nbetween differential privacy (DP) guarantee and DNN's accuracy than other\napproaches. Results on a diabetic retinopathy~(DR) task show that Dopamine\nprovides a DP guarantee close to the centralized training counterpart, while\nachieving a better classification accuracy than FL with parallel DP where DPSGD\nis applied without coordination. Code is available at\nhttps://github.com/ipc-lab/private-ml-for-health.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 21:27:23 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 16:40:17 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Malekzadeh", "Mohammad", ""], ["Hasircioglu", "Burak", ""], ["Mital", "Nitish", ""], ["Katarya", "Kunal", ""], ["Ozfatura", "Mehmet Emre", ""], ["G\u00fcnd\u00fcz", "Deniz", ""]]}, {"id": "2101.11702", "submitter": "Domen Vre\\v{s}", "authors": "Domen Vre\\v{s} and Marko Robnik \\v{S}ikonja", "title": "Better sampling in explanation methods can prevent dieselgate-like\n  deception", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning models are used in many sensitive areas where besides\npredictive accuracy their comprehensibility is also important. Interpretability\nof prediction models is necessary to determine their biases and causes of\nerrors, and is a necessary prerequisite for users' confidence. For complex\nstate-of-the-art black-box models post-hoc model-independent explanation\ntechniques are an established solution. Popular and effective techniques, such\nas IME, LIME, and SHAP, use perturbation of instance features to explain\nindividual predictions. Recently, Slack et al. (2020) put their robustness into\nquestion by showing that their outcomes can be manipulated due to poor\nperturbation sampling employed. This weakness would allow dieselgate type\ncheating of owners of sensitive models who could deceive inspection and hide\npotentially unethical or illegal biases existing in their predictive models.\nThis could undermine public trust in machine learning models and give rise to\nlegal restrictions on their use.\n  We show that better sampling in these explanation methods prevents malicious\nmanipulations. The proposed sampling uses data generators that learn the\ntraining set distribution and generate new perturbation instances much more\nsimilar to the training set. We show that the improved sampling increases the\nrobustness of the LIME and SHAP, while previously untested method IME is\nalready the most robust of all.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 13:41:37 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Vre\u0161", "Domen", ""], ["\u0160ikonja", "Marko Robnik", ""]]}, {"id": "2101.11720", "submitter": "Federico Turrin", "authors": "Luca Attanasio and Mauro Conti and Denis Donadel and Federico Turrin", "title": "MiniV2G: An Electric Vehicle Charging Emulator", "comments": null, "journal-ref": null, "doi": "10.1145/3457339.3457980", "report-no": null, "categories": "cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The impact of global warming and the imperative to limit climate change have\nstimulated the need to develop new solutions based on renewable energy sources.\nOne of the emerging trends in this endeavor are the Electric Vehicles (EVs),\nwhich use electricity instead of traditional fossil fuels as a power source,\nrelying on the Vehicle-to-Grid (V2G) paradigm. The novelty of such a paradigm\nrequires careful analysis to avoid malicious attempts. An attacker can exploit\nseveral surfaces, such as the remote connection between the Distribution Grid\nand Charging Supply or the authentication system between the charging Supply\nEquipment and the Electric Vehicles. However, V2G architecture's high cost and\ncomplexity in implementation can restrain this field's research capability. In\nthis paper, we approach this limitation by proposing MiniV2G, an open-source\nemulator to simulate Electric Vehicle Charging (EVC) built on top of Mininet\nand RiseV2G. MiniV2G is particularly suitable for security researchers to study\nand test real V2G charging scenarios. MiniV2G can reproduce with high fidelity\na V2G architecture to easily simulate an EV charging process. Finally, we\npresent a MiniV2G application and show how MiniV2G can be used to study V2G\ncommunication and develop attacks and countermeasures that can be applied to\nreal systems. Since we believe our tool can be of great help for research in\nthis field, we also made it freely available.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 22:14:27 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Attanasio", "Luca", ""], ["Conti", "Mauro", ""], ["Donadel", "Denis", ""], ["Turrin", "Federico", ""]]}, {"id": "2101.11728", "submitter": "Abhishek Kumar Mishra", "authors": "Abhishek Kumar Mishra, Aline Carneiro Viana, Nadjib Achir", "title": "SimBle: Generating privacy preserving real-world BLE traces with ground\n  truth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bluetooth has become critical as many IoT devices are arriving in the market.\nMost of the current literature focusing on Bluetooth simulation concentrates on\nthe network protocols' performances and completely neglects the privacy\nprotection recommendations introduced in the BLE standard. Indeed, privacy\nprotection is one of the main issues handled in the Bluetooth standard. For\ninstance, the current standard forces devices to change the identifier they\nembed within the public and private packets, known as MAC address\nrandomization. Although randomizing MAC addresses is intended to preserve\ndevice privacy, recent literature shows many challenges that are still present.\nOne of them is the correlation between the public packets and the emitters.\nUnfortunately, existing evaluation tools such as NS-3 are not designed to\nreproduce this Bluetooth standard's essential functionality. This makes it\nimpossible to test solutions for different device-fingerprinting strategies as\nthere is a lack of ground truth for large-scale scenarios with the majority of\ncurrent BLE devices implementing MAC address randomization. In this paper, we\nfirst introduce a solution of standard-compliant MAC address randomization in\nthe NS-3 framework, capable of emulating any real BLE device in the simulation\nand generating real-world Bluetooth traces. In addition, since the simulation\nrun-time for trace-collection grows exponentially with the number of devices,\nwe introduce an optimization to linearize public-packet sniffing. This made the\nlarge-scale trace-collection practically feasible. Then, we use the generated\ntraces and associated ground truth to do a case study on the evaluation of a\ngeneric MAC address association available in the literature. Our case study\nreveals that close to 90 percent of randomized addresses could be correctly\nlinked even in highly dense and mobile scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 22:32:43 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 13:52:57 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Mishra", "Abhishek Kumar", ""], ["Viana", "Aline Carneiro", ""], ["Achir", "Nadjib", ""]]}, {"id": "2101.11835", "submitter": "Inbar Helbitz", "authors": "Inbar Helbitz, Shai Avidan", "title": "Reducing ReLU Count for Privacy-Preserving CNN Speedup", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy-Preserving Machine Learning algorithms must balance classification\naccuracy with data privacy. This can be done using a combination of\ncryptographic and machine learning tools such as Convolutional Neural Networks\n(CNN). CNNs typically consist of two types of operations: a convolutional or\nlinear layer, followed by a non-linear function such as ReLU. Each of these\ntypes can be implemented efficiently using a different cryptographic tool. But\nthese tools require different representations and switching between them is\ntime-consuming and expensive. Recent research suggests that ReLU is responsible\nfor most of the communication bandwidth. ReLU is usually applied at each pixel\n(or activation) location, which is quite expensive. We propose to share ReLU\noperations. Specifically, the ReLU decision of one activation can be used by\nothers, and we explore different ways to group activations and different ways\nto determine the ReLU for such a group of activations. Experiments on several\ndatasets reveal that we can cut the number of ReLU operations by up to three\norders of magnitude and, as a result, cut the communication bandwidth by more\nthan 50%.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 06:49:31 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Helbitz", "Inbar", ""], ["Avidan", "Shai", ""]]}, {"id": "2101.11866", "submitter": "Taejun Choi MEng CISSP CISA", "authors": "Taejun Choi, Guangdong Bai, Ryan K L Ko, Naipeng Dong, Wenlu Zhang,\n  Shunyao Wang", "title": "An Analytics Framework for Heuristic Inference Attacks against\n  Industrial Control Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Industrial control systems (ICS) of critical infrastructure are increasingly\nconnected to the Internet for remote site management at scale. However, cyber\nattacks against ICS - especially at the communication channels between\nhumanmachine interface (HMIs) and programmable logic controllers (PLCs) - are\nincreasing at a rate which outstrips the rate of mitigation.\n  In this paper, we introduce a vendor-agnostic analytics framework which\nallows security researchers to analyse attacks against ICS systems, even if the\nresearchers have zero control automation domain knowledge or are faced with a\nmyriad of heterogenous ICS systems. Unlike existing works that require\nexpertise in domain knowledge and specialised tool usage, our analytics\nframework does not require prior knowledge about ICS communication protocols,\nPLCs, and expertise of any network penetration testing tool. Using `digital\ntwin' scenarios comprising industry-representative HMIs, PLCs and firewalls in\nour test lab, our framework's steps were demonstrated to successfully implement\na stealthy deception attack based on false data injection attacks (FDIA).\nFurthermore, our framework also demonstrated the relative ease of attack\ndataset collection, and the ability to leverage well-known penetration testing\ntools.\n  We also introduce the concept of `heuristic inference attacks', a new family\nof attack types on ICS which is agnostic to PLC and HMI brands/models commonly\ndeployed in ICS. Our experiments were also validated on a separate ICS dataset\ncollected from a cyber-physical scenario of water utilities. Finally, we\nutilized time complexity theory to estimate the difficulty for the attacker to\nconduct the proposed packet analyses, and recommended countermeasures based on\nour findings.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 08:33:28 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Choi", "Taejun", ""], ["Bai", "Guangdong", ""], ["Ko", "Ryan K L", ""], ["Dong", "Naipeng", ""], ["Zhang", "Wenlu", ""], ["Wang", "Shunyao", ""]]}, {"id": "2101.11871", "submitter": "Pengwei Zhan", "authors": "Pengwei Zhan, Liming Wang, Yi Tang", "title": "Website Fingerprinting on Early QUIC Traffic", "comments": "30 pages, 7 figures, submitted to Elsevier Computer Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptographic protocols have been widely used to protect the user's privacy\nand avoid exposing private information. QUIC (Quick UDP Internet Connections),\nas an alternative to traditional HTTP, demonstrates its unique transmission\ncharacteristics: based on UDP for encrypted resource transmission, accelerating\nweb page rendering. However, existing encrypted transmission schemes based on\nTCP are vulnerable to website fingerprinting (WFP) attacks, allowing\nadversaries to infer the users' visited websites by eavesdropping on the\ntransmission channel. Whether QUIC protocol can effectively resisting to such\nattacks is worth investigating. In this work, we demonstrated the extreme\nvulnerability of QUIC under WFP attacks by comparing attack results under\nwell-designed conditions. We also study the transferability of features, which\nenable the adversary to use proven effective features on a special protocol\nattacking a new protocol. This study shows that QUIC is more vulnerable to WFP\nattacks than HTTPS in the early traffic scenario but is similar in the normal\nscenario. The maximum attack accuracy on QUIC is 56.8 % and 73 % higher than on\nHTTPS utilizing Simple features and Transfer features. The insecurity\ncharacteristic of QUIC explains the dramatic gap. We also find that features\nare transferable between protocols, and the feature importance is partially\ninherited on normal traffic due to the relatively fixed browser rendering\nsequence and the similar request-response model of protocols. However, the\ntransferability is inefficient when on early traffic, as QUIC and HTTPS show\nsignificantly different vulnerability when considering early traffic. We also\nshow that attack accuracy on QUIC could reach 95.4 % with only 40 packets and\njust using simple features, whereas only 60.7 % when on HTTPS.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 08:53:51 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Zhan", "Pengwei", ""], ["Wang", "Liming", ""], ["Tang", "Yi", ""]]}, {"id": "2101.11915", "submitter": "Rachit Agarwal", "authors": "Rachit Agarwal, Tanmay Thapliyal, Sandeep K. Shukla", "title": "Detecting Malicious Accounts showing Adversarial Behavior in\n  Permissionless Blockchains", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Different types of malicious activities have been flagged in multiple\npermissionless blockchains such as bitcoin, Ethereum etc. While some malicious\nactivities exploit vulnerabilities in the infrastructure of the blockchain,\nsome target its users through social engineering techniques. To address these\nproblems, we aim at automatically flagging blockchain accounts that originate\nsuch malicious exploitation of accounts of other participants. To that end, we\nidentify a robust supervised machine learning (ML) algorithm that is resistant\nto any bias induced by an over representation of certain malicious activity in\nthe available dataset, as well as is robust against adversarial attacks. We\nfind that most of the malicious activities reported thus far, for example, in\nEthereum blockchain ecosystem, behaves statistically similar. Further, the\npreviously used ML algorithms for identifying malicious accounts show bias\ntowards a particular malicious activity which is over-represented. In the\nsequel, we identify that Neural Networks (NN) holds up the best in the face of\nsuch bias inducing dataset at the same time being robust against certain\nadversarial attacks.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 10:33:50 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Agarwal", "Rachit", ""], ["Thapliyal", "Tanmay", ""], ["Shukla", "Sandeep K.", ""]]}, {"id": "2101.12016", "submitter": "Peter Bajcsy", "authors": "Peter Bajcsy and Michael Majurski", "title": "Baseline Pruning-Based Approach to Trojan Detection in Neural Networks", "comments": "The funding for all authors was provided by IARPA:\n  IARPA-20001-D2020-2007180011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper addresses the problem of detecting trojans in neural networks\n(NNs) by analyzing systematically pruned NN models. Our pruning-based approach\nconsists of three main steps. First, detect any deviations from the reference\nlook-up tables of model file sizes and model graphs. Next, measure the accuracy\nof a set of systematically pruned NN models following multiple pruning schemas.\nFinally, classify a NN model as clean or poisoned by applying a mapping between\naccuracy measurements and NN model labels. This work outlines a theoretical and\nexperimental framework for finding the optimal mapping over a large search\nspace of pruning parameters. Based on our experiments using Round 1 and Round 2\nTrojAI Challenge datasets, the approach achieves average classification\naccuracy of 69.73 % and 82.41% respectively with an average processing time of\nless than 60 s per model. For both datasets random guessing would produce 50%\nclassification accuracy. Reference model graphs and source code are available\nfrom GitHub.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 23:10:31 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 14:58:21 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Bajcsy", "Peter", ""], ["Majurski", "Michael", ""]]}, {"id": "2101.12031", "submitter": "Mohit Sewak", "authors": "Hemant Rathore and Sanjay K. Sahay and Piyush Nikam and Mohit Sewak", "title": "Robust Android Malware Detection System against Adversarial Attacks\n  using Q-Learning", "comments": "Inf Syst Front (2020)", "journal-ref": null, "doi": "10.1007/s10796-020-10083-8", "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current state-of-the-art Android malware detection systems are based on\nmachine learning and deep learning models. Despite having superior performance,\nthese models are susceptible to adversarial attacks. Therefore in this paper,\nwe developed eight Android malware detection models based on machine learning\nand deep neural network and investigated their robustness against adversarial\nattacks. For this purpose, we created new variants of malware using\nReinforcement Learning, which will be misclassified as benign by the existing\nAndroid malware detection models. We propose two novel attack strategies,\nnamely single policy attack and multiple policy attack using reinforcement\nlearning for white-box and grey-box scenario respectively. Putting ourselves in\nthe adversary's shoes, we designed adversarial attacks on the detection models\nwith the goal of maximizing fooling rate, while making minimum modifications to\nthe Android application and ensuring that the app's functionality and behavior\ndo not change. We achieved an average fooling rate of 44.21% and 53.20% across\nall the eight detection models with a maximum of five modifications using a\nsingle policy attack and multiple policy attack, respectively. The highest\nfooling rate of 86.09% with five changes was attained against the decision\ntree-based model using the multiple policy approach. Finally, we propose an\nadversarial defense strategy that reduces the average fooling rate by threefold\nto 15.22% against a single policy attack, thereby increasing the robustness of\nthe detection models i.e. the proposed model can effectively detect variants\n(metamorphic) of malware. The experimental analysis shows that our proposed\nAndroid malware detection system using reinforcement learning is more robust\nagainst adversarial attacks.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 16:45:57 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Rathore", "Hemant", ""], ["Sahay", "Sanjay K.", ""], ["Nikam", "Piyush", ""], ["Sewak", "Mohit", ""]]}, {"id": "2101.12078", "submitter": "Debayan Gupta", "authors": "Prashanthi Ramachandran, Shivam Agarwal, Arup Mondal, Aastha Shah,\n  Debayan Gupta", "title": "S++: A Fast and Deployable Secure-Computation Framework for\n  Privacy-Preserving Neural Network Training", "comments": "Appeared at the Second AAAI Workshop on Privacy-Preserving Artificial\n  Intelligence (PPAI-21). (7 pages, technical paper.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce S++, a simple, robust, and deployable framework for training a\nneural network (NN) using private data from multiple sources, using\nsecret-shared secure function evaluation. In short, consider a virtual third\nparty to whom every data-holder sends their inputs, and which computes the\nneural network: in our case, this virtual third party is actually a set of\nservers which individually learn nothing, even with a malicious (but\nnon-colluding) adversary.\n  Previous work in this area has been limited to just one specific activation\nfunction: ReLU, rendering the approach impractical for many use-cases. For the\nfirst time, we provide fast and verifiable protocols for all common activation\nfunctions and optimize them for running in a secret-shared manner. The ability\nto quickly, verifiably, and robustly compute exponentiation, softmax, sigmoid,\netc., allows us to use previously written NNs without modification, vastly\nreducing developer effort and complexity of code. In recent times, ReLU has\nbeen found to converge much faster and be more computationally efficient as\ncompared to non-linear functions like sigmoid or tanh. However, we argue that\nit would be remiss not to extend the mechanism to non-linear functions such as\nthe logistic sigmoid, tanh, and softmax that are fundamental due to their\nability to express outputs as probabilities and their universal approximation\nproperty. Their contribution in RNNs and a few recent advancements also makes\nthem more relevant.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 15:48:54 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Ramachandran", "Prashanthi", ""], ["Agarwal", "Shivam", ""], ["Mondal", "Arup", ""], ["Shah", "Aastha", ""], ["Gupta", "Debayan", ""]]}, {"id": "2101.12097", "submitter": "Hamidreza Habibollahi Najaf Abadi", "authors": "Hamidreza Habibollahi Najaf Abadi", "title": "Adversarial Machine Learning Attacks on Condition-Based Maintenance\n  Capabilities", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Condition-based maintenance (CBM) strategies exploit machine learning models\nto assess the health status of systems based on the collected data from the\nphysical environment, while machine learning models are vulnerable to\nadversarial attacks. A malicious adversary can manipulate the collected data to\ndeceive the machine learning model and affect the CBM system's performance.\nAdversarial machine learning techniques introduced in the computer vision\ndomain can be used to make stealthy attacks on CBM systems by adding\nperturbation to data to confuse trained models. The stealthy nature causes\ndifficulty and delay in detection of the attacks. In this paper, adversarial\nmachine learning in the domain of CBM is introduced. A case study shows how\nadversarial machine learning can be used to attack CBM capabilities.\nAdversarial samples are crafted using the Fast Gradient Sign method, and the\nperformance of a CBM system under attack is investigated. The obtained results\nreveal that CBM systems are vulnerable to adversarial machine learning attacks\nand defense strategies need to be considered.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 16:34:04 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Abadi", "Hamidreza Habibollahi Najaf", ""]]}, {"id": "2101.12124", "submitter": "Kayvon Mazooji", "authors": "Kayvon Mazooji, Roy Dong, Ilan Shomorony", "title": "Private DNA Sequencing: Hiding Information in Discrete Noise", "comments": "10 pages, 5 figures, shorter version to appear in proceedings of ITW\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When an individual's DNA is sequenced, sensitive medical information becomes\navailable to the sequencing laboratory. A recently proposed way to hide an\nindividual's genetic information is to mix in DNA samples of other individuals.\nWe assume these samples are known to the individual but unknown to the\nsequencing laboratory. Thus, these DNA samples act as \"noise\" to the sequencing\nlaboratory, but still allow the individual to recover their own DNA samples\nafterward. Motivated by this idea, we study the problem of hiding a binary\nrandom variable X (a genetic marker) with the additive noise provided by mixing\nDNA samples, using mutual information as a privacy metric. This is equivalent\nto the problem of finding a worst-case noise distribution for recovering X from\nthe noisy observation among a set of feasible discrete distributions. We\ncharacterize upper and lower bounds to the solution of this problem, which are\nempirically shown to be very close. The lower bound is obtained through a\nconvex relaxation of the original discrete optimization problem, and yields a\nclosed-form expression. The upper bound is computed via a greedy algorithm for\nselecting the mixing proportions.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 17:13:26 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Mazooji", "Kayvon", ""], ["Dong", "Roy", ""], ["Shomorony", "Ilan", ""]]}, {"id": "2101.12143", "submitter": "Donald Beaver", "authors": "Donald Rozinak Beaver", "title": "Security, Fault Tolerance, and Communication Complexity in Distributed\n  Systems", "comments": "PhD thesis, Harvard University, Cambridge, Massachusetts, USA, May\n  1990. Some chapters report joint work", "journal-ref": null, "doi": null, "report-no": "Harvard University Technical Report TR-24-90", "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present efficient and practical algorithms for a large, distributed system\nof processors to achieve reliable computations in a secure manner.\nSpecifically, we address the problem of computing a general function of several\nprivate inputs distributed among the processors of a network, while ensuring\nthe correctness of the results and the privacy of the inputs, despite\naccidental or malicious faults in the system. [...] Our algorithms maintain a\nlow cost in local processing time, are the first to achieve optimal levels of\nfault-tolerance, and most importantly, have low communication complexity. In\ncontrast to the best known previous methods, which require large numbers of\nrounds even for fairly simple computations, we devise protocols that use small\nmessages and a constant number of rounds regardless of the complexity of the\nfunction to be computed. Through direct algebraic approaches, we separate the\ncommunication complexity of secure computing from the computational complexity\nof the function to be computed. We examine security under both the modern\napproach of computational complexity-based cryptography and the classical\napproach of unconditional, information-theoretic security. We [...] support\nformal proofs of claims to security, addressing an important deficiency in the\nliterature. Our protocols are provably secure. In the realm of\ninformation-theoretic security, we characterize those functions which two\nparties can compute jointly with absolute privacy. We also characterize those\nfunctions which a weak processor can compute using the aid of powerful\nprocessors without having to reveal the instances of the problem it would like\nto solve. Our methods include a promising new technique called a locally random\nreduction, which has given rise not only to efficient solutions for many of the\nproblems considered in this work but to several powerful new results in\ncomplexity theory.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 17:51:04 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Beaver", "Donald Rozinak", ""]]}, {"id": "2101.12270", "submitter": "William Buchanan Prof", "authors": "Andrew Churcher, Rehmat Ullah, Jawad Ahmad, Sadaqat ur Rehman, Fawad\n  Masood, Mandar Gogate, Fehaid Alqahtani, Boubakr Nour and William J. Buchanan", "title": "An Experimental Analysis of Attack Classification Using Machine Learning\n  in IoT Networks", "comments": null, "journal-ref": "Sensors. 2021; 21(2):446", "doi": "10.3390/s21020446", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, there has been a massive increase in the amount of Internet\nof Things (IoT) devices as well as the data generated by such devices. The\nparticipating devices in IoT networks can be problematic due to their\nresource-constrained nature, and integrating security on these devices is often\noverlooked. This has resulted in attackers having an increased incentive to\ntarget IoT devices. As the number of attacks possible on a network increases,\nit becomes more difficult for traditional intrusion detection systems (IDS) to\ncope with these attacks efficiently. In this paper, we highlight several\nmachine learning (ML) methods such as k-nearest neighbour (KNN), support vector\nmachine (SVM), decision tree (DT), naive Bayes (NB), random forest (RF),\nartificial neural network (ANN), and logistic regression (LR) that can be used\nin IDS. In this work, ML algorithms are compared for both binary and\nmulti-class classification on Bot-IoT dataset. Based on several parameters such\nas accuracy, precision, recall, F1 score, and log loss, we experimentally\ncompared the aforementioned ML algorithms. In the case of HTTP distributed\ndenial-of-service (DDoS) attack, the accuracy of RF is 99%. Furthermore, other\nsimulation results-based precision, recall, F1 score, and log loss metric\nreveal that RF outperforms on all types of attacks in binary classification.\nHowever, in multi-class classification, KNN outperforms other ML algorithms\nwith an accuracy of 99%, which is 4% higher than RF.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jan 2021 11:48:37 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Churcher", "Andrew", ""], ["Ullah", "Rehmat", ""], ["Ahmad", "Jawad", ""], ["Rehman", "Sadaqat ur", ""], ["Masood", "Fawad", ""], ["Gogate", "Mandar", ""], ["Alqahtani", "Fehaid", ""], ["Nour", "Boubakr", ""], ["Buchanan", "William J.", ""]]}, {"id": "2101.12279", "submitter": "Dake Chen", "authors": "Dake Chen, Chunxiao Lin, Peter A. Beerel", "title": "GF-Flush: A GF(2) Algebraic Attack on Secure Scan Chains", "comments": "Submitted to IEEE Transactions on Computer-Aided Design of Integrated\n  Circuits And Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Scan chains provide increased controllability and observability for testing\ndigital circuits. The increased testability, however, can also be a source of\ninformation leakage for sensitive designs. The state-of-the-art defenses to\nsecure scan chains apply dynamic keys to pseudo-randomly invert the scan\nvectors. In this paper, we pinpoint an algebraic vulnerability of these dynamic\ndefenses that involves creating and solving a system of linear equations over\nthe finite field GF(2). In particular, we propose a novel GF(2)-based flush\nattack that breaks even the most rigorous version of state-of-the-art dynamic\ndefenses. Our experimental results demonstrate that our attack recovers the key\nas long as 500 bits in less than 7 seconds, the attack times are about one\nhundredth of state-of-the-art SAT based attacks on the same defenses. We then\ndemonstrate how our attacks can be extended to scan chains compressed with\nMultiple-Input Signature Registers (MISRs).\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 21:07:23 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Chen", "Dake", ""], ["Lin", "Chunxiao", ""], ["Beerel", "Peter A.", ""]]}, {"id": "2101.12332", "submitter": "Philipp Hoenisch", "authors": "Philipp Hoenisch and Lucas Soriano del Pino", "title": "Atomic Swaps between Bitcoin and Monero", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to the evergrowing blockchain ecosystem, interoperability has become a\nmatter of great importance. Atomic swaps allow connecting otherwise isolated\nblockchains while adhering to the core principles of censorship resistance and\npermissionlessnes. Up until recently, atomic swap protocols have mostly relied\non complex script support, excluding certain types of blockchains. With\nadvances in cryptography, it is now possible to build a bridge between almost\nany two blockchains. In this work, we give an explanation of one such protocol\nwhich applies adaptor signatures on Bitcoin to procure atomic swaps between\nMonero and Bitcoin. We dive into the cryptographic details, discuss its\nlimitations and give an outlook on our current work where we use adaptor\nsignatures on the Monero signature scheme.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 00:53:06 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 05:51:52 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Hoenisch", "Philipp", ""], ["del Pino", "Lucas Soriano", ""]]}, {"id": "2101.12412", "submitter": "Philipp Hoenisch", "authors": "Thomas Eizinger and Philipp Hoenisch and Lucas Soriano del Pino", "title": "Open problems in cross-chain protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blockchain interoperability is a prominent research field which aims to build\nbridges between otherwise isolated blockchains. With advances in cryptography,\nnovel protocols are published by academia and applied in different applications\nand products in the industry. In theory, these innovative protocols provide\nstrong privacy and security guarantees by including formal proofs. However,\npure theoretical work often lacks the perspective of real world applications.\nIn this work, we describe a number of hardly researched problems which\ndevelopers encounter when building cross-chain products.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 05:45:43 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Eizinger", "Thomas", ""], ["Hoenisch", "Philipp", ""], ["del Pino", "Lucas Soriano", ""]]}, {"id": "2101.12428", "submitter": "Cong Nguyen", "authors": "Cong T. Nguyen, Dinh Thai Hoang, Diep N. Nguyen, Yong Xiao, Hoang-Anh\n  Pham, Eryk Dutkiewicz and Nguyen Huynh Tuong", "title": "FedChain: Secure Proof-of-Stake-based Framework for Federated-blockchain\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose FedChain, a novel framework for\nfederated-blockchain systems, to enable effective transferring of tokens\nbetween different blockchain networks. Particularly, we first introduce a\nfederated-blockchain system together with a cross-chain transfer protocol to\nfacilitate the secure and decentralized transfer of tokens between chains. We\nthen develop a novel PoS-based consensus mechanism for FedChain, which can\nsatisfy strict security requirements, prevent various blockchain-specific\nattacks, and achieve a more desirable performance compared to those of other\nexisting consensus mechanisms. Moreover, a Stackelberg game model is developed\nto examine and address the problem of centralization in the FedChain system.\nFurthermore, the game model can enhance the security and performance of\nFedChain. By analyzing interactions between the stakeholders and chain\noperators, we can prove the uniqueness of the Stackelberg equilibrium and find\nthe exact formula for this equilibrium. These results are especially important\nfor the stakeholders to determine their best investment strategies and for the\nchain operators to design the optimal policy to maximize their benefits and\nsecurity protection for FedChain. Simulations results then clearly show that\nthe FedChain framework can help stakeholders to maximize their profits and the\nchain operators to design appropriate parameters to enhance FedChain's security\nand performance.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 06:45:50 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Nguyen", "Cong T.", ""], ["Hoang", "Dinh Thai", ""], ["Nguyen", "Diep N.", ""], ["Xiao", "Yong", ""], ["Pham", "Hoang-Anh", ""], ["Dutkiewicz", "Eryk", ""], ["Tuong", "Nguyen Huynh", ""]]}, {"id": "2101.12434", "submitter": "Muhammad Ejaz Ahmed", "authors": "Muhammad Ejaz Ahmed, Hyoungshick Kim, Seyit Camtepe, Surya Nepal", "title": "Peeler: Profiling Kernel-Level Events to Detect Ransomware", "comments": "15 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ransomware is a growing threat that typically operates by either encrypting a\nvictim's files or locking a victim's computer until the victim pays a ransom.\nHowever, it is still challenging to detect such malware timely with existing\ntraditional malware detection techniques. In this paper, we present a novel\nransomware detection system, called \"Peeler\" (Profiling kErnEl -Level Events to\ndetect Ransomware). Peeler deviates from signatures for individual ransomware\nsamples and relies on common and generic characteristics of ransomware depicted\nat the kernel-level. Analyzing diverse ransomware families, we observed\nransomware's inherent behavioral characteristics such as stealth operations\nperformed before the attack, file I/O request patterns, process spawning, and\ncorrelations among kernel-level events. Based on those characteristics, we\ndevelop Peeler that continuously monitors a target system's kernel events and\ndetects ransomware attacks on the system. Our experimental results show that\nPeeler achieves more than 99\\% detection rate with 0.58\\% false-positive rate\nagainst 43 distinct ransomware families, containing samples from both crypto\nand screen-locker types of ransomware. For crypto ransomware, Peeler detects\nthem promptly after only one file is lost (within 115 milliseconds on average).\nPeeler utilizes around 4.9\\% of CPU time with only 9.8 MB memory under the\nnormal workload condition. Our analysis demonstrates that Peeler can\nefficiently detect diverse malware families by monitoring their kernel-level\nevents.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 07:05:01 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Ahmed", "Muhammad Ejaz", ""], ["Kim", "Hyoungshick", ""], ["Camtepe", "Seyit", ""], ["Nepal", "Surya", ""]]}, {"id": "2101.12442", "submitter": "AbdelRahman Eldosouky", "authors": "Abdelrahman Eldosouky, Tapadhir Das, Anuraag Kotra, and Shamik\n  Sengupta", "title": "Finding the Sweet Spot for Data Anonymization: A Mechanism Design\n  Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data sharing between different organizations is an essential process in\ntoday's connected world. However, recently there were many concerns about data\nsharing as sharing sensitive information can jeopardize users' privacy. To\npreserve the privacy, organizations use anonymization techniques to conceal\nusers' sensitive data. However, these techniques are vulnerable to\nde-anonymization attacks which aim to identify individual records within a\ndataset. In this paper, a two-tier mathematical framework is proposed for\nanalyzing and mitigating the de-anonymization attacks, by studying the\ninteractions between sharing organizations, data collector, and a prospective\nattacker. In the first level, a game-theoretic model is proposed to enable\nsharing organizations to optimally select their anonymization levels for\nk-anonymization under two potential attacks: background-knowledge attack and\nhomogeneity attack. In the second level, a contract-theoretic model is proposed\nto enable the data collector to optimally reward the organizations for their\ndata. The formulated problems are studied under single-time sharing and\nrepeated sharing scenarios. Different Nash equilibria for the proposed game and\nthe optimal solution of the contract-based problem are analytically derived for\nboth scenarios. Simulation results show that the organizations can optimally\nselect their anonymization levels, while the data collector can benefit from\nincentivizing the organizations to share their data.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 07:31:09 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Eldosouky", "Abdelrahman", ""], ["Das", "Tapadhir", ""], ["Kotra", "Anuraag", ""], ["Sengupta", "Shamik", ""]]}, {"id": "2101.12602", "submitter": "Shun Zhang", "authors": "Zhang Shun, Duan Benfei, Chen Zhili, Zhong Hong", "title": "On the differential privacy of dynamic location obfuscation with\n  personalized error bounds", "comments": "5 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geo-indistinguishability and expected inference error are two complementary\nnotions for location privacy. The joint guarantee of differential privacy\n(indistinguishability) and distortion privacy (inference error) limits the\ninformation leakage. In this paper, we analyze the differential privacy of PIVE\ndynamic location obfuscation mechanism proposed by Yu, Liu and Pu (ISOC Network\nand Distributed System Security Symposium, 2017) and show that PIVE fails to\noffer differential privacy guarantees on adaptive protection location set as\nclaimed. Specifically, we demonstrate that different protection location sets\ncould intersect with one another due to the defined search algorithm and then\ndifferent locations in the same protection location set could have different\nprotection diameters. As a result, we can show that the proof of differential\nprivacy for PIVE is incorrect. We also make some detailed discussions on\nfeasible privacy frameworks with achieving personalized error bounds.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 14:31:18 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Shun", "Zhang", ""], ["Benfei", "Duan", ""], ["Zhili", "Chen", ""], ["Hong", "Zhong", ""]]}, {"id": "2101.12604", "submitter": "Anca Jurcut Dr.", "authors": "Jinyong Chen, Reiner Dojen and Anca Jurcut", "title": "Detection and Prevention of New Attacks for ID-based Authentication\n  Protocols", "comments": null, "journal-ref": "9th ACM International Conference on Networks, Communication and\n  Computing (ICNCC 2020)", "doi": "10.1145/3447654.3447666", "report-no": null, "categories": "cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The rapid development of information and network technologies motivates the\nemergence of various new computing paradigms, such as distributed computing,\nand edge computing. This also enables more and more network enterprises to\nprovide multiple different services simultaneously. To ensure these services\ncan conveniently be accessed only by authorized users, many password and smart\ncard-based authentication schemes for multi-server architecture have been\nproposed. In this paper, we review several dynamic ID-based password\nauthentication schemes for multi-server environments. New attacks against four\nof these schemes are presented, demonstrating that an adversary can impersonate\neither legitimate or fictitious users. The impact of these attacks is the\nfailure to achieve the main security requirement: authentication. Thus, the\nsecurity of the analyzed schemes is proven to be compromised. We analyze these\nfour dynamic ID-based schemes and discuss the reasons for the success of the\nnew attacks. Additionally, we propose a new set of design guidelines to prevent\nsuch exploitable weaknesses on dynamic ID-based authentication protocols.\nFinally, we apply the proposed guidelines to the analyzed protocols and\ndemonstrate that violation of these guidelines leads to insecure protocols.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 14:32:48 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Chen", "Jinyong", ""], ["Dojen", "Reiner", ""], ["Jurcut", "Anca", ""]]}, {"id": "2101.12620", "submitter": "Rafa{\\l} Graczyk", "authors": "Rafal Graczyk, Marcus Voelp, Paulo Esteves-Verissimo", "title": "EphemeriShield -- defence against cyber-antisatellite weapons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Satellites, are both crucial and, despite common misbelieve, very fragile\nparts our civilian and military critical infrastructure. While, many efforts\nare focused on securing ground and space segments, especially when national\nsecurity or large businesses interests are affected, the small-sat, newspace\nrevolution democratizes access to, and exploitation of the near earth orbits.\nThis brings new players to the market, typically in the form of small to medium\nsized companies, offering new or more affordable services. Despite the\nnecessity and inevitability of this process, it also opens potential new venues\nfor targeted attacks against space-related infrastructure. Since sources of\nsatellite ephemerides are very often centralized, they are subject to classical\nMan-in-the-Middle attacks which open venues for TLE spoofing attack, which may\nresult in unnecessary collision avoidance maneuvers, in best case and\norchestrated crashes, in worst case. In this work, we propose a countermeasure\nto the presented problem that include distributed solution, which will have no\ncentral authority responsible for storing and disseminating TLE information.\nInstead, each of the peers participating to the system, have full access to all\nof the records stored in the system, and distribute the data in a consensual\nmanner,ensuring information replication at each peer node. This way, single\npoint of failure syndromes of classic systems, which currently exist due to the\ndirect ephemerids distribution mechanism, are removed. Our proposed solution is\nto build data dissemination systems using permissioned, private ledgers where\npeers have strong and verifiable identities, which allow also for redundancy in\nSST data sourcing.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 15:02:15 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Graczyk", "Rafal", ""], ["Voelp", "Marcus", ""], ["Esteves-Verissimo", "Paulo", ""]]}, {"id": "2101.12723", "submitter": "Luis Felipe Casta\\~no Ledesma", "authors": "F. Casta\\~no, E. Fidalgo, E. Alegre, D. Chaves, M. Sanchez-Paniagua", "title": "State of the Art: Content-based and Hybrid Phishing Detection", "comments": "6 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Phishing attacks have evolved and increased over time and, for this reason,\nthe task of distinguishing between a legitimate site and a phishing site is\nmore and more difficult, fooling even the most expert users. The main proposals\nfocused on addressing this problem can be divided into four approaches:\nList-based, URL based, content-based, and hybrid. In this state of the art, the\nmost recent techniques using web content-based and hybrid approaches for\nPhishing Detection are reviewed and compared.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 18:34:59 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Casta\u00f1o", "F.", ""], ["Fidalgo", "E.", ""], ["Alegre", "E.", ""], ["Chaves", "D.", ""], ["Sanchez-Paniagua", "M.", ""]]}, {"id": "2101.12736", "submitter": "Osman Ramadan", "authors": "Osman Ramadan, James Withers, Douglas Orr", "title": "N-grams Bayesian Differential Privacy", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy has gained popularity in machine learning as a strong\nprivacy guarantee, in contrast to privacy mitigation techniques such as\nk-anonymity. However, applying differential privacy to n-gram counts\nsignificantly degrades the utility of derived language models due to their\nlarge vocabularies. We propose a differential privacy mechanism that uses\npublic data as a prior in a Bayesian setup to provide tighter bounds on the\nprivacy loss metric epsilon, and thus better privacy-utility trade-offs. It\nfirst transforms the counts to log space, approximating the distribution of the\npublic and private data as Gaussian. The posterior distribution is then\nevaluated and softmax is applied to produce a probability distribution. This\ntechnique achieves up to 85% reduction in KL divergence compared to previously\nknown mechanisms at epsilon equals 0.1. We compare our mechanism to k-anonymity\nin a n-gram language modelling task and show that it offers competitive\nperformance at large vocabulary sizes, while also providing superior privacy\nprotection.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 18:48:49 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Ramadan", "Osman", ""], ["Withers", "James", ""], ["Orr", "Douglas", ""]]}]