[{"id": "1707.01089", "submitter": "Ingo Weber", "authors": "Christopher Klinkm\\\"uler and Ingo Weber", "title": "Control Flow Information Analysis in Process Model Matching Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online Appendix to: \"Analyzing Control Flow Information to Improve the\nEffectiveness of Process Model Matching Techniques\" by the same authors.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 04:09:21 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Klinkm\u00fcler", "Christopher", ""], ["Weber", "Ingo", ""]]}, {"id": "1707.01865", "submitter": "Claudia Schulz", "authors": "Elias Marcopoulos, Christian Reotutar and Yuanlin Zhang", "title": "An Online Development Environment for Answer Set Programming", "comments": "Proceedings of the 2nd International Workshop on User-Oriented Logic\n  Paradigms(IULP 2017), Editors: Claudia Schulz and Stefan Ellmauthaler", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in logic programming (e.g., the development of the Answer Set\nProgramming paradigm) has made it possible to teach it to general undergraduate\nand even high school students. Given the limited exposure of these students to\ncomputer science, the complexity of downloading, installing and using tools for\nwriting logic programs could be a major barrier for logic programming to reach\na much wider audience. We developed an online answer set programming\nenvironment with a self contained file system and a simple interface, allowing\nusers to write logic programs and perform several tasks over the programs.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 10:01:24 GMT"}], "update_date": "2017-07-07", "authors_parsed": [["Marcopoulos", "Elias", ""], ["Reotutar", "Christian", ""], ["Zhang", "Yuanlin", ""]]}, {"id": "1707.01880", "submitter": "Maurizio Naldi", "authors": "Maurizio Naldi and Marta Flamini", "title": "Project Makespan Estimation: Computational Load of Interval and Point\n  Estimates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The estimation of project completion time is to be repeated several times in\nthe project planning phase to reach the optimal tradeoff between time, cost,\nand quality. Estimation procedures provide either an interval or a point\nestimate. The computational load of several estimation procedures is reviewed.\nA multiple polynomial regression model is provided for major interval\nestimation procedures and shows that the accuracy in the probability model for\nactivities is the most influential factor. The computational time does not\nappear to be an impeding factor, though it is larger for MonteCarlo simulation,\nso that the computational time can be traded off in search of a simpler\nestimation procedure.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jul 2017 17:36:33 GMT"}], "update_date": "2017-07-07", "authors_parsed": [["Naldi", "Maurizio", ""], ["Flamini", "Marta", ""]]}, {"id": "1707.02296", "submitter": "Siamak Sarjoghian", "authors": "Siamak Sarjoghian", "title": "Skin Temperature Measurement", "comments": "MSc Dissertation, London South Bank University", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report represents the design and implementation of a skin temperature\nmeasurement system. The system aims to measure the skin temperature from a\nsensor and send it to the PC using a USB cable to display on screen. The data\nneeds to be updated every second. The PIC18F4550 microcontroller has been used\nin this project to obtain data from the sensor and send it to the PC using USB\n2.0 that has been built into the microcontroller. The microcontroller has a\n10-bit Analog Digital Converting accuracy that is one of the important criteria\nfor this design as it is going to be used for medical purposes. As the project\nconcentrates more on designing software than hardware, the EasyPIC4 development\nboard was used which comes with all hardware required for this project. The\nJackson diagram method was used to design and implement the coding program for\nthe microcontroller software part of the system. The MikroC IDE has been used\nto compile and load the program into PIC18F4550 microcontroller. The program\nfor the microcontroller uses C language that aims to keep the USB link alive by\nusing interrupt function. A sensor collects data from sensor as 4 bits and send\nit to the PC every second using a USB cable. The data received from sensor,\nwill be sent by microcontroller to the PC. The Visual Basic software was used\nin the PC side of device to catch and output the data on the screen. A template\nfile for the Visual Basic program was generated by Easy HID wizard to make\nsoftware programming part easier for designer. The USBTrace analyzer has been\nused in the scenario any problems occur during or after the design and\nconstruction of the software. The software enables a user to monitor the data\non the USB bus that sends the data to the PC from microcontroller.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jul 2017 15:03:43 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Sarjoghian", "Siamak", ""]]}, {"id": "1707.02842", "submitter": "Na-Young Ahn", "authors": "Na-Young Ahn and Dong Hoon Lee", "title": "Duty to Delete on Non-Volatile Memory", "comments": "3 pages, 8 figures", "journal-ref": null, "doi": "10.8080/1020190046820", "report-no": "CPS-2017-0088", "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We firstly suggest new cache policy applying the duty to delete invalid cache\ndata on Non-volatile Memory (NVM). This cache policy includes generating random\ndata and overwriting the random data into invalid cache data. Proposed cache\npolicy is more economical and effective regarding perfect deletion of data. It\nis ensure that the invalid cache data in NVM is secure against malicious\nhackers.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jul 2017 15:44:11 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Ahn", "Na-Young", ""], ["Lee", "Dong Hoon", ""]]}, {"id": "1707.05259", "submitter": "Joel Colloc", "authors": "Jo\\\"el Colloc (IDEES)", "title": "Ethics of autonomous information systems towards an artificial thinking", "comments": "in French", "journal-ref": "Les Cahiers du num\\'erique, Lavoisier, Enjeux du big data et\n  identifications des donn\\'ees m\\'edicales, 12 (1-2), pp.187-211 (2016)", "doi": "10.3166/LCN.12.1-2.187-212", "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many projects relies on cognitives sciences, neurosciences, computer sciences\nand robotics. They concerned today the building of autonomous artificial beings\nable to think. This paper shows a model to compare the human thinking with an\nhypothetic numerical way of thinking based on four hierarchies : the\ninformation system classification, the cognitive pyramid, the linguistic\npyramid and the digital information hierarchy. After a state of art on the\nnature of human thinking, feasibility of autonomous multi-agent systems\nprovided with artificial consciousness which are able to think is discussed.\nThe ethical aspects and consequences for humanity of such systems is evaluated.\nThese systems lead the scientific community to react.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 11:44:09 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Colloc", "Jo\u00ebl", "", "IDEES"]]}, {"id": "1707.06257", "submitter": "Subhash Kak", "authors": "Subhash Kak", "title": "The Limits to Machine Consciousness", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is generally accepted that machines can replicate cognitive tasks\nperformed by conscious agents as long as they are not based on the capacity of\nawareness. We consider several views on the nature of subjective awareness,\nwhich is fundamental for self-reflection and review, and present reasons why\nthis property is not computable. We argue that consciousness is more than an\nepiphenomenon and assuming it to be a separate category is consistent with both\nquantum mechanics and cognitive science. We speak of two kinds of\nconsciousness, little-C and big-C, and discuss the significance of this\nclassification in analyzing the current academic debates in the field. The\ninteraction between the system and the measuring apparatus of the experimenter\nis examined both from the perspectives of decoherence and the quantum Zeno\neffect. These ideas are used as context to address the question of limits to\nmachine consciousness.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 21:35:35 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Kak", "Subhash", ""]]}, {"id": "1707.06289", "submitter": "Orianna DeMasi", "authors": "Orianna DeMasi, Konrad Kording and Benjamin Recht", "title": "Meaningless comparisons lead to false optimism in medical machine\n  learning", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0184604", "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new trend in medicine is the use of algorithms to analyze big datasets,\ne.g. using everything your phone measures about you for diagnostics or\nmonitoring. However, these algorithms are commonly compared against weak\nbaselines, which may contribute to excessive optimism. To assess how well an\nalgorithm works, scientists typically ask how well its output correlates with\nmedically assigned scores. Here we perform a meta-analysis to quantify how the\nliterature evaluates their algorithms for monitoring mental wellbeing. We find\nthat the bulk of the literature ($\\sim$77%) uses meaningless comparisons that\nignore patient baseline state. For example, having an algorithm that uses phone\ndata to diagnose mood disorders would be useful. However, it is possible to\nover 80% of the variance of some mood measures in the population by simply\nguessing that each patient has their own average mood - the patient-specific\nbaseline. Thus, an algorithm that just predicts that our mood is like it\nusually is can explain the majority of variance, but is, obviously, entirely\nuseless. Comparing to the wrong (population) baseline has a massive effect on\nthe perceived quality of algorithms and produces baseless optimism in the\nfield. To solve this problem we propose \"user lift\" that reduces these\nsystematic errors in the evaluation of personalized medical monitoring.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 20:39:51 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["DeMasi", "Orianna", ""], ["Kording", "Konrad", ""], ["Recht", "Benjamin", ""]]}, {"id": "1707.09280", "submitter": "Jingjie Ding", "authors": "Jingjie Ding, Tong Ye, Tony T. Lee and Weisheng Hu", "title": "Modular AWG-based Optical Shuffle Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an arrayed-waveguide grating (AWG) based\nwavelength-division-multiplexing (WDM) shuffle network. Compared with previous\noptical shuffle networks, our proposal is compact, easy to implement, highly\nscalable, and cost effective.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 10:31:09 GMT"}], "update_date": "2017-07-31", "authors_parsed": [["Ding", "Jingjie", ""], ["Ye", "Tong", ""], ["Lee", "Tony T.", ""], ["Hu", "Weisheng", ""]]}, {"id": "1707.09320", "submitter": "Dingwen Tao", "authors": "Dingwen Tao, Sheng Di, Hanqi Guo, Zizhong Chen, Franck Cappello", "title": "Z-checker: A Framework for Assessing Lossy Compression of Scientific\n  Data", "comments": "Accepted by The International Journal of High Performance Computing\n  Application", "journal-ref": null, "doi": "10.1177/1094342017737147", "report-no": null, "categories": "cs.OH astro-ph.IM cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because of vast volume of data being produced by today's scientific\nsimulations and experiments, lossy data compressor allowing user-controlled\nloss of accuracy during the compression is a relevant solution for\nsignificantly reducing the data size. However, lossy compressor developers and\nusers are missing a tool to explore the features of scientific datasets and\nunderstand the data alteration after compression in a systematic and reliable\nway. To address this gap, we have designed and implemented a generic framework\ncalled Z-checker. On the one hand, Z-checker combines a battery of data\nanalysis components for data compression. On the other hand, Z-checker is\nimplemented as an open-source community tool to which users and developers can\ncontribute and add new analysis components based on their additional analysis\ndemands. In this paper, we present a survey of existing lossy compressors. Then\nwe describe the design framework of Z-checker, in which we integrated\nevaluation metrics proposed in prior work as well as other analysis tools.\nSpecifically, for lossy compressor developers, Z-checker can be used to\ncharacterize critical properties of any dataset to improve compression\nstrategies. For lossy compression users, Z-checker can detect the compression\nquality, provide various global distortion analysis comparing the original data\nwith the decompressed data and statistical analysis of the compression error.\nZ-checker can perform the analysis with either coarse granularity or fine\ngranularity, such that the users and developers can select the best-fit,\nadaptive compressors for different parts of the dataset. Z-checker features a\nvisualization interface displaying all analysis results in addition to some\nbasic views of the datasets such as time series. To the best of our knowledge,\nZ-checker is the first tool designed to assess lossy compression\ncomprehensively for scientific datasets.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 18:09:33 GMT"}, {"version": "v2", "created": "Fri, 10 Nov 2017 20:16:10 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Tao", "Dingwen", ""], ["Di", "Sheng", ""], ["Guo", "Hanqi", ""], ["Chen", "Zizhong", ""], ["Cappello", "Franck", ""]]}]