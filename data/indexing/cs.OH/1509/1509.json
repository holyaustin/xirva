[{"id": "1509.00025", "submitter": "Markus Vogt", "authors": "Markus Vogt, Gerald Hempel, Jeronimo Castrillon, Christian Hochberger", "title": "GCC-Plugin for Automated Accelerator Generation and Integration on\n  Hybrid FPGA-SoCs", "comments": "Presented at Second International Workshop on FPGAs for Software\n  Programmers (FSP 2015) (arXiv:1508.06320)", "journal-ref": null, "doi": null, "report-no": "FSP/2015/17", "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, architectures combining a reconfigurable fabric and a\ngeneral purpose processor on a single chip became increasingly popular. Such\nhybrid architectures allow extending embedded software with application\nspecific hardware accelerators to improve performance and/or energy efficiency.\nAiding system designers and programmers at handling the complexity of the\nrequired process of hardware/software (HW/SW) partitioning is an important\nissue. Current methods are often restricted, either to bare-metal systems, to\nsubsets of mainstream programming languages, or require special coding\nguidelines, e.g., via annotations. These restrictions still represent a high\nentry barrier for the wider community of programmers that new hybrid\narchitectures are intended for. In this paper we revisit HW/SW partitioning and\npresent a seamless programming flow for unrestricted, legacy C code. It\nconsists of a retargetable GCC plugin that automatically identifies code\nsections for hardware acceleration and generates code accordingly. The proposed\nworkflow was evaluated on the Xilinx Zynq platform using unmodified code from\nan embedded benchmark suite.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2015 09:15:49 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2015 11:35:57 GMT"}], "update_date": "2015-09-24", "authors_parsed": [["Vogt", "Markus", ""], ["Hempel", "Gerald", ""], ["Castrillon", "Jeronimo", ""], ["Hochberger", "Christian", ""]]}, {"id": "1509.00036", "submitter": "Shaodong Qin", "authors": "Shaodong Qin, Mladen Berekovic", "title": "A Comparison of High-Level Design Tools for SoC-FPGA on Disparity Map\n  Calculation Example", "comments": "Presented at Second International Workshop on FPGAs for Software\n  Programmers (FSP 2015) (arXiv:1508.06320)", "journal-ref": null, "doi": null, "report-no": "FSP/2015/15", "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern SoC-FPGA that consists of FPGA with embedded ARM cores is being\npopularized as an embedded vision system platform. However, the design approach\nof SoC-FPGA applications still follows traditional hardware-software separate\nworkflow, which becomes the barrier of rapid product design and iteration on\nSoC-FPGA. High-Level Synthesis (HLS) and OpenCL-based system-level design\napproaches provide programmers the possibility to design SoC-FGPA at\nsystem-level with an unified development environment for both hardware and\nsoftware. To evaluate the feasibility of high-level design approach especially\nfor embedded vision applications, Vivado HLS and Altera SDK for OpenCL,\nrepresentative and most popular commercial tools in market, are selected as\nevaluation design tools, disparity map calculation as targeting application. In\nthis paper, hardware accelerators of disparity map calculation are designed\nwith both tools and implemented on Zedboard and SoCKit development board,\nrespectively. Comparisons between design tools are made in aspects of\nsupporting directives, accelerator design process, and generated hardware\nperformance. The results show that both tools can generate efficient hardware\nfor disparity map calculation application with much less developing time.\nMoreover, we can also state that, more directives (e.g., interface type, array\nreshape, resource type specification) are supported, but more hardware\nknowledge is required, in Vivado HLS. In contrast, Altera SDK for OpenCL is\nrelatively easier for software programmers who is new to hardware, but with the\nprice of more resources usage on FPGA for similar hardware accelerator\ngeneration.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2015 08:59:11 GMT"}], "update_date": "2015-09-02", "authors_parsed": [["Qin", "Shaodong", ""], ["Berekovic", "Mladen", ""]]}, {"id": "1509.00238", "submitter": "Vladimir Savic Dr", "authors": "Vladimir Savic and Henk Wymeersch and Erik G. Larsson", "title": "Target Tracking in Confined Environments with Uncertain Sensor Positions", "comments": "IEEE Transactions on Vehicular Technology, 2015", "journal-ref": null, "doi": "10.1109/TVT.2015.2404132", "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To ensure safety in confined environments such as mines or subway tunnels, a\n(wireless) sensor network can be deployed to monitor various environmental\nconditions. One of its most important applications is to track personnel,\nmobile equipment and vehicles. However, the state-of-the-art algorithms assume\nthat the positions of the sensors are perfectly known, which is not necessarily\ntrue due to imprecise placement and/or dropping of sensors. Therefore, we\npropose an automatic approach for simultaneous refinement of sensors' positions\nand target tracking. We divide the considered area in a finite number of cells,\ndefine dynamic and measurement models, and apply a discrete variant of belief\npropagation which can efficiently solve this high-dimensional problem, and\nhandle all non-Gaussian uncertainties expected in this kind of environments.\nFinally, we use ray-tracing simulation to generate an artificial mine-like\nenvironment and generate synthetic measurement data. According to our extensive\nsimulation study, the proposed approach performs significantly better than\nstandard Bayesian target tracking and localization algorithms, and provides\nrobustness against outliers.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2015 11:45:56 GMT"}], "update_date": "2015-09-02", "authors_parsed": [["Savic", "Vladimir", ""], ["Wymeersch", "Henk", ""], ["Larsson", "Erik G.", ""]]}, {"id": "1509.00818", "submitter": "Michael Bannister", "authors": "Michael J. Bannister and David A. Brown and David Eppstein", "title": "Confluent Orthogonal Drawings of Syntax Diagrams", "comments": "GD 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a pipeline for generating syntax diagrams (also called railroad\ndiagrams) from context free grammars. Syntax diagrams are a graphical\nrepresentation of a context free language, which we formalize abstractly as a\nset of mutually recursive nondeterministic finite automata and draw by\ncombining elements from the confluent drawing, layered drawing, and smooth\northogonal drawing styles. Within our pipeline we introduce several heuristics\nthat modify the grammar but preserve the language, improving the aesthetics of\nthe final drawing.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2015 18:54:49 GMT"}], "update_date": "2015-09-03", "authors_parsed": [["Bannister", "Michael J.", ""], ["Brown", "David A.", ""], ["Eppstein", "David", ""]]}, {"id": "1509.03781", "submitter": "Waldemar Koczkodaj Prof.", "authors": "W.W. Koczkodaj and J.-P. Magnot", "title": "Axiomatization of Inconsistency Indicators for Pairwise Comparisons", "comments": "23 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes revised axioms for defining inconsistency indicators in\npairwise comparisons. It is based on the new findings that \"PC submatrix cannot\nhave a worse inconsistency indicator than the PC matrix containing it\" and that\nthere must be a PC submatrix with the same inconsistency as the given PC\nmatrix.\n  This study also provides better reasoning for the need of normalization. It\nis a revision of axiomatization by Koczkodaj and Szwarc, 2014 which proposed\naxioms expressed informally with some deficiencies addressed in this study.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2015 21:57:17 GMT"}, {"version": "v2", "created": "Wed, 15 Mar 2017 16:09:03 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Koczkodaj", "W. W.", ""], ["Magnot", "J. -P.", ""]]}, {"id": "1509.04738", "submitter": "Harry Boyer", "authors": "H. Boyer (PIMENT), S. Guichard (PIMENT), A. Jean (PIMENT), T. Libelle\n  (PIMENT), Dimitri Bigot (PIMENT), F. Miranville (PIMENT), M. Boji\\'c", "title": "Validation of daylighting model in CODYRUN building simulation code", "comments": "ICRET 2014 : 2014 International Conference on Renewable Energy\n  Technologies, Nov 2014, Hong Kong, China. 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CODYRUN is a multi-zone software integrating thermal building simulation,\nairflow, and pollutant transfer. A first question thus arose as to the\nintegration of indoor lighting conditions into the simulation, leading to a new\nmodel calculating natural and artificial lighting. The results of this new\ndaylighting module were then compared with results of other simulation codes\nand experimental cases both in artificial and natural environments. Excellent\nagreements were obtained, such as the values for luminous efficiencies in a\ntropical and humid climate. In this paper, a comparison of the model output\nwith detailed measures is presented using a dedicated test cell in Reunion\nIsland (French overseas territory in the Indian Ocean), thus confirming the\ninterest for thermal and daylighting designs in low-energy buildings.\nIntroduction Several software packages are available for thermal and airflow\nsimulation in buildings. The most frequently used are ENERGY+ [1], ESP-r [2],\nand TRNSYS [3]. These applications allow an increasing number of models to be\nintegrated, such as airflow, pollutant transport, and daylighting. In the\nlatter category, we may note ENERGY+, ESP-r and ECOTECT [4] software. After\nmore than 20 years of developing a specific code named CODYRUN, we decided to\nadd a lighting module to our software. This paper therefore provides some\ndetails on this evolution and elements of validation. The CODYRUN initial\nsoftware and its validation Developed by the Physics and Mathematical\nEngineering Laboratory for Energy and Environment at the University of Reunion\nIsland, CODYRUN [5-14] is a multi-zone software program integrating ventilation\nand moisture transport transfer in buildings. The software employs a zone\napproach based on nodal analysis and resolves a coupled system describing\nthermal and airflow phenomena. Numerous validation tests of the CODYRUN code\nwere successfully applied to the software. Apart from the daylighting model,\nthe majority applied the BESTEST procedure [15]. The International Energy\nAgency (IEA) sponsors a number of programs to improve the use and associated\ntechnologies of energy. The National Renewable Energy Laboratory (NREL)\ndeveloped BESTEST, which is a method based on comparative testing of building\nsimulation programs, on the IEA's behalf. The procedure consists of a series of\ntest cases buildings that are designed to isolate individual aspects of\nbuilding energy and test the extremes of a program. As the modelling approach\nis very different between codes, the test cases are specified so that input\nequivalency can be defined thus allowing the different cases to be modelled by\nmost of codes. The basis for comparison is a range of results from a number of\nprograms considered to be a state-of-art in United States and Europe.\nAssociated with other specific comparisons, a very confident level of\nvalidation was obtained for the CODYRUN initial software [8].\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2015 06:57:18 GMT"}], "update_date": "2015-09-17", "authors_parsed": [["Boyer", "H.", "", "PIMENT"], ["Guichard", "S.", "", "PIMENT"], ["Jean", "A.", "", "PIMENT"], ["Libelle", "T.", "", "PIMENT"], ["Bigot", "Dimitri", "", "PIMENT"], ["Miranville", "F.", "", "PIMENT"], ["Boji\u0107", "M.", ""]]}, {"id": "1509.05022", "submitter": "Elizaveta Kondrashova V", "authors": "Elizaveta V. Kondrashova", "title": "Problem of optimization of a transport traffic at preliminary\n  registration of queires with use of CBSMAP-model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of optimization of a transport traffic at preliminary\nregistration of demands with use of the CBSMAP model is investigated. For the\nsolution of an objective application of the queueing theory and the theory of\ncontrolled processes is supposed.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2015 06:17:24 GMT"}], "update_date": "2015-09-17", "authors_parsed": [["Kondrashova", "Elizaveta V.", ""]]}, {"id": "1509.05192", "submitter": "Bo Wang", "authors": "Bo Wang, Kezhi Li, Zhongjian Chen, Xinan Wang", "title": "A balanced rail-to-rail all digital comparator using only standard cells", "comments": "This paper has been withdrawn by the author due to the imperfection\n  of the circuit, i.e., the long reset time of hundreds ns to several us", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An all-digital comparator with full input range is presented. It outperforms\nthe nowaday all-digital comparators with its large rail-to-rail input range.\nThis is achieved by the proposed Yin-yang balance mechanism between the two\nlogic gates: NAND3 and OAI (Or-And-Invert). The important design considerations\nto achieve this balance are presented, such as the driving strength\nmanipulation and the use of pre-distortion technique. Constructed only by\ncommercially available digital standard cells, the layout of the proposed\ncomparator is generated automatically by standard digital Place & Route routine\nwithin several minutes. The Verilog code for the proposed circuit is given, and\nthe circuit is successfully implemented in 130nm CMOS technology with the power\nconsumption of 0.176mW at the clock of 330MHz.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2015 10:11:02 GMT"}, {"version": "v2", "created": "Tue, 10 May 2016 04:09:32 GMT"}], "update_date": "2016-05-11", "authors_parsed": [["Wang", "Bo", ""], ["Li", "Kezhi", ""], ["Chen", "Zhongjian", ""], ["Wang", "Xinan", ""]]}, {"id": "1509.07757", "submitter": "Soham Das", "authors": "Soham Das, Kishaloy Halder, Sanjoy Pratihar and Partha Bhowmick", "title": "Properties of Farey Sequence and their Applications to Digital Image\n  Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Farey sequence has been a topic of interest to the mathematicians since the\nvery beginning of last century. With the emergence of various algorithms\ninvolving the digital plane in recent times, several interesting works related\nwith the Farey sequence have come up. Our work is related with the problem of\nsearching an arbitrary fraction in a Farey sequence and its relevance to image\nprocessing. Given an arbitrary fraction p/q (0 < p < q) and a Farey sequence Fn\nof order n, we propose a novel algorithm using the Regula Falsi method and the\nconcept of Farey table to efficiently find the fraction of Fn closest to p/q.\nAll computations are in the integer domain only, which is its added benefit.\nSome contemporary applications of image processing have also been shown where\nsuch concepts can be incorporated. Experimental results have been furnished to\ndemonstrate its efficiency and elegance.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2015 15:36:00 GMT"}], "update_date": "2015-09-28", "authors_parsed": [["Das", "Soham", ""], ["Halder", "Kishaloy", ""], ["Pratihar", "Sanjoy", ""], ["Bhowmick", "Partha", ""]]}, {"id": "1509.08806", "submitter": "Zoha Pajouhi", "authors": "Zoha Pajouhi, Xuanyao Fong, Anand Raghunathan and Kaushik Roy", "title": "Yield, Area and Energy Optimization in Stt-MRAMs using failure aware ECC", "comments": "This paper will be published in ACM JETC journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spin Transfer Torque MRAMs are attractive due to their non-volatility, high\ndensity and zero leakage. However, STT-MRAMs suffer from poor reliability due\nto shared read and write paths. Additionally, conflicting requirements for data\nretention and write-ability (both related to the energy barrier height of the\nmagnet) makes design more challenging. Furthermore, the energy barrier height\ndepends on the physical dimensions of the free layer. Any variations in the\ndimensions of the free layer lead to variations in the energy barrier height.\nIn order to address poor reliability of STT-MRAMs, usage of Error Correcting\nCodes (ECC) have been proposed. Unlike traditional CMOS memory technologies,\nECC is expected to correct both soft and hard errors in STT_MRAMs. To achieve\nacceptable yield with low write power, stronger ECC is required, resulting in\nincreased number of encoded bits and degraded memory efficiency. In this paper,\nwe propose Failure aware ECC (FaECC), which masks permanent faults while\nmaintaining the same correction capability for soft errors without increased\nencoded bits. Furthermore, we investigate the impact of process variations on\nrun-time reliability of STT-MRAMs. We provide an analysis on the impact of\nprocess variations on the life-time of the free layer and retention failures.\nIn order to analyze the effectiveness of our methodology, we developed a\ncross-layer simulation framework that consists of device, circuit and array\nlevel analysis of STT-MRAM memory arrays. Our results show that using FaECC\nrelaxes the requirements on the energy barrier height, which reduces the write\nenergy and results in smaller access transistor size and memory array area.\nKeywords: STT-MRAM, reliability, Error Correcting Codes, ECC, magnetic memory\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2015 17:50:42 GMT"}, {"version": "v2", "created": "Thu, 16 Jun 2016 23:41:04 GMT"}], "update_date": "2016-06-20", "authors_parsed": [["Pajouhi", "Zoha", ""], ["Fong", "Xuanyao", ""], ["Raghunathan", "Anand", ""], ["Roy", "Kaushik", ""]]}, {"id": "1509.09174", "submitter": "Nuno Fachada", "authors": "Nuno Fachada, Vitor V. Lopes, Rui C. Martins, Agostinho C. Rosa", "title": "Model-independent comparison of simulation output", "comments": "The peer-reviewed version of this paper is published in Simulation\n  Modelling Practice and Theory at\n  http://dx.doi.org/10.1016/j.simpat.2016.12.013 . This version is typeset by\n  the authors and differs only in pagination and typographical detail", "journal-ref": "Simulation Modelling Practice and Theory, 72C, pp. 131-149, 2017", "doi": "10.1016/j.simpat.2016.12.013", "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational models of complex systems are usually elaborate and sensitive\nto implementation details, characteristics which often affect their\nverification and validation. Model replication is a possible solution to this\nissue. It avoids biases associated with the language or toolkit used to develop\nthe original model, not only promoting its verification and validation, but\nalso fostering the credibility of the underlying conceptual model. However,\ndifferent model implementations must be compared to assess their equivalence.\nThe problem is, given two or more implementations of a stochastic model, how to\nprove that they display similar behavior? In this paper, we present a model\ncomparison technique, which uses principal component analysis to convert\nsimulation output into a set of linearly uncorrelated statistical measures,\nanalyzable in a consistent, model-independent fashion. It is appropriate for\nascertaining distributional equivalence of a model replication with its\noriginal implementation. Besides model-independence, this technique has three\nother desirable properties: a) it automatically selects output features that\nbest explain implementation differences; b) it does not depend on the\ndistributional properties of simulation output; and, c) it simplifies the\nmodelers' work, as it can be used directly on simulation outputs. The proposed\ntechnique is shown to produce similar results to the manual or empirical\nselection of output features when applied to a well-studied reference model.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2015 13:48:38 GMT"}, {"version": "v2", "created": "Wed, 23 Mar 2016 11:40:43 GMT"}, {"version": "v3", "created": "Tue, 15 Nov 2016 19:05:59 GMT"}, {"version": "v4", "created": "Fri, 6 Jan 2017 12:33:05 GMT"}], "update_date": "2017-01-09", "authors_parsed": [["Fachada", "Nuno", ""], ["Lopes", "Vitor V.", ""], ["Martins", "Rui C.", ""], ["Rosa", "Agostinho C.", ""]]}]