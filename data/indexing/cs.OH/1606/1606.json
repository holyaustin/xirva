[{"id": "1606.00864", "submitter": "Kenth Eng{\\o}-Monsen Dr.", "authors": "Caroline O. Buckee and Kenth Eng{\\o}-Monsen", "title": "Mobile phone data for public health: towards data-sharing solutions that\n  protect individual privacy and national security", "comments": null, "journal-ref": null, "doi": null, "report-no": "Telenor R 2 / 2016", "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We outline the constraints faced by operators when deciding to share\nde-identified data with researchers or policy makers. We describe a\nconservative approach that we have taken to harness the value of CDRs for\ninfectious disease epidemiology while ensuring that identification of\nindividuals is impossible. We believe this approach serves as a useful and\nhighly conservative model for productive partnerships between mobile operators,\nresearchers, and public health practitioners.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2016 20:38:32 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Buckee", "Caroline O.", ""], ["Eng\u00f8-Monsen", "Kenth", ""]]}, {"id": "1606.00981", "submitter": "Enmei Tu", "authors": "Enmei Tu, Guanghao Zhang, Lily Rachmawati, Eshan Rajabally and\n  Guang-Bin Huang", "title": "Exploiting AIS Data for Intelligent Maritime Navigation: A Comprehensive\n  Survey", "comments": "24 pages, 7 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Automatic Identification System (AIS) tracks vessel movement by means of\nelectronic exchange of navigation data between vessels, with onboard\ntransceiver, terrestrial and/or satellite base stations. The gathered data\ncontains a wealth of information useful for maritime safety, security and\nefficiency. This paper surveys AIS data sources and relevant aspects of\nnavigation in which such data is or could be exploited for safety of seafaring,\nnamely traffic anomaly detection, route estimation, collision prediction and\npath planning.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 06:46:31 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Tu", "Enmei", ""], ["Zhang", "Guanghao", ""], ["Rachmawati", "Lily", ""], ["Rajabally", "Eshan", ""], ["Huang", "Guang-Bin", ""]]}, {"id": "1606.01177", "submitter": "Jos Vermaseren A", "authors": "John C. Collins and J.A.M. Vermaseren", "title": "Axodraw Version 2", "comments": "Files can be found at\n  www.nikhef.nl/~form/maindir/others/axodraw2/axodraw2.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH hep-ph hep-th", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present version two of the Latex graphical style file Axodraw. It has a\nnumber of new drawing primitives and many extra options, and it can now work\nwith \\program{pdflatex} to directly produce output in PDF file format (but with\nthe aid of an auxiliary program).\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2016 14:28:38 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Collins", "John C.", ""], ["Vermaseren", "J. A. M.", ""]]}, {"id": "1606.01419", "submitter": "Onur Ugurlu", "authors": "Deniz Tanir, Onur Ugurlu, Asli Guler, and Urfat Nuriyev", "title": "One-dimensional Cutting Stock Problem with Divisible Items", "comments": "12 pages, 2 figures", "journal-ref": "TWMS Journal of Applied and Engineering Mathematics, 9(3), (2019).\n  473-484", "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the one-dimensional cutting stock problem with divisible\nitems, which is a new problem in the cutting stock literature. The problem\nexists in steel industries. In the new problem, each item can be divided into\nsmaller pieces, then they can be recombined again by welding. The objective is\nto minimize both the trim loss and the number of the welds. We present a\nmathematical model and a dynamic programming based heuristic for the problem.\nFurthermore, a software, which is based on the proposed heuristic algorithm, is\ndeveloped to use in MKA company, and its performance is analyzed by solving\nreal-life problems in the steel industry. The computational experiments show\nthe efficiency of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jun 2016 22:01:25 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Tanir", "Deniz", ""], ["Ugurlu", "Onur", ""], ["Guler", "Asli", ""], ["Nuriyev", "Urfat", ""]]}, {"id": "1606.01431", "submitter": "Quang V Nguyen", "authors": "Quang V Nguyen, Mary Tate, Philip Calvert and Benoit Aubert", "title": "Leveraging ERP Implementation to Create Intellectual Capital: the Role\n  of Organizational Learning Capability", "comments": "ISBN# 978-0-646-95337-3 Presented at the Australasian Conference on\n  Information Systems 2015 (arXiv:1605.01032)", "journal-ref": null, "doi": null, "report-no": "ACIS/2015/131", "categories": "cs.OH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The extent to which enterprise resource planning (ERP) systems deliver value\nfor organizations has been debated. In this study, we argue that the presence\nof appropriate organizational resources is essential for capturing the\npotential of ERP implementation. We investigate the relationship between ERP\nimplementation and two organizational resources, specifically, Intellectual\nCapital (IC) and Organizational Learning Capability (OLC) to enrich the\nunderstanding of the way the value of ERP implementations can be realized. A\nsample of 226 manufacturing firms in Vietnam was surveyed to test the\ntheoretical model. Structural equation modelling with partial least square\nmethod and two approaches for moderation analysis were used to analyze the\ndata. The results indicate that ERP implementation scope has a positive impact\non intellectual capital (IC). However, firms need to build a certain level of\nOLC to utilize ERP implementation for the enhancement of IC.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jun 2016 23:12:17 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Nguyen", "Quang V", ""], ["Tate", "Mary", ""], ["Calvert", "Philip", ""], ["Aubert", "Benoit", ""]]}, {"id": "1606.01810", "submitter": "Santiago Hern\\'andez Orozco", "authors": "Santiago Hern\\'andez-Orozco, Francisco Hern\\'andez-Quiroz and Hector\n  Zenil", "title": "Undecidability and Irreducibility Conditions for Open-Ended Evolution\n  and Emergence", "comments": "Reduced version of this article was submitted and accepted for oral\n  presentation at ALife XV (July 4-8, 2016, Cancun, Mexico)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Is undecidability a requirement for open-ended evolution (OEE)? Using methods\nderived from algorithmic complexity theory, we propose robust computational\ndefinitions of open-ended evolution and the adaptability of computable\ndynamical systems. Within this framework, we show that decidability imposes\nabsolute limits to the stable growth of complexity in computable dynamical\nsystems. Conversely, systems that exhibit (strong) open-ended evolution must be\nundecidable, establishing undecidability as a requirement for such systems.\nComplexity is assessed in terms of three measures: sophistication, coarse\nsophistication and busy beaver logical depth. These three complexity measures\nassign low complexity values to random (incompressible) objects. As time grows,\nthe stated complexity measures allow for the existence of complex states during\nthe evolution of a computable dynamical system. We show, however, that finding\nthese states involves undecidable computations. We conjecture that for similar\ncomplexity measures that assign low complexity values, decidability imposes\ncomparable limits to the stable growth of complexity, and that such behaviour\nis necessary for non-trivial evolutionary systems. We show that the\nundecidability of adapted states imposes novel and unpredictable behaviour on\nthe individuals or populations being modelled. Such behaviour is irreducible.\nFinally, we offer an example of a system, first proposed by Chaitin, that\nexhibits strong OEE.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2016 16:19:13 GMT"}, {"version": "v2", "created": "Tue, 7 Jun 2016 06:02:06 GMT"}, {"version": "v3", "created": "Sat, 19 Nov 2016 20:42:52 GMT"}, {"version": "v4", "created": "Tue, 27 Dec 2016 20:01:37 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Hern\u00e1ndez-Orozco", "Santiago", ""], ["Hern\u00e1ndez-Quiroz", "Francisco", ""], ["Zenil", "Hector", ""]]}, {"id": "1606.02017", "submitter": "EPTCS", "authors": "Eerke A. Boiten (University of Kent)", "title": "Big Data Refinement", "comments": "In Proceedings Refine'15, arXiv:1606.01344", "journal-ref": "EPTCS 209, 2016, pp. 17-23", "doi": "10.4204/EPTCS.209.2", "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Big data\" has become a major area of research and associated funding, as\nwell as a focus of utopian thinking. In the still growing research community,\none of the favourite optimistic analogies for data processing is that of the\noil refinery, extracting the essence out of the raw data. Pessimists look for\ntheir imagery to the other end of the petrol cycle, and talk about the \"data\nexhausts\" of our society.\n  Obviously, the refinement community knows how to do \"refining\". This paper\nexplores the extent to which notions of refinement and data in the formal\nmethods community relate to the core concepts in \"big data\". In particular, can\nthe data refinement paradigm can be used to explain aspects of big data\nprocessing?\n", "versions": [{"version": "v1", "created": "Tue, 7 Jun 2016 04:09:00 GMT"}], "update_date": "2016-06-08", "authors_parsed": [["Boiten", "Eerke A.", "", "University of Kent"]]}, {"id": "1606.02042", "submitter": "Lee Prangnell", "authors": "Lee Prangnell and Victor Sanchez", "title": "Adaptive Quantization Matrices for HD and UHD Display Resolutions in\n  Scalable HEVC", "comments": "Data Compression Conference 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  HEVC contains an option to enable custom quantization matrices, which are\ndesigned based on the Human Visual System and a 2D Contrast Sensitivity\nFunction. Visual Display Units, capable of displaying video data at High\nDefinition and Ultra HD display resolutions, are frequently utilized on a\nglobal scale. Video compression artifacts that are present due to high levels\nof quantization, which are typically inconspicuous in low display resolution\nenvironments, are clearly visible on HD and UHD video data and VDUs. The\ndefault QM technique in HEVC does not take into account the video data\nresolution, nor does it take into consideration the associated display\nresolution of a VDU to determine the appropriate levels of quantization\nrequired to reduce unwanted video compression artifacts. Based on this fact, we\npropose a novel, adaptive quantization matrix technique for the HEVC standard,\nincluding Scalable HEVC. Our technique, which is based on a refinement of the\ncurrent HVS-CSF QM approach in HEVC, takes into consideration the display\nresolution of the target VDU for the purpose of minimizing video compression\nartifacts. In SHVC SHM 9.0, and compared with anchors, the proposed technique\nyields important quality and coding improvements for the Random Access\nconfiguration, with a maximum of 56.5% luma BD-Rate reductions in the\nenhancement layer. Furthermore, compared with the default QMs and the Sony QMs,\nour method yields encoding time reductions of 0.75% and 1.19%, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jun 2016 07:13:59 GMT"}, {"version": "v2", "created": "Sun, 12 Jun 2016 10:45:56 GMT"}], "update_date": "2016-06-14", "authors_parsed": [["Prangnell", "Lee", ""], ["Sanchez", "Victor", ""]]}, {"id": "1606.04876", "submitter": "Christos Papadimitriou", "authors": "Christos H. Papadimitriou", "title": "On the optimality of grid cells", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grid cells, discovered more than a decade ago [5], are neurons in the brain\nof mammals that fire when the animal is located near certain specific points in\nits familiar terrain. Intriguingly, these points form, for a single cell, a\ntwo-dimensional triangular grid, not unlike our Figure 3. Grid cells are widely\nbelieved to be involved in path integration, that is, the maintenance of a\nlocation state through the summation of small displacements. We provide\ntheoretical evidence for this assertion by showing that cells with grid-like\ntuning curves are indeed well adapted for the path integration task. In\nparticular we prove that, in one dimension under Gaussian noise, the\nsensitivity of measuring small displacements is maximized by a population of\nneurons whose tuning curves are near-sinusoids -- that is to say, with peaks\nforming a one-dimensional grid. We also show that effective computation of the\ndisplacement is possible through a second population of cells whose sinusoid\ntuning curves are in phase difference from the first. In two dimensions, under\nadditional assumptions it can be shown that measurement sensitivity is\noptimized by the product of two sinusoids, again yielding a grid-like pattern.\nWe discuss the connection of our results to the triangular grid pattern\nobserved in animals.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2016 17:36:44 GMT"}], "update_date": "2016-06-16", "authors_parsed": [["Papadimitriou", "Christos H.", ""]]}, {"id": "1606.05666", "submitter": "Mohammad Arif Hossain", "authors": "Trang Nguyen, Mohammad Arif Hossain, and Yeong Min Jang", "title": "Design and Implementation of a Novel Compatible Encoding Scheme in the\n  Time Domain for Image Sensor Communication", "comments": "24 pages, 15 figures, 5 tables, Sensors Journal", "journal-ref": null, "doi": "10.3390/s16050736", "report-no": null, "categories": "cs.OH cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a modulation scheme in the time domain based on\nOn-Off-Keying and proposes various compatible supports for different types of\nimage sensors. The content of this article is a sub-proposal to the IEEE\n802.15.7r1 Task Group (TG7r1) aimed at Optical Wireless Communication (OWC)\nusing an image sensor as the receiver. The compatibility support is\nindispensable for Image Sensor Communications (ISC) because the rolling shutter\nimage sensors currently available have different frame rates, shutter speeds,\nsampling rates, and resolutions. However, focusing on unidirectional\ncommunications (i.e., data broadcasting, beacons), an asynchronous\ncommunication prototype is also discussed in the paper. Due to the physical\nlimitations associated with typical image sensors (including low and varying\nframe rates, long exposures, and low shutter speeds), the link speed\nperformance is critically considered. Based on the practical measurement of\ncamera response to modulated light, an operating frequency range is suggested\nalong with the similar system architecture, decoding procedure, and algorithms.\nA significant feature of our novel data frame structure is that it can support\nboth typical frame rate cameras (in the oversampling mode) as well as very low\nframe rate cameras (in the error detection mode for a camera whose frame rate\nis lower than the transmission packet rate). A high frame rate camera, i.e., no\nless than 20 fps, is supported in an oversampling mode in which a majority\nvoting scheme for decoding data is applied. A low frame rate camera, i.e., when\nthe frame rate drops to less than 20 fps at some certain time, is supported by\nan error detection mode in which any missing data sub-packet is detected in\ndecoding and later corrected by external code. Numerical results and valuable\nanalysis are also included to indicate the capability of the proposed schemes.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 12:02:32 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Nguyen", "Trang", ""], ["Hossain", "Mohammad Arif", ""], ["Jang", "Yeong Min", ""]]}, {"id": "1606.05875", "submitter": "Nabil Amrani Bensaid", "authors": "N. Bensaid Amrani, L. Saintis, D. Sarsri, and M. Barreau", "title": "Evaluating the predicted reliability of mechatronic systems: state of\n  the art", "comments": "13 page, Mechanical Engineering: An International Journal (MEIJ),\n  Vol. 3, No. 2, May 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliability analysis of mechatronic systems is a recent field and a dynamic\nbranch of research. It is addressed whenever there is a need for reliable,\navailable, and safe systems. The studies of reliability must be conducted\nearlier during the design phase, in order to reduce costs and the number of\nprototypes required in the validation of the system. The process of reliability\nis then deployed throughout the full cycle of development. This process is\nbroken down into three major phases: the predictive reliability, the\nexperimental reliability and operational reliability. The main objective of\nthis article is a kind of portrayal of the various studies enabling a\nnoteworthy mastery of the predictive reliability. The weak points are\nhighlighted. Presenting an overview of all the quantitative and qualitative\napproaches concerned with modelling and evaluating the prediction of\nreliability is so important for future reliability studies and for academic\nresearch to come up with new methods and tools. The mechatronic system is a\nhybrid system, it is dynamic, reconfigurable, and interactive. The modeling\ncarried out of reliability prediction must take into account these criteria.\nSeveral methodologies have been developed in this track of research. In this\nregard, the aforementioned methodologies will be analytically sketched in this\npaper.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jun 2016 14:40:37 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Amrani", "N. Bensaid", ""], ["Saintis", "L.", ""], ["Sarsri", "D.", ""], ["Barreau", "M.", ""]]}, {"id": "1606.06973", "submitter": "Renato dos Santos", "authors": "Renato P. dos Santos", "title": "Some comments on the reliability of NOAA's Storm Events Database", "comments": "22 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Storms and other severe weather events can result in fatalities, injuries,\nand property damage. Therefore, preventing such outcomes to the extent possible\nis a key concern, and the scientific community faces an increasing demand for\nregularly updated appraisals of evolving climate conditions and extreme\nweather. NOAA's Storm Events Database is undoubtedly an invaluable resource to\nthe general public, to the professional, and to the researcher. Due to such\nimportance, the primary objective of this study was to explore this database\nand get clues about its reliability. A complete investigation of the damage\nestimates, injuries or fatalities figures is unfeasible due to the extension of\nthe database. However, an exploratory data analysis with the resources of the R\nstatistical data analysis language found that damage reports are missing in\nmore than half of the records, that part of the damage values are incorrect,\nand that, despite all efforts of standardizations, non-standard event type\nnames are still finding their way into the database. These few results are\nenough to demonstrate that the database suffers from incompleteness and\ninconsistencies and should not be used without taking reservations and\nappropriate precautions before advancing any inferences from the data.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 15:00:37 GMT"}, {"version": "v2", "created": "Thu, 23 Jun 2016 13:01:53 GMT"}], "update_date": "2016-06-27", "authors_parsed": [["Santos", "Renato P. dos", ""]]}, {"id": "1606.07092", "submitter": "Roman Yampolskiy", "authors": "Soenke Ziesche, Roman V. Yampolskiy", "title": "Artificial Fun: Mapping Minds to the Space of Fun", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Yampolskiy and others have shown that the space of possible minds is vast,\nactually infinite (Yampolskiy, 2015). A question of interest is 'Which\nactivities can minds perform during their lifetime?' This question is very\nbroad, thus in this article restricted to 'Which non-boring activities can\nminds perform?' The space of potential non-boring activities has been called by\nYudkowsky 'fun space' (Yudkowsky, 2009). This paper aims to discuss the\nrelation between various types of minds and the part of the fun space, which is\naccessible for them.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 20:28:53 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Ziesche", "Soenke", ""], ["Yampolskiy", "Roman V.", ""]]}, {"id": "1606.07498", "submitter": "Biljana Risteska Stojkoska Dr", "authors": "Danco Davcev, Biljana Stojkoska, Slobodan Kalajdziski and Kire\n  Trivodaliev", "title": "Project Based Learning of Embedded Systems", "comments": null, "journal-ref": "Proceedings of the 2nd WSEAS International Conference on CIRCUITS,\n  SYSTEMS, SIGNAL and TELECOMMUNICATIONS (CISST'08) Acapulco, Mexico, January\n  25-27, 2008. ISSN: 1790-5117, ISBN: 978-960-6766-34-3, pp.120-125", "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional teaching, usually based on lectures and tutorials fosters the\nidea of instruction-driven learning model where students are passive listeners.\nBesides this approach, Project Based Learning (PBL) as a different learning\nparadigm is standing behind constructivism learning theory, where learning from\nreal-world situations is put on the first place. The purpose of this paper is\nto present our approach in learning embedded systems at our University. It is\nbased on combination of traditional (face-to-face) learning and PBL. Our PBL\nrepresents an interdisciplinary project based on wireless sensor monitoring of\nreal-world environment (greenhouse). The students use UML that was shown as an\nexcellent tool for developing such a projects. From the student perspective, we\nfound that this high level of interdisciplinary is very valuable from the point\nof view of facing the students with real-life problems.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 22:19:01 GMT"}, {"version": "v2", "created": "Thu, 19 Jan 2017 22:23:21 GMT"}], "update_date": "2017-01-23", "authors_parsed": [["Davcev", "Danco", ""], ["Stojkoska", "Biljana", ""], ["Kalajdziski", "Slobodan", ""], ["Trivodaliev", "Kire", ""]]}]