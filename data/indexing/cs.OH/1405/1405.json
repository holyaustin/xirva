[{"id": "1405.0109", "submitter": "Vaibhav Jha", "authors": "Vaibhav Jha, Mohit Jha, GK Sharma", "title": "Estimation of Optimized Energy and Latency Constraints for Task\n  Allocation in 3d Network on Chip", "comments": "20 Pages,17 Figure, International Journal of Computer Science &\n  Information Technology. arXiv admin note: substantial text overlap with\n  arXiv:1404.2512", "journal-ref": "International Journal of Computer Science & Information Technology\n  Vol 6,No 2,pp 67-86 April 2014", "doi": "10.5121/ijcsit.2014.6205", "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Network on Chip (NoC) rooted system, energy consumption is affected by\ntask scheduling and allocation schemes which affect the performance of the\nsystem. In this paper we test the pre-existing proposed algorithms and\nintroduced a new energy skilled algorithm for 3D NoC architecture. An efficient\ndynamic and cluster approaches are proposed along with the optimization using\nbio-inspired algorithm. The proposed algorithm has been implemented and\nevaluated on randomly generated benchmark and real life application such as\nMMS, Telecom and VOPD. The algorithm has also been tested with the E3S\nbenchmark and has been compared with the existing mapping algorithm spiral and\ncrinkle and has shown better reduction in the communication energy consumption\nand shows improvement in the performance of the system. On performing\nexperimental analysis of proposed algorithm results shows that average\nreduction in energy consumption is 49%, reduction in communication cost is 48%\nand average latency is 34%. Cluster based approach is mapped onto NoC using\nDynamic Diagonal Mapping (DDMap), Crinkle and Spiral algorithms and found DDmap\nprovides improved result. On analysis and comparison of mapping of cluster\nusing DDmap approach the average energy reduction is 14% and 9% with crinkle\nand spiral.\n", "versions": [{"version": "v1", "created": "Thu, 1 May 2014 07:38:46 GMT"}], "update_date": "2014-05-02", "authors_parsed": [["Jha", "Vaibhav", ""], ["Jha", "Mohit", ""], ["Sharma", "GK", ""]]}, {"id": "1405.0276", "submitter": "James Whitacre", "authors": "James Whitacre, Sven Schellenberg, Antony Iorio", "title": "Coal Blending: Business Value, Analysis, and Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coal blending is a critically important process in the coal mining industry\nas it directly influences the number of product tonnes and the total revenue\ngenerated by a mine site. Coal blending represents a challenging and complex\nproblem with numerous blending possibilities, multiple constraints and\ncompeting objectives. At many mine sites, blending decisions are made using\nheuristics that have been developed through experience or made by using\ncomputer assisted control algorithms or linear programming. While current\nblending procedures have achieved profitable outcomes in the past, they often\nresult in a sub-optimal utilization of high quality coal. This sub-optimality\nhas a considerable negative impact on mine site productivity as it can reduce\nthe amount of lower quality ROM that is blended and sold. This article reviews\nthe coal blending problem and discusses some of the difficult trade-offs and\nchallenges that arise in trying to address this problem. We highlight some of\nthe risks from making simplifying assumptions and the limitations of current\nsoftware optimization systems. We conclude by explaining how the mining\nindustry would significantly benefit from research and development into\noptimization algorithms and technologies that are better able to combine\ncomputer optimization algorithm capabilities with the important insights of\nengineers and quality control specialists.\n", "versions": [{"version": "v1", "created": "Thu, 1 May 2014 07:59:10 GMT"}, {"version": "v2", "created": "Mon, 26 May 2014 05:04:28 GMT"}], "update_date": "2014-05-27", "authors_parsed": [["Whitacre", "James", ""], ["Schellenberg", "Sven", ""], ["Iorio", "Antony", ""]]}, {"id": "1405.1085", "submitter": "Sufyan Faraj", "authors": "Narada Wickramage", "title": "Rapture in the Cartesian Wall between Real World Entities and their\n  Abstract Models", "comments": "International Conference on Future Trends in Computing and\n  Communication Technologies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short paper envisages that the advancements made with respect to Big\nData (BD), High Performance Computing, etc. would give rise to a new paradigm\nof concrete information models, which would closely replicate the real world\nand the consequences such as self-verifying information models, BD warehouses\nas intermediaries between data sources and information systems, etc.\n", "versions": [{"version": "v1", "created": "Mon, 5 May 2014 21:40:58 GMT"}], "update_date": "2014-05-07", "authors_parsed": [["Wickramage", "Narada", ""]]}, {"id": "1405.2063", "submitter": "Bob Scurlock", "authors": "Bob J. Scurlock", "title": "Use of ARAS 360 to Facilitate Rapid Development of Articulated Total\n  Body Biomechanical Physics Simulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of 3-dimensional environments to be used within a\nbiomechanical physics simulation framework, such as Articulated Total Body, can\nbe laborious and time intensive. This brief article demonstrates how the ARAS\n360 software package can aid the user by speeding up development time.\n", "versions": [{"version": "v1", "created": "Thu, 17 Apr 2014 19:32:40 GMT"}], "update_date": "2014-05-09", "authors_parsed": [["Scurlock", "Bob J.", ""]]}, {"id": "1405.2157", "submitter": "Arash Batni", "authors": "Arash Batni (1), Farshad Safaei (1 and 2) ((1) Faculty of ECE,\n  ShahidBeheshti University G.C., Tehran, Iran (2) Institute for Studies in\n  Theoretical Physics and Mathematics (IPM) School of Computer Science, Tehran,\n  Iran)", "title": "A New Multi-Tiered Solid State Disk Using Slc/Mlc Combined Flash Memory", "comments": "13 pages, 18 figures", "journal-ref": "International Journal of Computer Science, Engineering and\n  Information Technology (IJCSEIT), Vol. 4, No.2, April 2014", "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Storing digital information, ensuring the accuracy, steady and uninterrupted\naccess to the data are considered as fundamental challenges in enterprise-class\norganizations and companies. In recent years, new types of storage systems such\nas solid state disks (SSD) have been introduced. Unlike hard disks that have\nmechanical structure, SSDs are based on flash memory and thus have electronic\nstructure. Generally a SSD consists of a number of flash memory chips, some\nbuffers of the volatile memory type, and an embedded microprocessor, which have\nbeen interconnected by a port. This microprocessor run a small file system\nwhich called flash translation layer (FTL). This software controls and\nschedules buffers, data transfers and all flash memory tasks. SSDs have some\nadvantages over hard disks such as high speed, low energy consumption, lower\nheat and noise, resistance against damage, and smaller size. Besides, some\ndisadvantages such as limited endurance and high price are still challenging.\nIn this study, the effort is to combine two common technologies - SLC and MLC\nchips - used in the manufacture of SSDs in a single SSD to decrease the side\neffects of current SSDs. The idea of using multi-layer SSD is regarded as an\nefficient solution in this field.\n", "versions": [{"version": "v1", "created": "Fri, 9 May 2014 06:58:18 GMT"}], "update_date": "2014-05-12", "authors_parsed": [["Batni", "Arash", "", "1 and 2"], ["Safaei", "Farshad", "", "1 and 2"]]}, {"id": "1405.2305", "submitter": "Piero Giacomelli", "authors": "Piero Giacomelli and Asa Smedberg", "title": "The Eve of 3D Printing in Telemedicine: State of the Art and Future\n  Challenges", "comments": "5 pages submitted to The Sixth International Conference on eHealth,\n  Telemedicine, and Social Medicine (eTELEMED 2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  3D printing has raised a lot of attention from fields outside the\nmanufacturing one in the last years. In this paper, we will illustrate some\nrecent advances of 3D printing technology, applied to the field of telemedicine\nand remote patient care. The potentiality of this technology will be detailed\nwithout lab examples. Some crucial aspect such as the regulation of these\ndevices and the need of some standards will also be discussed. The purpose of\nthis paper is to present some of the most promising applications of such\ntechnology.\n", "versions": [{"version": "v1", "created": "Tue, 6 May 2014 10:54:29 GMT"}], "update_date": "2014-05-12", "authors_parsed": [["Giacomelli", "Piero", ""], ["Smedberg", "Asa", ""]]}, {"id": "1405.2512", "submitter": "Hadassa Daltrophe", "authors": "Hadassa Daltrophe, Shlomi Dolev, Zvi Lotker", "title": "Mending the Big-Data Missing Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Consider a high-dimensional data set, in which for every data-point there is\nincomplete information. Each object in the data set represents a real entity,\nwhich is described by a point in high-dimensional space. We model the lack of\ninformation for a given object as an affine subspace in $\\mathbb{R}^d$ whose\ndimension $k$ is the number of missing features.\n  Our goal in this study is to find clusters of objects where the main problem\nis to cope with partial information and high dimension. Assuming the data set\nis separable, namely, its emergence from clusters that can be modeled as a set\nof disjoint ball in $\\mathbb{R}^d$, we suggest a simple data clustering\nalgorithm. Our suggested algorithm use the affine subspaces minimum distance\nand calculates pair-wise projection of the data achieving poly-logarithmic time\ncomplexity.\n  We use probabilistic considerations to prove the algorithm's correctness.\nThese probabilistic results are of independent interest, and can serve to\nbetter understand the geometry of high dimensional objects.\n", "versions": [{"version": "v1", "created": "Sun, 11 May 2014 09:40:19 GMT"}, {"version": "v2", "created": "Wed, 14 May 2014 05:27:06 GMT"}, {"version": "v3", "created": "Tue, 3 Jun 2014 05:46:29 GMT"}, {"version": "v4", "created": "Mon, 18 May 2015 06:55:23 GMT"}, {"version": "v5", "created": "Sun, 8 May 2016 09:11:47 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["Daltrophe", "Hadassa", ""], ["Dolev", "Shlomi", ""], ["Lotker", "Zvi", ""]]}, {"id": "1405.2917", "submitter": "Aurang Zaib", "authors": "Aurang Zaib, Prashanth Raju, Thomas Wild, Andreas Herkersdorf", "title": "A Layered Modeling and Simulation Approach to investigate Resource-aware\n  Computing in MPSoCs", "comments": "Presented at 1st Workshop on Resource Awareness and Adaptivity in\n  Multi-Core Computing (Racing 2014) (arXiv:1405.2281)", "journal-ref": null, "doi": null, "report-no": "Racing/2014/11", "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing complexity of modern multi-processor system on chip (MPSoC) and\nthe decreasing feature size have introduced new challenges. System designers\nhave to consider now aspects which were not part of the design process in past\ntimes. Resource-aware Computing is one of such emerging design concerns which\ncan help to improve performance, dependability and resource utilization of\noverall system. Resource-aware execution takes into account the resource status\nwhen executing tasks on MPSoCs. Exploration of resource-aware computing at\nearly design stages of complex systems is mandatory and appropriate\nmethodologies to do this in an efficient manner are thus required. In this\npaper, we present a modular approach which provides modeling and simulation\nsupport for investigation of resource-aware execution in MPSoCs. The proposed\nmethodology enables rapid exploration of the design space by modeling and\nsimulating the resource-awareness in a separate layer while widely reusing the\nlegacy system model in the other layer. Our experiments illustrate the benefits\nof our approach for the exploration of resource-aware execution on MPSoCs.\n", "versions": [{"version": "v1", "created": "Mon, 12 May 2014 16:43:19 GMT"}], "update_date": "2014-05-14", "authors_parsed": [["Zaib", "Aurang", ""], ["Raju", "Prashanth", ""], ["Wild", "Thomas", ""], ["Herkersdorf", "Andreas", ""]]}, {"id": "1405.3100", "submitter": "Andrea Monacchi", "authors": "Andrea Monacchi, Dominik Egarter, Wilfried Elmenreich, Salvatore\n  D'Alessandro, Andrea M. Tonello", "title": "GREEND: An Energy Consumption Dataset of Households in Italy and Austria", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Home energy management systems can be used to monitor and optimize\nconsumption and local production from renewable energy. To assess solutions\nbefore their deployment, researchers and designers of those systems demand for\nenergy consumption datasets. In this paper, we present the GREEND dataset,\ncontaining detailed power usage information obtained through a measurement\ncampaign in households in Austria and Italy. We provide a description of\nconsumption scenarios and discuss design choices for the sensing\ninfrastructure. Finally, we benchmark the dataset with state-of-the-art\ntechniques in load disaggregation, occupancy detection and appliance usage\nmining.\n", "versions": [{"version": "v1", "created": "Tue, 13 May 2014 10:51:32 GMT"}, {"version": "v2", "created": "Thu, 22 May 2014 13:57:03 GMT"}], "update_date": "2014-05-23", "authors_parsed": [["Monacchi", "Andrea", ""], ["Egarter", "Dominik", ""], ["Elmenreich", "Wilfried", ""], ["D'Alessandro", "Salvatore", ""], ["Tonello", "Andrea M.", ""]]}, {"id": "1405.4597", "submitter": "Marjan Naderinejad", "authors": "Marjan Naderinejad and Mohammad Jafar Tarokh and Alireza Poorebrahimi", "title": "Recognition and Ranking Critical Success Factors of Business\n  Intelligence in Hospitals -- Case Study: Hasheminejad Hospital", "comments": "http://airccse.org/journal/ijcsit2014_curr.html", "journal-ref": null, "doi": "10.5121/ijcsit.2014.6208", "report-no": null, "categories": "cs.OH", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Business Intelligence, not as a tool of a product but as a new approach is\npropounded in organizations to make tough decisions in business as shortly as\npossible. Hospital managers often need business intelligence in their fiscal,\noperational, and clinical reports and indices. The main goal of recognition and\nranking CSF is implementation of a business intelligent system in hospitals to\nincrease success factor of application of business intelligence in health and\ntreatment sector. This paper is an application and descriptive-analytical one,\nin which we use questionnaires to gather data and we used SPSS and LISREL to\nanalyze them. Its statistical society is managers and personnel of Hasheminejad\nhospital and case studies are selected by Cochran formula. The findings show\nthat all three organizational, process, and technological factors equally\naffect implementation of business intelligence based on Yeoh & Koronis\napproach, where the assumptions are based upon it. The proposed model for CSFs\nof business intelligence in hospitals include: declaring perspective, goals and\nstrategies, development of human and financial resources, clarification of\norganizational culture, documentation and process mature, management support,\netc. Business intelligence implementation is affected by different components.\nCenter of Hasheminejad hospital BI system as a leader in providing quality\nhealth care, partially succeeded to take advantage of the benefits the\norganization in passing the information revolution but the development of this\nsystem to achieve intelligent hospital and its certainty is a high priority,\nthus it can`t be said that the hospital-wide BI system is quite favorable. In\nthis regard, it can be concluded that Hasheminejad hospital requires practical\nmodel for business intelligence systems development.\n", "versions": [{"version": "v1", "created": "Mon, 19 May 2014 04:26:13 GMT"}], "update_date": "2014-05-20", "authors_parsed": [["Naderinejad", "Marjan", ""], ["Tarokh", "Mohammad Jafar", ""], ["Poorebrahimi", "Alireza", ""]]}, {"id": "1405.5501", "submitter": "Dominik Kopczynski", "authors": "Dominik Kopczynski, Sven Rahmann", "title": "Using the Expectation Maximization Algorithm with Heterogeneous Mixture\n  Components for the Analysis of Spectrometry Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coupling a multi-capillary column (MCC) with an ion mobility (IM)\nspectrometer (IMS) opened a multitude of new application areas for gas\nanalysis, especially in a medical context, as volatile organic compounds (VOCs)\nin exhaled breath can hint at a person's state of health. To obtain a potential\ndiagnosis from a raw MCC/IMS measurement, several computational steps are\nnecessary, which so far have required manual interaction, e.g., human\nevaluation of discovered peaks. We have recently proposed an automated pipeline\nfor this task that does not require human intervention during the analysis.\nNevertheless, there is a need for improved methods for each computational step.\nIn comparison to gas chromatography / mass spectrometry (GC/MS) data, MCC/IMS\ndata is easier and less expensive to obtain, but peaks are more diffuse and\nthere is a higher noise level. MCC/IMS measurements can be described as samples\nof mixture models (i.e., of convex combinations) of two-dimensional probability\ndistributions. So we use the expectation-maximization (EM) algorithm to\ndeconvolute mixtures in order to develop methods that improve data processing\nin three computational steps: denoising, baseline correction and peak\nclustering. A common theme of these methods is that mixture components within\none model are not homogeneous (e.g., all Gaussian), but of different types.\nEvaluation shows that the novel methods outperform the existing ones. We\nprovide Python software implementing all three methods and make our evaluation\ndata available at http://www.rahmannlab.de/research/ims.\n", "versions": [{"version": "v1", "created": "Wed, 21 May 2014 18:14:50 GMT"}], "update_date": "2014-05-22", "authors_parsed": [["Kopczynski", "Dominik", ""], ["Rahmann", "Sven", ""]]}, {"id": "1405.5793", "submitter": "Swen Jacobs", "authors": "Swen Jacobs", "title": "Extended AIGER Format for Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the AIGER format, as used in HWMCC, to a format that is suitable to\ndefine synthesis problems with safety specifications. We recap the original\nformat and define one format for posing synthesis problems and one for\nsolutions of synthesis problems in this setting.\n", "versions": [{"version": "v1", "created": "Thu, 22 May 2014 15:25:15 GMT"}, {"version": "v2", "created": "Mon, 26 May 2014 07:21:40 GMT"}], "update_date": "2014-05-27", "authors_parsed": [["Jacobs", "Swen", ""]]}, {"id": "1405.6161", "submitter": "Ali Rakhshan", "authors": "Ali Rakhshan and Evan Ray and Hossein Pishro-Nik", "title": "Real-Time Estimation of the Distribution of Brake Response Times for an\n  Individual Driver Using Vehicular Ad Hoc Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adapting the functioning of the collision warning systems to the specific\ndrivers' characteristics is of great benefit to drivers. For example, by\ncustomizing collision warning algorithms we can minimize false alarms, thereby\nreducing injuries and deaths in highway traffic accidents. In order to take the\nbehaviors of individual drivers into account, the system needs to have a\nReal-Time estimation of the distribution of brake response times for an\nindividual driver. In this paper, we propose a method for doing this estimation\nwhich is not computationally intensive and can take advantage of the\ninformation contained in all data points.\n", "versions": [{"version": "v1", "created": "Tue, 29 Apr 2014 19:49:28 GMT"}], "update_date": "2014-05-26", "authors_parsed": [["Rakhshan", "Ali", ""], ["Ray", "Evan", ""], ["Pishro-Nik", "Hossein", ""]]}, {"id": "1405.6163", "submitter": "Borui Li", "authors": "Borui Li, Chundi Mu, Tao Wang, Qian Peng", "title": "Revised Version of a JCIT Paper-Comparison of Feature Point Extraction\n  Algorithms for Vision Based Autonomous Aerial Refueling", "comments": null, "journal-ref": "Journal of Convergence Information Technology. 2012, 7(20):\n  108-118", "doi": "10.4156/jcit.vol7.issue20.14", "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a revised version of our paper published in Journal of Convergence\nInformation Technology(JCIT): \"Comparison of Feature Point Extraction\nAlgorithms for Vision Based Autonomous Aerial Refueling\". We corrected some\nerrors including measurement unit errors, spelling errors and so on. Since the\npublished papers in JCIT are not allowed to be modified, we submit the revised\nversion to arXiv.org to make the paper more rigorous and not to confuse other\nresearchers.\n", "versions": [{"version": "v1", "created": "Mon, 28 Apr 2014 16:12:43 GMT"}, {"version": "v2", "created": "Wed, 4 Jun 2014 11:30:23 GMT"}], "update_date": "2014-06-05", "authors_parsed": [["Li", "Borui", ""], ["Mu", "Chundi", ""], ["Wang", "Tao", ""], ["Peng", "Qian", ""]]}, {"id": "1405.6174", "submitter": "Shuliang Wang", "authors": "Shuliang Wang, Zhe Zhou, Wenzhong Shi", "title": "Adaptive Minimum-Maximum Exclusive Mean Filter for Impulse Noise Removal", "comments": "This paper has been withdrawn by the author due to a crucial error in\n  experiment", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many filters are proposed for impulse noise removal. However, they are hard\nto keep excellent denoising performance with high computational efficiency. In\nresponse to this difficulty, this paper presents a novel fast filter, adaptive\nminimum-maximum exclusive mean (AMMEM) filter to remove impulse noise. Although\nthe AMMEM filter is a variety of the maximum-minimum exclusive mean (MMEM)\nfilter, however, the AMMEM filter inherits the advantages, and overcomes the\ndrawbacks, compared with the MMEM filter. To increase the various performances\nof noise removal, the AMMEM filter uses an adaptive size window, introduces two\nflexible factors, projection factor P and detection factor T, and limits the\ncalculation scope of the AVG. The experimental results show the AMMEM filter\nmakes a significant improvement in terms of noise detection, image restoration,\nand computational efficiency. Even at noise level as high as 95%, the AMMEM\nfilter still can restore the images with good visual effect.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2014 08:51:52 GMT"}, {"version": "v2", "created": "Sun, 2 Nov 2014 01:10:46 GMT"}], "update_date": "2014-11-04", "authors_parsed": [["Wang", "Shuliang", ""], ["Zhou", "Zhe", ""], ["Shi", "Wenzhong", ""]]}, {"id": "1405.6822", "submitter": "Hiba Zaidi", "authors": "Hiba Zaidi", "title": "Mobile Application for GBAS Air Traffic Status Unit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At present, the Air Traffic Status Unit is a windows PC based application,\nwhich receives the status of ground based augmentation system station over\nEthernet and displays on the screen. The objective of this project is to\nconvert the PC based Application into Mobile application using Android OS.\n", "versions": [{"version": "v1", "created": "Tue, 27 May 2014 07:26:37 GMT"}], "update_date": "2014-05-28", "authors_parsed": [["Zaidi", "Hiba", ""]]}, {"id": "1405.7135", "submitter": "Samir Lemes", "authors": "Samir Leme\\v{s}", "title": "Odr\\v{z}avanje ra\\v{c}unarskih sistema", "comments": "3. konferencija Odr\\v{z}avanje - Maintenance 2014 (S. Brdarevi\\'c, S.\n  Ja\\v{s}arevi\\'c, editors), ISSN 1986-583X, Zenica", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer hardware and software are resources without which the modern\nbusiness of any organization, from manufacturing to services, is impossible.\nNot enough attention is being payed to maintenance of computer systems as an\naspect of business. This paper gives some recommendations for the selection of\nthe computer systems maintenance approach, based on many years of experience\nmaintaining these systems at the University of Zenica.\n", "versions": [{"version": "v1", "created": "Wed, 28 May 2014 07:01:00 GMT"}], "update_date": "2014-05-29", "authors_parsed": [["Leme\u0161", "Samir", ""]]}]