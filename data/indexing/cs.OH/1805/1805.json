[{"id": "1805.00105", "submitter": "Md Johirul Islam", "authors": "Md Johirul Islam, Anuj Sharma, Hridesh Rajan", "title": "A Cyberinfrastructure for BigData Transportation Engineering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big Data-driven transportation engineering has the potential to improve\nutilization of road infrastructure, decrease traffic fatalities, improve fuel\nconsumption, decrease construction worker injuries, among others. Despite these\nbenefits, research on Big Data-driven transportation engineering is difficult\ntoday due to the computational expertise required to get started. This work\nproposes BoaT, a transportation-specific programming language, and it's Big\nData infrastructure that is aimed at decreasing this barrier to entry. Our\nevaluation that uses over two dozen research questions from six categories show\nthat research is easier to realize as a BoaT computer program, an order of\nmagnitude faster when this program is run, and exhibits 12-14x decrease in\nstorage requirements.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 21:22:02 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Islam", "Md Johirul", ""], ["Sharma", "Anuj", ""], ["Rajan", "Hridesh", ""]]}, {"id": "1805.00140", "submitter": "Saba Ahmadian", "authors": "Saba Ahmadian, Farhad Taheri, Mehrshad Lotfi, Maryam Karimi, and\n  Hossein Asad", "title": "Investigating Power Outage Effects on Reliability of Solid-State Drives", "comments": "Design, Automation & Test in Europe Conference & Exhibition (DATE),\n  2018. IEEE, 2018", "journal-ref": null, "doi": "10.23919/DATE.2018.8342004", "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solid-State Drives (SSDs) are recently employed in enterprise servers and\nhigh-end storage systems in order to enhance performance of storage subsystem.\nAlthough employing high speed SSDs in the storage subsystems can significantly\nimprove system performance, it comes with significant reliability threat for\nwrite operations upon power failures. In this paper, we present a comprehensive\nanalysis investigating the impact of workload dependent parameters on the\nreliability of SSDs under power failure for variety of SSDs (from top\nmanufacturers). To this end, we first develop a platform to perform two\nimportant features required for study: a) a realistic fault injection into the\nSSD in the computing systems and b) data loss detection mechanism on the SSD\nupon power failure. In the proposed physical fault injection platform, SSDs\nexperience a real discharge phase of Power Supply Unit (PSU) that occurs during\npower failure in data centers which was neglected in previous studies. The\nimpact of workload dependent parameters such as workload Working Set Size\n(WSS), request size, request type, access pattern, and sequence of accesses on\nthe failure of SSDs is carefully studied in the presence of realistic power\nfailures. Experimental results over thousands number of fault injections show\nthat data loss occurs even after completion of the request (up to 700ms) where\nthe failure rate is influenced by the type, size, access pattern, and sequence\nof IO accesses while other parameters such as workload WSS has no impact on the\nfailure of SSDs.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 07:20:10 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Ahmadian", "Saba", ""], ["Taheri", "Farhad", ""], ["Lotfi", "Mehrshad", ""], ["Karimi", "Maryam", ""], ["Asad", "Hossein", ""]]}, {"id": "1805.00321", "submitter": "Ravi Lanka", "authors": "Ravi Lanka", "title": "PURE: Scalable Phase Unwrapping with Spatial Redundant Arcs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.CV cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phase unwrapping is a key problem in many coherent imaging systems, such as\nsynthetic aperture radar (SAR) interferometry. A general formulation for\nredundant integration of finite differences for phase unwrapping (Costantini et\nal., 2010) was shown to produce a more reliable solution by exploiting\nredundant differential estimates. However, this technique requires a commercial\nlinear programming solver for large-scale problems. For a linear cost function,\nwe propose a method based on Dual Decomposition that breaks the given problem\ndefined over a non-planar graph into tractable sub-problems over planar\nsubgraphs. We also propose a decomposition technique that exploits the\nunderlying graph structure for solving the sub-problems efficiently and\nguarantees asymptotic convergence to the globally optimal solution. The\nexperimental results demonstrate that the proposed approach is comparable to\nthe existing state-of-the-art methods in terms of the estimate with a better\nruntime and memory footprint.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 06:05:07 GMT"}, {"version": "v2", "created": "Thu, 3 May 2018 04:13:51 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Lanka", "Ravi", ""]]}, {"id": "1805.01586", "submitter": "Somya Mohanty", "authors": "Bin Luo, Qi Zhang, Somya D. Mohanty", "title": "Data-Driven Exploration of Factors Affecting Federal Student Loan\n  Repayment", "comments": "7 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.OH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Student loans occupy a significant portion of the federal budget, as well as,\nthe largest financial burden in terms of debt for graduates. This paper\nexplores data-driven approaches towards understanding the repayment of such\nloans. Using statistical and machine learning models on the College Scorecard\nData, this research focuses on extracting and identifying key factors affecting\nthe repayment of a student loan. The specific factors can be used to develop\nmodels which provide predictive capability towards repayment rate, detect\nirregularities/non-repayment, and help understand the intricacies of student\nloans.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 15:02:35 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Luo", "Bin", ""], ["Zhang", "Qi", ""], ["Mohanty", "Somya D.", ""]]}, {"id": "1805.04907", "submitter": "Ranjini Swaminathan", "authors": "Ranjini Swaminathan, Mohan Sridharan, Katharine Hayhoe", "title": "A Computational Framework for Modelling and Analyzing Ice Storms", "comments": "7 pages including bibliography", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ao-ph cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ice storms are extreme weather events that can have devastating implications\nfor the sustainability of natural ecosystems as well as man made\ninfrastructure. Ice storms are caused by a complex mix of atmospheric\nconditions and are among the least understood of severe weather events. Our\nability to model ice storms and characterize storm features will go a long way\ntowards both enabling support systems that offset storm impacts and increasing\nour understanding of ice storms. In this paper, we present a holistic\ncomputational framework to answer key questions of interest about ice storms.\nWe model ice storms as a function of relevant surface and atmospheric\nvariables. We learn these models by adapting and applying supervised and\nunsupervised machine learning algorithms on data with missing or incorrect\nlabels. We also include a knowledge representation module that reasons with\ndomain knowledge to revise the output of the learned models. Our models are\ntrained using reanalysis data and historical records of storm events. We\nevaluate these models on reanalyis data as well as Global Climate Model (GCM)\ndata for historical and future climate change scenarios. Furthermore, we\ndiscuss the use of appropriate bias correction approaches to run such modeling\nframeworks with GCM data.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 16:18:32 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Swaminathan", "Ranjini", ""], ["Sridharan", "Mohan", ""], ["Hayhoe", "Katharine", ""]]}, {"id": "1805.05946", "submitter": "Kamran Binaee", "authors": "Kamran Binaee, Anna Starynska, Jeff B Pelz, Christopher Kanan, Gabriel\n  Jacob Diaz", "title": "Characterizing the Temporal Dynamics of Information in Visually Guided\n  Predictive Control Using LSTM Recurrent Neural Networks", "comments": "6 pages, 6 figures, Cognitive Science Conference 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Theories for visually guided action account for online control in the\npresence of reliable sources of visual information, and predictive control to\ncompensate for visuomotor delay and temporary occlusion. In this study, we\ncharacterize the temporal relationship between information integration window\nand prediction distance using computational models. Subjects were immersed in a\nsimulated environment and attempted to catch virtual balls that were\ntransiently \"blanked\" during flight. Recurrent neural networks were trained to\nreproduce subject's gaze and hand movements during blank. The models\nsuccessfully predict gaze behavior within 3 degrees, and hand movements within\n8.5 cm as far as 500 ms in time, with integration window as short as 27 ms.\nFurthermore, we quantified the contribution of each input source of information\nto motor output through an ablation study. The model is a proof of concept for\nprediction as a discrete mapping between information integrated over time and a\ntemporally distant motor output.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 00:43:23 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Binaee", "Kamran", ""], ["Starynska", "Anna", ""], ["Pelz", "Jeff B", ""], ["Kanan", "Christopher", ""], ["Diaz", "Gabriel Jacob", ""]]}, {"id": "1805.06033", "submitter": "Nasser Aloufi", "authors": "Nasser Aloufi", "title": "Autonomous Vehicle Scheduling At Intersections Based On Production Line\n  Technique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis considers the problem of scheduling autonomous vehicles at\nintersections. A new system is proposed which is more efficient and could\nreplace the recently introduced Autonomous Intersection Management (AIM) model.\nThe proposed system is based on the production line technique. The environment\nof the intersection, vehicles position, speeds, and turning are specified and\ndetermined in advance. The goal of the proposed system is to eliminate vehicle\ncollision and reduce the waiting time to cross the intersection. Three\ndifferent patterns of traffic flow towards the intersection have been tested.\nThe system requires less waiting time, compared to the other models, including\nthe random case where the flow is unpredictable. The K-Nearest Neighbors (KNN)\nalgorithm has been used to predict vehicles making a right turn at the\nintersection. The experimental results show there is no chance of collision\ninside the intersection using the proposed model; however, the system might\nrequire more space in the traffic lane for some specific traffic patterns.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 20:57:16 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Aloufi", "Nasser", ""]]}, {"id": "1805.07643", "submitter": "Yan Chang", "authors": "Yan Chang, Weiqing Yang, Ding Zhao", "title": "Energy Efficiency and Emission Testing for Connected and Automated\n  Vehicles Using Real-World Driving Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH eess.SP stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By using the onboard sensing and external connectivity technology, connected\nand automated vehicles (CAV) could lead to improved energy efficiency, better\nrouting, and lower traffic congestion. With the rapid development of the\ntechnology and adaptation of CAV, it is more critical to develop the universal\nevaluation method and the testing standard which could evaluate the impacts on\nenergy consumption and environmental pollution of CAV fairly, especially under\nthe various traffic conditions. In this paper, we proposed a new method and\nframework to evaluate the energy efficiency and emission of the vehicle based\non the unsupervised learning methods. Both the real-world driving data of the\nevaluated vehicle and the large naturalistic driving dataset are used to\nperform the driving primitive analysis and coupling. Then the linear weighted\nestimation method could be used to calculate the testing result of the\nevaluated vehicle. The results show that this method can successfully identify\nthe typical driving primitives. The couples of the driving primitives from the\nevaluated vehicle and the typical driving primitives from the large real-world\ndriving dataset coincide with each other very well. This new method could\nenhance the standard development of the energy efficiency and emission testing\nof CAV and other off-cycle credits.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 19:20:31 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 14:29:51 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Chang", "Yan", ""], ["Yang", "Weiqing", ""], ["Zhao", "Ding", ""]]}, {"id": "1805.08575", "submitter": "Min Chen", "authors": "Min Chen", "title": "Cost-Benefit Analysis of Data Intelligence -- Its Broader\n  Interpretations", "comments": "The first version was archived in May 2018. It was updated in\n  December 2018 following a minor revision according to the reviewers' comments\n  and suggestions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The core of data science is our fundamental understanding about data\nintelligence processes for transforming data to decisions. One aspect of this\nunderstanding is how to analyze the cost-benefit of data intelligence\nworkflows. This work is built on the information-theoretic metric proposed by\nChen and Golan for this purpose and several recent studies and applications of\nthe metric. We present a set of extended interpretations of the metric by\nrelating the metric to encryption, compression, model development, perception,\ncognition, languages, and news media.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 15:03:09 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 10:35:09 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Chen", "Min", ""]]}, {"id": "1805.10012", "submitter": "Yongfu Li", "authors": "Yongfu Li, Chin Hui Lee, Wan Chia Ang, Kok Peng Chua, Yoong Seang\n  Jonathan Ong, Chiu Wing Colin Hui", "title": "Constraining the Synopsys Pin Access Checker Utility for Improved\n  Standard Cells Library Verification Flow", "comments": null, "journal-ref": "Synopsys User Conference (SNUG) Silicon Valley 2017", "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While standard cell layouts are drawn with minimum design rules for maximum\nbenefit of design area shrinkage, the complicated design rules begin to cause\ndifficulties with signal routes accessing the pins in standard cell layouts.\nMultiple design iterations are required to resolve routing issues, thus\nincreasing the runtime and the overall chip area. To optimize the chip\nperformance, power and area (PPA) and improve the routability, it is necessary\nto consider the pin accessibility during standard cell development phase so\nthat each cell is designed to maximize the number of feasible pin-access\nsolutions available to the router. As part of the Synopsys IC Compiler Library\nPreparation Reference Methodology, the Synopsys Pin Access Checker (PAC)\nreports DRC violations associated with the standard cell. Based on Synopsys\nPAC's methodology, we demonstrate several methods to improve the probability of\ndetecting pin accessibility issues, such as reducing the number of cells\nrequired for each Synopsys 'testcell', increasing the complexity of the pin\nconnectivity assignment and recommending the router constraints.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 07:18:08 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Li", "Yongfu", ""], ["Lee", "Chin Hui", ""], ["Ang", "Wan Chia", ""], ["Chua", "Kok Peng", ""], ["Ong", "Yoong Seang Jonathan", ""], ["Hui", "Chiu Wing Colin", ""]]}, {"id": "1805.10016", "submitter": "Yongfu Li", "authors": "Vikas Tripathi, Yongfu Li, Zhao Chuan Lee, I-Lun Tseng, Jason Khaw,\n  Jonathan Ong", "title": "In Design DFM Rule Scoring and Fixing Method using ICV", "comments": null, "journal-ref": "Synopsys User Group Penang (SNUG) 2017", "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As compared to DRC rules, DFM rules are a list of selected recommended rules\nwhich aim to improve the design margins for better manufacturability. In\nGLOBALFOUNDRIES, we use DFM scoring methodology as an effective technique to\nanalyze design quality in terms of manufacturability. Physical design engineers\ncan perform our Manufacturability Check Deck (MCD) to asset their design\nquality during the sign-off stage. In the past, Synopsys users have to convert\ntheir design though milkyway database to GDSII format and execute the\nverification through the third party EDA tools. This method is costly and\ntime-consuming for our Synopsys users. Today, we propose a new and easy-to-use\nintegrated flow which leverages on the ICV engine to provide DFM scoring and\nin-design fixing techniques. The new methodology address DFM violations early\nin the design flow and achieve DFM compliance design during sign-off phase.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 07:45:40 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Tripathi", "Vikas", ""], ["Li", "Yongfu", ""], ["Lee", "Zhao Chuan", ""], ["Tseng", "I-Lun", ""], ["Khaw", "Jason", ""], ["Ong", "Jonathan", ""]]}, {"id": "1805.10283", "submitter": "Yongfu Li", "authors": "Yongfu Li, Valerio Perez, I-Lun Tseng, Zhao Chuan Lee, Vikas Tripathi,\n  Jason Khaw, Yoong Seang Jonathan Ong", "title": "Advanced In-Design Auto-Fixing Flow for Cell Abutment Pattern Matching\n  Weakpoints", "comments": null, "journal-ref": "Synopsys User Group Singapore (SNUG) 2017", "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pattern matching design verification has gained noticeable attention in\nsemiconductor technologies as it can precisely identify more localized\nproblematic areas (weakpoints) in the layout. To address these weakpoints,\nengineers adopt 'Rip-up and Reroute' methodology to reroute the nets and avoid\nthese weakpoints. However, the technique is unable to address weakpoints due to\nthe cell placement. The only present approach is to manually shift or flip the\nstandard cells to eradicate the weakpoint. To overcome the challenge in going\nfrom a manual and laborious process to a fully automated fixing, we have\nproposed an in-design auto-fixing feature, tested with the commercial design\ntool, Synopsys IC Compiler. Our experimental result has demonstrated close to\none hundred percent lithography weakpoints fixing on all of our 14nm designs.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 09:42:03 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Li", "Yongfu", ""], ["Perez", "Valerio", ""], ["Tseng", "I-Lun", ""], ["Lee", "Zhao Chuan", ""], ["Tripathi", "Vikas", ""], ["Khaw", "Jason", ""], ["Ong", "Yoong Seang Jonathan", ""]]}, {"id": "1805.10635", "submitter": "Wayes Tushar", "authors": "Wayes Tushar, Nipun Wijerathne, Wen-Tai Li, Chau Yuen, H. Vincent\n  Poor, Tapan Kumar Saha, and Kristin L. Wood", "title": "IoT for Green Building Management", "comments": "20 pages, 7 figures, 1 table, accepted journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Buildings consume 60% of global electricity. However, current building\nmanagement systems (BMSs) are highly expensive and difficult to justify for\nsmall to medium-sized buildings. As such, the Internet of Things (IoT), which\ncan monitor and collect a large amount of data on different contexts of a\nbuilding and feed the data to the processor of the BMS, provides a new\nopportunity to integrate intelligence into the BMS to monitor and manage the\nenergy consumption of the building in a cost-effective manner. Although an\nextensive literature is available on IoT based BMS and applications of signal\nprocessing techniques for some aspects of building energy management\nseparately, detailed study on their integration to address the overall BMS is\nquite limited. As such, the proposed paper will address this gap by providing\nan overview of an IoT based BMS leveraging signal processing and machine\nlearning techniques. It is demonstrated how to extract high-level building\noccupancy information through simple and low-cost IoT sensors and studied the\nimpact of human activities on energy usage of a building, which can be\nexploited to design energy conservation measures to reduce the building's\nenergy consumption.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2018 14:57:14 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Tushar", "Wayes", ""], ["Wijerathne", "Nipun", ""], ["Li", "Wen-Tai", ""], ["Yuen", "Chau", ""], ["Poor", "H. Vincent", ""], ["Saha", "Tapan Kumar", ""], ["Wood", "Kristin L.", ""]]}, {"id": "1805.10745", "submitter": "Yongfu Li", "authors": "Yongfu Li, Wan Chia Ang, Chin Hui Lee, Kok Peng Chua, Yoong Seang\n  Jonathan Ong, Chiu Wing Colin Hui", "title": "Multiple-Lithography-Compliant Verification for Standard Cell Library\n  Development Flow", "comments": "Synopsys User Group Silicon Valley (SNUG) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Starting from 22-nm, a standard cell must be designed to be full\nlithography-compliant, which includes Design Rule Check,\nDesign-for-Manufacturability and Double-Patterning compliant. It has become a\ngreat challenge for physical layout designers to provide a full\nlithography-compliant standard cell layout that is optimized for area, power,\ntiming, signal integrity, and yield. This challenge is further exacerbated with\nabutted single- and multiple-height standard cells. At present, different\nfoundries and library vendors have different approaches for full\nlithography-compliant library preparation and validation. To the best of our\nknowledge, there is no single tool integrates all types of\nlithography-compliant check in standard cell libraries validation flow. In this\nwork, we will demonstrate multiple lithography-compliant verification for\nstandard cell library development flow. Validation flow and detailed algorithm\nimplementation will be explained to assist engineers to achieve full\nlithography-compliant standard cell libraries. An area-efficient standard cell\nplacement methodology will also be discussed to validate the issues arises from\nstandard cell abutment.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 02:48:22 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Li", "Yongfu", ""], ["Ang", "Wan Chia", ""], ["Lee", "Chin Hui", ""], ["Chua", "Kok Peng", ""], ["Ong", "Yoong Seang Jonathan", ""], ["Hui", "Chiu Wing Colin", ""]]}, {"id": "1805.11426", "submitter": "Yongfu Li", "authors": "Yongfu Li, Wan Chia Ang, Chin Hui Lee, Kok Peng Chua, Yoong Seang\n  Jonathan Ong, Chiu Wing Colin Hui", "title": "Standard Cell Library Evaluation with Multiple lithography-compliant\n  verification and Improved Synopsys Pin Access Checking Utility", "comments": "Synopsys User Group Singapore (SNUG) 2017. arXiv admin note:\n  substantial text overlap with arXiv:1805.10012, arXiv:1805.10745", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While standard cell layouts are drawn with minimum design rules to maximize\nthe benefit of design area shrinkage, the complicated design rules have caused\ndifficulties with signal routes accessing the pins in standard cell layouts. As\na result, it has become a great challenge for physical layout designers to\ndesign a standard cell layout that is optimized for area, power, timing, signal\nintegrity, and printability. Multiple design iterations are required to\nconsider pin accessibility during standard cells layout to increase the number\nof feasible solutions available to the router. In this work, we will\ndemonstrate several improvements with the Synopsys PAC methodology, such as\nreducing the number of cells required for each Synopsys 'testcell' with the\nsame cell abutment condition, increasing the complexity of the pin connection\nfor better pin accessibility evaluation. We also recommend additional\nconstraints to improve the probability of detecting pin accessibility issues.\nWe also integrate other physical verification methods to access the design rule\ncompliance and the printability of standard cells. We hope that the easy to use\nutility enables layout engineers to perform the verification, simplifying the\nverification methodology.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 02:51:04 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Li", "Yongfu", ""], ["Ang", "Wan Chia", ""], ["Lee", "Chin Hui", ""], ["Chua", "Kok Peng", ""], ["Ong", "Yoong Seang Jonathan", ""], ["Hui", "Chiu Wing Colin", ""]]}, {"id": "1805.11479", "submitter": "Sahil Imtiyaz", "authors": "Sahil Imtiyaz", "title": "Quantum Adiabatic Evolution for Global Optimization in Big Data", "comments": ":118 Pages: 2 figures:5 graphs:Conferences 2:Journal Papers 3 under\n  review. arXiv admin note: text overlap with arXiv:1506.08978,\n  arXiv:1511.03010, arXiv:0811.2519 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big Data is characterized by Volume, Velocity, Veracity and Complexity. The\ninteraction between this huge data is complex with an associated free will\nhaving dynamic and non linear nature. We reduced big data based on its\ncharacteristics, conceptually driven by quantum field theory and utilizing the\nphysics of condensed matter theory in a complex nonlinear dynamic system:\nQuantum Topological Field Theory of Data. The model is formulated from the\ndynamics and evolution of single datum, eventually defining the global\nproperties and evolution of collective data space via action, partition\nfunction, green propagators in almost polynomially solvable O(nlogn)\ncomplexity. The simulated results show that the time complexity of our\nalgorithm for global optimization via quantum adiabatic evolution is almost in\nO(logn) Our algorithm first mines the space via greedy approach and makes a\nlist of all ground state Hamiltonians, then utilizing the tunnelling property\nof quantum mechanics optimizes the algorithm unlike up hill and iterative\ntechniques and doesnot let algorithm to get localized in local minima or sharp\nvalley due to adiabatic evolution of the system. The loss in quantumness, non\nrealizable, no clone, noise, decoherence, splitting of energy states due to\nelectric and magnetic fields, variant to perturbations and less lifetime makes\nit inefficient for practical implementation. The inefficiencies of qubit can be\novercome via property that remains invariant to perturbation and Cartesian\nindependent having well defined mathematical structure. It can be well\naddressed via topological field theory of data.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 23:49:52 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Imtiyaz", "Sahil", ""]]}, {"id": "1805.11883", "submitter": "Laura Koesten", "authors": "Paul Groth (Elsevier Labs), Laura Koesten (The Open Data Institute +\n  University of Southampton), Philipp Mayr (GESIS - Leibniz Institute for the\n  Social Sciences), Maarten de Rijke (University of Amsterdam), Elena Simperl\n  (University of Southampton)", "title": "DATA:SEARCH'18 -- Searching Data on the Web", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This half day workshop explores challenges in data search, with a particular\nfocus on data on the web. We want to stimulate an interdisciplinary discussion\naround how to improve the description, discovery, ranking and presentation of\nstructured and semi-structured data, across data formats and domain\napplications. We welcome contributions describing algorithms and systems, as\nwell as frameworks and studies in human data interaction. The workshop aims to\nbring together communities interested in making the web of data more\ndiscoverable, easier to search and more user friendly.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 09:53:05 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Groth", "Paul", "", "Elsevier Labs"], ["Koesten", "Laura", "", "The Open Data Institute +\n  University of Southampton"], ["Mayr", "Philipp", "", "GESIS - Leibniz Institute for the\n  Social Sciences"], ["de Rijke", "Maarten", "", "University of Amsterdam"], ["Simperl", "Elena", "", "University of Southampton"]]}, {"id": "1805.11907", "submitter": "Atis Elsts", "authors": "Atis Elsts, Tilo Burghardt, Dallan Byrne, Massimo Camplani, Dima\n  Damen, Xenofon Fafoutis, Sion Hannuna, William Harwin, Michael Holmes, Balazs\n  Janko, Victor Ponce Lopez, Alessandro Masullo, Majid Mirmehdi, George\n  Oikonomou, Robert Piechocki, R. Simon Sherratt, Emma Tonkin, Niall Twomey,\n  Antonis Vafeas, Przemyslaw Woznowski, and Ian Craddock", "title": "A Guide to the SPHERE 100 Homes Study Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The SPHERE project has developed a multi-modal sensor platform for health and\nbehavior monitoring in residential environments. So far, the SPHERE platform\nhas been deployed for data collection in approximately 50 homes for duration up\nto one year. This technical document describes the format and the expected\ncontent of the SPHERE dataset(s) under preparation. It includes a list of some\ndata quality problems (both known to exist in the dataset(s) and potential\nones), their workarounds, and other information important to people working\nwith the SPHERE data, software, and hardware. This document does not aim to be\nan exhaustive descriptor of the SPHERE dataset(s); it also does not aim to\ndiscuss or validate the potential scientific uses of the SPHERE data.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 11:34:48 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 14:33:45 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Elsts", "Atis", ""], ["Burghardt", "Tilo", ""], ["Byrne", "Dallan", ""], ["Camplani", "Massimo", ""], ["Damen", "Dima", ""], ["Fafoutis", "Xenofon", ""], ["Hannuna", "Sion", ""], ["Harwin", "William", ""], ["Holmes", "Michael", ""], ["Janko", "Balazs", ""], ["Lopez", "Victor Ponce", ""], ["Masullo", "Alessandro", ""], ["Mirmehdi", "Majid", ""], ["Oikonomou", "George", ""], ["Piechocki", "Robert", ""], ["Sherratt", "R. Simon", ""], ["Tonkin", "Emma", ""], ["Twomey", "Niall", ""], ["Vafeas", "Antonis", ""], ["Woznowski", "Przemyslaw", ""], ["Craddock", "Ian", ""]]}, {"id": "1805.12485", "submitter": "Paul Grefen", "authors": "Paul Grefen, Wout Hofman, Remco Dijkman, Albert Veenstra, Sander\n  Peters", "title": "An Integrated View on the Future of Logistics and Information Technology", "comments": "22 pages, 7 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this position paper, we present our vision on the future of the logistics\nbusiness domain and the use of information technology (IT) in this domain. The\nvision is based on extensive experience with Dutch and European logistics in\nvarious contexts and from various perspectives. We expect that the vision also\nholds for logistics outside Europe. We build our vision in a number of steps.\nFirst, we make an inventory of the most important trends in the logistics\ndomain - we call these mega-trends. Next, we do the same for the information\ntechnology domain, restricted to technologies that have relevance for\nlogistics. Then, we introduce logistics meta-concepts that we use to describe\nour vision and relate them to business engineering. We use these three\ningredients to analyze leading concepts that we currently observe in the\nlogistics domain. Next, we consolidate all elements into a model that\nrepresents our vision of the integrated future of logistics and IT. We\nelaborate on the role of data platforms and open standards in this integrated\nvision.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 14:15:29 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Grefen", "Paul", ""], ["Hofman", "Wout", ""], ["Dijkman", "Remco", ""], ["Veenstra", "Albert", ""], ["Peters", "Sander", ""]]}]