[{"id": "1705.00221", "submitter": "Manuele Rusci Mr.", "authors": "Manuele Rusci, Davide Rossi, Elisabetta Farella, Luca Benini", "title": "A sub-mW IoT-endnode for always-on visual monitoring and smart\n  triggering", "comments": "11 pages, 9 figures, submitteted to IEEE IoT Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a fully-programmable Internet of Things (IoT) visual\nsensing node that targets sub-mW power consumption in always-on monitoring\nscenarios. The system features a spatial-contrast $128\\mathrm{x}64$ binary\npixel imager with focal-plane processing. The sensor, when working at its\nlowest power mode ($10\\mu W$ at 10 fps), provides as output the number of\nchanged pixels. Based on this information, a dedicated camera interface,\nimplemented on a low-power FPGA, wakes up an ultra-low-power parallel\nprocessing unit to extract context-aware visual information. We evaluate the\nsmart sensor on three always-on visual triggering application scenarios.\nTriggering accuracy comparable to RGB image sensors is achieved at nominal\nlighting conditions, while consuming an average power between $193\\mu W$ and\n$277\\mu W$, depending on context activity. The digital sub-system is extremely\nflexible, thanks to a fully-programmable digital signal processing engine, but\nstill achieves 19x lower power consumption compared to MCU-based cameras with\nsignificantly lower on-board computing capabilities.\n", "versions": [{"version": "v1", "created": "Sat, 29 Apr 2017 18:23:43 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Rusci", "Manuele", ""], ["Rossi", "Davide", ""], ["Farella", "Elisabetta", ""], ["Benini", "Luca", ""]]}, {"id": "1705.01013", "submitter": "Wen Jiang", "authors": "Zichang He and Wen Jiang", "title": "Quantum Mechanical Approach to Modelling Reliability of Sensor Reports", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dempster-Shafer evidence theory is wildly applied in multi-sensor data\nfusion. However, lots of uncertainty and interference exist in practical\nsituation, especially in the battle field. It is still an open issue to model\nthe reliability of sensor reports. Many methods are proposed based on the\nrelationship among collected data. In this letter, we proposed a quantum\nmechanical approach to evaluate the reliability of sensor reports, which is\nbased on the properties of a sensor itself. The proposed method is used to\nmodify the combining of evidences.\n", "versions": [{"version": "v1", "created": "Mon, 17 Apr 2017 01:22:15 GMT"}], "update_date": "2017-05-03", "authors_parsed": [["He", "Zichang", ""], ["Jiang", "Wen", ""]]}, {"id": "1705.01402", "submitter": "Zhe Chen", "authors": "Yongshuai Shao and Zhe Chen", "title": "Reconstruction of Missing Big Sensor Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With ubiquitous sensors continuously monitoring and collecting large amounts\nof information, there is no doubt that this is an era of big data. One of the\nimportant sources for scientific big data is the datasets collected by Internet\nof things (IoT). It's considered that these datesets contain highly useful and\nvaluable information. For an IoT application to analyze big sensor data, it is\nnecessary that the data are clean and lossless. However, due to unreliable\nwireless link or hardware failure in the nodes, data loss in IoT is very\ncommon. To reconstruct the missing big sensor data, firstly, we propose an\nalgorithm based on matrix rank-minimization method. Then, we consider IoT with\nmultiple types of sensor in each node. Accounting for possible correlations\namong multiple-attribute sensor data, we propose tensor-based methods to\nestimate missing values. Moreover, effective solutions are proposed using the\nalternating direction method of multipliers. Finally, we evaluate the\napproaches using two real sensor datasets with two missing data-patterns, i.e.,\nrandom missing pattern and consecutive missing pattern. The experiments with\nreal-world sensor data show the effectiveness of the proposed methods.\n", "versions": [{"version": "v1", "created": "Wed, 3 May 2017 13:17:49 GMT"}], "update_date": "2017-05-04", "authors_parsed": [["Shao", "Yongshuai", ""], ["Chen", "Zhe", ""]]}, {"id": "1705.03082", "submitter": "Susan Mniszewski", "authors": "Hayato Ushijima-Mwesigwa, Christian F. A. Negre, and Susan M.\n  Mniszewski", "title": "Graph Partitioning using Quantum Annealing on the D-Wave System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we explore graph partitioning (GP) using quantum annealing on\nthe D-Wave 2X machine. Motivated by a recently proposed graph-based electronic\nstructure theory applied to quantum molecular dynamics (QMD) simulations, graph\npartitioning is used for reducing the calculation of the density matrix into\nsmaller subsystems rendering the calculation more computationally efficient.\nUnconstrained graph partitioning as community clustering based on the\nmodularity metric can be naturally mapped into the Hamiltonian of the quantum\nannealer. On the other hand, when constraints are imposed for partitioning into\nequal parts and minimizing the number of cut edges between parts, a quadratic\nunconstrained binary optimization (QUBO) reformulation is required. This\nreformulation may employ the graph complement to fit the problem in the Chimera\ngraph of the quantum annealer. Partitioning into 2 parts, 2^N parts\nrecursively, and k parts concurrently are demonstrated with benchmark graphs,\nrandom graphs, and small material system density matrix based graphs. Results\nfor graph partitioning using quantum and hybrid classical-quantum approaches\nare shown to equal or out-perform current \"state of the art\" methods.\n", "versions": [{"version": "v1", "created": "Thu, 4 May 2017 23:13:39 GMT"}], "update_date": "2017-05-10", "authors_parsed": [["Ushijima-Mwesigwa", "Hayato", ""], ["Negre", "Christian F. A.", ""], ["Mniszewski", "Susan M.", ""]]}, {"id": "1705.03391", "submitter": "Layan Nahlawi", "authors": "Layan Nahlawi", "title": "Increasing the Discovery Power and Confidence Levels of Disease\n  Association Studies: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of common diseases are influenced by multiple genetic and\nenvironmental factors such as Cancer. Even though uncovering the main causes of\ndisease is deemed difficult due to the complexity of gene-gene and\ngene-environment interactions, major research efforts aim at identifying\ndisease risk factors, especially genetic ones. Over the past decade, disease\nassociation studies have been used to uncover the susceptibility, aetiology and\nmechanisms of action pertaining to common diseases. In disease association\nstudies, genetic data is analyzed in order to reveal the relationship between\ndifferent types of variants, and a disease of interest. The ultimate goal of\nassociation studies is to facilitate susceptibility testing for disease\nprediction, early diagnosis and enhanced prognosis . Susceptibility testing and\ndisease prediction are particularly important for diseases that can be\nprevented by diet, drugs or change in lifestyle. The discovered associations\nassist in understanding the molecular mechanisms influenced by the reported\nvariants, and in identifying important risk factors. Current association\nstudies suffer from several shortcomings. This report surveys the literature\nthat addresses the shortcomings of current methods the identify genetic disease\nassociations. In addition, it reviews the suggested solutions that either\nenhance some aspect of the methodologies, or complement them.\n", "versions": [{"version": "v1", "created": "Tue, 9 May 2017 15:37:47 GMT"}], "update_date": "2017-05-10", "authors_parsed": [["Nahlawi", "Layan", ""]]}, {"id": "1705.04543", "submitter": "Kamel Abdelouahab", "authors": "Kamel Abdelouahab, Maxime Pelcat, Jocelyn Serot, Cedric Bourrasset,\n  Jean-Charles Quinton, Fran\\c{c}ois Berry", "title": "Hardware Automated Dataflow Deployment of CNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": "Haddoc/2016-06TR03", "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Convolutional Neural Networks (CNNs) are the state of the art systems\nfor image classification and scene understating. However, such techniques are\ncomputationally intensive and involve highly regular parallel computation. CNNs\ncan thus benefit from a significant acceleration in execution time when running\non fine grain programmable logic devices. As a consequence, several studies\nhave proposed FPGA-based accelerators for CNNs. However, because of the huge\namount of the required hardware resources, none of these studies directly was\nbased on a direct mapping of the CNN computing elements onto the FPGA physical\nresources. In this work, we demonstrate the feasibility of this so-called\ndirect hardware mapping approach and discuss several associated implementation\nissues. As a proof of concept, we introduce the haddoc2 open source tool, that\nis able to automatically transform a CNN description into a platform\nindependent hardware description for FPGA implementation.\n", "versions": [{"version": "v1", "created": "Thu, 4 May 2017 09:06:29 GMT"}, {"version": "v2", "created": "Thu, 18 May 2017 11:48:13 GMT"}, {"version": "v3", "created": "Thu, 29 Jun 2017 13:27:45 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Abdelouahab", "Kamel", ""], ["Pelcat", "Maxime", ""], ["Serot", "Jocelyn", ""], ["Bourrasset", "Cedric", ""], ["Quinton", "Jean-Charles", ""], ["Berry", "Fran\u00e7ois", ""]]}, {"id": "1705.04583", "submitter": "Athar Khodabakhsh", "authors": "Athar Khodabakhsh, Ismail Ari, Mustafa Bakir", "title": "Cloud-based Fault Detection and Classification for Oil & Gas Industry", "comments": "Part of DM4OG 2017 proceedings (arXiv:1705.03451)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Oil & Gas industry relies on automated, mission-critical equipment and\ncomplex systems built upon their interaction and cooperation. To assure\ncontinuous operation and avoid any supervision, architects embed Distributed\nControl Systems (DCS), a.k.a. Supervisory Control and Data Acquisition (SCADA)\nsystems, on top of their equipment to generate data, monitor state and make\ncritical online & offline decisions.\n  In this paper, we propose a new Lambda architecture for oil & gas industry\nfor unified data and analytical processing on data received from DCS, discuss\ncloud integration issues and share our experiences with the implementation of\nsensor fault-detection and classification modules inside the proposed\narchitecture.\n", "versions": [{"version": "v1", "created": "Thu, 11 May 2017 14:46:32 GMT"}], "update_date": "2017-05-15", "authors_parsed": [["Khodabakhsh", "Athar", ""], ["Ari", "Ismail", ""], ["Bakir", "Mustafa", ""]]}, {"id": "1705.04832", "submitter": "Renata Rychtarikova", "authors": "Renata Rychtarikova, Jan Urban, Dalibor Stys", "title": "Zampa's systems theory: a comprehensive theory of measurement in dynamic\n  systems", "comments": "16 pages, 9 figures", "journal-ref": "Acta Polytechnica 58(2), 128-143, 2018", "doi": "10.14311/AP.2018.58.0128", "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article outlines in memoriam Prof. Pavel Zampa's concepts of system\ntheory which enable to devise a measurement in dynamic systems independently of\nthe particular system behaviour. From the point of view of Zampa's theory,\nterms like system time, system attributes, system link, system element, input,\noutput, subsystems, and state variables are defined. In Conclusions, Zampa's\ntheory is discussed together with another mathematical approaches of\nqualitative dynamics known since the 19th century. In Appendices, we present\napplications of Zampa's technical approach to measurement of complex dynamical\n(chemical and biological) systems at the Institute of Complex Systems,\nUniversity of South Bohemia in Ceske Budejovice.\n", "versions": [{"version": "v1", "created": "Sat, 13 May 2017 14:10:47 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 12:28:38 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Rychtarikova", "Renata", ""], ["Urban", "Jan", ""], ["Stys", "Dalibor", ""]]}, {"id": "1705.04958", "submitter": "Jaydip Sen", "authors": "Sanjib Biswas and Jaydip Sen", "title": "A Proposed Architecture for Big Data Driven Supply Chain Analytics", "comments": "24 pages, 4 figures, 3 tables", "journal-ref": "ICFAI University Press (IUP) Journal of Supply Chain Management,\n  Vol XIII, No 3 (2016), pp. 7 - 34", "doi": "10.2139/ssrn.2795906", "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advancement in information and communication technology (ICT) has given rise\nto explosion of data in every field of operations. Working with the enormous\nvolume of data (or Big Data, as it is popularly known as) for extraction of\nuseful information to support decision making is one of the sources of\ncompetitive advantage for organizations today. Enterprises are leveraging the\npower of analytics in formulating business strategy in every facet of their\noperations to mitigate business risk. Volatile global market scenario has\ncompelled the organizations to redefine their supply chain management (SCM). In\nthis paper, we have delineated the relevance of Big Data and its importance in\nmanaging end to end supply chains for achieving business excellence. A Big\nData-centric architecture for SCM has been proposed that exploits the current\nstate of the art technology of data management, analytics and visualization.\nThe security and privacy requirements of a Big Data system have also been\nhighlighted and several mechanisms have been discussed to implement these\nfeatures in a real world Big Data system deployment in the context of SCM. Some\nfuture scope of work has also been pointed out. Keyword: Big Data, Analytics,\nCloud, Architecture, Protocols, Supply Chain Management, Security, Privacy.\n", "versions": [{"version": "v1", "created": "Sun, 14 May 2017 12:39:46 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Biswas", "Sanjib", ""], ["Sen", "Jaydip", ""]]}, {"id": "1705.04980", "submitter": "Bing Li", "authors": "Bing Li, Ning Chen, Ulf Schlichtmann", "title": "Statistical Timing Analysis for Latch-Controlled Circuits with Reduced\n  Iterations and Graph Transformations", "comments": null, "journal-ref": "IEEE Transactions on Computer-Aided Design of Integrated Circuits\n  and Systems 31(11), 1670-1683, November 2012", "doi": "10.1109/TCAD.2012.2202393", "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Level-sensitive latches are widely used in high- performance designs. For\nsuch circuits efficient statistical timing analysis algorithms are needed to\ntake increasing process vari- ations into account. But existing methods solving\nthis problem are still computationally expensive and can only provide the yield\nat a given clock period. In this paper we propose a method combining reduced\niterations and graph transformations. The reduced iterations extract setup time\nconstraints and identify a subgraph for the following graph transformations\nhandling the constraints from nonpositive loops. The combined algorithms are\nvery efficient, more than 10 times faster than other existing methods, and\nresult in a parametric minimum clock period, which together with the hold time\nconstraints can be used to compute the yield at any given clock period very\neasily.\n", "versions": [{"version": "v1", "created": "Sun, 14 May 2017 15:44:38 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Li", "Bing", ""], ["Chen", "Ning", ""], ["Schlichtmann", "Ulf", ""]]}, {"id": "1705.05219", "submitter": "Sobhan Moosavi", "authors": "Sobhan Moosavi, Behrooz Omidvar-Tehrani, R. Bruce Craig, Rajiv Ramnath", "title": "Annotation of Car Trajectories based on Driving Patterns", "comments": "A 10 pages technical report which described the process of preparing\n  a ground-truth dataset", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the ubiquity of various sensors enables the collection of\nvoluminous datasets of car trajectories. Such datasets enable analysts to make\nsense of driving patterns and behaviors: in order to understand the behavior of\ndrivers, one approach is to break a trajectory into its underlying patterns and\nthen analyze that trajectory in terms of derived patterns. The process of\ntrajectory segmentation is a function of various resources including a set of\nground truth trajectories with their driving patterns. To the best of our\nknowledge, no such ground-truth dataset exists in the literature. In this\npaper, we describe a trajectory annotation framework and report our results to\nannotate a dataset of personal car trajectories. Our annotation methodology\nconsists of a crowd-sourcing task followed by a precise process of aggregation.\nOur annotation process consists of two granularity levels, one to specify the\nannotation (segment border) and the other one to describe the type of the\nsegment (e.g. speed-up, turn, merge, etc.). The output of our project, Dataset\nof Annotated Car Trajectories (DACT), is available online at\nhttps://figshare.com/articles/dact_dataset_of_annotated_car_trajectories/5005289 .\n", "versions": [{"version": "v1", "created": "Mon, 15 May 2017 13:30:36 GMT"}, {"version": "v2", "created": "Tue, 16 May 2017 14:48:34 GMT"}], "update_date": "2017-05-17", "authors_parsed": [["Moosavi", "Sobhan", ""], ["Omidvar-Tehrani", "Behrooz", ""], ["Craig", "R. Bruce", ""], ["Ramnath", "Rajiv", ""]]}, {"id": "1705.05237", "submitter": "Wiktor Daszczuk", "authors": "Wiktor B. Daszczuk", "title": "Discrete Event Simulation of Personal Rapid Transit (PRT) Systems", "comments": "12 pages, 3 figures", "journal-ref": "Autobusy-TEST, vol. 17(2016), No.3, pp.1302-1310", "doi": null, "report-no": null, "categories": "cs.OH cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article discusses issues related to the construction of the PRT network\nsimulator and the simulation process: the elements of PRT network structure,\ntheir representation in the simulator, the simulation process itself,\nanimation, and automation of the experiments. An example of a simulation\nenvironment Feniks is described, elaborated within the framework of the\nEco-Mobility project.\n", "versions": [{"version": "v1", "created": "Fri, 12 May 2017 09:44:25 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Daszczuk", "Wiktor B.", ""]]}, {"id": "1705.05767", "submitter": "Stephen Makonin", "authors": "Stephen Makonin, Z. Jane Wang, and Chris Tumpach", "title": "RAE: The Rainforest Automation Energy Dataset for Smart Grid Meter Data\n  Analysis", "comments": null, "journal-ref": null, "doi": "10.3390/data3010008", "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Datasets are important for researchers to build models and test how well\ntheir machine learning algorithms perform. This paper presents the Rainforest\nAutomation Energy (RAE) dataset to help smart grid researchers test their\nalgorithms which make use of smart meter data. This initial release of RAE\ncontains 1Hz data (mains and sub-meters) from two a residential house. In\naddition to power data, environmental and sensor data from the house's\nthermostat is included. Sub-meter data from one of the houses includes heat\npump and rental suite captures which is of interest to power utilities. We also\nshow and energy breakdown of each house and show (by example) how RAE can be\nused to test non-intrusive load monitoring (NILM) algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 14 May 2017 04:57:27 GMT"}, {"version": "v2", "created": "Tue, 23 May 2017 16:11:47 GMT"}, {"version": "v3", "created": "Wed, 3 Jan 2018 02:01:57 GMT"}, {"version": "v4", "created": "Mon, 12 Feb 2018 10:09:36 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Makonin", "Stephen", ""], ["Wang", "Z. Jane", ""], ["Tumpach", "Chris", ""]]}, {"id": "1705.06345", "submitter": "Hamed Nikhalat Jahromi", "authors": "Hamed Nikhalat Jahromi, Alpio M. Jorge", "title": "An Overview of Data Mining Applications in Oil and Gas Exploration:\n  Structural Geology and Reservoir Property-Issues", "comments": "Part of DM4OG 2017 proceedings (arXiv:1705.03451)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low oil prices have motivated energy executives to look into cost reduction\nin their supply chains more seriously. To this end, a new technology that is\nexperimentally considered in hydrocarbon exploration is data mining. There are\ntwo major categories of geoscientific problems in which data mining is applied:\nstructural geology and reservoir property-issues. This research overviews these\ncategories by considering a variety of interesting works in each of them. The\nresult is an understanding of the specific geoscientific problems studied in\nthe literature, along with the relative data mining methods. This way, this\nwork tries to lay the ground for a mutual understanding on oil and gas\nexploration between the data miners and the geoscientists.\n", "versions": [{"version": "v1", "created": "Fri, 12 May 2017 16:22:06 GMT"}], "update_date": "2017-05-19", "authors_parsed": [["Jahromi", "Hamed Nikhalat", ""], ["Jorge", "Alpio M.", ""]]}, {"id": "1705.06556", "submitter": "Jorge Guevara", "authors": "Jorge Guevara, Matthias Kormaksson, Bianca Zadrozny, Ligang Lu, John\n  Tolle, Tyler Croft, Mingqi Wu, Jan Limbeck, Detlef Hohl", "title": "A data-driven workflow for predicting horizontal well production using\n  vertical well logs", "comments": "Part of DM4OG 2017 proceedings (arXiv:1705.03451)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent work, data-driven sweet spotting technique for shale plays\npreviously explored with vertical wells has been proposed. Here, we extend this\ntechnique to multiple formations and formalize a general data-driven workflow\nto facilitate feature extraction from vertical well logs and predictive\nmodeling of horizontal well production. We also develop an experimental\nframework that facilitates model selection and validation in a realistic\ndrilling scenario. We present some experimental results using this methodology\nin a field with 90 vertical wells and 98 horizontal wells, showing that it can\nachieve better results in terms of predictive ability than kriging of known\nproduction values.\n", "versions": [{"version": "v1", "created": "Mon, 15 May 2017 18:35:50 GMT"}], "update_date": "2017-05-19", "authors_parsed": [["Guevara", "Jorge", ""], ["Kormaksson", "Matthias", ""], ["Zadrozny", "Bianca", ""], ["Lu", "Ligang", ""], ["Tolle", "John", ""], ["Croft", "Tyler", ""], ["Wu", "Mingqi", ""], ["Limbeck", "Jan", ""], ["Hohl", "Detlef", ""]]}, {"id": "1705.11104", "submitter": "Imran Memon", "authors": "Imran Memon, Qasim Ali Arain", "title": "Optimal placement of mix zones in road networks", "comments": "10 pages,9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The road networks, vehicle users could enjoy numerous kind of services such\nas location based service in vehicle users can connected to Internet and\ncommunication of different users. Therefore, in order to acquire adequate\nprivacy level and quality of service, one must have to wisely place mix zones\nto connect vehicle users to internet or some other internetwork. According to\nthis research, we have analyzed the problem of optimal placement mix zones over\nroad network. To enhance the coverage capacity of vehicles, in order to reduce\nthe cost and communication delay. Further, it has also been discovered to\nminimize the cost of mix zone placement. Moreover, it has also been shown that,\nas the best deployment mix zones get minimized cost while at the same time the\naverage capacity of mix zone can be maximized also privacy level increased\nbecause of optimal placement and high traffic environment.\n", "versions": [{"version": "v1", "created": "Wed, 17 May 2017 01:20:07 GMT"}], "update_date": "2017-06-01", "authors_parsed": [["Memon", "Imran", ""], ["Arain", "Qasim Ali", ""]]}, {"id": "1705.11132", "submitter": "Zhanyu Ma", "authors": "Zhanyu Ma, Jiyang Xie, Hailong Li, Qie Sun, Zhongwei Si, Jianhua\n  Zhang, Jun Guo", "title": "The Role of Data Analysis in the Development of Intelligent Energy\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data analysis plays an important role in the development of intelligent\nenergy networks (IENs). This article reviews and discusses the application of\ndata analysis methods for energy big data. The installation of smart energy\nmeters has provided a huge volume of data at different time resolutions,\nsuggesting data analysis is required for clustering, demand forecasting, energy\ngeneration optimization, energy pricing, monitoring and diagnostics. The\ncurrently adopted data analysis technologies for IENs include pattern\nrecognition, machine learning, data mining, statistics methods, etc. However,\nexisting methods for data analysis cannot fully meet the requirements for\nprocessing the big data produced by the IENs and, therefore, more comprehensive\ndata analysis methods are needed to handle the increasing amount of data and to\nmine more valuable information.\n", "versions": [{"version": "v1", "created": "Tue, 30 May 2017 08:53:29 GMT"}], "update_date": "2017-06-01", "authors_parsed": [["Ma", "Zhanyu", ""], ["Xie", "Jiyang", ""], ["Li", "Hailong", ""], ["Sun", "Qie", ""], ["Si", "Zhongwei", ""], ["Zhang", "Jianhua", ""], ["Guo", "Jun", ""]]}]