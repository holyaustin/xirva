[{"id": "1711.00333", "submitter": "Jimmy Lin", "authors": "Raphael Tang, Weijie Wang, Zhucheng Tu, Jimmy Lin", "title": "An Experimental Analysis of the Power Consumption of Convolutional\n  Neural Networks for Keyword Spotting", "comments": "Published in ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nearly all previous work on small-footprint keyword spotting with neural\nnetworks quantify model footprint in terms of the number of parameters and\nmultiply operations for a feedforward inference pass. These values are,\nhowever, proxy measures since empirical performance in actual deployments is\ndetermined by many factors. In this paper, we study the power consumption of a\nfamily of convolutional neural networks for keyword spotting on a Raspberry Pi.\nWe find that both proxies are good predictors of energy usage, although the\nnumber of multiplies is more predictive than the number of model parameters. We\nalso confirm that models with the highest accuracies are, unsurprisingly, the\nmost power hungry.\n", "versions": [{"version": "v1", "created": "Mon, 30 Oct 2017 18:24:35 GMT"}, {"version": "v2", "created": "Fri, 21 Sep 2018 11:00:40 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Tang", "Raphael", ""], ["Wang", "Weijie", ""], ["Tu", "Zhucheng", ""], ["Lin", "Jimmy", ""]]}, {"id": "1711.02149", "submitter": "Hatem Mahmoud", "authors": "Hatem A. Mahmoud", "title": "Detecting Disguised Plagiarism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Source code plagiarism detection is a problem that has been addressed several\ntimes before; and several tools have been developed for that purpose. In this\nresearch project we investigated a set of possible disguises that can be\nmechanically applied to plagiarized source code to defeat plagiarism detection\ntools. We propose a preprocessor to be used with existing plagiarism detection\ntools to \"normalize\" source code before checking it, thus making such disguises\nineffective.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 08:58:52 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Mahmoud", "Hatem A.", ""]]}, {"id": "1711.03406", "submitter": "Chen Zheng", "authors": "HuaChun Zhang, Lynden Kagan, Chen Zheng", "title": "Machine Learning Based Fast Power Integrity Classifier", "comments": "6 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we proposed a new machine learning based fast power integrity\nclassifier that quickly flags the EM/IR hotspots. We discussed the features to\nextract to describe the power grid, cell power density, routing impact and\ncontrolled collapse chip connection (C4) bumps, etc. The continuous and\ndiscontinuous cases are identified and treated using different machine learning\nmodels. Nearest neighbors, random forest and neural network models are compared\nto select the best performance candidates. Experiments are run on open source\nbenchmark, and result is showing promising prediction accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 03:07:05 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Zhang", "HuaChun", ""], ["Kagan", "Lynden", ""], ["Zheng", "Chen", ""]]}, {"id": "1711.03651", "submitter": "Liang He", "authors": "Liang He, Kang G. Shin", "title": "How Long Will My Phone Battery Last?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile devices are only as useful as their battery lasts. Unfortunately, the\noperation and life of a mobile device's battery degrade over time and usage.\nThe state-of-health (SoH) of batteries quantifies their degradation, but mobile\ndevices are unable to support its accurate estimation -- despite its importance\n-- due mainly to their limited hardware and dynamic usage patterns, causing\nvarious problems such as unexpected device shutoffs or even fire/explosion. To\nremedy this lack of support, we design, implement and evaluate V-Health, a\nlow-cost user-level SoH estimation service for mobile devices based only on\ntheir battery voltage, which is commonly available on all commodity mobile\ndevices. V-Health also enables four novel use-cases that improve mobile users'\nexperience from different perspectives. The design of V-Health is inspired by\nour empirical finding that the relaxing voltages of a device battery\nfingerprint its SoH, and is steered by extensive measurements with 15 batteries\nused for various commodity mobile devices, such as Nexus 6P, Galaxy S3, iPhone\n6 Plus, etc. These measurements consist of 13,377 battery\ndischarging/charging/resting cycles and have been conducted over 72 months\ncumulatively. V-Health has been evaluated via both laboratory experiments and\nfield tests over 4-6 months, showing <5% error in SoH estimation.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 23:52:41 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["He", "Liang", ""], ["Shin", "Kang G.", ""]]}, {"id": "1711.05879", "submitter": "Leonardo Santos", "authors": "Leonardo B L Santos, Aurelienne A S Jorge, Marcio Rossato, Jessica D\n  Santos, Onofre A Candido, Wilson Seron, Charles N de Santana", "title": "(geo)graphs - Complex Networks as a shapefile of nodes and a shapefile\n  of edges for different applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial dependency and spatial embedding are basic physical properties of\nmany phenomena modeled by networks. The most indicated computational\nenvironment to deal with spatial information is to use Georeferenced\nInformation System (GIS) and Geographical Database Management Systems (GDBMS).\nSeveral models have been proposed in this direction, however there is a gap in\nthe literature in generic frameworks for working with Complex Networks in\nGIS/GDBMS environments. Here we introduce the concept of (geo)graphs: graphs in\nwhich the nodes have a known geographical location and the edges have spatial\ndependence. We present case studies and two open source softwares (GIS4GRAPH\nand GeoCNet) that indicate how to retrieve networks from GIS data and how to\nrepresent networks over GIS data by using (geo)graphs.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 01:19:14 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Santos", "Leonardo B L", ""], ["Jorge", "Aurelienne A S", ""], ["Rossato", "Marcio", ""], ["Santos", "Jessica D", ""], ["Candido", "Onofre A", ""], ["Seron", "Wilson", ""], ["de Santana", "Charles N", ""]]}, {"id": "1711.07106", "submitter": "Zhen Shen", "authors": "Zhen Shen, Yong Yao, Yi Xie, Chao Guo, Xiuqin Shang, Xisong Dong,\n  Yuqing Li, Zhouxian Pan, Shi Chen, Hui Pan and Gang Xiong", "title": "The process of 3D-printed skull models for the anatomy education", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective The 3D printed medical models can come from virtual digital\nresources, like CT scanning. Nevertheless, the accuracy of CT scanning\ntechnology is limited, which is 1mm. In this situation, the collected data is\nnot exactly the same as the real structure and there might be some errors\ncausing the print to fail. This study presents a common and practical way to\nprocess the skull data to make the structures correctly. And then we make a\nskull model through 3D printing technology, which is useful for medical\nstudents to understand the complex structure of skull. Materials and Methods\nThe skull data is collected by the CT scan. To get a corrected medical model,\nthe computer-assisted image processing goes with the combination of five 3D\nmanipulation tools: Mimics, 3ds Max, Geomagic, Mudbox and Meshmixer, to\nreconstruct the digital model and repair it. Subsequently, we utilize a\nlow-cost desktop 3D printer, Ultimaker2, with polylactide filament (PLA)\nmaterial to print the model and paint it based on the atlas. Result After the\nrestoration and repairing, we eliminate the errors and repair the model by\nadding the missing parts of the uploaded data within 6 hours. Then we print it\nand compare the model with the cadaveric skull from frontal, left, right and\nanterior views respectively. The printed model can show the same structures and\nalso the details of the skull clearly and is a good alternative of the\ncadaveric skull.\n", "versions": [{"version": "v1", "created": "Sun, 19 Nov 2017 23:58:25 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Shen", "Zhen", ""], ["Yao", "Yong", ""], ["Xie", "Yi", ""], ["Guo", "Chao", ""], ["Shang", "Xiuqin", ""], ["Dong", "Xisong", ""], ["Li", "Yuqing", ""], ["Pan", "Zhouxian", ""], ["Chen", "Shi", ""], ["Pan", "Hui", ""], ["Xiong", "Gang", ""]]}, {"id": "1711.07304", "submitter": "Ananya Saha", "authors": "Ananya Saha and Buddhadeb Sau", "title": "Solution of network localization problem with noisy distances and its\n  convergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The network localization problem with convex and non-convex distance\nconstraints may be modeled as a nonlinear optimization problem. The existing\nlocalization techniques are mainly based on convex optimization. In those\ntechniques, the non-convex distance constraints are either ignored or relaxed\ninto convex constraints for using the convex optimization methods like SDP,\nleast square approximation, etc.. We propose a method to solve the nonlinear\nnon-convex network localization problem with noisy distance measurements\nwithout any modification of constraints in the general model. We use the\nnonlinear Lagrangian technique for non-convex optimization to convert the\nproblem to a root finding problem of a single variable continuous function.\nThis problem is then solved using an iterative method. However, in each step of\nthe iteration the computation of the functional value involves a finite\nmini-max problem (FMX). We use smoothing gradient method to fix the FMX\nproblem. We also prove that the solution obtained from the proposed iterative\nmethod converges to the actual solution of the general localization problem.\nThe proposed method obtains the solutions with a desired label of accuracy in\nreal time.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 13:34:10 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Saha", "Ananya", ""], ["Sau", "Buddhadeb", ""]]}, {"id": "1711.09369", "submitter": "Alfonso Luis Casta\\~no Mar\\'in", "authors": "Alfonso L. Casta\\~no, Javier Cuenca, Domingo Gim\\'enez, Jose J.\n  L\\'opez-Esp\\'in, Alberto P\\'erez-Bernabeu", "title": "Obtaining the coefficients of a Vector Autoregression Model through\n  minimization of parameter criteria", "comments": "International Workshop on Optimization and Learning: Challenges and\n  Applications, Alicante (Spain)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  VAR models are a type of multi-equation model that have been widely applied\nin econometrics. With the arrival of Big Data, huge amounts of data are being\ncollected in numerous fields, making feasible the application of these kind of\nstatistical models. Tools exist to tackle this problem, but the large amount of\ndata, along with the availability of computational techniques and high\nperformance systems, advise an in-depth analysis of the computational aspects\nof VAR, so large models can be solved efficiently with today's computational\nsystems.\n  This work aims to solve a VAR model by obtaining the coefficients through\nheuristic and metaheuristic algorithms, minimizing one parameter criterion, and\nalso to compare with those coefficients obtained by OLS. Furthermore, we\nconsider different approaches to reduce the time required to find the model\nlike using matrix decompositions (QR or LQ), exploiting matrix structure, using\nhigh performance linear algebra subroutines (BLAS and LAPACK) or parallel\nmetaheuristics.\n", "versions": [{"version": "v1", "created": "Sun, 26 Nov 2017 11:22:53 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Casta\u00f1o", "Alfonso L.", ""], ["Cuenca", "Javier", ""], ["Gim\u00e9nez", "Domingo", ""], ["L\u00f3pez-Esp\u00edn", "Jose J.", ""], ["P\u00e9rez-Bernabeu", "Alberto", ""]]}, {"id": "1711.10481", "submitter": "Efstratios Rappos", "authors": "Efstratios Rappos", "title": "Treatment of Unicode canoncal decomposition among operating systems", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article shows how the text characters that have multiple representations\nunder the Unicode standard are treated by popular operating systems. Whilst\nmost characters have a unique representation in Unicode, some characters such\nas the accented European letters, can have multiple representations due to a\nfeature of Unicode called normalization. These characters are treated\ndifferently by popular operating systems, leading to additional challenges\nduring interoperability of computer programs.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 12:59:22 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Rappos", "Efstratios", ""]]}, {"id": "1711.10801", "submitter": "Saptarshi Pal", "authors": "Saptarshi Pal and Soumya K Ghosh", "title": "Rule based End-to-End Learning Framework for Urban Growth Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the rapid growth of urban areas in the past decades, it has become\nincreasingly important to model and monitor urban growth in mega cities.\nAlthough several researchers have proposed models for simulating urban growth,\nthey have been primarily dependent on various manually selected spatial and\nnonspatial explanatory features for building models. A practical difficulty\nwith this approach is manual selection procedure, which tends to make model\ndesign process laborious and non-generic. Despite the fact that explanatory\nfeatures provide us with the understanding of a complex process, there has been\nno standard set of features in urban growth prediction over which scholars have\nconsensus. Hence, design and deploying of systems for urban growth prediction\nhave remained challenging tasks. In order to reduce the dependency on human\ndevised features, we have proposed a novel End-to-End prediction framework to\nrepresent remotely sensed satellite data in terms of rules of a cellular\nautomata model in order to improve the performance of urban growth prediction.\nUsing our End-to-End framework, we have achieved superior performance in Figure\nof Merit, Producer's accuracy, User's accuracy, and Overall accuracy metrics\nrespectively over existing learning based methods.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 11:53:02 GMT"}, {"version": "v2", "created": "Mon, 11 Dec 2017 08:57:22 GMT"}, {"version": "v3", "created": "Sat, 3 Feb 2018 04:10:37 GMT"}, {"version": "v4", "created": "Tue, 29 May 2018 08:58:12 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Pal", "Saptarshi", ""], ["Ghosh", "Soumya K", ""]]}, {"id": "1711.10874", "submitter": "Asad Malik", "authors": "Asad Malik", "title": "Explanation of an Invisible Common Constraint of Mind, Mathematics and\n  Computational Complexity", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a cognitive limit in Human Mind. This cognitive limit has played a\ndecisive role in almost all fields including computer sciences. The cognitive\nlimit replicated in computer sciences is responsible for inherent Computational\nComplexity. The complexity starts decreasing if certain conditions are met,\neven sometime it does not appears at all. Very simple Mechanical computing\nsystems are designed and implemented to demonstrate this idea and it is further\nsupported by Electrical systems. These verifiable and consistent systems\ndemonstrate the idea of computational complexity reduction. This work explains\na very important but invisible connection from Mind to Mathematical axioms\n(Peano Axioms etc.) and Mathematical axioms to computational complexity. This\nstudy gives a completely new perspective that goes well beyond Cognitive\nScience, Mathematics, Physics, Computer Sciences and Philosophy. Based on this\nnew insight some important predictions are made.\n", "versions": [{"version": "v1", "created": "Thu, 23 Nov 2017 18:23:07 GMT"}, {"version": "v2", "created": "Mon, 11 Dec 2017 13:01:17 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Malik", "Asad", ""]]}]