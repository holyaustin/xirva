[{"id": "1909.02960", "submitter": "Emil Pricop", "authors": "Florin Zamfir, Nicolae Paraschiv, Emil Pricop", "title": "Real-time stock analysis for blending recipes in industrial plants", "comments": "Accepted for presentation at 23rd International Conference on System\n  Theory, Control and Computing (ICSTCC 2019), October 9-11, 2019, Sinaia,\n  Romania", "journal-ref": null, "doi": "10.1109/ICSTCC.2019.8886147", "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many companies use Excel spreadsheets to keep stock records and to calculate\nprocess-specific data. These spreadsheets are often hard to understand and\ntrack. And if the user does not protect them, there is a risk that the user\nrandomly changes or erase formulas. The paper focuses on the stocks of products\nused in a blending process with a known recipe. Developing an application that\ncan bring this data in a centralized form and that can assist the operator in\ndecide is a necessity. When a programmer implements an application that uses\ndata from plants he needs to consider one fundamental aspect as reading\nreal-time data from the process. The real-time stock analysis application takes\ninto account all the above elements. The application is easy to use by an\noperator in the command room of installation because of the planning algorithms\nintegrated into it. The algorithms proposed and implemented in this paper have\nwell-defined goals: identifying the ingredients needed to achieve the blending\nprocess for required quantities, determine the quantities of the finished\nproduct that can be made with the existing ingredients and determine the\noptimum quantities of the finished product. The application implemented in C#\nintensively uses these algorithms and gives the user the ability to build the\nresult step by step.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 13:36:09 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Zamfir", "Florin", ""], ["Paraschiv", "Nicolae", ""], ["Pricop", "Emil", ""]]}, {"id": "1909.09954", "submitter": "Grigory Tsiperman", "authors": "Grigory Tsiperman", "title": "Stochastic model of business process decomposition", "comments": "Published in two languages (English and Russian)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decomposition is the basis of works dedicated to business process modelling\nat the stage of information and management systems analysis and design. The\narticle shows that the business process decomposition can be represented as a\nGalton Watson branching stochastic process. This representation allows\nestimating the decomposition tree depth and the total amount of its elements,\nas well as explaining the empirical requirement for the business function\ndecomposition (not more than 7 elements). The problem is deemed relevant as the\nobtained results allow objectively estimating the labor input in business\nprocess modelling.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 07:30:35 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Tsiperman", "Grigory", ""]]}, {"id": "1909.10308", "submitter": "Marco Piangerelli", "authors": "Marco Piangerelli, Giacomo Rocchetti, Alessandro Liscio, Renato De\n  Leone", "title": "BinarySDG: binary sensor data generation with R", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scarcity of Smart Home data is still a pretty big problem, and in a world\nwhere the size of a dataset can often make the difference between a poor\nperformance and a good performance for problems related to machine learning\nprojects, this needs to be resolved. But whereas the problem of retrieving real\ndata can't really be resolved, as most of the time the process of installing\nsensors and retrieving data can be found to be really expensive and\ntime-consuming, we need to find a faster and easier solution, which is where\nsynthetic data comes in. Here we propose BinarySDG (Binary Synthetic Data\nGenerator) as a flexible and easy way to generate synthetic data for binary\nsensors.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 14:39:08 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Piangerelli", "Marco", ""], ["Rocchetti", "Giacomo", ""], ["Liscio", "Alessandro", ""], ["De Leone", "Renato", ""]]}, {"id": "1909.11156", "submitter": "Emilio Almansi", "authors": "Emilio Almansi, Ver\\'onica Becher", "title": "Completely uniformly distributed sequences based on de Bruijn sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.OH math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a construction published by Donald Knuth in 1965 yielding a\ncompletely uniformly distributed sequence of real numbers. Knuth's work is\nbased on de Bruijn sequences of increasing orders and alphabet sizes, which\ngrow exponentially in each of the successive segments composing the generated\nsequence. In this work we present a similar albeit simpler construction using\nlinearly increasing alphabet sizes, and give an elementary proof showing that\nthe sequence it yields is also completely uniformly distributed. In addition,\nwe present an alternative proof of the same result based on Weyl's criterion.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 20:12:11 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Almansi", "Emilio", ""], ["Becher", "Ver\u00f3nica", ""]]}, {"id": "1909.13710", "submitter": "John Nairn", "authors": "John A. Nairn", "title": "Exact Calculation of Expected Values for Splitting Pairs in Blackjack", "comments": "23 pages, 3 figures, 4 tables (two of them sideways, full page\n  tables)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer calculations for most exact expected values in blackjack have been\navailable since the 1960's, but exact results for pair splitting and\nresplitting have previously been too computer intensive. This paper describes a\nnew algorithm for exact pair-splitting. By using dealer probability caching\nmethods and revising the method for recursively generating possible player\nhands, the estimated calculation time compared to standard methods was reduced\nby five orders of magnitude. The resulting algorithm was used to calculate the\nfirst exact and complete pair splitting results for a single deck game. The\nexact results were compared to prior approximate theories for resplitting. The\nprior theories are accurate for many calculations, but inaccurate for\nresplitting tens. A new approximation method was developed that is accurate for\nall resplitting calculations.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 23:13:03 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Nairn", "John A.", ""]]}]